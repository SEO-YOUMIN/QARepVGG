==========================================
real base lr:  0.1
==========================================
[32m[2023-07-06 16:35:26 RepVGG-A0][33m(main.py 419)[39m: INFO Full config saved to /your/path/to/save/dir/RepVGG-A0/train_from_scratch/config.json
[32m[2023-07-06 16:35:26 RepVGG-A0][33m(main.py 422)[39m: INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 32
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /workspace/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 32
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /your/path/to/save/dir/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 0.1
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001
Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
use raw ImageNet data
local rank 0 / global rank 0 successfully build train dataset
use raw ImageNet data
local rank 0 / global rank 0 successfully build val dataset
[32m[2023-07-06 16:35:31 RepVGG-A0][33m(main.py 84)[39m: INFO Creating model:RepVGG-A0
=================== Building the vanila RepVGG ===================
RepVGG Block, identity =  None
RepVGG Block, identity =  None
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  None
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  None
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  Identity()
RepVGG Block, identity =  None
stage0.rbr_dense.conv.weight USE weight decay
stage0.rbr_dense.bn.weight has no weight decay
stage0.rbr_dense.bn.bias has no weight decay
stage0.rbr_1x1.conv.weight USE weight decay
stage0.rbr_whbn.weight has no weight decay
stage0.rbr_whbn.bias has no weight decay
stage1.0.rbr_dense.conv.weight USE weight decay
stage1.0.rbr_dense.bn.weight has no weight decay
stage1.0.rbr_dense.bn.bias has no weight decay
stage1.0.rbr_1x1.conv.weight USE weight decay
stage1.0.rbr_whbn.weight has no weight decay
stage1.0.rbr_whbn.bias has no weight decay
stage1.1.rbr_dense.conv.weight USE weight decay
stage1.1.rbr_dense.bn.weight has no weight decay
stage1.1.rbr_dense.bn.bias has no weight decay
stage1.1.rbr_1x1.conv.weight USE weight decay
stage1.1.rbr_whbn.weight has no weight decay
stage1.1.rbr_whbn.bias has no weight decay
stage2.0.rbr_dense.conv.weight USE weight decay
stage2.0.rbr_dense.bn.weight has no weight decay
stage2.0.rbr_dense.bn.bias has no weight decay
stage2.0.rbr_1x1.conv.weight USE weight decay
stage2.0.rbr_whbn.weight has no weight decay
stage2.0.rbr_whbn.bias has no weight decay
stage2.1.rbr_dense.conv.weight USE weight decay
stage2.1.rbr_dense.bn.weight has no weight decay
stage2.1.rbr_dense.bn.bias has no weight decay
stage2.1.rbr_1x1.conv.weight USE weight decay
stage2.1.rbr_whbn.weight has no weight decay
stage2.1.rbr_whbn.bias has no weight decay
stage2.2.rbr_dense.conv.weight USE weight decay
stage2.2.rbr_dense.bn.weight has no weight decay
stage2.2.rbr_dense.bn.bias has no weight decay
stage2.2.rbr_1x1.conv.weight USE weight decay
stage2.2.rbr_whbn.weight has no weight decay
stage2.2.rbr_whbn.bias has no weight decay
stage2.3.rbr_dense.conv.weight USE weight decay
stage2.3.rbr_dense.bn.weight has no weight decay
stage2.3.rbr_dense.bn.bias has no weight decay
stage2.3.rbr_1x1.conv.weight USE weight decay
stage2.3.rbr_whbn.weight has no weight decay
stage2.3.rbr_whbn.bias has no weight decay
stage3.0.rbr_dense.conv.weight USE weight decay
stage3.0.rbr_dense.bn.weight has no weight decay
stage3.0.rbr_dense.bn.bias has no weight decay
stage3.0.rbr_1x1.conv.weight USE weight decay
stage3.0.rbr_whbn.weight has no weight decay
stage3.0.rbr_whbn.bias has no weight decay
stage3.1.rbr_dense.conv.weight USE weight decay
stage3.1.rbr_dense.bn.weight has no weight decay
stage3.1.rbr_dense.bn.bias has no weight decay
stage3.1.rbr_1x1.conv.weight USE weight decay
stage3.1.rbr_whbn.weight has no weight decay
stage3.1.rbr_whbn.bias has no weight decay
stage3.2.rbr_dense.conv.weight USE weight decay
stage3.2.rbr_dense.bn.weight has no weight decay
stage3.2.rbr_dense.bn.bias has no weight decay
stage3.2.rbr_1x1.conv.weight USE weight decay
stage3.2.rbr_whbn.weight has no weight decay
stage3.2.rbr_whbn.bias has no weight decay
stage3.3.rbr_dense.conv.weight USE weight decay
stage3.3.rbr_dense.bn.weight has no weight decay
stage3.3.rbr_dense.bn.bias has no weight decay
stage3.3.rbr_1x1.conv.weight USE weight decay
stage3.3.rbr_whbn.weight has no weight decay
stage3.3.rbr_whbn.bias has no weight decay
stage3.4.rbr_dense.conv.weight USE weight decay
stage3.4.rbr_dense.bn.weight has no weight decay
stage3.4.rbr_dense.bn.bias has no weight decay
stage3.4.rbr_1x1.conv.weight USE weight decay
stage3.4.rbr_whbn.weight has no weight decay
stage3.4.rbr_whbn.bias has no weight decay
stage3.5.rbr_dense.conv.weight USE weight decay
stage3.5.rbr_dense.bn.weight has no weight decay
stage3.5.rbr_dense.bn.bias has no weight decay
stage3.5.rbr_1x1.conv.weight USE weight decay
stage3.5.rbr_whbn.weight has no weight decay
stage3.5.rbr_whbn.bias has no weight decay
stage3.6.rbr_dense.conv.weight USE weight decay
stage3.6.rbr_dense.bn.weight has no weight decay
stage3.6.rbr_dense.bn.bias has no weight decay
stage3.6.rbr_1x1.conv.weight USE weight decay
stage3.6.rbr_whbn.weight has no weight decay
stage3.6.rbr_whbn.bias has no weight decay
stage3.7.rbr_dense.conv.weight USE weight decay
stage3.7.rbr_dense.bn.weight has no weight decay
stage3.7.rbr_dense.bn.bias has no weight decay
stage3.7.rbr_1x1.conv.weight USE weight decay
stage3.7.rbr_whbn.weight has no weight decay
stage3.7.rbr_whbn.bias has no weight decay
stage3.8.rbr_dense.conv.weight USE weight decay
stage3.8.rbr_dense.bn.weight has no weight decay
stage3.8.rbr_dense.bn.bias has no weight decay
stage3.8.rbr_1x1.conv.weight USE weight decay
stage3.8.rbr_whbn.weight has no weight decay
stage3.8.rbr_whbn.bias has no weight decay
stage3.9.rbr_dense.conv.weight USE weight decay
stage3.9.rbr_dense.bn.weight has no weight decay
stage3.9.rbr_dense.bn.bias has no weight decay
stage3.9.rbr_1x1.conv.weight USE weight decay
stage3.9.rbr_whbn.weight has no weight decay
stage3.9.rbr_whbn.bias has no weight decay
stage3.10.rbr_dense.conv.weight USE weight decay
stage3.10.rbr_dense.bn.weight has no weight decay
stage3.10.rbr_dense.bn.bias has no weight decay
stage3.10.rbr_1x1.conv.weight USE weight decay
stage3.10.rbr_whbn.weight has no weight decay
stage3.10.rbr_whbn.bias has no weight decay
stage3.11.rbr_dense.conv.weight USE weight decay
stage3.11.rbr_dense.bn.weight has no weight decay
stage3.11.rbr_dense.bn.bias has no weight decay
stage3.11.rbr_1x1.conv.weight USE weight decay
stage3.11.rbr_whbn.weight has no weight decay
stage3.11.rbr_whbn.bias has no weight decay
stage3.12.rbr_dense.conv.weight USE weight decay
stage3.12.rbr_dense.bn.weight has no weight decay
stage3.12.rbr_dense.bn.bias has no weight decay
stage3.12.rbr_1x1.conv.weight USE weight decay
stage3.12.rbr_whbn.weight has no weight decay
stage3.12.rbr_whbn.bias has no weight decay
stage3.13.rbr_dense.conv.weight USE weight decay
stage3.13.rbr_dense.bn.weight has no weight decay
stage3.13.rbr_dense.bn.bias has no weight decay
stage3.13.rbr_1x1.conv.weight USE weight decay
stage3.13.rbr_whbn.weight has no weight decay
stage3.13.rbr_whbn.bias has no weight decay
stage4.0.rbr_dense.conv.weight USE weight decay
stage4.0.rbr_dense.bn.weight has no weight decay
stage4.0.rbr_dense.bn.bias has no weight decay
stage4.0.rbr_1x1.conv.weight USE weight decay
stage4.0.rbr_whbn.weight has no weight decay
stage4.0.rbr_whbn.bias has no weight decay
linear.weight USE weight decay
linear.bias has no weight decay
================================== SGD nest, momentum = 0.9, wd = 0.0001
[32m[2023-07-06 16:35:31 RepVGG-A0][33m(main.py 89)[39m: INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[32m[2023-07-06 16:35:31 RepVGG-A0][33m(main.py 106)[39m: INFO number of params: 9103304
[32m[2023-07-06 16:35:31 RepVGG-A0][33m(main.py 155)[39m: INFO Start training
/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
[32m[2023-07-06 16:35:36 RepVGG-A0][33m(main.py 282)[39m: INFO Train: [0/300][0/5004]	eta 6:46:32 lr 0.000000	time 4.8747 (4.8747)	loss 6.9118 (6.9118)	grad_norm 3.1617 (3.1617)	mem 1963MB
[32m[2023-07-06 16:35:40 RepVGG-A0][33m(main.py 282)[39m: INFO Train: [0/300][10/5004]	eta 1:08:29 lr 0.000040	time 0.0711 (0.8228)	loss 6.8576 (6.9330)	grad_norm 2.9449 (3.0736)	mem 1963MB
[32m[2023-07-06 16:35:57 RepVGG-A0][33m(main.py 282)[39m: INFO Train: [0/300][20/5004]	eta 1:41:47 lr 0.000080	time 2.4905 (1.2254)	loss 6.9707 (6.9372)	grad_norm 3.0462 (3.0632)	mem 1963MB
[32m[2023-07-06 16:36:02 RepVGG-A0][33m(main.py 282)[39m: INFO Train: [0/300][30/5004]	eta 1:23:15 lr 0.000120	time 0.0751 (1.0044)	loss 6.9336 (6.9399)	grad_norm 2.9811 (3.0750)	mem 1963MB
[32m[2023-07-06 16:36:09 RepVGG-A0][33m(main.py 282)[39m: INFO Train: [0/300][40/5004]	eta 1:17:10 lr 0.000160	time 0.0735 (0.9329)	loss 6.9266 (6.9364)	grad_norm 3.1394 (3.0862)	mem 1963MB
[32m[2023-07-06 16:36:21 RepVGG-A0][33m(main.py 282)[39m: INFO Train: [0/300][50/5004]	eta 1:20:24 lr 0.000200	time 0.0750 (0.9738)	loss 6.8963 (6.9332)	grad_norm 2.9834 (3.0840)	mem 1963MB
