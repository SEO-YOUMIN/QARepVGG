[2023-07-07 06:57:03 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 6
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 06:57:07 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 06:57:07 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 06:57:07 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 06:57:07 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 06:58:00 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 1:08:48 lr 0.000000	time 52.9351 (52.9351)	loss 6.9319 (6.9319)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 06:58:12 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:06:42 lr 0.164103	time 1.3739 (5.9234)	loss 6.8674 (6.9134)	grad_norm 0.3863 (0.4375)	mem 39782MB
[2023-07-07 06:58:25 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:36 lr 0.328205	time 1.1298 (3.7246)	loss 6.8469 (6.8829)	grad_norm 0.6087 (0.4656)	mem 39782MB
[2023-07-07 06:58:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:22 lr 0.492308	time 1.5162 (2.9776)	loss 6.7138 (6.8459)	grad_norm 0.3451 (0.4584)	mem 39782MB
[2023-07-07 06:58:52 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:37 lr 0.656410	time 1.3729 (2.5742)	loss 6.6169 (6.8052)	grad_norm 0.2875 (0.4779)	mem 39782MB
[2023-07-07 06:59:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:05 lr 0.820513	time 1.9146 (2.3568)	loss 6.5649 (6.7585)	grad_norm 0.4756 (0.4584)	mem 39782MB
[2023-07-07 06:59:24 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:40 lr 0.984615	time 2.0010 (2.2515)	loss 6.5136 (6.7204)	grad_norm 0.2836 (0.4587)	mem 39782MB
[2023-07-07 06:59:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:17 lr 1.148718	time 1.3554 (2.1490)	loss 6.4079 (6.6888)	grad_norm 0.2158 (0.4426)	mem 39782MB
[2023-07-07 06:59:50 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:43
[2023-07-07 07:01:01 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 4096
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 4096
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 6
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 12.8
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:01:05 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:01:05 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:01:05 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:01:05 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:09 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 6
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:03:12 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:03:12 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:03:12 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:03:12 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:55 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 0:56:13 lr 0.000000	time 43.2492 (43.2492)	loss 6.9319 (6.9319)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 07:04:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:05:41 lr 0.164103	time 1.1699 (5.0183)	loss 6.8661 (6.9130)	grad_norm 0.3837 (0.4372)	mem 39782MB
[2023-07-07 07:04:20 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:06 lr 0.328205	time 1.1725 (3.2159)	loss 6.8286 (6.8784)	grad_norm 0.6673 (0.4541)	mem 39782MB
[2023-07-07 07:04:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:04 lr 0.492308	time 1.1725 (2.5842)	loss 6.7331 (6.8477)	grad_norm 0.3204 (0.5029)	mem 39782MB
[2023-07-07 07:04:45 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:26 lr 0.656410	time 1.1722 (2.2744)	loss 6.6173 (6.8025)	grad_norm 0.2427 (0.4866)	mem 39782MB
[2023-07-07 07:05:02 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:00 lr 0.820513	time 2.4292 (2.1500)	loss 6.5180 (6.7604)	grad_norm 0.2072 (0.4704)	mem 39782MB
[2023-07-07 07:05:17 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:36 lr 0.984615	time 1.3384 (2.0432)	loss 6.4297 (6.7141)	grad_norm 0.3638 (0.4523)	mem 39782MB
[2023-07-07 07:05:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:15 lr 1.148718	time 1.3001 (1.9739)	loss 6.3334 (6.6714)	grad_norm 0.2930 (0.4425)	mem 39782MB
[2023-07-07 07:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:32
[2023-07-07 07:06:02 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.496 (17.496)	Loss 8.4176 (8.4176)	Acc@1 0.433 (0.433)	Acc@5 1.807 (1.807)	Mem 39782MB
[2023-07-07 07:06:04 RepVGG-A0] (main.py 342): INFO  * Acc@1 0.438 Acc@5 1.750
[2023-07-07 07:06:04 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 0: 0.438%
[2023-07-07 07:06:04 RepVGG-A0] (main.py 172): INFO Max accuracy: 0.44%
[2023-07-07 07:06:25 RepVGG-A0] (main.py 282): INFO Train: [1/300][0/78]	eta 0:27:43 lr 1.280000	time 21.3212 (21.3212)	loss 6.4171 (6.4171)	grad_norm 0.3022 (0.3022)	mem 39782MB
[2023-07-07 07:06:39 RepVGG-A0] (main.py 282): INFO Train: [1/300][10/78]	eta 0:03:36 lr 1.444103	time 1.1722 (3.1862)	loss 6.2793 (6.3397)	grad_norm 0.2858 (0.3078)	mem 39782MB
[2023-07-07 07:06:53 RepVGG-A0] (main.py 282): INFO Train: [1/300][20/78]	eta 0:02:15 lr 1.608205	time 1.1893 (2.3401)	loss 6.2730 (6.3014)	grad_norm 0.3848 (0.3558)	mem 39782MB
[2023-07-07 07:07:09 RepVGG-A0] (main.py 282): INFO Train: [1/300][30/78]	eta 0:01:39 lr 1.772308	time 1.2818 (2.0808)	loss 6.2129 (6.2744)	grad_norm 0.3921 (0.3527)	mem 39782MB
[2023-07-07 07:07:28 RepVGG-A0] (main.py 282): INFO Train: [1/300][40/78]	eta 0:01:17 lr 1.936410	time 4.3360 (2.0521)	loss 6.1631 (6.2427)	grad_norm 0.3742 (0.3538)	mem 39782MB
[2023-07-07 07:07:44 RepVGG-A0] (main.py 282): INFO Train: [1/300][50/78]	eta 0:00:54 lr 2.100513	time 1.1725 (1.9510)	loss 6.2019 (6.2172)	grad_norm 0.5806 (0.3590)	mem 39782MB
[2023-07-07 07:07:59 RepVGG-A0] (main.py 282): INFO Train: [1/300][60/78]	eta 0:00:33 lr 2.264615	time 1.3937 (1.8789)	loss 6.1183 (6.1926)	grad_norm 0.4412 (0.3583)	mem 39782MB
[2023-07-07 07:08:14 RepVGG-A0] (main.py 282): INFO Train: [1/300][70/78]	eta 0:00:14 lr 2.428718	time 1.2508 (1.8331)	loss 6.0065 (6.1635)	grad_norm 0.4348 (0.3595)	mem 39782MB
[2023-07-07 07:08:25 RepVGG-A0] (main.py 291): INFO EPOCH 1 training takes 0:02:21
[2023-07-07 07:08:47 RepVGG-A0] (main.py 282): INFO Train: [2/300][0/78]	eta 0:28:08 lr 2.560000	time 21.6508 (21.6508)	loss 5.8402 (5.8402)	grad_norm 0.3089 (0.3089)	mem 39782MB
[2023-07-07 07:09:01 RepVGG-A0] (main.py 282): INFO Train: [2/300][10/78]	eta 0:03:39 lr 2.724103	time 1.1883 (3.2344)	loss 5.8429 (5.8720)	grad_norm 0.3208 (0.3754)	mem 39782MB
[2023-07-07 07:09:16 RepVGG-A0] (main.py 282): INFO Train: [2/300][20/78]	eta 0:02:19 lr 2.888205	time 1.1732 (2.4025)	loss 5.8871 (5.8501)	grad_norm 0.5859 (0.3874)	mem 39782MB
[2023-07-07 07:09:31 RepVGG-A0] (main.py 282): INFO Train: [2/300][30/78]	eta 0:01:41 lr 3.052308	time 1.2479 (2.1174)	loss 5.8228 (5.8660)	grad_norm 0.3534 (0.3930)	mem 39782MB
[2023-07-07 07:09:49 RepVGG-A0] (main.py 282): INFO Train: [2/300][40/78]	eta 0:01:17 lr 3.216410	time 3.6721 (2.0291)	loss 5.7313 (5.8501)	grad_norm 0.2448 (0.3795)	mem 39782MB
[2023-07-07 07:10:04 RepVGG-A0] (main.py 282): INFO Train: [2/300][50/78]	eta 0:00:54 lr 3.380513	time 1.3521 (1.9319)	loss 5.6256 (5.8169)	grad_norm 0.2856 (0.3737)	mem 39782MB
[2023-07-07 07:10:20 RepVGG-A0] (main.py 282): INFO Train: [2/300][60/78]	eta 0:00:33 lr 3.544615	time 1.3076 (1.8759)	loss 5.5623 (5.7834)	grad_norm 0.3870 (0.3667)	mem 39782MB
[2023-07-07 07:10:35 RepVGG-A0] (main.py 282): INFO Train: [2/300][70/78]	eta 0:00:14 lr 3.708718	time 1.1691 (1.8220)	loss 5.4961 (5.7555)	grad_norm 0.2952 (0.3666)	mem 39782MB
[2023-07-07 07:10:47 RepVGG-A0] (main.py 291): INFO EPOCH 2 training takes 0:02:21
[2023-07-07 07:11:07 RepVGG-A0] (main.py 282): INFO Train: [3/300][0/78]	eta 0:26:31 lr 3.840000	time 20.4014 (20.4014)	loss 5.4643 (5.4643)	grad_norm 0.4211 (0.4211)	mem 39782MB
[2023-07-07 07:11:22 RepVGG-A0] (main.py 282): INFO Train: [3/300][10/78]	eta 0:03:35 lr 4.004103	time 1.1895 (3.1731)	loss 5.6176 (5.7004)	grad_norm 0.3348 (0.4536)	mem 39782MB
[2023-07-07 07:11:37 RepVGG-A0] (main.py 282): INFO Train: [3/300][20/78]	eta 0:02:18 lr 4.168205	time 1.1725 (2.3822)	loss 5.4590 (5.6369)	grad_norm 0.2892 (0.3932)	mem 39782MB
[2023-07-07 07:11:52 RepVGG-A0] (main.py 282): INFO Train: [3/300][30/78]	eta 0:01:40 lr 4.332308	time 1.5027 (2.1022)	loss 5.5318 (5.5690)	grad_norm 0.4183 (0.3690)	mem 39782MB
[2023-07-07 07:12:09 RepVGG-A0] (main.py 282): INFO Train: [3/300][40/78]	eta 0:01:16 lr 4.496410	time 3.7341 (2.0088)	loss 5.4083 (5.5168)	grad_norm 0.4425 (0.3594)	mem 39782MB
[2023-07-07 07:12:24 RepVGG-A0] (main.py 282): INFO Train: [3/300][50/78]	eta 0:00:53 lr 4.660513	time 1.1747 (1.8987)	loss 5.3685 (5.5094)	grad_norm 0.3540 (0.3620)	mem 39782MB
[2023-07-07 07:12:39 RepVGG-A0] (main.py 282): INFO Train: [3/300][60/78]	eta 0:00:33 lr 4.824615	time 1.3979 (1.8407)	loss 5.2440 (5.4721)	grad_norm 0.3398 (0.3547)	mem 39782MB
[2023-07-07 07:12:53 RepVGG-A0] (main.py 282): INFO Train: [3/300][70/78]	eta 0:00:14 lr 4.988718	time 1.4365 (1.7836)	loss 5.2082 (5.4357)	grad_norm 0.3245 (0.3490)	mem 39782MB
[2023-07-07 07:13:05 RepVGG-A0] (main.py 291): INFO EPOCH 3 training takes 0:02:18
[2023-07-07 07:13:26 RepVGG-A0] (main.py 282): INFO Train: [4/300][0/78]	eta 0:27:04 lr 5.120000	time 20.8316 (20.8316)	loss 5.0540 (5.0540)	grad_norm 0.3194 (0.3194)	mem 39782MB
[2023-07-07 07:13:40 RepVGG-A0] (main.py 282): INFO Train: [4/300][10/78]	eta 0:03:38 lr 5.284103	time 1.1932 (3.2121)	loss 5.2359 (5.2283)	grad_norm 0.3480 (0.3871)	mem 39782MB
[2023-07-07 07:13:55 RepVGG-A0] (main.py 282): INFO Train: [4/300][20/78]	eta 0:02:18 lr 5.448205	time 1.3843 (2.3847)	loss 5.0584 (5.1943)	grad_norm 0.3079 (0.3590)	mem 39782MB
[2023-07-07 07:14:10 RepVGG-A0] (main.py 282): INFO Train: [4/300][30/78]	eta 0:01:40 lr 5.612308	time 1.2885 (2.0912)	loss 5.1009 (5.1592)	grad_norm 0.4055 (0.3539)	mem 39782MB
[2023-07-07 07:14:28 RepVGG-A0] (main.py 282): INFO Train: [4/300][40/78]	eta 0:01:16 lr 5.776410	time 4.9600 (2.0260)	loss 5.1501 (5.1902)	grad_norm 0.2796 (0.3646)	mem 39782MB
[2023-07-07 07:14:44 RepVGG-A0] (main.py 282): INFO Train: [4/300][50/78]	eta 0:00:54 lr 5.940513	time 1.1379 (1.9299)	loss 5.0473 (5.1915)	grad_norm 0.2789 (0.3640)	mem 39782MB
[2023-07-07 07:14:59 RepVGG-A0] (main.py 282): INFO Train: [4/300][60/78]	eta 0:00:33 lr 6.104615	time 1.4721 (1.8638)	loss 5.1168 (5.1604)	grad_norm 0.4101 (0.3544)	mem 39782MB
[2023-07-07 07:15:14 RepVGG-A0] (main.py 282): INFO Train: [4/300][70/78]	eta 0:00:14 lr 6.268718	time 1.3739 (1.8150)	loss 4.9005 (5.1345)	grad_norm 0.3424 (0.3485)	mem 39782MB
[2023-07-07 07:15:26 RepVGG-A0] (main.py 291): INFO EPOCH 4 training takes 0:02:20
[2023-07-07 07:15:47 RepVGG-A0] (main.py 282): INFO Train: [5/300][0/78]	eta 0:27:53 lr 6.395615	time 21.4490 (21.4490)	loss 5.0127 (5.0127)	grad_norm 0.3501 (0.3501)	mem 39782MB
[2023-07-07 07:16:03 RepVGG-A0] (main.py 282): INFO Train: [5/300][10/78]	eta 0:03:48 lr 6.395387	time 1.1699 (3.3650)	loss 4.8596 (4.8985)	grad_norm 0.3121 (0.3207)	mem 39782MB
[2023-07-07 07:16:17 RepVGG-A0] (main.py 282): INFO Train: [5/300][20/78]	eta 0:02:20 lr 6.395153	time 1.2878 (2.4298)	loss 4.7617 (4.8586)	grad_norm 0.3066 (0.3194)	mem 39782MB
[2023-07-07 07:16:33 RepVGG-A0] (main.py 282): INFO Train: [5/300][30/78]	eta 0:01:43 lr 6.394914	time 1.2220 (2.1622)	loss 4.7632 (4.8390)	grad_norm 0.3153 (0.3274)	mem 39782MB
[2023-07-07 07:16:50 RepVGG-A0] (main.py 282): INFO Train: [5/300][40/78]	eta 0:01:18 lr 6.394669	time 3.6033 (2.0574)	loss 4.8511 (4.8255)	grad_norm 0.4065 (0.3341)	mem 39782MB
[2023-07-07 07:17:05 RepVGG-A0] (main.py 282): INFO Train: [5/300][50/78]	eta 0:00:54 lr 6.394418	time 1.1709 (1.9405)	loss 4.7300 (4.8227)	grad_norm 0.3186 (0.3363)	mem 39782MB
[2023-07-07 07:17:20 RepVGG-A0] (main.py 282): INFO Train: [5/300][60/78]	eta 0:00:33 lr 6.394162	time 1.3333 (1.8667)	loss 4.6417 (4.8052)	grad_norm 0.2947 (0.3370)	mem 39782MB
[2023-07-07 07:17:35 RepVGG-A0] (main.py 282): INFO Train: [5/300][70/78]	eta 0:00:14 lr 6.393899	time 1.3457 (1.8192)	loss 4.8043 (4.7874)	grad_norm 0.3928 (0.3394)	mem 39782MB
[2023-07-07 07:17:47 RepVGG-A0] (main.py 291): INFO EPOCH 5 training takes 0:02:21
[2023-07-07 07:18:09 RepVGG-A0] (main.py 282): INFO Train: [6/300][0/78]	eta 0:28:30 lr 6.393686	time 21.9348 (21.9348)	loss 4.5838 (4.5838)	grad_norm 0.3199 (0.3199)	mem 39782MB
[2023-07-07 07:18:24 RepVGG-A0] (main.py 282): INFO Train: [6/300][10/78]	eta 0:03:47 lr 6.393413	time 1.1722 (3.3488)	loss 4.5930 (4.5802)	grad_norm 0.3654 (0.3503)	mem 39782MB
[2023-07-07 07:18:38 RepVGG-A0] (main.py 282): INFO Train: [6/300][20/78]	eta 0:02:21 lr 6.393134	time 1.1969 (2.4443)	loss 4.6704 (4.5566)	grad_norm 0.4356 (0.3452)	mem 39782MB
[2023-07-07 07:18:53 RepVGG-A0] (main.py 282): INFO Train: [6/300][30/78]	eta 0:01:41 lr 6.392850	time 1.3745 (2.1221)	loss 4.7739 (4.6775)	grad_norm 0.3324 (0.3829)	mem 39782MB
[2023-07-07 07:19:11 RepVGG-A0] (main.py 282): INFO Train: [6/300][40/78]	eta 0:01:17 lr 6.392560	time 3.2688 (2.0424)	loss 4.5441 (4.6669)	grad_norm 0.3424 (0.3618)	mem 39782MB
[2023-07-07 07:19:27 RepVGG-A0] (main.py 282): INFO Train: [6/300][50/78]	eta 0:00:54 lr 6.392265	time 1.1718 (1.9526)	loss 4.4348 (4.6387)	grad_norm 0.2716 (0.3537)	mem 39782MB
[2023-07-07 07:19:42 RepVGG-A0] (main.py 282): INFO Train: [6/300][60/78]	eta 0:00:33 lr 6.391963	time 1.1936 (1.8820)	loss 4.6081 (4.6093)	grad_norm 0.4000 (0.3523)	mem 39782MB
[2023-07-07 07:19:57 RepVGG-A0] (main.py 282): INFO Train: [6/300][70/78]	eta 0:00:14 lr 6.391656	time 1.2021 (1.8299)	loss 4.3898 (4.5888)	grad_norm 0.3288 (0.3490)	mem 39782MB
[2023-07-07 07:20:09 RepVGG-A0] (main.py 291): INFO EPOCH 6 training takes 0:02:22
[2023-07-07 07:20:31 RepVGG-A0] (main.py 282): INFO Train: [7/300][0/78]	eta 0:27:47 lr 6.391406	time 21.3795 (21.3795)	loss 4.8383 (4.8383)	grad_norm 0.6078 (0.6078)	mem 39782MB
[2023-07-07 07:20:45 RepVGG-A0] (main.py 282): INFO Train: [7/300][10/78]	eta 0:03:39 lr 6.391089	time 1.1716 (3.2210)	loss 5.0683 (5.2139)	grad_norm 0.3224 (0.5314)	mem 39782MB
[2023-07-07 07:20:59 RepVGG-A0] (main.py 282): INFO Train: [7/300][20/78]	eta 0:02:17 lr 6.390766	time 1.1726 (2.3785)	loss 4.4714 (4.9977)	grad_norm 0.2351 (0.4205)	mem 39782MB
[2023-07-07 07:21:15 RepVGG-A0] (main.py 282): INFO Train: [7/300][30/78]	eta 0:01:41 lr 6.390437	time 1.4267 (2.1119)	loss 4.4180 (4.8610)	grad_norm 0.2142 (0.3827)	mem 39782MB
[2023-07-07 07:21:34 RepVGG-A0] (main.py 282): INFO Train: [7/300][40/78]	eta 0:01:18 lr 6.390102	time 3.9622 (2.0562)	loss 4.3661 (4.7436)	grad_norm 0.3031 (0.3593)	mem 39782MB
[2023-07-07 07:21:50 RepVGG-A0] (main.py 282): INFO Train: [7/300][50/78]	eta 0:00:55 lr 6.389761	time 1.2674 (1.9697)	loss 4.4291 (4.6655)	grad_norm 0.3885 (0.3520)	mem 39782MB
[2023-07-07 07:22:05 RepVGG-A0] (main.py 282): INFO Train: [7/300][60/78]	eta 0:00:34 lr 6.389415	time 1.1444 (1.8960)	loss 4.1523 (4.6125)	grad_norm 0.2802 (0.3473)	mem 39782MB
[2023-07-07 07:22:20 RepVGG-A0] (main.py 282): INFO Train: [7/300][70/78]	eta 0:00:14 lr 6.389063	time 1.1760 (1.8375)	loss 4.3985 (4.5787)	grad_norm 0.3772 (0.3502)	mem 39782MB
[2023-07-07 07:22:31 RepVGG-A0] (main.py 291): INFO EPOCH 7 training takes 0:02:21
[2023-07-07 07:22:53 RepVGG-A0] (main.py 282): INFO Train: [8/300][0/78]	eta 0:28:11 lr 6.388777	time 21.6873 (21.6873)	loss 4.2752 (4.2752)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 07:23:06 RepVGG-A0] (main.py 282): INFO Train: [8/300][10/78]	eta 0:03:36 lr 6.388415	time 1.1709 (3.1845)	loss 4.1689 (4.2257)	grad_norm 0.3247 (0.3365)	mem 39782MB
[2023-07-07 07:23:20 RepVGG-A0] (main.py 282): INFO Train: [8/300][20/78]	eta 0:02:15 lr 6.388047	time 1.1897 (2.3444)	loss 4.3289 (4.2575)	grad_norm 0.3676 (0.3602)	mem 39782MB
[2023-07-07 07:23:36 RepVGG-A0] (main.py 282): INFO Train: [8/300][30/78]	eta 0:01:40 lr 6.387673	time 1.4105 (2.0845)	loss 4.2246 (4.2619)	grad_norm 0.3572 (0.3583)	mem 39782MB
[2023-07-07 07:23:54 RepVGG-A0] (main.py 282): INFO Train: [8/300][40/78]	eta 0:01:16 lr 6.387293	time 4.2645 (2.0158)	loss 4.1100 (4.2392)	grad_norm 0.3285 (0.3522)	mem 39782MB
[2023-07-07 07:24:09 RepVGG-A0] (main.py 282): INFO Train: [8/300][50/78]	eta 0:00:53 lr 6.386908	time 1.1721 (1.9169)	loss 4.1337 (4.2384)	grad_norm 0.3480 (0.3560)	mem 39782MB
[2023-07-07 07:24:23 RepVGG-A0] (main.py 282): INFO Train: [8/300][60/78]	eta 0:00:33 lr 6.386517	time 1.2021 (1.8413)	loss 4.1121 (4.2252)	grad_norm 0.3056 (0.3526)	mem 39782MB
[2023-07-07 07:24:39 RepVGG-A0] (main.py 282): INFO Train: [8/300][70/78]	eta 0:00:14 lr 6.386120	time 1.4132 (1.8041)	loss 4.6708 (4.2481)	grad_norm 0.5369 (0.3675)	mem 39782MB
[2023-07-07 07:24:51 RepVGG-A0] (main.py 291): INFO EPOCH 8 training takes 0:02:20
[2023-07-07 07:25:13 RepVGG-A0] (main.py 282): INFO Train: [9/300][0/78]	eta 0:28:45 lr 6.385798	time 22.1215 (22.1215)	loss 4.5768 (4.5768)	grad_norm 0.3629 (0.3629)	mem 39782MB
[2023-07-07 07:25:27 RepVGG-A0] (main.py 282): INFO Train: [9/300][10/78]	eta 0:03:41 lr 6.385391	time 1.1727 (3.2537)	loss 4.1079 (4.2928)	grad_norm 0.2382 (0.2936)	mem 39782MB
[2023-07-07 07:25:43 RepVGG-A0] (main.py 282): INFO Train: [9/300][20/78]	eta 0:02:22 lr 6.384978	time 1.1818 (2.4502)	loss 4.0844 (4.2219)	grad_norm 0.3011 (0.2995)	mem 39782MB
[2023-07-07 07:25:57 RepVGG-A0] (main.py 282): INFO Train: [9/300][30/78]	eta 0:01:42 lr 6.384560	time 1.4518 (2.1295)	loss 4.0003 (4.1813)	grad_norm 0.2605 (0.3031)	mem 39782MB
[2023-07-07 07:26:14 RepVGG-A0] (main.py 282): INFO Train: [9/300][40/78]	eta 0:01:16 lr 6.384135	time 2.4380 (2.0194)	loss 4.0475 (4.1571)	grad_norm 0.3226 (0.3117)	mem 39782MB
[2023-07-07 07:26:30 RepVGG-A0] (main.py 282): INFO Train: [9/300][50/78]	eta 0:00:54 lr 6.383705	time 1.1748 (1.9376)	loss 4.3207 (4.1698)	grad_norm 0.4367 (0.3327)	mem 39782MB
[2023-07-07 07:26:45 RepVGG-A0] (main.py 282): INFO Train: [9/300][60/78]	eta 0:00:33 lr 6.383269	time 1.1767 (1.8668)	loss 4.0319 (4.1530)	grad_norm 0.3265 (0.3286)	mem 39782MB
[2023-07-07 07:27:00 RepVGG-A0] (main.py 282): INFO Train: [9/300][70/78]	eta 0:00:14 lr 6.382827	time 1.3989 (1.8127)	loss 3.9881 (4.1310)	grad_norm 0.3517 (0.3280)	mem 39782MB
[2023-07-07 07:27:11 RepVGG-A0] (main.py 291): INFO EPOCH 9 training takes 0:02:19
[2023-07-07 07:27:32 RepVGG-A0] (main.py 282): INFO Train: [10/300][0/78]	eta 0:27:08 lr 6.382470	time 20.8815 (20.8815)	loss 4.2499 (4.2499)	grad_norm 0.4651 (0.4651)	mem 39782MB
[2023-07-07 07:27:47 RepVGG-A0] (main.py 282): INFO Train: [10/300][10/78]	eta 0:03:40 lr 6.382018	time 1.1715 (3.2419)	loss 4.0190 (4.1129)	grad_norm 0.3140 (0.3522)	mem 39782MB
[2023-07-07 07:28:02 RepVGG-A0] (main.py 282): INFO Train: [10/300][20/78]	eta 0:02:20 lr 6.381560	time 1.2101 (2.4139)	loss 4.0860 (4.0637)	grad_norm 0.3932 (0.3513)	mem 39782MB
[2023-07-07 07:28:17 RepVGG-A0] (main.py 282): INFO Train: [10/300][30/78]	eta 0:01:41 lr 6.381097	time 1.5228 (2.1131)	loss 4.1136 (4.0340)	grad_norm 0.4598 (0.3468)	mem 39782MB
[2023-07-07 07:28:34 RepVGG-A0] (main.py 282): INFO Train: [10/300][40/78]	eta 0:01:17 lr 6.380628	time 3.8503 (2.0348)	loss 4.0805 (4.0494)	grad_norm 0.3532 (0.3555)	mem 39782MB
[2023-07-07 07:28:50 RepVGG-A0] (main.py 282): INFO Train: [10/300][50/78]	eta 0:00:54 lr 6.380153	time 1.1742 (1.9410)	loss 3.9777 (4.0405)	grad_norm 0.3167 (0.3534)	mem 39782MB
[2023-07-07 07:29:06 RepVGG-A0] (main.py 282): INFO Train: [10/300][60/78]	eta 0:00:33 lr 6.379672	time 1.2778 (1.8771)	loss 3.9517 (4.0307)	grad_norm 0.3627 (0.3533)	mem 39782MB
[2023-07-07 07:29:21 RepVGG-A0] (main.py 282): INFO Train: [10/300][70/78]	eta 0:00:14 lr 6.379186	time 1.1369 (1.8344)	loss 3.8864 (4.0177)	grad_norm 0.3247 (0.3522)	mem 39782MB
[2023-07-07 07:29:33 RepVGG-A0] (main.py 291): INFO EPOCH 10 training takes 0:02:21
[2023-07-07 07:29:55 RepVGG-A0] (main.py 282): INFO Train: [11/300][0/78]	eta 0:28:46 lr 6.378793	time 22.1305 (22.1305)	loss 4.2731 (4.2731)	grad_norm 0.4965 (0.4965)	mem 39782MB
[2023-07-07 07:30:09 RepVGG-A0] (main.py 282): INFO Train: [11/300][10/78]	eta 0:03:45 lr 6.378296	time 1.1899 (3.3206)	loss 4.5242 (4.6069)	grad_norm 0.4137 (0.5417)	mem 39782MB
[2023-07-07 07:30:23 RepVGG-A0] (main.py 282): INFO Train: [11/300][20/78]	eta 0:02:19 lr 6.377794	time 1.1761 (2.4118)	loss 4.0280 (4.4206)	grad_norm 0.2363 (0.4263)	mem 39782MB
[2023-07-07 07:30:40 RepVGG-A0] (main.py 282): INFO Train: [11/300][30/78]	eta 0:01:43 lr 6.377286	time 1.6334 (2.1545)	loss 3.9023 (4.2781)	grad_norm 0.2683 (0.3847)	mem 39782MB
[2023-07-07 07:30:57 RepVGG-A0] (main.py 282): INFO Train: [11/300][40/78]	eta 0:01:18 lr 6.376772	time 3.3286 (2.0603)	loss 3.9098 (4.1833)	grad_norm 0.3163 (0.3636)	mem 39782MB
[2023-07-07 07:31:12 RepVGG-A0] (main.py 282): INFO Train: [11/300][50/78]	eta 0:00:54 lr 6.376252	time 1.1706 (1.9446)	loss 3.9397 (4.1186)	grad_norm 0.3426 (0.3517)	mem 39782MB
[2023-07-07 07:31:28 RepVGG-A0] (main.py 282): INFO Train: [11/300][60/78]	eta 0:00:33 lr 6.375727	time 1.1375 (1.8831)	loss 3.8504 (4.0987)	grad_norm 0.3005 (0.3552)	mem 39782MB
[2023-07-07 07:31:43 RepVGG-A0] (main.py 282): INFO Train: [11/300][70/78]	eta 0:00:14 lr 6.375196	time 1.3458 (1.8277)	loss 4.3119 (4.0852)	grad_norm 0.5178 (0.3610)	mem 39782MB
[2023-07-07 07:31:54 RepVGG-A0] (main.py 291): INFO EPOCH 11 training takes 0:02:21
[2023-07-07 07:32:16 RepVGG-A0] (main.py 282): INFO Train: [12/300][0/78]	eta 0:28:06 lr 6.374767	time 21.6161 (21.6161)	loss 3.9905 (3.9905)	grad_norm 0.3421 (0.3421)	mem 39782MB
[2023-07-07 07:32:30 RepVGG-A0] (main.py 282): INFO Train: [12/300][10/78]	eta 0:03:42 lr 6.374226	time 1.1717 (3.2782)	loss 3.8322 (3.8660)	grad_norm 0.3571 (0.3158)	mem 39782MB
[2023-07-07 07:32:45 RepVGG-A0] (main.py 282): INFO Train: [12/300][20/78]	eta 0:02:20 lr 6.373679	time 1.2077 (2.4238)	loss 3.8416 (3.8610)	grad_norm 0.3231 (0.3243)	mem 39782MB
[2023-07-07 07:33:00 RepVGG-A0] (main.py 282): INFO Train: [12/300][30/78]	eta 0:01:42 lr 6.373126	time 1.1280 (2.1401)	loss 4.0679 (3.8681)	grad_norm 0.4718 (0.3424)	mem 39782MB
[2023-07-07 07:33:18 RepVGG-A0] (main.py 282): INFO Train: [12/300][40/78]	eta 0:01:17 lr 6.372567	time 2.8233 (2.0356)	loss 3.7682 (3.8807)	grad_norm 0.2953 (0.3434)	mem 39782MB
[2023-07-07 07:33:33 RepVGG-A0] (main.py 282): INFO Train: [12/300][50/78]	eta 0:00:54 lr 6.372003	time 1.1738 (1.9359)	loss 3.9113 (3.8721)	grad_norm 0.3674 (0.3439)	mem 39782MB
[2023-07-07 07:33:49 RepVGG-A0] (main.py 282): INFO Train: [12/300][60/78]	eta 0:00:33 lr 6.371433	time 1.4130 (1.8819)	loss 3.9304 (3.8656)	grad_norm 0.3711 (0.3458)	mem 39782MB
[2023-07-07 07:34:03 RepVGG-A0] (main.py 282): INFO Train: [12/300][70/78]	eta 0:00:14 lr 6.370858	time 1.4769 (1.8182)	loss 4.1891 (3.8749)	grad_norm 0.5503 (0.3526)	mem 39782MB
[2023-07-07 07:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 12 training takes 0:02:20
[2023-07-07 07:34:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][0/78]	eta 0:28:30 lr 6.370393	time 21.9326 (21.9326)	loss 4.5525 (4.5525)	grad_norm 0.5121 (0.5121)	mem 39782MB
[2023-07-07 07:34:50 RepVGG-A0] (main.py 282): INFO Train: [13/300][10/78]	eta 0:03:42 lr 6.369807	time 1.1706 (3.2757)	loss 3.9799 (4.2362)	grad_norm 0.3029 (0.3710)	mem 39782MB
[2023-07-07 07:35:05 RepVGG-A0] (main.py 282): INFO Train: [13/300][20/78]	eta 0:02:19 lr 6.369216	time 1.1741 (2.3983)	loss 3.8167 (4.0644)	grad_norm 0.2852 (0.3273)	mem 39782MB
[2023-07-07 07:35:19 RepVGG-A0] (main.py 282): INFO Train: [13/300][30/78]	eta 0:01:40 lr 6.368618	time 1.3556 (2.0980)	loss 3.9757 (3.9926)	grad_norm 0.3547 (0.3255)	mem 39782MB
[2023-07-07 07:35:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][40/78]	eta 0:01:16 lr 6.368015	time 3.2998 (2.0014)	loss 3.7818 (3.9516)	grad_norm 0.3138 (0.3253)	mem 39782MB
[2023-07-07 07:35:52 RepVGG-A0] (main.py 282): INFO Train: [13/300][50/78]	eta 0:00:53 lr 6.367406	time 1.3420 (1.9146)	loss 4.1567 (3.9367)	grad_norm 0.4586 (0.3365)	mem 39782MB
[2023-07-07 07:36:07 RepVGG-A0] (main.py 282): INFO Train: [13/300][60/78]	eta 0:00:33 lr 6.366792	time 1.1724 (1.8435)	loss 3.7604 (3.9261)	grad_norm 0.3021 (0.3360)	mem 39782MB
[2023-07-07 07:36:22 RepVGG-A0] (main.py 282): INFO Train: [13/300][70/78]	eta 0:00:14 lr 6.366172	time 1.2009 (1.8013)	loss 3.8562 (3.9045)	grad_norm 0.3652 (0.3343)	mem 39782MB
[2023-07-07 07:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 13 training takes 0:02:19
[2023-07-07 07:36:55 RepVGG-A0] (main.py 282): INFO Train: [14/300][0/78]	eta 0:27:01 lr 6.365671	time 20.7910 (20.7910)	loss 3.8514 (3.8514)	grad_norm 0.3951 (0.3951)	mem 39782MB
[2023-07-07 07:37:10 RepVGG-A0] (main.py 282): INFO Train: [14/300][10/78]	eta 0:03:42 lr 6.365041	time 1.1731 (3.2742)	loss 3.6836 (3.7745)	grad_norm 0.3136 (0.3536)	mem 39782MB
[2023-07-07 07:37:25 RepVGG-A0] (main.py 282): INFO Train: [14/300][20/78]	eta 0:02:20 lr 6.364405	time 1.1727 (2.4230)	loss 3.7221 (3.7563)	grad_norm 0.3702 (0.3490)	mem 39782MB
[2023-07-07 07:37:40 RepVGG-A0] (main.py 282): INFO Train: [14/300][30/78]	eta 0:01:42 lr 6.363763	time 1.5144 (2.1360)	loss 3.9033 (3.7794)	grad_norm 0.3959 (0.3608)	mem 39782MB
[2023-07-07 07:37:59 RepVGG-A0] (main.py 282): INFO Train: [14/300][40/78]	eta 0:01:18 lr 6.363115	time 4.3125 (2.0609)	loss 3.7423 (3.7829)	grad_norm 0.3423 (0.3600)	mem 39782MB
[2023-07-07 07:38:14 RepVGG-A0] (main.py 282): INFO Train: [14/300][50/78]	eta 0:00:54 lr 6.362462	time 1.2455 (1.9518)	loss 3.7586 (3.7764)	grad_norm 0.3715 (0.3569)	mem 39782MB
[2023-07-07 07:38:29 RepVGG-A0] (main.py 282): INFO Train: [14/300][60/78]	eta 0:00:33 lr 6.361803	time 1.1827 (1.8778)	loss 4.3927 (3.8404)	grad_norm 0.5011 (0.3816)	mem 39782MB
[2023-07-07 07:38:44 RepVGG-A0] (main.py 282): INFO Train: [14/300][70/78]	eta 0:00:14 lr 6.361139	time 1.3887 (1.8296)	loss 3.7813 (3.8726)	grad_norm 0.2397 (0.3792)	mem 39782MB
[2023-07-07 07:38:56 RepVGG-A0] (main.py 291): INFO EPOCH 14 training takes 0:02:21
[2023-07-07 07:39:16 RepVGG-A0] (main.py 282): INFO Train: [15/300][0/78]	eta 0:25:54 lr 6.360603	time 19.9291 (19.9291)	loss 3.6737 (3.6737)	grad_norm 0.2818 (0.2818)	mem 39782MB
[2023-07-07 07:39:32 RepVGG-A0] (main.py 282): INFO Train: [15/300][10/78]	eta 0:03:45 lr 6.359928	time 1.1744 (3.3181)	loss 3.6066 (3.7167)	grad_norm 0.2760 (0.3218)	mem 39782MB
[2023-07-07 07:39:46 RepVGG-A0] (main.py 282): INFO Train: [15/300][20/78]	eta 0:02:20 lr 6.359247	time 1.1897 (2.4175)	loss 3.6992 (3.7105)	grad_norm 0.3307 (0.3248)	mem 39782MB
[2023-07-07 07:40:02 RepVGG-A0] (main.py 282): INFO Train: [15/300][30/78]	eta 0:01:42 lr 6.358561	time 1.7148 (2.1397)	loss 3.6636 (3.6976)	grad_norm 0.3374 (0.3216)	mem 39782MB
[2023-07-07 07:40:20 RepVGG-A0] (main.py 282): INFO Train: [15/300][40/78]	eta 0:01:17 lr 6.357869	time 3.6498 (2.0486)	loss 3.7281 (3.7039)	grad_norm 0.3651 (0.3323)	mem 39782MB
[2023-07-07 07:40:35 RepVGG-A0] (main.py 282): INFO Train: [15/300][50/78]	eta 0:00:54 lr 6.357171	time 1.1721 (1.9405)	loss 4.3653 (3.7474)	grad_norm 0.6949 (0.3576)	mem 39782MB
[2023-07-07 07:40:50 RepVGG-A0] (main.py 282): INFO Train: [15/300][60/78]	eta 0:00:33 lr 6.356468	time 1.3150 (1.8702)	loss 5.2202 (4.0205)	grad_norm 0.4850 (0.4067)	mem 39782MB
[2023-07-07 07:41:05 RepVGG-A0] (main.py 282): INFO Train: [15/300][70/78]	eta 0:00:14 lr 6.355759	time 1.2061 (1.8170)	loss 4.3900 (4.1217)	grad_norm 0.2292 (0.3932)	mem 39782MB
[2023-07-07 07:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 15 training takes 0:02:21
[2023-07-07 07:41:37 RepVGG-A0] (main.py 282): INFO Train: [16/300][0/78]	eta 0:26:22 lr 6.355187	time 20.2908 (20.2908)	loss 4.2013 (4.2013)	grad_norm 0.2985 (0.2985)	mem 39782MB
[2023-07-07 07:41:53 RepVGG-A0] (main.py 282): INFO Train: [16/300][10/78]	eta 0:03:43 lr 6.354468	time 1.1707 (3.2861)	loss 3.9776 (4.0538)	grad_norm 0.2392 (0.2544)	mem 39782MB
[2023-07-07 07:42:07 RepVGG-A0] (main.py 282): INFO Train: [16/300][20/78]	eta 0:02:19 lr 6.353743	time 1.1716 (2.4028)	loss 3.9783 (3.9927)	grad_norm 0.3623 (0.2789)	mem 39782MB
[2023-07-07 07:42:23 RepVGG-A0] (main.py 282): INFO Train: [16/300][30/78]	eta 0:01:42 lr 6.353012	time 1.5008 (2.1264)	loss 3.7461 (3.9661)	grad_norm 0.2343 (0.2871)	mem 39782MB
[2023-07-07 07:42:40 RepVGG-A0] (main.py 282): INFO Train: [16/300][40/78]	eta 0:01:17 lr 6.352276	time 3.6246 (2.0381)	loss 3.9957 (3.9444)	grad_norm 0.4042 (0.2984)	mem 39782MB
[2023-07-07 07:42:55 RepVGG-A0] (main.py 282): INFO Train: [16/300][50/78]	eta 0:00:54 lr 6.351534	time 1.1723 (1.9326)	loss 3.8061 (3.9200)	grad_norm 0.3138 (0.2998)	mem 39782MB
[2023-07-07 07:43:12 RepVGG-A0] (main.py 282): INFO Train: [16/300][60/78]	eta 0:00:33 lr 6.350786	time 1.4930 (1.8793)	loss 3.9759 (3.9086)	grad_norm 0.4180 (0.3114)	mem 39782MB
[2023-07-07 07:43:26 RepVGG-A0] (main.py 282): INFO Train: [16/300][70/78]	eta 0:00:14 lr 6.350033	time 1.1766 (1.8213)	loss 3.8010 (3.8961)	grad_norm 0.3425 (0.3142)	mem 39782MB
[2023-07-07 07:43:38 RepVGG-A0] (main.py 291): INFO EPOCH 16 training takes 0:02:20
[2023-07-07 07:43:58 RepVGG-A0] (main.py 282): INFO Train: [17/300][0/78]	eta 0:26:51 lr 6.349426	time 20.6631 (20.6631)	loss 3.6666 (3.6666)	grad_norm 0.3172 (0.3172)	mem 39782MB
[2023-07-07 07:44:14 RepVGG-A0] (main.py 282): INFO Train: [17/300][10/78]	eta 0:03:43 lr 6.348662	time 1.1705 (3.2862)	loss 3.8118 (3.7638)	grad_norm 0.3768 (0.3612)	mem 39782MB
[2023-07-07 07:44:29 RepVGG-A0] (main.py 282): INFO Train: [17/300][20/78]	eta 0:02:21 lr 6.347893	time 1.1776 (2.4363)	loss 3.7377 (3.7435)	grad_norm 0.3442 (0.3521)	mem 39782MB
[2023-07-07 07:44:44 RepVGG-A0] (main.py 282): INFO Train: [17/300][30/78]	eta 0:01:43 lr 6.347118	time 1.7029 (2.1536)	loss 3.7709 (3.7507)	grad_norm 0.3819 (0.3557)	mem 39782MB
[2023-07-07 07:45:02 RepVGG-A0] (main.py 282): INFO Train: [17/300][40/78]	eta 0:01:18 lr 6.346337	time 3.9556 (2.0577)	loss 3.6703 (3.7438)	grad_norm 0.3219 (0.3521)	mem 39782MB
[2023-07-07 07:45:18 RepVGG-A0] (main.py 282): INFO Train: [17/300][50/78]	eta 0:00:55 lr 6.345551	time 1.4472 (1.9663)	loss 3.9042 (3.7530)	grad_norm 0.4348 (0.3601)	mem 39782MB
[2023-07-07 07:45:32 RepVGG-A0] (main.py 282): INFO Train: [17/300][60/78]	eta 0:00:33 lr 6.344759	time 1.1821 (1.8785)	loss 3.7084 (3.7692)	grad_norm 0.2790 (0.3611)	mem 39782MB
[2023-07-07 07:45:47 RepVGG-A0] (main.py 282): INFO Train: [17/300][70/78]	eta 0:00:14 lr 6.343961	time 1.3549 (1.8265)	loss 3.6629 (3.7578)	grad_norm 0.3194 (0.3548)	mem 39782MB
[2023-07-07 07:46:00 RepVGG-A0] (main.py 291): INFO EPOCH 17 training takes 0:02:22
[2023-07-07 07:46:22 RepVGG-A0] (main.py 282): INFO Train: [18/300][0/78]	eta 0:27:34 lr 6.343319	time 21.2070 (21.2070)	loss 6.2156 (6.2156)	grad_norm 1.0156 (1.0156)	mem 39782MB
[2023-07-07 07:46:36 RepVGG-A0] (main.py 282): INFO Train: [18/300][10/78]	eta 0:03:42 lr 6.342511	time 1.1912 (3.2708)	loss 5.3948 (5.8317)	grad_norm 0.4270 (0.5488)	mem 39782MB
[2023-07-07 07:46:51 RepVGG-A0] (main.py 282): INFO Train: [18/300][20/78]	eta 0:02:19 lr 6.341698	time 1.1718 (2.3988)	loss 4.7222 (5.4317)	grad_norm 0.3467 (0.4279)	mem 39782MB
[2023-07-07 07:47:06 RepVGG-A0] (main.py 282): INFO Train: [18/300][30/78]	eta 0:01:41 lr 6.340879	time 1.2116 (2.1045)	loss 4.3910 (5.1646)	grad_norm 0.2444 (0.3872)	mem 39782MB
[2023-07-07 07:47:24 RepVGG-A0] (main.py 282): INFO Train: [18/300][40/78]	eta 0:01:17 lr 6.340054	time 4.0263 (2.0463)	loss 4.2382 (4.9476)	grad_norm 0.3201 (0.3564)	mem 39782MB
[2023-07-07 07:47:39 RepVGG-A0] (main.py 282): INFO Train: [18/300][50/78]	eta 0:00:54 lr 6.339223	time 1.1712 (1.9432)	loss 4.0872 (4.8010)	grad_norm 0.2617 (0.3466)	mem 39782MB
[2023-07-07 07:47:55 RepVGG-A0] (main.py 282): INFO Train: [18/300][60/78]	eta 0:00:33 lr 6.338387	time 1.3926 (1.8843)	loss 4.1378 (4.6812)	grad_norm 0.3505 (0.3408)	mem 39782MB
[2023-07-07 07:48:11 RepVGG-A0] (main.py 282): INFO Train: [18/300][70/78]	eta 0:00:14 lr 6.337545	time 1.1276 (1.8402)	loss 4.0346 (4.5853)	grad_norm 0.3598 (0.3366)	mem 39782MB
[2023-07-07 07:48:22 RepVGG-A0] (main.py 291): INFO EPOCH 18 training takes 0:02:21
[2023-07-07 07:48:43 RepVGG-A0] (main.py 282): INFO Train: [19/300][0/78]	eta 0:27:35 lr 6.336868	time 21.2231 (21.2231)	loss 3.8901 (3.8901)	grad_norm 0.3231 (0.3231)	mem 39782MB
[2023-07-07 07:48:57 RepVGG-A0] (main.py 282): INFO Train: [19/300][10/78]	eta 0:03:37 lr 6.336016	time 1.1704 (3.1928)	loss 3.8216 (3.9097)	grad_norm 0.3505 (0.3401)	mem 39782MB
[2023-07-07 07:49:13 RepVGG-A0] (main.py 282): INFO Train: [19/300][20/78]	eta 0:02:19 lr 6.335158	time 1.3163 (2.4045)	loss 3.9926 (3.9134)	grad_norm 0.3872 (0.3436)	mem 39782MB
[2023-07-07 07:49:27 RepVGG-A0] (main.py 282): INFO Train: [19/300][30/78]	eta 0:01:40 lr 6.334295	time 1.3202 (2.0894)	loss 3.7383 (3.9089)	grad_norm 0.3336 (0.3445)	mem 39782MB
[2023-07-07 07:49:44 RepVGG-A0] (main.py 282): INFO Train: [19/300][40/78]	eta 0:01:16 lr 6.333426	time 4.0418 (2.0034)	loss 3.8878 (3.8866)	grad_norm 0.4114 (0.3415)	mem 39782MB
[2023-07-07 07:50:00 RepVGG-A0] (main.py 282): INFO Train: [19/300][50/78]	eta 0:00:53 lr 6.332551	time 1.1733 (1.9105)	loss 3.7369 (3.8798)	grad_norm 0.3259 (0.3416)	mem 39782MB
[2023-07-07 07:50:14 RepVGG-A0] (main.py 282): INFO Train: [19/300][60/78]	eta 0:00:33 lr 6.331671	time 1.1928 (1.8427)	loss 3.8999 (3.8696)	grad_norm 0.3858 (0.3434)	mem 39782MB
[2023-07-07 07:50:30 RepVGG-A0] (main.py 282): INFO Train: [19/300][70/78]	eta 0:00:14 lr 6.330785	time 1.3515 (1.8012)	loss 4.0758 (3.8707)	grad_norm 0.4791 (0.3495)	mem 39782MB
[2023-07-07 07:50:41 RepVGG-A0] (main.py 291): INFO EPOCH 19 training takes 0:02:19
[2023-07-07 07:51:03 RepVGG-A0] (main.py 282): INFO Train: [20/300][0/78]	eta 0:28:09 lr 6.330072	time 21.6640 (21.6640)	loss 3.7470 (3.7470)	grad_norm 0.2921 (0.2921)	mem 39782MB
[2023-07-07 07:51:17 RepVGG-A0] (main.py 282): INFO Train: [20/300][10/78]	eta 0:03:42 lr 6.329176	time 1.1762 (3.2716)	loss 4.0425 (3.8337)	grad_norm 0.4776 (0.3881)	mem 39782MB
[2023-07-07 07:51:33 RepVGG-A0] (main.py 282): INFO Train: [20/300][20/78]	eta 0:02:23 lr 6.328275	time 1.4055 (2.4669)	loss 3.7820 (3.8425)	grad_norm 0.3171 (0.3670)	mem 39782MB
[2023-07-07 07:51:49 RepVGG-A0] (main.py 282): INFO Train: [20/300][30/78]	eta 0:01:43 lr 6.327367	time 1.4903 (2.1665)	loss 3.8313 (3.8609)	grad_norm 0.3293 (0.3753)	mem 39782MB
[2023-07-07 07:52:06 RepVGG-A0] (main.py 282): INFO Train: [20/300][40/78]	eta 0:01:18 lr 6.326454	time 3.9707 (2.0665)	loss 3.8324 (3.8338)	grad_norm 0.3773 (0.3609)	mem 39782MB
[2023-07-07 07:52:21 RepVGG-A0] (main.py 282): INFO Train: [20/300][50/78]	eta 0:00:54 lr 6.325536	time 1.1935 (1.9510)	loss 3.5753 (3.8073)	grad_norm 0.2934 (0.3514)	mem 39782MB
[2023-07-07 07:52:36 RepVGG-A0] (main.py 282): INFO Train: [20/300][60/78]	eta 0:00:33 lr 6.324611	time 1.6318 (1.8860)	loss 3.9260 (3.8035)	grad_norm 0.4276 (0.3578)	mem 39782MB
[2023-07-07 07:52:51 RepVGG-A0] (main.py 282): INFO Train: [20/300][70/78]	eta 0:00:14 lr 6.323682	time 1.1836 (1.8267)	loss 3.6453 (3.8043)	grad_norm 0.3177 (0.3581)	mem 39782MB
[2023-07-07 07:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 20 training takes 0:02:20
[2023-07-07 07:53:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.613 (17.613)	Loss 3.2837 (3.2837)	Acc@1 32.971 (32.971)	Acc@5 57.623 (57.623)	Mem 39782MB
[2023-07-07 07:53:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 32.742 Acc@5 57.506
[2023-07-07 07:53:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 20: 32.742%
[2023-07-07 07:53:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 07:53:42 RepVGG-A0] (main.py 282): INFO Train: [21/300][0/78]	eta 0:27:38 lr 6.322934	time 21.2631 (21.2631)	loss 3.6021 (3.6021)	grad_norm 0.3284 (0.3284)	mem 39782MB
[2023-07-07 07:53:57 RepVGG-A0] (main.py 282): INFO Train: [21/300][10/78]	eta 0:03:45 lr 6.321994	time 1.1740 (3.3164)	loss 3.7379 (3.6774)	grad_norm 0.4108 (0.3748)	mem 39782MB
[2023-07-07 07:54:12 RepVGG-A0] (main.py 282): INFO Train: [21/300][20/78]	eta 0:02:21 lr 6.321048	time 1.1911 (2.4359)	loss 3.8025 (3.7174)	grad_norm 0.3869 (0.3783)	mem 39782MB
[2023-07-07 07:54:27 RepVGG-A0] (main.py 282): INFO Train: [21/300][30/78]	eta 0:01:42 lr 6.320097	time 1.1739 (2.1409)	loss 3.6785 (3.7171)	grad_norm 0.3176 (0.3678)	mem 39782MB
[2023-07-07 07:54:44 RepVGG-A0] (main.py 282): INFO Train: [21/300][40/78]	eta 0:01:17 lr 6.319140	time 3.2079 (2.0447)	loss 3.6720 (3.6989)	grad_norm 0.4025 (0.3611)	mem 39782MB
[2023-07-07 07:54:59 RepVGG-A0] (main.py 282): INFO Train: [21/300][50/78]	eta 0:00:54 lr 6.318177	time 1.1724 (1.9419)	loss 3.4999 (3.6876)	grad_norm 0.3152 (0.3574)	mem 39782MB
[2023-07-07 07:55:15 RepVGG-A0] (main.py 282): INFO Train: [21/300][60/78]	eta 0:00:33 lr 6.317209	time 1.3494 (1.8758)	loss 3.6270 (3.6889)	grad_norm 0.3534 (0.3590)	mem 39782MB
[2023-07-07 07:55:30 RepVGG-A0] (main.py 282): INFO Train: [21/300][70/78]	eta 0:00:14 lr 6.316236	time 1.7658 (1.8290)	loss 3.8585 (3.7003)	grad_norm 0.4265 (0.3649)	mem 39782MB
[2023-07-07 07:55:42 RepVGG-A0] (main.py 291): INFO EPOCH 21 training takes 0:02:21
[2023-07-07 07:56:03 RepVGG-A0] (main.py 282): INFO Train: [22/300][0/78]	eta 0:27:58 lr 6.315452	time 21.5217 (21.5217)	loss 4.4940 (4.4940)	grad_norm 0.5225 (0.5225)	mem 39782MB
[2023-07-07 07:56:18 RepVGG-A0] (main.py 282): INFO Train: [22/300][10/78]	eta 0:03:43 lr 6.314469	time 1.1960 (3.2814)	loss 3.8672 (4.1203)	grad_norm 0.3035 (0.3728)	mem 39782MB
[2023-07-07 07:56:32 RepVGG-A0] (main.py 282): INFO Train: [22/300][20/78]	eta 0:02:19 lr 6.313479	time 1.1750 (2.4022)	loss 3.6671 (3.9119)	grad_norm 0.2631 (0.3263)	mem 39782MB
[2023-07-07 07:56:48 RepVGG-A0] (main.py 282): INFO Train: [22/300][30/78]	eta 0:01:43 lr 6.312484	time 1.1824 (2.1479)	loss 3.6198 (3.8162)	grad_norm 0.3040 (0.3154)	mem 39782MB
[2023-07-07 07:57:06 RepVGG-A0] (main.py 282): INFO Train: [22/300][40/78]	eta 0:01:17 lr 6.311483	time 3.8895 (2.0503)	loss 3.5302 (3.7640)	grad_norm 0.3168 (0.3164)	mem 39782MB
[2023-07-07 07:57:21 RepVGG-A0] (main.py 282): INFO Train: [22/300][50/78]	eta 0:00:54 lr 6.310477	time 1.4686 (1.9406)	loss 3.6635 (3.7458)	grad_norm 0.3499 (0.3246)	mem 39782MB
[2023-07-07 07:57:35 RepVGG-A0] (main.py 282): INFO Train: [22/300][60/78]	eta 0:00:33 lr 6.309465	time 1.1719 (1.8631)	loss 3.5976 (3.7224)	grad_norm 0.3477 (0.3247)	mem 39782MB
[2023-07-07 07:57:50 RepVGG-A0] (main.py 282): INFO Train: [22/300][70/78]	eta 0:00:14 lr 6.308448	time 1.1701 (1.8151)	loss 3.6356 (3.7097)	grad_norm 0.3597 (0.3286)	mem 39782MB
[2023-07-07 07:58:03 RepVGG-A0] (main.py 291): INFO EPOCH 22 training takes 0:02:21
[2023-07-07 07:58:24 RepVGG-A0] (main.py 282): INFO Train: [23/300][0/78]	eta 0:27:24 lr 6.307630	time 21.0772 (21.0772)	loss 3.4743 (3.4743)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 07:58:39 RepVGG-A0] (main.py 282): INFO Train: [23/300][10/78]	eta 0:03:41 lr 6.306602	time 1.1716 (3.2530)	loss 3.6742 (3.6154)	grad_norm 0.3604 (0.3686)	mem 39782MB
[2023-07-07 07:58:54 RepVGG-A0] (main.py 282): INFO Train: [23/300][20/78]	eta 0:02:22 lr 6.305569	time 1.1589 (2.4499)	loss 3.5928 (3.6046)	grad_norm 0.3414 (0.3583)	mem 39782MB
[2023-07-07 07:59:09 RepVGG-A0] (main.py 282): INFO Train: [23/300][30/78]	eta 0:01:42 lr 6.304530	time 1.3654 (2.1368)	loss 3.5351 (3.6039)	grad_norm 0.3500 (0.3585)	mem 39782MB
[2023-07-07 07:59:27 RepVGG-A0] (main.py 282): INFO Train: [23/300][40/78]	eta 0:01:18 lr 6.303486	time 3.0154 (2.0540)	loss 3.6937 (3.6132)	grad_norm 0.3400 (0.3606)	mem 39782MB
[2023-07-07 07:59:42 RepVGG-A0] (main.py 282): INFO Train: [23/300][50/78]	eta 0:00:54 lr 6.302436	time 1.1947 (1.9453)	loss 3.6094 (3.6062)	grad_norm 0.3568 (0.3566)	mem 39782MB
[2023-07-07 07:59:57 RepVGG-A0] (main.py 282): INFO Train: [23/300][60/78]	eta 0:00:33 lr 6.301380	time 1.3392 (1.8797)	loss 3.6835 (3.6114)	grad_norm 0.3734 (0.3597)	mem 39782MB
[2023-07-07 08:00:13 RepVGG-A0] (main.py 282): INFO Train: [23/300][70/78]	eta 0:00:14 lr 6.300319	time 1.4522 (1.8290)	loss 3.7271 (3.6123)	grad_norm 0.3992 (0.3592)	mem 39782MB
[2023-07-07 08:00:24 RepVGG-A0] (main.py 291): INFO EPOCH 23 training takes 0:02:20
[2023-07-07 08:00:46 RepVGG-A0] (main.py 282): INFO Train: [24/300][0/78]	eta 0:28:26 lr 6.299466	time 21.8746 (21.8746)	loss 3.6182 (3.6182)	grad_norm 0.3645 (0.3645)	mem 39782MB
[2023-07-07 08:00:59 RepVGG-A0] (main.py 282): INFO Train: [24/300][10/78]	eta 0:03:40 lr 6.298395	time 1.1715 (3.2399)	loss 3.4829 (3.5145)	grad_norm 0.3359 (0.3254)	mem 39782MB
[2023-07-07 08:01:14 RepVGG-A0] (main.py 282): INFO Train: [24/300][20/78]	eta 0:02:18 lr 6.297318	time 1.1719 (2.3923)	loss 4.5581 (3.6495)	grad_norm 0.7927 (0.4109)	mem 39782MB
[2023-07-07 08:01:29 RepVGG-A0] (main.py 282): INFO Train: [24/300][30/78]	eta 0:01:41 lr 6.296236	time 1.2966 (2.1044)	loss 5.5153 (4.3539)	grad_norm 0.3807 (0.4860)	mem 39782MB
[2023-07-07 08:01:47 RepVGG-A0] (main.py 282): INFO Train: [24/300][40/78]	eta 0:01:16 lr 6.295148	time 3.2337 (2.0255)	loss 4.8523 (4.5645)	grad_norm 0.2415 (0.4467)	mem 39782MB
[2023-07-07 08:02:02 RepVGG-A0] (main.py 282): INFO Train: [24/300][50/78]	eta 0:00:53 lr 6.294054	time 1.1893 (1.9177)	loss 4.4826 (4.5793)	grad_norm 0.2658 (0.4163)	mem 39782MB
[2023-07-07 08:02:17 RepVGG-A0] (main.py 282): INFO Train: [24/300][60/78]	eta 0:00:33 lr 6.292955	time 1.1793 (1.8498)	loss 4.3276 (4.5377)	grad_norm 0.3431 (0.3977)	mem 39782MB
[2023-07-07 08:02:32 RepVGG-A0] (main.py 282): INFO Train: [24/300][70/78]	eta 0:00:14 lr 6.291850	time 1.1710 (1.8006)	loss 4.3350 (4.4892)	grad_norm 0.4236 (0.3862)	mem 39782MB
[2023-07-07 08:02:44 RepVGG-A0] (main.py 291): INFO EPOCH 24 training takes 0:02:19
[2023-07-07 08:03:04 RepVGG-A0] (main.py 282): INFO Train: [25/300][0/78]	eta 0:26:46 lr 6.290963	time 20.5959 (20.5959)	loss 3.9457 (3.9457)	grad_norm 0.2841 (0.2841)	mem 39782MB
[2023-07-07 08:03:21 RepVGG-A0] (main.py 282): INFO Train: [25/300][10/78]	eta 0:03:49 lr 6.289848	time 1.1715 (3.3705)	loss 3.9111 (3.9398)	grad_norm 0.3544 (0.3094)	mem 39782MB
[2023-07-07 08:03:35 RepVGG-A0] (main.py 282): INFO Train: [25/300][20/78]	eta 0:02:21 lr 6.288728	time 1.2791 (2.4413)	loss 3.9022 (3.9246)	grad_norm 0.2953 (0.3101)	mem 39782MB
[2023-07-07 08:03:50 RepVGG-A0] (main.py 282): INFO Train: [25/300][30/78]	eta 0:01:42 lr 6.287602	time 1.2142 (2.1345)	loss 3.9066 (3.9037)	grad_norm 0.3473 (0.3172)	mem 39782MB
[2023-07-07 08:04:07 RepVGG-A0] (main.py 282): INFO Train: [25/300][40/78]	eta 0:01:17 lr 6.286470	time 4.1359 (2.0385)	loss 3.8610 (3.9004)	grad_norm 0.3601 (0.3316)	mem 39782MB
[2023-07-07 08:04:22 RepVGG-A0] (main.py 282): INFO Train: [25/300][50/78]	eta 0:00:54 lr 6.285333	time 1.1710 (1.9387)	loss 3.8712 (3.8829)	grad_norm 0.3959 (0.3312)	mem 39782MB
[2023-07-07 08:04:38 RepVGG-A0] (main.py 282): INFO Train: [25/300][60/78]	eta 0:00:33 lr 6.284191	time 1.1722 (1.8730)	loss 3.7868 (3.8692)	grad_norm 0.3242 (0.3322)	mem 39782MB
[2023-07-07 08:04:54 RepVGG-A0] (main.py 282): INFO Train: [25/300][70/78]	eta 0:00:14 lr 6.283043	time 1.2760 (1.8299)	loss 4.0115 (3.8586)	grad_norm 0.4574 (0.3368)	mem 39782MB
[2023-07-07 08:05:06 RepVGG-A0] (main.py 291): INFO EPOCH 25 training takes 0:02:21
[2023-07-07 08:05:27 RepVGG-A0] (main.py 282): INFO Train: [26/300][0/78]	eta 0:27:31 lr 6.282120	time 21.1734 (21.1734)	loss 3.6026 (3.6026)	grad_norm 0.3104 (0.3104)	mem 39782MB
[2023-07-07 08:05:42 RepVGG-A0] (main.py 282): INFO Train: [26/300][10/78]	eta 0:03:44 lr 6.280962	time 1.1712 (3.3021)	loss 4.4189 (3.7956)	grad_norm 0.7122 (0.4144)	mem 39782MB
[2023-07-07 08:05:56 RepVGG-A0] (main.py 282): INFO Train: [26/300][20/78]	eta 0:02:18 lr 6.279798	time 1.1747 (2.3955)	loss 4.7799 (4.3915)	grad_norm 0.3648 (0.5107)	mem 39782MB
[2023-07-07 08:06:11 RepVGG-A0] (main.py 282): INFO Train: [26/300][30/78]	eta 0:01:41 lr 6.278629	time 1.1721 (2.1173)	loss 4.2677 (4.3782)	grad_norm 0.3739 (0.4444)	mem 39782MB
[2023-07-07 08:06:30 RepVGG-A0] (main.py 282): INFO Train: [26/300][40/78]	eta 0:01:18 lr 6.277454	time 4.4765 (2.0535)	loss 4.0426 (4.3127)	grad_norm 0.2316 (0.4091)	mem 39782MB
[2023-07-07 08:06:45 RepVGG-A0] (main.py 282): INFO Train: [26/300][50/78]	eta 0:00:54 lr 6.276274	time 1.1741 (1.9408)	loss 3.7757 (4.2300)	grad_norm 0.2624 (0.3826)	mem 39782MB
[2023-07-07 08:07:00 RepVGG-A0] (main.py 282): INFO Train: [26/300][60/78]	eta 0:00:33 lr 6.275088	time 1.1806 (1.8737)	loss 3.8324 (4.1522)	grad_norm 0.3173 (0.3659)	mem 39782MB
[2023-07-07 08:07:14 RepVGG-A0] (main.py 282): INFO Train: [26/300][70/78]	eta 0:00:14 lr 6.273897	time 1.1722 (1.8126)	loss 3.7319 (4.0910)	grad_norm 0.3091 (0.3571)	mem 39782MB
[2023-07-07 08:07:26 RepVGG-A0] (main.py 291): INFO EPOCH 26 training takes 0:02:20
[2023-07-07 08:07:48 RepVGG-A0] (main.py 282): INFO Train: [27/300][0/78]	eta 0:28:03 lr 6.272940	time 21.5797 (21.5797)	loss 3.6820 (3.6820)	grad_norm 0.3342 (0.3342)	mem 39782MB
[2023-07-07 08:08:03 RepVGG-A0] (main.py 282): INFO Train: [27/300][10/78]	eta 0:03:44 lr 6.271738	time 1.1722 (3.3077)	loss 3.7961 (3.7172)	grad_norm 0.3630 (0.3613)	mem 39782MB
[2023-07-07 08:08:17 RepVGG-A0] (main.py 282): INFO Train: [27/300][20/78]	eta 0:02:21 lr 6.270532	time 1.1777 (2.4357)	loss 3.7976 (3.7302)	grad_norm 0.3418 (0.3543)	mem 39782MB
[2023-07-07 08:08:32 RepVGG-A0] (main.py 282): INFO Train: [27/300][30/78]	eta 0:01:42 lr 6.269319	time 1.2917 (2.1253)	loss 3.5862 (3.6961)	grad_norm 0.3159 (0.3384)	mem 39782MB
[2023-07-07 08:08:50 RepVGG-A0] (main.py 282): INFO Train: [27/300][40/78]	eta 0:01:17 lr 6.268101	time 3.0199 (2.0490)	loss 3.9979 (3.7091)	grad_norm 0.5404 (0.3534)	mem 39782MB
[2023-07-07 08:09:05 RepVGG-A0] (main.py 282): INFO Train: [27/300][50/78]	eta 0:00:54 lr 6.266878	time 1.1723 (1.9364)	loss 3.9294 (3.8093)	grad_norm 0.3163 (0.3780)	mem 39782MB
[2023-07-07 08:09:20 RepVGG-A0] (main.py 282): INFO Train: [27/300][60/78]	eta 0:00:33 lr 6.265649	time 1.1763 (1.8633)	loss 3.6872 (3.8050)	grad_norm 0.2731 (0.3623)	mem 39782MB
[2023-07-07 08:09:35 RepVGG-A0] (main.py 282): INFO Train: [27/300][70/78]	eta 0:00:14 lr 6.264414	time 1.1715 (1.8143)	loss 3.7241 (3.7832)	grad_norm 0.3163 (0.3513)	mem 39782MB
[2023-07-07 08:09:47 RepVGG-A0] (main.py 291): INFO EPOCH 27 training takes 0:02:20
[2023-07-07 08:10:09 RepVGG-A0] (main.py 282): INFO Train: [28/300][0/78]	eta 0:28:15 lr 6.263422	time 21.7410 (21.7410)	loss 3.6358 (3.6358)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 08:10:24 RepVGG-A0] (main.py 282): INFO Train: [28/300][10/78]	eta 0:03:48 lr 6.262178	time 1.1718 (3.3620)	loss 3.6285 (3.5704)	grad_norm 0.3147 (0.2939)	mem 39782MB
[2023-07-07 08:10:38 RepVGG-A0] (main.py 282): INFO Train: [28/300][20/78]	eta 0:02:21 lr 6.260928	time 1.1753 (2.4372)	loss 3.5540 (3.5618)	grad_norm 0.3378 (0.3093)	mem 39782MB
[2023-07-07 08:10:53 RepVGG-A0] (main.py 282): INFO Train: [28/300][30/78]	eta 0:01:41 lr 6.259672	time 1.4279 (2.1213)	loss 3.8273 (3.6117)	grad_norm 0.3801 (0.3378)	mem 39782MB
[2023-07-07 08:11:11 RepVGG-A0] (main.py 282): INFO Train: [28/300][40/78]	eta 0:01:17 lr 6.258411	time 3.1183 (2.0435)	loss 3.5900 (3.6186)	grad_norm 0.3011 (0.3368)	mem 39782MB
[2023-07-07 08:11:26 RepVGG-A0] (main.py 282): INFO Train: [28/300][50/78]	eta 0:00:54 lr 6.257145	time 1.1714 (1.9391)	loss 3.7004 (3.6176)	grad_norm 0.3926 (0.3398)	mem 39782MB
[2023-07-07 08:11:41 RepVGG-A0] (main.py 282): INFO Train: [28/300][60/78]	eta 0:00:33 lr 6.255873	time 1.2762 (1.8636)	loss 3.5787 (3.6295)	grad_norm 0.3168 (0.3440)	mem 39782MB
[2023-07-07 08:11:56 RepVGG-A0] (main.py 282): INFO Train: [28/300][70/78]	eta 0:00:14 lr 6.254595	time 1.1963 (1.8181)	loss 3.5581 (3.6189)	grad_norm 0.3334 (0.3408)	mem 39782MB
[2023-07-07 08:12:09 RepVGG-A0] (main.py 291): INFO EPOCH 28 training takes 0:02:21
[2023-07-07 08:12:31 RepVGG-A0] (main.py 282): INFO Train: [29/300][0/78]	eta 0:28:41 lr 6.253569	time 22.0680 (22.0680)	loss 3.5058 (3.5058)	grad_norm 0.3577 (0.3577)	mem 39782MB
[2023-07-07 08:12:45 RepVGG-A0] (main.py 282): INFO Train: [29/300][10/78]	eta 0:03:45 lr 6.252282	time 1.1714 (3.3184)	loss 6.0851 (4.6346)	grad_norm 0.7011 (0.6846)	mem 39782MB
[2023-07-07 08:13:00 RepVGG-A0] (main.py 282): INFO Train: [29/300][20/78]	eta 0:02:20 lr 6.250989	time 1.1892 (2.4179)	loss 5.0309 (5.0580)	grad_norm 0.3091 (0.5526)	mem 39782MB
[2023-07-07 08:13:15 RepVGG-A0] (main.py 282): INFO Train: [29/300][30/78]	eta 0:01:41 lr 6.249690	time 1.1869 (2.1179)	loss 4.5049 (4.9322)	grad_norm 0.3007 (0.4655)	mem 39782MB
[2023-07-07 08:13:33 RepVGG-A0] (main.py 282): INFO Train: [29/300][40/78]	eta 0:01:18 lr 6.248386	time 4.3228 (2.0557)	loss 4.1712 (4.7801)	grad_norm 0.2924 (0.4179)	mem 39782MB
[2023-07-07 08:13:48 RepVGG-A0] (main.py 282): INFO Train: [29/300][50/78]	eta 0:00:54 lr 6.247077	time 1.1748 (1.9464)	loss 4.1398 (4.6509)	grad_norm 0.3205 (0.3931)	mem 39782MB
[2023-07-07 08:14:04 RepVGG-A0] (main.py 282): INFO Train: [29/300][60/78]	eta 0:00:33 lr 6.245762	time 1.2817 (1.8842)	loss 3.9473 (4.5478)	grad_norm 0.3041 (0.3779)	mem 39782MB
[2023-07-07 08:14:18 RepVGG-A0] (main.py 282): INFO Train: [29/300][70/78]	eta 0:00:14 lr 6.244441	time 1.2725 (1.8196)	loss 3.8452 (4.4628)	grad_norm 0.2823 (0.3697)	mem 39782MB
[2023-07-07 08:14:31 RepVGG-A0] (main.py 291): INFO EPOCH 29 training takes 0:02:21
[2023-07-07 08:14:51 RepVGG-A0] (main.py 282): INFO Train: [30/300][0/78]	eta 0:27:08 lr 6.243381	time 20.8762 (20.8762)	loss 3.9250 (3.9250)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 08:15:06 RepVGG-A0] (main.py 282): INFO Train: [30/300][10/78]	eta 0:03:38 lr 6.242051	time 1.1701 (3.2159)	loss 3.8675 (3.8529)	grad_norm 0.3725 (0.3390)	mem 39782MB
[2023-07-07 08:15:20 RepVGG-A0] (main.py 282): INFO Train: [30/300][20/78]	eta 0:02:17 lr 6.240715	time 1.1906 (2.3765)	loss 3.7867 (3.8392)	grad_norm 0.3284 (0.3372)	mem 39782MB
[2023-07-07 08:15:35 RepVGG-A0] (main.py 282): INFO Train: [30/300][30/78]	eta 0:01:39 lr 6.239373	time 1.4826 (2.0761)	loss 3.7765 (3.8172)	grad_norm 0.3047 (0.3383)	mem 39782MB
[2023-07-07 08:15:53 RepVGG-A0] (main.py 282): INFO Train: [30/300][40/78]	eta 0:01:16 lr 6.238027	time 5.1759 (2.0207)	loss 3.8975 (3.8075)	grad_norm 0.3972 (0.3407)	mem 39782MB
[2023-07-07 08:16:08 RepVGG-A0] (main.py 282): INFO Train: [30/300][50/78]	eta 0:00:53 lr 6.236674	time 1.1728 (1.9154)	loss 3.6361 (3.7916)	grad_norm 0.3080 (0.3382)	mem 39782MB
[2023-07-07 08:16:24 RepVGG-A0] (main.py 282): INFO Train: [30/300][60/78]	eta 0:00:33 lr 6.235317	time 1.1808 (1.8627)	loss 3.7841 (3.7887)	grad_norm 0.3292 (0.3433)	mem 39782MB
[2023-07-07 08:16:38 RepVGG-A0] (main.py 282): INFO Train: [30/300][70/78]	eta 0:00:14 lr 6.233953	time 1.3713 (1.8010)	loss 3.9552 (3.7846)	grad_norm 0.4951 (0.3462)	mem 39782MB
[2023-07-07 08:16:50 RepVGG-A0] (main.py 291): INFO EPOCH 30 training takes 0:02:19
[2023-07-07 08:17:12 RepVGG-A0] (main.py 282): INFO Train: [31/300][0/78]	eta 0:28:23 lr 6.232859	time 21.8441 (21.8441)	loss 5.3212 (5.3212)	grad_norm 0.5897 (0.5897)	mem 39782MB
[2023-07-07 08:17:27 RepVGG-A0] (main.py 282): INFO Train: [31/300][10/78]	eta 0:03:49 lr 6.231486	time 1.1724 (3.3805)	loss 4.2852 (4.6491)	grad_norm 0.2788 (0.3600)	mem 39782MB
[2023-07-07 08:17:42 RepVGG-A0] (main.py 282): INFO Train: [31/300][20/78]	eta 0:02:22 lr 6.230107	time 1.3024 (2.4647)	loss 4.1213 (4.4053)	grad_norm 0.3201 (0.3397)	mem 39782MB
[2023-07-07 08:17:57 RepVGG-A0] (main.py 282): INFO Train: [31/300][30/78]	eta 0:01:44 lr 6.228723	time 1.2292 (2.1697)	loss 3.7588 (4.2293)	grad_norm 0.2599 (0.3074)	mem 39782MB
[2023-07-07 08:18:15 RepVGG-A0] (main.py 282): INFO Train: [31/300][40/78]	eta 0:01:18 lr 6.227334	time 3.1923 (2.0719)	loss 3.7509 (4.1074)	grad_norm 0.3200 (0.2997)	mem 39782MB
[2023-07-07 08:18:30 RepVGG-A0] (main.py 282): INFO Train: [31/300][50/78]	eta 0:00:54 lr 6.225939	time 1.1710 (1.9582)	loss 3.7697 (4.0377)	grad_norm 0.3230 (0.3059)	mem 39782MB
[2023-07-07 08:18:45 RepVGG-A0] (main.py 282): INFO Train: [31/300][60/78]	eta 0:00:33 lr 6.224539	time 1.1788 (1.8822)	loss 3.6369 (3.9825)	grad_norm 0.3415 (0.3073)	mem 39782MB
[2023-07-07 08:19:00 RepVGG-A0] (main.py 282): INFO Train: [31/300][70/78]	eta 0:00:14 lr 6.223133	time 1.2249 (1.8339)	loss 3.6149 (3.9374)	grad_norm 0.3307 (0.3094)	mem 39782MB
[2023-07-07 08:19:12 RepVGG-A0] (main.py 291): INFO EPOCH 31 training takes 0:02:21
[2023-07-07 08:19:32 RepVGG-A0] (main.py 282): INFO Train: [32/300][0/78]	eta 0:26:38 lr 6.222004	time 20.4906 (20.4906)	loss 3.5897 (3.5897)	grad_norm 0.3058 (0.3058)	mem 39782MB
[2023-07-07 08:19:46 RepVGG-A0] (main.py 282): INFO Train: [32/300][10/78]	eta 0:03:32 lr 6.220589	time 1.1714 (3.1263)	loss 3.7428 (3.7028)	grad_norm 0.3673 (0.3759)	mem 39782MB
[2023-07-07 08:20:02 RepVGG-A0] (main.py 282): INFO Train: [32/300][20/78]	eta 0:02:18 lr 6.219168	time 1.1744 (2.3814)	loss 3.6058 (3.6716)	grad_norm 0.2875 (0.3475)	mem 39782MB
[2023-07-07 08:20:17 RepVGG-A0] (main.py 282): INFO Train: [32/300][30/78]	eta 0:01:41 lr 6.217741	time 1.3490 (2.1183)	loss 3.5421 (3.6532)	grad_norm 0.3112 (0.3431)	mem 39782MB
[2023-07-07 08:20:35 RepVGG-A0] (main.py 282): INFO Train: [32/300][40/78]	eta 0:01:17 lr 6.216309	time 4.7984 (2.0396)	loss 3.7894 (3.6606)	grad_norm 0.4289 (0.3510)	mem 39782MB
[2023-07-07 08:20:50 RepVGG-A0] (main.py 282): INFO Train: [32/300][50/78]	eta 0:00:54 lr 6.214872	time 1.1737 (1.9330)	loss 3.8105 (3.6621)	grad_norm 0.4604 (0.3518)	mem 39782MB
[2023-07-07 08:21:05 RepVGG-A0] (main.py 282): INFO Train: [32/300][60/78]	eta 0:00:33 lr 6.213429	time 1.3759 (1.8645)	loss 3.6000 (3.6744)	grad_norm 0.3088 (0.3563)	mem 39782MB
[2023-07-07 08:21:20 RepVGG-A0] (main.py 282): INFO Train: [32/300][70/78]	eta 0:00:14 lr 6.211981	time 1.3092 (1.8121)	loss 3.5727 (3.6610)	grad_norm 0.3149 (0.3469)	mem 39782MB
[2023-07-07 08:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 32 training takes 0:02:20
[2023-07-07 08:21:54 RepVGG-A0] (main.py 282): INFO Train: [33/300][0/78]	eta 0:27:57 lr 6.210818	time 21.5072 (21.5072)	loss 4.0114 (4.0114)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 08:22:09 RepVGG-A0] (main.py 282): INFO Train: [33/300][10/78]	eta 0:03:45 lr 6.209360	time 1.1729 (3.3125)	loss 5.5637 (4.9283)	grad_norm 0.5298 (0.7022)	mem 39782MB
[2023-07-07 08:22:24 RepVGG-A0] (main.py 282): INFO Train: [33/300][20/78]	eta 0:02:21 lr 6.207897	time 1.1787 (2.4413)	loss 4.4428 (4.8577)	grad_norm 0.2923 (0.5366)	mem 39782MB
[2023-07-07 08:22:39 RepVGG-A0] (main.py 282): INFO Train: [33/300][30/78]	eta 0:01:43 lr 6.206428	time 1.3781 (2.1576)	loss 3.9609 (4.6292)	grad_norm 0.2446 (0.4461)	mem 39782MB
[2023-07-07 08:22:57 RepVGG-A0] (main.py 282): INFO Train: [33/300][40/78]	eta 0:01:18 lr 6.204954	time 3.6851 (2.0632)	loss 3.9490 (4.4642)	grad_norm 0.3565 (0.4098)	mem 39782MB
[2023-07-07 08:23:12 RepVGG-A0] (main.py 282): INFO Train: [33/300][50/78]	eta 0:00:54 lr 6.203474	time 1.1364 (1.9548)	loss 3.7647 (4.3399)	grad_norm 0.2677 (0.3821)	mem 39782MB
[2023-07-07 08:23:27 RepVGG-A0] (main.py 282): INFO Train: [33/300][60/78]	eta 0:00:33 lr 6.201989	time 1.2581 (1.8774)	loss 3.7345 (4.2416)	grad_norm 0.3083 (0.3665)	mem 39782MB
[2023-07-07 08:23:42 RepVGG-A0] (main.py 282): INFO Train: [33/300][70/78]	eta 0:00:14 lr 6.200499	time 1.3691 (1.8298)	loss 3.7027 (4.1711)	grad_norm 0.3201 (0.3605)	mem 39782MB
[2023-07-07 08:23:54 RepVGG-A0] (main.py 291): INFO EPOCH 33 training takes 0:02:21
[2023-07-07 08:24:16 RepVGG-A0] (main.py 282): INFO Train: [34/300][0/78]	eta 0:29:24 lr 6.199302	time 22.6251 (22.6251)	loss 3.6440 (3.6440)	grad_norm 0.2979 (0.2979)	mem 39782MB
[2023-07-07 08:24:31 RepVGG-A0] (main.py 282): INFO Train: [34/300][10/78]	eta 0:03:50 lr 6.197802	time 1.1732 (3.3828)	loss 3.6947 (3.6440)	grad_norm 0.3314 (0.3289)	mem 39782MB
[2023-07-07 08:24:46 RepVGG-A0] (main.py 282): INFO Train: [34/300][20/78]	eta 0:02:23 lr 6.196296	time 1.1481 (2.4698)	loss 3.8523 (3.7127)	grad_norm 0.4196 (0.3657)	mem 39782MB
[2023-07-07 08:25:01 RepVGG-A0] (main.py 282): INFO Train: [34/300][30/78]	eta 0:01:43 lr 6.194785	time 1.3640 (2.1554)	loss 3.6682 (3.7000)	grad_norm 0.3606 (0.3504)	mem 39782MB
[2023-07-07 08:25:17 RepVGG-A0] (main.py 282): INFO Train: [34/300][40/78]	eta 0:01:17 lr 6.193269	time 3.3736 (2.0367)	loss 3.7111 (3.6869)	grad_norm 0.3824 (0.3458)	mem 39782MB
[2023-07-07 08:25:32 RepVGG-A0] (main.py 282): INFO Train: [34/300][50/78]	eta 0:00:54 lr 6.191747	time 1.1777 (1.9339)	loss 3.6821 (3.6767)	grad_norm 0.3597 (0.3452)	mem 39782MB
[2023-07-07 08:25:47 RepVGG-A0] (main.py 282): INFO Train: [34/300][60/78]	eta 0:00:33 lr 6.190220	time 1.3181 (1.8600)	loss 3.5923 (3.6695)	grad_norm 0.3250 (0.3445)	mem 39782MB
[2023-07-07 08:26:02 RepVGG-A0] (main.py 282): INFO Train: [34/300][70/78]	eta 0:00:14 lr 6.188687	time 1.1716 (1.8022)	loss 3.7899 (3.6635)	grad_norm 0.4421 (0.3453)	mem 39782MB
[2023-07-07 08:26:14 RepVGG-A0] (main.py 291): INFO EPOCH 34 training takes 0:02:20
[2023-07-07 08:26:35 RepVGG-A0] (main.py 282): INFO Train: [35/300][0/78]	eta 0:27:21 lr 6.187457	time 21.0480 (21.0480)	loss 3.6516 (3.6516)	grad_norm 0.3010 (0.3010)	mem 39782MB
[2023-07-07 08:26:51 RepVGG-A0] (main.py 282): INFO Train: [35/300][10/78]	eta 0:03:46 lr 6.185915	time 1.1709 (3.3360)	loss 3.6157 (3.5711)	grad_norm 0.4171 (0.3401)	mem 39782MB
[2023-07-07 08:27:05 RepVGG-A0] (main.py 282): INFO Train: [35/300][20/78]	eta 0:02:22 lr 6.184367	time 1.1931 (2.4502)	loss 3.5562 (3.5979)	grad_norm 0.3161 (0.3442)	mem 39782MB
[2023-07-07 08:27:20 RepVGG-A0] (main.py 282): INFO Train: [35/300][30/78]	eta 0:01:42 lr 6.182814	time 1.4472 (2.1397)	loss 3.5660 (3.5772)	grad_norm 0.3487 (0.3416)	mem 39782MB
[2023-07-07 08:27:39 RepVGG-A0] (main.py 282): INFO Train: [35/300][40/78]	eta 0:01:18 lr 6.181256	time 2.9660 (2.0610)	loss 3.4990 (3.5701)	grad_norm 0.3401 (0.3428)	mem 39782MB
[2023-07-07 08:27:53 RepVGG-A0] (main.py 282): INFO Train: [35/300][50/78]	eta 0:00:54 lr 6.179692	time 1.1836 (1.9500)	loss 3.5259 (3.5780)	grad_norm 0.2910 (0.3484)	mem 39782MB
[2023-07-07 08:28:10 RepVGG-A0] (main.py 282): INFO Train: [35/300][60/78]	eta 0:00:34 lr 6.178123	time 1.2933 (1.9016)	loss 3.6832 (3.5736)	grad_norm 0.4451 (0.3473)	mem 39782MB
[2023-07-07 08:28:24 RepVGG-A0] (main.py 282): INFO Train: [35/300][70/78]	eta 0:00:14 lr 6.176548	time 1.3248 (1.8238)	loss 6.0171 (3.7966)	grad_norm 0.6339 (0.4042)	mem 39782MB
[2023-07-07 08:28:36 RepVGG-A0] (main.py 291): INFO EPOCH 35 training takes 0:02:22
[2023-07-07 08:28:57 RepVGG-A0] (main.py 282): INFO Train: [36/300][0/78]	eta 0:27:32 lr 6.175285	time 21.1908 (21.1908)	loss 5.1591 (5.1591)	grad_norm 0.3020 (0.3020)	mem 39782MB
[2023-07-07 08:29:13 RepVGG-A0] (main.py 282): INFO Train: [36/300][10/78]	eta 0:03:49 lr 6.173701	time 1.1723 (3.3731)	loss 4.5267 (4.8056)	grad_norm 0.2546 (0.2981)	mem 39782MB
[2023-07-07 08:29:29 RepVGG-A0] (main.py 282): INFO Train: [36/300][20/78]	eta 0:02:25 lr 6.172111	time 1.1792 (2.5071)	loss 4.2040 (4.6057)	grad_norm 0.2571 (0.2900)	mem 39782MB
[2023-07-07 08:29:45 RepVGG-A0] (main.py 282): INFO Train: [36/300][30/78]	eta 0:01:45 lr 6.170516	time 1.3828 (2.2052)	loss 4.0783 (4.4675)	grad_norm 0.2667 (0.2970)	mem 39782MB
[2023-07-07 08:30:02 RepVGG-A0] (main.py 282): INFO Train: [36/300][40/78]	eta 0:01:19 lr 6.168916	time 2.6300 (2.0949)	loss 3.9947 (4.3514)	grad_norm 0.2985 (0.2937)	mem 39782MB
[2023-07-07 08:30:17 RepVGG-A0] (main.py 282): INFO Train: [36/300][50/78]	eta 0:00:55 lr 6.167310	time 1.1711 (1.9845)	loss 3.8298 (4.2686)	grad_norm 0.2791 (0.2976)	mem 39782MB
[2023-07-07 08:30:32 RepVGG-A0] (main.py 282): INFO Train: [36/300][60/78]	eta 0:00:34 lr 6.165699	time 1.1736 (1.8948)	loss 3.7427 (4.1992)	grad_norm 0.2899 (0.3001)	mem 39782MB
[2023-07-07 08:30:48 RepVGG-A0] (main.py 282): INFO Train: [36/300][70/78]	eta 0:00:14 lr 6.164083	time 1.3872 (1.8488)	loss 3.8815 (4.1504)	grad_norm 0.3755 (0.3072)	mem 39782MB
[2023-07-07 08:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 36 training takes 0:02:21
[2023-07-07 08:31:20 RepVGG-A0] (main.py 282): INFO Train: [37/300][0/78]	eta 0:27:58 lr 6.162786	time 21.5169 (21.5169)	loss 3.6648 (3.6648)	grad_norm 0.2641 (0.2641)	mem 39782MB
[2023-07-07 08:31:35 RepVGG-A0] (main.py 282): INFO Train: [37/300][10/78]	eta 0:03:49 lr 6.161160	time 1.1705 (3.3822)	loss 4.1770 (3.8478)	grad_norm 0.5285 (0.3896)	mem 39782MB
[2023-07-07 08:31:51 RepVGG-A0] (main.py 282): INFO Train: [37/300][20/78]	eta 0:02:25 lr 6.159529	time 1.5087 (2.5056)	loss 3.6751 (3.8496)	grad_norm 0.2866 (0.3609)	mem 39782MB
[2023-07-07 08:32:05 RepVGG-A0] (main.py 282): INFO Train: [37/300][30/78]	eta 0:01:44 lr 6.157892	time 1.2199 (2.1681)	loss 3.6938 (3.8073)	grad_norm 0.3098 (0.3445)	mem 39782MB
[2023-07-07 08:32:24 RepVGG-A0] (main.py 282): INFO Train: [37/300][40/78]	eta 0:01:19 lr 6.156250	time 4.1157 (2.0811)	loss 3.9909 (3.7923)	grad_norm 0.4558 (0.3483)	mem 39782MB
[2023-07-07 08:32:38 RepVGG-A0] (main.py 282): INFO Train: [37/300][50/78]	eta 0:00:54 lr 6.154603	time 1.1722 (1.9642)	loss 3.6901 (3.7781)	grad_norm 0.3601 (0.3421)	mem 39782MB
[2023-07-07 08:32:54 RepVGG-A0] (main.py 282): INFO Train: [37/300][60/78]	eta 0:00:34 lr 6.152950	time 1.2081 (1.8959)	loss 3.6493 (3.7648)	grad_norm 0.2920 (0.3431)	mem 39782MB
[2023-07-07 08:33:09 RepVGG-A0] (main.py 282): INFO Train: [37/300][70/78]	eta 0:00:14 lr 6.151292	time 1.3209 (1.8458)	loss 3.6209 (3.7449)	grad_norm 0.3624 (0.3397)	mem 39782MB
[2023-07-07 08:33:21 RepVGG-A0] (main.py 291): INFO EPOCH 37 training takes 0:02:22
[2023-07-07 08:33:41 RepVGG-A0] (main.py 282): INFO Train: [38/300][0/78]	eta 0:26:31 lr 6.149962	time 20.4003 (20.4003)	loss 4.0336 (4.0336)	grad_norm 0.4791 (0.4791)	mem 39782MB
[2023-07-07 08:33:55 RepVGG-A0] (main.py 282): INFO Train: [38/300][10/78]	eta 0:03:35 lr 6.148295	time 1.1952 (3.1648)	loss 3.7080 (3.8362)	grad_norm 0.3382 (0.3775)	mem 39782MB
[2023-07-07 08:34:11 RepVGG-A0] (main.py 282): INFO Train: [38/300][20/78]	eta 0:02:18 lr 6.146622	time 1.1707 (2.3829)	loss 3.6753 (3.8229)	grad_norm 0.3023 (0.3812)	mem 39782MB
[2023-07-07 08:34:27 RepVGG-A0] (main.py 282): INFO Train: [38/300][30/78]	eta 0:01:42 lr 6.144944	time 1.3992 (2.1332)	loss 3.5952 (3.7463)	grad_norm 0.3173 (0.3514)	mem 39782MB
[2023-07-07 08:34:44 RepVGG-A0] (main.py 282): INFO Train: [38/300][40/78]	eta 0:01:17 lr 6.143260	time 2.7191 (2.0468)	loss 3.7587 (3.7133)	grad_norm 0.4193 (0.3488)	mem 39782MB
[2023-07-07 08:35:00 RepVGG-A0] (main.py 282): INFO Train: [38/300][50/78]	eta 0:00:54 lr 6.141571	time 1.1733 (1.9424)	loss 3.5666 (3.7069)	grad_norm 0.2784 (0.3514)	mem 39782MB
[2023-07-07 08:35:14 RepVGG-A0] (main.py 282): INFO Train: [38/300][60/78]	eta 0:00:33 lr 6.139877	time 1.2932 (1.8596)	loss 3.7376 (3.6894)	grad_norm 0.4043 (0.3475)	mem 39782MB
[2023-07-07 08:35:29 RepVGG-A0] (main.py 282): INFO Train: [38/300][70/78]	eta 0:00:14 lr 6.138178	time 1.1464 (1.8039)	loss 3.4704 (3.6762)	grad_norm 0.3260 (0.3473)	mem 39782MB
[2023-07-07 08:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 38 training takes 0:02:19
[2023-07-07 08:36:00 RepVGG-A0] (main.py 282): INFO Train: [39/300][0/78]	eta 0:25:33 lr 6.136815	time 19.6613 (19.6613)	loss 3.4918 (3.4918)	grad_norm 0.3211 (0.3211)	mem 39782MB
[2023-07-07 08:36:16 RepVGG-A0] (main.py 282): INFO Train: [39/300][10/78]	eta 0:03:42 lr 6.135106	time 1.1716 (3.2767)	loss 3.9953 (3.7120)	grad_norm 0.5231 (0.4356)	mem 39782MB
[2023-07-07 08:36:32 RepVGG-A0] (main.py 282): INFO Train: [39/300][20/78]	eta 0:02:21 lr 6.133392	time 1.1832 (2.4419)	loss 3.5846 (3.7360)	grad_norm 0.2831 (0.4031)	mem 39782MB
[2023-07-07 08:36:47 RepVGG-A0] (main.py 282): INFO Train: [39/300][30/78]	eta 0:01:43 lr 6.131672	time 1.2296 (2.1507)	loss 3.5206 (3.6706)	grad_norm 0.3069 (0.3710)	mem 39782MB
[2023-07-07 08:37:05 RepVGG-A0] (main.py 282): INFO Train: [39/300][40/78]	eta 0:01:18 lr 6.129948	time 3.5234 (2.0641)	loss 3.5931 (3.6505)	grad_norm 0.3971 (0.3680)	mem 39782MB
[2023-07-07 08:37:20 RepVGG-A0] (main.py 282): INFO Train: [39/300][50/78]	eta 0:00:54 lr 6.128218	time 1.2053 (1.9581)	loss 3.4442 (3.6269)	grad_norm 0.3044 (0.3579)	mem 39782MB
[2023-07-07 08:37:35 RepVGG-A0] (main.py 282): INFO Train: [39/300][60/78]	eta 0:00:33 lr 6.126482	time 1.2703 (1.8853)	loss 3.6376 (3.6144)	grad_norm 0.4063 (0.3590)	mem 39782MB
[2023-07-07 08:37:50 RepVGG-A0] (main.py 282): INFO Train: [39/300][70/78]	eta 0:00:14 lr 6.124742	time 1.3407 (1.8282)	loss 5.9472 (3.7853)	grad_norm 0.7251 (0.4069)	mem 39782MB
[2023-07-07 08:38:02 RepVGG-A0] (main.py 291): INFO EPOCH 39 training takes 0:02:21
[2023-07-07 08:38:24 RepVGG-A0] (main.py 282): INFO Train: [40/300][0/78]	eta 0:28:14 lr 6.123345	time 21.7204 (21.7204)	loss 4.9337 (4.9337)	grad_norm 0.3385 (0.3385)	mem 39782MB
[2023-07-07 08:38:38 RepVGG-A0] (main.py 282): INFO Train: [40/300][10/78]	eta 0:03:44 lr 6.121595	time 1.1910 (3.2971)	loss 4.3582 (4.6995)	grad_norm 0.2171 (0.3292)	mem 39782MB
[2023-07-07 08:38:54 RepVGG-A0] (main.py 282): INFO Train: [40/300][20/78]	eta 0:02:23 lr 6.119840	time 1.2673 (2.4684)	loss 4.1085 (4.4683)	grad_norm 0.2960 (0.2941)	mem 39782MB
[2023-07-07 08:39:09 RepVGG-A0] (main.py 282): INFO Train: [40/300][30/78]	eta 0:01:43 lr 6.118080	time 1.2978 (2.1534)	loss 4.1354 (4.3391)	grad_norm 0.3498 (0.2936)	mem 39782MB
[2023-07-07 08:39:26 RepVGG-A0] (main.py 282): INFO Train: [40/300][40/78]	eta 0:01:18 lr 6.116314	time 4.3046 (2.0589)	loss 3.8073 (4.2333)	grad_norm 0.2709 (0.2886)	mem 39782MB
[2023-07-07 08:39:42 RepVGG-A0] (main.py 282): INFO Train: [40/300][50/78]	eta 0:00:54 lr 6.114543	time 1.1725 (1.9537)	loss 3.9021 (4.1533)	grad_norm 0.3507 (0.2931)	mem 39782MB
[2023-07-07 08:39:56 RepVGG-A0] (main.py 282): INFO Train: [40/300][60/78]	eta 0:00:33 lr 6.112766	time 1.1363 (1.8619)	loss 3.7406 (4.1013)	grad_norm 0.2797 (0.2978)	mem 39782MB
[2023-07-07 08:40:11 RepVGG-A0] (main.py 282): INFO Train: [40/300][70/78]	eta 0:00:14 lr 6.110985	time 1.2455 (1.8163)	loss 3.9145 (4.0575)	grad_norm 0.4053 (0.3037)	mem 39782MB
[2023-07-07 08:40:23 RepVGG-A0] (main.py 291): INFO EPOCH 40 training takes 0:02:20
[2023-07-07 08:40:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.974 (16.974)	Loss 3.4978 (3.4978)	Acc@1 30.176 (30.176)	Acc@5 54.333 (54.333)	Mem 39782MB
[2023-07-07 08:40:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 30.152 Acc@5 53.964
[2023-07-07 08:40:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 40: 30.152%
[2023-07-07 08:40:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 08:41:03 RepVGG-A0] (main.py 282): INFO Train: [41/300][0/78]	eta 0:28:12 lr 6.109556	time 21.6938 (21.6938)	loss 3.6116 (3.6116)	grad_norm 0.2828 (0.2828)	mem 39782MB
[2023-07-07 08:41:17 RepVGG-A0] (main.py 282): INFO Train: [41/300][10/78]	eta 0:03:43 lr 6.107765	time 1.1717 (3.2861)	loss 3.7168 (3.6753)	grad_norm 0.3373 (0.3208)	mem 39782MB
[2023-07-07 08:41:33 RepVGG-A0] (main.py 282): INFO Train: [41/300][20/78]	eta 0:02:23 lr 6.105968	time 1.1794 (2.4689)	loss 3.6606 (3.6691)	grad_norm 0.3243 (0.3212)	mem 39782MB
[2023-07-07 08:41:47 RepVGG-A0] (main.py 282): INFO Train: [41/300][30/78]	eta 0:01:42 lr 6.104167	time 1.3248 (2.1318)	loss 3.7275 (3.6972)	grad_norm 0.3527 (0.3398)	mem 39782MB
[2023-07-07 08:42:06 RepVGG-A0] (main.py 282): INFO Train: [41/300][40/78]	eta 0:01:18 lr 6.102360	time 4.8008 (2.0705)	loss 4.8204 (3.7980)	grad_norm 0.7509 (0.3882)	mem 39782MB
[2023-07-07 08:42:21 RepVGG-A0] (main.py 282): INFO Train: [41/300][50/78]	eta 0:00:54 lr 6.100548	time 1.1841 (1.9567)	loss 4.1399 (3.9476)	grad_norm 0.2980 (0.4007)	mem 39782MB
[2023-07-07 08:42:36 RepVGG-A0] (main.py 282): INFO Train: [41/300][60/78]	eta 0:00:33 lr 6.098731	time 1.2986 (1.8798)	loss 3.8634 (3.9424)	grad_norm 0.2564 (0.3769)	mem 39782MB
[2023-07-07 08:42:51 RepVGG-A0] (main.py 282): INFO Train: [41/300][70/78]	eta 0:00:14 lr 6.096908	time 1.1748 (1.8245)	loss 3.7299 (3.9221)	grad_norm 0.2968 (0.3665)	mem 39782MB
[2023-07-07 08:43:03 RepVGG-A0] (main.py 291): INFO EPOCH 41 training takes 0:02:21
[2023-07-07 08:43:23 RepVGG-A0] (main.py 282): INFO Train: [42/300][0/78]	eta 0:26:34 lr 6.095447	time 20.4454 (20.4454)	loss 3.5063 (3.5063)	grad_norm 0.2683 (0.2683)	mem 39782MB
[2023-07-07 08:43:39 RepVGG-A0] (main.py 282): INFO Train: [42/300][10/78]	eta 0:03:45 lr 6.093615	time 1.1715 (3.3122)	loss 3.5587 (3.6206)	grad_norm 0.3046 (0.3101)	mem 39782MB
[2023-07-07 08:43:54 RepVGG-A0] (main.py 282): INFO Train: [42/300][20/78]	eta 0:02:22 lr 6.091778	time 1.1829 (2.4540)	loss 3.6091 (3.6210)	grad_norm 0.3314 (0.3194)	mem 39782MB
[2023-07-07 08:44:10 RepVGG-A0] (main.py 282): INFO Train: [42/300][30/78]	eta 0:01:43 lr 6.089935	time 1.4627 (2.1537)	loss 3.7374 (3.6184)	grad_norm 0.3844 (0.3224)	mem 39782MB
[2023-07-07 08:44:27 RepVGG-A0] (main.py 282): INFO Train: [42/300][40/78]	eta 0:01:18 lr 6.088088	time 2.8600 (2.0637)	loss 3.6510 (3.6263)	grad_norm 0.3619 (0.3305)	mem 39782MB
[2023-07-07 08:44:43 RepVGG-A0] (main.py 282): INFO Train: [42/300][50/78]	eta 0:00:54 lr 6.086235	time 1.1751 (1.9586)	loss 3.6292 (3.6276)	grad_norm 0.3298 (0.3319)	mem 39782MB
[2023-07-07 08:44:59 RepVGG-A0] (main.py 282): INFO Train: [42/300][60/78]	eta 0:00:34 lr 6.084377	time 1.5688 (1.8994)	loss 3.5850 (3.6205)	grad_norm 0.3289 (0.3301)	mem 39782MB
[2023-07-07 08:45:13 RepVGG-A0] (main.py 282): INFO Train: [42/300][70/78]	eta 0:00:14 lr 6.082514	time 1.3056 (1.8323)	loss 5.3929 (3.7475)	grad_norm 0.6171 (0.3765)	mem 39782MB
[2023-07-07 08:45:25 RepVGG-A0] (main.py 291): INFO EPOCH 42 training takes 0:02:22
[2023-07-07 08:45:48 RepVGG-A0] (main.py 282): INFO Train: [43/300][0/78]	eta 0:30:00 lr 6.081020	time 23.0798 (23.0798)	loss 4.3286 (4.3286)	grad_norm 0.2995 (0.2995)	mem 39782MB
[2023-07-07 08:46:03 RepVGG-A0] (main.py 282): INFO Train: [43/300][10/78]	eta 0:03:54 lr 6.079148	time 1.1729 (3.4541)	loss 4.0765 (4.1567)	grad_norm 0.3257 (0.2908)	mem 39782MB
[2023-07-07 08:46:19 RepVGG-A0] (main.py 282): INFO Train: [43/300][20/78]	eta 0:02:30 lr 6.077270	time 1.1726 (2.5887)	loss 3.7589 (4.0139)	grad_norm 0.2543 (0.2742)	mem 39782MB
[2023-07-07 08:46:34 RepVGG-A0] (main.py 282): INFO Train: [43/300][30/78]	eta 0:01:46 lr 6.075387	time 1.1549 (2.2146)	loss 3.7240 (3.9500)	grad_norm 0.2847 (0.2890)	mem 39782MB
[2023-07-07 08:46:52 RepVGG-A0] (main.py 282): INFO Train: [43/300][40/78]	eta 0:01:20 lr 6.073499	time 4.2381 (2.1303)	loss 3.7125 (3.8763)	grad_norm 0.2838 (0.2848)	mem 39782MB
[2023-07-07 08:47:07 RepVGG-A0] (main.py 282): INFO Train: [43/300][50/78]	eta 0:00:55 lr 6.071606	time 1.1736 (1.9981)	loss 3.5745 (3.8287)	grad_norm 0.3253 (0.2884)	mem 39782MB
[2023-07-07 08:47:24 RepVGG-A0] (main.py 282): INFO Train: [43/300][60/78]	eta 0:00:34 lr 6.069708	time 1.1361 (1.9441)	loss 3.6121 (3.8008)	grad_norm 0.3038 (0.2949)	mem 39782MB
[2023-07-07 08:47:40 RepVGG-A0] (main.py 282): INFO Train: [43/300][70/78]	eta 0:00:15 lr 6.067804	time 1.3231 (1.8971)	loss 3.7072 (3.7751)	grad_norm 0.3611 (0.2987)	mem 39782MB
[2023-07-07 08:47:50 RepVGG-A0] (main.py 291): INFO EPOCH 43 training takes 0:02:24
[2023-07-07 08:48:14 RepVGG-A0] (main.py 282): INFO Train: [44/300][0/78]	eta 0:31:01 lr 6.066278	time 23.8629 (23.8629)	loss 3.5227 (3.5227)	grad_norm 0.2954 (0.2954)	mem 39782MB
[2023-07-07 08:48:29 RepVGG-A0] (main.py 282): INFO Train: [44/300][10/78]	eta 0:03:59 lr 6.064365	time 1.1992 (3.5269)	loss 3.7613 (3.6217)	grad_norm 0.4345 (0.3724)	mem 39782MB
[2023-07-07 08:48:42 RepVGG-A0] (main.py 282): INFO Train: [44/300][20/78]	eta 0:02:25 lr 6.062447	time 1.1734 (2.5106)	loss 3.5484 (3.6267)	grad_norm 0.2973 (0.3572)	mem 39782MB
[2023-07-07 08:48:59 RepVGG-A0] (main.py 282): INFO Train: [44/300][30/78]	eta 0:01:47 lr 6.060524	time 1.4398 (2.2349)	loss 3.6073 (3.6085)	grad_norm 0.3415 (0.3459)	mem 39782MB
[2023-07-07 08:49:17 RepVGG-A0] (main.py 282): INFO Train: [44/300][40/78]	eta 0:01:20 lr 6.058595	time 2.4988 (2.1252)	loss 3.5453 (3.6061)	grad_norm 0.3129 (0.3475)	mem 39782MB
[2023-07-07 08:49:32 RepVGG-A0] (main.py 282): INFO Train: [44/300][50/78]	eta 0:00:56 lr 6.056662	time 1.1777 (2.0112)	loss 3.5768 (3.5945)	grad_norm 0.3771 (0.3424)	mem 39782MB
[2023-07-07 08:49:47 RepVGG-A0] (main.py 282): INFO Train: [44/300][60/78]	eta 0:00:34 lr 6.054723	time 1.1775 (1.9255)	loss 6.1290 (3.8361)	grad_norm 0.5306 (0.4077)	mem 39782MB
[2023-07-07 08:50:02 RepVGG-A0] (main.py 282): INFO Train: [44/300][70/78]	eta 0:00:14 lr 6.052780	time 1.4106 (1.8632)	loss 5.1055 (4.0723)	grad_norm 0.2979 (0.4005)	mem 39782MB
[2023-07-07 08:50:14 RepVGG-A0] (main.py 291): INFO EPOCH 44 training takes 0:02:24
[2023-07-07 08:50:34 RepVGG-A0] (main.py 282): INFO Train: [45/300][0/78]	eta 0:26:29 lr 6.051221	time 20.3832 (20.3832)	loss 4.7975 (4.7975)	grad_norm 0.4593 (0.4593)	mem 39782MB
[2023-07-07 08:50:49 RepVGG-A0] (main.py 282): INFO Train: [45/300][10/78]	eta 0:03:38 lr 6.049268	time 1.1708 (3.2094)	loss 4.2265 (4.4621)	grad_norm 0.2622 (0.2962)	mem 39782MB
[2023-07-07 08:51:03 RepVGG-A0] (main.py 282): INFO Train: [45/300][20/78]	eta 0:02:16 lr 6.047310	time 1.1901 (2.3500)	loss 4.1881 (4.3291)	grad_norm 0.3535 (0.3022)	mem 39782MB
[2023-07-07 08:51:18 RepVGG-A0] (main.py 282): INFO Train: [45/300][30/78]	eta 0:01:39 lr 6.045346	time 1.2026 (2.0717)	loss 3.9712 (4.2224)	grad_norm 0.3194 (0.2951)	mem 39782MB
[2023-07-07 08:51:37 RepVGG-A0] (main.py 282): INFO Train: [45/300][40/78]	eta 0:01:16 lr 6.043378	time 4.4172 (2.0165)	loss 3.8310 (4.1586)	grad_norm 0.2758 (0.3002)	mem 39782MB
[2023-07-07 08:51:51 RepVGG-A0] (main.py 282): INFO Train: [45/300][50/78]	eta 0:00:53 lr 6.041405	time 1.1712 (1.9084)	loss 3.9189 (4.0998)	grad_norm 0.3430 (0.3055)	mem 39782MB
[2023-07-07 08:52:07 RepVGG-A0] (main.py 282): INFO Train: [45/300][60/78]	eta 0:00:33 lr 6.039426	time 1.2628 (1.8501)	loss 4.3567 (4.0729)	grad_norm 0.6054 (0.3205)	mem 39782MB
[2023-07-07 08:52:22 RepVGG-A0] (main.py 282): INFO Train: [45/300][70/78]	eta 0:00:14 lr 6.037442	time 1.2322 (1.8035)	loss 3.9627 (4.1067)	grad_norm 0.2760 (0.3360)	mem 39782MB
[2023-07-07 08:52:34 RepVGG-A0] (main.py 291): INFO EPOCH 45 training takes 0:02:19
[2023-07-07 08:52:55 RepVGG-A0] (main.py 282): INFO Train: [46/300][0/78]	eta 0:27:17 lr 6.035851	time 20.9950 (20.9950)	loss 3.7283 (3.7283)	grad_norm 0.2596 (0.2596)	mem 39782MB
[2023-07-07 08:53:10 RepVGG-A0] (main.py 282): INFO Train: [46/300][10/78]	eta 0:03:45 lr 6.033858	time 1.1725 (3.3162)	loss 3.7876 (3.7364)	grad_norm 0.3166 (0.2873)	mem 39782MB
[2023-07-07 08:53:26 RepVGG-A0] (main.py 282): INFO Train: [46/300][20/78]	eta 0:02:22 lr 6.031860	time 1.3013 (2.4574)	loss 3.7199 (3.7441)	grad_norm 0.2918 (0.3043)	mem 39782MB
[2023-07-07 08:53:42 RepVGG-A0] (main.py 282): INFO Train: [46/300][30/78]	eta 0:01:45 lr 6.029857	time 1.6494 (2.1986)	loss 3.8914 (3.7405)	grad_norm 0.3898 (0.3162)	mem 39782MB
[2023-07-07 08:54:00 RepVGG-A0] (main.py 282): INFO Train: [46/300][40/78]	eta 0:01:19 lr 6.027849	time 3.3070 (2.0876)	loss 3.7461 (3.7379)	grad_norm 0.3323 (0.3213)	mem 39782MB
[2023-07-07 08:54:14 RepVGG-A0] (main.py 282): INFO Train: [46/300][50/78]	eta 0:00:55 lr 6.025836	time 1.1726 (1.9660)	loss 3.6723 (3.7232)	grad_norm 0.3697 (0.3247)	mem 39782MB
[2023-07-07 08:54:29 RepVGG-A0] (main.py 282): INFO Train: [46/300][60/78]	eta 0:00:33 lr 6.023817	time 1.3046 (1.8816)	loss 3.7370 (3.7333)	grad_norm 0.3131 (0.3347)	mem 39782MB
[2023-07-07 08:54:45 RepVGG-A0] (main.py 282): INFO Train: [46/300][70/78]	eta 0:00:14 lr 6.021794	time 1.3337 (1.8424)	loss 3.9215 (3.7314)	grad_norm 0.4250 (0.3374)	mem 39782MB
[2023-07-07 08:54:56 RepVGG-A0] (main.py 291): INFO EPOCH 46 training takes 0:02:22
[2023-07-07 08:55:19 RepVGG-A0] (main.py 282): INFO Train: [47/300][0/78]	eta 0:28:52 lr 6.020171	time 22.2071 (22.2071)	loss 3.4764 (3.4764)	grad_norm 0.2796 (0.2796)	mem 39782MB
[2023-07-07 08:55:32 RepVGG-A0] (main.py 282): INFO Train: [47/300][10/78]	eta 0:03:39 lr 6.018138	time 1.1894 (3.2330)	loss 3.6030 (3.6011)	grad_norm 0.3517 (0.3406)	mem 39782MB
[2023-07-07 08:55:48 RepVGG-A0] (main.py 282): INFO Train: [47/300][20/78]	eta 0:02:22 lr 6.016101	time 1.1827 (2.4512)	loss 3.6408 (3.6087)	grad_norm 0.3655 (0.3468)	mem 39782MB
[2023-07-07 08:56:02 RepVGG-A0] (main.py 282): INFO Train: [47/300][30/78]	eta 0:01:41 lr 6.014058	time 1.3511 (2.1177)	loss 3.9855 (3.6284)	grad_norm 0.5037 (0.3573)	mem 39782MB
[2023-07-07 08:56:20 RepVGG-A0] (main.py 282): INFO Train: [47/300][40/78]	eta 0:01:17 lr 6.012010	time 3.6267 (2.0357)	loss 3.6896 (3.7128)	grad_norm 0.2925 (0.3810)	mem 39782MB
[2023-07-07 08:56:34 RepVGG-A0] (main.py 282): INFO Train: [47/300][50/78]	eta 0:00:53 lr 6.009957	time 1.1715 (1.9174)	loss 3.7267 (3.6986)	grad_norm 0.4113 (0.3637)	mem 39782MB
[2023-07-07 08:56:49 RepVGG-A0] (main.py 282): INFO Train: [47/300][60/78]	eta 0:00:33 lr 6.007899	time 1.1742 (1.8515)	loss 3.5614 (3.6929)	grad_norm 0.2575 (0.3587)	mem 39782MB
[2023-07-07 08:57:05 RepVGG-A0] (main.py 282): INFO Train: [47/300][70/78]	eta 0:00:14 lr 6.005836	time 1.4493 (1.8037)	loss 3.6879 (3.6777)	grad_norm 0.3760 (0.3543)	mem 39782MB
[2023-07-07 08:57:16 RepVGG-A0] (main.py 291): INFO EPOCH 47 training takes 0:02:19
[2023-07-07 08:57:38 RepVGG-A0] (main.py 282): INFO Train: [48/300][0/78]	eta 0:27:32 lr 6.004181	time 21.1923 (21.1923)	loss 3.5870 (3.5870)	grad_norm 0.3321 (0.3321)	mem 39782MB
[2023-07-07 08:57:52 RepVGG-A0] (main.py 282): INFO Train: [48/300][10/78]	eta 0:03:41 lr 6.002109	time 1.1727 (3.2567)	loss 3.5520 (3.5467)	grad_norm 0.3679 (0.3627)	mem 39782MB
[2023-07-07 08:58:07 RepVGG-A0] (main.py 282): INFO Train: [48/300][20/78]	eta 0:02:20 lr 6.000032	time 1.1738 (2.4253)	loss 3.5564 (3.5553)	grad_norm 0.3330 (0.3525)	mem 39782MB
[2023-07-07 08:58:23 RepVGG-A0] (main.py 282): INFO Train: [48/300][30/78]	eta 0:01:42 lr 5.997950	time 1.7245 (2.1366)	loss 3.4623 (3.5441)	grad_norm 0.3271 (0.3473)	mem 39782MB
[2023-07-07 08:58:41 RepVGG-A0] (main.py 282): INFO Train: [48/300][40/78]	eta 0:01:18 lr 5.995862	time 4.1591 (2.0712)	loss 6.0869 (3.6850)	grad_norm 1.0851 (0.4075)	mem 39782MB
[2023-07-07 08:58:55 RepVGG-A0] (main.py 282): INFO Train: [48/300][50/78]	eta 0:00:54 lr 5.993770	time 1.1713 (1.9392)	loss 5.4142 (4.1322)	grad_norm 0.3712 (0.4201)	mem 39782MB
[2023-07-07 08:59:11 RepVGG-A0] (main.py 282): INFO Train: [48/300][60/78]	eta 0:00:33 lr 5.991672	time 1.4013 (1.8776)	loss 4.7021 (4.2759)	grad_norm 0.2745 (0.4012)	mem 39782MB
[2023-07-07 08:59:26 RepVGG-A0] (main.py 282): INFO Train: [48/300][70/78]	eta 0:00:14 lr 5.989570	time 1.2263 (1.8232)	loss 4.3374 (4.3081)	grad_norm 0.2977 (0.3865)	mem 39782MB
[2023-07-07 08:59:37 RepVGG-A0] (main.py 291): INFO EPOCH 48 training takes 0:02:20
[2023-07-07 08:59:58 RepVGG-A0] (main.py 282): INFO Train: [49/300][0/78]	eta 0:27:34 lr 5.987884	time 21.2064 (21.2064)	loss 4.0975 (4.0975)	grad_norm 0.3038 (0.3038)	mem 39782MB
[2023-07-07 09:00:13 RepVGG-A0] (main.py 282): INFO Train: [49/300][10/78]	eta 0:03:42 lr 5.985773	time 1.1726 (3.2689)	loss 4.1579 (4.0506)	grad_norm 0.4388 (0.3053)	mem 39782MB
[2023-07-07 09:00:28 RepVGG-A0] (main.py 282): INFO Train: [49/300][20/78]	eta 0:02:21 lr 5.983656	time 1.2049 (2.4421)	loss 3.9196 (4.0891)	grad_norm 0.2403 (0.3206)	mem 39782MB
[2023-07-07 09:00:44 RepVGG-A0] (main.py 282): INFO Train: [49/300][30/78]	eta 0:01:43 lr 5.981535	time 1.5325 (2.1642)	loss 3.8960 (4.0198)	grad_norm 0.3422 (0.3050)	mem 39782MB
[2023-07-07 09:01:02 RepVGG-A0] (main.py 282): INFO Train: [49/300][40/78]	eta 0:01:19 lr 5.979408	time 2.7602 (2.0820)	loss 3.8687 (3.9797)	grad_norm 0.3663 (0.3073)	mem 39782MB
[2023-07-07 09:01:17 RepVGG-A0] (main.py 282): INFO Train: [49/300][50/78]	eta 0:00:54 lr 5.977276	time 1.2178 (1.9632)	loss 3.6756 (3.9472)	grad_norm 0.2899 (0.3088)	mem 39782MB
[2023-07-07 09:01:32 RepVGG-A0] (main.py 282): INFO Train: [49/300][60/78]	eta 0:00:34 lr 5.975140	time 1.2962 (1.8909)	loss 3.9588 (3.9264)	grad_norm 0.4693 (0.3180)	mem 39782MB
[2023-07-07 09:01:47 RepVGG-A0] (main.py 282): INFO Train: [49/300][70/78]	eta 0:00:14 lr 5.972998	time 1.1787 (1.8245)	loss 4.0822 (3.9690)	grad_norm 0.3394 (0.3382)	mem 39782MB
[2023-07-07 09:01:59 RepVGG-A0] (main.py 291): INFO EPOCH 49 training takes 0:02:21
[2023-07-07 09:02:20 RepVGG-A0] (main.py 282): INFO Train: [50/300][0/78]	eta 0:26:57 lr 5.971281	time 20.7329 (20.7329)	loss 3.6973 (3.6973)	grad_norm 0.2950 (0.2950)	mem 39782MB
[2023-07-07 09:02:35 RepVGG-A0] (main.py 282): INFO Train: [50/300][10/78]	eta 0:03:42 lr 5.969131	time 1.1918 (3.2739)	loss 3.6303 (3.7197)	grad_norm 0.2737 (0.2964)	mem 39782MB
[2023-07-07 09:02:50 RepVGG-A0] (main.py 282): INFO Train: [50/300][20/78]	eta 0:02:21 lr 5.966975	time 1.4602 (2.4473)	loss 3.6863 (3.7037)	grad_norm 0.3660 (0.3141)	mem 39782MB
[2023-07-07 09:03:06 RepVGG-A0] (main.py 282): INFO Train: [50/300][30/78]	eta 0:01:44 lr 5.964815	time 2.0669 (2.1810)	loss 3.7136 (3.7020)	grad_norm 0.3405 (0.3242)	mem 39782MB
[2023-07-07 09:03:23 RepVGG-A0] (main.py 282): INFO Train: [50/300][40/78]	eta 0:01:18 lr 5.962649	time 2.4865 (2.0542)	loss 3.6266 (3.6867)	grad_norm 0.3403 (0.3205)	mem 39782MB
[2023-07-07 09:03:37 RepVGG-A0] (main.py 282): INFO Train: [50/300][50/78]	eta 0:00:53 lr 5.960478	time 1.1911 (1.9219)	loss 3.8240 (3.7221)	grad_norm 0.3356 (0.3412)	mem 39782MB
[2023-07-07 09:03:53 RepVGG-A0] (main.py 282): INFO Train: [50/300][60/78]	eta 0:00:33 lr 5.958303	time 1.1980 (1.8677)	loss 3.6452 (3.7093)	grad_norm 0.3280 (0.3350)	mem 39782MB
[2023-07-07 09:04:07 RepVGG-A0] (main.py 282): INFO Train: [50/300][70/78]	eta 0:00:14 lr 5.956122	time 1.1499 (1.8055)	loss 3.6767 (3.7018)	grad_norm 0.3263 (0.3350)	mem 39782MB
[2023-07-07 09:04:19 RepVGG-A0] (main.py 291): INFO EPOCH 50 training takes 0:02:20
[2023-07-07 09:04:40 RepVGG-A0] (main.py 282): INFO Train: [51/300][0/78]	eta 0:26:53 lr 5.954374	time 20.6868 (20.6868)	loss 3.6319 (3.6319)	grad_norm 0.3777 (0.3777)	mem 39782MB
[2023-07-07 09:04:54 RepVGG-A0] (main.py 282): INFO Train: [51/300][10/78]	eta 0:03:37 lr 5.952185	time 1.1712 (3.1931)	loss 3.6431 (3.6623)	grad_norm 0.3116 (0.3741)	mem 39782MB
[2023-07-07 09:05:09 RepVGG-A0] (main.py 282): INFO Train: [51/300][20/78]	eta 0:02:18 lr 5.949991	time 1.1753 (2.3959)	loss 3.5454 (3.6459)	grad_norm 0.3179 (0.3613)	mem 39782MB
[2023-07-07 09:05:25 RepVGG-A0] (main.py 282): INFO Train: [51/300][30/78]	eta 0:01:42 lr 5.947791	time 1.6048 (2.1269)	loss 3.5743 (3.6321)	grad_norm 0.3729 (0.3550)	mem 39782MB
[2023-07-07 09:05:43 RepVGG-A0] (main.py 282): INFO Train: [51/300][40/78]	eta 0:01:17 lr 5.945587	time 3.9004 (2.0398)	loss 3.6311 (3.6298)	grad_norm 0.3457 (0.3568)	mem 39782MB
[2023-07-07 09:05:57 RepVGG-A0] (main.py 282): INFO Train: [51/300][50/78]	eta 0:00:54 lr 5.943378	time 1.1714 (1.9286)	loss 3.6455 (3.6277)	grad_norm 0.3412 (0.3562)	mem 39782MB
[2023-07-07 09:06:13 RepVGG-A0] (main.py 282): INFO Train: [51/300][60/78]	eta 0:00:33 lr 5.941164	time 1.5677 (1.8641)	loss 6.0753 (3.8140)	grad_norm 0.5566 (0.4047)	mem 39782MB
[2023-07-07 09:06:27 RepVGG-A0] (main.py 282): INFO Train: [51/300][70/78]	eta 0:00:14 lr 5.938944	time 1.1476 (1.8032)	loss 5.2862 (4.0850)	grad_norm 0.2728 (0.4118)	mem 39782MB
[2023-07-07 09:06:39 RepVGG-A0] (main.py 291): INFO EPOCH 51 training takes 0:02:19
[2023-07-07 09:07:00 RepVGG-A0] (main.py 282): INFO Train: [52/300][0/78]	eta 0:27:32 lr 5.937166	time 21.1914 (21.1914)	loss 4.7314 (4.7314)	grad_norm 0.3029 (0.3029)	mem 39782MB
[2023-07-07 09:07:15 RepVGG-A0] (main.py 282): INFO Train: [52/300][10/78]	eta 0:03:42 lr 5.934938	time 1.1725 (3.2756)	loss 4.3843 (4.5165)	grad_norm 0.3327 (0.2876)	mem 39782MB
[2023-07-07 09:07:29 RepVGG-A0] (main.py 282): INFO Train: [52/300][20/78]	eta 0:02:18 lr 5.932705	time 1.1734 (2.3956)	loss 4.1621 (4.3935)	grad_norm 0.3075 (0.2900)	mem 39782MB
[2023-07-07 09:07:44 RepVGG-A0] (main.py 282): INFO Train: [52/300][30/78]	eta 0:01:41 lr 5.930467	time 1.2465 (2.1122)	loss 4.0868 (4.3126)	grad_norm 0.2978 (0.2967)	mem 39782MB
[2023-07-07 09:08:03 RepVGG-A0] (main.py 282): INFO Train: [52/300][40/78]	eta 0:01:17 lr 5.928224	time 3.6372 (2.0475)	loss 3.9138 (4.2329)	grad_norm 0.2919 (0.2976)	mem 39782MB
[2023-07-07 09:08:18 RepVGG-A0] (main.py 282): INFO Train: [52/300][50/78]	eta 0:00:54 lr 5.925976	time 1.1756 (1.9457)	loss 3.9642 (4.1745)	grad_norm 0.3220 (0.2993)	mem 39782MB
[2023-07-07 09:08:33 RepVGG-A0] (main.py 282): INFO Train: [52/300][60/78]	eta 0:00:33 lr 5.923724	time 1.2385 (1.8769)	loss 3.9311 (4.1370)	grad_norm 0.3542 (0.3089)	mem 39782MB
[2023-07-07 09:08:48 RepVGG-A0] (main.py 282): INFO Train: [52/300][70/78]	eta 0:00:14 lr 5.921466	time 1.2320 (1.8183)	loss 4.4970 (4.1037)	grad_norm 0.7432 (0.3164)	mem 39782MB
[2023-07-07 09:09:01 RepVGG-A0] (main.py 291): INFO EPOCH 52 training takes 0:02:21
[2023-07-07 09:09:21 RepVGG-A0] (main.py 282): INFO Train: [53/300][0/78]	eta 0:26:11 lr 5.919657	time 20.1537 (20.1537)	loss 5.0745 (5.0745)	grad_norm 0.4777 (0.4777)	mem 39782MB
[2023-07-07 09:09:36 RepVGG-A0] (main.py 282): INFO Train: [53/300][10/78]	eta 0:03:40 lr 5.917390	time 1.1708 (3.2377)	loss 4.2574 (4.4981)	grad_norm 0.3043 (0.3298)	mem 39782MB
[2023-07-07 09:09:50 RepVGG-A0] (main.py 282): INFO Train: [53/300][20/78]	eta 0:02:17 lr 5.915119	time 1.1709 (2.3687)	loss 3.9903 (4.3030)	grad_norm 0.2308 (0.3019)	mem 39782MB
[2023-07-07 09:10:06 RepVGG-A0] (main.py 282): INFO Train: [53/300][30/78]	eta 0:01:40 lr 5.912843	time 1.3792 (2.1017)	loss 3.9815 (4.1707)	grad_norm 0.3032 (0.2942)	mem 39782MB
[2023-07-07 09:10:24 RepVGG-A0] (main.py 282): INFO Train: [53/300][40/78]	eta 0:01:16 lr 5.910562	time 3.7812 (2.0231)	loss 3.7714 (4.0792)	grad_norm 0.2973 (0.2907)	mem 39782MB
[2023-07-07 09:10:39 RepVGG-A0] (main.py 282): INFO Train: [53/300][50/78]	eta 0:00:53 lr 5.908276	time 1.1755 (1.9241)	loss 3.7991 (4.0221)	grad_norm 0.3332 (0.2959)	mem 39782MB
[2023-07-07 09:10:54 RepVGG-A0] (main.py 282): INFO Train: [53/300][60/78]	eta 0:00:33 lr 5.905985	time 1.2771 (1.8517)	loss 3.7000 (3.9890)	grad_norm 0.2992 (0.3058)	mem 39782MB
[2023-07-07 09:11:08 RepVGG-A0] (main.py 282): INFO Train: [53/300][70/78]	eta 0:00:14 lr 5.903689	time 1.2129 (1.7981)	loss 3.6811 (3.9504)	grad_norm 0.3184 (0.3045)	mem 39782MB
[2023-07-07 09:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 53 training takes 0:02:19
[2023-07-07 09:11:41 RepVGG-A0] (main.py 282): INFO Train: [54/300][0/78]	eta 0:27:29 lr 5.901849	time 21.1441 (21.1441)	loss 3.8025 (3.8025)	grad_norm 0.4143 (0.4143)	mem 39782MB
[2023-07-07 09:11:57 RepVGG-A0] (main.py 282): INFO Train: [54/300][10/78]	eta 0:03:47 lr 5.899545	time 1.1708 (3.3498)	loss 3.6839 (3.9358)	grad_norm 0.2811 (0.4191)	mem 39782MB
[2023-07-07 09:12:12 RepVGG-A0] (main.py 282): INFO Train: [54/300][20/78]	eta 0:02:23 lr 5.897236	time 1.1859 (2.4685)	loss 3.6088 (3.8119)	grad_norm 0.3360 (0.3612)	mem 39782MB
[2023-07-07 09:12:28 RepVGG-A0] (main.py 282): INFO Train: [54/300][30/78]	eta 0:01:44 lr 5.894921	time 1.5596 (2.1833)	loss 3.8120 (3.7821)	grad_norm 0.3742 (0.3560)	mem 39782MB
[2023-07-07 09:12:45 RepVGG-A0] (main.py 282): INFO Train: [54/300][40/78]	eta 0:01:19 lr 5.892602	time 2.8656 (2.0815)	loss 3.5951 (3.7496)	grad_norm 0.3055 (0.3458)	mem 39782MB
[2023-07-07 09:13:00 RepVGG-A0] (main.py 282): INFO Train: [54/300][50/78]	eta 0:00:54 lr 5.890278	time 1.1724 (1.9640)	loss 3.6493 (3.7356)	grad_norm 0.3613 (0.3470)	mem 39782MB
[2023-07-07 09:13:16 RepVGG-A0] (main.py 282): INFO Train: [54/300][60/78]	eta 0:00:34 lr 5.887950	time 1.4144 (1.8992)	loss 4.1409 (3.7327)	grad_norm 0.5986 (0.3528)	mem 39782MB
[2023-07-07 09:13:31 RepVGG-A0] (main.py 282): INFO Train: [54/300][70/78]	eta 0:00:14 lr 5.885616	time 1.3115 (1.8418)	loss 3.7759 (3.7821)	grad_norm 0.2966 (0.3676)	mem 39782MB
[2023-07-07 09:13:42 RepVGG-A0] (main.py 291): INFO EPOCH 54 training takes 0:02:22
[2023-07-07 09:14:04 RepVGG-A0] (main.py 282): INFO Train: [55/300][0/78]	eta 0:29:00 lr 5.883746	time 22.3114 (22.3114)	loss 3.6958 (3.6958)	grad_norm 0.3142 (0.3142)	mem 39782MB
[2023-07-07 09:14:18 RepVGG-A0] (main.py 282): INFO Train: [55/300][10/78]	eta 0:03:44 lr 5.881404	time 1.1698 (3.3007)	loss 3.5397 (3.6677)	grad_norm 0.2664 (0.3141)	mem 39782MB
[2023-07-07 09:14:32 RepVGG-A0] (main.py 282): INFO Train: [55/300][20/78]	eta 0:02:18 lr 5.879056	time 1.1913 (2.3941)	loss 3.6862 (3.6434)	grad_norm 0.3742 (0.3193)	mem 39782MB
[2023-07-07 09:14:48 RepVGG-A0] (main.py 282): INFO Train: [55/300][30/78]	eta 0:01:41 lr 5.876704	time 1.4837 (2.1165)	loss 3.5361 (3.6358)	grad_norm 0.3462 (0.3244)	mem 39782MB
[2023-07-07 09:15:05 RepVGG-A0] (main.py 282): INFO Train: [55/300][40/78]	eta 0:01:16 lr 5.874348	time 3.4878 (2.0186)	loss 3.7044 (3.6216)	grad_norm 0.4316 (0.3270)	mem 39782MB
[2023-07-07 09:15:22 RepVGG-A0] (main.py 282): INFO Train: [55/300][50/78]	eta 0:00:54 lr 5.871986	time 1.2093 (1.9539)	loss 3.6764 (3.6330)	grad_norm 0.3439 (0.3371)	mem 39782MB
[2023-07-07 09:15:37 RepVGG-A0] (main.py 282): INFO Train: [55/300][60/78]	eta 0:00:33 lr 5.869620	time 1.3287 (1.8833)	loss 3.6024 (3.6301)	grad_norm 0.3490 (0.3377)	mem 39782MB
[2023-07-07 09:15:52 RepVGG-A0] (main.py 282): INFO Train: [55/300][70/78]	eta 0:00:14 lr 5.867248	time 1.1498 (1.8281)	loss 4.2654 (3.6774)	grad_norm 0.5416 (0.3622)	mem 39782MB
[2023-07-07 09:16:03 RepVGG-A0] (main.py 291): INFO EPOCH 55 training takes 0:02:20
[2023-07-07 09:16:24 RepVGG-A0] (main.py 282): INFO Train: [56/300][0/78]	eta 0:27:26 lr 5.865348	time 21.1127 (21.1127)	loss 3.6263 (3.6263)	grad_norm 0.2869 (0.2869)	mem 39782MB
[2023-07-07 09:16:40 RepVGG-A0] (main.py 282): INFO Train: [56/300][10/78]	eta 0:03:47 lr 5.862968	time 1.1699 (3.3524)	loss 3.5708 (3.5974)	grad_norm 0.2982 (0.2909)	mem 39782MB
[2023-07-07 09:16:54 RepVGG-A0] (main.py 282): INFO Train: [56/300][20/78]	eta 0:02:21 lr 5.860583	time 1.3321 (2.4379)	loss 3.6174 (3.5753)	grad_norm 0.3235 (0.3030)	mem 39782MB
[2023-07-07 09:17:10 RepVGG-A0] (main.py 282): INFO Train: [56/300][30/78]	eta 0:01:42 lr 5.858194	time 1.2050 (2.1457)	loss 3.5617 (3.5608)	grad_norm 0.3312 (0.3073)	mem 39782MB
[2023-07-07 09:17:27 RepVGG-A0] (main.py 282): INFO Train: [56/300][40/78]	eta 0:01:18 lr 5.855800	time 2.9988 (2.0528)	loss 3.6173 (3.5562)	grad_norm 0.3846 (0.3146)	mem 39782MB
[2023-07-07 09:17:43 RepVGG-A0] (main.py 282): INFO Train: [56/300][50/78]	eta 0:00:54 lr 5.853401	time 1.1965 (1.9538)	loss 4.2837 (3.6294)	grad_norm 0.6707 (0.3569)	mem 39782MB
[2023-07-07 09:17:59 RepVGG-A0] (main.py 282): INFO Train: [56/300][60/78]	eta 0:00:34 lr 5.850997	time 1.4346 (1.8968)	loss 3.8064 (3.7233)	grad_norm 0.2702 (0.3711)	mem 39782MB
[2023-07-07 09:18:14 RepVGG-A0] (main.py 282): INFO Train: [56/300][70/78]	eta 0:00:14 lr 5.848588	time 1.1498 (1.8392)	loss 3.6276 (3.7214)	grad_norm 0.3020 (0.3574)	mem 39782MB
[2023-07-07 09:18:24 RepVGG-A0] (main.py 291): INFO EPOCH 56 training takes 0:02:21
[2023-07-07 09:18:46 RepVGG-A0] (main.py 282): INFO Train: [57/300][0/78]	eta 0:27:54 lr 5.846658	time 21.4710 (21.4710)	loss 3.4788 (3.4788)	grad_norm 0.2411 (0.2411)	mem 39782MB
[2023-07-07 09:19:00 RepVGG-A0] (main.py 282): INFO Train: [57/300][10/78]	eta 0:03:36 lr 5.844241	time 1.1720 (3.1881)	loss 3.4972 (3.5026)	grad_norm 0.3036 (0.2740)	mem 39782MB
[2023-07-07 09:19:15 RepVGG-A0] (main.py 282): INFO Train: [57/300][20/78]	eta 0:02:18 lr 5.841819	time 1.1916 (2.3900)	loss 3.6486 (3.5174)	grad_norm 0.3639 (0.3037)	mem 39782MB
[2023-07-07 09:19:31 RepVGG-A0] (main.py 282): INFO Train: [57/300][30/78]	eta 0:01:42 lr 5.839392	time 1.5062 (2.1366)	loss 3.5511 (3.5327)	grad_norm 0.3151 (0.3156)	mem 39782MB
[2023-07-07 09:19:48 RepVGG-A0] (main.py 282): INFO Train: [57/300][40/78]	eta 0:01:17 lr 5.836960	time 2.1467 (2.0354)	loss 3.5161 (3.5234)	grad_norm 0.3532 (0.3159)	mem 39782MB
[2023-07-07 09:20:03 RepVGG-A0] (main.py 282): INFO Train: [57/300][50/78]	eta 0:00:54 lr 5.834524	time 1.1723 (1.9339)	loss 3.5350 (3.5283)	grad_norm 0.3171 (0.3222)	mem 39782MB
[2023-07-07 09:20:19 RepVGG-A0] (main.py 282): INFO Train: [57/300][60/78]	eta 0:00:33 lr 5.832083	time 1.2750 (1.8691)	loss 3.7432 (3.5408)	grad_norm 0.4287 (0.3322)	mem 39782MB
[2023-07-07 09:20:35 RepVGG-A0] (main.py 282): INFO Train: [57/300][70/78]	eta 0:00:14 lr 5.829637	time 1.4224 (1.8336)	loss 3.5647 (3.5514)	grad_norm 0.3394 (0.3365)	mem 39782MB
[2023-07-07 09:20:46 RepVGG-A0] (main.py 291): INFO EPOCH 57 training takes 0:02:21
[2023-07-07 09:21:07 RepVGG-A0] (main.py 282): INFO Train: [58/300][0/78]	eta 0:28:08 lr 5.827677	time 21.6420 (21.6420)	loss 3.4557 (3.4557)	grad_norm 0.3257 (0.3257)	mem 39782MB
[2023-07-07 09:21:22 RepVGG-A0] (main.py 282): INFO Train: [58/300][10/78]	eta 0:03:41 lr 5.825223	time 1.2014 (3.2638)	loss 3.5910 (3.4553)	grad_norm 0.4379 (0.3458)	mem 39782MB
[2023-07-07 09:21:37 RepVGG-A0] (main.py 282): INFO Train: [58/300][20/78]	eta 0:02:21 lr 5.822764	time 1.1726 (2.4372)	loss 5.7764 (3.9870)	grad_norm 0.8552 (0.5332)	mem 39782MB
[2023-07-07 09:21:51 RepVGG-A0] (main.py 282): INFO Train: [58/300][30/78]	eta 0:01:41 lr 5.820300	time 1.1648 (2.1163)	loss 4.2845 (4.2559)	grad_norm 0.2507 (0.4912)	mem 39782MB
[2023-07-07 09:22:09 RepVGG-A0] (main.py 282): INFO Train: [58/300][40/78]	eta 0:01:17 lr 5.817832	time 4.0957 (2.0417)	loss 3.9015 (4.2286)	grad_norm 0.2199 (0.4393)	mem 39782MB
[2023-07-07 09:22:24 RepVGG-A0] (main.py 282): INFO Train: [58/300][50/78]	eta 0:00:54 lr 5.815359	time 1.1741 (1.9352)	loss 3.8199 (4.1513)	grad_norm 0.2943 (0.4105)	mem 39782MB
[2023-07-07 09:22:40 RepVGG-A0] (main.py 282): INFO Train: [58/300][60/78]	eta 0:00:33 lr 5.812881	time 1.4969 (1.8800)	loss 3.7278 (4.0789)	grad_norm 0.2548 (0.3863)	mem 39782MB
[2023-07-07 09:22:56 RepVGG-A0] (main.py 282): INFO Train: [58/300][70/78]	eta 0:00:14 lr 5.810398	time 1.3276 (1.8300)	loss 3.5753 (4.0209)	grad_norm 0.2529 (0.3735)	mem 39782MB
[2023-07-07 09:23:07 RepVGG-A0] (main.py 291): INFO EPOCH 58 training takes 0:02:21
[2023-07-07 09:23:27 RepVGG-A0] (main.py 282): INFO Train: [59/300][0/78]	eta 0:26:35 lr 5.808409	time 20.4496 (20.4496)	loss 3.6501 (3.6501)	grad_norm 0.4193 (0.4193)	mem 39782MB
[2023-07-07 09:23:43 RepVGG-A0] (main.py 282): INFO Train: [59/300][10/78]	eta 0:03:41 lr 5.805918	time 1.1927 (3.2517)	loss 3.5204 (3.5895)	grad_norm 0.2791 (0.3217)	mem 39782MB
[2023-07-07 09:23:58 RepVGG-A0] (main.py 282): INFO Train: [59/300][20/78]	eta 0:02:21 lr 5.803422	time 1.1738 (2.4395)	loss 3.6124 (3.5857)	grad_norm 0.3507 (0.3272)	mem 39782MB
[2023-07-07 09:24:14 RepVGG-A0] (main.py 282): INFO Train: [59/300][30/78]	eta 0:01:44 lr 5.800922	time 1.6031 (2.1682)	loss 3.5532 (3.5941)	grad_norm 0.2843 (0.3336)	mem 39782MB
[2023-07-07 09:24:32 RepVGG-A0] (main.py 282): INFO Train: [59/300][40/78]	eta 0:01:19 lr 5.798417	time 3.4233 (2.0898)	loss 3.5430 (3.5838)	grad_norm 0.3075 (0.3316)	mem 39782MB
[2023-07-07 09:24:47 RepVGG-A0] (main.py 282): INFO Train: [59/300][50/78]	eta 0:00:55 lr 5.795907	time 1.1762 (1.9732)	loss 3.5892 (3.5750)	grad_norm 0.3520 (0.3340)	mem 39782MB
[2023-07-07 09:25:02 RepVGG-A0] (main.py 282): INFO Train: [59/300][60/78]	eta 0:00:34 lr 5.793392	time 1.2413 (1.8954)	loss 3.6606 (3.5795)	grad_norm 0.3667 (0.3382)	mem 39782MB
[2023-07-07 09:25:18 RepVGG-A0] (main.py 282): INFO Train: [59/300][70/78]	eta 0:00:14 lr 5.790873	time 1.4878 (1.8540)	loss 3.4267 (3.5735)	grad_norm 0.2880 (0.3382)	mem 39782MB
[2023-07-07 09:25:29 RepVGG-A0] (main.py 291): INFO EPOCH 59 training takes 0:02:22
[2023-07-07 09:25:51 RepVGG-A0] (main.py 282): INFO Train: [60/300][0/78]	eta 0:28:33 lr 5.788854	time 21.9620 (21.9620)	loss 3.4850 (3.4850)	grad_norm 0.3800 (0.3800)	mem 39782MB
[2023-07-07 09:26:05 RepVGG-A0] (main.py 282): INFO Train: [60/300][10/78]	eta 0:03:41 lr 5.786327	time 1.1731 (3.2602)	loss 3.7375 (3.7595)	grad_norm 0.4371 (0.4711)	mem 39782MB
[2023-07-07 09:26:20 RepVGG-A0] (main.py 282): INFO Train: [60/300][20/78]	eta 0:02:19 lr 5.783795	time 1.1730 (2.4103)	loss 3.4692 (3.6642)	grad_norm 0.3213 (0.3947)	mem 39782MB
[2023-07-07 09:26:35 RepVGG-A0] (main.py 282): INFO Train: [60/300][30/78]	eta 0:01:41 lr 5.781258	time 1.1855 (2.1131)	loss 3.4050 (3.6044)	grad_norm 0.2783 (0.3676)	mem 39782MB
[2023-07-07 09:26:54 RepVGG-A0] (main.py 282): INFO Train: [60/300][40/78]	eta 0:01:18 lr 5.778716	time 4.8058 (2.0587)	loss 3.5608 (3.5733)	grad_norm 0.3812 (0.3604)	mem 39782MB
[2023-07-07 09:27:09 RepVGG-A0] (main.py 282): INFO Train: [60/300][50/78]	eta 0:00:54 lr 5.776170	time 1.3136 (1.9496)	loss 3.5211 (3.5926)	grad_norm 0.3176 (0.3683)	mem 39782MB
[2023-07-07 09:27:23 RepVGG-A0] (main.py 282): INFO Train: [60/300][60/78]	eta 0:00:33 lr 5.773619	time 1.1749 (1.8631)	loss 3.4574 (3.5702)	grad_norm 0.3014 (0.3571)	mem 39782MB
[2023-07-07 09:27:38 RepVGG-A0] (main.py 282): INFO Train: [60/300][70/78]	eta 0:00:14 lr 5.771064	time 1.3719 (1.8171)	loss 4.6611 (3.6179)	grad_norm 0.9074 (0.3854)	mem 39782MB
[2023-07-07 09:27:50 RepVGG-A0] (main.py 291): INFO EPOCH 60 training takes 0:02:21
[2023-07-07 09:28:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.434 (17.434)	Loss 9.5352 (9.5352)	Acc@1 1.117 (1.117)	Acc@5 4.065 (4.065)	Mem 39782MB
[2023-07-07 09:28:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 1.154 Acc@5 3.944
[2023-07-07 09:28:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 60: 1.154%
[2023-07-07 09:28:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 09:28:31 RepVGG-A0] (main.py 282): INFO Train: [61/300][0/78]	eta 0:28:34 lr 5.769016	time 21.9806 (21.9806)	loss 4.4532 (4.4532)	grad_norm 0.3837 (0.3837)	mem 39782MB
[2023-07-07 09:28:48 RepVGG-A0] (main.py 282): INFO Train: [61/300][10/78]	eta 0:04:00 lr 5.766452	time 1.1775 (3.5355)	loss 3.8223 (4.0707)	grad_norm 0.2932 (0.3212)	mem 39782MB
[2023-07-07 09:29:02 RepVGG-A0] (main.py 282): INFO Train: [61/300][20/78]	eta 0:02:26 lr 5.763884	time 1.1745 (2.5242)	loss 3.6397 (3.9057)	grad_norm 0.2410 (0.3010)	mem 39782MB
[2023-07-07 09:29:17 RepVGG-A0] (main.py 282): INFO Train: [61/300][30/78]	eta 0:01:44 lr 5.761311	time 1.4154 (2.1849)	loss 3.6104 (3.8000)	grad_norm 0.2852 (0.2923)	mem 39782MB
[2023-07-07 09:29:34 RepVGG-A0] (main.py 282): INFO Train: [61/300][40/78]	eta 0:01:18 lr 5.758733	time 3.1492 (2.0714)	loss 3.4690 (3.7230)	grad_norm 0.3038 (0.2913)	mem 39782MB
[2023-07-07 09:29:49 RepVGG-A0] (main.py 282): INFO Train: [61/300][50/78]	eta 0:00:54 lr 5.756151	time 1.2177 (1.9583)	loss 3.4658 (3.6825)	grad_norm 0.3334 (0.2957)	mem 39782MB
[2023-07-07 09:30:05 RepVGG-A0] (main.py 282): INFO Train: [61/300][60/78]	eta 0:00:34 lr 5.753564	time 1.3308 (1.8947)	loss 3.4509 (3.6508)	grad_norm 0.2989 (0.2962)	mem 39782MB
[2023-07-07 09:30:20 RepVGG-A0] (main.py 282): INFO Train: [61/300][70/78]	eta 0:00:14 lr 5.750972	time 1.2130 (1.8455)	loss 3.6124 (3.6343)	grad_norm 0.4232 (0.3059)	mem 39782MB
[2023-07-07 09:30:31 RepVGG-A0] (main.py 291): INFO EPOCH 61 training takes 0:02:22
[2023-07-07 09:30:52 RepVGG-A0] (main.py 282): INFO Train: [62/300][0/78]	eta 0:26:51 lr 5.748896	time 20.6643 (20.6643)	loss 3.5028 (3.5028)	grad_norm 0.3303 (0.3303)	mem 39782MB
[2023-07-07 09:31:06 RepVGG-A0] (main.py 282): INFO Train: [62/300][10/78]	eta 0:03:31 lr 5.746296	time 1.1732 (3.1157)	loss 3.3730 (3.4288)	grad_norm 0.3172 (0.3186)	mem 39782MB
[2023-07-07 09:31:21 RepVGG-A0] (main.py 282): INFO Train: [62/300][20/78]	eta 0:02:17 lr 5.743692	time 1.2821 (2.3733)	loss 3.5024 (3.4345)	grad_norm 0.3536 (0.3274)	mem 39782MB
[2023-07-07 09:31:37 RepVGG-A0] (main.py 282): INFO Train: [62/300][30/78]	eta 0:01:41 lr 5.741083	time 1.1795 (2.1202)	loss 3.6205 (3.4664)	grad_norm 0.4112 (0.3466)	mem 39782MB
[2023-07-07 09:31:55 RepVGG-A0] (main.py 282): INFO Train: [62/300][40/78]	eta 0:01:17 lr 5.738469	time 4.0029 (2.0281)	loss 3.5894 (3.5588)	grad_norm 0.3568 (0.3771)	mem 39782MB
[2023-07-07 09:32:10 RepVGG-A0] (main.py 282): INFO Train: [62/300][50/78]	eta 0:00:53 lr 5.735851	time 1.1717 (1.9280)	loss 3.4417 (3.5505)	grad_norm 0.2826 (0.3600)	mem 39782MB
[2023-07-07 09:32:25 RepVGG-A0] (main.py 282): INFO Train: [62/300][60/78]	eta 0:00:33 lr 5.733228	time 1.3074 (1.8587)	loss 3.4384 (3.5363)	grad_norm 0.3257 (0.3530)	mem 39782MB
[2023-07-07 09:32:40 RepVGG-A0] (main.py 282): INFO Train: [62/300][70/78]	eta 0:00:14 lr 5.730601	time 1.2885 (1.8073)	loss 3.5212 (3.5311)	grad_norm 0.3370 (0.3522)	mem 39782MB
[2023-07-07 09:32:52 RepVGG-A0] (main.py 291): INFO EPOCH 62 training takes 0:02:20
[2023-07-07 09:33:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][0/78]	eta 0:28:28 lr 5.728496	time 21.9098 (21.9098)	loss 3.3748 (3.3748)	grad_norm 0.3240 (0.3240)	mem 39782MB
[2023-07-07 09:33:28 RepVGG-A0] (main.py 282): INFO Train: [63/300][10/78]	eta 0:03:41 lr 5.725861	time 1.1733 (3.2589)	loss 3.5465 (3.4132)	grad_norm 0.4217 (0.3436)	mem 39782MB
[2023-07-07 09:33:42 RepVGG-A0] (main.py 282): INFO Train: [63/300][20/78]	eta 0:02:18 lr 5.723221	time 1.4798 (2.3886)	loss 5.2235 (3.9073)	grad_norm 0.7453 (0.5193)	mem 39782MB
[2023-07-07 09:33:57 RepVGG-A0] (main.py 282): INFO Train: [63/300][30/78]	eta 0:01:40 lr 5.720576	time 1.4746 (2.0939)	loss 4.1186 (4.1627)	grad_norm 0.2767 (0.4875)	mem 39782MB
[2023-07-07 09:34:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][40/78]	eta 0:01:15 lr 5.717927	time 3.0426 (1.9986)	loss 3.8667 (4.1191)	grad_norm 0.2881 (0.4358)	mem 39782MB
[2023-07-07 09:34:29 RepVGG-A0] (main.py 282): INFO Train: [63/300][50/78]	eta 0:00:53 lr 5.715273	time 1.3437 (1.9172)	loss 3.7182 (4.0461)	grad_norm 0.3010 (0.4041)	mem 39782MB
[2023-07-07 09:34:45 RepVGG-A0] (main.py 282): INFO Train: [63/300][60/78]	eta 0:00:33 lr 5.712615	time 1.1729 (1.8535)	loss 3.5375 (3.9785)	grad_norm 0.2600 (0.3830)	mem 39782MB
[2023-07-07 09:35:00 RepVGG-A0] (main.py 282): INFO Train: [63/300][70/78]	eta 0:00:14 lr 5.709952	time 1.3312 (1.8116)	loss 3.5339 (3.9158)	grad_norm 0.3287 (0.3677)	mem 39782MB
[2023-07-07 09:35:12 RepVGG-A0] (main.py 291): INFO EPOCH 63 training takes 0:02:19
[2023-07-07 09:35:33 RepVGG-A0] (main.py 282): INFO Train: [64/300][0/78]	eta 0:27:52 lr 5.707819	time 21.4420 (21.4420)	loss 3.4547 (3.4547)	grad_norm 0.3458 (0.3458)	mem 39782MB
[2023-07-07 09:35:49 RepVGG-A0] (main.py 282): INFO Train: [64/300][10/78]	eta 0:03:49 lr 5.705148	time 1.1710 (3.3802)	loss 3.4422 (3.4730)	grad_norm 0.2726 (0.3107)	mem 39782MB
[2023-07-07 09:36:05 RepVGG-A0] (main.py 282): INFO Train: [64/300][20/78]	eta 0:02:26 lr 5.702473	time 1.4039 (2.5220)	loss 3.6167 (3.4623)	grad_norm 0.4396 (0.3233)	mem 39782MB
[2023-07-07 09:36:20 RepVGG-A0] (main.py 282): INFO Train: [64/300][30/78]	eta 0:01:45 lr 5.699793	time 1.5735 (2.1957)	loss 3.5165 (3.5087)	grad_norm 0.2986 (0.3359)	mem 39782MB
[2023-07-07 09:36:38 RepVGG-A0] (main.py 282): INFO Train: [64/300][40/78]	eta 0:01:19 lr 5.697109	time 2.0475 (2.0948)	loss 3.5354 (3.4995)	grad_norm 0.3475 (0.3318)	mem 39782MB
[2023-07-07 09:36:53 RepVGG-A0] (main.py 282): INFO Train: [64/300][50/78]	eta 0:00:55 lr 5.694420	time 1.1751 (1.9853)	loss 3.5160 (3.4873)	grad_norm 0.3971 (0.3264)	mem 39782MB
[2023-07-07 09:37:07 RepVGG-A0] (main.py 282): INFO Train: [64/300][60/78]	eta 0:00:34 lr 5.691726	time 1.1753 (1.8924)	loss 3.5681 (3.5167)	grad_norm 0.3464 (0.3421)	mem 39782MB
[2023-07-07 09:37:22 RepVGG-A0] (main.py 282): INFO Train: [64/300][70/78]	eta 0:00:14 lr 5.689029	time 1.2917 (1.8355)	loss 3.4934 (3.5124)	grad_norm 0.3460 (0.3384)	mem 39782MB
[2023-07-07 09:37:34 RepVGG-A0] (main.py 291): INFO EPOCH 64 training takes 0:02:22
[2023-07-07 09:37:55 RepVGG-A0] (main.py 282): INFO Train: [65/300][0/78]	eta 0:27:27 lr 5.686867	time 21.1184 (21.1184)	loss 3.3887 (3.3887)	grad_norm 0.3390 (0.3390)	mem 39782MB
[2023-07-07 09:38:09 RepVGG-A0] (main.py 282): INFO Train: [65/300][10/78]	eta 0:03:39 lr 5.684161	time 1.1738 (3.2206)	loss 3.4033 (3.4609)	grad_norm 0.3396 (0.3593)	mem 39782MB
[2023-07-07 09:38:25 RepVGG-A0] (main.py 282): INFO Train: [65/300][20/78]	eta 0:02:21 lr 5.681451	time 1.1853 (2.4477)	loss 3.4742 (3.4304)	grad_norm 0.3700 (0.3420)	mem 39782MB
[2023-07-07 09:38:40 RepVGG-A0] (main.py 282): INFO Train: [65/300][30/78]	eta 0:01:43 lr 5.678736	time 1.5526 (2.1526)	loss 3.4687 (3.4553)	grad_norm 0.3616 (0.3542)	mem 39782MB
[2023-07-07 09:38:58 RepVGG-A0] (main.py 282): INFO Train: [65/300][40/78]	eta 0:01:17 lr 5.676017	time 3.4856 (2.0508)	loss 3.5366 (3.4452)	grad_norm 0.4233 (0.3501)	mem 39782MB
[2023-07-07 09:39:13 RepVGG-A0] (main.py 282): INFO Train: [65/300][50/78]	eta 0:00:54 lr 5.673293	time 1.1731 (1.9459)	loss 4.7621 (3.6219)	grad_norm 0.6230 (0.4151)	mem 39782MB
[2023-07-07 09:39:28 RepVGG-A0] (main.py 282): INFO Train: [65/300][60/78]	eta 0:00:33 lr 5.670564	time 1.2094 (1.8709)	loss 4.1912 (3.7875)	grad_norm 0.3560 (0.4301)	mem 39782MB
[2023-07-07 09:39:43 RepVGG-A0] (main.py 282): INFO Train: [65/300][70/78]	eta 0:00:14 lr 5.667832	time 1.2441 (1.8161)	loss 3.8689 (3.8097)	grad_norm 0.3073 (0.4077)	mem 39782MB
[2023-07-07 09:39:55 RepVGG-A0] (main.py 291): INFO EPOCH 65 training takes 0:02:21
[2023-07-07 09:40:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][0/78]	eta 0:26:56 lr 5.665642	time 20.7297 (20.7297)	loss 3.6359 (3.6359)	grad_norm 0.2577 (0.2577)	mem 39782MB
[2023-07-07 09:40:30 RepVGG-A0] (main.py 282): INFO Train: [66/300][10/78]	eta 0:03:33 lr 5.662902	time 1.1918 (3.1357)	loss 3.5169 (3.5706)	grad_norm 0.2528 (0.2668)	mem 39782MB
[2023-07-07 09:40:44 RepVGG-A0] (main.py 282): INFO Train: [66/300][20/78]	eta 0:02:14 lr 5.660156	time 1.1917 (2.3189)	loss 3.5464 (3.5332)	grad_norm 0.2966 (0.2720)	mem 39782MB
[2023-07-07 09:40:59 RepVGG-A0] (main.py 282): INFO Train: [66/300][30/78]	eta 0:01:38 lr 5.657407	time 1.1758 (2.0422)	loss 3.4621 (3.5103)	grad_norm 0.3068 (0.2793)	mem 39782MB
[2023-07-07 09:41:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][40/78]	eta 0:01:14 lr 5.654653	time 3.3767 (1.9696)	loss 3.4277 (3.5045)	grad_norm 0.2734 (0.2895)	mem 39782MB
[2023-07-07 09:41:32 RepVGG-A0] (main.py 282): INFO Train: [66/300][50/78]	eta 0:00:52 lr 5.651894	time 2.1488 (1.8912)	loss 3.4960 (3.4902)	grad_norm 0.3489 (0.2950)	mem 39782MB
[2023-07-07 09:41:47 RepVGG-A0] (main.py 282): INFO Train: [66/300][60/78]	eta 0:00:32 lr 5.649132	time 1.1779 (1.8264)	loss 5.2996 (3.6577)	grad_norm 0.5786 (0.3609)	mem 39782MB
[2023-07-07 09:42:02 RepVGG-A0] (main.py 282): INFO Train: [66/300][70/78]	eta 0:00:14 lr 5.646364	time 1.2629 (1.7899)	loss 4.4442 (3.8175)	grad_norm 0.3216 (0.3730)	mem 39782MB
[2023-07-07 09:42:15 RepVGG-A0] (main.py 291): INFO EPOCH 66 training takes 0:02:19
[2023-07-07 09:42:36 RepVGG-A0] (main.py 282): INFO Train: [67/300][0/78]	eta 0:27:41 lr 5.644147	time 21.3057 (21.3057)	loss 4.0132 (4.0132)	grad_norm 0.2578 (0.2578)	mem 39782MB
[2023-07-07 09:42:50 RepVGG-A0] (main.py 282): INFO Train: [67/300][10/78]	eta 0:03:40 lr 5.641372	time 1.1918 (3.2422)	loss 3.7613 (3.8614)	grad_norm 0.2625 (0.2836)	mem 39782MB
[2023-07-07 09:43:04 RepVGG-A0] (main.py 282): INFO Train: [67/300][20/78]	eta 0:02:16 lr 5.638592	time 1.1718 (2.3550)	loss 3.6938 (3.7892)	grad_norm 0.2765 (0.2761)	mem 39782MB
[2023-07-07 09:43:19 RepVGG-A0] (main.py 282): INFO Train: [67/300][30/78]	eta 0:01:39 lr 5.635808	time 1.1798 (2.0730)	loss 3.5072 (3.7394)	grad_norm 0.2977 (0.2811)	mem 39782MB
[2023-07-07 09:43:37 RepVGG-A0] (main.py 282): INFO Train: [67/300][40/78]	eta 0:01:16 lr 5.633020	time 3.3792 (2.0123)	loss 3.4789 (3.7143)	grad_norm 0.2655 (0.2931)	mem 39782MB
[2023-07-07 09:43:53 RepVGG-A0] (main.py 282): INFO Train: [67/300][50/78]	eta 0:00:53 lr 5.630227	time 1.1733 (1.9265)	loss 3.5927 (3.6840)	grad_norm 0.3324 (0.2952)	mem 39782MB
[2023-07-07 09:44:07 RepVGG-A0] (main.py 282): INFO Train: [67/300][60/78]	eta 0:00:33 lr 5.627430	time 1.3084 (1.8492)	loss 3.7100 (3.6672)	grad_norm 0.3992 (0.3004)	mem 39782MB
[2023-07-07 09:44:23 RepVGG-A0] (main.py 282): INFO Train: [67/300][70/78]	eta 0:00:14 lr 5.624629	time 1.5171 (1.8084)	loss 3.6139 (3.6565)	grad_norm 0.3790 (0.3068)	mem 39782MB
[2023-07-07 09:44:35 RepVGG-A0] (main.py 291): INFO EPOCH 67 training takes 0:02:20
[2023-07-07 09:44:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][0/78]	eta 0:27:58 lr 5.622384	time 21.5182 (21.5182)	loss 3.4300 (3.4300)	grad_norm 0.2924 (0.2924)	mem 39782MB
[2023-07-07 09:45:10 RepVGG-A0] (main.py 282): INFO Train: [68/300][10/78]	eta 0:03:37 lr 5.619575	time 1.1721 (3.1930)	loss 3.4571 (3.4962)	grad_norm 0.3247 (0.3421)	mem 39782MB
[2023-07-07 09:45:25 RepVGG-A0] (main.py 282): INFO Train: [68/300][20/78]	eta 0:02:18 lr 5.616761	time 1.1733 (2.3960)	loss 3.4308 (3.4757)	grad_norm 0.3365 (0.3351)	mem 39782MB
[2023-07-07 09:45:40 RepVGG-A0] (main.py 282): INFO Train: [68/300][30/78]	eta 0:01:41 lr 5.613943	time 1.1519 (2.1165)	loss 3.5352 (3.4764)	grad_norm 0.3669 (0.3429)	mem 39782MB
[2023-07-07 09:45:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][40/78]	eta 0:01:15 lr 5.611120	time 2.0786 (1.9920)	loss 3.3927 (3.4884)	grad_norm 0.3171 (0.3462)	mem 39782MB
[2023-07-07 09:46:13 RepVGG-A0] (main.py 282): INFO Train: [68/300][50/78]	eta 0:00:54 lr 5.608294	time 1.1730 (1.9353)	loss 3.5904 (3.4984)	grad_norm 0.3760 (0.3501)	mem 39782MB
[2023-07-07 09:46:29 RepVGG-A0] (main.py 282): INFO Train: [68/300][60/78]	eta 0:00:33 lr 5.605462	time 1.3225 (1.8661)	loss 3.5546 (3.5051)	grad_norm 0.3654 (0.3540)	mem 39782MB
[2023-07-07 09:46:44 RepVGG-A0] (main.py 282): INFO Train: [68/300][70/78]	eta 0:00:14 lr 5.602627	time 1.1782 (1.8197)	loss 3.5974 (3.5026)	grad_norm 0.3921 (0.3495)	mem 39782MB
[2023-07-07 09:46:56 RepVGG-A0] (main.py 291): INFO EPOCH 68 training takes 0:02:20
[2023-07-07 09:47:17 RepVGG-A0] (main.py 282): INFO Train: [69/300][0/78]	eta 0:28:14 lr 5.600355	time 21.7201 (21.7201)	loss 3.5079 (3.5079)	grad_norm 0.4097 (0.4097)	mem 39782MB
[2023-07-07 09:47:32 RepVGG-A0] (main.py 282): INFO Train: [69/300][10/78]	eta 0:03:45 lr 5.597512	time 1.1708 (3.3100)	loss 3.4917 (3.5363)	grad_norm 0.3140 (0.3957)	mem 39782MB
[2023-07-07 09:47:46 RepVGG-A0] (main.py 282): INFO Train: [69/300][20/78]	eta 0:02:19 lr 5.594665	time 1.2086 (2.4120)	loss 3.4021 (3.4969)	grad_norm 0.3201 (0.3725)	mem 39782MB
[2023-07-07 09:48:02 RepVGG-A0] (main.py 282): INFO Train: [69/300][30/78]	eta 0:01:42 lr 5.591813	time 1.3206 (2.1322)	loss 3.4219 (3.4600)	grad_norm 0.3596 (0.3596)	mem 39782MB
[2023-07-07 09:48:20 RepVGG-A0] (main.py 282): INFO Train: [69/300][40/78]	eta 0:01:17 lr 5.588956	time 3.6813 (2.0505)	loss 3.5842 (3.4626)	grad_norm 0.4635 (0.3623)	mem 39782MB
[2023-07-07 09:48:35 RepVGG-A0] (main.py 282): INFO Train: [69/300][50/78]	eta 0:00:54 lr 5.586096	time 1.1723 (1.9506)	loss 6.2167 (3.7753)	grad_norm 0.6966 (0.4551)	mem 39782MB
[2023-07-07 09:48:50 RepVGG-A0] (main.py 282): INFO Train: [69/300][60/78]	eta 0:00:33 lr 5.583231	time 1.4235 (1.8756)	loss 5.0818 (4.0682)	grad_norm 0.3042 (0.4439)	mem 39782MB
[2023-07-07 09:49:05 RepVGG-A0] (main.py 282): INFO Train: [69/300][70/78]	eta 0:00:14 lr 5.580362	time 1.1940 (1.8221)	loss 4.4957 (4.1545)	grad_norm 0.3020 (0.4236)	mem 39782MB
[2023-07-07 09:49:17 RepVGG-A0] (main.py 291): INFO EPOCH 69 training takes 0:02:21
[2023-07-07 09:49:39 RepVGG-A0] (main.py 282): INFO Train: [70/300][0/78]	eta 0:28:37 lr 5.578063	time 22.0232 (22.0232)	loss 4.1076 (4.1076)	grad_norm 0.2419 (0.2419)	mem 39782MB
[2023-07-07 09:49:53 RepVGG-A0] (main.py 282): INFO Train: [70/300][10/78]	eta 0:03:41 lr 5.575187	time 1.1718 (3.2631)	loss 4.0918 (4.0858)	grad_norm 0.3224 (0.2928)	mem 39782MB
[2023-07-07 09:50:09 RepVGG-A0] (main.py 282): INFO Train: [70/300][20/78]	eta 0:02:23 lr 5.572305	time 1.3017 (2.4684)	loss 3.8524 (4.0136)	grad_norm 0.2858 (0.2949)	mem 39782MB
[2023-07-07 09:50:24 RepVGG-A0] (main.py 282): INFO Train: [70/300][30/78]	eta 0:01:44 lr 5.569420	time 1.1827 (2.1702)	loss 3.6784 (3.9377)	grad_norm 0.2641 (0.2913)	mem 39782MB
[2023-07-07 09:50:41 RepVGG-A0] (main.py 282): INFO Train: [70/300][40/78]	eta 0:01:18 lr 5.566530	time 3.0365 (2.0605)	loss 3.8475 (3.9108)	grad_norm 0.3403 (0.3055)	mem 39782MB
[2023-07-07 09:50:56 RepVGG-A0] (main.py 282): INFO Train: [70/300][50/78]	eta 0:00:54 lr 5.563636	time 1.1738 (1.9410)	loss 3.7121 (3.8728)	grad_norm 0.2810 (0.3034)	mem 39782MB
[2023-07-07 09:51:11 RepVGG-A0] (main.py 282): INFO Train: [70/300][60/78]	eta 0:00:33 lr 5.560738	time 1.1580 (1.8714)	loss 3.8569 (3.8462)	grad_norm 0.4148 (0.3113)	mem 39782MB
[2023-07-07 09:51:25 RepVGG-A0] (main.py 282): INFO Train: [70/300][70/78]	eta 0:00:14 lr 5.557836	time 1.1708 (1.7993)	loss 3.6187 (3.8274)	grad_norm 0.2909 (0.3134)	mem 39782MB
[2023-07-07 09:51:36 RepVGG-A0] (main.py 291): INFO EPOCH 70 training takes 0:02:19
[2023-07-07 09:51:58 RepVGG-A0] (main.py 282): INFO Train: [71/300][0/78]	eta 0:28:20 lr 5.555511	time 21.8007 (21.8007)	loss 3.4622 (3.4622)	grad_norm 0.2949 (0.2949)	mem 39782MB
[2023-07-07 09:52:12 RepVGG-A0] (main.py 282): INFO Train: [71/300][10/78]	eta 0:03:42 lr 5.552601	time 1.1732 (3.2653)	loss 3.5930 (3.6623)	grad_norm 0.2917 (0.3733)	mem 39782MB
[2023-07-07 09:52:26 RepVGG-A0] (main.py 282): INFO Train: [71/300][20/78]	eta 0:02:17 lr 5.549686	time 1.1719 (2.3624)	loss 3.5018 (3.6006)	grad_norm 0.2888 (0.3414)	mem 39782MB
[2023-07-07 09:52:42 RepVGG-A0] (main.py 282): INFO Train: [71/300][30/78]	eta 0:01:41 lr 5.546768	time 1.3658 (2.1076)	loss 3.5744 (3.5951)	grad_norm 0.3619 (0.3468)	mem 39782MB
[2023-07-07 09:53:00 RepVGG-A0] (main.py 282): INFO Train: [71/300][40/78]	eta 0:01:17 lr 5.543845	time 4.2995 (2.0356)	loss 3.5555 (3.5775)	grad_norm 0.3471 (0.3410)	mem 39782MB
[2023-07-07 09:53:15 RepVGG-A0] (main.py 282): INFO Train: [71/300][50/78]	eta 0:00:53 lr 5.540918	time 1.1724 (1.9240)	loss 3.7108 (3.6451)	grad_norm 0.3041 (0.3686)	mem 39782MB
[2023-07-07 09:53:29 RepVGG-A0] (main.py 282): INFO Train: [71/300][60/78]	eta 0:00:33 lr 5.537986	time 1.2292 (1.8527)	loss 3.6029 (3.6423)	grad_norm 0.3630 (0.3598)	mem 39782MB
[2023-07-07 09:53:45 RepVGG-A0] (main.py 282): INFO Train: [71/300][70/78]	eta 0:00:14 lr 5.535051	time 1.2881 (1.8039)	loss 3.5602 (3.6251)	grad_norm 0.3185 (0.3501)	mem 39782MB
[2023-07-07 09:53:56 RepVGG-A0] (main.py 291): INFO EPOCH 71 training takes 0:02:20
[2023-07-07 09:54:18 RepVGG-A0] (main.py 282): INFO Train: [72/300][0/78]	eta 0:28:05 lr 5.532700	time 21.6086 (21.6086)	loss 3.3723 (3.3723)	grad_norm 0.2911 (0.2911)	mem 39782MB
[2023-07-07 09:54:32 RepVGG-A0] (main.py 282): INFO Train: [72/300][10/78]	eta 0:03:42 lr 5.529757	time 1.1727 (3.2684)	loss 3.4542 (3.4323)	grad_norm 0.3112 (0.3135)	mem 39782MB
[2023-07-07 09:54:48 RepVGG-A0] (main.py 282): INFO Train: [72/300][20/78]	eta 0:02:22 lr 5.526809	time 1.2347 (2.4515)	loss 3.5763 (3.5078)	grad_norm 0.3500 (0.3556)	mem 39782MB
[2023-07-07 09:55:04 RepVGG-A0] (main.py 282): INFO Train: [72/300][30/78]	eta 0:01:44 lr 5.523858	time 1.9725 (2.1805)	loss 3.4994 (3.5006)	grad_norm 0.3324 (0.3452)	mem 39782MB
[2023-07-07 09:55:21 RepVGG-A0] (main.py 282): INFO Train: [72/300][40/78]	eta 0:01:18 lr 5.520902	time 4.0223 (2.0560)	loss 3.5793 (3.5067)	grad_norm 0.3531 (0.3500)	mem 39782MB
[2023-07-07 09:55:36 RepVGG-A0] (main.py 282): INFO Train: [72/300][50/78]	eta 0:00:54 lr 5.517942	time 1.1717 (1.9456)	loss 3.3441 (3.4975)	grad_norm 0.3320 (0.3453)	mem 39782MB
[2023-07-07 09:55:50 RepVGG-A0] (main.py 282): INFO Train: [72/300][60/78]	eta 0:00:33 lr 5.514978	time 1.1437 (1.8672)	loss 3.5559 (3.4967)	grad_norm 0.4239 (0.3478)	mem 39782MB
[2023-07-07 09:56:06 RepVGG-A0] (main.py 282): INFO Train: [72/300][70/78]	eta 0:00:14 lr 5.512010	time 1.6384 (1.8271)	loss 5.5962 (3.6381)	grad_norm 0.8740 (0.4036)	mem 39782MB
[2023-07-07 09:56:18 RepVGG-A0] (main.py 291): INFO EPOCH 72 training takes 0:02:21
[2023-07-07 09:56:39 RepVGG-A0] (main.py 282): INFO Train: [73/300][0/78]	eta 0:28:13 lr 5.509633	time 21.7100 (21.7100)	loss 4.7708 (4.7708)	grad_norm 0.3197 (0.3197)	mem 39782MB
[2023-07-07 09:56:54 RepVGG-A0] (main.py 282): INFO Train: [73/300][10/78]	eta 0:03:44 lr 5.506657	time 1.1901 (3.3080)	loss 4.1242 (4.3686)	grad_norm 0.2373 (0.2861)	mem 39782MB
[2023-07-07 09:57:09 RepVGG-A0] (main.py 282): INFO Train: [73/300][20/78]	eta 0:02:21 lr 5.503677	time 1.2936 (2.4353)	loss 3.9431 (4.2287)	grad_norm 0.2448 (0.3022)	mem 39782MB
[2023-07-07 09:57:24 RepVGG-A0] (main.py 282): INFO Train: [73/300][30/78]	eta 0:01:42 lr 5.500693	time 1.2432 (2.1310)	loss 3.7145 (4.0925)	grad_norm 0.2543 (0.2828)	mem 39782MB
[2023-07-07 09:57:42 RepVGG-A0] (main.py 282): INFO Train: [73/300][40/78]	eta 0:01:18 lr 5.497705	time 3.8242 (2.0550)	loss 3.6752 (3.9942)	grad_norm 0.2672 (0.2799)	mem 39782MB
[2023-07-07 09:57:57 RepVGG-A0] (main.py 282): INFO Train: [73/300][50/78]	eta 0:00:54 lr 5.494713	time 1.1728 (1.9431)	loss 3.6363 (3.9225)	grad_norm 0.3221 (0.2826)	mem 39782MB
[2023-07-07 09:58:12 RepVGG-A0] (main.py 282): INFO Train: [73/300][60/78]	eta 0:00:33 lr 5.491716	time 1.3980 (1.8680)	loss 3.6081 (3.8706)	grad_norm 0.2941 (0.2880)	mem 39782MB
[2023-07-07 09:58:26 RepVGG-A0] (main.py 282): INFO Train: [73/300][70/78]	eta 0:00:14 lr 5.488716	time 1.1702 (1.8095)	loss 3.6133 (3.8275)	grad_norm 0.3572 (0.2900)	mem 39782MB
[2023-07-07 09:58:38 RepVGG-A0] (main.py 291): INFO EPOCH 73 training takes 0:02:20
[2023-07-07 09:59:00 RepVGG-A0] (main.py 282): INFO Train: [74/300][0/78]	eta 0:27:52 lr 5.486313	time 21.4397 (21.4397)	loss 3.5518 (3.5518)	grad_norm 0.3862 (0.3862)	mem 39782MB
[2023-07-07 09:59:15 RepVGG-A0] (main.py 282): INFO Train: [74/300][10/78]	eta 0:03:48 lr 5.483305	time 1.1707 (3.3531)	loss 3.4381 (3.5309)	grad_norm 0.2935 (0.3335)	mem 39782MB
[2023-07-07 09:59:30 RepVGG-A0] (main.py 282): INFO Train: [74/300][20/78]	eta 0:02:22 lr 5.480293	time 1.1752 (2.4568)	loss 3.6249 (3.5329)	grad_norm 0.3946 (0.3368)	mem 39782MB
[2023-07-07 09:59:46 RepVGG-A0] (main.py 282): INFO Train: [74/300][30/78]	eta 0:01:44 lr 5.477276	time 1.2345 (2.1725)	loss 3.4426 (3.5303)	grad_norm 0.2881 (0.3353)	mem 39782MB
[2023-07-07 10:00:04 RepVGG-A0] (main.py 282): INFO Train: [74/300][40/78]	eta 0:01:19 lr 5.474256	time 4.0084 (2.0869)	loss 3.4999 (3.5242)	grad_norm 0.3264 (0.3352)	mem 39782MB
[2023-07-07 10:00:18 RepVGG-A0] (main.py 282): INFO Train: [74/300][50/78]	eta 0:00:54 lr 5.471232	time 1.1730 (1.9589)	loss 3.5565 (3.5246)	grad_norm 0.3907 (0.3412)	mem 39782MB
[2023-07-07 10:00:34 RepVGG-A0] (main.py 282): INFO Train: [74/300][60/78]	eta 0:00:33 lr 5.468203	time 1.1432 (1.8867)	loss 3.4858 (3.5238)	grad_norm 0.3227 (0.3421)	mem 39782MB
[2023-07-07 10:00:50 RepVGG-A0] (main.py 282): INFO Train: [74/300][70/78]	eta 0:00:14 lr 5.465171	time 1.5255 (1.8537)	loss 3.7625 (3.5270)	grad_norm 0.4644 (0.3466)	mem 39782MB
[2023-07-07 10:01:01 RepVGG-A0] (main.py 291): INFO EPOCH 74 training takes 0:02:22
[2023-07-07 10:01:22 RepVGG-A0] (main.py 282): INFO Train: [75/300][0/78]	eta 0:26:53 lr 5.462742	time 20.6883 (20.6883)	loss 3.4362 (3.4362)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 10:01:36 RepVGG-A0] (main.py 282): INFO Train: [75/300][10/78]	eta 0:03:38 lr 5.459702	time 1.1725 (3.2141)	loss 3.5643 (3.4841)	grad_norm 0.3977 (0.3616)	mem 39782MB
[2023-07-07 10:01:51 RepVGG-A0] (main.py 282): INFO Train: [75/300][20/78]	eta 0:02:17 lr 5.456658	time 1.1707 (2.3769)	loss 3.4216 (3.4567)	grad_norm 0.3402 (0.3409)	mem 39782MB
[2023-07-07 10:02:07 RepVGG-A0] (main.py 282): INFO Train: [75/300][30/78]	eta 0:01:41 lr 5.453610	time 1.2852 (2.1105)	loss 3.6742 (3.4974)	grad_norm 0.4109 (0.3673)	mem 39782MB
[2023-07-07 10:02:24 RepVGG-A0] (main.py 282): INFO Train: [75/300][40/78]	eta 0:01:16 lr 5.450558	time 2.7837 (2.0143)	loss 3.3829 (3.4926)	grad_norm 0.2769 (0.3562)	mem 39782MB
[2023-07-07 10:02:41 RepVGG-A0] (main.py 282): INFO Train: [75/300][50/78]	eta 0:00:54 lr 5.447501	time 1.1997 (1.9627)	loss 3.5629 (3.4904)	grad_norm 0.3503 (0.3551)	mem 39782MB
[2023-07-07 10:02:57 RepVGG-A0] (main.py 282): INFO Train: [75/300][60/78]	eta 0:00:34 lr 5.444441	time 1.2527 (1.8950)	loss 3.4235 (3.4770)	grad_norm 0.3656 (0.3504)	mem 39782MB
[2023-07-07 10:03:12 RepVGG-A0] (main.py 282): INFO Train: [75/300][70/78]	eta 0:00:14 lr 5.441377	time 1.1721 (1.8438)	loss 3.5169 (3.5079)	grad_norm 0.3341 (0.3662)	mem 39782MB
[2023-07-07 10:03:23 RepVGG-A0] (main.py 291): INFO EPOCH 75 training takes 0:02:21
[2023-07-07 10:03:44 RepVGG-A0] (main.py 282): INFO Train: [76/300][0/78]	eta 0:27:52 lr 5.438923	time 21.4378 (21.4378)	loss 3.3510 (3.3510)	grad_norm 0.2974 (0.2974)	mem 39782MB
[2023-07-07 10:04:01 RepVGG-A0] (main.py 282): INFO Train: [76/300][10/78]	eta 0:03:53 lr 5.435851	time 1.1982 (3.4310)	loss 3.3631 (3.4147)	grad_norm 0.3213 (0.3309)	mem 39782MB
[2023-07-07 10:04:15 RepVGG-A0] (main.py 282): INFO Train: [76/300][20/78]	eta 0:02:22 lr 5.432776	time 1.3132 (2.4607)	loss 3.3717 (3.3935)	grad_norm 0.3448 (0.3281)	mem 39782MB
[2023-07-07 10:04:30 RepVGG-A0] (main.py 282): INFO Train: [76/300][30/78]	eta 0:01:43 lr 5.429696	time 1.6664 (2.1609)	loss 3.5521 (3.4296)	grad_norm 0.4127 (0.3527)	mem 39782MB
[2023-07-07 10:04:47 RepVGG-A0] (main.py 282): INFO Train: [76/300][40/78]	eta 0:01:18 lr 5.426612	time 3.6093 (2.0621)	loss 3.3935 (3.4311)	grad_norm 0.3175 (0.3496)	mem 39782MB
[2023-07-07 10:05:02 RepVGG-A0] (main.py 282): INFO Train: [76/300][50/78]	eta 0:00:54 lr 5.423525	time 1.1723 (1.9460)	loss 3.4829 (3.4302)	grad_norm 0.3627 (0.3508)	mem 39782MB
[2023-07-07 10:05:18 RepVGG-A0] (main.py 282): INFO Train: [76/300][60/78]	eta 0:00:33 lr 5.420433	time 1.1612 (1.8820)	loss 3.4655 (3.4261)	grad_norm 0.3779 (0.3503)	mem 39782MB
[2023-07-07 10:05:32 RepVGG-A0] (main.py 282): INFO Train: [76/300][70/78]	eta 0:00:14 lr 5.417338	time 1.1809 (1.8193)	loss 5.4553 (3.5071)	grad_norm 1.0900 (0.3931)	mem 39782MB
[2023-07-07 10:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 76 training takes 0:02:21
[2023-07-07 10:06:06 RepVGG-A0] (main.py 282): INFO Train: [77/300][0/78]	eta 0:28:57 lr 5.414858	time 22.2705 (22.2705)	loss 5.2657 (5.2657)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 10:06:20 RepVGG-A0] (main.py 282): INFO Train: [77/300][10/78]	eta 0:03:41 lr 5.411755	time 1.1716 (3.2573)	loss 4.4517 (4.8037)	grad_norm 0.3152 (0.3642)	mem 39782MB
[2023-07-07 10:06:34 RepVGG-A0] (main.py 282): INFO Train: [77/300][20/78]	eta 0:02:18 lr 5.408649	time 1.1909 (2.3810)	loss 4.0408 (4.5179)	grad_norm 0.2650 (0.3186)	mem 39782MB
[2023-07-07 10:06:50 RepVGG-A0] (main.py 282): INFO Train: [77/300][30/78]	eta 0:01:42 lr 5.405538	time 1.2019 (2.1251)	loss 3.8785 (4.3370)	grad_norm 0.3430 (0.3121)	mem 39782MB
[2023-07-07 10:07:08 RepVGG-A0] (main.py 282): INFO Train: [77/300][40/78]	eta 0:01:18 lr 5.402423	time 4.2332 (2.0601)	loss 3.7528 (4.2055)	grad_norm 0.3259 (0.3036)	mem 39782MB
[2023-07-07 10:07:23 RepVGG-A0] (main.py 282): INFO Train: [77/300][50/78]	eta 0:00:54 lr 5.399304	time 1.1722 (1.9346)	loss 3.7678 (4.1153)	grad_norm 0.3076 (0.3064)	mem 39782MB
[2023-07-07 10:07:39 RepVGG-A0] (main.py 282): INFO Train: [77/300][60/78]	eta 0:00:33 lr 5.396182	time 1.2471 (1.8805)	loss 3.7234 (4.0359)	grad_norm 0.3446 (0.3027)	mem 39782MB
[2023-07-07 10:07:54 RepVGG-A0] (main.py 282): INFO Train: [77/300][70/78]	eta 0:00:14 lr 5.393055	time 1.3750 (1.8307)	loss 3.5620 (3.9852)	grad_norm 0.2742 (0.3071)	mem 39782MB
[2023-07-07 10:08:06 RepVGG-A0] (main.py 291): INFO EPOCH 77 training takes 0:02:21
[2023-07-07 10:08:27 RepVGG-A0] (main.py 282): INFO Train: [78/300][0/78]	eta 0:28:25 lr 5.390551	time 21.8647 (21.8647)	loss 3.5276 (3.5276)	grad_norm 0.3382 (0.3382)	mem 39782MB
[2023-07-07 10:08:42 RepVGG-A0] (main.py 282): INFO Train: [78/300][10/78]	eta 0:03:44 lr 5.387417	time 1.1712 (3.2969)	loss 3.4657 (3.5592)	grad_norm 0.2988 (0.3343)	mem 39782MB
[2023-07-07 10:08:57 RepVGG-A0] (main.py 282): INFO Train: [78/300][20/78]	eta 0:02:22 lr 5.384279	time 1.3857 (2.4546)	loss 3.6181 (3.5690)	grad_norm 0.3817 (0.3522)	mem 39782MB
[2023-07-07 10:09:12 RepVGG-A0] (main.py 282): INFO Train: [78/300][30/78]	eta 0:01:42 lr 5.381138	time 1.5145 (2.1296)	loss 3.4942 (3.5430)	grad_norm 0.3380 (0.3396)	mem 39782MB
[2023-07-07 10:09:30 RepVGG-A0] (main.py 282): INFO Train: [78/300][40/78]	eta 0:01:18 lr 5.377992	time 3.3257 (2.0621)	loss 3.5024 (3.5377)	grad_norm 0.3562 (0.3401)	mem 39782MB
[2023-07-07 10:09:46 RepVGG-A0] (main.py 282): INFO Train: [78/300][50/78]	eta 0:00:54 lr 5.374843	time 1.2117 (1.9635)	loss 3.5786 (3.5333)	grad_norm 0.3894 (0.3455)	mem 39782MB
[2023-07-07 10:10:01 RepVGG-A0] (main.py 282): INFO Train: [78/300][60/78]	eta 0:00:33 lr 5.371689	time 1.4250 (1.8875)	loss 3.5346 (3.5314)	grad_norm 0.3290 (0.3454)	mem 39782MB
[2023-07-07 10:10:15 RepVGG-A0] (main.py 282): INFO Train: [78/300][70/78]	eta 0:00:14 lr 5.368532	time 1.1768 (1.8268)	loss 3.7583 (3.5272)	grad_norm 0.5386 (0.3483)	mem 39782MB
[2023-07-07 10:10:27 RepVGG-A0] (main.py 291): INFO EPOCH 78 training takes 0:02:21
[2023-07-07 10:10:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][0/78]	eta 0:28:48 lr 5.366003	time 22.1542 (22.1542)	loss 3.7933 (3.7933)	grad_norm 0.3883 (0.3883)	mem 39782MB
[2023-07-07 10:11:03 RepVGG-A0] (main.py 282): INFO Train: [79/300][10/78]	eta 0:03:43 lr 5.362839	time 1.1703 (3.2865)	loss 3.3781 (3.5554)	grad_norm 0.2665 (0.3224)	mem 39782MB
[2023-07-07 10:11:17 RepVGG-A0] (main.py 282): INFO Train: [79/300][20/78]	eta 0:02:17 lr 5.359670	time 1.3070 (2.3709)	loss 3.4415 (3.4818)	grad_norm 0.3262 (0.3080)	mem 39782MB
[2023-07-07 10:11:32 RepVGG-A0] (main.py 282): INFO Train: [79/300][30/78]	eta 0:01:40 lr 5.356498	time 1.1282 (2.0965)	loss 3.5071 (3.4827)	grad_norm 0.3432 (0.3223)	mem 39782MB
[2023-07-07 10:11:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][40/78]	eta 0:01:16 lr 5.353322	time 2.2786 (2.0125)	loss 3.3445 (3.4797)	grad_norm 0.3033 (0.3284)	mem 39782MB
[2023-07-07 10:12:05 RepVGG-A0] (main.py 282): INFO Train: [79/300][50/78]	eta 0:00:53 lr 5.350142	time 1.3030 (1.9239)	loss 3.4941 (3.4731)	grad_norm 0.3717 (0.3329)	mem 39782MB
[2023-07-07 10:12:21 RepVGG-A0] (main.py 282): INFO Train: [79/300][60/78]	eta 0:00:33 lr 5.346959	time 1.2244 (1.8675)	loss 3.4433 (3.4621)	grad_norm 0.3667 (0.3314)	mem 39782MB
[2023-07-07 10:12:36 RepVGG-A0] (main.py 282): INFO Train: [79/300][70/78]	eta 0:00:14 lr 5.343771	time 1.5734 (1.8247)	loss 4.1145 (3.5030)	grad_norm 0.7083 (0.3583)	mem 39782MB
[2023-07-07 10:12:47 RepVGG-A0] (main.py 291): INFO EPOCH 79 training takes 0:02:20
[2023-07-07 10:13:08 RepVGG-A0] (main.py 282): INFO Train: [80/300][0/78]	eta 0:26:15 lr 5.341218	time 20.2031 (20.2031)	loss 3.7361 (3.7361)	grad_norm 0.3243 (0.3243)	mem 39782MB
[2023-07-07 10:13:22 RepVGG-A0] (main.py 282): INFO Train: [80/300][10/78]	eta 0:03:36 lr 5.338023	time 1.1901 (3.1829)	loss 3.5152 (3.5943)	grad_norm 0.2977 (0.2853)	mem 39782MB
[2023-07-07 10:13:38 RepVGG-A0] (main.py 282): INFO Train: [80/300][20/78]	eta 0:02:19 lr 5.334825	time 1.1830 (2.4025)	loss 3.4974 (3.5402)	grad_norm 0.3072 (0.2960)	mem 39782MB
[2023-07-07 10:13:53 RepVGG-A0] (main.py 282): INFO Train: [80/300][30/78]	eta 0:01:42 lr 5.331623	time 1.3877 (2.1269)	loss 3.2879 (3.4959)	grad_norm 0.2722 (0.2921)	mem 39782MB
[2023-07-07 10:14:11 RepVGG-A0] (main.py 282): INFO Train: [80/300][40/78]	eta 0:01:17 lr 5.328416	time 4.3319 (2.0501)	loss 3.3978 (3.4603)	grad_norm 0.3658 (0.2937)	mem 39782MB
[2023-07-07 10:14:27 RepVGG-A0] (main.py 282): INFO Train: [80/300][50/78]	eta 0:00:54 lr 5.325206	time 1.1724 (1.9430)	loss 3.3855 (3.4589)	grad_norm 0.3275 (0.3082)	mem 39782MB
[2023-07-07 10:14:41 RepVGG-A0] (main.py 282): INFO Train: [80/300][60/78]	eta 0:00:33 lr 5.321993	time 1.2732 (1.8668)	loss 3.5283 (3.4481)	grad_norm 0.4813 (0.3119)	mem 39782MB
[2023-07-07 10:14:56 RepVGG-A0] (main.py 282): INFO Train: [80/300][70/78]	eta 0:00:14 lr 5.318775	time 1.3845 (1.8156)	loss 4.8239 (3.6070)	grad_norm 0.5154 (0.3707)	mem 39782MB
[2023-07-07 10:15:08 RepVGG-A0] (main.py 291): INFO EPOCH 80 training takes 0:02:20
[2023-07-07 10:15:25 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.027 (17.027)	Loss 5.1657 (5.1657)	Acc@1 11.731 (11.731)	Acc@5 27.191 (27.191)	Mem 39782MB
[2023-07-07 10:15:26 RepVGG-A0] (main.py 342): INFO  * Acc@1 11.640 Acc@5 26.608
[2023-07-07 10:15:26 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 80: 11.640%
[2023-07-07 10:15:26 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 10:15:46 RepVGG-A0] (main.py 282): INFO Train: [81/300][0/78]	eta 0:25:47 lr 5.316198	time 19.8343 (19.8343)	loss 3.9520 (3.9520)	grad_norm 0.2790 (0.2790)	mem 39782MB
[2023-07-07 10:16:01 RepVGG-A0] (main.py 282): INFO Train: [81/300][10/78]	eta 0:03:37 lr 5.312973	time 1.1696 (3.2000)	loss 3.6511 (3.7327)	grad_norm 0.2627 (0.2694)	mem 39782MB
[2023-07-07 10:16:16 RepVGG-A0] (main.py 282): INFO Train: [81/300][20/78]	eta 0:02:16 lr 5.309745	time 1.1904 (2.3593)	loss 3.4143 (3.6423)	grad_norm 0.2382 (0.2740)	mem 39782MB
[2023-07-07 10:16:31 RepVGG-A0] (main.py 282): INFO Train: [81/300][30/78]	eta 0:01:40 lr 5.306513	time 1.2249 (2.0877)	loss 3.4408 (3.5837)	grad_norm 0.2845 (0.2751)	mem 39782MB
[2023-07-07 10:16:49 RepVGG-A0] (main.py 282): INFO Train: [81/300][40/78]	eta 0:01:16 lr 5.303277	time 2.0521 (2.0213)	loss 3.4551 (3.5440)	grad_norm 0.2972 (0.2759)	mem 39782MB
[2023-07-07 10:17:06 RepVGG-A0] (main.py 282): INFO Train: [81/300][50/78]	eta 0:00:54 lr 5.300037	time 2.6890 (1.9526)	loss 3.4151 (3.5275)	grad_norm 0.3083 (0.2858)	mem 39782MB
[2023-07-07 10:17:21 RepVGG-A0] (main.py 282): INFO Train: [81/300][60/78]	eta 0:00:33 lr 5.296794	time 1.2880 (1.8763)	loss 3.4174 (3.5041)	grad_norm 0.3078 (0.2882)	mem 39782MB
[2023-07-07 10:17:36 RepVGG-A0] (main.py 282): INFO Train: [81/300][70/78]	eta 0:00:14 lr 5.293546	time 1.1727 (1.8232)	loss 3.3853 (3.4949)	grad_norm 0.3443 (0.2952)	mem 39782MB
[2023-07-07 10:17:48 RepVGG-A0] (main.py 291): INFO EPOCH 81 training takes 0:02:21
[2023-07-07 10:18:08 RepVGG-A0] (main.py 282): INFO Train: [82/300][0/78]	eta 0:26:49 lr 5.290946	time 20.6399 (20.6399)	loss 3.4308 (3.4308)	grad_norm 0.3601 (0.3601)	mem 39782MB
[2023-07-07 10:18:23 RepVGG-A0] (main.py 282): INFO Train: [82/300][10/78]	eta 0:03:37 lr 5.287692	time 1.1725 (3.2022)	loss 3.2956 (3.3960)	grad_norm 0.2981 (0.3495)	mem 39782MB
[2023-07-07 10:18:38 RepVGG-A0] (main.py 282): INFO Train: [82/300][20/78]	eta 0:02:19 lr 5.284434	time 1.1730 (2.4055)	loss 3.4761 (3.3837)	grad_norm 0.3628 (0.3463)	mem 39782MB
[2023-07-07 10:18:52 RepVGG-A0] (main.py 282): INFO Train: [82/300][30/78]	eta 0:01:39 lr 5.281172	time 1.1931 (2.0825)	loss 3.4454 (3.3748)	grad_norm 0.3732 (0.3417)	mem 39782MB
[2023-07-07 10:19:11 RepVGG-A0] (main.py 282): INFO Train: [82/300][40/78]	eta 0:01:17 lr 5.277907	time 3.9559 (2.0266)	loss 4.6517 (3.4864)	grad_norm 0.8830 (0.4006)	mem 39782MB
[2023-07-07 10:19:26 RepVGG-A0] (main.py 282): INFO Train: [82/300][50/78]	eta 0:00:53 lr 5.274638	time 1.1726 (1.9249)	loss 3.8324 (3.6353)	grad_norm 0.3246 (0.4212)	mem 39782MB
[2023-07-07 10:19:42 RepVGG-A0] (main.py 282): INFO Train: [82/300][60/78]	eta 0:00:33 lr 5.271365	time 1.2744 (1.8693)	loss 3.5050 (3.6386)	grad_norm 0.2857 (0.3992)	mem 39782MB
[2023-07-07 10:19:55 RepVGG-A0] (main.py 282): INFO Train: [82/300][70/78]	eta 0:00:14 lr 5.268089	time 1.1729 (1.7975)	loss 3.3689 (3.6160)	grad_norm 0.2560 (0.3825)	mem 39782MB
[2023-07-07 10:20:08 RepVGG-A0] (main.py 291): INFO EPOCH 82 training takes 0:02:19
[2023-07-07 10:20:29 RepVGG-A0] (main.py 282): INFO Train: [83/300][0/78]	eta 0:28:09 lr 5.265465	time 21.6557 (21.6557)	loss 3.3882 (3.3882)	grad_norm 0.3216 (0.3216)	mem 39782MB
[2023-07-07 10:20:44 RepVGG-A0] (main.py 282): INFO Train: [83/300][10/78]	eta 0:03:43 lr 5.262181	time 1.1700 (3.2830)	loss 3.4442 (3.3437)	grad_norm 0.3384 (0.3006)	mem 39782MB
[2023-07-07 10:20:58 RepVGG-A0] (main.py 282): INFO Train: [83/300][20/78]	eta 0:02:19 lr 5.258894	time 1.1740 (2.3987)	loss 3.5017 (3.3548)	grad_norm 0.3841 (0.3199)	mem 39782MB
[2023-07-07 10:21:14 RepVGG-A0] (main.py 282): INFO Train: [83/300][30/78]	eta 0:01:42 lr 5.255604	time 1.1878 (2.1290)	loss 3.2963 (3.3721)	grad_norm 0.3160 (0.3292)	mem 39782MB
[2023-07-07 10:21:32 RepVGG-A0] (main.py 282): INFO Train: [83/300][40/78]	eta 0:01:18 lr 5.252309	time 4.2949 (2.0650)	loss 3.4306 (3.3625)	grad_norm 0.3920 (0.3250)	mem 39782MB
[2023-07-07 10:21:46 RepVGG-A0] (main.py 282): INFO Train: [83/300][50/78]	eta 0:00:54 lr 5.249011	time 1.1905 (1.9308)	loss 3.3789 (3.3643)	grad_norm 0.3291 (0.3297)	mem 39782MB
[2023-07-07 10:22:02 RepVGG-A0] (main.py 282): INFO Train: [83/300][60/78]	eta 0:00:33 lr 5.245709	time 1.3594 (1.8698)	loss 3.3266 (3.3673)	grad_norm 0.3200 (0.3347)	mem 39782MB
[2023-07-07 10:22:16 RepVGG-A0] (main.py 282): INFO Train: [83/300][70/78]	eta 0:00:14 lr 5.242404	time 1.3411 (1.8126)	loss 3.3981 (3.3681)	grad_norm 0.3974 (0.3345)	mem 39782MB
[2023-07-07 10:22:28 RepVGG-A0] (main.py 291): INFO EPOCH 83 training takes 0:02:20
[2023-07-07 10:22:49 RepVGG-A0] (main.py 282): INFO Train: [84/300][0/78]	eta 0:27:32 lr 5.239757	time 21.1841 (21.1841)	loss 3.6597 (3.6597)	grad_norm 0.5047 (0.5047)	mem 39782MB
[2023-07-07 10:23:03 RepVGG-A0] (main.py 282): INFO Train: [84/300][10/78]	eta 0:03:37 lr 5.236445	time 1.1731 (3.2030)	loss 3.3068 (3.4313)	grad_norm 0.2995 (0.3506)	mem 39782MB
[2023-07-07 10:23:18 RepVGG-A0] (main.py 282): INFO Train: [84/300][20/78]	eta 0:02:19 lr 5.233129	time 1.1718 (2.4001)	loss 3.2914 (3.3963)	grad_norm 0.3304 (0.3447)	mem 39782MB
[2023-07-07 10:23:33 RepVGG-A0] (main.py 282): INFO Train: [84/300][30/78]	eta 0:01:41 lr 5.229809	time 1.1983 (2.1064)	loss 3.4357 (3.3888)	grad_norm 0.4088 (0.3489)	mem 39782MB
[2023-07-07 10:23:51 RepVGG-A0] (main.py 282): INFO Train: [84/300][40/78]	eta 0:01:17 lr 5.226486	time 4.6106 (2.0391)	loss 3.3309 (3.3823)	grad_norm 0.3027 (0.3448)	mem 39782MB
[2023-07-07 10:24:06 RepVGG-A0] (main.py 282): INFO Train: [84/300][50/78]	eta 0:00:53 lr 5.223160	time 1.1726 (1.9242)	loss 3.4541 (3.3864)	grad_norm 0.3730 (0.3488)	mem 39782MB
[2023-07-07 10:24:21 RepVGG-A0] (main.py 282): INFO Train: [84/300][60/78]	eta 0:00:33 lr 5.219829	time 1.1848 (1.8565)	loss 3.5182 (3.3820)	grad_norm 0.4371 (0.3504)	mem 39782MB
[2023-07-07 10:24:36 RepVGG-A0] (main.py 282): INFO Train: [84/300][70/78]	eta 0:00:14 lr 5.216495	time 1.2382 (1.8051)	loss 3.2643 (3.3846)	grad_norm 0.2982 (0.3514)	mem 39782MB
[2023-07-07 10:24:47 RepVGG-A0] (main.py 291): INFO EPOCH 84 training takes 0:02:19
[2023-07-07 10:25:09 RepVGG-A0] (main.py 282): INFO Train: [85/300][0/78]	eta 0:28:04 lr 5.213825	time 21.5921 (21.5921)	loss 3.3879 (3.3879)	grad_norm 0.4159 (0.4159)	mem 39782MB
[2023-07-07 10:25:22 RepVGG-A0] (main.py 282): INFO Train: [85/300][10/78]	eta 0:03:37 lr 5.210485	time 1.1885 (3.1960)	loss 3.8272 (3.6080)	grad_norm 0.5796 (0.5154)	mem 39782MB
[2023-07-07 10:25:37 RepVGG-A0] (main.py 282): INFO Train: [85/300][20/78]	eta 0:02:18 lr 5.207140	time 1.1715 (2.3815)	loss 3.3770 (3.5750)	grad_norm 0.2774 (0.4386)	mem 39782MB
[2023-07-07 10:25:52 RepVGG-A0] (main.py 282): INFO Train: [85/300][30/78]	eta 0:01:40 lr 5.203793	time 1.1640 (2.0908)	loss 3.4171 (3.5005)	grad_norm 0.3069 (0.3939)	mem 39782MB
[2023-07-07 10:26:10 RepVGG-A0] (main.py 282): INFO Train: [85/300][40/78]	eta 0:01:17 lr 5.200441	time 3.6026 (2.0272)	loss 3.3628 (3.4543)	grad_norm 0.3181 (0.3711)	mem 39782MB
[2023-07-07 10:26:25 RepVGG-A0] (main.py 282): INFO Train: [85/300][50/78]	eta 0:00:53 lr 5.197086	time 1.1730 (1.9283)	loss 3.3162 (3.4313)	grad_norm 0.3898 (0.3666)	mem 39782MB
[2023-07-07 10:26:41 RepVGG-A0] (main.py 282): INFO Train: [85/300][60/78]	eta 0:00:33 lr 5.193728	time 1.1802 (1.8630)	loss 3.2984 (3.4187)	grad_norm 0.3192 (0.3636)	mem 39782MB
[2023-07-07 10:26:56 RepVGG-A0] (main.py 282): INFO Train: [85/300][70/78]	eta 0:00:14 lr 5.190365	time 1.1736 (1.8175)	loss 3.3067 (3.4066)	grad_norm 0.3511 (0.3602)	mem 39782MB
[2023-07-07 10:27:07 RepVGG-A0] (main.py 291): INFO EPOCH 85 training takes 0:02:20
[2023-07-07 10:27:28 RepVGG-A0] (main.py 282): INFO Train: [86/300][0/78]	eta 0:27:13 lr 5.187673	time 20.9476 (20.9476)	loss 3.7612 (3.7612)	grad_norm 0.5963 (0.5963)	mem 39782MB
[2023-07-07 10:27:44 RepVGG-A0] (main.py 282): INFO Train: [86/300][10/78]	eta 0:03:45 lr 5.184304	time 1.1713 (3.3222)	loss 5.1665 (4.4966)	grad_norm 0.7889 (0.7841)	mem 39782MB
[2023-07-07 10:27:59 RepVGG-A0] (main.py 282): INFO Train: [86/300][20/78]	eta 0:02:21 lr 5.180932	time 1.3185 (2.4450)	loss 4.1145 (4.5597)	grad_norm 0.2884 (0.6187)	mem 39782MB
[2023-07-07 10:28:13 RepVGG-A0] (main.py 282): INFO Train: [86/300][30/78]	eta 0:01:42 lr 5.177556	time 1.1821 (2.1281)	loss 3.8445 (4.3455)	grad_norm 0.3546 (0.5155)	mem 39782MB
[2023-07-07 10:28:33 RepVGG-A0] (main.py 282): INFO Train: [86/300][40/78]	eta 0:01:19 lr 5.174177	time 4.3436 (2.0790)	loss 3.7352 (4.1785)	grad_norm 0.2587 (0.4501)	mem 39782MB
[2023-07-07 10:28:48 RepVGG-A0] (main.py 282): INFO Train: [86/300][50/78]	eta 0:00:54 lr 5.170794	time 1.1368 (1.9640)	loss 3.5030 (4.0521)	grad_norm 0.2524 (0.4154)	mem 39782MB
[2023-07-07 10:29:03 RepVGG-A0] (main.py 282): INFO Train: [86/300][60/78]	eta 0:00:34 lr 5.167407	time 1.4230 (1.8946)	loss 3.4177 (3.9497)	grad_norm 0.2897 (0.3935)	mem 39782MB
[2023-07-07 10:29:17 RepVGG-A0] (main.py 282): INFO Train: [86/300][70/78]	eta 0:00:14 lr 5.164017	time 1.3816 (1.8239)	loss 3.4359 (3.8771)	grad_norm 0.3005 (0.3827)	mem 39782MB
[2023-07-07 10:29:29 RepVGG-A0] (main.py 291): INFO EPOCH 86 training takes 0:02:21
[2023-07-07 10:29:50 RepVGG-A0] (main.py 282): INFO Train: [87/300][0/78]	eta 0:28:00 lr 5.161303	time 21.5468 (21.5468)	loss 3.3666 (3.3666)	grad_norm 0.3264 (0.3264)	mem 39782MB
[2023-07-07 10:30:06 RepVGG-A0] (main.py 282): INFO Train: [87/300][10/78]	eta 0:03:48 lr 5.157906	time 1.1891 (3.3675)	loss 3.2937 (3.3470)	grad_norm 0.3041 (0.3253)	mem 39782MB
[2023-07-07 10:30:21 RepVGG-A0] (main.py 282): INFO Train: [87/300][20/78]	eta 0:02:23 lr 5.154506	time 1.2147 (2.4715)	loss 3.4835 (3.3693)	grad_norm 0.4556 (0.3385)	mem 39782MB
[2023-07-07 10:30:36 RepVGG-A0] (main.py 282): INFO Train: [87/300][30/78]	eta 0:01:43 lr 5.151103	time 1.3752 (2.1577)	loss 3.3684 (3.3659)	grad_norm 0.3088 (0.3321)	mem 39782MB
[2023-07-07 10:30:54 RepVGG-A0] (main.py 282): INFO Train: [87/300][40/78]	eta 0:01:18 lr 5.147696	time 3.9573 (2.0740)	loss 3.3953 (3.3675)	grad_norm 0.3761 (0.3334)	mem 39782MB
[2023-07-07 10:31:08 RepVGG-A0] (main.py 282): INFO Train: [87/300][50/78]	eta 0:00:54 lr 5.144285	time 1.1904 (1.9571)	loss 3.3108 (3.3631)	grad_norm 0.2973 (0.3326)	mem 39782MB
[2023-07-07 10:31:23 RepVGG-A0] (main.py 282): INFO Train: [87/300][60/78]	eta 0:00:33 lr 5.140871	time 1.1752 (1.8797)	loss 3.3752 (3.3766)	grad_norm 0.3193 (0.3411)	mem 39782MB
[2023-07-07 10:31:39 RepVGG-A0] (main.py 282): INFO Train: [87/300][70/78]	eta 0:00:14 lr 5.137454	time 1.2921 (1.8347)	loss 3.4319 (3.3707)	grad_norm 0.3821 (0.3391)	mem 39782MB
[2023-07-07 10:31:50 RepVGG-A0] (main.py 291): INFO EPOCH 87 training takes 0:02:21
[2023-07-07 10:32:13 RepVGG-A0] (main.py 282): INFO Train: [88/300][0/78]	eta 0:28:47 lr 5.134717	time 22.1468 (22.1468)	loss 3.3407 (3.3407)	grad_norm 0.3599 (0.3599)	mem 39782MB
[2023-07-07 10:32:28 RepVGG-A0] (main.py 282): INFO Train: [88/300][10/78]	eta 0:03:53 lr 5.131293	time 1.1897 (3.4400)	loss 3.3011 (3.3635)	grad_norm 0.3363 (0.3783)	mem 39782MB
[2023-07-07 10:32:43 RepVGG-A0] (main.py 282): INFO Train: [88/300][20/78]	eta 0:02:25 lr 5.127866	time 1.1841 (2.5084)	loss 3.2839 (3.3273)	grad_norm 0.3279 (0.3545)	mem 39782MB
[2023-07-07 10:32:58 RepVGG-A0] (main.py 282): INFO Train: [88/300][30/78]	eta 0:01:44 lr 5.124435	time 1.5173 (2.1823)	loss 3.3257 (3.3243)	grad_norm 0.3467 (0.3561)	mem 39782MB
[2023-07-07 10:33:16 RepVGG-A0] (main.py 282): INFO Train: [88/300][40/78]	eta 0:01:19 lr 5.121001	time 4.6071 (2.0939)	loss 3.4836 (3.3274)	grad_norm 0.4504 (0.3562)	mem 39782MB
[2023-07-07 10:33:30 RepVGG-A0] (main.py 282): INFO Train: [88/300][50/78]	eta 0:00:54 lr 5.117563	time 1.1754 (1.9616)	loss 5.6208 (3.5992)	grad_norm 0.5972 (0.4390)	mem 39782MB
[2023-07-07 10:33:46 RepVGG-A0] (main.py 282): INFO Train: [88/300][60/78]	eta 0:00:34 lr 5.114122	time 1.2868 (1.8955)	loss 4.4968 (3.8300)	grad_norm 0.2926 (0.4385)	mem 39782MB
[2023-07-07 10:34:01 RepVGG-A0] (main.py 282): INFO Train: [88/300][70/78]	eta 0:00:14 lr 5.110678	time 1.2921 (1.8380)	loss 4.0882 (3.8848)	grad_norm 0.2949 (0.4208)	mem 39782MB
[2023-07-07 10:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 88 training takes 0:02:23
[2023-07-07 10:34:36 RepVGG-A0] (main.py 282): INFO Train: [89/300][0/78]	eta 0:28:48 lr 5.107920	time 22.1596 (22.1596)	loss 3.7306 (3.7306)	grad_norm 0.2494 (0.2494)	mem 39782MB
[2023-07-07 10:34:50 RepVGG-A0] (main.py 282): INFO Train: [89/300][10/78]	eta 0:03:47 lr 5.104469	time 1.1914 (3.3466)	loss 3.5527 (3.6856)	grad_norm 0.2979 (0.2737)	mem 39782MB
[2023-07-07 10:35:05 RepVGG-A0] (main.py 282): INFO Train: [89/300][20/78]	eta 0:02:22 lr 5.101015	time 1.1292 (2.4563)	loss 3.5311 (3.6336)	grad_norm 0.3213 (0.2793)	mem 39782MB
[2023-07-07 10:35:19 RepVGG-A0] (main.py 282): INFO Train: [89/300][30/78]	eta 0:01:42 lr 5.097557	time 1.3504 (2.1258)	loss 3.5433 (3.6023)	grad_norm 0.3384 (0.2874)	mem 39782MB
[2023-07-07 10:35:37 RepVGG-A0] (main.py 282): INFO Train: [89/300][40/78]	eta 0:01:17 lr 5.094096	time 3.2339 (2.0461)	loss 3.4911 (3.5813)	grad_norm 0.2683 (0.2941)	mem 39782MB
[2023-07-07 10:35:52 RepVGG-A0] (main.py 282): INFO Train: [89/300][50/78]	eta 0:00:54 lr 5.090631	time 1.1906 (1.9364)	loss 3.4700 (3.5554)	grad_norm 0.3317 (0.2978)	mem 39782MB
[2023-07-07 10:36:08 RepVGG-A0] (main.py 282): INFO Train: [89/300][60/78]	eta 0:00:33 lr 5.087164	time 1.4753 (1.8737)	loss 3.4079 (3.5370)	grad_norm 0.3111 (0.3032)	mem 39782MB
[2023-07-07 10:36:23 RepVGG-A0] (main.py 282): INFO Train: [89/300][70/78]	eta 0:00:14 lr 5.083692	time 1.2863 (1.8226)	loss 3.4067 (3.5219)	grad_norm 0.3837 (0.3085)	mem 39782MB
[2023-07-07 10:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 89 training takes 0:02:20
[2023-07-07 10:36:55 RepVGG-A0] (main.py 282): INFO Train: [90/300][0/78]	eta 0:28:02 lr 5.080913	time 21.5677 (21.5677)	loss 3.3364 (3.3364)	grad_norm 0.2854 (0.2854)	mem 39782MB
[2023-07-07 10:37:11 RepVGG-A0] (main.py 282): INFO Train: [90/300][10/78]	eta 0:03:49 lr 5.077435	time 1.1719 (3.3762)	loss 3.6241 (3.4861)	grad_norm 0.4454 (0.4168)	mem 39782MB
[2023-07-07 10:37:25 RepVGG-A0] (main.py 282): INFO Train: [90/300][20/78]	eta 0:02:21 lr 5.073955	time 1.2685 (2.4388)	loss 3.4367 (3.4772)	grad_norm 0.2934 (0.3839)	mem 39782MB
[2023-07-07 10:37:40 RepVGG-A0] (main.py 282): INFO Train: [90/300][30/78]	eta 0:01:42 lr 5.070470	time 1.2412 (2.1391)	loss 3.3749 (3.4426)	grad_norm 0.3416 (0.3664)	mem 39782MB
[2023-07-07 10:37:58 RepVGG-A0] (main.py 282): INFO Train: [90/300][40/78]	eta 0:01:18 lr 5.066983	time 3.7083 (2.0619)	loss 3.3254 (3.4228)	grad_norm 0.2938 (0.3541)	mem 39782MB
[2023-07-07 10:38:14 RepVGG-A0] (main.py 282): INFO Train: [90/300][50/78]	eta 0:00:54 lr 5.063492	time 1.1724 (1.9564)	loss 3.6480 (3.4184)	grad_norm 0.4873 (0.3578)	mem 39782MB
[2023-07-07 10:38:28 RepVGG-A0] (main.py 282): INFO Train: [90/300][60/78]	eta 0:00:33 lr 5.059998	time 1.2987 (1.8731)	loss 5.1254 (3.6007)	grad_norm 0.6534 (0.4244)	mem 39782MB
[2023-07-07 10:38:43 RepVGG-A0] (main.py 282): INFO Train: [90/300][70/78]	eta 0:00:14 lr 5.056500	time 1.2889 (1.8237)	loss 4.0726 (3.7225)	grad_norm 0.2893 (0.4222)	mem 39782MB
[2023-07-07 10:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 90 training takes 0:02:21
[2023-07-07 10:39:17 RepVGG-A0] (main.py 282): INFO Train: [91/300][0/78]	eta 0:28:41 lr 5.053700	time 22.0745 (22.0745)	loss 3.7110 (3.7110)	grad_norm 0.2900 (0.2900)	mem 39782MB
[2023-07-07 10:39:31 RepVGG-A0] (main.py 282): INFO Train: [91/300][10/78]	eta 0:03:42 lr 5.050196	time 1.1727 (3.2744)	loss 3.5874 (3.6358)	grad_norm 0.3048 (0.2744)	mem 39782MB
[2023-07-07 10:39:46 RepVGG-A0] (main.py 282): INFO Train: [91/300][20/78]	eta 0:02:20 lr 5.046689	time 1.3508 (2.4202)	loss 3.4326 (3.5846)	grad_norm 0.2436 (0.2787)	mem 39782MB
[2023-07-07 10:40:02 RepVGG-A0] (main.py 282): INFO Train: [91/300][30/78]	eta 0:01:44 lr 5.043179	time 1.4313 (2.1702)	loss 3.3415 (3.5416)	grad_norm 0.2710 (0.2819)	mem 39782MB
[2023-07-07 10:40:18 RepVGG-A0] (main.py 282): INFO Train: [91/300][40/78]	eta 0:01:17 lr 5.039665	time 2.9187 (2.0330)	loss 3.4032 (3.5110)	grad_norm 0.2918 (0.2888)	mem 39782MB
[2023-07-07 10:40:33 RepVGG-A0] (main.py 282): INFO Train: [91/300][50/78]	eta 0:00:53 lr 5.036148	time 1.1725 (1.9242)	loss 3.3927 (3.4821)	grad_norm 0.3607 (0.2909)	mem 39782MB
[2023-07-07 10:40:48 RepVGG-A0] (main.py 282): INFO Train: [91/300][60/78]	eta 0:00:33 lr 5.032628	time 1.3964 (1.8536)	loss 3.3806 (3.4721)	grad_norm 0.3677 (0.3011)	mem 39782MB
[2023-07-07 10:41:03 RepVGG-A0] (main.py 282): INFO Train: [91/300][70/78]	eta 0:00:14 lr 5.029105	time 1.3194 (1.8079)	loss 3.3871 (3.4574)	grad_norm 0.3018 (0.3001)	mem 39782MB
[2023-07-07 10:41:15 RepVGG-A0] (main.py 291): INFO EPOCH 91 training takes 0:02:20
[2023-07-07 10:41:36 RepVGG-A0] (main.py 282): INFO Train: [92/300][0/78]	eta 0:27:25 lr 5.026283	time 21.0982 (21.0982)	loss 3.5652 (3.5652)	grad_norm 0.4467 (0.4467)	mem 39782MB
[2023-07-07 10:41:51 RepVGG-A0] (main.py 282): INFO Train: [92/300][10/78]	eta 0:03:42 lr 5.022754	time 1.1721 (3.2693)	loss 3.3172 (3.3808)	grad_norm 0.3085 (0.3474)	mem 39782MB
[2023-07-07 10:42:05 RepVGG-A0] (main.py 282): INFO Train: [92/300][20/78]	eta 0:02:18 lr 5.019221	time 1.3240 (2.3959)	loss 3.3269 (3.3718)	grad_norm 0.3563 (0.3408)	mem 39782MB
[2023-07-07 10:42:20 RepVGG-A0] (main.py 282): INFO Train: [92/300][30/78]	eta 0:01:41 lr 5.015685	time 1.2189 (2.1044)	loss 3.4145 (3.3706)	grad_norm 0.3890 (0.3458)	mem 39782MB
[2023-07-07 10:42:38 RepVGG-A0] (main.py 282): INFO Train: [92/300][40/78]	eta 0:01:16 lr 5.012146	time 4.2062 (2.0250)	loss 3.3072 (3.3694)	grad_norm 0.3086 (0.3479)	mem 39782MB
[2023-07-07 10:42:53 RepVGG-A0] (main.py 282): INFO Train: [92/300][50/78]	eta 0:00:53 lr 5.008603	time 1.1749 (1.9235)	loss 3.4285 (3.3605)	grad_norm 0.3969 (0.3440)	mem 39782MB
[2023-07-07 10:43:08 RepVGG-A0] (main.py 282): INFO Train: [92/300][60/78]	eta 0:00:33 lr 5.005057	time 1.1956 (1.8583)	loss 3.3687 (3.3766)	grad_norm 0.3106 (0.3543)	mem 39782MB
[2023-07-07 10:43:23 RepVGG-A0] (main.py 282): INFO Train: [92/300][70/78]	eta 0:00:14 lr 5.001508	time 1.3669 (1.8086)	loss 3.3521 (3.3709)	grad_norm 0.3792 (0.3507)	mem 39782MB
[2023-07-07 10:43:35 RepVGG-A0] (main.py 291): INFO EPOCH 92 training takes 0:02:20
[2023-07-07 10:43:57 RepVGG-A0] (main.py 282): INFO Train: [93/300][0/78]	eta 0:28:42 lr 4.998667	time 22.0781 (22.0781)	loss 3.5907 (3.5907)	grad_norm 0.4690 (0.4690)	mem 39782MB
[2023-07-07 10:44:12 RepVGG-A0] (main.py 282): INFO Train: [93/300][10/78]	eta 0:03:47 lr 4.995112	time 1.1738 (3.3423)	loss 3.3586 (3.3931)	grad_norm 0.3758 (0.3627)	mem 39782MB
[2023-07-07 10:44:26 RepVGG-A0] (main.py 282): INFO Train: [93/300][20/78]	eta 0:02:19 lr 4.991554	time 1.1728 (2.3970)	loss 3.2483 (3.3305)	grad_norm 0.3243 (0.3417)	mem 39782MB
[2023-07-07 10:44:41 RepVGG-A0] (main.py 282): INFO Train: [93/300][30/78]	eta 0:01:42 lr 4.987992	time 1.1419 (2.1344)	loss 3.3873 (3.3398)	grad_norm 0.3700 (0.3540)	mem 39782MB
[2023-07-07 10:44:59 RepVGG-A0] (main.py 282): INFO Train: [93/300][40/78]	eta 0:01:17 lr 4.984428	time 3.4639 (2.0393)	loss 3.3744 (3.3310)	grad_norm 0.3630 (0.3527)	mem 39782MB
[2023-07-07 10:45:14 RepVGG-A0] (main.py 282): INFO Train: [93/300][50/78]	eta 0:00:54 lr 4.980860	time 1.1730 (1.9342)	loss 3.2712 (3.3247)	grad_norm 0.3187 (0.3509)	mem 39782MB
[2023-07-07 10:45:29 RepVGG-A0] (main.py 282): INFO Train: [93/300][60/78]	eta 0:00:33 lr 4.977289	time 1.2710 (1.8642)	loss 3.7622 (3.3592)	grad_norm 0.5721 (0.3726)	mem 39782MB
[2023-07-07 10:45:44 RepVGG-A0] (main.py 282): INFO Train: [93/300][70/78]	eta 0:00:14 lr 4.973715	time 1.3720 (1.8142)	loss 3.3954 (3.3953)	grad_norm 0.2790 (0.3798)	mem 39782MB
[2023-07-07 10:45:56 RepVGG-A0] (main.py 291): INFO EPOCH 93 training takes 0:02:20
[2023-07-07 10:46:16 RepVGG-A0] (main.py 282): INFO Train: [94/300][0/78]	eta 0:26:01 lr 4.970853	time 20.0241 (20.0241)	loss 3.1855 (3.1855)	grad_norm 0.2970 (0.2970)	mem 39782MB
[2023-07-07 10:46:33 RepVGG-A0] (main.py 282): INFO Train: [94/300][10/78]	eta 0:03:47 lr 4.967273	time 1.1716 (3.3434)	loss 3.1851 (3.2541)	grad_norm 0.3257 (0.3105)	mem 39782MB
[2023-07-07 10:46:49 RepVGG-A0] (main.py 282): INFO Train: [94/300][20/78]	eta 0:02:25 lr 4.963690	time 1.1974 (2.5063)	loss 3.3015 (3.2646)	grad_norm 0.3192 (0.3282)	mem 39782MB
[2023-07-07 10:47:05 RepVGG-A0] (main.py 282): INFO Train: [94/300][30/78]	eta 0:01:46 lr 4.960103	time 1.5024 (2.2125)	loss 3.3452 (3.2601)	grad_norm 0.3676 (0.3276)	mem 39782MB
[2023-07-07 10:47:21 RepVGG-A0] (main.py 282): INFO Train: [94/300][40/78]	eta 0:01:18 lr 4.956514	time 2.0034 (2.0737)	loss 3.4569 (3.3064)	grad_norm 0.3815 (0.3565)	mem 39782MB
[2023-07-07 10:47:36 RepVGG-A0] (main.py 282): INFO Train: [94/300][50/78]	eta 0:00:54 lr 4.952921	time 1.2216 (1.9629)	loss 3.3678 (3.3060)	grad_norm 0.3048 (0.3481)	mem 39782MB
[2023-07-07 10:47:51 RepVGG-A0] (main.py 282): INFO Train: [94/300][60/78]	eta 0:00:33 lr 4.949325	time 1.1939 (1.8832)	loss 3.3399 (3.3012)	grad_norm 0.3780 (0.3469)	mem 39782MB
[2023-07-07 10:48:06 RepVGG-A0] (main.py 282): INFO Train: [94/300][70/78]	eta 0:00:14 lr 4.945726	time 1.4563 (1.8249)	loss 3.2507 (3.3003)	grad_norm 0.3318 (0.3462)	mem 39782MB
[2023-07-07 10:48:18 RepVGG-A0] (main.py 291): INFO EPOCH 94 training takes 0:02:21
[2023-07-07 10:48:40 RepVGG-A0] (main.py 282): INFO Train: [95/300][0/78]	eta 0:28:43 lr 4.942845	time 22.1015 (22.1015)	loss 3.4736 (3.4736)	grad_norm 0.4473 (0.4473)	mem 39782MB
[2023-07-07 10:48:54 RepVGG-A0] (main.py 282): INFO Train: [95/300][10/78]	eta 0:03:44 lr 4.939240	time 1.1718 (3.3076)	loss 3.2615 (3.3476)	grad_norm 0.3206 (0.3940)	mem 39782MB
[2023-07-07 10:49:10 RepVGG-A0] (main.py 282): INFO Train: [95/300][20/78]	eta 0:02:23 lr 4.935632	time 1.2755 (2.4734)	loss 3.1609 (3.2903)	grad_norm 0.3305 (0.3543)	mem 39782MB
[2023-07-07 10:49:25 RepVGG-A0] (main.py 282): INFO Train: [95/300][30/78]	eta 0:01:44 lr 4.932022	time 1.4713 (2.1721)	loss 3.3826 (3.3037)	grad_norm 0.4079 (0.3655)	mem 39782MB
[2023-07-07 10:49:42 RepVGG-A0] (main.py 282): INFO Train: [95/300][40/78]	eta 0:01:17 lr 4.928407	time 2.7061 (2.0475)	loss 3.2778 (3.3078)	grad_norm 0.3472 (0.3665)	mem 39782MB
[2023-07-07 10:49:57 RepVGG-A0] (main.py 282): INFO Train: [95/300][50/78]	eta 0:00:54 lr 4.924790	time 1.1719 (1.9478)	loss 3.3948 (3.3013)	grad_norm 0.4050 (0.3629)	mem 39782MB
[2023-07-07 10:50:12 RepVGG-A0] (main.py 282): INFO Train: [95/300][60/78]	eta 0:00:33 lr 4.921170	time 1.3006 (1.8665)	loss 3.2316 (3.3125)	grad_norm 0.2904 (0.3676)	mem 39782MB
[2023-07-07 10:50:26 RepVGG-A0] (main.py 282): INFO Train: [95/300][70/78]	eta 0:00:14 lr 4.917547	time 1.3814 (1.8128)	loss 3.2558 (3.3062)	grad_norm 0.3459 (0.3644)	mem 39782MB
[2023-07-07 10:50:38 RepVGG-A0] (main.py 291): INFO EPOCH 95 training takes 0:02:20
[2023-07-07 10:50:59 RepVGG-A0] (main.py 282): INFO Train: [96/300][0/78]	eta 0:27:13 lr 4.914646	time 20.9398 (20.9398)	loss 3.3851 (3.3851)	grad_norm 0.4653 (0.4653)	mem 39782MB
[2023-07-07 10:51:14 RepVGG-A0] (main.py 282): INFO Train: [96/300][10/78]	eta 0:03:40 lr 4.911017	time 1.1922 (3.2484)	loss 6.3482 (4.4640)	grad_norm 0.8510 (0.8143)	mem 39782MB
[2023-07-07 10:51:29 RepVGG-A0] (main.py 282): INFO Train: [96/300][20/78]	eta 0:02:19 lr 4.907385	time 1.1728 (2.4027)	loss 5.1711 (5.1124)	grad_norm 0.2901 (0.6619)	mem 39782MB
[2023-07-07 10:51:43 RepVGG-A0] (main.py 282): INFO Train: [96/300][30/78]	eta 0:01:40 lr 4.903750	time 1.1839 (2.0938)	loss 4.4405 (5.0141)	grad_norm 0.2770 (0.5503)	mem 39782MB
[2023-07-07 10:52:02 RepVGG-A0] (main.py 282): INFO Train: [96/300][40/78]	eta 0:01:17 lr 4.900111	time 3.9479 (2.0266)	loss 4.1794 (4.8501)	grad_norm 0.2482 (0.4951)	mem 39782MB
[2023-07-07 10:52:16 RepVGG-A0] (main.py 282): INFO Train: [96/300][50/78]	eta 0:00:53 lr 4.896470	time 1.1722 (1.9166)	loss 3.9155 (4.6828)	grad_norm 0.2669 (0.4522)	mem 39782MB
[2023-07-07 10:52:31 RepVGG-A0] (main.py 282): INFO Train: [96/300][60/78]	eta 0:00:33 lr 4.892826	time 1.1421 (1.8464)	loss 3.8219 (4.5460)	grad_norm 0.3133 (0.4259)	mem 39782MB
[2023-07-07 10:52:47 RepVGG-A0] (main.py 282): INFO Train: [96/300][70/78]	eta 0:00:14 lr 4.889179	time 1.2857 (1.8055)	loss 3.7332 (4.4340)	grad_norm 0.3464 (0.4095)	mem 39782MB
[2023-07-07 10:52:58 RepVGG-A0] (main.py 291): INFO EPOCH 96 training takes 0:02:19
[2023-07-07 10:53:20 RepVGG-A0] (main.py 282): INFO Train: [97/300][0/78]	eta 0:28:44 lr 4.886259	time 22.1044 (22.1044)	loss 3.5619 (3.5619)	grad_norm 0.2730 (0.2730)	mem 39782MB
[2023-07-07 10:53:35 RepVGG-A0] (main.py 282): INFO Train: [97/300][10/78]	eta 0:03:44 lr 4.882606	time 1.1889 (3.3045)	loss 3.5253 (3.5698)	grad_norm 0.3142 (0.3169)	mem 39782MB
[2023-07-07 10:53:49 RepVGG-A0] (main.py 282): INFO Train: [97/300][20/78]	eta 0:02:19 lr 4.878950	time 1.2609 (2.4039)	loss 3.4537 (3.5640)	grad_norm 0.3494 (0.3215)	mem 39782MB
[2023-07-07 10:54:05 RepVGG-A0] (main.py 282): INFO Train: [97/300][30/78]	eta 0:01:42 lr 4.875291	time 1.4129 (2.1430)	loss 3.5866 (3.5546)	grad_norm 0.3804 (0.3323)	mem 39782MB
[2023-07-07 10:54:23 RepVGG-A0] (main.py 282): INFO Train: [97/300][40/78]	eta 0:01:18 lr 4.871629	time 3.5378 (2.0531)	loss 3.3705 (3.5438)	grad_norm 0.3200 (0.3301)	mem 39782MB
[2023-07-07 10:54:37 RepVGG-A0] (main.py 282): INFO Train: [97/300][50/78]	eta 0:00:54 lr 4.867964	time 1.1775 (1.9367)	loss 3.4608 (3.5415)	grad_norm 0.3250 (0.3386)	mem 39782MB
[2023-07-07 10:54:52 RepVGG-A0] (main.py 282): INFO Train: [97/300][60/78]	eta 0:00:33 lr 4.864296	time 1.1799 (1.8692)	loss 3.3752 (3.5259)	grad_norm 0.3264 (0.3380)	mem 39782MB
[2023-07-07 10:55:07 RepVGG-A0] (main.py 282): INFO Train: [97/300][70/78]	eta 0:00:14 lr 4.860625	time 1.1968 (1.8150)	loss 3.5468 (3.5184)	grad_norm 0.3968 (0.3426)	mem 39782MB
[2023-07-07 10:55:18 RepVGG-A0] (main.py 291): INFO EPOCH 97 training takes 0:02:20
[2023-07-07 10:55:40 RepVGG-A0] (main.py 282): INFO Train: [98/300][0/78]	eta 0:28:05 lr 4.857686	time 21.6130 (21.6130)	loss 3.3809 (3.3809)	grad_norm 0.3202 (0.3202)	mem 39782MB
[2023-07-07 10:55:54 RepVGG-A0] (main.py 282): INFO Train: [98/300][10/78]	eta 0:03:40 lr 4.854010	time 1.1925 (3.2449)	loss 3.5551 (3.4855)	grad_norm 0.3928 (0.4157)	mem 39782MB
[2023-07-07 10:56:09 RepVGG-A0] (main.py 282): INFO Train: [98/300][20/78]	eta 0:02:20 lr 4.850331	time 1.1739 (2.4250)	loss 3.3081 (3.4346)	grad_norm 0.3147 (0.3766)	mem 39782MB
[2023-07-07 10:56:24 RepVGG-A0] (main.py 282): INFO Train: [98/300][30/78]	eta 0:01:41 lr 4.846649	time 1.4316 (2.1235)	loss 3.3464 (3.4096)	grad_norm 0.3499 (0.3597)	mem 39782MB
[2023-07-07 10:56:42 RepVGG-A0] (main.py 282): INFO Train: [98/300][40/78]	eta 0:01:17 lr 4.842963	time 3.7182 (2.0503)	loss 3.4910 (3.4019)	grad_norm 0.4264 (0.3585)	mem 39782MB
[2023-07-07 10:56:57 RepVGG-A0] (main.py 282): INFO Train: [98/300][50/78]	eta 0:00:54 lr 4.839275	time 1.1719 (1.9424)	loss 3.5321 (3.4252)	grad_norm 0.3982 (0.3720)	mem 39782MB
[2023-07-07 10:57:13 RepVGG-A0] (main.py 282): INFO Train: [98/300][60/78]	eta 0:00:33 lr 4.835584	time 1.4640 (1.8731)	loss 3.3862 (3.4161)	grad_norm 0.3177 (0.3655)	mem 39782MB
[2023-07-07 10:57:28 RepVGG-A0] (main.py 282): INFO Train: [98/300][70/78]	eta 0:00:14 lr 4.831890	time 1.3530 (1.8210)	loss 3.3548 (3.4066)	grad_norm 0.3478 (0.3604)	mem 39782MB
[2023-07-07 10:57:40 RepVGG-A0] (main.py 291): INFO EPOCH 98 training takes 0:02:21
[2023-07-07 10:58:02 RepVGG-A0] (main.py 282): INFO Train: [99/300][0/78]	eta 0:28:05 lr 4.828933	time 21.6091 (21.6091)	loss 3.3224 (3.3224)	grad_norm 0.4066 (0.4066)	mem 39782MB
[2023-07-07 10:58:16 RepVGG-A0] (main.py 282): INFO Train: [99/300][10/78]	eta 0:03:40 lr 4.825233	time 1.1713 (3.2420)	loss 3.4106 (3.4350)	grad_norm 0.3805 (0.4299)	mem 39782MB
[2023-07-07 10:58:29 RepVGG-A0] (main.py 282): INFO Train: [99/300][20/78]	eta 0:02:15 lr 4.821531	time 1.1723 (2.3400)	loss 3.3073 (3.3701)	grad_norm 0.3074 (0.3755)	mem 39782MB
[2023-07-07 10:58:44 RepVGG-A0] (main.py 282): INFO Train: [99/300][30/78]	eta 0:01:38 lr 4.817826	time 1.3031 (2.0621)	loss 3.3841 (3.3585)	grad_norm 0.3995 (0.3717)	mem 39782MB
[2023-07-07 10:59:03 RepVGG-A0] (main.py 282): INFO Train: [99/300][40/78]	eta 0:01:16 lr 4.814117	time 4.4689 (2.0125)	loss 3.8334 (3.4138)	grad_norm 0.5800 (0.4067)	mem 39782MB
[2023-07-07 10:59:17 RepVGG-A0] (main.py 282): INFO Train: [99/300][50/78]	eta 0:00:53 lr 4.810406	time 1.2253 (1.9031)	loss 3.3774 (3.4347)	grad_norm 0.3095 (0.3978)	mem 39782MB
[2023-07-07 10:59:33 RepVGG-A0] (main.py 282): INFO Train: [99/300][60/78]	eta 0:00:33 lr 4.806692	time 1.1879 (1.8413)	loss 3.3059 (3.4222)	grad_norm 0.3078 (0.3838)	mem 39782MB
[2023-07-07 10:59:48 RepVGG-A0] (main.py 282): INFO Train: [99/300][70/78]	eta 0:00:14 lr 4.802976	time 1.2293 (1.7948)	loss 3.3121 (3.4110)	grad_norm 0.3218 (0.3770)	mem 39782MB
[2023-07-07 10:59:59 RepVGG-A0] (main.py 291): INFO EPOCH 99 training takes 0:02:18
[2023-07-07 11:00:20 RepVGG-A0] (main.py 282): INFO Train: [100/300][0/78]	eta 0:27:02 lr 4.800000	time 20.8051 (20.8051)	loss 3.2522 (3.2522)	grad_norm 0.3370 (0.3370)	mem 39782MB
[2023-07-07 11:00:33 RepVGG-A0] (main.py 282): INFO Train: [100/300][10/78]	eta 0:03:32 lr 4.796278	time 1.1728 (3.1320)	loss 3.2904 (3.2911)	grad_norm 0.3589 (0.3672)	mem 39782MB
[2023-07-07 11:00:48 RepVGG-A0] (main.py 282): INFO Train: [100/300][20/78]	eta 0:02:15 lr 4.792553	time 1.1717 (2.3340)	loss 3.3135 (3.2787)	grad_norm 0.3386 (0.3572)	mem 39782MB
[2023-07-07 11:01:03 RepVGG-A0] (main.py 282): INFO Train: [100/300][30/78]	eta 0:01:39 lr 4.788825	time 1.2664 (2.0793)	loss 3.3451 (3.2893)	grad_norm 0.3677 (0.3633)	mem 39782MB
[2023-07-07 11:01:21 RepVGG-A0] (main.py 282): INFO Train: [100/300][40/78]	eta 0:01:16 lr 4.785095	time 3.2602 (2.0028)	loss 3.4004 (3.2900)	grad_norm 0.3622 (0.3610)	mem 39782MB
[2023-07-07 11:01:36 RepVGG-A0] (main.py 282): INFO Train: [100/300][50/78]	eta 0:00:53 lr 4.781361	time 1.2909 (1.9043)	loss 3.4086 (3.2918)	grad_norm 0.3899 (0.3616)	mem 39782MB
[2023-07-07 11:01:51 RepVGG-A0] (main.py 282): INFO Train: [100/300][60/78]	eta 0:00:33 lr 4.777625	time 1.1961 (1.8357)	loss 3.2840 (3.2992)	grad_norm 0.3464 (0.3632)	mem 39782MB
[2023-07-07 11:02:06 RepVGG-A0] (main.py 282): INFO Train: [100/300][70/78]	eta 0:00:14 lr 4.773885	time 1.2132 (1.7928)	loss 3.3584 (3.3033)	grad_norm 0.4160 (0.3661)	mem 39782MB
[2023-07-07 11:02:18 RepVGG-A0] (main.py 291): INFO EPOCH 100 training takes 0:02:19
[2023-07-07 11:02:36 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.407 (17.407)	Loss 2.8196 (2.8196)	Acc@1 40.741 (40.741)	Acc@5 66.449 (66.449)	Mem 39782MB
[2023-07-07 11:02:37 RepVGG-A0] (main.py 342): INFO  * Acc@1 40.988 Acc@5 66.530
[2023-07-07 11:02:37 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 100: 40.988%
[2023-07-07 11:02:37 RepVGG-A0] (main.py 172): INFO Max accuracy: 40.99%
[2023-07-07 11:02:58 RepVGG-A0] (main.py 282): INFO Train: [101/300][0/78]	eta 0:27:23 lr 4.770892	time 21.0739 (21.0739)	loss 3.2136 (3.2136)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 11:03:15 RepVGG-A0] (main.py 282): INFO Train: [101/300][10/78]	eta 0:03:57 lr 4.767148	time 1.1762 (3.4942)	loss 3.3269 (3.2520)	grad_norm 0.3965 (0.3596)	mem 39782MB
[2023-07-07 11:03:29 RepVGG-A0] (main.py 282): INFO Train: [101/300][20/78]	eta 0:02:24 lr 4.763401	time 1.1762 (2.4874)	loss 3.2746 (3.2731)	grad_norm 0.3963 (0.3756)	mem 39782MB
[2023-07-07 11:03:45 RepVGG-A0] (main.py 282): INFO Train: [101/300][30/78]	eta 0:01:44 lr 4.759651	time 1.5057 (2.1873)	loss 3.3655 (3.2932)	grad_norm 0.3679 (0.3772)	mem 39782MB
[2023-07-07 11:04:03 RepVGG-A0] (main.py 282): INFO Train: [101/300][40/78]	eta 0:01:19 lr 4.755898	time 4.4255 (2.1030)	loss 3.2746 (3.2792)	grad_norm 0.3157 (0.3655)	mem 39782MB
[2023-07-07 11:04:17 RepVGG-A0] (main.py 282): INFO Train: [101/300][50/78]	eta 0:00:55 lr 4.752142	time 1.3047 (1.9696)	loss 6.4667 (3.5109)	grad_norm 0.9319 (0.4543)	mem 39782MB
[2023-07-07 11:04:33 RepVGG-A0] (main.py 282): INFO Train: [101/300][60/78]	eta 0:00:34 lr 4.748384	time 1.1943 (1.8957)	loss 5.4414 (3.9178)	grad_norm 0.3905 (0.4563)	mem 39782MB
[2023-07-07 11:04:48 RepVGG-A0] (main.py 282): INFO Train: [101/300][70/78]	eta 0:00:14 lr 4.744623	time 1.2888 (1.8462)	loss 4.8474 (4.0894)	grad_norm 0.2919 (0.4443)	mem 39782MB
[2023-07-07 11:04:59 RepVGG-A0] (main.py 291): INFO EPOCH 101 training takes 0:02:21
[2023-07-07 11:05:20 RepVGG-A0] (main.py 282): INFO Train: [102/300][0/78]	eta 0:27:35 lr 4.741612	time 21.2222 (21.2222)	loss 4.3266 (4.3266)	grad_norm 0.2890 (0.2890)	mem 39782MB
[2023-07-07 11:05:34 RepVGG-A0] (main.py 282): INFO Train: [102/300][10/78]	eta 0:03:41 lr 4.737846	time 1.1712 (3.2547)	loss 4.1492 (4.2647)	grad_norm 0.3381 (0.3161)	mem 39782MB
[2023-07-07 11:05:49 RepVGG-A0] (main.py 282): INFO Train: [102/300][20/78]	eta 0:02:18 lr 4.734077	time 1.1721 (2.3924)	loss 3.9915 (4.1709)	grad_norm 0.3016 (0.3182)	mem 39782MB
[2023-07-07 11:06:04 RepVGG-A0] (main.py 282): INFO Train: [102/300][30/78]	eta 0:01:41 lr 4.730305	time 1.5026 (2.1244)	loss 3.9717 (4.0884)	grad_norm 0.4031 (0.3212)	mem 39782MB
[2023-07-07 11:06:23 RepVGG-A0] (main.py 282): INFO Train: [102/300][40/78]	eta 0:01:18 lr 4.726530	time 3.8079 (2.0604)	loss 3.8248 (4.0194)	grad_norm 0.3427 (0.3224)	mem 39782MB
[2023-07-07 11:06:38 RepVGG-A0] (main.py 282): INFO Train: [102/300][50/78]	eta 0:00:54 lr 4.722753	time 1.1725 (1.9435)	loss 3.7497 (3.9624)	grad_norm 0.3630 (0.3240)	mem 39782MB
[2023-07-07 11:06:53 RepVGG-A0] (main.py 282): INFO Train: [102/300][60/78]	eta 0:00:33 lr 4.718973	time 1.1784 (1.8708)	loss 3.7009 (3.9199)	grad_norm 0.3410 (0.3284)	mem 39782MB
[2023-07-07 11:07:07 RepVGG-A0] (main.py 282): INFO Train: [102/300][70/78]	eta 0:00:14 lr 4.715191	time 1.5240 (1.8160)	loss 3.5810 (3.8720)	grad_norm 0.3241 (0.3260)	mem 39782MB
[2023-07-07 11:07:19 RepVGG-A0] (main.py 291): INFO EPOCH 102 training takes 0:02:20
[2023-07-07 11:07:42 RepVGG-A0] (main.py 282): INFO Train: [103/300][0/78]	eta 0:30:03 lr 4.712162	time 23.1176 (23.1176)	loss 3.6105 (3.6105)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 11:07:58 RepVGG-A0] (main.py 282): INFO Train: [103/300][10/78]	eta 0:04:02 lr 4.708375	time 1.2891 (3.5663)	loss 3.4289 (3.5222)	grad_norm 0.3307 (0.3436)	mem 39782MB
[2023-07-07 11:08:12 RepVGG-A0] (main.py 282): INFO Train: [103/300][20/78]	eta 0:02:27 lr 4.704585	time 1.1718 (2.5516)	loss 3.5984 (3.5249)	grad_norm 0.4160 (0.3458)	mem 39782MB
[2023-07-07 11:08:28 RepVGG-A0] (main.py 282): INFO Train: [103/300][30/78]	eta 0:01:47 lr 4.700791	time 1.4013 (2.2455)	loss 3.4797 (3.5164)	grad_norm 0.3507 (0.3477)	mem 39782MB
[2023-07-07 11:08:46 RepVGG-A0] (main.py 282): INFO Train: [103/300][40/78]	eta 0:01:20 lr 4.696996	time 4.0216 (2.1211)	loss 3.5837 (3.5167)	grad_norm 0.4226 (0.3557)	mem 39782MB
[2023-07-07 11:09:02 RepVGG-A0] (main.py 282): INFO Train: [103/300][50/78]	eta 0:00:56 lr 4.693197	time 1.3061 (2.0159)	loss 3.5409 (3.5107)	grad_norm 0.3632 (0.3557)	mem 39782MB
[2023-07-07 11:09:17 RepVGG-A0] (main.py 282): INFO Train: [103/300][60/78]	eta 0:00:34 lr 4.689396	time 1.3118 (1.9347)	loss 3.3361 (3.5015)	grad_norm 0.3377 (0.3563)	mem 39782MB
[2023-07-07 11:09:31 RepVGG-A0] (main.py 282): INFO Train: [103/300][70/78]	eta 0:00:14 lr 4.685592	time 1.3415 (1.8701)	loss 3.9073 (3.5260)	grad_norm 0.6074 (0.3754)	mem 39782MB
[2023-07-07 11:09:43 RepVGG-A0] (main.py 291): INFO EPOCH 103 training takes 0:02:24
[2023-07-07 11:10:05 RepVGG-A0] (main.py 282): INFO Train: [104/300][0/78]	eta 0:28:35 lr 4.682547	time 21.9890 (21.9890)	loss 3.5331 (3.5331)	grad_norm 0.3481 (0.3481)	mem 39782MB
[2023-07-07 11:10:21 RepVGG-A0] (main.py 282): INFO Train: [104/300][10/78]	eta 0:03:51 lr 4.678739	time 1.3228 (3.4108)	loss 3.2871 (3.4395)	grad_norm 0.2905 (0.3089)	mem 39782MB
[2023-07-07 11:10:36 RepVGG-A0] (main.py 282): INFO Train: [104/300][20/78]	eta 0:02:25 lr 4.674927	time 1.2692 (2.5141)	loss 3.3097 (3.4266)	grad_norm 0.3190 (0.3227)	mem 39782MB
[2023-07-07 11:10:52 RepVGG-A0] (main.py 282): INFO Train: [104/300][30/78]	eta 0:01:45 lr 4.671113	time 1.3920 (2.1965)	loss 3.4433 (3.4107)	grad_norm 0.4319 (0.3306)	mem 39782MB
[2023-07-07 11:11:09 RepVGG-A0] (main.py 282): INFO Train: [104/300][40/78]	eta 0:01:18 lr 4.667297	time 3.5089 (2.0788)	loss 3.3830 (3.4045)	grad_norm 0.3650 (0.3313)	mem 39782MB
[2023-07-07 11:11:23 RepVGG-A0] (main.py 282): INFO Train: [104/300][50/78]	eta 0:00:54 lr 4.663478	time 1.2325 (1.9615)	loss 3.2998 (3.3972)	grad_norm 0.3621 (0.3355)	mem 39782MB
[2023-07-07 11:11:39 RepVGG-A0] (main.py 282): INFO Train: [104/300][60/78]	eta 0:00:34 lr 4.659656	time 1.1747 (1.8969)	loss 3.3886 (3.3942)	grad_norm 0.4318 (0.3407)	mem 39782MB
[2023-07-07 11:11:54 RepVGG-A0] (main.py 282): INFO Train: [104/300][70/78]	eta 0:00:14 lr 4.655831	time 1.1735 (1.8402)	loss 5.5247 (3.5246)	grad_norm 0.8881 (0.3996)	mem 39782MB
[2023-07-07 11:12:06 RepVGG-A0] (main.py 291): INFO EPOCH 104 training takes 0:02:22
[2023-07-07 11:12:26 RepVGG-A0] (main.py 282): INFO Train: [105/300][0/78]	eta 0:26:12 lr 4.652770	time 20.1564 (20.1564)	loss 4.1797 (4.1797)	grad_norm 0.3295 (0.3295)	mem 39782MB
[2023-07-07 11:12:41 RepVGG-A0] (main.py 282): INFO Train: [105/300][10/78]	eta 0:03:35 lr 4.648940	time 1.1722 (3.1717)	loss 3.7135 (3.9142)	grad_norm 0.2783 (0.2920)	mem 39782MB
[2023-07-07 11:12:55 RepVGG-A0] (main.py 282): INFO Train: [105/300][20/78]	eta 0:02:15 lr 4.645108	time 1.1723 (2.3441)	loss 3.5210 (3.7776)	grad_norm 0.2957 (0.2914)	mem 39782MB
[2023-07-07 11:13:10 RepVGG-A0] (main.py 282): INFO Train: [105/300][30/78]	eta 0:01:38 lr 4.641274	time 1.3572 (2.0585)	loss 3.4539 (3.6758)	grad_norm 0.3138 (0.2870)	mem 39782MB
[2023-07-07 11:13:28 RepVGG-A0] (main.py 282): INFO Train: [105/300][40/78]	eta 0:01:15 lr 4.637437	time 3.4428 (1.9956)	loss 3.4553 (3.6157)	grad_norm 0.3247 (0.2892)	mem 39782MB
[2023-07-07 11:13:43 RepVGG-A0] (main.py 282): INFO Train: [105/300][50/78]	eta 0:00:53 lr 4.633597	time 1.1723 (1.9117)	loss 3.3198 (3.5768)	grad_norm 0.3176 (0.2935)	mem 39782MB
[2023-07-07 11:13:58 RepVGG-A0] (main.py 282): INFO Train: [105/300][60/78]	eta 0:00:33 lr 4.629755	time 1.3699 (1.8430)	loss 3.3550 (3.5423)	grad_norm 0.3564 (0.2974)	mem 39782MB
[2023-07-07 11:14:13 RepVGG-A0] (main.py 282): INFO Train: [105/300][70/78]	eta 0:00:14 lr 4.625910	time 1.2471 (1.7872)	loss 3.4536 (3.5202)	grad_norm 0.3480 (0.3017)	mem 39782MB
[2023-07-07 11:14:25 RepVGG-A0] (main.py 291): INFO EPOCH 105 training takes 0:02:19
[2023-07-07 11:14:46 RepVGG-A0] (main.py 282): INFO Train: [106/300][0/78]	eta 0:27:26 lr 4.622833	time 21.1105 (21.1105)	loss 3.3815 (3.3815)	grad_norm 0.4038 (0.4038)	mem 39782MB
[2023-07-07 11:15:01 RepVGG-A0] (main.py 282): INFO Train: [106/300][10/78]	eta 0:03:42 lr 4.618983	time 1.1729 (3.2781)	loss 3.4024 (3.3554)	grad_norm 0.3277 (0.3555)	mem 39782MB
[2023-07-07 11:15:15 RepVGG-A0] (main.py 282): INFO Train: [106/300][20/78]	eta 0:02:18 lr 4.615131	time 1.1731 (2.3912)	loss 3.2826 (3.3441)	grad_norm 0.3653 (0.3493)	mem 39782MB
[2023-07-07 11:15:31 RepVGG-A0] (main.py 282): INFO Train: [106/300][30/78]	eta 0:01:42 lr 4.611277	time 1.1854 (2.1370)	loss 3.4142 (3.3357)	grad_norm 0.3596 (0.3467)	mem 39782MB
[2023-07-07 11:15:49 RepVGG-A0] (main.py 282): INFO Train: [106/300][40/78]	eta 0:01:17 lr 4.607420	time 4.2328 (2.0459)	loss 3.4006 (3.3384)	grad_norm 0.3452 (0.3519)	mem 39782MB
[2023-07-07 11:16:04 RepVGG-A0] (main.py 282): INFO Train: [106/300][50/78]	eta 0:00:54 lr 4.603560	time 1.1720 (1.9427)	loss 3.3382 (3.3426)	grad_norm 0.3828 (0.3579)	mem 39782MB
[2023-07-07 11:16:19 RepVGG-A0] (main.py 282): INFO Train: [106/300][60/78]	eta 0:00:33 lr 4.599698	time 1.2926 (1.8770)	loss 3.3982 (3.3471)	grad_norm 0.3683 (0.3593)	mem 39782MB
[2023-07-07 11:16:34 RepVGG-A0] (main.py 282): INFO Train: [106/300][70/78]	eta 0:00:14 lr 4.595833	time 1.1723 (1.8203)	loss 3.2566 (3.3399)	grad_norm 0.3370 (0.3559)	mem 39782MB
[2023-07-07 11:16:47 RepVGG-A0] (main.py 291): INFO EPOCH 106 training takes 0:02:21
[2023-07-07 11:17:10 RepVGG-A0] (main.py 282): INFO Train: [107/300][0/78]	eta 0:29:44 lr 4.592740	time 22.8839 (22.8839)	loss 3.5163 (3.5163)	grad_norm 0.5276 (0.5276)	mem 39782MB
[2023-07-07 11:17:25 RepVGG-A0] (main.py 282): INFO Train: [107/300][10/78]	eta 0:03:55 lr 4.588870	time 1.1766 (3.4641)	loss 3.2483 (3.3908)	grad_norm 0.3273 (0.4080)	mem 39782MB
[2023-07-07 11:17:39 RepVGG-A0] (main.py 282): INFO Train: [107/300][20/78]	eta 0:02:25 lr 4.584999	time 1.3172 (2.5014)	loss 3.3068 (3.3386)	grad_norm 0.3680 (0.3765)	mem 39782MB
[2023-07-07 11:17:54 RepVGG-A0] (main.py 282): INFO Train: [107/300][30/78]	eta 0:01:45 lr 4.581124	time 1.2741 (2.1878)	loss 3.1985 (3.3230)	grad_norm 0.2996 (0.3620)	mem 39782MB
[2023-07-07 11:18:13 RepVGG-A0] (main.py 282): INFO Train: [107/300][40/78]	eta 0:01:19 lr 4.577248	time 3.6540 (2.1004)	loss 3.4440 (3.3381)	grad_norm 0.4557 (0.3777)	mem 39782MB
[2023-07-07 11:18:28 RepVGG-A0] (main.py 282): INFO Train: [107/300][50/78]	eta 0:00:55 lr 4.573369	time 1.1729 (1.9917)	loss 3.3232 (3.3564)	grad_norm 0.3145 (0.3829)	mem 39782MB
[2023-07-07 11:18:43 RepVGG-A0] (main.py 282): INFO Train: [107/300][60/78]	eta 0:00:34 lr 4.569487	time 1.4095 (1.9085)	loss 3.2408 (3.3339)	grad_norm 0.3167 (0.3693)	mem 39782MB
[2023-07-07 11:18:58 RepVGG-A0] (main.py 282): INFO Train: [107/300][70/78]	eta 0:00:14 lr 4.565603	time 1.1962 (1.8513)	loss 3.2649 (3.3280)	grad_norm 0.3865 (0.3690)	mem 39782MB
[2023-07-07 11:19:10 RepVGG-A0] (main.py 291): INFO EPOCH 107 training takes 0:02:23
[2023-07-07 11:19:32 RepVGG-A0] (main.py 282): INFO Train: [108/300][0/78]	eta 0:28:12 lr 4.562494	time 21.7015 (21.7015)	loss 3.2320 (3.2320)	grad_norm 0.3557 (0.3557)	mem 39782MB
[2023-07-07 11:19:46 RepVGG-A0] (main.py 282): INFO Train: [108/300][10/78]	eta 0:03:44 lr 4.558605	time 1.1716 (3.3034)	loss 3.3260 (3.3054)	grad_norm 0.3630 (0.3826)	mem 39782MB
[2023-07-07 11:20:01 RepVGG-A0] (main.py 282): INFO Train: [108/300][20/78]	eta 0:02:21 lr 4.554714	time 1.1752 (2.4367)	loss 3.1853 (3.2796)	grad_norm 0.3497 (0.3675)	mem 39782MB
[2023-07-07 11:20:17 RepVGG-A0] (main.py 282): INFO Train: [108/300][30/78]	eta 0:01:43 lr 4.550821	time 1.1998 (2.1578)	loss 3.6559 (3.3004)	grad_norm 0.6360 (0.3946)	mem 39782MB
[2023-07-07 11:20:34 RepVGG-A0] (main.py 282): INFO Train: [108/300][40/78]	eta 0:01:17 lr 4.546925	time 3.3836 (2.0518)	loss 6.1598 (3.7352)	grad_norm 0.7834 (0.5315)	mem 39782MB
[2023-07-07 11:20:49 RepVGG-A0] (main.py 282): INFO Train: [108/300][50/78]	eta 0:00:54 lr 4.543027	time 1.1836 (1.9314)	loss 4.7663 (4.0264)	grad_norm 0.3638 (0.5098)	mem 39782MB
[2023-07-07 11:21:03 RepVGG-A0] (main.py 282): INFO Train: [108/300][60/78]	eta 0:00:33 lr 4.539126	time 1.1956 (1.8560)	loss 4.1981 (4.0847)	grad_norm 0.3112 (0.4736)	mem 39782MB
[2023-07-07 11:21:19 RepVGG-A0] (main.py 282): INFO Train: [108/300][70/78]	eta 0:00:14 lr 4.535223	time 1.2217 (1.8116)	loss 3.9664 (4.0792)	grad_norm 0.3120 (0.4521)	mem 39782MB
[2023-07-07 11:21:31 RepVGG-A0] (main.py 291): INFO EPOCH 108 training takes 0:02:20
[2023-07-07 11:21:52 RepVGG-A0] (main.py 282): INFO Train: [109/300][0/78]	eta 0:27:21 lr 4.532099	time 21.0455 (21.0455)	loss 3.8222 (3.8222)	grad_norm 0.3026 (0.3026)	mem 39782MB
[2023-07-07 11:22:07 RepVGG-A0] (main.py 282): INFO Train: [109/300][10/78]	eta 0:03:43 lr 4.528191	time 1.1910 (3.2858)	loss 3.6527 (3.6742)	grad_norm 0.2990 (0.2913)	mem 39782MB
[2023-07-07 11:22:22 RepVGG-A0] (main.py 282): INFO Train: [109/300][20/78]	eta 0:02:20 lr 4.524281	time 1.1743 (2.4277)	loss 3.5642 (3.6519)	grad_norm 0.3674 (0.3030)	mem 39782MB
[2023-07-07 11:22:37 RepVGG-A0] (main.py 282): INFO Train: [109/300][30/78]	eta 0:01:42 lr 4.520369	time 1.3688 (2.1436)	loss 3.5439 (3.6393)	grad_norm 0.3363 (0.3214)	mem 39782MB
[2023-07-07 11:22:55 RepVGG-A0] (main.py 282): INFO Train: [109/300][40/78]	eta 0:01:18 lr 4.516454	time 2.7147 (2.0554)	loss 3.4661 (3.6070)	grad_norm 0.2979 (0.3182)	mem 39782MB
[2023-07-07 11:23:10 RepVGG-A0] (main.py 282): INFO Train: [109/300][50/78]	eta 0:00:54 lr 4.512537	time 1.3373 (1.9428)	loss 3.4634 (3.5752)	grad_norm 0.3396 (0.3165)	mem 39782MB
[2023-07-07 11:23:25 RepVGG-A0] (main.py 282): INFO Train: [109/300][60/78]	eta 0:00:33 lr 4.508618	time 1.1729 (1.8721)	loss 3.4147 (3.5565)	grad_norm 0.3085 (0.3234)	mem 39782MB
[2023-07-07 11:23:39 RepVGG-A0] (main.py 282): INFO Train: [109/300][70/78]	eta 0:00:14 lr 4.504696	time 1.1865 (1.8109)	loss 3.3432 (3.5392)	grad_norm 0.3000 (0.3251)	mem 39782MB
[2023-07-07 11:23:51 RepVGG-A0] (main.py 291): INFO EPOCH 109 training takes 0:02:20
[2023-07-07 11:24:11 RepVGG-A0] (main.py 282): INFO Train: [110/300][0/78]	eta 0:25:56 lr 4.501557	time 19.9512 (19.9512)	loss 3.4203 (3.4203)	grad_norm 0.3769 (0.3769)	mem 39782MB
[2023-07-07 11:24:28 RepVGG-A0] (main.py 282): INFO Train: [110/300][10/78]	eta 0:03:45 lr 4.497631	time 1.1722 (3.3105)	loss 3.4581 (3.4408)	grad_norm 0.3576 (0.3923)	mem 39782MB
[2023-07-07 11:24:43 RepVGG-A0] (main.py 282): INFO Train: [110/300][20/78]	eta 0:02:23 lr 4.493703	time 1.2661 (2.4711)	loss 3.3525 (3.3980)	grad_norm 0.3262 (0.3626)	mem 39782MB
[2023-07-07 11:24:58 RepVGG-A0] (main.py 282): INFO Train: [110/300][30/78]	eta 0:01:43 lr 4.489772	time 1.1973 (2.1467)	loss 3.4579 (3.3970)	grad_norm 0.3733 (0.3650)	mem 39782MB
[2023-07-07 11:25:16 RepVGG-A0] (main.py 282): INFO Train: [110/300][40/78]	eta 0:01:18 lr 4.485839	time 3.4113 (2.0746)	loss 3.3412 (3.3878)	grad_norm 0.3394 (0.3637)	mem 39782MB
[2023-07-07 11:25:30 RepVGG-A0] (main.py 282): INFO Train: [110/300][50/78]	eta 0:00:54 lr 4.481904	time 1.1921 (1.9358)	loss 3.3362 (3.3814)	grad_norm 0.3152 (0.3632)	mem 39782MB
[2023-07-07 11:25:45 RepVGG-A0] (main.py 282): INFO Train: [110/300][60/78]	eta 0:00:33 lr 4.477967	time 1.1719 (1.8588)	loss 3.4829 (3.3787)	grad_norm 0.4600 (0.3634)	mem 39782MB
[2023-07-07 11:26:00 RepVGG-A0] (main.py 282): INFO Train: [110/300][70/78]	eta 0:00:14 lr 4.474027	time 1.1716 (1.8108)	loss 5.7101 (3.5714)	grad_norm 0.7272 (0.4327)	mem 39782MB
[2023-07-07 11:26:11 RepVGG-A0] (main.py 291): INFO EPOCH 110 training takes 0:02:19
[2023-07-07 11:26:32 RepVGG-A0] (main.py 282): INFO Train: [111/300][0/78]	eta 0:28:12 lr 4.470873	time 21.7008 (21.7008)	loss 4.4901 (4.4901)	grad_norm 0.3477 (0.3477)	mem 39782MB
[2023-07-07 11:26:47 RepVGG-A0] (main.py 282): INFO Train: [111/300][10/78]	eta 0:03:41 lr 4.466929	time 1.1720 (3.2638)	loss 4.0337 (4.2379)	grad_norm 0.2552 (0.3349)	mem 39782MB
[2023-07-07 11:27:01 RepVGG-A0] (main.py 282): INFO Train: [111/300][20/78]	eta 0:02:19 lr 4.462983	time 1.2876 (2.4010)	loss 3.9138 (4.0524)	grad_norm 0.3483 (0.3131)	mem 39782MB
[2023-07-07 11:27:17 RepVGG-A0] (main.py 282): INFO Train: [111/300][30/78]	eta 0:01:42 lr 4.459034	time 1.4705 (2.1378)	loss 3.7354 (3.9395)	grad_norm 0.3363 (0.3081)	mem 39782MB
[2023-07-07 11:27:35 RepVGG-A0] (main.py 282): INFO Train: [111/300][40/78]	eta 0:01:17 lr 4.455084	time 4.4378 (2.0482)	loss 3.4583 (3.8484)	grad_norm 0.2866 (0.3069)	mem 39782MB
[2023-07-07 11:27:49 RepVGG-A0] (main.py 282): INFO Train: [111/300][50/78]	eta 0:00:54 lr 4.451130	time 1.3013 (1.9354)	loss 3.6144 (3.7888)	grad_norm 0.4533 (0.3089)	mem 39782MB
[2023-07-07 11:28:05 RepVGG-A0] (main.py 282): INFO Train: [111/300][60/78]	eta 0:00:33 lr 4.447175	time 1.3031 (1.8713)	loss 3.3440 (3.7470)	grad_norm 0.2819 (0.3109)	mem 39782MB
[2023-07-07 11:28:20 RepVGG-A0] (main.py 282): INFO Train: [111/300][70/78]	eta 0:00:14 lr 4.443218	time 1.3230 (1.8178)	loss 3.4330 (3.7025)	grad_norm 0.3564 (0.3111)	mem 39782MB
[2023-07-07 11:28:31 RepVGG-A0] (main.py 291): INFO EPOCH 111 training takes 0:02:20
[2023-07-07 11:28:52 RepVGG-A0] (main.py 282): INFO Train: [112/300][0/78]	eta 0:26:47 lr 4.440050	time 20.6094 (20.6094)	loss 3.4019 (3.4019)	grad_norm 0.2872 (0.2872)	mem 39782MB
[2023-07-07 11:29:08 RepVGG-A0] (main.py 282): INFO Train: [112/300][10/78]	eta 0:03:44 lr 4.436088	time 1.1722 (3.3057)	loss 3.3203 (3.3754)	grad_norm 0.2874 (0.3194)	mem 39782MB
[2023-07-07 11:29:23 RepVGG-A0] (main.py 282): INFO Train: [112/300][20/78]	eta 0:02:23 lr 4.432124	time 1.3974 (2.4749)	loss 3.5588 (3.4248)	grad_norm 0.4420 (0.3740)	mem 39782MB
[2023-07-07 11:29:39 RepVGG-A0] (main.py 282): INFO Train: [112/300][30/78]	eta 0:01:45 lr 4.428158	time 1.9433 (2.1926)	loss 3.3672 (3.4249)	grad_norm 0.3504 (0.3588)	mem 39782MB
[2023-07-07 11:29:57 RepVGG-A0] (main.py 282): INFO Train: [112/300][40/78]	eta 0:01:19 lr 4.424190	time 4.6894 (2.0810)	loss 3.4279 (3.4122)	grad_norm 0.3638 (0.3531)	mem 39782MB
[2023-07-07 11:30:11 RepVGG-A0] (main.py 282): INFO Train: [112/300][50/78]	eta 0:00:54 lr 4.420220	time 1.1737 (1.9446)	loss 3.3279 (3.4085)	grad_norm 0.3132 (0.3519)	mem 39782MB
[2023-07-07 11:30:26 RepVGG-A0] (main.py 282): INFO Train: [112/300][60/78]	eta 0:00:33 lr 4.416247	time 1.4291 (1.8782)	loss 3.4190 (3.4078)	grad_norm 0.4104 (0.3566)	mem 39782MB
[2023-07-07 11:30:41 RepVGG-A0] (main.py 282): INFO Train: [112/300][70/78]	eta 0:00:14 lr 4.412272	time 1.2862 (1.8294)	loss 3.3583 (3.4007)	grad_norm 0.3236 (0.3543)	mem 39782MB
[2023-07-07 11:30:53 RepVGG-A0] (main.py 291): INFO EPOCH 112 training takes 0:02:21
[2023-07-07 11:31:15 RepVGG-A0] (main.py 282): INFO Train: [113/300][0/78]	eta 0:29:18 lr 4.409091	time 22.5509 (22.5509)	loss 3.3544 (3.3544)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:31:29 RepVGG-A0] (main.py 282): INFO Train: [113/300][10/78]	eta 0:03:45 lr 4.405112	time 1.1719 (3.3162)	loss 3.4415 (3.3494)	grad_norm 0.4377 (0.3845)	mem 39782MB
[2023-07-07 11:31:44 RepVGG-A0] (main.py 282): INFO Train: [113/300][20/78]	eta 0:02:20 lr 4.401131	time 1.1745 (2.4296)	loss 3.3630 (3.3436)	grad_norm 0.3471 (0.3794)	mem 39782MB
[2023-07-07 11:31:58 RepVGG-A0] (main.py 282): INFO Train: [113/300][30/78]	eta 0:01:41 lr 4.397148	time 1.3083 (2.1148)	loss 3.2892 (3.3352)	grad_norm 0.3474 (0.3720)	mem 39782MB
[2023-07-07 11:32:17 RepVGG-A0] (main.py 282): INFO Train: [113/300][40/78]	eta 0:01:17 lr 4.393162	time 3.4041 (2.0422)	loss 3.2239 (3.3305)	grad_norm 0.3684 (0.3746)	mem 39782MB
[2023-07-07 11:32:32 RepVGG-A0] (main.py 282): INFO Train: [113/300][50/78]	eta 0:00:54 lr 4.389175	time 1.1789 (1.9404)	loss 3.3468 (3.3305)	grad_norm 0.3695 (0.3714)	mem 39782MB
[2023-07-07 11:32:47 RepVGG-A0] (main.py 282): INFO Train: [113/300][60/78]	eta 0:00:33 lr 4.385185	time 1.4300 (1.8697)	loss 3.3843 (3.3341)	grad_norm 0.4120 (0.3745)	mem 39782MB
[2023-07-07 11:33:02 RepVGG-A0] (main.py 282): INFO Train: [113/300][70/78]	eta 0:00:14 lr 4.381193	time 1.2777 (1.8169)	loss 3.3237 (3.3359)	grad_norm 0.3438 (0.3746)	mem 39782MB
[2023-07-07 11:33:13 RepVGG-A0] (main.py 291): INFO EPOCH 113 training takes 0:02:20
[2023-07-07 11:33:34 RepVGG-A0] (main.py 282): INFO Train: [114/300][0/78]	eta 0:27:44 lr 4.377999	time 21.3407 (21.3407)	loss 3.3718 (3.3718)	grad_norm 0.4531 (0.4531)	mem 39782MB
[2023-07-07 11:33:49 RepVGG-A0] (main.py 282): INFO Train: [114/300][10/78]	eta 0:03:43 lr 4.374003	time 1.1712 (3.2922)	loss 3.3621 (3.3533)	grad_norm 0.4236 (0.4216)	mem 39782MB
[2023-07-07 11:34:05 RepVGG-A0] (main.py 282): INFO Train: [114/300][20/78]	eta 0:02:23 lr 4.370005	time 1.2051 (2.4740)	loss 3.2665 (3.3203)	grad_norm 0.3482 (0.3937)	mem 39782MB
[2023-07-07 11:34:20 RepVGG-A0] (main.py 282): INFO Train: [114/300][30/78]	eta 0:01:43 lr 4.366006	time 1.3902 (2.1478)	loss 3.2180 (3.2903)	grad_norm 0.3508 (0.3768)	mem 39782MB
[2023-07-07 11:34:37 RepVGG-A0] (main.py 282): INFO Train: [114/300][40/78]	eta 0:01:17 lr 4.362004	time 3.1192 (2.0402)	loss 3.4472 (3.2993)	grad_norm 0.5292 (0.3844)	mem 39782MB
[2023-07-07 11:34:52 RepVGG-A0] (main.py 282): INFO Train: [114/300][50/78]	eta 0:00:54 lr 4.358000	time 1.1720 (1.9304)	loss 5.7423 (3.7116)	grad_norm 0.5064 (0.4853)	mem 39782MB
[2023-07-07 11:35:07 RepVGG-A0] (main.py 282): INFO Train: [114/300][60/78]	eta 0:00:33 lr 4.353994	time 1.1881 (1.8669)	loss 4.5043 (3.9188)	grad_norm 0.3221 (0.4664)	mem 39782MB
[2023-07-07 11:35:22 RepVGG-A0] (main.py 282): INFO Train: [114/300][70/78]	eta 0:00:14 lr 4.349985	time 1.3076 (1.8127)	loss 4.0044 (3.9697)	grad_norm 0.2630 (0.4472)	mem 39782MB
[2023-07-07 11:35:33 RepVGG-A0] (main.py 291): INFO EPOCH 114 training takes 0:02:20
[2023-07-07 11:35:55 RepVGG-A0] (main.py 282): INFO Train: [115/300][0/78]	eta 0:28:17 lr 4.346777	time 21.7628 (21.7628)	loss 3.8644 (3.8644)	grad_norm 0.3248 (0.3248)	mem 39782MB
[2023-07-07 11:36:11 RepVGG-A0] (main.py 282): INFO Train: [115/300][10/78]	eta 0:03:53 lr 4.342766	time 1.1707 (3.4280)	loss 3.7036 (3.7906)	grad_norm 0.3051 (0.3070)	mem 39782MB
[2023-07-07 11:36:25 RepVGG-A0] (main.py 282): INFO Train: [115/300][20/78]	eta 0:02:23 lr 4.338752	time 1.1875 (2.4717)	loss 3.5760 (3.7326)	grad_norm 0.2789 (0.3140)	mem 39782MB
[2023-07-07 11:36:42 RepVGG-A0] (main.py 282): INFO Train: [115/300][30/78]	eta 0:01:46 lr 4.334736	time 1.2349 (2.2190)	loss 3.5543 (3.6691)	grad_norm 0.3284 (0.3023)	mem 39782MB
[2023-07-07 11:36:58 RepVGG-A0] (main.py 282): INFO Train: [115/300][40/78]	eta 0:01:18 lr 4.330718	time 4.0563 (2.0735)	loss 3.5342 (3.6447)	grad_norm 0.3425 (0.3178)	mem 39782MB
[2023-07-07 11:37:13 RepVGG-A0] (main.py 282): INFO Train: [115/300][50/78]	eta 0:00:54 lr 4.326698	time 1.1726 (1.9567)	loss 3.4897 (3.6095)	grad_norm 0.3487 (0.3182)	mem 39782MB
[2023-07-07 11:37:28 RepVGG-A0] (main.py 282): INFO Train: [115/300][60/78]	eta 0:00:33 lr 4.322675	time 1.1833 (1.8754)	loss 3.5156 (3.5831)	grad_norm 0.3808 (0.3186)	mem 39782MB
[2023-07-07 11:37:43 RepVGG-A0] (main.py 282): INFO Train: [115/300][70/78]	eta 0:00:14 lr 4.318651	time 1.1728 (1.8291)	loss 3.4193 (3.5700)	grad_norm 0.3352 (0.3265)	mem 39782MB
[2023-07-07 11:37:55 RepVGG-A0] (main.py 291): INFO EPOCH 115 training takes 0:02:21
[2023-07-07 11:38:18 RepVGG-A0] (main.py 282): INFO Train: [116/300][0/78]	eta 0:29:26 lr 4.315431	time 22.6426 (22.6426)	loss 3.4197 (3.4197)	grad_norm 0.3650 (0.3650)	mem 39782MB
[2023-07-07 11:38:32 RepVGG-A0] (main.py 282): INFO Train: [116/300][10/78]	eta 0:03:49 lr 4.311403	time 1.1768 (3.3739)	loss 3.3338 (3.3692)	grad_norm 0.3171 (0.3505)	mem 39782MB
[2023-07-07 11:38:47 RepVGG-A0] (main.py 282): INFO Train: [116/300][20/78]	eta 0:02:23 lr 4.307373	time 1.1848 (2.4795)	loss 3.3817 (3.3660)	grad_norm 0.3678 (0.3540)	mem 39782MB
[2023-07-07 11:39:03 RepVGG-A0] (main.py 282): INFO Train: [116/300][30/78]	eta 0:01:44 lr 4.303341	time 1.1703 (2.1782)	loss 3.4653 (3.3633)	grad_norm 0.4433 (0.3512)	mem 39782MB
[2023-07-07 11:39:20 RepVGG-A0] (main.py 282): INFO Train: [116/300][40/78]	eta 0:01:19 lr 4.299308	time 3.9300 (2.0816)	loss 3.3900 (3.3755)	grad_norm 0.3991 (0.3630)	mem 39782MB
[2023-07-07 11:39:35 RepVGG-A0] (main.py 282): INFO Train: [116/300][50/78]	eta 0:00:54 lr 4.295272	time 1.1726 (1.9591)	loss 3.4850 (3.3789)	grad_norm 0.4535 (0.3668)	mem 39782MB
[2023-07-07 11:39:50 RepVGG-A0] (main.py 282): INFO Train: [116/300][60/78]	eta 0:00:34 lr 4.291234	time 1.1363 (1.8909)	loss 3.4021 (3.3764)	grad_norm 0.3718 (0.3664)	mem 39782MB
[2023-07-07 11:40:06 RepVGG-A0] (main.py 282): INFO Train: [116/300][70/78]	eta 0:00:14 lr 4.287194	time 1.1368 (1.8433)	loss 3.3307 (3.3690)	grad_norm 0.3259 (0.3620)	mem 39782MB
[2023-07-07 11:40:17 RepVGG-A0] (main.py 291): INFO EPOCH 116 training takes 0:02:22
[2023-07-07 11:40:39 RepVGG-A0] (main.py 282): INFO Train: [117/300][0/78]	eta 0:28:15 lr 4.283961	time 21.7328 (21.7328)	loss 3.2655 (3.2655)	grad_norm 0.3688 (0.3688)	mem 39782MB
[2023-07-07 11:40:53 RepVGG-A0] (main.py 282): INFO Train: [117/300][10/78]	eta 0:03:41 lr 4.279918	time 1.1717 (3.2619)	loss 3.4242 (3.3096)	grad_norm 0.5023 (0.3819)	mem 39782MB
[2023-07-07 11:41:08 RepVGG-A0] (main.py 282): INFO Train: [117/300][20/78]	eta 0:02:19 lr 4.275873	time 1.1745 (2.4053)	loss 3.7765 (3.5358)	grad_norm 0.5983 (0.4939)	mem 39782MB
[2023-07-07 11:41:23 RepVGG-A0] (main.py 282): INFO Train: [117/300][30/78]	eta 0:01:41 lr 4.271826	time 1.4149 (2.1141)	loss 3.3646 (3.5428)	grad_norm 0.2836 (0.4522)	mem 39782MB
[2023-07-07 11:41:42 RepVGG-A0] (main.py 282): INFO Train: [117/300][40/78]	eta 0:01:18 lr 4.267777	time 4.6548 (2.0690)	loss 3.2657 (3.4846)	grad_norm 0.3041 (0.4120)	mem 39782MB
[2023-07-07 11:41:56 RepVGG-A0] (main.py 282): INFO Train: [117/300][50/78]	eta 0:00:54 lr 4.263726	time 1.1763 (1.9401)	loss 3.3033 (3.4484)	grad_norm 0.3454 (0.3936)	mem 39782MB
[2023-07-07 11:42:12 RepVGG-A0] (main.py 282): INFO Train: [117/300][60/78]	eta 0:00:33 lr 4.259673	time 1.2692 (1.8808)	loss 3.2567 (3.4173)	grad_norm 0.3274 (0.3820)	mem 39782MB
[2023-07-07 11:42:27 RepVGG-A0] (main.py 282): INFO Train: [117/300][70/78]	eta 0:00:14 lr 4.255618	time 1.2861 (1.8248)	loss 3.3338 (3.3964)	grad_norm 0.3250 (0.3736)	mem 39782MB
[2023-07-07 11:42:38 RepVGG-A0] (main.py 291): INFO EPOCH 117 training takes 0:02:21
[2023-07-07 11:43:00 RepVGG-A0] (main.py 282): INFO Train: [118/300][0/78]	eta 0:28:12 lr 4.252373	time 21.7032 (21.7032)	loss 3.2165 (3.2165)	grad_norm 0.4037 (0.4037)	mem 39782MB
[2023-07-07 11:43:14 RepVGG-A0] (main.py 282): INFO Train: [118/300][10/78]	eta 0:03:40 lr 4.248315	time 1.1740 (3.2413)	loss 3.2361 (3.2462)	grad_norm 0.3842 (0.3773)	mem 39782MB
[2023-07-07 11:43:29 RepVGG-A0] (main.py 282): INFO Train: [118/300][20/78]	eta 0:02:20 lr 4.244255	time 1.1735 (2.4276)	loss 3.3132 (3.2586)	grad_norm 0.4043 (0.3773)	mem 39782MB
[2023-07-07 11:43:45 RepVGG-A0] (main.py 282): INFO Train: [118/300][30/78]	eta 0:01:42 lr 4.240193	time 1.7963 (2.1429)	loss 3.2135 (3.2568)	grad_norm 0.3339 (0.3742)	mem 39782MB
[2023-07-07 11:44:02 RepVGG-A0] (main.py 282): INFO Train: [118/300][40/78]	eta 0:01:17 lr 4.236129	time 3.8867 (2.0414)	loss 3.4489 (3.2682)	grad_norm 0.4177 (0.3778)	mem 39782MB
[2023-07-07 11:44:17 RepVGG-A0] (main.py 282): INFO Train: [118/300][50/78]	eta 0:00:54 lr 4.232064	time 1.1729 (1.9420)	loss 3.4011 (3.2699)	grad_norm 0.4319 (0.3776)	mem 39782MB
[2023-07-07 11:44:32 RepVGG-A0] (main.py 282): INFO Train: [118/300][60/78]	eta 0:00:33 lr 4.227996	time 1.2929 (1.8714)	loss 3.2585 (3.2800)	grad_norm 0.3622 (0.3796)	mem 39782MB
[2023-07-07 11:44:48 RepVGG-A0] (main.py 282): INFO Train: [118/300][70/78]	eta 0:00:14 lr 4.223927	time 1.4377 (1.8252)	loss 3.2618 (3.2759)	grad_norm 0.3388 (0.3744)	mem 39782MB
[2023-07-07 11:45:00 RepVGG-A0] (main.py 291): INFO EPOCH 118 training takes 0:02:21
[2023-07-07 11:45:21 RepVGG-A0] (main.py 282): INFO Train: [119/300][0/78]	eta 0:27:44 lr 4.220670	time 21.3369 (21.3369)	loss 3.2844 (3.2844)	grad_norm 0.4124 (0.4124)	mem 39782MB
[2023-07-07 11:45:36 RepVGG-A0] (main.py 282): INFO Train: [119/300][10/78]	eta 0:03:45 lr 4.216597	time 1.1963 (3.3201)	loss 3.2908 (3.3028)	grad_norm 0.4046 (0.4327)	mem 39782MB
[2023-07-07 11:45:52 RepVGG-A0] (main.py 282): INFO Train: [119/300][20/78]	eta 0:02:24 lr 4.212523	time 1.3528 (2.4912)	loss 3.2783 (3.2850)	grad_norm 0.3663 (0.3993)	mem 39782MB
[2023-07-07 11:46:07 RepVGG-A0] (main.py 282): INFO Train: [119/300][30/78]	eta 0:01:43 lr 4.208446	time 1.5533 (2.1602)	loss 3.2717 (3.2635)	grad_norm 0.3449 (0.3821)	mem 39782MB
[2023-07-07 11:46:25 RepVGG-A0] (main.py 282): INFO Train: [119/300][40/78]	eta 0:01:19 lr 4.204368	time 3.6264 (2.0832)	loss 3.8070 (3.3086)	grad_norm 0.7106 (0.4147)	mem 39782MB
[2023-07-07 11:46:40 RepVGG-A0] (main.py 282): INFO Train: [119/300][50/78]	eta 0:00:55 lr 4.200288	time 1.1779 (1.9674)	loss 4.5428 (3.5624)	grad_norm 0.5672 (0.4931)	mem 39782MB
[2023-07-07 11:46:55 RepVGG-A0] (main.py 282): INFO Train: [119/300][60/78]	eta 0:00:33 lr 4.196206	time 1.1822 (1.8832)	loss 3.7314 (3.6244)	grad_norm 0.2740 (0.4655)	mem 39782MB
[2023-07-07 11:47:10 RepVGG-A0] (main.py 282): INFO Train: [119/300][70/78]	eta 0:00:14 lr 4.192123	time 1.3249 (1.8334)	loss 3.5195 (3.6253)	grad_norm 0.2807 (0.4434)	mem 39782MB
[2023-07-07 11:47:23 RepVGG-A0] (main.py 291): INFO EPOCH 119 training takes 0:02:22
[2023-07-07 11:47:44 RepVGG-A0] (main.py 282): INFO Train: [120/300][0/78]	eta 0:27:30 lr 4.188854	time 21.1574 (21.1574)	loss 3.3888 (3.3888)	grad_norm 0.2635 (0.2635)	mem 39782MB
[2023-07-07 11:48:00 RepVGG-A0] (main.py 282): INFO Train: [120/300][10/78]	eta 0:03:48 lr 4.184768	time 1.1882 (3.3531)	loss 3.3445 (3.2821)	grad_norm 0.2956 (0.2783)	mem 39782MB
[2023-07-07 11:48:14 RepVGG-A0] (main.py 282): INFO Train: [120/300][20/78]	eta 0:02:20 lr 4.180679	time 1.1986 (2.4211)	loss 3.2659 (3.2757)	grad_norm 0.3431 (0.2922)	mem 39782MB
[2023-07-07 11:48:28 RepVGG-A0] (main.py 282): INFO Train: [120/300][30/78]	eta 0:01:41 lr 4.176589	time 1.3321 (2.1191)	loss 3.2034 (3.2686)	grad_norm 0.2969 (0.2938)	mem 39782MB
[2023-07-07 11:48:46 RepVGG-A0] (main.py 282): INFO Train: [120/300][40/78]	eta 0:01:17 lr 4.172497	time 4.0757 (2.0358)	loss 3.2670 (3.2637)	grad_norm 0.3494 (0.3035)	mem 39782MB
[2023-07-07 11:49:02 RepVGG-A0] (main.py 282): INFO Train: [120/300][50/78]	eta 0:00:54 lr 4.168403	time 1.1891 (1.9393)	loss 3.2254 (3.2607)	grad_norm 0.3221 (0.3095)	mem 39782MB
[2023-07-07 11:49:16 RepVGG-A0] (main.py 282): INFO Train: [120/300][60/78]	eta 0:00:33 lr 4.164307	time 1.2223 (1.8633)	loss 3.2580 (3.2569)	grad_norm 0.3574 (0.3145)	mem 39782MB
[2023-07-07 11:49:31 RepVGG-A0] (main.py 282): INFO Train: [120/300][70/78]	eta 0:00:14 lr 4.160210	time 1.2764 (1.8061)	loss 3.2476 (3.2646)	grad_norm 0.3350 (0.3239)	mem 39782MB
[2023-07-07 11:49:43 RepVGG-A0] (main.py 291): INFO EPOCH 120 training takes 0:02:19
[2023-07-07 11:50:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.841 (17.841)	Loss 2.7981 (2.7981)	Acc@1 41.357 (41.357)	Acc@5 67.542 (67.542)	Mem 39782MB
[2023-07-07 11:50:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 41.654 Acc@5 67.390
[2023-07-07 11:50:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 120: 41.654%
[2023-07-07 11:50:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 11:50:24 RepVGG-A0] (main.py 282): INFO Train: [121/300][0/78]	eta 0:28:47 lr 4.156931	time 22.1492 (22.1492)	loss 3.2775 (3.2775)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:50:39 RepVGG-A0] (main.py 282): INFO Train: [121/300][10/78]	eta 0:03:49 lr 4.152830	time 1.1743 (3.3780)	loss 3.1415 (3.1997)	grad_norm 0.3425 (0.3579)	mem 39782MB
[2023-07-07 11:50:54 RepVGG-A0] (main.py 282): INFO Train: [121/300][20/78]	eta 0:02:25 lr 4.148728	time 1.1796 (2.5044)	loss 3.3195 (3.2259)	grad_norm 0.4370 (0.3791)	mem 39782MB
[2023-07-07 11:51:10 RepVGG-A0] (main.py 282): INFO Train: [121/300][30/78]	eta 0:01:45 lr 4.144624	time 1.6078 (2.1939)	loss 3.2128 (3.2179)	grad_norm 0.3754 (0.3653)	mem 39782MB
[2023-07-07 11:51:28 RepVGG-A0] (main.py 282): INFO Train: [121/300][40/78]	eta 0:01:19 lr 4.140518	time 2.3303 (2.1030)	loss 3.1880 (3.2237)	grad_norm 0.3326 (0.3670)	mem 39782MB
[2023-07-07 11:51:43 RepVGG-A0] (main.py 282): INFO Train: [121/300][50/78]	eta 0:00:55 lr 4.136411	time 1.2883 (1.9876)	loss 3.3085 (3.2227)	grad_norm 0.3987 (0.3655)	mem 39782MB
[2023-07-07 11:51:58 RepVGG-A0] (main.py 282): INFO Train: [121/300][60/78]	eta 0:00:34 lr 4.132302	time 1.1738 (1.9017)	loss 3.2096 (3.2296)	grad_norm 0.3280 (0.3717)	mem 39782MB
[2023-07-07 11:52:12 RepVGG-A0] (main.py 282): INFO Train: [121/300][70/78]	eta 0:00:14 lr 4.128191	time 1.6797 (1.8344)	loss 3.3049 (3.2279)	grad_norm 0.4218 (0.3689)	mem 39782MB
[2023-07-07 11:52:23 RepVGG-A0] (main.py 291): INFO EPOCH 121 training takes 0:02:21
[2023-07-07 11:52:43 RepVGG-A0] (main.py 282): INFO Train: [122/300][0/78]	eta 0:26:37 lr 4.124902	time 20.4864 (20.4864)	loss 3.1941 (3.1941)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 11:52:59 RepVGG-A0] (main.py 282): INFO Train: [122/300][10/78]	eta 0:03:40 lr 4.120788	time 1.1708 (3.2440)	loss 3.1744 (3.2451)	grad_norm 0.3633 (0.4267)	mem 39782MB
[2023-07-07 11:53:15 RepVGG-A0] (main.py 282): INFO Train: [122/300][20/78]	eta 0:02:22 lr 4.116673	time 1.1805 (2.4549)	loss 3.1924 (3.2104)	grad_norm 0.3262 (0.3902)	mem 39782MB
[2023-07-07 11:53:30 RepVGG-A0] (main.py 282): INFO Train: [122/300][30/78]	eta 0:01:43 lr 4.112556	time 1.7389 (2.1503)	loss 3.3069 (3.2107)	grad_norm 0.4414 (0.3851)	mem 39782MB
[2023-07-07 11:53:49 RepVGG-A0] (main.py 282): INFO Train: [122/300][40/78]	eta 0:01:19 lr 4.108437	time 5.4851 (2.0893)	loss 3.1420 (3.2103)	grad_norm 0.3652 (0.3833)	mem 39782MB
[2023-07-07 11:54:03 RepVGG-A0] (main.py 282): INFO Train: [122/300][50/78]	eta 0:00:55 lr 4.104317	time 1.1768 (1.9697)	loss 3.3022 (3.2089)	grad_norm 0.4328 (0.3792)	mem 39782MB
[2023-07-07 11:54:19 RepVGG-A0] (main.py 282): INFO Train: [122/300][60/78]	eta 0:00:34 lr 4.100195	time 1.2579 (1.9092)	loss 3.1719 (3.2128)	grad_norm 0.3409 (0.3807)	mem 39782MB
[2023-07-07 11:54:34 RepVGG-A0] (main.py 282): INFO Train: [122/300][70/78]	eta 0:00:14 lr 4.096072	time 1.2092 (1.8524)	loss 3.2316 (3.2110)	grad_norm 0.4102 (0.3791)	mem 39782MB
[2023-07-07 11:54:45 RepVGG-A0] (main.py 291): INFO EPOCH 122 training takes 0:02:21
[2023-07-07 11:55:06 RepVGG-A0] (main.py 282): INFO Train: [123/300][0/78]	eta 0:28:02 lr 4.092772	time 21.5683 (21.5683)	loss 3.2322 (3.2322)	grad_norm 0.4251 (0.4251)	mem 39782MB
[2023-07-07 11:55:21 RepVGG-A0] (main.py 282): INFO Train: [123/300][10/78]	eta 0:03:44 lr 4.088645	time 1.1928 (3.2980)	loss 3.1104 (3.2332)	grad_norm 0.3225 (0.4078)	mem 39782MB
[2023-07-07 11:55:36 RepVGG-A0] (main.py 282): INFO Train: [123/300][20/78]	eta 0:02:21 lr 4.084517	time 1.1735 (2.4420)	loss 3.1878 (3.1939)	grad_norm 0.3635 (0.3850)	mem 39782MB
[2023-07-07 11:55:51 RepVGG-A0] (main.py 282): INFO Train: [123/300][30/78]	eta 0:01:41 lr 4.080388	time 1.2056 (2.1219)	loss 3.7438 (3.2151)	grad_norm 0.7181 (0.4055)	mem 39782MB
[2023-07-07 11:56:09 RepVGG-A0] (main.py 282): INFO Train: [123/300][40/78]	eta 0:01:17 lr 4.076256	time 4.0646 (2.0462)	loss 5.6199 (3.8045)	grad_norm 0.5610 (0.5285)	mem 39782MB
[2023-07-07 11:56:24 RepVGG-A0] (main.py 282): INFO Train: [123/300][50/78]	eta 0:00:54 lr 4.072124	time 1.1709 (1.9336)	loss 4.4708 (3.9993)	grad_norm 0.3829 (0.4949)	mem 39782MB
[2023-07-07 11:56:38 RepVGG-A0] (main.py 282): INFO Train: [123/300][60/78]	eta 0:00:33 lr 4.067989	time 1.1793 (1.8517)	loss 4.0024 (4.0362)	grad_norm 0.2804 (0.4687)	mem 39782MB
[2023-07-07 11:56:53 RepVGG-A0] (main.py 282): INFO Train: [123/300][70/78]	eta 0:00:14 lr 4.063853	time 1.5658 (1.8039)	loss 3.8041 (4.0114)	grad_norm 0.2780 (0.4430)	mem 39782MB
[2023-07-07 11:57:05 RepVGG-A0] (main.py 291): INFO EPOCH 123 training takes 0:02:19
[2023-07-07 11:57:26 RepVGG-A0] (main.py 282): INFO Train: [124/300][0/78]	eta 0:27:22 lr 4.060543	time 21.0552 (21.0552)	loss 3.6534 (3.6534)	grad_norm 0.3113 (0.3113)	mem 39782MB
[2023-07-07 11:57:40 RepVGG-A0] (main.py 282): INFO Train: [124/300][10/78]	eta 0:03:38 lr 4.056405	time 1.1701 (3.2155)	loss 3.4201 (3.5717)	grad_norm 0.2768 (0.3000)	mem 39782MB
[2023-07-07 11:57:55 RepVGG-A0] (main.py 282): INFO Train: [124/300][20/78]	eta 0:02:19 lr 4.052264	time 1.3393 (2.4048)	loss 3.5987 (3.5451)	grad_norm 0.3314 (0.3120)	mem 39782MB
[2023-07-07 11:58:11 RepVGG-A0] (main.py 282): INFO Train: [124/300][30/78]	eta 0:01:43 lr 4.048123	time 1.2754 (2.1508)	loss 3.4754 (3.5134)	grad_norm 0.3085 (0.3089)	mem 39782MB
[2023-07-07 11:58:29 RepVGG-A0] (main.py 282): INFO Train: [124/300][40/78]	eta 0:01:18 lr 4.043979	time 2.0426 (2.0586)	loss 3.4753 (3.5028)	grad_norm 0.3648 (0.3243)	mem 39782MB
[2023-07-07 11:58:45 RepVGG-A0] (main.py 282): INFO Train: [124/300][50/78]	eta 0:00:54 lr 4.039835	time 1.1779 (1.9615)	loss 3.4197 (3.4864)	grad_norm 0.3472 (0.3260)	mem 39782MB
[2023-07-07 11:58:59 RepVGG-A0] (main.py 282): INFO Train: [124/300][60/78]	eta 0:00:33 lr 4.035688	time 1.3807 (1.8802)	loss 3.4807 (3.4764)	grad_norm 0.3672 (0.3340)	mem 39782MB
[2023-07-07 11:59:15 RepVGG-A0] (main.py 282): INFO Train: [124/300][70/78]	eta 0:00:14 lr 4.031540	time 1.1944 (1.8310)	loss 3.4677 (3.4615)	grad_norm 0.3971 (0.3335)	mem 39782MB
[2023-07-07 11:59:26 RepVGG-A0] (main.py 291): INFO EPOCH 124 training takes 0:02:21
[2023-07-07 11:59:46 RepVGG-A0] (main.py 282): INFO Train: [125/300][0/78]	eta 0:26:27 lr 4.028221	time 20.3526 (20.3526)	loss 3.4487 (3.4487)	grad_norm 0.4339 (0.4339)	mem 39782MB
[2023-07-07 12:00:00 RepVGG-A0] (main.py 282): INFO Train: [125/300][10/78]	eta 0:03:33 lr 4.024070	time 1.1731 (3.1409)	loss 3.3219 (3.3171)	grad_norm 0.4142 (0.3486)	mem 39782MB
[2023-07-07 12:00:15 RepVGG-A0] (main.py 282): INFO Train: [125/300][20/78]	eta 0:02:15 lr 4.019918	time 1.1718 (2.3431)	loss 3.3076 (3.3319)	grad_norm 0.3500 (0.3644)	mem 39782MB
[2023-07-07 12:00:30 RepVGG-A0] (main.py 282): INFO Train: [125/300][30/78]	eta 0:01:39 lr 4.015765	time 1.3347 (2.0825)	loss 3.2944 (3.3152)	grad_norm 0.3681 (0.3536)	mem 39782MB
[2023-07-07 12:00:48 RepVGG-A0] (main.py 282): INFO Train: [125/300][40/78]	eta 0:01:16 lr 4.011610	time 4.0709 (2.0169)	loss 3.2675 (3.3237)	grad_norm 0.3332 (0.3625)	mem 39782MB
[2023-07-07 12:01:03 RepVGG-A0] (main.py 282): INFO Train: [125/300][50/78]	eta 0:00:53 lr 4.007453	time 1.1745 (1.9166)	loss 3.2692 (3.3175)	grad_norm 0.3658 (0.3631)	mem 39782MB
[2023-07-07 12:01:18 RepVGG-A0] (main.py 282): INFO Train: [125/300][60/78]	eta 0:00:33 lr 4.003296	time 1.4649 (1.8478)	loss 3.3843 (3.3139)	grad_norm 0.4948 (0.3656)	mem 39782MB
[2023-07-07 12:01:34 RepVGG-A0] (main.py 282): INFO Train: [125/300][70/78]	eta 0:00:14 lr 3.999136	time 1.1882 (1.8045)	loss 3.2988 (3.3188)	grad_norm 0.3758 (0.3696)	mem 39782MB
[2023-07-07 12:01:46 RepVGG-A0] (main.py 291): INFO EPOCH 125 training takes 0:02:19
[2023-07-07 12:02:09 RepVGG-A0] (main.py 282): INFO Train: [126/300][0/78]	eta 0:29:56 lr 3.995808	time 23.0267 (23.0267)	loss 3.2427 (3.2427)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 12:02:23 RepVGG-A0] (main.py 282): INFO Train: [126/300][10/78]	eta 0:03:48 lr 3.991646	time 1.1729 (3.3605)	loss 3.2715 (3.2228)	grad_norm 0.4313 (0.3699)	mem 39782MB
[2023-07-07 12:02:36 RepVGG-A0] (main.py 282): INFO Train: [126/300][20/78]	eta 0:02:20 lr 3.987482	time 1.2344 (2.4138)	loss 4.1817 (3.4885)	grad_norm 0.7351 (0.5165)	mem 39782MB
[2023-07-07 12:02:51 RepVGG-A0] (main.py 282): INFO Train: [126/300][30/78]	eta 0:01:40 lr 3.983318	time 1.1772 (2.1012)	loss 3.5315 (3.5953)	grad_norm 0.2850 (0.4961)	mem 39782MB
[2023-07-07 12:03:10 RepVGG-A0] (main.py 282): INFO Train: [126/300][40/78]	eta 0:01:17 lr 3.979151	time 4.5594 (2.0516)	loss 3.3441 (3.5447)	grad_norm 0.2782 (0.4436)	mem 39782MB
[2023-07-07 12:03:24 RepVGG-A0] (main.py 282): INFO Train: [126/300][50/78]	eta 0:00:54 lr 3.974984	time 1.1735 (1.9350)	loss 3.2126 (3.4920)	grad_norm 0.3118 (0.4131)	mem 39782MB
[2023-07-07 12:03:40 RepVGG-A0] (main.py 282): INFO Train: [126/300][60/78]	eta 0:00:33 lr 3.970815	time 1.4935 (1.8761)	loss 3.1916 (3.4501)	grad_norm 0.2914 (0.3957)	mem 39782MB
[2023-07-07 12:03:56 RepVGG-A0] (main.py 282): INFO Train: [126/300][70/78]	eta 0:00:14 lr 3.966644	time 1.6346 (1.8297)	loss 3.2468 (3.4158)	grad_norm 0.3286 (0.3824)	mem 39782MB
[2023-07-07 12:04:07 RepVGG-A0] (main.py 291): INFO EPOCH 126 training takes 0:02:21
[2023-07-07 12:04:27 RepVGG-A0] (main.py 282): INFO Train: [127/300][0/78]	eta 0:26:35 lr 3.963307	time 20.4581 (20.4581)	loss 3.2264 (3.2264)	grad_norm 0.3726 (0.3726)	mem 39782MB
[2023-07-07 12:04:42 RepVGG-A0] (main.py 282): INFO Train: [127/300][10/78]	eta 0:03:37 lr 3.959134	time 1.3358 (3.2042)	loss 3.0292 (3.1824)	grad_norm 0.2905 (0.3446)	mem 39782MB
[2023-07-07 12:04:59 RepVGG-A0] (main.py 282): INFO Train: [127/300][20/78]	eta 0:02:24 lr 3.954960	time 1.4442 (2.4956)	loss 3.3061 (3.2136)	grad_norm 0.4340 (0.3657)	mem 39782MB
[2023-07-07 12:05:15 RepVGG-A0] (main.py 282): INFO Train: [127/300][30/78]	eta 0:01:44 lr 3.950784	time 1.2702 (2.1842)	loss 3.1623 (3.2122)	grad_norm 0.3447 (0.3619)	mem 39782MB
[2023-07-07 12:05:32 RepVGG-A0] (main.py 282): INFO Train: [127/300][40/78]	eta 0:01:18 lr 3.946607	time 1.6192 (2.0671)	loss 3.1662 (3.2013)	grad_norm 0.3421 (0.3549)	mem 39782MB
[2023-07-07 12:05:46 RepVGG-A0] (main.py 282): INFO Train: [127/300][50/78]	eta 0:00:54 lr 3.942429	time 1.1904 (1.9320)	loss 3.1565 (3.2065)	grad_norm 0.3641 (0.3589)	mem 39782MB
[2023-07-07 12:06:01 RepVGG-A0] (main.py 282): INFO Train: [127/300][60/78]	eta 0:00:33 lr 3.938249	time 1.1747 (1.8662)	loss 3.2321 (3.2069)	grad_norm 0.3602 (0.3625)	mem 39782MB
[2023-07-07 12:06:16 RepVGG-A0] (main.py 282): INFO Train: [127/300][70/78]	eta 0:00:14 lr 3.934069	time 1.4490 (1.8141)	loss 3.2539 (3.2048)	grad_norm 0.3669 (0.3619)	mem 39782MB
[2023-07-07 12:06:27 RepVGG-A0] (main.py 291): INFO EPOCH 127 training takes 0:02:19
[2023-07-07 12:06:47 RepVGG-A0] (main.py 282): INFO Train: [128/300][0/78]	eta 0:26:36 lr 3.930723	time 20.4672 (20.4672)	loss 3.2205 (3.2205)	grad_norm 0.4096 (0.4096)	mem 39782MB
[2023-07-07 12:07:02 RepVGG-A0] (main.py 282): INFO Train: [128/300][10/78]	eta 0:03:37 lr 3.926539	time 1.1734 (3.1984)	loss 3.3504 (3.1803)	grad_norm 0.5200 (0.3976)	mem 39782MB
[2023-07-07 12:07:17 RepVGG-A0] (main.py 282): INFO Train: [128/300][20/78]	eta 0:02:18 lr 3.922355	time 1.1737 (2.3802)	loss 3.2762 (3.2412)	grad_norm 0.3907 (0.4163)	mem 39782MB
[2023-07-07 12:07:32 RepVGG-A0] (main.py 282): INFO Train: [128/300][30/78]	eta 0:01:41 lr 3.918169	time 1.3589 (2.1049)	loss 3.2063 (3.2244)	grad_norm 0.3474 (0.3936)	mem 39782MB
[2023-07-07 12:07:49 RepVGG-A0] (main.py 282): INFO Train: [128/300][40/78]	eta 0:01:16 lr 3.913982	time 1.9648 (2.0095)	loss 3.1888 (3.2070)	grad_norm 0.3579 (0.3849)	mem 39782MB
[2023-07-07 12:08:04 RepVGG-A0] (main.py 282): INFO Train: [128/300][50/78]	eta 0:00:53 lr 3.909793	time 1.1717 (1.9092)	loss 3.4869 (3.2381)	grad_norm 0.5066 (0.4082)	mem 39782MB
[2023-07-07 12:08:20 RepVGG-A0] (main.py 282): INFO Train: [128/300][60/78]	eta 0:00:33 lr 3.905603	time 1.3121 (1.8500)	loss 3.2513 (3.2527)	grad_norm 0.3325 (0.4079)	mem 39782MB
[2023-07-07 12:08:35 RepVGG-A0] (main.py 282): INFO Train: [128/300][70/78]	eta 0:00:14 lr 3.901412	time 1.3427 (1.7987)	loss 3.1533 (3.2423)	grad_norm 0.3498 (0.3960)	mem 39782MB
[2023-07-07 12:08:46 RepVGG-A0] (main.py 291): INFO EPOCH 128 training takes 0:02:19
[2023-07-07 12:09:07 RepVGG-A0] (main.py 282): INFO Train: [129/300][0/78]	eta 0:26:50 lr 3.898058	time 20.6526 (20.6526)	loss 3.1093 (3.1093)	grad_norm 0.3332 (0.3332)	mem 39782MB
[2023-07-07 12:09:22 RepVGG-A0] (main.py 282): INFO Train: [129/300][10/78]	eta 0:03:44 lr 3.893865	time 1.1725 (3.2945)	loss 3.1638 (3.1246)	grad_norm 0.3821 (0.3543)	mem 39782MB
[2023-07-07 12:09:37 RepVGG-A0] (main.py 282): INFO Train: [129/300][20/78]	eta 0:02:20 lr 3.889670	time 1.1384 (2.4301)	loss 3.1499 (3.1282)	grad_norm 0.3358 (0.3566)	mem 39782MB
[2023-07-07 12:09:53 RepVGG-A0] (main.py 282): INFO Train: [129/300][30/78]	eta 0:01:43 lr 3.885475	time 1.4383 (2.1530)	loss 3.2739 (3.1379)	grad_norm 0.3979 (0.3596)	mem 39782MB
[2023-07-07 12:10:11 RepVGG-A0] (main.py 282): INFO Train: [129/300][40/78]	eta 0:01:18 lr 3.881277	time 4.1828 (2.0727)	loss 3.3904 (3.1996)	grad_norm 0.4657 (0.3996)	mem 39782MB
[2023-07-07 12:10:26 RepVGG-A0] (main.py 282): INFO Train: [129/300][50/78]	eta 0:00:55 lr 3.877079	time 1.2950 (1.9657)	loss 3.1611 (3.2080)	grad_norm 0.3066 (0.3906)	mem 39782MB
[2023-07-07 12:10:41 RepVGG-A0] (main.py 282): INFO Train: [129/300][60/78]	eta 0:00:33 lr 3.872880	time 1.4304 (1.8802)	loss 3.1385 (3.2025)	grad_norm 0.3338 (0.3834)	mem 39782MB
[2023-07-07 12:10:56 RepVGG-A0] (main.py 282): INFO Train: [129/300][70/78]	eta 0:00:14 lr 3.868679	time 1.3835 (1.8242)	loss 3.2026 (3.1962)	grad_norm 0.3892 (0.3804)	mem 39782MB
[2023-07-07 12:11:07 RepVGG-A0] (main.py 291): INFO EPOCH 129 training takes 0:02:20
[2023-07-07 12:11:28 RepVGG-A0] (main.py 282): INFO Train: [130/300][0/78]	eta 0:26:53 lr 3.865317	time 20.6923 (20.6923)	loss 3.1505 (3.1505)	grad_norm 0.3896 (0.3896)	mem 39782MB
[2023-07-07 12:11:43 RepVGG-A0] (main.py 282): INFO Train: [130/300][10/78]	eta 0:03:42 lr 3.861114	time 1.1912 (3.2746)	loss 3.1692 (3.1055)	grad_norm 0.4363 (0.3777)	mem 39782MB
[2023-07-07 12:11:58 RepVGG-A0] (main.py 282): INFO Train: [130/300][20/78]	eta 0:02:20 lr 3.856910	time 1.1751 (2.4290)	loss 3.2233 (3.1450)	grad_norm 0.3774 (0.3877)	mem 39782MB
[2023-07-07 12:12:14 RepVGG-A0] (main.py 282): INFO Train: [130/300][30/78]	eta 0:01:43 lr 3.852705	time 1.1961 (2.1526)	loss 3.1771 (3.1678)	grad_norm 0.3818 (0.4039)	mem 39782MB
[2023-07-07 12:12:31 RepVGG-A0] (main.py 282): INFO Train: [130/300][40/78]	eta 0:01:18 lr 3.848499	time 3.7135 (2.0584)	loss 3.0932 (3.1625)	grad_norm 0.3226 (0.3881)	mem 39782MB
[2023-07-07 12:12:46 RepVGG-A0] (main.py 282): INFO Train: [130/300][50/78]	eta 0:00:54 lr 3.844291	time 1.1728 (1.9444)	loss 3.1425 (3.1620)	grad_norm 0.3681 (0.3855)	mem 39782MB
[2023-07-07 12:13:00 RepVGG-A0] (main.py 282): INFO Train: [130/300][60/78]	eta 0:00:33 lr 3.840082	time 1.2107 (1.8533)	loss 3.2353 (3.1634)	grad_norm 0.4122 (0.3846)	mem 39782MB
[2023-07-07 12:13:16 RepVGG-A0] (main.py 282): INFO Train: [130/300][70/78]	eta 0:00:14 lr 3.835872	time 1.2102 (1.8086)	loss 3.3246 (3.1719)	grad_norm 0.4715 (0.3867)	mem 39782MB
[2023-07-07 12:13:27 RepVGG-A0] (main.py 291): INFO EPOCH 130 training takes 0:02:19
[2023-07-07 12:13:49 RepVGG-A0] (main.py 282): INFO Train: [131/300][0/78]	eta 0:29:04 lr 3.832503	time 22.3631 (22.3631)	loss 3.1775 (3.1775)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 12:14:04 RepVGG-A0] (main.py 282): INFO Train: [131/300][10/78]	eta 0:03:50 lr 3.828291	time 1.1716 (3.3969)	loss 3.0637 (3.1490)	grad_norm 0.3330 (0.3943)	mem 39782MB
[2023-07-07 12:14:18 RepVGG-A0] (main.py 282): INFO Train: [131/300][20/78]	eta 0:02:22 lr 3.824078	time 1.1722 (2.4581)	loss 3.1053 (3.1283)	grad_norm 0.3571 (0.3748)	mem 39782MB
[2023-07-07 12:14:34 RepVGG-A0] (main.py 282): INFO Train: [131/300][30/78]	eta 0:01:44 lr 3.819864	time 1.2831 (2.1688)	loss 3.1571 (3.1299)	grad_norm 0.4180 (0.3766)	mem 39782MB
[2023-07-07 12:14:52 RepVGG-A0] (main.py 282): INFO Train: [131/300][40/78]	eta 0:01:19 lr 3.815649	time 4.1116 (2.0866)	loss 3.1073 (3.1473)	grad_norm 0.4111 (0.3874)	mem 39782MB
[2023-07-07 12:15:07 RepVGG-A0] (main.py 282): INFO Train: [131/300][50/78]	eta 0:00:54 lr 3.811432	time 1.1739 (1.9619)	loss 3.1097 (3.1482)	grad_norm 0.3226 (0.3814)	mem 39782MB
[2023-07-07 12:15:22 RepVGG-A0] (main.py 282): INFO Train: [131/300][60/78]	eta 0:00:34 lr 3.807215	time 1.5165 (1.8904)	loss 3.1091 (3.1515)	grad_norm 0.4056 (0.3848)	mem 39782MB
[2023-07-07 12:15:36 RepVGG-A0] (main.py 282): INFO Train: [131/300][70/78]	eta 0:00:14 lr 3.802996	time 1.3418 (1.8231)	loss 3.1710 (3.1583)	grad_norm 0.3524 (0.3884)	mem 39782MB
[2023-07-07 12:15:48 RepVGG-A0] (main.py 291): INFO EPOCH 131 training takes 0:02:21
[2023-07-07 12:16:10 RepVGG-A0] (main.py 282): INFO Train: [132/300][0/78]	eta 0:27:52 lr 3.799620	time 21.4409 (21.4409)	loss 3.0930 (3.0930)	grad_norm 0.3986 (0.3986)	mem 39782MB
[2023-07-07 12:16:25 RepVGG-A0] (main.py 282): INFO Train: [132/300][10/78]	eta 0:03:49 lr 3.795400	time 1.1730 (3.3733)	loss 3.0750 (3.1010)	grad_norm 0.3565 (0.3877)	mem 39782MB
[2023-07-07 12:16:41 RepVGG-A0] (main.py 282): INFO Train: [132/300][20/78]	eta 0:02:24 lr 3.791178	time 1.1746 (2.4927)	loss 3.1067 (3.0922)	grad_norm 0.4164 (0.3764)	mem 39782MB
[2023-07-07 12:16:56 RepVGG-A0] (main.py 282): INFO Train: [132/300][30/78]	eta 0:01:45 lr 3.786955	time 1.3816 (2.1903)	loss 3.1849 (3.1218)	grad_norm 0.4345 (0.3963)	mem 39782MB
[2023-07-07 12:17:14 RepVGG-A0] (main.py 282): INFO Train: [132/300][40/78]	eta 0:01:19 lr 3.782731	time 4.0710 (2.0949)	loss 3.1700 (3.1289)	grad_norm 0.3607 (0.3917)	mem 39782MB
[2023-07-07 12:17:30 RepVGG-A0] (main.py 282): INFO Train: [132/300][50/78]	eta 0:00:55 lr 3.778506	time 1.2388 (1.9882)	loss 3.1192 (3.1339)	grad_norm 0.3569 (0.3917)	mem 39782MB
[2023-07-07 12:17:45 RepVGG-A0] (main.py 282): INFO Train: [132/300][60/78]	eta 0:00:34 lr 3.774280	time 1.4255 (1.9142)	loss 3.2053 (3.1353)	grad_norm 0.4383 (0.3900)	mem 39782MB
[2023-07-07 12:18:01 RepVGG-A0] (main.py 282): INFO Train: [132/300][70/78]	eta 0:00:14 lr 3.770053	time 1.1830 (1.8730)	loss 3.1155 (3.1400)	grad_norm 0.3495 (0.3890)	mem 39782MB
[2023-07-07 12:18:13 RepVGG-A0] (main.py 291): INFO EPOCH 132 training takes 0:02:24
[2023-07-07 12:18:35 RepVGG-A0] (main.py 282): INFO Train: [133/300][0/78]	eta 0:27:39 lr 3.766671	time 21.2729 (21.2729)	loss 3.1005 (3.1005)	grad_norm 0.4493 (0.4493)	mem 39782MB
[2023-07-07 12:18:50 RepVGG-A0] (main.py 282): INFO Train: [133/300][10/78]	eta 0:03:48 lr 3.762442	time 1.1882 (3.3676)	loss 3.1550 (3.1466)	grad_norm 0.3868 (0.4279)	mem 39782MB
[2023-07-07 12:19:04 RepVGG-A0] (main.py 282): INFO Train: [133/300][20/78]	eta 0:02:21 lr 3.758213	time 1.1787 (2.4346)	loss 3.0540 (3.1139)	grad_norm 0.3395 (0.3970)	mem 39782MB
[2023-07-07 12:19:20 RepVGG-A0] (main.py 282): INFO Train: [133/300][30/78]	eta 0:01:44 lr 3.753982	time 1.3337 (2.1669)	loss 3.2590 (3.1114)	grad_norm 0.5089 (0.3999)	mem 39782MB
[2023-07-07 12:19:38 RepVGG-A0] (main.py 282): INFO Train: [133/300][40/78]	eta 0:01:18 lr 3.749750	time 2.9335 (2.0775)	loss 3.3001 (3.1540)	grad_norm 0.4644 (0.4221)	mem 39782MB
[2023-07-07 12:19:53 RepVGG-A0] (main.py 282): INFO Train: [133/300][50/78]	eta 0:00:54 lr 3.745517	time 1.1739 (1.9611)	loss 3.1699 (3.1636)	grad_norm 0.3405 (0.4122)	mem 39782MB
[2023-07-07 12:20:08 RepVGG-A0] (main.py 282): INFO Train: [133/300][60/78]	eta 0:00:34 lr 3.741283	time 1.3157 (1.8895)	loss 3.0951 (3.1609)	grad_norm 0.3420 (0.4020)	mem 39782MB
[2023-07-07 12:20:24 RepVGG-A0] (main.py 282): INFO Train: [133/300][70/78]	eta 0:00:14 lr 3.737049	time 1.2801 (1.8381)	loss 3.1645 (3.1542)	grad_norm 0.3681 (0.3957)	mem 39782MB
[2023-07-07 12:20:35 RepVGG-A0] (main.py 291): INFO EPOCH 133 training takes 0:02:21
[2023-07-07 12:20:56 RepVGG-A0] (main.py 282): INFO Train: [134/300][0/78]	eta 0:27:51 lr 3.733660	time 21.4319 (21.4319)	loss 3.0615 (3.0615)	grad_norm 0.4067 (0.4067)	mem 39782MB
[2023-07-07 12:21:10 RepVGG-A0] (main.py 282): INFO Train: [134/300][10/78]	eta 0:03:34 lr 3.729423	time 1.1926 (3.1482)	loss 3.1203 (3.0846)	grad_norm 0.3856 (0.3913)	mem 39782MB
[2023-07-07 12:21:24 RepVGG-A0] (main.py 282): INFO Train: [134/300][20/78]	eta 0:02:15 lr 3.725186	time 1.1723 (2.3396)	loss 3.0263 (3.0919)	grad_norm 0.3655 (0.3833)	mem 39782MB
[2023-07-07 12:21:39 RepVGG-A0] (main.py 282): INFO Train: [134/300][30/78]	eta 0:01:38 lr 3.720948	time 1.1729 (2.0556)	loss 3.0535 (3.0973)	grad_norm 0.3957 (0.3810)	mem 39782MB
[2023-07-07 12:21:58 RepVGG-A0] (main.py 282): INFO Train: [134/300][40/78]	eta 0:01:16 lr 3.716708	time 4.1556 (2.0216)	loss 3.1806 (3.0986)	grad_norm 0.4246 (0.3872)	mem 39782MB
[2023-07-07 12:22:13 RepVGG-A0] (main.py 282): INFO Train: [134/300][50/78]	eta 0:00:53 lr 3.712468	time 1.1933 (1.9200)	loss 3.1205 (3.1075)	grad_norm 0.3637 (0.3909)	mem 39782MB
[2023-07-07 12:22:27 RepVGG-A0] (main.py 282): INFO Train: [134/300][60/78]	eta 0:00:33 lr 3.708227	time 1.1735 (1.8429)	loss 3.0514 (3.1072)	grad_norm 0.3580 (0.3857)	mem 39782MB
[2023-07-07 12:22:42 RepVGG-A0] (main.py 282): INFO Train: [134/300][70/78]	eta 0:00:14 lr 3.703985	time 1.2308 (1.7939)	loss 3.2002 (3.1138)	grad_norm 0.4400 (0.3887)	mem 39782MB
[2023-07-07 12:22:56 RepVGG-A0] (main.py 291): INFO EPOCH 134 training takes 0:02:20
[2023-07-07 12:23:17 RepVGG-A0] (main.py 282): INFO Train: [135/300][0/78]	eta 0:27:41 lr 3.700590	time 21.2950 (21.2950)	loss 3.0752 (3.0752)	grad_norm 0.3975 (0.3975)	mem 39782MB
[2023-07-07 12:23:31 RepVGG-A0] (main.py 282): INFO Train: [135/300][10/78]	eta 0:03:38 lr 3.696347	time 1.1714 (3.2083)	loss 2.9868 (3.0345)	grad_norm 0.3464 (0.3517)	mem 39782MB
[2023-07-07 12:23:46 RepVGG-A0] (main.py 282): INFO Train: [135/300][20/78]	eta 0:02:20 lr 3.692102	time 1.1726 (2.4240)	loss 3.3436 (3.1007)	grad_norm 0.5393 (0.4071)	mem 39782MB
[2023-07-07 12:24:02 RepVGG-A0] (main.py 282): INFO Train: [135/300][30/78]	eta 0:01:42 lr 3.687856	time 1.4000 (2.1341)	loss 3.0900 (3.1218)	grad_norm 0.3365 (0.4024)	mem 39782MB
[2023-07-07 12:24:20 RepVGG-A0] (main.py 282): INFO Train: [135/300][40/78]	eta 0:01:17 lr 3.683610	time 3.6071 (2.0522)	loss 3.0153 (3.1167)	grad_norm 0.3426 (0.3885)	mem 39782MB
[2023-07-07 12:24:35 RepVGG-A0] (main.py 282): INFO Train: [135/300][50/78]	eta 0:00:54 lr 3.679363	time 1.1806 (1.9437)	loss 3.0300 (3.1118)	grad_norm 0.3445 (0.3864)	mem 39782MB
[2023-07-07 12:24:50 RepVGG-A0] (main.py 282): INFO Train: [135/300][60/78]	eta 0:00:33 lr 3.675115	time 1.3816 (1.8715)	loss 3.0625 (3.0997)	grad_norm 0.3513 (0.3794)	mem 39782MB
[2023-07-07 12:25:04 RepVGG-A0] (main.py 282): INFO Train: [135/300][70/78]	eta 0:00:14 lr 3.670866	time 1.1549 (1.8144)	loss 3.1552 (3.1137)	grad_norm 0.4666 (0.3906)	mem 39782MB
[2023-07-07 12:25:17 RepVGG-A0] (main.py 291): INFO EPOCH 135 training takes 0:02:20
[2023-07-07 12:25:38 RepVGG-A0] (main.py 282): INFO Train: [136/300][0/78]	eta 0:28:24 lr 3.667466	time 21.8519 (21.8519)	loss 3.0289 (3.0289)	grad_norm 0.3493 (0.3493)	mem 39782MB
[2023-07-07 12:25:53 RepVGG-A0] (main.py 282): INFO Train: [136/300][10/78]	eta 0:03:47 lr 3.663215	time 1.1997 (3.3484)	loss 3.0895 (3.0506)	grad_norm 0.3979 (0.3630)	mem 39782MB
[2023-07-07 12:26:08 RepVGG-A0] (main.py 282): INFO Train: [136/300][20/78]	eta 0:02:22 lr 3.658964	time 1.1707 (2.4504)	loss 3.0754 (3.0569)	grad_norm 0.3678 (0.3712)	mem 39782MB
[2023-07-07 12:26:24 RepVGG-A0] (main.py 282): INFO Train: [136/300][30/78]	eta 0:01:43 lr 3.654712	time 1.4754 (2.1642)	loss 3.0556 (3.0588)	grad_norm 0.3802 (0.3806)	mem 39782MB
[2023-07-07 12:26:41 RepVGG-A0] (main.py 282): INFO Train: [136/300][40/78]	eta 0:01:18 lr 3.650459	time 3.0631 (2.0617)	loss 3.1240 (3.0669)	grad_norm 0.3895 (0.3786)	mem 39782MB
[2023-07-07 12:26:56 RepVGG-A0] (main.py 282): INFO Train: [136/300][50/78]	eta 0:00:54 lr 3.646205	time 1.2338 (1.9560)	loss 3.1806 (3.0790)	grad_norm 0.4674 (0.3877)	mem 39782MB
[2023-07-07 12:27:11 RepVGG-A0] (main.py 282): INFO Train: [136/300][60/78]	eta 0:00:33 lr 3.641950	time 1.2696 (1.8687)	loss 3.0571 (3.0856)	grad_norm 0.3659 (0.3899)	mem 39782MB
[2023-07-07 12:27:26 RepVGG-A0] (main.py 282): INFO Train: [136/300][70/78]	eta 0:00:14 lr 3.637695	time 1.2983 (1.8233)	loss 3.0260 (3.0864)	grad_norm 0.3520 (0.3849)	mem 39782MB
[2023-07-07 12:27:37 RepVGG-A0] (main.py 291): INFO EPOCH 136 training takes 0:02:20
[2023-07-07 12:27:59 RepVGG-A0] (main.py 282): INFO Train: [137/300][0/78]	eta 0:28:04 lr 3.634290	time 21.5928 (21.5928)	loss 3.0769 (3.0769)	grad_norm 0.3797 (0.3797)	mem 39782MB
[2023-07-07 12:28:14 RepVGG-A0] (main.py 282): INFO Train: [137/300][10/78]	eta 0:03:44 lr 3.630033	time 1.1719 (3.3061)	loss 3.1189 (3.1252)	grad_norm 0.4715 (0.4509)	mem 39782MB
[2023-07-07 12:28:28 RepVGG-A0] (main.py 282): INFO Train: [137/300][20/78]	eta 0:02:20 lr 3.625775	time 1.1732 (2.4141)	loss 3.0330 (3.1175)	grad_norm 0.4067 (0.4225)	mem 39782MB
[2023-07-07 12:28:45 RepVGG-A0] (main.py 282): INFO Train: [137/300][30/78]	eta 0:01:44 lr 3.621517	time 1.2384 (2.1836)	loss 3.0996 (3.1011)	grad_norm 0.3459 (0.3985)	mem 39782MB
[2023-07-07 12:29:02 RepVGG-A0] (main.py 282): INFO Train: [137/300][40/78]	eta 0:01:18 lr 3.617258	time 3.4854 (2.0579)	loss 3.1788 (3.1011)	grad_norm 0.3950 (0.3992)	mem 39782MB
[2023-07-07 12:29:16 RepVGG-A0] (main.py 282): INFO Train: [137/300][50/78]	eta 0:00:54 lr 3.612998	time 1.1746 (1.9413)	loss 3.1469 (3.1061)	grad_norm 0.4106 (0.4028)	mem 39782MB
[2023-07-07 12:29:32 RepVGG-A0] (main.py 282): INFO Train: [137/300][60/78]	eta 0:00:33 lr 3.608737	time 1.3476 (1.8718)	loss 3.1004 (3.1039)	grad_norm 0.3766 (0.3988)	mem 39782MB
[2023-07-07 12:29:48 RepVGG-A0] (main.py 282): INFO Train: [137/300][70/78]	eta 0:00:14 lr 3.604476	time 1.3782 (1.8388)	loss 3.0198 (3.1008)	grad_norm 0.3647 (0.3944)	mem 39782MB
[2023-07-07 12:29:59 RepVGG-A0] (main.py 291): INFO EPOCH 137 training takes 0:02:21
[2023-07-07 12:30:20 RepVGG-A0] (main.py 282): INFO Train: [138/300][0/78]	eta 0:27:47 lr 3.601066	time 21.3742 (21.3742)	loss 2.9875 (2.9875)	grad_norm 0.3662 (0.3662)	mem 39782MB
[2023-07-07 12:30:35 RepVGG-A0] (main.py 282): INFO Train: [138/300][10/78]	eta 0:03:44 lr 3.596804	time 1.1733 (3.2999)	loss 3.1346 (3.1127)	grad_norm 0.4469 (0.4457)	mem 39782MB
[2023-07-07 12:30:50 RepVGG-A0] (main.py 282): INFO Train: [138/300][20/78]	eta 0:02:21 lr 3.592540	time 1.1728 (2.4374)	loss 3.0374 (3.0824)	grad_norm 0.3703 (0.4149)	mem 39782MB
[2023-07-07 12:31:05 RepVGG-A0] (main.py 282): INFO Train: [138/300][30/78]	eta 0:01:42 lr 3.588276	time 1.3676 (2.1282)	loss 3.1028 (3.0674)	grad_norm 0.4117 (0.4038)	mem 39782MB
[2023-07-07 12:31:23 RepVGG-A0] (main.py 282): INFO Train: [138/300][40/78]	eta 0:01:17 lr 3.584011	time 4.0877 (2.0480)	loss 3.0729 (3.0679)	grad_norm 0.3636 (0.3978)	mem 39782MB
[2023-07-07 12:31:38 RepVGG-A0] (main.py 282): INFO Train: [138/300][50/78]	eta 0:00:54 lr 3.579746	time 1.1928 (1.9365)	loss 2.9814 (3.0616)	grad_norm 0.3665 (0.3944)	mem 39782MB
[2023-07-07 12:31:53 RepVGG-A0] (main.py 282): INFO Train: [138/300][60/78]	eta 0:00:33 lr 3.575480	time 1.2473 (1.8751)	loss 3.1632 (3.0671)	grad_norm 0.4636 (0.3988)	mem 39782MB
[2023-07-07 12:32:09 RepVGG-A0] (main.py 282): INFO Train: [138/300][70/78]	eta 0:00:14 lr 3.571213	time 1.4120 (1.8269)	loss 3.2534 (3.0865)	grad_norm 0.3824 (0.4076)	mem 39782MB
[2023-07-07 12:32:20 RepVGG-A0] (main.py 291): INFO EPOCH 138 training takes 0:02:21
[2023-07-07 12:32:41 RepVGG-A0] (main.py 282): INFO Train: [139/300][0/78]	eta 0:27:10 lr 3.567799	time 20.9059 (20.9059)	loss 2.9766 (2.9766)	grad_norm 0.3523 (0.3523)	mem 39782MB
[2023-07-07 12:32:56 RepVGG-A0] (main.py 282): INFO Train: [139/300][10/78]	eta 0:03:42 lr 3.563531	time 1.1900 (3.2724)	loss 3.0792 (3.0614)	grad_norm 0.3781 (0.3952)	mem 39782MB
[2023-07-07 12:33:12 RepVGG-A0] (main.py 282): INFO Train: [139/300][20/78]	eta 0:02:23 lr 3.559262	time 1.1406 (2.4722)	loss 3.0610 (3.0480)	grad_norm 0.4609 (0.3871)	mem 39782MB
[2023-07-07 12:33:25 RepVGG-A0] (main.py 282): INFO Train: [139/300][30/78]	eta 0:01:40 lr 3.554993	time 1.2880 (2.1033)	loss 2.9589 (3.0564)	grad_norm 0.3551 (0.3905)	mem 39782MB
[2023-07-07 12:33:43 RepVGG-A0] (main.py 282): INFO Train: [139/300][40/78]	eta 0:01:16 lr 3.550723	time 3.3079 (2.0237)	loss 3.0703 (3.0558)	grad_norm 0.4109 (0.3861)	mem 39782MB
[2023-07-07 12:33:59 RepVGG-A0] (main.py 282): INFO Train: [139/300][50/78]	eta 0:00:54 lr 3.546452	time 1.1714 (1.9389)	loss 2.9331 (3.0532)	grad_norm 0.3252 (0.3840)	mem 39782MB
[2023-07-07 12:34:14 RepVGG-A0] (main.py 282): INFO Train: [139/300][60/78]	eta 0:00:33 lr 3.542181	time 1.2707 (1.8660)	loss 3.1389 (3.0618)	grad_norm 0.4667 (0.3906)	mem 39782MB
[2023-07-07 12:34:29 RepVGG-A0] (main.py 282): INFO Train: [139/300][70/78]	eta 0:00:14 lr 3.537909	time 1.1474 (1.8171)	loss 3.0583 (3.0701)	grad_norm 0.3444 (0.3918)	mem 39782MB
[2023-07-07 12:34:41 RepVGG-A0] (main.py 291): INFO EPOCH 139 training takes 0:02:20
[2023-07-07 12:35:03 RepVGG-A0] (main.py 282): INFO Train: [140/300][0/78]	eta 0:28:53 lr 3.534491	time 22.2188 (22.2188)	loss 2.9790 (2.9790)	grad_norm 0.3325 (0.3325)	mem 39782MB
[2023-07-07 12:35:17 RepVGG-A0] (main.py 282): INFO Train: [140/300][10/78]	eta 0:03:45 lr 3.530218	time 1.1831 (3.3140)	loss 3.0843 (3.0343)	grad_norm 0.4228 (0.3946)	mem 39782MB
[2023-07-07 12:35:31 RepVGG-A0] (main.py 282): INFO Train: [140/300][20/78]	eta 0:02:17 lr 3.525945	time 1.1716 (2.3707)	loss 3.0350 (3.0291)	grad_norm 0.3781 (0.3896)	mem 39782MB
[2023-07-07 12:35:46 RepVGG-A0] (main.py 282): INFO Train: [140/300][30/78]	eta 0:01:40 lr 3.521670	time 1.1506 (2.0983)	loss 2.9503 (3.0291)	grad_norm 0.3498 (0.3859)	mem 39782MB
[2023-07-07 12:36:04 RepVGG-A0] (main.py 282): INFO Train: [140/300][40/78]	eta 0:01:16 lr 3.517396	time 3.4949 (2.0160)	loss 3.0372 (3.0499)	grad_norm 0.3589 (0.3966)	mem 39782MB
[2023-07-07 12:36:19 RepVGG-A0] (main.py 282): INFO Train: [140/300][50/78]	eta 0:00:53 lr 3.513120	time 1.1730 (1.9265)	loss 3.1409 (3.0529)	grad_norm 0.3936 (0.3909)	mem 39782MB
[2023-07-07 12:36:34 RepVGG-A0] (main.py 282): INFO Train: [140/300][60/78]	eta 0:00:33 lr 3.508845	time 1.1802 (1.8590)	loss 3.0661 (3.0580)	grad_norm 0.3913 (0.3921)	mem 39782MB
[2023-07-07 12:36:50 RepVGG-A0] (main.py 282): INFO Train: [140/300][70/78]	eta 0:00:14 lr 3.504568	time 1.5241 (1.8149)	loss 3.1416 (3.0582)	grad_norm 0.3965 (0.3920)	mem 39782MB
[2023-07-07 12:37:01 RepVGG-A0] (main.py 291): INFO EPOCH 140 training takes 0:02:20
[2023-07-07 12:37:18 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.418 (17.418)	Loss 3.0108 (3.0108)	Acc@1 38.049 (38.049)	Acc@5 64.020 (64.020)	Mem 39782MB
[2023-07-07 12:37:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 38.532 Acc@5 64.328
[2023-07-07 12:37:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 140: 38.532%
[2023-07-07 12:37:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 12:37:40 RepVGG-A0] (main.py 282): INFO Train: [141/300][0/78]	eta 0:26:38 lr 3.501147	time 20.4917 (20.4917)	loss 3.0627 (3.0627)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 12:37:55 RepVGG-A0] (main.py 282): INFO Train: [141/300][10/78]	eta 0:03:39 lr 3.496869	time 1.1950 (3.2284)	loss 3.0490 (3.0367)	grad_norm 0.3821 (0.3968)	mem 39782MB
[2023-07-07 12:38:10 RepVGG-A0] (main.py 282): INFO Train: [141/300][20/78]	eta 0:02:19 lr 3.492591	time 1.1748 (2.4100)	loss 2.9619 (3.0254)	grad_norm 0.3761 (0.3932)	mem 39782MB
[2023-07-07 12:38:25 RepVGG-A0] (main.py 282): INFO Train: [141/300][30/78]	eta 0:01:41 lr 3.488313	time 1.2229 (2.1067)	loss 2.9542 (3.0101)	grad_norm 0.3603 (0.3842)	mem 39782MB
[2023-07-07 12:38:43 RepVGG-A0] (main.py 282): INFO Train: [141/300][40/78]	eta 0:01:17 lr 3.484034	time 2.7693 (2.0321)	loss 3.1801 (3.0220)	grad_norm 0.4305 (0.3917)	mem 39782MB
[2023-07-07 12:38:59 RepVGG-A0] (main.py 282): INFO Train: [141/300][50/78]	eta 0:00:54 lr 3.479754	time 1.1349 (1.9365)	loss 2.9170 (3.0240)	grad_norm 0.3592 (0.3885)	mem 39782MB
[2023-07-07 12:39:13 RepVGG-A0] (main.py 282): INFO Train: [141/300][60/78]	eta 0:00:33 lr 3.475474	time 1.1372 (1.8581)	loss 3.0200 (3.0364)	grad_norm 0.3673 (0.3943)	mem 39782MB
[2023-07-07 12:39:29 RepVGG-A0] (main.py 282): INFO Train: [141/300][70/78]	eta 0:00:14 lr 3.471194	time 1.3169 (1.8119)	loss 3.1470 (3.0399)	grad_norm 0.4624 (0.3934)	mem 39782MB
[2023-07-07 12:39:40 RepVGG-A0] (main.py 291): INFO EPOCH 141 training takes 0:02:20
[2023-07-07 12:40:02 RepVGG-A0] (main.py 282): INFO Train: [142/300][0/78]	eta 0:27:36 lr 3.467769	time 21.2374 (21.2374)	loss 3.0572 (3.0572)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 12:40:16 RepVGG-A0] (main.py 282): INFO Train: [142/300][10/78]	eta 0:03:39 lr 3.463488	time 1.1731 (3.2315)	loss 3.0609 (3.0063)	grad_norm 0.3824 (0.3771)	mem 39782MB
[2023-07-07 12:40:31 RepVGG-A0] (main.py 282): INFO Train: [142/300][20/78]	eta 0:02:20 lr 3.459206	time 1.1768 (2.4262)	loss 3.0853 (3.0117)	grad_norm 0.4019 (0.3849)	mem 39782MB
[2023-07-07 12:40:46 RepVGG-A0] (main.py 282): INFO Train: [142/300][30/78]	eta 0:01:42 lr 3.454924	time 1.6067 (2.1262)	loss 2.9929 (3.0126)	grad_norm 0.4027 (0.3831)	mem 39782MB
[2023-07-07 12:41:04 RepVGG-A0] (main.py 282): INFO Train: [142/300][40/78]	eta 0:01:17 lr 3.450641	time 2.6554 (2.0335)	loss 3.1525 (3.0434)	grad_norm 0.4964 (0.4087)	mem 39782MB
[2023-07-07 12:41:18 RepVGG-A0] (main.py 282): INFO Train: [142/300][50/78]	eta 0:00:53 lr 3.446358	time 1.3406 (1.9167)	loss 2.9377 (3.0432)	grad_norm 0.3573 (0.4009)	mem 39782MB
[2023-07-07 12:41:34 RepVGG-A0] (main.py 282): INFO Train: [142/300][60/78]	eta 0:00:33 lr 3.442074	time 1.1807 (1.8549)	loss 2.9801 (3.0444)	grad_norm 0.3691 (0.3967)	mem 39782MB
[2023-07-07 12:41:49 RepVGG-A0] (main.py 282): INFO Train: [142/300][70/78]	eta 0:00:14 lr 3.437790	time 1.5040 (1.8130)	loss 3.0360 (3.0454)	grad_norm 0.4186 (0.3950)	mem 39782MB
[2023-07-07 12:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 142 training takes 0:02:19
[2023-07-07 12:42:20 RepVGG-A0] (main.py 282): INFO Train: [143/300][0/78]	eta 0:26:15 lr 3.434362	time 20.2048 (20.2048)	loss 2.9934 (2.9934)	grad_norm 0.3851 (0.3851)	mem 39782MB
[2023-07-07 12:42:39 RepVGG-A0] (main.py 282): INFO Train: [143/300][10/78]	eta 0:03:57 lr 3.430077	time 1.2702 (3.4957)	loss 3.0139 (2.9855)	grad_norm 0.4055 (0.3765)	mem 39782MB
[2023-07-07 12:42:52 RepVGG-A0] (main.py 282): INFO Train: [143/300][20/78]	eta 0:02:23 lr 3.425792	time 1.1981 (2.4687)	loss 3.0419 (3.0072)	grad_norm 0.4733 (0.3959)	mem 39782MB
[2023-07-07 12:43:06 RepVGG-A0] (main.py 282): INFO Train: [143/300][30/78]	eta 0:01:41 lr 3.421506	time 1.1825 (2.1131)	loss 3.0522 (3.0172)	grad_norm 0.3792 (0.3978)	mem 39782MB
[2023-07-07 12:43:25 RepVGG-A0] (main.py 282): INFO Train: [143/300][40/78]	eta 0:01:18 lr 3.417220	time 5.0509 (2.0601)	loss 3.1071 (3.0248)	grad_norm 0.4165 (0.3976)	mem 39782MB
[2023-07-07 12:43:40 RepVGG-A0] (main.py 282): INFO Train: [143/300][50/78]	eta 0:00:54 lr 3.412934	time 1.2421 (1.9582)	loss 3.0505 (3.0284)	grad_norm 0.3946 (0.3977)	mem 39782MB
[2023-07-07 12:43:56 RepVGG-A0] (main.py 282): INFO Train: [143/300][60/78]	eta 0:00:34 lr 3.408647	time 1.2914 (1.8912)	loss 3.0793 (3.0279)	grad_norm 0.4138 (0.3988)	mem 39782MB
[2023-07-07 12:44:10 RepVGG-A0] (main.py 282): INFO Train: [143/300][70/78]	eta 0:00:14 lr 3.404360	time 1.3611 (1.8257)	loss 3.1078 (3.0343)	grad_norm 0.4123 (0.3991)	mem 39782MB
[2023-07-07 12:44:22 RepVGG-A0] (main.py 291): INFO EPOCH 143 training takes 0:02:22
[2023-07-07 12:44:44 RepVGG-A0] (main.py 282): INFO Train: [144/300][0/78]	eta 0:27:55 lr 3.400930	time 21.4823 (21.4823)	loss 2.9484 (2.9484)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:44:58 RepVGG-A0] (main.py 282): INFO Train: [144/300][10/78]	eta 0:03:41 lr 3.396642	time 1.1713 (3.2554)	loss 2.9784 (2.9950)	grad_norm 0.4112 (0.4074)	mem 39782MB
[2023-07-07 12:45:12 RepVGG-A0] (main.py 282): INFO Train: [144/300][20/78]	eta 0:02:17 lr 3.392354	time 1.1731 (2.3630)	loss 3.0225 (3.0048)	grad_norm 0.3925 (0.4080)	mem 39782MB
[2023-07-07 12:45:27 RepVGG-A0] (main.py 282): INFO Train: [144/300][30/78]	eta 0:01:39 lr 3.388065	time 1.1757 (2.0749)	loss 2.9846 (3.0139)	grad_norm 0.3883 (0.4014)	mem 39782MB
[2023-07-07 12:45:45 RepVGG-A0] (main.py 282): INFO Train: [144/300][40/78]	eta 0:01:16 lr 3.383776	time 3.6959 (2.0259)	loss 3.0128 (3.0101)	grad_norm 0.4080 (0.3968)	mem 39782MB
[2023-07-07 12:46:01 RepVGG-A0] (main.py 282): INFO Train: [144/300][50/78]	eta 0:00:53 lr 3.379487	time 1.1735 (1.9269)	loss 3.0340 (3.0242)	grad_norm 0.3644 (0.4038)	mem 39782MB
[2023-07-07 12:46:16 RepVGG-A0] (main.py 282): INFO Train: [144/300][60/78]	eta 0:00:33 lr 3.375197	time 1.3773 (1.8615)	loss 3.1201 (3.0270)	grad_norm 0.3939 (0.4006)	mem 39782MB
[2023-07-07 12:46:31 RepVGG-A0] (main.py 282): INFO Train: [144/300][70/78]	eta 0:00:14 lr 3.370907	time 1.3932 (1.8122)	loss 3.0875 (3.0320)	grad_norm 0.4046 (0.4025)	mem 39782MB
[2023-07-07 12:46:43 RepVGG-A0] (main.py 291): INFO EPOCH 144 training takes 0:02:20
[2023-07-07 12:47:05 RepVGG-A0] (main.py 282): INFO Train: [145/300][0/78]	eta 0:28:36 lr 3.367475	time 22.0114 (22.0114)	loss 3.0822 (3.0822)	grad_norm 0.4466 (0.4466)	mem 39782MB
[2023-07-07 12:47:20 RepVGG-A0] (main.py 282): INFO Train: [145/300][10/78]	eta 0:03:47 lr 3.363185	time 1.1725 (3.3418)	loss 3.0479 (3.0293)	grad_norm 0.4192 (0.4218)	mem 39782MB
[2023-07-07 12:47:35 RepVGG-A0] (main.py 282): INFO Train: [145/300][20/78]	eta 0:02:22 lr 3.358894	time 1.3441 (2.4601)	loss 3.0321 (3.0328)	grad_norm 0.4341 (0.4198)	mem 39782MB
[2023-07-07 12:47:50 RepVGG-A0] (main.py 282): INFO Train: [145/300][30/78]	eta 0:01:43 lr 3.354603	time 1.5385 (2.1511)	loss 2.9449 (3.0267)	grad_norm 0.3616 (0.4094)	mem 39782MB
[2023-07-07 12:48:08 RepVGG-A0] (main.py 282): INFO Train: [145/300][40/78]	eta 0:01:18 lr 3.350311	time 3.9510 (2.0754)	loss 3.0125 (3.0206)	grad_norm 0.3599 (0.4018)	mem 39782MB
[2023-07-07 12:48:23 RepVGG-A0] (main.py 282): INFO Train: [145/300][50/78]	eta 0:00:54 lr 3.346020	time 1.1737 (1.9589)	loss 2.9772 (3.0213)	grad_norm 0.3457 (0.4026)	mem 39782MB
[2023-07-07 12:48:39 RepVGG-A0] (main.py 282): INFO Train: [145/300][60/78]	eta 0:00:33 lr 3.341728	time 1.1777 (1.8886)	loss 3.1602 (3.0181)	grad_norm 0.4584 (0.3997)	mem 39782MB
[2023-07-07 12:48:54 RepVGG-A0] (main.py 282): INFO Train: [145/300][70/78]	eta 0:00:14 lr 3.337436	time 1.2361 (1.8372)	loss 5.6870 (3.1000)	grad_norm 1.6408 (0.4593)	mem 39782MB
[2023-07-07 12:49:05 RepVGG-A0] (main.py 291): INFO EPOCH 145 training takes 0:02:21
[2023-07-07 12:49:27 RepVGG-A0] (main.py 282): INFO Train: [146/300][0/78]	eta 0:29:08 lr 3.334002	time 22.4219 (22.4219)	loss 5.7612 (5.7612)	grad_norm 0.4792 (0.4792)	mem 39782MB
[2023-07-07 12:49:41 RepVGG-A0] (main.py 282): INFO Train: [146/300][10/78]	eta 0:03:44 lr 3.329710	time 1.1727 (3.3051)	loss 4.7704 (5.2536)	grad_norm 0.3540 (0.4210)	mem 39782MB
[2023-07-07 12:49:56 RepVGG-A0] (main.py 282): INFO Train: [146/300][20/78]	eta 0:02:21 lr 3.325417	time 1.1742 (2.4447)	loss 4.2866 (4.9436)	grad_norm 0.3067 (0.4277)	mem 39782MB
[2023-07-07 12:50:11 RepVGG-A0] (main.py 282): INFO Train: [146/300][30/78]	eta 0:01:42 lr 3.321124	time 1.5266 (2.1398)	loss 4.0373 (4.6798)	grad_norm 0.3535 (0.3978)	mem 39782MB
[2023-07-07 12:50:28 RepVGG-A0] (main.py 282): INFO Train: [146/300][40/78]	eta 0:01:16 lr 3.316831	time 2.7513 (2.0230)	loss 3.8524 (4.4723)	grad_norm 0.3586 (0.3782)	mem 39782MB
[2023-07-07 12:50:44 RepVGG-A0] (main.py 282): INFO Train: [146/300][50/78]	eta 0:00:54 lr 3.312537	time 1.1722 (1.9438)	loss 3.6370 (4.3291)	grad_norm 0.3339 (0.3789)	mem 39782MB
[2023-07-07 12:50:59 RepVGG-A0] (main.py 282): INFO Train: [146/300][60/78]	eta 0:00:33 lr 3.308243	time 1.1953 (1.8684)	loss 3.5797 (4.2050)	grad_norm 0.3752 (0.3709)	mem 39782MB
[2023-07-07 12:51:14 RepVGG-A0] (main.py 282): INFO Train: [146/300][70/78]	eta 0:00:14 lr 3.303950	time 1.4999 (1.8196)	loss 3.4293 (4.1091)	grad_norm 0.4020 (0.3701)	mem 39782MB
[2023-07-07 12:51:26 RepVGG-A0] (main.py 291): INFO EPOCH 146 training takes 0:02:20
[2023-07-07 12:51:49 RepVGG-A0] (main.py 282): INFO Train: [147/300][0/78]	eta 0:29:47 lr 3.300514	time 22.9115 (22.9115)	loss 3.4258 (3.4258)	grad_norm 0.3848 (0.3848)	mem 39782MB
[2023-07-07 12:52:03 RepVGG-A0] (main.py 282): INFO Train: [147/300][10/78]	eta 0:03:49 lr 3.296220	time 1.1707 (3.3777)	loss 3.3035 (3.3872)	grad_norm 0.2838 (0.3664)	mem 39782MB
[2023-07-07 12:52:17 RepVGG-A0] (main.py 282): INFO Train: [147/300][20/78]	eta 0:02:22 lr 3.291926	time 1.1748 (2.4563)	loss 3.4523 (3.3617)	grad_norm 0.4730 (0.3555)	mem 39782MB
[2023-07-07 12:52:32 RepVGG-A0] (main.py 282): INFO Train: [147/300][30/78]	eta 0:01:43 lr 3.287631	time 1.2997 (2.1487)	loss 3.3218 (3.3633)	grad_norm 0.3753 (0.3671)	mem 39782MB
[2023-07-07 12:52:50 RepVGG-A0] (main.py 282): INFO Train: [147/300][40/78]	eta 0:01:18 lr 3.283337	time 3.5122 (2.0688)	loss 3.2364 (3.3505)	grad_norm 0.3578 (0.3627)	mem 39782MB
[2023-07-07 12:53:05 RepVGG-A0] (main.py 282): INFO Train: [147/300][50/78]	eta 0:00:54 lr 3.279042	time 1.1723 (1.9430)	loss 3.2376 (3.3382)	grad_norm 0.3598 (0.3630)	mem 39782MB
[2023-07-07 12:53:20 RepVGG-A0] (main.py 282): INFO Train: [147/300][60/78]	eta 0:00:33 lr 3.274747	time 1.1478 (1.8735)	loss 3.2449 (3.3264)	grad_norm 0.3440 (0.3625)	mem 39782MB
[2023-07-07 12:53:35 RepVGG-A0] (main.py 282): INFO Train: [147/300][70/78]	eta 0:00:14 lr 3.270452	time 1.3174 (1.8272)	loss 3.3031 (3.3239)	grad_norm 0.3847 (0.3696)	mem 39782MB
[2023-07-07 12:53:47 RepVGG-A0] (main.py 291): INFO EPOCH 147 training takes 0:02:21
[2023-07-07 12:54:10 RepVGG-A0] (main.py 282): INFO Train: [148/300][0/78]	eta 0:30:06 lr 3.267016	time 23.1586 (23.1586)	loss 3.1166 (3.1166)	grad_norm 0.3653 (0.3653)	mem 39782MB
[2023-07-07 12:54:24 RepVGG-A0] (main.py 282): INFO Train: [148/300][10/78]	eta 0:03:47 lr 3.262720	time 1.1728 (3.3518)	loss 3.2127 (3.2121)	grad_norm 0.3601 (0.3765)	mem 39782MB
[2023-07-07 12:54:37 RepVGG-A0] (main.py 282): INFO Train: [148/300][20/78]	eta 0:02:18 lr 3.258425	time 1.1764 (2.3925)	loss 3.1996 (3.2028)	grad_norm 0.4312 (0.3857)	mem 39782MB
[2023-07-07 12:54:53 RepVGG-A0] (main.py 282): INFO Train: [148/300][30/78]	eta 0:01:42 lr 3.254129	time 1.3774 (2.1341)	loss 3.1785 (3.1927)	grad_norm 0.3788 (0.3801)	mem 39782MB
[2023-07-07 12:55:11 RepVGG-A0] (main.py 282): INFO Train: [148/300][40/78]	eta 0:01:18 lr 3.249834	time 4.0091 (2.0535)	loss 3.1568 (3.1930)	grad_norm 0.3711 (0.3819)	mem 39782MB
[2023-07-07 12:55:26 RepVGG-A0] (main.py 282): INFO Train: [148/300][50/78]	eta 0:00:54 lr 3.245538	time 1.1745 (1.9451)	loss 3.2508 (3.1891)	grad_norm 0.4977 (0.3843)	mem 39782MB
[2023-07-07 12:55:40 RepVGG-A0] (main.py 282): INFO Train: [148/300][60/78]	eta 0:00:33 lr 3.241242	time 1.2937 (1.8647)	loss 3.2276 (3.2038)	grad_norm 0.3681 (0.3927)	mem 39782MB
[2023-07-07 12:55:55 RepVGG-A0] (main.py 282): INFO Train: [148/300][70/78]	eta 0:00:14 lr 3.236946	time 1.2447 (1.8138)	loss 3.1176 (3.2044)	grad_norm 0.3063 (0.3898)	mem 39782MB
[2023-07-07 12:56:07 RepVGG-A0] (main.py 291): INFO EPOCH 148 training takes 0:02:20
[2023-07-07 12:56:30 RepVGG-A0] (main.py 282): INFO Train: [149/300][0/78]	eta 0:29:16 lr 3.233510	time 22.5253 (22.5253)	loss 3.1067 (3.1067)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:56:45 RepVGG-A0] (main.py 282): INFO Train: [149/300][10/78]	eta 0:03:49 lr 3.229214	time 1.1720 (3.3814)	loss 3.2186 (3.1199)	grad_norm 0.4202 (0.3863)	mem 39782MB
[2023-07-07 12:57:00 RepVGG-A0] (main.py 282): INFO Train: [149/300][20/78]	eta 0:02:26 lr 3.224918	time 1.1750 (2.5205)	loss 3.1179 (3.1206)	grad_norm 0.3391 (0.3832)	mem 39782MB
[2023-07-07 12:57:16 RepVGG-A0] (main.py 282): INFO Train: [149/300][30/78]	eta 0:01:45 lr 3.220622	time 1.4486 (2.2081)	loss 3.2197 (3.1342)	grad_norm 0.3770 (0.3956)	mem 39782MB
[2023-07-07 12:57:33 RepVGG-A0] (main.py 282): INFO Train: [149/300][40/78]	eta 0:01:19 lr 3.216325	time 2.6301 (2.0998)	loss 3.1848 (3.1270)	grad_norm 0.4092 (0.3872)	mem 39782MB
[2023-07-07 12:57:49 RepVGG-A0] (main.py 282): INFO Train: [149/300][50/78]	eta 0:00:55 lr 3.212029	time 1.1731 (1.9865)	loss 3.1551 (3.1335)	grad_norm 0.4082 (0.3911)	mem 39782MB
[2023-07-07 12:58:04 RepVGG-A0] (main.py 282): INFO Train: [149/300][60/78]	eta 0:00:34 lr 3.207733	time 1.1917 (1.9086)	loss 3.1879 (3.1363)	grad_norm 0.3677 (0.3913)	mem 39782MB
[2023-07-07 12:58:19 RepVGG-A0] (main.py 282): INFO Train: [149/300][70/78]	eta 0:00:14 lr 3.203437	time 1.1736 (1.8547)	loss 3.3321 (3.1454)	grad_norm 0.5420 (0.3976)	mem 39782MB
[2023-07-07 12:58:30 RepVGG-A0] (main.py 291): INFO EPOCH 149 training takes 0:02:23
[2023-07-07 12:58:53 RepVGG-A0] (main.py 282): INFO Train: [150/300][0/78]	eta 0:28:38 lr 3.200000	time 22.0278 (22.0278)	loss 3.3939 (3.3939)	grad_norm 0.5789 (0.5789)	mem 39782MB
[2023-07-07 12:59:07 RepVGG-A0] (main.py 282): INFO Train: [150/300][10/78]	eta 0:03:43 lr 3.195704	time 1.1721 (3.2883)	loss 3.1495 (3.2141)	grad_norm 0.3354 (0.3925)	mem 39782MB
[2023-07-07 12:59:22 RepVGG-A0] (main.py 282): INFO Train: [150/300][20/78]	eta 0:02:21 lr 3.191408	time 1.1741 (2.4362)	loss 3.0995 (3.1663)	grad_norm 0.4256 (0.3746)	mem 39782MB
[2023-07-07 12:59:36 RepVGG-A0] (main.py 282): INFO Train: [150/300][30/78]	eta 0:01:41 lr 3.187111	time 1.2469 (2.1210)	loss 3.0661 (3.1467)	grad_norm 0.3508 (0.3665)	mem 39782MB
[2023-07-07 12:59:54 RepVGG-A0] (main.py 282): INFO Train: [150/300][40/78]	eta 0:01:17 lr 3.182815	time 3.9445 (2.0468)	loss 3.1390 (3.1425)	grad_norm 0.3752 (0.3712)	mem 39782MB
[2023-07-07 13:00:09 RepVGG-A0] (main.py 282): INFO Train: [150/300][50/78]	eta 0:00:54 lr 3.178519	time 1.1712 (1.9384)	loss 3.0994 (3.1281)	grad_norm 0.3473 (0.3678)	mem 39782MB
[2023-07-07 13:00:24 RepVGG-A0] (main.py 282): INFO Train: [150/300][60/78]	eta 0:00:33 lr 3.174223	time 1.1781 (1.8675)	loss 3.0882 (3.1187)	grad_norm 0.3779 (0.3675)	mem 39782MB
[2023-07-07 13:00:40 RepVGG-A0] (main.py 282): INFO Train: [150/300][70/78]	eta 0:00:14 lr 3.169927	time 1.3352 (1.8202)	loss 3.1889 (3.1167)	grad_norm 0.4487 (0.3727)	mem 39782MB
[2023-07-07 13:00:51 RepVGG-A0] (main.py 291): INFO EPOCH 150 training takes 0:02:20
[2023-07-07 13:01:12 RepVGG-A0] (main.py 282): INFO Train: [151/300][0/78]	eta 0:26:12 lr 3.166490	time 20.1630 (20.1630)	loss 3.0934 (3.0934)	grad_norm 0.3840 (0.3840)	mem 39782MB
[2023-07-07 13:01:28 RepVGG-A0] (main.py 282): INFO Train: [151/300][10/78]	eta 0:03:46 lr 3.162194	time 1.1708 (3.3261)	loss 3.0447 (3.0612)	grad_norm 0.3811 (0.3730)	mem 39782MB
[2023-07-07 13:01:42 RepVGG-A0] (main.py 282): INFO Train: [151/300][20/78]	eta 0:02:20 lr 3.157899	time 1.2371 (2.4269)	loss 3.0680 (3.0626)	grad_norm 0.3919 (0.3801)	mem 39782MB
[2023-07-07 13:01:57 RepVGG-A0] (main.py 282): INFO Train: [151/300][30/78]	eta 0:01:41 lr 3.153603	time 1.2297 (2.1250)	loss 3.0883 (3.0780)	grad_norm 0.3902 (0.3928)	mem 39782MB
[2023-07-07 13:02:14 RepVGG-A0] (main.py 282): INFO Train: [151/300][40/78]	eta 0:01:16 lr 3.149307	time 3.6460 (2.0196)	loss 3.0852 (3.0780)	grad_norm 0.4150 (0.3921)	mem 39782MB
[2023-07-07 13:02:29 RepVGG-A0] (main.py 282): INFO Train: [151/300][50/78]	eta 0:00:53 lr 3.145011	time 1.1729 (1.9139)	loss 3.0753 (3.0765)	grad_norm 0.4151 (0.3928)	mem 39782MB
[2023-07-07 13:02:45 RepVGG-A0] (main.py 282): INFO Train: [151/300][60/78]	eta 0:00:33 lr 3.140716	time 1.1792 (1.8559)	loss 3.1207 (3.0814)	grad_norm 0.3924 (0.3960)	mem 39782MB
[2023-07-07 13:02:59 RepVGG-A0] (main.py 282): INFO Train: [151/300][70/78]	eta 0:00:14 lr 3.136420	time 1.1457 (1.8002)	loss 3.1157 (3.0894)	grad_norm 0.3548 (0.4000)	mem 39782MB
[2023-07-07 13:03:11 RepVGG-A0] (main.py 291): INFO EPOCH 151 training takes 0:02:19
[2023-07-07 13:03:33 RepVGG-A0] (main.py 282): INFO Train: [152/300][0/78]	eta 0:28:20 lr 3.132984	time 21.8033 (21.8033)	loss 3.1216 (3.1216)	grad_norm 0.4497 (0.4497)	mem 39782MB
[2023-07-07 13:03:48 RepVGG-A0] (main.py 282): INFO Train: [152/300][10/78]	eta 0:03:44 lr 3.128689	time 1.1949 (3.3036)	loss 3.0624 (3.0541)	grad_norm 0.3745 (0.3943)	mem 39782MB
[2023-07-07 13:04:03 RepVGG-A0] (main.py 282): INFO Train: [152/300][20/78]	eta 0:02:22 lr 3.124394	time 1.1727 (2.4543)	loss 3.0168 (3.0305)	grad_norm 0.4298 (0.3839)	mem 39782MB
[2023-07-07 13:04:18 RepVGG-A0] (main.py 282): INFO Train: [152/300][30/78]	eta 0:01:43 lr 3.120099	time 1.3779 (2.1625)	loss 3.0982 (3.0590)	grad_norm 0.3830 (0.4053)	mem 39782MB
[2023-07-07 13:04:36 RepVGG-A0] (main.py 282): INFO Train: [152/300][40/78]	eta 0:01:18 lr 3.115804	time 3.8700 (2.0664)	loss 3.1829 (3.0626)	grad_norm 0.4093 (0.4006)	mem 39782MB
[2023-07-07 13:04:51 RepVGG-A0] (main.py 282): INFO Train: [152/300][50/78]	eta 0:00:54 lr 3.111510	time 1.1924 (1.9502)	loss 3.1554 (3.0643)	grad_norm 0.3895 (0.3977)	mem 39782MB
[2023-07-07 13:05:06 RepVGG-A0] (main.py 282): INFO Train: [152/300][60/78]	eta 0:00:33 lr 3.107215	time 1.3428 (1.8823)	loss 3.0657 (3.0634)	grad_norm 0.4042 (0.3981)	mem 39782MB
[2023-07-07 13:05:21 RepVGG-A0] (main.py 282): INFO Train: [152/300][70/78]	eta 0:00:14 lr 3.102921	time 1.1751 (1.8321)	loss 3.0235 (3.0598)	grad_norm 0.3651 (0.3966)	mem 39782MB
[2023-07-07 13:05:33 RepVGG-A0] (main.py 291): INFO EPOCH 152 training takes 0:02:21
[2023-07-07 13:05:56 RepVGG-A0] (main.py 282): INFO Train: [153/300][0/78]	eta 0:29:33 lr 3.099486	time 22.7351 (22.7351)	loss 2.9669 (2.9669)	grad_norm 0.3790 (0.3790)	mem 39782MB
[2023-07-07 13:06:10 RepVGG-A0] (main.py 282): INFO Train: [153/300][10/78]	eta 0:03:50 lr 3.095192	time 1.1740 (3.3827)	loss 3.0255 (3.0039)	grad_norm 0.4287 (0.4123)	mem 39782MB
[2023-07-07 13:06:25 RepVGG-A0] (main.py 282): INFO Train: [153/300][20/78]	eta 0:02:24 lr 3.090898	time 1.3318 (2.4861)	loss 3.0813 (3.0274)	grad_norm 0.4022 (0.4028)	mem 39782MB
[2023-07-07 13:06:40 RepVGG-A0] (main.py 282): INFO Train: [153/300][30/78]	eta 0:01:43 lr 3.086604	time 1.3829 (2.1581)	loss 3.0256 (3.0416)	grad_norm 0.3835 (0.4120)	mem 39782MB
[2023-07-07 13:06:59 RepVGG-A0] (main.py 282): INFO Train: [153/300][40/78]	eta 0:01:19 lr 3.082311	time 3.1653 (2.0807)	loss 3.0285 (3.0314)	grad_norm 0.3912 (0.4003)	mem 39782MB
[2023-07-07 13:07:13 RepVGG-A0] (main.py 282): INFO Train: [153/300][50/78]	eta 0:00:54 lr 3.078018	time 1.1909 (1.9639)	loss 3.0771 (3.0349)	grad_norm 0.4246 (0.4045)	mem 39782MB
[2023-07-07 13:07:29 RepVGG-A0] (main.py 282): INFO Train: [153/300][60/78]	eta 0:00:34 lr 3.073725	time 1.2564 (1.8915)	loss 3.0787 (3.0405)	grad_norm 0.4018 (0.4046)	mem 39782MB
[2023-07-07 13:07:45 RepVGG-A0] (main.py 282): INFO Train: [153/300][70/78]	eta 0:00:14 lr 3.069432	time 1.2576 (1.8522)	loss 3.0679 (3.0394)	grad_norm 0.3880 (0.4005)	mem 39782MB
[2023-07-07 13:07:55 RepVGG-A0] (main.py 291): INFO EPOCH 153 training takes 0:02:22
[2023-07-07 13:08:18 RepVGG-A0] (main.py 282): INFO Train: [154/300][0/78]	eta 0:29:04 lr 3.065998	time 22.3686 (22.3686)	loss 3.0152 (3.0152)	grad_norm 0.4179 (0.4179)	mem 39782MB
[2023-07-07 13:08:32 RepVGG-A0] (main.py 282): INFO Train: [154/300][10/78]	eta 0:03:48 lr 3.061706	time 1.1968 (3.3656)	loss 3.0409 (2.9989)	grad_norm 0.3944 (0.4052)	mem 39782MB
[2023-07-07 13:08:47 RepVGG-A0] (main.py 282): INFO Train: [154/300][20/78]	eta 0:02:23 lr 3.057414	time 1.1545 (2.4740)	loss 3.0259 (3.0027)	grad_norm 0.3801 (0.4055)	mem 39782MB
[2023-07-07 13:09:03 RepVGG-A0] (main.py 282): INFO Train: [154/300][30/78]	eta 0:01:44 lr 3.053122	time 1.5895 (2.1777)	loss 3.0283 (3.0083)	grad_norm 0.4335 (0.4096)	mem 39782MB
[2023-07-07 13:09:21 RepVGG-A0] (main.py 282): INFO Train: [154/300][40/78]	eta 0:01:18 lr 3.048830	time 2.6476 (2.0774)	loss 3.0322 (3.0150)	grad_norm 0.3554 (0.4097)	mem 39782MB
[2023-07-07 13:09:36 RepVGG-A0] (main.py 282): INFO Train: [154/300][50/78]	eta 0:00:55 lr 3.044539	time 1.5868 (1.9676)	loss 2.9809 (3.0178)	grad_norm 0.3664 (0.4070)	mem 39782MB
[2023-07-07 13:09:51 RepVGG-A0] (main.py 282): INFO Train: [154/300][60/78]	eta 0:00:34 lr 3.040248	time 1.2479 (1.8901)	loss 3.0356 (3.0175)	grad_norm 0.4155 (0.4075)	mem 39782MB
[2023-07-07 13:10:06 RepVGG-A0] (main.py 282): INFO Train: [154/300][70/78]	eta 0:00:14 lr 3.035957	time 1.3595 (1.8411)	loss 3.0651 (3.0230)	grad_norm 0.4036 (0.4070)	mem 39782MB
[2023-07-07 13:10:18 RepVGG-A0] (main.py 291): INFO EPOCH 154 training takes 0:02:22
[2023-07-07 13:10:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][0/78]	eta 0:28:08 lr 3.032525	time 21.6523 (21.6523)	loss 2.9513 (2.9513)	grad_norm 0.3518 (0.3518)	mem 39782MB
[2023-07-07 13:10:54 RepVGG-A0] (main.py 282): INFO Train: [155/300][10/78]	eta 0:03:45 lr 3.028235	time 1.1725 (3.3164)	loss 3.8336 (3.1677)	grad_norm 1.1281 (0.5835)	mem 39782MB
[2023-07-07 13:11:08 RepVGG-A0] (main.py 282): INFO Train: [155/300][20/78]	eta 0:02:17 lr 3.023945	time 1.1722 (2.3717)	loss 5.6771 (4.3631)	grad_norm 0.5419 (0.8188)	mem 39782MB
[2023-07-07 13:11:22 RepVGG-A0] (main.py 282): INFO Train: [155/300][30/78]	eta 0:01:39 lr 3.019655	time 1.2115 (2.0725)	loss 4.5468 (4.5575)	grad_norm 0.3827 (0.6999)	mem 39782MB
[2023-07-07 13:11:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][40/78]	eta 0:01:16 lr 3.015366	time 3.0224 (2.0005)	loss 4.0732 (4.4778)	grad_norm 0.3370 (0.6117)	mem 39782MB
[2023-07-07 13:11:56 RepVGG-A0] (main.py 282): INFO Train: [155/300][50/78]	eta 0:00:53 lr 3.011077	time 1.1759 (1.9164)	loss 3.9096 (4.3686)	grad_norm 0.4179 (0.5589)	mem 39782MB
[2023-07-07 13:12:11 RepVGG-A0] (main.py 282): INFO Train: [155/300][60/78]	eta 0:00:33 lr 3.006789	time 1.1792 (1.8468)	loss 3.6125 (4.2599)	grad_norm 0.2972 (0.5206)	mem 39782MB
[2023-07-07 13:12:26 RepVGG-A0] (main.py 282): INFO Train: [155/300][70/78]	eta 0:00:14 lr 3.002501	time 1.3082 (1.8073)	loss 3.4430 (4.1598)	grad_norm 0.3013 (0.4941)	mem 39782MB
[2023-07-07 13:12:38 RepVGG-A0] (main.py 291): INFO EPOCH 155 training takes 0:02:19
[2023-07-07 13:12:59 RepVGG-A0] (main.py 282): INFO Train: [156/300][0/78]	eta 0:27:22 lr 2.999070	time 21.0528 (21.0528)	loss 3.4133 (3.4133)	grad_norm 0.3452 (0.3452)	mem 39782MB
[2023-07-07 13:13:16 RepVGG-A0] (main.py 282): INFO Train: [156/300][10/78]	eta 0:03:53 lr 2.994783	time 1.1725 (3.4283)	loss 3.3525 (3.3837)	grad_norm 0.3327 (0.3296)	mem 39782MB
[2023-07-07 13:13:30 RepVGG-A0] (main.py 282): INFO Train: [156/300][20/78]	eta 0:02:23 lr 2.990496	time 1.1754 (2.4825)	loss 3.2676 (3.3598)	grad_norm 0.3448 (0.3362)	mem 39782MB
[2023-07-07 13:13:46 RepVGG-A0] (main.py 282): INFO Train: [156/300][30/78]	eta 0:01:45 lr 2.986209	time 1.6888 (2.1888)	loss 3.3337 (3.3379)	grad_norm 0.3727 (0.3414)	mem 39782MB
[2023-07-07 13:14:03 RepVGG-A0] (main.py 282): INFO Train: [156/300][40/78]	eta 0:01:18 lr 2.981922	time 3.3031 (2.0734)	loss 3.2950 (3.3322)	grad_norm 0.3332 (0.3497)	mem 39782MB
[2023-07-07 13:14:18 RepVGG-A0] (main.py 282): INFO Train: [156/300][50/78]	eta 0:00:55 lr 2.977636	time 1.1774 (1.9714)	loss 3.1889 (3.3154)	grad_norm 0.3488 (0.3481)	mem 39782MB
[2023-07-07 13:14:34 RepVGG-A0] (main.py 282): INFO Train: [156/300][60/78]	eta 0:00:34 lr 2.973351	time 1.3804 (1.9111)	loss 3.2756 (3.3025)	grad_norm 0.3679 (0.3528)	mem 39782MB
[2023-07-07 13:14:49 RepVGG-A0] (main.py 282): INFO Train: [156/300][70/78]	eta 0:00:14 lr 2.969066	time 1.3966 (1.8542)	loss 3.2133 (3.2896)	grad_norm 0.3609 (0.3550)	mem 39782MB
[2023-07-07 13:15:02 RepVGG-A0] (main.py 291): INFO EPOCH 156 training takes 0:02:23
[2023-07-07 13:15:23 RepVGG-A0] (main.py 282): INFO Train: [157/300][0/78]	eta 0:28:21 lr 2.965638	time 21.8198 (21.8198)	loss 3.1143 (3.1143)	grad_norm 0.3462 (0.3462)	mem 39782MB
[2023-07-07 13:15:38 RepVGG-A0] (main.py 282): INFO Train: [157/300][10/78]	eta 0:03:46 lr 2.961353	time 1.1715 (3.3325)	loss 3.1818 (3.1543)	grad_norm 0.3874 (0.3658)	mem 39782MB
[2023-07-07 13:15:52 RepVGG-A0] (main.py 282): INFO Train: [157/300][20/78]	eta 0:02:18 lr 2.957069	time 1.1735 (2.3841)	loss 3.1393 (3.1661)	grad_norm 0.3753 (0.3879)	mem 39782MB
[2023-07-07 13:16:08 RepVGG-A0] (main.py 282): INFO Train: [157/300][30/78]	eta 0:01:43 lr 2.952786	time 1.3944 (2.1572)	loss 3.0889 (3.1496)	grad_norm 0.3456 (0.3768)	mem 39782MB
[2023-07-07 13:16:26 RepVGG-A0] (main.py 282): INFO Train: [157/300][40/78]	eta 0:01:18 lr 2.948503	time 4.8362 (2.0624)	loss 3.1647 (3.1557)	grad_norm 0.3783 (0.3821)	mem 39782MB
[2023-07-07 13:16:41 RepVGG-A0] (main.py 282): INFO Train: [157/300][50/78]	eta 0:00:54 lr 2.944220	time 1.2438 (1.9538)	loss 3.1616 (3.1504)	grad_norm 0.4047 (0.3796)	mem 39782MB
[2023-07-07 13:16:57 RepVGG-A0] (main.py 282): INFO Train: [157/300][60/78]	eta 0:00:34 lr 2.939938	time 1.4676 (1.8892)	loss 3.1883 (3.1459)	grad_norm 0.4442 (0.3806)	mem 39782MB
[2023-07-07 13:17:10 RepVGG-A0] (main.py 282): INFO Train: [157/300][70/78]	eta 0:00:14 lr 2.935656	time 1.3743 (1.8114)	loss 3.1060 (3.1490)	grad_norm 0.3872 (0.3874)	mem 39782MB
[2023-07-07 13:17:23 RepVGG-A0] (main.py 291): INFO EPOCH 157 training takes 0:02:21
[2023-07-07 13:17:45 RepVGG-A0] (main.py 282): INFO Train: [158/300][0/78]	eta 0:28:49 lr 2.932231	time 22.1749 (22.1749)	loss 3.0578 (3.0578)	grad_norm 0.3878 (0.3878)	mem 39782MB
[2023-07-07 13:17:59 RepVGG-A0] (main.py 282): INFO Train: [158/300][10/78]	eta 0:03:46 lr 2.927950	time 1.1722 (3.3288)	loss 3.0820 (3.0408)	grad_norm 0.3798 (0.3710)	mem 39782MB
[2023-07-07 13:18:13 RepVGG-A0] (main.py 282): INFO Train: [158/300][20/78]	eta 0:02:19 lr 2.923670	time 1.1747 (2.4104)	loss 3.0178 (3.0555)	grad_norm 0.3635 (0.3752)	mem 39782MB
[2023-07-07 13:18:29 RepVGG-A0] (main.py 282): INFO Train: [158/300][30/78]	eta 0:01:42 lr 2.919390	time 1.1529 (2.1432)	loss 3.0752 (3.0537)	grad_norm 0.3642 (0.3777)	mem 39782MB
[2023-07-07 13:18:48 RepVGG-A0] (main.py 282): INFO Train: [158/300][40/78]	eta 0:01:19 lr 2.915110	time 4.4641 (2.0840)	loss 3.1695 (3.0652)	grad_norm 0.4779 (0.3854)	mem 39782MB
[2023-07-07 13:19:03 RepVGG-A0] (main.py 282): INFO Train: [158/300][50/78]	eta 0:00:55 lr 2.910831	time 1.1728 (1.9651)	loss 3.2105 (3.0860)	grad_norm 0.4053 (0.3954)	mem 39782MB
[2023-07-07 13:19:18 RepVGG-A0] (main.py 282): INFO Train: [158/300][60/78]	eta 0:00:34 lr 2.906553	time 1.3853 (1.8919)	loss 3.0946 (3.0874)	grad_norm 0.4078 (0.3960)	mem 39782MB
[2023-07-07 13:19:33 RepVGG-A0] (main.py 282): INFO Train: [158/300][70/78]	eta 0:00:14 lr 2.902275	time 1.2599 (1.8281)	loss 3.1178 (3.0887)	grad_norm 0.4382 (0.3976)	mem 39782MB
[2023-07-07 13:19:44 RepVGG-A0] (main.py 291): INFO EPOCH 158 training takes 0:02:21
[2023-07-07 13:20:07 RepVGG-A0] (main.py 282): INFO Train: [159/300][0/78]	eta 0:29:54 lr 2.898853	time 23.0016 (23.0016)	loss 3.0371 (3.0371)	grad_norm 0.3711 (0.3711)	mem 39782MB
[2023-07-07 13:20:21 RepVGG-A0] (main.py 282): INFO Train: [159/300][10/78]	eta 0:03:48 lr 2.894577	time 1.1724 (3.3605)	loss 3.0152 (3.0287)	grad_norm 0.3875 (0.3844)	mem 39782MB
[2023-07-07 13:20:35 RepVGG-A0] (main.py 282): INFO Train: [159/300][20/78]	eta 0:02:20 lr 2.890300	time 1.1981 (2.4305)	loss 3.2458 (3.0457)	grad_norm 0.5703 (0.4232)	mem 39782MB
[2023-07-07 13:20:49 RepVGG-A0] (main.py 282): INFO Train: [159/300][30/78]	eta 0:01:41 lr 2.886024	time 1.1447 (2.1128)	loss 3.0418 (3.0518)	grad_norm 0.3473 (0.4154)	mem 39782MB
[2023-07-07 13:21:08 RepVGG-A0] (main.py 282): INFO Train: [159/300][40/78]	eta 0:01:17 lr 2.881749	time 3.5065 (2.0455)	loss 3.0615 (3.0505)	grad_norm 0.4536 (0.4129)	mem 39782MB
[2023-07-07 13:21:23 RepVGG-A0] (main.py 282): INFO Train: [159/300][50/78]	eta 0:00:54 lr 2.877475	time 1.2287 (1.9452)	loss 3.0391 (3.0542)	grad_norm 0.3559 (0.4114)	mem 39782MB
[2023-07-07 13:21:39 RepVGG-A0] (main.py 282): INFO Train: [159/300][60/78]	eta 0:00:34 lr 2.873201	time 1.4531 (1.8903)	loss 2.9990 (3.0518)	grad_norm 0.3696 (0.4046)	mem 39782MB
[2023-07-07 13:21:54 RepVGG-A0] (main.py 282): INFO Train: [159/300][70/78]	eta 0:00:14 lr 2.868927	time 1.3747 (1.8362)	loss 3.0626 (3.0518)	grad_norm 0.3634 (0.4023)	mem 39782MB
[2023-07-07 13:22:06 RepVGG-A0] (main.py 291): INFO EPOCH 159 training takes 0:02:22
[2023-07-07 13:22:28 RepVGG-A0] (main.py 282): INFO Train: [160/300][0/78]	eta 0:28:49 lr 2.865509	time 22.1714 (22.1714)	loss 3.0720 (3.0720)	grad_norm 0.3670 (0.3670)	mem 39782MB
[2023-07-07 13:22:43 RepVGG-A0] (main.py 282): INFO Train: [160/300][10/78]	eta 0:03:47 lr 2.861237	time 1.1722 (3.3515)	loss 3.1849 (3.0836)	grad_norm 0.4970 (0.4653)	mem 39782MB
[2023-07-07 13:22:58 RepVGG-A0] (main.py 282): INFO Train: [160/300][20/78]	eta 0:02:23 lr 2.856965	time 1.4411 (2.4811)	loss 2.9717 (3.0477)	grad_norm 0.3629 (0.4239)	mem 39782MB
[2023-07-07 13:23:14 RepVGG-A0] (main.py 282): INFO Train: [160/300][30/78]	eta 0:01:44 lr 2.852694	time 1.2881 (2.1799)	loss 3.0335 (3.0343)	grad_norm 0.4084 (0.4091)	mem 39782MB
[2023-07-07 13:23:31 RepVGG-A0] (main.py 282): INFO Train: [160/300][40/78]	eta 0:01:18 lr 2.848423	time 3.1208 (2.0679)	loss 3.0271 (3.0309)	grad_norm 0.3805 (0.4102)	mem 39782MB
[2023-07-07 13:23:47 RepVGG-A0] (main.py 282): INFO Train: [160/300][50/78]	eta 0:00:55 lr 2.844153	time 1.1778 (1.9678)	loss 2.9647 (3.0268)	grad_norm 0.3968 (0.4078)	mem 39782MB
[2023-07-07 13:24:01 RepVGG-A0] (main.py 282): INFO Train: [160/300][60/78]	eta 0:00:33 lr 2.839884	time 1.2822 (1.8782)	loss 2.9972 (3.0290)	grad_norm 0.3754 (0.4087)	mem 39782MB
[2023-07-07 13:24:17 RepVGG-A0] (main.py 282): INFO Train: [160/300][70/78]	eta 0:00:14 lr 2.835616	time 1.4097 (1.8394)	loss 3.0191 (3.0417)	grad_norm 0.3880 (0.4187)	mem 39782MB
[2023-07-07 13:24:29 RepVGG-A0] (main.py 291): INFO EPOCH 160 training takes 0:02:22
[2023-07-07 13:24:47 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 18.149 (18.149)	Loss 2.4704 (2.4704)	Acc@1 47.650 (47.650)	Acc@5 72.766 (72.766)	Mem 39782MB
[2023-07-07 13:24:48 RepVGG-A0] (main.py 342): INFO  * Acc@1 48.562 Acc@5 72.958
[2023-07-07 13:24:48 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 160: 48.562%
[2023-07-07 13:24:48 RepVGG-A0] (main.py 172): INFO Max accuracy: 48.56%
[2023-07-07 13:25:09 RepVGG-A0] (main.py 282): INFO Train: [161/300][0/78]	eta 0:27:20 lr 2.832201	time 21.0356 (21.0356)	loss 2.9555 (2.9555)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 13:25:26 RepVGG-A0] (main.py 282): INFO Train: [161/300][10/78]	eta 0:03:52 lr 2.827934	time 1.1714 (3.4230)	loss 2.9508 (2.9761)	grad_norm 0.4074 (0.3967)	mem 39782MB
[2023-07-07 13:25:40 RepVGG-A0] (main.py 282): INFO Train: [161/300][20/78]	eta 0:02:24 lr 2.823667	time 1.2271 (2.4903)	loss 3.0437 (2.9807)	grad_norm 0.4197 (0.4031)	mem 39782MB
[2023-07-07 13:25:55 RepVGG-A0] (main.py 282): INFO Train: [161/300][30/78]	eta 0:01:44 lr 2.819401	time 1.4187 (2.1713)	loss 2.9566 (2.9817)	grad_norm 0.3911 (0.3961)	mem 39782MB
[2023-07-07 13:26:13 RepVGG-A0] (main.py 282): INFO Train: [161/300][40/78]	eta 0:01:18 lr 2.815136	time 3.6974 (2.0598)	loss 3.0223 (2.9820)	grad_norm 0.4257 (0.3975)	mem 39782MB
[2023-07-07 13:26:28 RepVGG-A0] (main.py 282): INFO Train: [161/300][50/78]	eta 0:00:54 lr 2.810871	time 1.2954 (1.9532)	loss 2.9815 (2.9945)	grad_norm 0.4067 (0.4060)	mem 39782MB
[2023-07-07 13:26:43 RepVGG-A0] (main.py 282): INFO Train: [161/300][60/78]	eta 0:00:33 lr 2.806607	time 1.1722 (1.8773)	loss 3.0753 (3.0006)	grad_norm 0.4276 (0.4064)	mem 39782MB
[2023-07-07 13:26:58 RepVGG-A0] (main.py 282): INFO Train: [161/300][70/78]	eta 0:00:14 lr 2.802344	time 1.2436 (1.8306)	loss 3.0126 (3.0023)	grad_norm 0.3827 (0.4061)	mem 39782MB
[2023-07-07 13:27:09 RepVGG-A0] (main.py 291): INFO EPOCH 161 training takes 0:02:21
[2023-07-07 13:27:29 RepVGG-A0] (main.py 282): INFO Train: [162/300][0/78]	eta 0:26:08 lr 2.798934	time 20.1118 (20.1118)	loss 2.9984 (2.9984)	grad_norm 0.4832 (0.4832)	mem 39782MB
[2023-07-07 13:27:45 RepVGG-A0] (main.py 282): INFO Train: [162/300][10/78]	eta 0:03:38 lr 2.794672	time 1.1707 (3.2165)	loss 3.0333 (2.9585)	grad_norm 0.4627 (0.4106)	mem 39782MB
[2023-07-07 13:28:00 RepVGG-A0] (main.py 282): INFO Train: [162/300][20/78]	eta 0:02:20 lr 2.790410	time 1.1965 (2.4272)	loss 3.0086 (2.9677)	grad_norm 0.4551 (0.4074)	mem 39782MB
[2023-07-07 13:28:14 RepVGG-A0] (main.py 282): INFO Train: [162/300][30/78]	eta 0:01:40 lr 2.786150	time 1.1961 (2.0964)	loss 2.9322 (2.9737)	grad_norm 0.3686 (0.4090)	mem 39782MB
[2023-07-07 13:28:33 RepVGG-A0] (main.py 282): INFO Train: [162/300][40/78]	eta 0:01:17 lr 2.781890	time 3.7894 (2.0348)	loss 3.0191 (2.9803)	grad_norm 0.5544 (0.4113)	mem 39782MB
[2023-07-07 13:28:48 RepVGG-A0] (main.py 282): INFO Train: [162/300][50/78]	eta 0:00:54 lr 2.777631	time 1.1732 (1.9361)	loss 6.2837 (3.2337)	grad_norm 1.1968 (0.5421)	mem 39782MB
[2023-07-07 13:29:04 RepVGG-A0] (main.py 282): INFO Train: [162/300][60/78]	eta 0:00:33 lr 2.773373	time 1.1598 (1.8724)	loss 5.0349 (3.5943)	grad_norm 0.6170 (0.5680)	mem 39782MB
[2023-07-07 13:29:19 RepVGG-A0] (main.py 282): INFO Train: [162/300][70/78]	eta 0:00:14 lr 2.769116	time 1.4123 (1.8263)	loss 4.2346 (3.7079)	grad_norm 0.4402 (0.5401)	mem 39782MB
[2023-07-07 13:29:31 RepVGG-A0] (main.py 291): INFO EPOCH 162 training takes 0:02:21
[2023-07-07 13:29:53 RepVGG-A0] (main.py 282): INFO Train: [163/300][0/78]	eta 0:29:05 lr 2.765710	time 22.3815 (22.3815)	loss 3.8229 (3.8229)	grad_norm 0.3159 (0.3159)	mem 39782MB
[2023-07-07 13:30:07 RepVGG-A0] (main.py 282): INFO Train: [163/300][10/78]	eta 0:03:41 lr 2.761454	time 1.1933 (3.2544)	loss 3.5204 (3.6878)	grad_norm 0.3559 (0.3428)	mem 39782MB
[2023-07-07 13:30:21 RepVGG-A0] (main.py 282): INFO Train: [163/300][20/78]	eta 0:02:17 lr 2.757199	time 1.1722 (2.3704)	loss 3.4230 (3.6040)	grad_norm 0.3433 (0.3434)	mem 39782MB
[2023-07-07 13:30:36 RepVGG-A0] (main.py 282): INFO Train: [163/300][30/78]	eta 0:01:40 lr 2.752944	time 1.1846 (2.0965)	loss 3.3888 (3.5429)	grad_norm 0.3365 (0.3408)	mem 39782MB
[2023-07-07 13:30:54 RepVGG-A0] (main.py 282): INFO Train: [163/300][40/78]	eta 0:01:16 lr 2.748691	time 3.8770 (2.0198)	loss 3.3604 (3.4955)	grad_norm 0.3382 (0.3436)	mem 39782MB
[2023-07-07 13:31:09 RepVGG-A0] (main.py 282): INFO Train: [163/300][50/78]	eta 0:00:53 lr 2.744438	time 1.1722 (1.9277)	loss 3.2617 (3.4579)	grad_norm 0.3159 (0.3447)	mem 39782MB
[2023-07-07 13:31:24 RepVGG-A0] (main.py 282): INFO Train: [163/300][60/78]	eta 0:00:33 lr 2.740186	time 1.3240 (1.8568)	loss 3.2630 (3.4281)	grad_norm 0.4374 (0.3462)	mem 39782MB
[2023-07-07 13:31:40 RepVGG-A0] (main.py 282): INFO Train: [163/300][70/78]	eta 0:00:14 lr 2.735935	time 1.4670 (1.8109)	loss 3.2297 (3.3987)	grad_norm 0.4030 (0.3485)	mem 39782MB
[2023-07-07 13:31:51 RepVGG-A0] (main.py 291): INFO EPOCH 163 training takes 0:02:20
[2023-07-07 13:32:12 RepVGG-A0] (main.py 282): INFO Train: [164/300][0/78]	eta 0:27:02 lr 2.732534	time 20.7993 (20.7993)	loss 3.1068 (3.1068)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 13:32:28 RepVGG-A0] (main.py 282): INFO Train: [164/300][10/78]	eta 0:03:44 lr 2.728285	time 1.1900 (3.3012)	loss 3.1742 (3.1459)	grad_norm 0.3385 (0.3550)	mem 39782MB
[2023-07-07 13:32:43 RepVGG-A0] (main.py 282): INFO Train: [164/300][20/78]	eta 0:02:22 lr 2.724036	time 1.1986 (2.4512)	loss 3.2343 (3.1457)	grad_norm 0.4180 (0.3588)	mem 39782MB
[2023-07-07 13:32:58 RepVGG-A0] (main.py 282): INFO Train: [164/300][30/78]	eta 0:01:43 lr 2.719788	time 1.1937 (2.1556)	loss 3.1798 (3.1492)	grad_norm 0.3496 (0.3657)	mem 39782MB
[2023-07-07 13:33:15 RepVGG-A0] (main.py 282): INFO Train: [164/300][40/78]	eta 0:01:17 lr 2.715541	time 2.7649 (2.0418)	loss 3.1199 (3.1392)	grad_norm 0.3559 (0.3653)	mem 39782MB
[2023-07-07 13:33:30 RepVGG-A0] (main.py 282): INFO Train: [164/300][50/78]	eta 0:00:53 lr 2.711294	time 1.1732 (1.9262)	loss 2.9957 (3.1287)	grad_norm 0.3679 (0.3675)	mem 39782MB
[2023-07-07 13:33:45 RepVGG-A0] (main.py 282): INFO Train: [164/300][60/78]	eta 0:00:33 lr 2.707049	time 1.2708 (1.8676)	loss 3.1789 (3.1318)	grad_norm 0.3913 (0.3753)	mem 39782MB
[2023-07-07 13:34:01 RepVGG-A0] (main.py 282): INFO Train: [164/300][70/78]	eta 0:00:14 lr 2.702805	time 1.1821 (1.8199)	loss 3.0809 (3.1286)	grad_norm 0.3562 (0.3726)	mem 39782MB
[2023-07-07 13:34:13 RepVGG-A0] (main.py 291): INFO EPOCH 164 training takes 0:02:21
[2023-07-07 13:34:34 RepVGG-A0] (main.py 282): INFO Train: [165/300][0/78]	eta 0:27:15 lr 2.699410	time 20.9640 (20.9640)	loss 2.9971 (2.9971)	grad_norm 0.4425 (0.4425)	mem 39782MB
[2023-07-07 13:34:48 RepVGG-A0] (main.py 282): INFO Train: [165/300][10/78]	eta 0:03:38 lr 2.695167	time 1.1727 (3.2138)	loss 2.9802 (3.0367)	grad_norm 0.3568 (0.3907)	mem 39782MB
[2023-07-07 13:35:02 RepVGG-A0] (main.py 282): INFO Train: [165/300][20/78]	eta 0:02:16 lr 2.690925	time 1.1726 (2.3593)	loss 3.0741 (3.0421)	grad_norm 0.4137 (0.3881)	mem 39782MB
[2023-07-07 13:35:18 RepVGG-A0] (main.py 282): INFO Train: [165/300][30/78]	eta 0:01:40 lr 2.686684	time 1.2069 (2.0995)	loss 3.0845 (3.0420)	grad_norm 0.3612 (0.3808)	mem 39782MB
[2023-07-07 13:35:37 RepVGG-A0] (main.py 282): INFO Train: [165/300][40/78]	eta 0:01:17 lr 2.682444	time 4.3175 (2.0472)	loss 3.1537 (3.0535)	grad_norm 0.5732 (0.3978)	mem 39782MB
[2023-07-07 13:35:51 RepVGG-A0] (main.py 282): INFO Train: [165/300][50/78]	eta 0:00:54 lr 2.678205	time 1.1967 (1.9295)	loss 3.1036 (3.0752)	grad_norm 0.3507 (0.4036)	mem 39782MB
[2023-07-07 13:36:06 RepVGG-A0] (main.py 282): INFO Train: [165/300][60/78]	eta 0:00:33 lr 2.673966	time 1.2542 (1.8653)	loss 3.0836 (3.0682)	grad_norm 0.3515 (0.3972)	mem 39782MB
[2023-07-07 13:36:22 RepVGG-A0] (main.py 282): INFO Train: [165/300][70/78]	eta 0:00:14 lr 2.669729	time 1.2769 (1.8196)	loss 3.1131 (3.0656)	grad_norm 0.3679 (0.3942)	mem 39782MB
[2023-07-07 13:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 165 training takes 0:02:21
[2023-07-07 13:36:55 RepVGG-A0] (main.py 282): INFO Train: [166/300][0/78]	eta 0:27:17 lr 2.666340	time 20.9975 (20.9975)	loss 3.0232 (3.0232)	grad_norm 0.3898 (0.3898)	mem 39782MB
[2023-07-07 13:37:11 RepVGG-A0] (main.py 282): INFO Train: [166/300][10/78]	eta 0:03:49 lr 2.662104	time 1.1926 (3.3740)	loss 3.0287 (3.0192)	grad_norm 0.3915 (0.4194)	mem 39782MB
[2023-07-07 13:37:26 RepVGG-A0] (main.py 282): INFO Train: [166/300][20/78]	eta 0:02:23 lr 2.657870	time 1.1749 (2.4782)	loss 3.0151 (3.0188)	grad_norm 0.4045 (0.4189)	mem 39782MB
[2023-07-07 13:37:41 RepVGG-A0] (main.py 282): INFO Train: [166/300][30/78]	eta 0:01:43 lr 2.653636	time 1.1292 (2.1652)	loss 3.0149 (3.0151)	grad_norm 0.4185 (0.4064)	mem 39782MB
[2023-07-07 13:37:59 RepVGG-A0] (main.py 282): INFO Train: [166/300][40/78]	eta 0:01:19 lr 2.649404	time 3.8261 (2.0800)	loss 2.9371 (3.0187)	grad_norm 0.3645 (0.4017)	mem 39782MB
[2023-07-07 13:38:14 RepVGG-A0] (main.py 282): INFO Train: [166/300][50/78]	eta 0:00:55 lr 2.645172	time 1.1961 (1.9694)	loss 3.0290 (3.0200)	grad_norm 0.3789 (0.4005)	mem 39782MB
[2023-07-07 13:38:30 RepVGG-A0] (main.py 282): INFO Train: [166/300][60/78]	eta 0:00:34 lr 2.640941	time 1.5677 (1.8996)	loss 3.0483 (3.0201)	grad_norm 0.4208 (0.4027)	mem 39782MB
[2023-07-07 13:38:45 RepVGG-A0] (main.py 282): INFO Train: [166/300][70/78]	eta 0:00:14 lr 2.636712	time 1.5704 (1.8458)	loss 3.0816 (3.0222)	grad_norm 0.4131 (0.4046)	mem 39782MB
[2023-07-07 13:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 166 training takes 0:02:21
[2023-07-07 13:39:17 RepVGG-A0] (main.py 282): INFO Train: [167/300][0/78]	eta 0:28:39 lr 2.633329	time 22.0487 (22.0487)	loss 3.1068 (3.1068)	grad_norm 0.4661 (0.4661)	mem 39782MB
[2023-07-07 13:39:33 RepVGG-A0] (main.py 282): INFO Train: [167/300][10/78]	eta 0:03:49 lr 2.629101	time 1.1724 (3.3684)	loss 2.9905 (2.9709)	grad_norm 0.4084 (0.4003)	mem 39782MB
[2023-07-07 13:39:47 RepVGG-A0] (main.py 282): INFO Train: [167/300][20/78]	eta 0:02:23 lr 2.624874	time 1.1955 (2.4710)	loss 3.0196 (2.9626)	grad_norm 0.4423 (0.4032)	mem 39782MB
[2023-07-07 13:40:01 RepVGG-A0] (main.py 282): INFO Train: [167/300][30/78]	eta 0:01:42 lr 2.620649	time 1.1672 (2.1254)	loss 2.9506 (2.9688)	grad_norm 0.3657 (0.4048)	mem 39782MB
[2023-07-07 13:40:20 RepVGG-A0] (main.py 282): INFO Train: [167/300][40/78]	eta 0:01:18 lr 2.616424	time 2.3154 (2.0698)	loss 3.0470 (2.9697)	grad_norm 0.3943 (0.3999)	mem 39782MB
[2023-07-07 13:40:35 RepVGG-A0] (main.py 282): INFO Train: [167/300][50/78]	eta 0:00:54 lr 2.612200	time 1.1774 (1.9525)	loss 2.9795 (2.9817)	grad_norm 0.3784 (0.4076)	mem 39782MB
[2023-07-07 13:40:50 RepVGG-A0] (main.py 282): INFO Train: [167/300][60/78]	eta 0:00:33 lr 2.607978	time 1.1876 (1.8835)	loss 3.0531 (2.9876)	grad_norm 0.4593 (0.4087)	mem 39782MB
[2023-07-07 13:41:06 RepVGG-A0] (main.py 282): INFO Train: [167/300][70/78]	eta 0:00:14 lr 2.603756	time 1.5463 (1.8387)	loss 3.0506 (2.9920)	grad_norm 0.4433 (0.4107)	mem 39782MB
[2023-07-07 13:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 167 training takes 0:02:21
[2023-07-07 13:41:38 RepVGG-A0] (main.py 282): INFO Train: [168/300][0/78]	eta 0:28:03 lr 2.600380	time 21.5810 (21.5810)	loss 2.9068 (2.9068)	grad_norm 0.3901 (0.3901)	mem 39782MB
[2023-07-07 13:41:53 RepVGG-A0] (main.py 282): INFO Train: [168/300][10/78]	eta 0:03:45 lr 2.596160	time 1.1719 (3.3106)	loss 2.9054 (2.9033)	grad_norm 0.4271 (0.3940)	mem 39782MB
[2023-07-07 13:42:08 RepVGG-A0] (main.py 282): INFO Train: [168/300][20/78]	eta 0:02:22 lr 2.591942	time 1.1814 (2.4543)	loss 2.9524 (2.9375)	grad_norm 0.4163 (0.4163)	mem 39782MB
[2023-07-07 13:42:24 RepVGG-A0] (main.py 282): INFO Train: [168/300][30/78]	eta 0:01:43 lr 2.587724	time 1.5989 (2.1626)	loss 2.9751 (2.9433)	grad_norm 0.4310 (0.4117)	mem 39782MB
[2023-07-07 13:42:41 RepVGG-A0] (main.py 282): INFO Train: [168/300][40/78]	eta 0:01:17 lr 2.583508	time 3.0699 (2.0510)	loss 2.9730 (2.9580)	grad_norm 0.3683 (0.4127)	mem 39782MB
[2023-07-07 13:42:56 RepVGG-A0] (main.py 282): INFO Train: [168/300][50/78]	eta 0:00:54 lr 2.579293	time 1.1746 (1.9454)	loss 3.0388 (2.9586)	grad_norm 0.4635 (0.4107)	mem 39782MB
[2023-07-07 13:43:11 RepVGG-A0] (main.py 282): INFO Train: [168/300][60/78]	eta 0:00:33 lr 2.575079	time 1.3579 (1.8816)	loss 3.0251 (2.9663)	grad_norm 0.4068 (0.4137)	mem 39782MB
[2023-07-07 13:43:27 RepVGG-A0] (main.py 282): INFO Train: [168/300][70/78]	eta 0:00:14 lr 2.570866	time 1.1751 (1.8375)	loss 2.9716 (2.9674)	grad_norm 0.4133 (0.4139)	mem 39782MB
[2023-07-07 13:43:39 RepVGG-A0] (main.py 291): INFO EPOCH 168 training takes 0:02:21
[2023-07-07 13:43:59 RepVGG-A0] (main.py 282): INFO Train: [169/300][0/78]	eta 0:26:57 lr 2.567497	time 20.7320 (20.7320)	loss 2.9172 (2.9172)	grad_norm 0.3882 (0.3882)	mem 39782MB
[2023-07-07 13:44:15 RepVGG-A0] (main.py 282): INFO Train: [169/300][10/78]	eta 0:03:47 lr 2.563286	time 1.1734 (3.3425)	loss 3.0542 (2.9411)	grad_norm 0.4695 (0.4336)	mem 39782MB
[2023-07-07 13:44:29 RepVGG-A0] (main.py 282): INFO Train: [169/300][20/78]	eta 0:02:18 lr 2.559076	time 1.1717 (2.3947)	loss 2.9509 (2.9351)	grad_norm 0.4118 (0.4210)	mem 39782MB
[2023-07-07 13:44:45 RepVGG-A0] (main.py 282): INFO Train: [169/300][30/78]	eta 0:01:42 lr 2.554867	time 1.7352 (2.1333)	loss 2.9806 (2.9412)	grad_norm 0.4428 (0.4221)	mem 39782MB
[2023-07-07 13:45:02 RepVGG-A0] (main.py 282): INFO Train: [169/300][40/78]	eta 0:01:17 lr 2.550660	time 3.9548 (2.0397)	loss 2.9460 (2.9445)	grad_norm 0.4374 (0.4156)	mem 39782MB
[2023-07-07 13:45:18 RepVGG-A0] (main.py 282): INFO Train: [169/300][50/78]	eta 0:00:54 lr 2.546454	time 1.1749 (1.9516)	loss 2.9837 (2.9494)	grad_norm 0.3932 (0.4165)	mem 39782MB
[2023-07-07 13:45:32 RepVGG-A0] (main.py 282): INFO Train: [169/300][60/78]	eta 0:00:33 lr 2.542249	time 1.3621 (1.8678)	loss 2.9618 (2.9530)	grad_norm 0.4186 (0.4186)	mem 39782MB
[2023-07-07 13:45:47 RepVGG-A0] (main.py 282): INFO Train: [169/300][70/78]	eta 0:00:14 lr 2.538045	time 1.3266 (1.8152)	loss 2.9179 (2.9495)	grad_norm 0.3849 (0.4143)	mem 39782MB
[2023-07-07 13:45:59 RepVGG-A0] (main.py 291): INFO EPOCH 169 training takes 0:02:20
[2023-07-07 13:46:20 RepVGG-A0] (main.py 282): INFO Train: [170/300][0/78]	eta 0:27:41 lr 2.534683	time 21.3011 (21.3011)	loss 2.9090 (2.9090)	grad_norm 0.4632 (0.4632)	mem 39782MB
[2023-07-07 13:46:35 RepVGG-A0] (main.py 282): INFO Train: [170/300][10/78]	eta 0:03:39 lr 2.530481	time 1.1716 (3.2224)	loss 2.9665 (2.9428)	grad_norm 0.4123 (0.4232)	mem 39782MB
[2023-07-07 13:46:49 RepVGG-A0] (main.py 282): INFO Train: [170/300][20/78]	eta 0:02:18 lr 2.526280	time 1.1749 (2.3882)	loss 2.9517 (2.9346)	grad_norm 0.3891 (0.4195)	mem 39782MB
[2023-07-07 13:47:05 RepVGG-A0] (main.py 282): INFO Train: [170/300][30/78]	eta 0:01:42 lr 2.522081	time 1.7302 (2.1368)	loss 2.9415 (2.9310)	grad_norm 0.3868 (0.4124)	mem 39782MB
[2023-07-07 13:47:24 RepVGG-A0] (main.py 282): INFO Train: [170/300][40/78]	eta 0:01:18 lr 2.517883	time 4.1051 (2.0567)	loss 2.9796 (2.9362)	grad_norm 0.4497 (0.4109)	mem 39782MB
[2023-07-07 13:47:38 RepVGG-A0] (main.py 282): INFO Train: [170/300][50/78]	eta 0:00:54 lr 2.513686	time 1.1898 (1.9315)	loss 2.9940 (2.9410)	grad_norm 0.4956 (0.4200)	mem 39782MB
[2023-07-07 13:47:52 RepVGG-A0] (main.py 282): INFO Train: [170/300][60/78]	eta 0:00:33 lr 2.509491	time 1.1881 (1.8547)	loss 2.9631 (2.9455)	grad_norm 0.3695 (0.4194)	mem 39782MB
[2023-07-07 13:48:08 RepVGG-A0] (main.py 282): INFO Train: [170/300][70/78]	eta 0:00:14 lr 2.505296	time 1.6785 (1.8087)	loss 2.9647 (2.9444)	grad_norm 0.4598 (0.4178)	mem 39782MB
[2023-07-07 13:48:19 RepVGG-A0] (main.py 291): INFO EPOCH 170 training takes 0:02:20
[2023-07-07 13:48:41 RepVGG-A0] (main.py 282): INFO Train: [171/300][0/78]	eta 0:28:37 lr 2.501942	time 22.0245 (22.0245)	loss 2.9477 (2.9477)	grad_norm 0.4047 (0.4047)	mem 39782MB
[2023-07-07 13:48:56 RepVGG-A0] (main.py 282): INFO Train: [171/300][10/78]	eta 0:03:45 lr 2.497750	time 1.1721 (3.3156)	loss 2.9102 (2.8991)	grad_norm 0.4071 (0.4257)	mem 39782MB
[2023-07-07 13:49:10 RepVGG-A0] (main.py 282): INFO Train: [171/300][20/78]	eta 0:02:19 lr 2.493559	time 1.1734 (2.4064)	loss 2.9088 (2.8979)	grad_norm 0.4124 (0.4168)	mem 39782MB
[2023-07-07 13:49:26 RepVGG-A0] (main.py 282): INFO Train: [171/300][30/78]	eta 0:01:43 lr 2.489369	time 1.1929 (2.1628)	loss 2.8676 (2.9105)	grad_norm 0.4142 (0.4192)	mem 39782MB
[2023-07-07 13:49:45 RepVGG-A0] (main.py 282): INFO Train: [171/300][40/78]	eta 0:01:19 lr 2.485181	time 3.6071 (2.0984)	loss 2.9775 (2.9247)	grad_norm 0.4302 (0.4287)	mem 39782MB
[2023-07-07 13:50:00 RepVGG-A0] (main.py 282): INFO Train: [171/300][50/78]	eta 0:00:55 lr 2.480994	time 1.1758 (1.9720)	loss 2.9222 (2.9247)	grad_norm 0.4170 (0.4232)	mem 39782MB
[2023-07-07 13:50:15 RepVGG-A0] (main.py 282): INFO Train: [171/300][60/78]	eta 0:00:34 lr 2.476808	time 1.1553 (1.9003)	loss 2.9265 (2.9304)	grad_norm 0.4056 (0.4211)	mem 39782MB
[2023-07-07 13:50:31 RepVGG-A0] (main.py 282): INFO Train: [171/300][70/78]	eta 0:00:14 lr 2.472624	time 1.3794 (1.8483)	loss 2.9960 (2.9358)	grad_norm 0.3904 (0.4189)	mem 39782MB
[2023-07-07 13:50:42 RepVGG-A0] (main.py 291): INFO EPOCH 171 training takes 0:02:22
[2023-07-07 13:51:02 RepVGG-A0] (main.py 282): INFO Train: [172/300][0/78]	eta 0:26:07 lr 2.469277	time 20.0944 (20.0944)	loss 2.9419 (2.9419)	grad_norm 0.4223 (0.4223)	mem 39782MB
[2023-07-07 13:51:18 RepVGG-A0] (main.py 282): INFO Train: [172/300][10/78]	eta 0:03:45 lr 2.465095	time 1.1896 (3.3210)	loss 2.7909 (2.8892)	grad_norm 0.3867 (0.4099)	mem 39782MB
[2023-07-07 13:51:32 RepVGG-A0] (main.py 282): INFO Train: [172/300][20/78]	eta 0:02:18 lr 2.460914	time 1.1730 (2.3950)	loss 3.0186 (2.9070)	grad_norm 0.4396 (0.4193)	mem 39782MB
[2023-07-07 13:51:47 RepVGG-A0] (main.py 282): INFO Train: [172/300][30/78]	eta 0:01:41 lr 2.456735	time 1.1749 (2.1168)	loss 2.9413 (2.9095)	grad_norm 0.4349 (0.4197)	mem 39782MB
[2023-07-07 13:52:04 RepVGG-A0] (main.py 282): INFO Train: [172/300][40/78]	eta 0:01:16 lr 2.452557	time 2.0378 (2.0017)	loss 2.9291 (2.9106)	grad_norm 0.4100 (0.4195)	mem 39782MB
[2023-07-07 13:52:19 RepVGG-A0] (main.py 282): INFO Train: [172/300][50/78]	eta 0:00:53 lr 2.448380	time 1.6147 (1.8990)	loss 3.0316 (2.9107)	grad_norm 0.4344 (0.4189)	mem 39782MB
[2023-07-07 13:52:35 RepVGG-A0] (main.py 282): INFO Train: [172/300][60/78]	eta 0:00:33 lr 2.444205	time 1.1452 (1.8542)	loss 2.8826 (2.9167)	grad_norm 0.3808 (0.4183)	mem 39782MB
[2023-07-07 13:52:50 RepVGG-A0] (main.py 282): INFO Train: [172/300][70/78]	eta 0:00:14 lr 2.440031	time 1.1380 (1.8087)	loss 2.9993 (2.9182)	grad_norm 0.5303 (0.4188)	mem 39782MB
[2023-07-07 13:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 172 training takes 0:02:20
[2023-07-07 13:53:23 RepVGG-A0] (main.py 282): INFO Train: [173/300][0/78]	eta 0:26:59 lr 2.436693	time 20.7568 (20.7568)	loss 3.0295 (3.0295)	grad_norm 0.5914 (0.5914)	mem 39782MB
[2023-07-07 13:53:37 RepVGG-A0] (main.py 282): INFO Train: [173/300][10/78]	eta 0:03:40 lr 2.432521	time 1.1729 (3.2461)	loss 2.9703 (3.0135)	grad_norm 0.3664 (0.4833)	mem 39782MB
[2023-07-07 13:53:52 RepVGG-A0] (main.py 282): INFO Train: [173/300][20/78]	eta 0:02:18 lr 2.428351	time 1.2814 (2.3937)	loss 2.9462 (2.9619)	grad_norm 0.3851 (0.4326)	mem 39782MB
[2023-07-07 13:54:07 RepVGG-A0] (main.py 282): INFO Train: [173/300][30/78]	eta 0:01:41 lr 2.424183	time 1.3024 (2.1146)	loss 2.7960 (2.9325)	grad_norm 0.3749 (0.4145)	mem 39782MB
[2023-07-07 13:54:24 RepVGG-A0] (main.py 282): INFO Train: [173/300][40/78]	eta 0:01:16 lr 2.420015	time 3.7686 (2.0173)	loss 2.8713 (2.9255)	grad_norm 0.3728 (0.4113)	mem 39782MB
[2023-07-07 13:54:41 RepVGG-A0] (main.py 282): INFO Train: [173/300][50/78]	eta 0:00:54 lr 2.415849	time 1.1268 (1.9375)	loss 2.8934 (2.9232)	grad_norm 0.3827 (0.4085)	mem 39782MB
[2023-07-07 13:54:56 RepVGG-A0] (main.py 282): INFO Train: [173/300][60/78]	eta 0:00:33 lr 2.411685	time 1.1712 (1.8654)	loss 2.9381 (2.9167)	grad_norm 0.4212 (0.4086)	mem 39782MB
[2023-07-07 13:55:11 RepVGG-A0] (main.py 282): INFO Train: [173/300][70/78]	eta 0:00:14 lr 2.407522	time 1.1743 (1.8159)	loss 2.9334 (2.9203)	grad_norm 0.3730 (0.4077)	mem 39782MB
[2023-07-07 13:55:22 RepVGG-A0] (main.py 291): INFO EPOCH 173 training takes 0:02:20
[2023-07-07 13:55:45 RepVGG-A0] (main.py 282): INFO Train: [174/300][0/78]	eta 0:28:53 lr 2.404192	time 22.2272 (22.2272)	loss 2.9326 (2.9326)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 13:55:59 RepVGG-A0] (main.py 282): INFO Train: [174/300][10/78]	eta 0:03:43 lr 2.400032	time 1.1718 (3.2935)	loss 2.8778 (2.8714)	grad_norm 0.3906 (0.4351)	mem 39782MB
[2023-07-07 13:56:13 RepVGG-A0] (main.py 282): INFO Train: [174/300][20/78]	eta 0:02:19 lr 2.395873	time 1.1917 (2.4090)	loss 2.8790 (2.8739)	grad_norm 0.4054 (0.4213)	mem 39782MB
[2023-07-07 13:56:28 RepVGG-A0] (main.py 282): INFO Train: [174/300][30/78]	eta 0:01:41 lr 2.391715	time 1.5257 (2.1249)	loss 2.9327 (2.8804)	grad_norm 0.4346 (0.4207)	mem 39782MB
[2023-07-07 13:56:46 RepVGG-A0] (main.py 282): INFO Train: [174/300][40/78]	eta 0:01:17 lr 2.387559	time 3.8215 (2.0411)	loss 2.8917 (2.8849)	grad_norm 0.4119 (0.4222)	mem 39782MB
[2023-07-07 13:57:01 RepVGG-A0] (main.py 282): INFO Train: [174/300][50/78]	eta 0:00:54 lr 2.383404	time 1.1893 (1.9406)	loss 2.8734 (2.8901)	grad_norm 0.3976 (0.4227)	mem 39782MB
[2023-07-07 13:57:17 RepVGG-A0] (main.py 282): INFO Train: [174/300][60/78]	eta 0:00:33 lr 2.379251	time 1.2055 (1.8761)	loss 2.8710 (2.8893)	grad_norm 0.3892 (0.4201)	mem 39782MB
[2023-07-07 13:57:32 RepVGG-A0] (main.py 282): INFO Train: [174/300][70/78]	eta 0:00:14 lr 2.375099	time 1.5196 (1.8260)	loss 2.9296 (2.8953)	grad_norm 0.4304 (0.4233)	mem 39782MB
[2023-07-07 13:57:44 RepVGG-A0] (main.py 291): INFO EPOCH 174 training takes 0:02:21
[2023-07-07 13:58:06 RepVGG-A0] (main.py 282): INFO Train: [175/300][0/78]	eta 0:28:48 lr 2.371779	time 22.1613 (22.1613)	loss 2.8512 (2.8512)	grad_norm 0.4550 (0.4550)	mem 39782MB
[2023-07-07 13:58:20 RepVGG-A0] (main.py 282): INFO Train: [175/300][10/78]	eta 0:03:45 lr 2.367630	time 1.1724 (3.3198)	loss 2.8827 (2.8848)	grad_norm 0.3782 (0.4255)	mem 39782MB
[2023-07-07 13:58:34 RepVGG-A0] (main.py 282): INFO Train: [175/300][20/78]	eta 0:02:18 lr 2.363482	time 1.1731 (2.3922)	loss 2.9150 (2.8771)	grad_norm 0.4397 (0.4166)	mem 39782MB
[2023-07-07 13:58:50 RepVGG-A0] (main.py 282): INFO Train: [175/300][30/78]	eta 0:01:42 lr 2.359336	time 1.2730 (2.1336)	loss 2.8302 (2.8765)	grad_norm 0.3908 (0.4234)	mem 39782MB
[2023-07-07 13:59:08 RepVGG-A0] (main.py 282): INFO Train: [175/300][40/78]	eta 0:01:18 lr 2.355192	time 3.6396 (2.0590)	loss 2.9557 (2.8885)	grad_norm 0.4323 (0.4225)	mem 39782MB
[2023-07-07 13:59:23 RepVGG-A0] (main.py 282): INFO Train: [175/300][50/78]	eta 0:00:54 lr 2.351049	time 1.1743 (1.9512)	loss 2.9110 (2.9012)	grad_norm 0.4569 (0.4365)	mem 39782MB
[2023-07-07 13:59:38 RepVGG-A0] (main.py 282): INFO Train: [175/300][60/78]	eta 0:00:33 lr 2.346907	time 1.1416 (1.8776)	loss 2.9401 (2.9035)	grad_norm 0.4288 (0.4316)	mem 39782MB
[2023-07-07 13:59:52 RepVGG-A0] (main.py 282): INFO Train: [175/300][70/78]	eta 0:00:14 lr 2.342767	time 1.2306 (1.8109)	loss 2.9249 (2.9023)	grad_norm 0.4479 (0.4276)	mem 39782MB
[2023-07-07 14:00:04 RepVGG-A0] (main.py 291): INFO EPOCH 175 training takes 0:02:20
[2023-07-07 14:00:26 RepVGG-A0] (main.py 282): INFO Train: [176/300][0/78]	eta 0:28:40 lr 2.339457	time 22.0591 (22.0591)	loss 2.7890 (2.7890)	grad_norm 0.4049 (0.4049)	mem 39782MB
[2023-07-07 14:00:40 RepVGG-A0] (main.py 282): INFO Train: [176/300][10/78]	eta 0:03:41 lr 2.335319	time 1.1724 (3.2537)	loss 2.8683 (2.8349)	grad_norm 0.4052 (0.4060)	mem 39782MB
[2023-07-07 14:00:54 RepVGG-A0] (main.py 282): INFO Train: [176/300][20/78]	eta 0:02:18 lr 2.331184	time 1.1913 (2.3964)	loss 2.8276 (2.8406)	grad_norm 0.3774 (0.4057)	mem 39782MB
[2023-07-07 14:01:11 RepVGG-A0] (main.py 282): INFO Train: [176/300][30/78]	eta 0:01:42 lr 2.327050	time 1.2977 (2.1417)	loss 2.8829 (2.8530)	grad_norm 0.4550 (0.4164)	mem 39782MB
[2023-07-07 14:01:28 RepVGG-A0] (main.py 282): INFO Train: [176/300][40/78]	eta 0:01:17 lr 2.322917	time 3.6430 (2.0456)	loss 2.8920 (2.8623)	grad_norm 0.4153 (0.4206)	mem 39782MB
[2023-07-07 14:01:44 RepVGG-A0] (main.py 282): INFO Train: [176/300][50/78]	eta 0:00:54 lr 2.318786	time 1.2363 (1.9486)	loss 2.9234 (2.8682)	grad_norm 0.4460 (0.4203)	mem 39782MB
[2023-07-07 14:01:59 RepVGG-A0] (main.py 282): INFO Train: [176/300][60/78]	eta 0:00:33 lr 2.314657	time 1.1807 (1.8801)	loss 2.8654 (2.8714)	grad_norm 0.4125 (0.4201)	mem 39782MB
[2023-07-07 14:02:14 RepVGG-A0] (main.py 282): INFO Train: [176/300][70/78]	eta 0:00:14 lr 2.310529	time 1.4504 (1.8279)	loss 2.9668 (2.8772)	grad_norm 0.4762 (0.4207)	mem 39782MB
[2023-07-07 14:02:25 RepVGG-A0] (main.py 291): INFO EPOCH 176 training takes 0:02:20
[2023-07-07 14:02:47 RepVGG-A0] (main.py 282): INFO Train: [177/300][0/78]	eta 0:28:21 lr 2.307228	time 21.8085 (21.8085)	loss 2.8301 (2.8301)	grad_norm 0.4294 (0.4294)	mem 39782MB
[2023-07-07 14:03:03 RepVGG-A0] (main.py 282): INFO Train: [177/300][10/78]	eta 0:03:52 lr 2.303104	time 1.1710 (3.4127)	loss 2.8449 (2.8596)	grad_norm 0.4109 (0.4347)	mem 39782MB
[2023-07-07 14:03:17 RepVGG-A0] (main.py 282): INFO Train: [177/300][20/78]	eta 0:02:23 lr 2.298980	time 1.1772 (2.4825)	loss 2.8541 (2.8584)	grad_norm 0.4054 (0.4214)	mem 39782MB
[2023-07-07 14:03:32 RepVGG-A0] (main.py 282): INFO Train: [177/300][30/78]	eta 0:01:43 lr 2.294859	time 1.2790 (2.1611)	loss 2.8649 (2.8623)	grad_norm 0.4534 (0.4241)	mem 39782MB
[2023-07-07 14:03:51 RepVGG-A0] (main.py 282): INFO Train: [177/300][40/78]	eta 0:01:19 lr 2.290739	time 3.6476 (2.0860)	loss 2.8784 (2.8674)	grad_norm 0.4210 (0.4281)	mem 39782MB
[2023-07-07 14:04:05 RepVGG-A0] (main.py 282): INFO Train: [177/300][50/78]	eta 0:00:55 lr 2.286621	time 1.1835 (1.9686)	loss 2.8893 (2.8762)	grad_norm 0.4044 (0.4290)	mem 39782MB
[2023-07-07 14:04:20 RepVGG-A0] (main.py 282): INFO Train: [177/300][60/78]	eta 0:00:33 lr 2.282504	time 1.1746 (1.8800)	loss 2.8857 (2.8733)	grad_norm 0.4053 (0.4258)	mem 39782MB
[2023-07-07 14:04:36 RepVGG-A0] (main.py 282): INFO Train: [177/300][70/78]	eta 0:00:14 lr 2.278389	time 1.4493 (1.8399)	loss 2.9401 (2.8743)	grad_norm 0.4117 (0.4240)	mem 39782MB
[2023-07-07 14:04:48 RepVGG-A0] (main.py 291): INFO EPOCH 177 training takes 0:02:22
[2023-07-07 14:05:08 RepVGG-A0] (main.py 282): INFO Train: [178/300][0/78]	eta 0:26:37 lr 2.275098	time 20.4820 (20.4820)	loss 2.9423 (2.9423)	grad_norm 0.5030 (0.5030)	mem 39782MB
[2023-07-07 14:05:23 RepVGG-A0] (main.py 282): INFO Train: [178/300][10/78]	eta 0:03:40 lr 2.270986	time 1.1722 (3.2393)	loss 2.8527 (2.9070)	grad_norm 0.4013 (0.4872)	mem 39782MB
[2023-07-07 14:05:39 RepVGG-A0] (main.py 282): INFO Train: [178/300][20/78]	eta 0:02:20 lr 2.266876	time 1.1731 (2.4216)	loss 2.8127 (2.8731)	grad_norm 0.4032 (0.4468)	mem 39782MB
[2023-07-07 14:05:54 RepVGG-A0] (main.py 282): INFO Train: [178/300][30/78]	eta 0:01:42 lr 2.262767	time 1.3387 (2.1378)	loss 2.9832 (2.8728)	grad_norm 0.5090 (0.4396)	mem 39782MB
[2023-07-07 14:06:12 RepVGG-A0] (main.py 282): INFO Train: [178/300][40/78]	eta 0:01:18 lr 2.258660	time 3.1704 (2.0588)	loss 2.7874 (2.8777)	grad_norm 0.3990 (0.4328)	mem 39782MB
[2023-07-07 14:06:27 RepVGG-A0] (main.py 282): INFO Train: [178/300][50/78]	eta 0:00:54 lr 2.254555	time 1.1715 (1.9439)	loss 2.8903 (2.8772)	grad_norm 0.4083 (0.4322)	mem 39782MB
[2023-07-07 14:06:42 RepVGG-A0] (main.py 282): INFO Train: [178/300][60/78]	eta 0:00:33 lr 2.250452	time 1.4212 (1.8769)	loss 2.8695 (2.8737)	grad_norm 0.4020 (0.4271)	mem 39782MB
[2023-07-07 14:06:57 RepVGG-A0] (main.py 282): INFO Train: [178/300][70/78]	eta 0:00:14 lr 2.246350	time 1.1714 (1.8230)	loss 2.9052 (2.8736)	grad_norm 0.4972 (0.4286)	mem 39782MB
[2023-07-07 14:07:09 RepVGG-A0] (main.py 291): INFO EPOCH 178 training takes 0:02:20
[2023-07-07 14:07:31 RepVGG-A0] (main.py 282): INFO Train: [179/300][0/78]	eta 0:29:36 lr 2.243069	time 22.7734 (22.7734)	loss 2.8633 (2.8633)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 14:07:45 RepVGG-A0] (main.py 282): INFO Train: [179/300][10/78]	eta 0:03:45 lr 2.238971	time 1.1699 (3.3163)	loss 2.9088 (2.8191)	grad_norm 0.4358 (0.4013)	mem 39782MB
[2023-07-07 14:08:00 RepVGG-A0] (main.py 282): INFO Train: [179/300][20/78]	eta 0:02:22 lr 2.234874	time 1.1735 (2.4604)	loss 2.8955 (2.8286)	grad_norm 0.4070 (0.4127)	mem 39782MB
[2023-07-07 14:08:15 RepVGG-A0] (main.py 282): INFO Train: [179/300][30/78]	eta 0:01:43 lr 2.230778	time 1.1972 (2.1500)	loss 2.8233 (2.8347)	grad_norm 0.3977 (0.4138)	mem 39782MB
[2023-07-07 14:08:33 RepVGG-A0] (main.py 282): INFO Train: [179/300][40/78]	eta 0:01:18 lr 2.226685	time 1.4532 (2.0551)	loss 2.8784 (2.8376)	grad_norm 0.4566 (0.4153)	mem 39782MB
[2023-07-07 14:08:48 RepVGG-A0] (main.py 282): INFO Train: [179/300][50/78]	eta 0:00:54 lr 2.222593	time 1.1754 (1.9507)	loss 2.7994 (2.8480)	grad_norm 0.4202 (0.4243)	mem 39782MB
[2023-07-07 14:09:03 RepVGG-A0] (main.py 282): INFO Train: [179/300][60/78]	eta 0:00:33 lr 2.218503	time 1.1929 (1.8786)	loss 2.8862 (2.8562)	grad_norm 0.4486 (0.4242)	mem 39782MB
[2023-07-07 14:09:18 RepVGG-A0] (main.py 282): INFO Train: [179/300][70/78]	eta 0:00:14 lr 2.214415	time 1.1431 (1.8249)	loss 2.8995 (2.8616)	grad_norm 0.4134 (0.4272)	mem 39782MB
[2023-07-07 14:09:30 RepVGG-A0] (main.py 291): INFO EPOCH 179 training takes 0:02:21
[2023-07-07 14:09:52 RepVGG-A0] (main.py 282): INFO Train: [180/300][0/78]	eta 0:28:51 lr 2.211146	time 22.1938 (22.1938)	loss 2.7502 (2.7502)	grad_norm 0.4234 (0.4234)	mem 39782MB
[2023-07-07 14:10:06 RepVGG-A0] (main.py 282): INFO Train: [180/300][10/78]	eta 0:03:42 lr 2.207061	time 1.1736 (3.2761)	loss 2.8310 (2.8086)	grad_norm 0.4227 (0.4185)	mem 39782MB
[2023-07-07 14:10:21 RepVGG-A0] (main.py 282): INFO Train: [180/300][20/78]	eta 0:02:21 lr 2.202977	time 1.2549 (2.4433)	loss 2.8418 (2.8176)	grad_norm 0.4307 (0.4238)	mem 39782MB
[2023-07-07 14:10:38 RepVGG-A0] (main.py 282): INFO Train: [180/300][30/78]	eta 0:01:45 lr 2.198896	time 2.2200 (2.1906)	loss 2.8862 (2.8284)	grad_norm 0.4013 (0.4360)	mem 39782MB
[2023-07-07 14:10:55 RepVGG-A0] (main.py 282): INFO Train: [180/300][40/78]	eta 0:01:18 lr 2.194816	time 3.1692 (2.0657)	loss 2.8715 (2.8341)	grad_norm 0.4398 (0.4329)	mem 39782MB
[2023-07-07 14:11:09 RepVGG-A0] (main.py 282): INFO Train: [180/300][50/78]	eta 0:00:54 lr 2.190738	time 1.1731 (1.9478)	loss 2.8413 (2.8426)	grad_norm 0.4570 (0.4285)	mem 39782MB
[2023-07-07 14:11:25 RepVGG-A0] (main.py 282): INFO Train: [180/300][60/78]	eta 0:00:33 lr 2.186662	time 1.4733 (1.8878)	loss 2.8222 (2.8427)	grad_norm 0.4141 (0.4297)	mem 39782MB
[2023-07-07 14:11:38 RepVGG-A0] (main.py 282): INFO Train: [180/300][70/78]	eta 0:00:14 lr 2.182588	time 1.1766 (1.8081)	loss 2.8453 (2.8470)	grad_norm 0.4716 (0.4313)	mem 39782MB
[2023-07-07 14:11:51 RepVGG-A0] (main.py 291): INFO EPOCH 180 training takes 0:02:20
[2023-07-07 14:12:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.600 (17.600)	Loss 2.2331 (2.2331)	Acc@1 51.160 (51.160)	Acc@5 75.751 (75.751)	Mem 39782MB
[2023-07-07 14:12:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 51.752 Acc@5 76.092
[2023-07-07 14:12:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 180: 51.752%
[2023-07-07 14:12:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 51.75%
[2023-07-07 14:12:30 RepVGG-A0] (main.py 282): INFO Train: [181/300][0/78]	eta 0:27:12 lr 2.179330	time 20.9236 (20.9236)	loss 2.7940 (2.7940)	grad_norm 0.4137 (0.4137)	mem 39782MB
[2023-07-07 14:12:47 RepVGG-A0] (main.py 282): INFO Train: [181/300][10/78]	eta 0:03:50 lr 2.175259	time 1.1705 (3.3917)	loss 2.7758 (2.8306)	grad_norm 0.3866 (0.4094)	mem 39782MB
[2023-07-07 14:13:01 RepVGG-A0] (main.py 282): INFO Train: [181/300][20/78]	eta 0:02:23 lr 2.171190	time 1.1963 (2.4660)	loss 2.8817 (2.8213)	grad_norm 0.4492 (0.4071)	mem 39782MB
[2023-07-07 14:13:17 RepVGG-A0] (main.py 282): INFO Train: [181/300][30/78]	eta 0:01:44 lr 2.167123	time 1.7355 (2.1797)	loss 2.8652 (2.8230)	grad_norm 0.4161 (0.4194)	mem 39782MB
[2023-07-07 14:13:34 RepVGG-A0] (main.py 282): INFO Train: [181/300][40/78]	eta 0:01:18 lr 2.163058	time 4.2174 (2.0632)	loss 2.8602 (2.8239)	grad_norm 0.4424 (0.4200)	mem 39782MB
[2023-07-07 14:13:49 RepVGG-A0] (main.py 282): INFO Train: [181/300][50/78]	eta 0:00:54 lr 2.158994	time 1.1742 (1.9533)	loss 2.8295 (2.8288)	grad_norm 0.4372 (0.4223)	mem 39782MB
[2023-07-07 14:14:03 RepVGG-A0] (main.py 282): INFO Train: [181/300][60/78]	eta 0:00:33 lr 2.154933	time 1.1743 (1.8716)	loss 2.8992 (2.8370)	grad_norm 0.4500 (0.4270)	mem 39782MB
[2023-07-07 14:14:19 RepVGG-A0] (main.py 282): INFO Train: [181/300][70/78]	eta 0:00:14 lr 2.150873	time 1.4392 (1.8325)	loss 2.8752 (2.8350)	grad_norm 0.4354 (0.4248)	mem 39782MB
[2023-07-07 14:14:30 RepVGG-A0] (main.py 291): INFO EPOCH 181 training takes 0:02:20
[2023-07-07 14:14:51 RepVGG-A0] (main.py 282): INFO Train: [182/300][0/78]	eta 0:27:07 lr 2.147627	time 20.8595 (20.8595)	loss 2.8138 (2.8138)	grad_norm 0.4604 (0.4604)	mem 39782MB
[2023-07-07 14:15:05 RepVGG-A0] (main.py 282): INFO Train: [182/300][10/78]	eta 0:03:36 lr 2.143570	time 1.1708 (3.1895)	loss 2.8269 (2.8096)	grad_norm 0.3832 (0.4279)	mem 39782MB
[2023-07-07 14:15:20 RepVGG-A0] (main.py 282): INFO Train: [182/300][20/78]	eta 0:02:17 lr 2.139516	time 1.1721 (2.3697)	loss 2.8607 (2.8146)	grad_norm 0.4696 (0.4289)	mem 39782MB
[2023-07-07 14:15:35 RepVGG-A0] (main.py 282): INFO Train: [182/300][30/78]	eta 0:01:40 lr 2.135464	time 1.1541 (2.0947)	loss 2.7530 (2.8350)	grad_norm 0.4038 (0.4527)	mem 39782MB
[2023-07-07 14:15:53 RepVGG-A0] (main.py 282): INFO Train: [182/300][40/78]	eta 0:01:17 lr 2.131413	time 4.0352 (2.0305)	loss 2.8177 (2.8324)	grad_norm 0.4073 (0.4402)	mem 39782MB
[2023-07-07 14:16:08 RepVGG-A0] (main.py 282): INFO Train: [182/300][50/78]	eta 0:00:54 lr 2.127364	time 1.1731 (1.9302)	loss 2.8506 (2.8346)	grad_norm 0.3986 (0.4338)	mem 39782MB
[2023-07-07 14:16:23 RepVGG-A0] (main.py 282): INFO Train: [182/300][60/78]	eta 0:00:33 lr 2.123318	time 1.1825 (1.8556)	loss 2.8776 (2.8364)	grad_norm 0.4175 (0.4315)	mem 39782MB
[2023-07-07 14:16:39 RepVGG-A0] (main.py 282): INFO Train: [182/300][70/78]	eta 0:00:14 lr 2.119273	time 1.1717 (1.8139)	loss 2.9245 (2.8429)	grad_norm 0.5108 (0.4387)	mem 39782MB
[2023-07-07 14:16:51 RepVGG-A0] (main.py 291): INFO EPOCH 182 training takes 0:02:20
[2023-07-07 14:17:12 RepVGG-A0] (main.py 282): INFO Train: [183/300][0/78]	eta 0:27:55 lr 2.116039	time 21.4819 (21.4819)	loss 2.8103 (2.8103)	grad_norm 0.4088 (0.4088)	mem 39782MB
[2023-07-07 14:17:27 RepVGG-A0] (main.py 282): INFO Train: [183/300][10/78]	eta 0:03:46 lr 2.111997	time 1.1723 (3.3265)	loss 2.8220 (2.8120)	grad_norm 0.4117 (0.4263)	mem 39782MB
[2023-07-07 14:17:41 RepVGG-A0] (main.py 282): INFO Train: [183/300][20/78]	eta 0:02:20 lr 2.107958	time 1.1750 (2.4140)	loss 2.7797 (2.8203)	grad_norm 0.4094 (0.4277)	mem 39782MB
[2023-07-07 14:17:57 RepVGG-A0] (main.py 282): INFO Train: [183/300][30/78]	eta 0:01:43 lr 2.103921	time 1.4292 (2.1497)	loss 2.7950 (2.8163)	grad_norm 0.4136 (0.4238)	mem 39782MB
[2023-07-07 14:18:15 RepVGG-A0] (main.py 282): INFO Train: [183/300][40/78]	eta 0:01:17 lr 2.099886	time 3.7698 (2.0454)	loss 2.8134 (2.8243)	grad_norm 0.4417 (0.4279)	mem 39782MB
[2023-07-07 14:18:30 RepVGG-A0] (main.py 282): INFO Train: [183/300][50/78]	eta 0:00:54 lr 2.095852	time 1.1742 (1.9388)	loss 2.8583 (2.8244)	grad_norm 0.4075 (0.4246)	mem 39782MB
[2023-07-07 14:18:45 RepVGG-A0] (main.py 282): INFO Train: [183/300][60/78]	eta 0:00:33 lr 2.091821	time 1.5013 (1.8659)	loss 2.8366 (2.8249)	grad_norm 0.3917 (0.4247)	mem 39782MB
[2023-07-07 14:19:00 RepVGG-A0] (main.py 282): INFO Train: [183/300][70/78]	eta 0:00:14 lr 2.087791	time 1.2041 (1.8172)	loss 2.7907 (2.8304)	grad_norm 0.4519 (0.4292)	mem 39782MB
[2023-07-07 14:19:11 RepVGG-A0] (main.py 291): INFO EPOCH 183 training takes 0:02:20
[2023-07-07 14:19:33 RepVGG-A0] (main.py 282): INFO Train: [184/300][0/78]	eta 0:28:35 lr 2.084569	time 21.9962 (21.9962)	loss 2.7806 (2.7806)	grad_norm 0.4164 (0.4164)	mem 39782MB
[2023-07-07 14:19:48 RepVGG-A0] (main.py 282): INFO Train: [184/300][10/78]	eta 0:03:51 lr 2.080544	time 1.1711 (3.4040)	loss 2.8353 (2.8031)	grad_norm 0.4092 (0.4290)	mem 39782MB
[2023-07-07 14:20:04 RepVGG-A0] (main.py 282): INFO Train: [184/300][20/78]	eta 0:02:25 lr 2.076520	time 1.1966 (2.5008)	loss 2.8415 (2.8193)	grad_norm 0.4272 (0.4374)	mem 39782MB
[2023-07-07 14:20:19 RepVGG-A0] (main.py 282): INFO Train: [184/300][30/78]	eta 0:01:45 lr 2.072498	time 1.8623 (2.1943)	loss 2.8292 (2.8138)	grad_norm 0.4715 (0.4347)	mem 39782MB
[2023-07-07 14:20:34 RepVGG-A0] (main.py 282): INFO Train: [184/300][40/78]	eta 0:01:16 lr 2.068479	time 1.8124 (2.0174)	loss 2.8712 (2.8224)	grad_norm 0.4266 (0.4359)	mem 39782MB
[2023-07-07 14:20:52 RepVGG-A0] (main.py 282): INFO Train: [184/300][50/78]	eta 0:00:55 lr 2.064461	time 1.3118 (1.9747)	loss 2.8279 (2.8240)	grad_norm 0.4441 (0.4355)	mem 39782MB
[2023-07-07 14:21:06 RepVGG-A0] (main.py 282): INFO Train: [184/300][60/78]	eta 0:00:34 lr 2.060445	time 1.2974 (1.8928)	loss 2.8189 (2.8233)	grad_norm 0.4380 (0.4349)	mem 39782MB
[2023-07-07 14:21:21 RepVGG-A0] (main.py 282): INFO Train: [184/300][70/78]	eta 0:00:14 lr 2.056432	time 1.2148 (1.8266)	loss 2.8640 (2.8268)	grad_norm 0.4162 (0.4350)	mem 39782MB
[2023-07-07 14:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 184 training takes 0:02:21
[2023-07-07 14:21:55 RepVGG-A0] (main.py 282): INFO Train: [185/300][0/78]	eta 0:28:59 lr 2.053223	time 22.3023 (22.3023)	loss 2.7847 (2.7847)	grad_norm 0.4285 (0.4285)	mem 39782MB
[2023-07-07 14:22:10 RepVGG-A0] (main.py 282): INFO Train: [185/300][10/78]	eta 0:03:49 lr 2.049213	time 1.1706 (3.3776)	loss 2.7875 (2.7979)	grad_norm 0.4397 (0.4510)	mem 39782MB
[2023-07-07 14:22:25 RepVGG-A0] (main.py 282): INFO Train: [185/300][20/78]	eta 0:02:24 lr 2.045205	time 1.1753 (2.4849)	loss 2.7627 (2.8112)	grad_norm 0.4867 (0.4514)	mem 39782MB
[2023-07-07 14:22:40 RepVGG-A0] (main.py 282): INFO Train: [185/300][30/78]	eta 0:01:43 lr 2.041199	time 1.5111 (2.1562)	loss 2.7807 (2.8062)	grad_norm 0.4233 (0.4425)	mem 39782MB
[2023-07-07 14:22:59 RepVGG-A0] (main.py 282): INFO Train: [185/300][40/78]	eta 0:01:19 lr 2.037196	time 4.2417 (2.0946)	loss 2.7743 (2.8125)	grad_norm 0.4123 (0.4435)	mem 39782MB
[2023-07-07 14:23:14 RepVGG-A0] (main.py 282): INFO Train: [185/300][50/78]	eta 0:00:55 lr 2.033194	time 1.1985 (1.9745)	loss 2.8877 (2.8137)	grad_norm 0.4245 (0.4378)	mem 39782MB
[2023-07-07 14:23:29 RepVGG-A0] (main.py 282): INFO Train: [185/300][60/78]	eta 0:00:34 lr 2.029195	time 1.1762 (1.9089)	loss 2.8688 (2.8158)	grad_norm 0.4865 (0.4370)	mem 39782MB
[2023-07-07 14:23:45 RepVGG-A0] (main.py 282): INFO Train: [185/300][70/78]	eta 0:00:14 lr 2.025198	time 1.5579 (1.8606)	loss 2.9574 (2.8317)	grad_norm 0.5153 (0.4496)	mem 39782MB
[2023-07-07 14:23:56 RepVGG-A0] (main.py 291): INFO EPOCH 185 training takes 0:02:22
[2023-07-07 14:24:16 RepVGG-A0] (main.py 282): INFO Train: [186/300][0/78]	eta 0:26:46 lr 2.022001	time 20.5958 (20.5958)	loss 2.7374 (2.7374)	grad_norm 0.3953 (0.3953)	mem 39782MB
[2023-07-07 14:24:32 RepVGG-A0] (main.py 282): INFO Train: [186/300][10/78]	eta 0:03:47 lr 2.018008	time 1.1729 (3.3448)	loss 2.8131 (2.7799)	grad_norm 0.4386 (0.4102)	mem 39782MB
[2023-07-07 14:24:46 RepVGG-A0] (main.py 282): INFO Train: [186/300][20/78]	eta 0:02:20 lr 2.014017	time 1.1720 (2.4191)	loss 2.8126 (2.7775)	grad_norm 0.4457 (0.4197)	mem 39782MB
[2023-07-07 14:25:01 RepVGG-A0] (main.py 282): INFO Train: [186/300][30/78]	eta 0:01:41 lr 2.010028	time 1.4569 (2.1195)	loss 2.7026 (2.7852)	grad_norm 0.4208 (0.4273)	mem 39782MB
[2023-07-07 14:25:19 RepVGG-A0] (main.py 282): INFO Train: [186/300][40/78]	eta 0:01:17 lr 2.006040	time 3.1810 (2.0434)	loss 2.8019 (2.7893)	grad_norm 0.3876 (0.4283)	mem 39782MB
[2023-07-07 14:25:35 RepVGG-A0] (main.py 282): INFO Train: [186/300][50/78]	eta 0:00:54 lr 2.002056	time 1.1714 (1.9487)	loss 2.7373 (2.7890)	grad_norm 0.4566 (0.4273)	mem 39782MB
[2023-07-07 14:25:50 RepVGG-A0] (main.py 282): INFO Train: [186/300][60/78]	eta 0:00:33 lr 1.998073	time 1.3487 (1.8754)	loss 2.8181 (2.7931)	grad_norm 0.4367 (0.4297)	mem 39782MB
[2023-07-07 14:26:04 RepVGG-A0] (main.py 282): INFO Train: [186/300][70/78]	eta 0:00:14 lr 1.994092	time 1.1718 (1.8157)	loss 2.8186 (2.7971)	grad_norm 0.4443 (0.4279)	mem 39782MB
[2023-07-07 14:26:16 RepVGG-A0] (main.py 291): INFO EPOCH 186 training takes 0:02:20
[2023-07-07 14:26:38 RepVGG-A0] (main.py 282): INFO Train: [187/300][0/78]	eta 0:28:31 lr 1.990909	time 21.9423 (21.9423)	loss 2.7115 (2.7115)	grad_norm 0.4073 (0.4073)	mem 39782MB
[2023-07-07 14:26:53 RepVGG-A0] (main.py 282): INFO Train: [187/300][10/78]	eta 0:03:46 lr 1.986933	time 1.1936 (3.3309)	loss 2.8355 (2.7590)	grad_norm 0.5060 (0.4395)	mem 39782MB
[2023-07-07 14:27:08 RepVGG-A0] (main.py 282): INFO Train: [187/300][20/78]	eta 0:02:23 lr 1.982958	time 1.1804 (2.4750)	loss 2.7332 (2.7668)	grad_norm 0.4179 (0.4472)	mem 39782MB
[2023-07-07 14:27:24 RepVGG-A0] (main.py 282): INFO Train: [187/300][30/78]	eta 0:01:44 lr 1.978986	time 1.3234 (2.1806)	loss 2.7584 (2.7736)	grad_norm 0.4245 (0.4434)	mem 39782MB
[2023-07-07 14:27:41 RepVGG-A0] (main.py 282): INFO Train: [187/300][40/78]	eta 0:01:18 lr 1.975016	time 1.7631 (2.0698)	loss 2.8307 (2.7827)	grad_norm 0.4820 (0.4404)	mem 39782MB
[2023-07-07 14:27:56 RepVGG-A0] (main.py 282): INFO Train: [187/300][50/78]	eta 0:00:54 lr 1.971048	time 1.2666 (1.9562)	loss 2.7862 (2.7855)	grad_norm 0.4164 (0.4371)	mem 39782MB
[2023-07-07 14:28:11 RepVGG-A0] (main.py 282): INFO Train: [187/300][60/78]	eta 0:00:33 lr 1.967083	time 1.4094 (1.8826)	loss 2.8143 (2.7902)	grad_norm 0.4245 (0.4376)	mem 39782MB
[2023-07-07 14:28:26 RepVGG-A0] (main.py 282): INFO Train: [187/300][70/78]	eta 0:00:14 lr 1.963119	time 1.3033 (1.8310)	loss 2.8321 (2.7949)	grad_norm 0.3970 (0.4364)	mem 39782MB
[2023-07-07 14:28:38 RepVGG-A0] (main.py 291): INFO EPOCH 187 training takes 0:02:21
[2023-07-07 14:28:59 RepVGG-A0] (main.py 282): INFO Train: [188/300][0/78]	eta 0:27:21 lr 1.959950	time 21.0461 (21.0461)	loss 2.8088 (2.8088)	grad_norm 0.4687 (0.4687)	mem 39782MB
[2023-07-07 14:29:14 RepVGG-A0] (main.py 282): INFO Train: [188/300][10/78]	eta 0:03:40 lr 1.955991	time 1.1912 (3.2405)	loss 2.8489 (2.7961)	grad_norm 0.5163 (0.4936)	mem 39782MB
[2023-07-07 14:29:28 RepVGG-A0] (main.py 282): INFO Train: [188/300][20/78]	eta 0:02:18 lr 1.952034	time 1.1724 (2.3866)	loss 2.8084 (2.7861)	grad_norm 0.4126 (0.4590)	mem 39782MB
[2023-07-07 14:29:44 RepVGG-A0] (main.py 282): INFO Train: [188/300][30/78]	eta 0:01:42 lr 1.948079	time 1.6241 (2.1270)	loss 2.8430 (2.7948)	grad_norm 0.4578 (0.4553)	mem 39782MB
[2023-07-07 14:30:01 RepVGG-A0] (main.py 282): INFO Train: [188/300][40/78]	eta 0:01:16 lr 1.944126	time 2.6521 (2.0167)	loss 2.7915 (2.7906)	grad_norm 0.4701 (0.4472)	mem 39782MB
[2023-07-07 14:30:16 RepVGG-A0] (main.py 282): INFO Train: [188/300][50/78]	eta 0:00:53 lr 1.940176	time 1.1921 (1.9212)	loss 2.8403 (2.7964)	grad_norm 0.4409 (0.4484)	mem 39782MB
[2023-07-07 14:30:31 RepVGG-A0] (main.py 282): INFO Train: [188/300][60/78]	eta 0:00:33 lr 1.936228	time 1.1781 (1.8532)	loss 2.7955 (2.7981)	grad_norm 0.4234 (0.4458)	mem 39782MB
[2023-07-07 14:30:46 RepVGG-A0] (main.py 282): INFO Train: [188/300][70/78]	eta 0:00:14 lr 1.932282	time 1.1725 (1.8045)	loss 2.7467 (2.7981)	grad_norm 0.4376 (0.4440)	mem 39782MB
[2023-07-07 14:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 188 training takes 0:02:19
[2023-07-07 14:31:19 RepVGG-A0] (main.py 282): INFO Train: [189/300][0/78]	eta 0:27:23 lr 1.929127	time 21.0730 (21.0730)	loss 2.7289 (2.7289)	grad_norm 0.4253 (0.4253)	mem 39782MB
[2023-07-07 14:31:34 RepVGG-A0] (main.py 282): INFO Train: [189/300][10/78]	eta 0:03:45 lr 1.925185	time 1.1929 (3.3197)	loss 2.7554 (2.7398)	grad_norm 0.4329 (0.4367)	mem 39782MB
[2023-07-07 14:31:48 RepVGG-A0] (main.py 282): INFO Train: [189/300][20/78]	eta 0:02:19 lr 1.921246	time 1.2071 (2.4074)	loss 2.9050 (2.7783)	grad_norm 0.5442 (0.4628)	mem 39782MB
[2023-07-07 14:32:04 RepVGG-A0] (main.py 282): INFO Train: [189/300][30/78]	eta 0:01:42 lr 1.917309	time 1.1789 (2.1364)	loss 2.8240 (2.7937)	grad_norm 0.4085 (0.4646)	mem 39782MB
[2023-07-07 14:32:21 RepVGG-A0] (main.py 282): INFO Train: [189/300][40/78]	eta 0:01:17 lr 1.913374	time 3.3885 (2.0379)	loss 2.7628 (2.7891)	grad_norm 0.4250 (0.4580)	mem 39782MB
[2023-07-07 14:32:37 RepVGG-A0] (main.py 282): INFO Train: [189/300][50/78]	eta 0:00:54 lr 1.909441	time 1.1350 (1.9400)	loss 2.8955 (2.7935)	grad_norm 0.5137 (0.4555)	mem 39782MB
[2023-07-07 14:32:52 RepVGG-A0] (main.py 282): INFO Train: [189/300][60/78]	eta 0:00:33 lr 1.905511	time 1.1924 (1.8648)	loss 2.8976 (2.7984)	grad_norm 0.4503 (0.4533)	mem 39782MB
[2023-07-07 14:33:07 RepVGG-A0] (main.py 282): INFO Train: [189/300][70/78]	eta 0:00:14 lr 1.901583	time 1.4254 (1.8230)	loss 2.8082 (2.8009)	grad_norm 0.3960 (0.4496)	mem 39782MB
[2023-07-07 14:33:19 RepVGG-A0] (main.py 291): INFO EPOCH 189 training takes 0:02:21
[2023-07-07 14:33:41 RepVGG-A0] (main.py 282): INFO Train: [190/300][0/78]	eta 0:28:50 lr 1.898443	time 22.1889 (22.1889)	loss 2.7885 (2.7885)	grad_norm 0.4072 (0.4072)	mem 39782MB
[2023-07-07 14:33:56 RepVGG-A0] (main.py 282): INFO Train: [190/300][10/78]	eta 0:03:46 lr 1.894519	time 1.1713 (3.3365)	loss 2.8094 (2.7631)	grad_norm 0.4427 (0.4193)	mem 39782MB
[2023-07-07 14:34:10 RepVGG-A0] (main.py 282): INFO Train: [190/300][20/78]	eta 0:02:20 lr 1.890598	time 1.1717 (2.4140)	loss 2.7590 (2.7639)	grad_norm 0.4369 (0.4279)	mem 39782MB
[2023-07-07 14:34:25 RepVGG-A0] (main.py 282): INFO Train: [190/300][30/78]	eta 0:01:42 lr 1.886679	time 1.2624 (2.1250)	loss 2.8048 (2.7676)	grad_norm 0.4388 (0.4329)	mem 39782MB
[2023-07-07 14:34:43 RepVGG-A0] (main.py 282): INFO Train: [190/300][40/78]	eta 0:01:17 lr 1.882763	time 3.1592 (2.0462)	loss 2.7942 (2.7752)	grad_norm 0.4305 (0.4336)	mem 39782MB
[2023-07-07 14:34:59 RepVGG-A0] (main.py 282): INFO Train: [190/300][50/78]	eta 0:00:54 lr 1.878848	time 1.1727 (1.9554)	loss 2.7898 (2.7775)	grad_norm 0.4950 (0.4375)	mem 39782MB
[2023-07-07 14:35:14 RepVGG-A0] (main.py 282): INFO Train: [190/300][60/78]	eta 0:00:33 lr 1.874937	time 1.5981 (1.8858)	loss 2.7822 (2.7776)	grad_norm 0.4458 (0.4381)	mem 39782MB
[2023-07-07 14:35:29 RepVGG-A0] (main.py 282): INFO Train: [190/300][70/78]	eta 0:00:14 lr 1.871027	time 1.1754 (1.8246)	loss 2.8101 (2.7806)	grad_norm 0.4468 (0.4383)	mem 39782MB
[2023-07-07 14:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 190 training takes 0:02:20
[2023-07-07 14:36:02 RepVGG-A0] (main.py 282): INFO Train: [191/300][0/78]	eta 0:28:16 lr 1.867901	time 21.7461 (21.7461)	loss 2.7237 (2.7237)	grad_norm 0.4486 (0.4486)	mem 39782MB
[2023-07-07 14:36:17 RepVGG-A0] (main.py 282): INFO Train: [191/300][10/78]	eta 0:03:49 lr 1.863996	time 1.1719 (3.3717)	loss 2.7205 (2.7414)	grad_norm 0.4554 (0.4545)	mem 39782MB
[2023-07-07 14:36:33 RepVGG-A0] (main.py 282): INFO Train: [191/300][20/78]	eta 0:02:24 lr 1.860094	time 1.1820 (2.4895)	loss 2.7566 (2.7492)	grad_norm 0.4229 (0.4408)	mem 39782MB
[2023-07-07 14:36:48 RepVGG-A0] (main.py 282): INFO Train: [191/300][30/78]	eta 0:01:45 lr 1.856194	time 1.1569 (2.1980)	loss 2.7581 (2.7548)	grad_norm 0.4214 (0.4470)	mem 39782MB
[2023-07-07 14:37:06 RepVGG-A0] (main.py 282): INFO Train: [191/300][40/78]	eta 0:01:19 lr 1.852296	time 3.1636 (2.0992)	loss 2.7440 (2.7559)	grad_norm 0.4349 (0.4468)	mem 39782MB
[2023-07-07 14:37:21 RepVGG-A0] (main.py 282): INFO Train: [191/300][50/78]	eta 0:00:55 lr 1.848400	time 1.1733 (1.9727)	loss 2.8129 (2.7609)	grad_norm 0.4610 (0.4467)	mem 39782MB
[2023-07-07 14:37:36 RepVGG-A0] (main.py 282): INFO Train: [191/300][60/78]	eta 0:00:34 lr 1.844507	time 1.1289 (1.9057)	loss 2.7616 (2.7626)	grad_norm 0.4316 (0.4449)	mem 39782MB
[2023-07-07 14:37:51 RepVGG-A0] (main.py 282): INFO Train: [191/300][70/78]	eta 0:00:14 lr 1.840617	time 1.3071 (1.8450)	loss 2.7578 (2.7631)	grad_norm 0.4229 (0.4425)	mem 39782MB
[2023-07-07 14:38:03 RepVGG-A0] (main.py 291): INFO EPOCH 191 training takes 0:02:22
[2023-07-07 14:38:25 RepVGG-A0] (main.py 282): INFO Train: [192/300][0/78]	eta 0:28:28 lr 1.837506	time 21.9025 (21.9025)	loss 2.6664 (2.6664)	grad_norm 0.4034 (0.4034)	mem 39782MB
[2023-07-07 14:38:39 RepVGG-A0] (main.py 282): INFO Train: [192/300][10/78]	eta 0:03:42 lr 1.833620	time 1.1718 (3.2736)	loss 2.8083 (2.7454)	grad_norm 0.5598 (0.4831)	mem 39782MB
[2023-07-07 14:38:53 RepVGG-A0] (main.py 282): INFO Train: [192/300][20/78]	eta 0:02:18 lr 1.829737	time 1.1717 (2.3821)	loss 2.7408 (2.7686)	grad_norm 0.4680 (0.4719)	mem 39782MB
[2023-07-07 14:39:08 RepVGG-A0] (main.py 282): INFO Train: [192/300][30/78]	eta 0:01:40 lr 1.825855	time 1.6966 (2.0915)	loss 2.8023 (2.7704)	grad_norm 0.4811 (0.4643)	mem 39782MB
[2023-07-07 14:39:27 RepVGG-A0] (main.py 282): INFO Train: [192/300][40/78]	eta 0:01:17 lr 1.821977	time 3.5819 (2.0372)	loss 2.7731 (2.7718)	grad_norm 0.4207 (0.4582)	mem 39782MB
[2023-07-07 14:39:42 RepVGG-A0] (main.py 282): INFO Train: [192/300][50/78]	eta 0:00:54 lr 1.818101	time 1.1726 (1.9352)	loss 2.7937 (2.7750)	grad_norm 0.4156 (0.4537)	mem 39782MB
[2023-07-07 14:39:57 RepVGG-A0] (main.py 282): INFO Train: [192/300][60/78]	eta 0:00:33 lr 1.814227	time 1.2674 (1.8695)	loss 2.8428 (2.7751)	grad_norm 0.4297 (0.4495)	mem 39782MB
[2023-07-07 14:40:12 RepVGG-A0] (main.py 282): INFO Train: [192/300][70/78]	eta 0:00:14 lr 1.810356	time 1.1735 (1.8143)	loss 2.8384 (2.7723)	grad_norm 0.4640 (0.4472)	mem 39782MB
[2023-07-07 14:40:23 RepVGG-A0] (main.py 291): INFO EPOCH 192 training takes 0:02:20
[2023-07-07 14:40:46 RepVGG-A0] (main.py 282): INFO Train: [193/300][0/78]	eta 0:29:16 lr 1.807260	time 22.5128 (22.5128)	loss 2.6542 (2.6542)	grad_norm 0.4036 (0.4036)	mem 39782MB
[2023-07-07 14:41:00 RepVGG-A0] (main.py 282): INFO Train: [193/300][10/78]	eta 0:03:48 lr 1.803394	time 1.1712 (3.3630)	loss 2.7068 (2.7349)	grad_norm 0.4517 (0.4502)	mem 39782MB
[2023-07-07 14:41:14 RepVGG-A0] (main.py 282): INFO Train: [193/300][20/78]	eta 0:02:20 lr 1.799530	time 1.2170 (2.4293)	loss 2.7307 (2.7494)	grad_norm 0.4116 (0.4525)	mem 39782MB
[2023-07-07 14:41:29 RepVGG-A0] (main.py 282): INFO Train: [193/300][30/78]	eta 0:01:41 lr 1.795668	time 1.1843 (2.1175)	loss 2.7323 (2.7517)	grad_norm 0.4694 (0.4457)	mem 39782MB
[2023-07-07 14:41:47 RepVGG-A0] (main.py 282): INFO Train: [193/300][40/78]	eta 0:01:17 lr 1.791809	time 3.7091 (2.0477)	loss 2.8228 (2.7561)	grad_norm 0.4968 (0.4518)	mem 39782MB
[2023-07-07 14:42:03 RepVGG-A0] (main.py 282): INFO Train: [193/300][50/78]	eta 0:00:54 lr 1.787952	time 1.1740 (1.9485)	loss 2.7278 (2.7567)	grad_norm 0.4137 (0.4515)	mem 39782MB
[2023-07-07 14:42:18 RepVGG-A0] (main.py 282): INFO Train: [193/300][60/78]	eta 0:00:33 lr 1.784098	time 1.2180 (1.8863)	loss 2.7360 (2.7572)	grad_norm 0.4364 (0.4494)	mem 39782MB
[2023-07-07 14:42:33 RepVGG-A0] (main.py 282): INFO Train: [193/300][70/78]	eta 0:00:14 lr 1.780247	time 1.1717 (1.8201)	loss 2.7547 (2.7587)	grad_norm 0.4380 (0.4486)	mem 39782MB
[2023-07-07 14:42:44 RepVGG-A0] (main.py 291): INFO EPOCH 193 training takes 0:02:20
[2023-07-07 14:43:05 RepVGG-A0] (main.py 282): INFO Train: [194/300][0/78]	eta 0:26:50 lr 1.777167	time 20.6418 (20.6418)	loss 2.7404 (2.7404)	grad_norm 0.4310 (0.4310)	mem 39782MB
[2023-07-07 14:43:20 RepVGG-A0] (main.py 282): INFO Train: [194/300][10/78]	eta 0:03:44 lr 1.773321	time 1.1716 (3.2985)	loss 2.8256 (2.7298)	grad_norm 0.4425 (0.4408)	mem 39782MB
[2023-07-07 14:43:35 RepVGG-A0] (main.py 282): INFO Train: [194/300][20/78]	eta 0:02:22 lr 1.769476	time 1.2999 (2.4523)	loss 2.7899 (2.7358)	grad_norm 0.4360 (0.4388)	mem 39782MB
[2023-07-07 14:43:51 RepVGG-A0] (main.py 282): INFO Train: [194/300][30/78]	eta 0:01:43 lr 1.765635	time 1.1474 (2.1555)	loss 2.7564 (2.7416)	grad_norm 0.4448 (0.4482)	mem 39782MB
[2023-07-07 14:44:10 RepVGG-A0] (main.py 282): INFO Train: [194/300][40/78]	eta 0:01:19 lr 1.761795	time 4.1281 (2.0953)	loss 2.7949 (2.7484)	grad_norm 0.4704 (0.4508)	mem 39782MB
[2023-07-07 14:44:24 RepVGG-A0] (main.py 282): INFO Train: [194/300][50/78]	eta 0:00:54 lr 1.757959	time 1.1913 (1.9583)	loss 2.7499 (2.7560)	grad_norm 0.4269 (0.4521)	mem 39782MB
[2023-07-07 14:44:40 RepVGG-A0] (main.py 282): INFO Train: [194/300][60/78]	eta 0:00:34 lr 1.754125	time 1.1436 (1.9103)	loss 2.7278 (2.7537)	grad_norm 0.4041 (0.4469)	mem 39782MB
[2023-07-07 14:44:55 RepVGG-A0] (main.py 282): INFO Train: [194/300][70/78]	eta 0:00:14 lr 1.750294	time 1.4062 (1.8401)	loss 2.7937 (2.7577)	grad_norm 0.4861 (0.4503)	mem 39782MB
[2023-07-07 14:45:06 RepVGG-A0] (main.py 291): INFO EPOCH 194 training takes 0:02:22
[2023-07-07 14:45:28 RepVGG-A0] (main.py 282): INFO Train: [195/300][0/78]	eta 0:28:38 lr 1.747230	time 22.0304 (22.0304)	loss 2.6180 (2.6180)	grad_norm 0.4089 (0.4089)	mem 39782MB
[2023-07-07 14:45:43 RepVGG-A0] (main.py 282): INFO Train: [195/300][10/78]	eta 0:03:45 lr 1.743404	time 1.1749 (3.3199)	loss 2.7440 (2.7187)	grad_norm 0.4321 (0.4382)	mem 39782MB
[2023-07-07 14:45:57 RepVGG-A0] (main.py 282): INFO Train: [195/300][20/78]	eta 0:02:20 lr 1.739580	time 1.1726 (2.4249)	loss 2.7609 (2.7268)	grad_norm 0.4999 (0.4435)	mem 39782MB
[2023-07-07 14:46:13 RepVGG-A0] (main.py 282): INFO Train: [195/300][30/78]	eta 0:01:43 lr 1.735758	time 1.4317 (2.1509)	loss 2.7636 (2.7360)	grad_norm 0.3932 (0.4407)	mem 39782MB
[2023-07-07 14:46:31 RepVGG-A0] (main.py 282): INFO Train: [195/300][40/78]	eta 0:01:18 lr 1.731940	time 3.6744 (2.0688)	loss 2.7527 (2.7330)	grad_norm 0.4674 (0.4386)	mem 39782MB
[2023-07-07 14:46:46 RepVGG-A0] (main.py 282): INFO Train: [195/300][50/78]	eta 0:00:54 lr 1.728124	time 1.1748 (1.9577)	loss 2.7481 (2.7446)	grad_norm 0.4913 (0.4462)	mem 39782MB
[2023-07-07 14:47:01 RepVGG-A0] (main.py 282): INFO Train: [195/300][60/78]	eta 0:00:33 lr 1.724310	time 1.4354 (1.8873)	loss 2.7212 (2.7458)	grad_norm 0.4378 (0.4458)	mem 39782MB
[2023-07-07 14:47:16 RepVGG-A0] (main.py 282): INFO Train: [195/300][70/78]	eta 0:00:14 lr 1.720499	time 1.2320 (1.8307)	loss 2.7591 (2.7495)	grad_norm 0.4418 (0.4459)	mem 39782MB
[2023-07-07 14:47:28 RepVGG-A0] (main.py 291): INFO EPOCH 195 training takes 0:02:21
[2023-07-07 14:47:49 RepVGG-A0] (main.py 282): INFO Train: [196/300][0/78]	eta 0:27:37 lr 1.717453	time 21.2474 (21.2474)	loss 2.7426 (2.7426)	grad_norm 0.4320 (0.4320)	mem 39782MB
[2023-07-07 14:48:04 RepVGG-A0] (main.py 282): INFO Train: [196/300][10/78]	eta 0:03:41 lr 1.713647	time 1.1721 (3.2601)	loss 2.7917 (2.7282)	grad_norm 0.4881 (0.4478)	mem 39782MB
[2023-07-07 14:48:18 RepVGG-A0] (main.py 282): INFO Train: [196/300][20/78]	eta 0:02:18 lr 1.709843	time 1.1733 (2.3816)	loss 2.7815 (2.7431)	grad_norm 0.4865 (0.4532)	mem 39782MB
[2023-07-07 14:48:34 RepVGG-A0] (main.py 282): INFO Train: [196/300][30/78]	eta 0:01:42 lr 1.706043	time 1.3890 (2.1354)	loss 2.7178 (2.7416)	grad_norm 0.4468 (0.4531)	mem 39782MB
[2023-07-07 14:48:52 RepVGG-A0] (main.py 282): INFO Train: [196/300][40/78]	eta 0:01:17 lr 1.702245	time 3.6856 (2.0487)	loss 2.6727 (2.7440)	grad_norm 0.4458 (0.4542)	mem 39782MB
[2023-07-07 14:49:07 RepVGG-A0] (main.py 282): INFO Train: [196/300][50/78]	eta 0:00:54 lr 1.698450	time 1.1729 (1.9408)	loss 2.7109 (2.7468)	grad_norm 0.4323 (0.4534)	mem 39782MB
[2023-07-07 14:49:22 RepVGG-A0] (main.py 282): INFO Train: [196/300][60/78]	eta 0:00:33 lr 1.694657	time 1.4002 (1.8715)	loss 2.8114 (2.7476)	grad_norm 0.4516 (0.4499)	mem 39782MB
[2023-07-07 14:49:38 RepVGG-A0] (main.py 282): INFO Train: [196/300][70/78]	eta 0:00:14 lr 1.690867	time 1.1725 (1.8343)	loss 2.7236 (2.7439)	grad_norm 0.4302 (0.4485)	mem 39782MB
[2023-07-07 14:49:49 RepVGG-A0] (main.py 291): INFO EPOCH 196 training takes 0:02:21
[2023-07-07 14:50:11 RepVGG-A0] (main.py 282): INFO Train: [197/300][0/78]	eta 0:28:34 lr 1.687838	time 21.9754 (21.9754)	loss 2.7573 (2.7573)	grad_norm 0.4770 (0.4770)	mem 39782MB
[2023-07-07 14:50:26 RepVGG-A0] (main.py 282): INFO Train: [197/300][10/78]	eta 0:03:48 lr 1.684053	time 1.1710 (3.3595)	loss 2.7126 (2.7140)	grad_norm 0.4498 (0.4401)	mem 39782MB
[2023-07-07 14:50:41 RepVGG-A0] (main.py 282): INFO Train: [197/300][20/78]	eta 0:02:23 lr 1.680271	time 1.1671 (2.4674)	loss 2.7351 (2.7249)	grad_norm 0.4524 (0.4523)	mem 39782MB
[2023-07-07 14:50:56 RepVGG-A0] (main.py 282): INFO Train: [197/300][30/78]	eta 0:01:43 lr 1.676491	time 1.3856 (2.1569)	loss 2.7306 (2.7206)	grad_norm 0.4815 (0.4515)	mem 39782MB
[2023-07-07 14:51:14 RepVGG-A0] (main.py 282): INFO Train: [197/300][40/78]	eta 0:01:18 lr 1.672714	time 4.1684 (2.0646)	loss 2.7483 (2.7343)	grad_norm 0.4727 (0.4603)	mem 39782MB
[2023-07-07 14:51:29 RepVGG-A0] (main.py 282): INFO Train: [197/300][50/78]	eta 0:00:54 lr 1.668941	time 1.1745 (1.9590)	loss 2.6995 (2.7320)	grad_norm 0.4550 (0.4557)	mem 39782MB
[2023-07-07 14:51:45 RepVGG-A0] (main.py 282): INFO Train: [197/300][60/78]	eta 0:00:34 lr 1.665169	time 1.2284 (1.8973)	loss 2.7130 (2.7361)	grad_norm 0.4759 (0.4596)	mem 39782MB
[2023-07-07 14:52:00 RepVGG-A0] (main.py 282): INFO Train: [197/300][70/78]	eta 0:00:14 lr 1.661401	time 1.1768 (1.8405)	loss 2.7299 (2.7348)	grad_norm 0.4191 (0.4553)	mem 39782MB
[2023-07-07 14:52:13 RepVGG-A0] (main.py 291): INFO EPOCH 197 training takes 0:02:23
[2023-07-07 14:52:34 RepVGG-A0] (main.py 282): INFO Train: [198/300][0/78]	eta 0:27:38 lr 1.658388	time 21.2662 (21.2662)	loss 2.7062 (2.7062)	grad_norm 0.4569 (0.4569)	mem 39782MB
[2023-07-07 14:52:50 RepVGG-A0] (main.py 282): INFO Train: [198/300][10/78]	eta 0:03:50 lr 1.654625	time 1.1730 (3.3964)	loss 2.7273 (2.6994)	grad_norm 0.4549 (0.4517)	mem 39782MB
[2023-07-07 14:53:04 RepVGG-A0] (main.py 282): INFO Train: [198/300][20/78]	eta 0:02:23 lr 1.650864	time 1.1732 (2.4697)	loss 2.7059 (2.7142)	grad_norm 0.4598 (0.4501)	mem 39782MB
[2023-07-07 14:53:19 RepVGG-A0] (main.py 282): INFO Train: [198/300][30/78]	eta 0:01:43 lr 1.647106	time 1.2550 (2.1552)	loss 2.7095 (2.7194)	grad_norm 0.4697 (0.4514)	mem 39782MB
[2023-07-07 14:53:39 RepVGG-A0] (main.py 282): INFO Train: [198/300][40/78]	eta 0:01:19 lr 1.643351	time 3.2578 (2.0981)	loss 2.7674 (2.7222)	grad_norm 0.4484 (0.4539)	mem 39782MB
[2023-07-07 14:53:53 RepVGG-A0] (main.py 282): INFO Train: [198/300][50/78]	eta 0:00:55 lr 1.639599	time 1.2780 (1.9774)	loss 2.7467 (2.7236)	grad_norm 0.4767 (0.4527)	mem 39782MB
[2023-07-07 14:54:08 RepVGG-A0] (main.py 282): INFO Train: [198/300][60/78]	eta 0:00:33 lr 1.635850	time 1.2814 (1.8871)	loss 2.7370 (2.7275)	grad_norm 0.4818 (0.4556)	mem 39782MB
[2023-07-07 14:54:23 RepVGG-A0] (main.py 282): INFO Train: [198/300][70/78]	eta 0:00:14 lr 1.632103	time 1.2894 (1.8440)	loss 2.7079 (2.7282)	grad_norm 0.4412 (0.4538)	mem 39782MB
[2023-07-07 14:54:36 RepVGG-A0] (main.py 291): INFO EPOCH 198 training takes 0:02:23
[2023-07-07 14:54:55 RepVGG-A0] (main.py 282): INFO Train: [199/300][0/78]	eta 0:25:35 lr 1.629108	time 19.6907 (19.6907)	loss 2.7296 (2.7296)	grad_norm 0.5080 (0.5080)	mem 39782MB
[2023-07-07 14:55:11 RepVGG-A0] (main.py 282): INFO Train: [199/300][10/78]	eta 0:03:39 lr 1.625367	time 1.1934 (3.2293)	loss 2.7974 (2.7141)	grad_norm 0.4871 (0.4536)	mem 39782MB
[2023-07-07 14:55:25 RepVGG-A0] (main.py 282): INFO Train: [199/300][20/78]	eta 0:02:17 lr 1.621628	time 1.1747 (2.3668)	loss 2.6918 (2.7155)	grad_norm 0.4320 (0.4726)	mem 39782MB
[2023-07-07 14:55:41 RepVGG-A0] (main.py 282): INFO Train: [199/300][30/78]	eta 0:01:40 lr 1.617892	time 1.3814 (2.1016)	loss 2.7431 (2.7149)	grad_norm 0.4160 (0.4564)	mem 39782MB
[2023-07-07 14:55:57 RepVGG-A0] (main.py 282): INFO Train: [199/300][40/78]	eta 0:01:15 lr 1.614159	time 2.1498 (1.9808)	loss 2.7411 (2.7143)	grad_norm 0.4930 (0.4578)	mem 39782MB
[2023-07-07 14:56:13 RepVGG-A0] (main.py 282): INFO Train: [199/300][50/78]	eta 0:00:53 lr 1.610429	time 1.3408 (1.9063)	loss 2.7073 (2.7144)	grad_norm 0.4328 (0.4530)	mem 39782MB
[2023-07-07 14:56:28 RepVGG-A0] (main.py 282): INFO Train: [199/300][60/78]	eta 0:00:33 lr 1.606702	time 1.2082 (1.8432)	loss 2.8192 (2.7177)	grad_norm 0.4593 (0.4521)	mem 39782MB
[2023-07-07 14:56:43 RepVGG-A0] (main.py 282): INFO Train: [199/300][70/78]	eta 0:00:14 lr 1.602977	time 1.1724 (1.7945)	loss 2.7591 (2.7181)	grad_norm 0.4478 (0.4521)	mem 39782MB
[2023-07-07 14:56:55 RepVGG-A0] (main.py 291): INFO EPOCH 199 training takes 0:02:19
[2023-07-07 14:57:17 RepVGG-A0] (main.py 282): INFO Train: [200/300][0/78]	eta 0:28:21 lr 1.600000	time 21.8097 (21.8097)	loss 2.6719 (2.6719)	grad_norm 0.4235 (0.4235)	mem 39782MB
[2023-07-07 14:57:32 RepVGG-A0] (main.py 282): INFO Train: [200/300][10/78]	eta 0:03:48 lr 1.596281	time 1.1721 (3.3604)	loss 2.6397 (2.7022)	grad_norm 0.4494 (0.4678)	mem 39782MB
[2023-07-07 14:57:46 RepVGG-A0] (main.py 282): INFO Train: [200/300][20/78]	eta 0:02:21 lr 1.592565	time 1.1385 (2.4372)	loss 2.7946 (2.6994)	grad_norm 0.4626 (0.4614)	mem 39782MB
[2023-07-07 14:58:02 RepVGG-A0] (main.py 282): INFO Train: [200/300][30/78]	eta 0:01:43 lr 1.588851	time 1.3458 (2.1601)	loss 2.7333 (2.7016)	grad_norm 0.4165 (0.4536)	mem 39782MB
[2023-07-07 14:58:19 RepVGG-A0] (main.py 282): INFO Train: [200/300][40/78]	eta 0:01:17 lr 1.585141	time 3.4794 (2.0446)	loss 2.6906 (2.7077)	grad_norm 0.4453 (0.4541)	mem 39782MB
[2023-07-07 14:58:35 RepVGG-A0] (main.py 282): INFO Train: [200/300][50/78]	eta 0:00:54 lr 1.581433	time 1.1924 (1.9613)	loss 2.7720 (2.7137)	grad_norm 0.4563 (0.4536)	mem 39782MB
[2023-07-07 14:58:50 RepVGG-A0] (main.py 282): INFO Train: [200/300][60/78]	eta 0:00:34 lr 1.577728	time 1.1808 (1.8905)	loss 2.7723 (2.7162)	grad_norm 0.4873 (0.4545)	mem 39782MB
[2023-07-07 14:59:06 RepVGG-A0] (main.py 282): INFO Train: [200/300][70/78]	eta 0:00:14 lr 1.574027	time 1.3727 (1.8447)	loss 2.7652 (2.7188)	grad_norm 0.4348 (0.4551)	mem 39782MB
[2023-07-07 14:59:17 RepVGG-A0] (main.py 291): INFO EPOCH 200 training takes 0:02:21
[2023-07-07 14:59:34 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.670 (17.670)	Loss 2.1103 (2.1103)	Acc@1 54.468 (54.468)	Acc@5 78.546 (78.546)	Mem 39782MB
[2023-07-07 14:59:35 RepVGG-A0] (main.py 342): INFO  * Acc@1 54.550 Acc@5 78.434
[2023-07-07 14:59:35 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 200: 54.550%
[2023-07-07 14:59:35 RepVGG-A0] (main.py 172): INFO Max accuracy: 54.55%
[2023-07-07 14:59:58 RepVGG-A0] (main.py 282): INFO Train: [201/300][0/78]	eta 0:29:12 lr 1.571067	time 22.4714 (22.4714)	loss 2.6794 (2.6794)	grad_norm 0.4643 (0.4643)	mem 39782MB
[2023-07-07 15:00:12 RepVGG-A0] (main.py 282): INFO Train: [201/300][10/78]	eta 0:03:48 lr 1.567371	time 1.1691 (3.3672)	loss 2.7174 (2.6763)	grad_norm 0.4720 (0.4569)	mem 39782MB
[2023-07-07 15:00:27 RepVGG-A0] (main.py 282): INFO Train: [201/300][20/78]	eta 0:02:21 lr 1.563678	time 1.2355 (2.4423)	loss 2.6762 (2.6862)	grad_norm 0.4784 (0.4527)	mem 39782MB
[2023-07-07 15:00:42 RepVGG-A0] (main.py 282): INFO Train: [201/300][30/78]	eta 0:01:42 lr 1.559987	time 1.3952 (2.1375)	loss 2.7045 (2.6910)	grad_norm 0.4531 (0.4595)	mem 39782MB
[2023-07-07 15:01:00 RepVGG-A0] (main.py 282): INFO Train: [201/300][40/78]	eta 0:01:18 lr 1.556299	time 4.1647 (2.0625)	loss 2.6792 (2.6957)	grad_norm 0.4294 (0.4565)	mem 39782MB
[2023-07-07 15:01:15 RepVGG-A0] (main.py 282): INFO Train: [201/300][50/78]	eta 0:00:54 lr 1.552615	time 1.1724 (1.9456)	loss 2.8131 (2.6988)	grad_norm 0.4932 (0.4562)	mem 39782MB
[2023-07-07 15:01:30 RepVGG-A0] (main.py 282): INFO Train: [201/300][60/78]	eta 0:00:33 lr 1.548933	time 1.1492 (1.8820)	loss 2.7310 (2.7076)	grad_norm 0.4492 (0.4645)	mem 39782MB
[2023-07-07 15:01:45 RepVGG-A0] (main.py 282): INFO Train: [201/300][70/78]	eta 0:00:14 lr 1.545254	time 1.1710 (1.8255)	loss 2.7540 (2.7110)	grad_norm 0.4466 (0.4634)	mem 39782MB
[2023-07-07 15:01:57 RepVGG-A0] (main.py 291): INFO EPOCH 201 training takes 0:02:21
[2023-07-07 15:02:19 RepVGG-A0] (main.py 282): INFO Train: [202/300][0/78]	eta 0:28:01 lr 1.542314	time 21.5638 (21.5638)	loss 2.7210 (2.7210)	grad_norm 0.4479 (0.4479)	mem 39782MB
[2023-07-07 15:02:33 RepVGG-A0] (main.py 282): INFO Train: [202/300][10/78]	eta 0:03:43 lr 1.538640	time 1.1718 (3.2896)	loss 2.6016 (2.6479)	grad_norm 0.4152 (0.4501)	mem 39782MB
[2023-07-07 15:02:48 RepVGG-A0] (main.py 282): INFO Train: [202/300][20/78]	eta 0:02:22 lr 1.534970	time 1.3001 (2.4534)	loss 2.7161 (2.6655)	grad_norm 0.4604 (0.4558)	mem 39782MB
[2023-07-07 15:03:03 RepVGG-A0] (main.py 282): INFO Train: [202/300][30/78]	eta 0:01:42 lr 1.531303	time 1.1822 (2.1339)	loss 2.7109 (2.6715)	grad_norm 0.4561 (0.4486)	mem 39782MB
[2023-07-07 15:03:22 RepVGG-A0] (main.py 282): INFO Train: [202/300][40/78]	eta 0:01:18 lr 1.527638	time 3.8715 (2.0690)	loss 2.8023 (2.6829)	grad_norm 0.5535 (0.4623)	mem 39782MB
[2023-07-07 15:03:36 RepVGG-A0] (main.py 282): INFO Train: [202/300][50/78]	eta 0:00:54 lr 1.523977	time 1.1763 (1.9479)	loss 2.7238 (2.6930)	grad_norm 0.4480 (0.4585)	mem 39782MB
[2023-07-07 15:03:52 RepVGG-A0] (main.py 282): INFO Train: [202/300][60/78]	eta 0:00:33 lr 1.520319	time 1.1778 (1.8812)	loss 2.7023 (2.6950)	grad_norm 0.4488 (0.4556)	mem 39782MB
[2023-07-07 15:04:06 RepVGG-A0] (main.py 282): INFO Train: [202/300][70/78]	eta 0:00:14 lr 1.516663	time 1.4006 (1.8215)	loss 2.7570 (2.6982)	grad_norm 0.4678 (0.4571)	mem 39782MB
[2023-07-07 15:04:18 RepVGG-A0] (main.py 291): INFO EPOCH 202 training takes 0:02:20
[2023-07-07 15:04:39 RepVGG-A0] (main.py 282): INFO Train: [203/300][0/78]	eta 0:27:34 lr 1.513741	time 21.2141 (21.2141)	loss 2.6629 (2.6629)	grad_norm 0.4610 (0.4610)	mem 39782MB
[2023-07-07 15:04:54 RepVGG-A0] (main.py 282): INFO Train: [203/300][10/78]	eta 0:03:42 lr 1.510092	time 1.1724 (3.2691)	loss 2.6365 (2.6628)	grad_norm 0.4398 (0.4600)	mem 39782MB
[2023-07-07 15:05:09 RepVGG-A0] (main.py 282): INFO Train: [203/300][20/78]	eta 0:02:22 lr 1.506445	time 1.3849 (2.4560)	loss 2.6890 (2.6649)	grad_norm 0.4564 (0.4558)	mem 39782MB
[2023-07-07 15:05:24 RepVGG-A0] (main.py 282): INFO Train: [203/300][30/78]	eta 0:01:42 lr 1.502801	time 1.1247 (2.1309)	loss 2.6882 (2.6628)	grad_norm 0.4566 (0.4520)	mem 39782MB
[2023-07-07 15:05:41 RepVGG-A0] (main.py 282): INFO Train: [203/300][40/78]	eta 0:01:17 lr 1.499161	time 2.1003 (2.0280)	loss 2.6914 (2.6686)	grad_norm 0.4678 (0.4598)	mem 39782MB
[2023-07-07 15:05:56 RepVGG-A0] (main.py 282): INFO Train: [203/300][50/78]	eta 0:00:54 lr 1.495523	time 1.1718 (1.9325)	loss 2.7176 (2.6756)	grad_norm 0.4720 (0.4575)	mem 39782MB
[2023-07-07 15:06:11 RepVGG-A0] (main.py 282): INFO Train: [203/300][60/78]	eta 0:00:33 lr 1.491889	time 1.3162 (1.8622)	loss 2.7112 (2.6786)	grad_norm 0.4767 (0.4594)	mem 39782MB
[2023-07-07 15:06:26 RepVGG-A0] (main.py 282): INFO Train: [203/300][70/78]	eta 0:00:14 lr 1.488257	time 1.2204 (1.8068)	loss 2.7165 (2.6824)	grad_norm 0.4470 (0.4568)	mem 39782MB
[2023-07-07 15:06:38 RepVGG-A0] (main.py 291): INFO EPOCH 203 training takes 0:02:20
[2023-07-07 15:06:58 RepVGG-A0] (main.py 282): INFO Train: [204/300][0/78]	eta 0:26:08 lr 1.485354	time 20.1122 (20.1122)	loss 2.6530 (2.6530)	grad_norm 0.4325 (0.4325)	mem 39782MB
[2023-07-07 15:07:13 RepVGG-A0] (main.py 282): INFO Train: [204/300][10/78]	eta 0:03:37 lr 1.481728	time 1.1681 (3.1952)	loss 2.6177 (2.6592)	grad_norm 0.4687 (0.4776)	mem 39782MB
[2023-07-07 15:07:29 RepVGG-A0] (main.py 282): INFO Train: [204/300][20/78]	eta 0:02:19 lr 1.478106	time 1.1756 (2.4133)	loss 2.7079 (2.6590)	grad_norm 0.4837 (0.4665)	mem 39782MB
[2023-07-07 15:07:45 RepVGG-A0] (main.py 282): INFO Train: [204/300][30/78]	eta 0:01:43 lr 1.474486	time 1.2723 (2.1466)	loss 2.6688 (2.6707)	grad_norm 0.4788 (0.4724)	mem 39782MB
[2023-07-07 15:08:02 RepVGG-A0] (main.py 282): INFO Train: [204/300][40/78]	eta 0:01:18 lr 1.470869	time 2.2643 (2.0553)	loss 2.6961 (2.6741)	grad_norm 0.4729 (0.4648)	mem 39782MB
[2023-07-07 15:08:17 RepVGG-A0] (main.py 282): INFO Train: [204/300][50/78]	eta 0:00:54 lr 1.467256	time 1.1733 (1.9407)	loss 2.6998 (2.6781)	grad_norm 0.4387 (0.4709)	mem 39782MB
[2023-07-07 15:08:33 RepVGG-A0] (main.py 282): INFO Train: [204/300][60/78]	eta 0:00:33 lr 1.463646	time 1.3181 (1.8775)	loss 2.6949 (2.6813)	grad_norm 0.4452 (0.4674)	mem 39782MB
[2023-07-07 15:08:47 RepVGG-A0] (main.py 282): INFO Train: [204/300][70/78]	eta 0:00:14 lr 1.460039	time 1.1919 (1.8147)	loss 2.7563 (2.6860)	grad_norm 0.5104 (0.4689)	mem 39782MB
[2023-07-07 15:08:59 RepVGG-A0] (main.py 291): INFO EPOCH 204 training takes 0:02:20
[2023-07-07 15:09:18 RepVGG-A0] (main.py 282): INFO Train: [205/300][0/78]	eta 0:25:05 lr 1.457155	time 19.3047 (19.3047)	loss 2.6654 (2.6654)	grad_norm 0.4268 (0.4268)	mem 39782MB
[2023-07-07 15:09:35 RepVGG-A0] (main.py 282): INFO Train: [205/300][10/78]	eta 0:03:41 lr 1.453554	time 1.1724 (3.2594)	loss 2.7310 (2.6594)	grad_norm 0.5214 (0.4603)	mem 39782MB
[2023-07-07 15:09:51 RepVGG-A0] (main.py 282): INFO Train: [205/300][20/78]	eta 0:02:23 lr 1.449955	time 1.2846 (2.4772)	loss 2.7043 (2.6752)	grad_norm 0.4474 (0.4633)	mem 39782MB
[2023-07-07 15:10:06 RepVGG-A0] (main.py 282): INFO Train: [205/300][30/78]	eta 0:01:43 lr 1.446360	time 1.3919 (2.1634)	loss 2.5492 (2.6644)	grad_norm 0.4202 (0.4566)	mem 39782MB
[2023-07-07 15:10:23 RepVGG-A0] (main.py 282): INFO Train: [205/300][40/78]	eta 0:01:17 lr 1.442768	time 2.4398 (2.0488)	loss 2.7298 (2.6655)	grad_norm 0.4638 (0.4551)	mem 39782MB
[2023-07-07 15:10:38 RepVGG-A0] (main.py 282): INFO Train: [205/300][50/78]	eta 0:00:54 lr 1.439179	time 1.1727 (1.9354)	loss 2.6510 (2.6696)	grad_norm 0.4931 (0.4569)	mem 39782MB
[2023-07-07 15:10:53 RepVGG-A0] (main.py 282): INFO Train: [205/300][60/78]	eta 0:00:33 lr 1.435593	time 1.1896 (1.8633)	loss 2.7221 (2.6762)	grad_norm 0.4572 (0.4584)	mem 39782MB
[2023-07-07 15:11:10 RepVGG-A0] (main.py 282): INFO Train: [205/300][70/78]	eta 0:00:14 lr 1.432011	time 1.4706 (1.8381)	loss 2.6854 (2.6781)	grad_norm 0.4536 (0.4589)	mem 39782MB
[2023-07-07 15:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 205 training takes 0:02:21
[2023-07-07 15:11:42 RepVGG-A0] (main.py 282): INFO Train: [206/300][0/78]	eta 0:28:26 lr 1.429147	time 21.8749 (21.8749)	loss 2.6251 (2.6251)	grad_norm 0.4490 (0.4490)	mem 39782MB
[2023-07-07 15:11:58 RepVGG-A0] (main.py 282): INFO Train: [206/300][10/78]	eta 0:03:50 lr 1.425570	time 1.2052 (3.3904)	loss 2.7017 (2.6589)	grad_norm 0.5078 (0.4835)	mem 39782MB
[2023-07-07 15:12:13 RepVGG-A0] (main.py 282): INFO Train: [206/300][20/78]	eta 0:02:24 lr 1.421997	time 1.2888 (2.4849)	loss 2.6505 (2.6475)	grad_norm 0.4207 (0.4753)	mem 39782MB
[2023-07-07 15:12:28 RepVGG-A0] (main.py 282): INFO Train: [206/300][30/78]	eta 0:01:44 lr 1.418426	time 1.4898 (2.1826)	loss 2.6611 (2.6536)	grad_norm 0.4883 (0.4718)	mem 39782MB
[2023-07-07 15:12:48 RepVGG-A0] (main.py 282): INFO Train: [206/300][40/78]	eta 0:01:20 lr 1.414859	time 2.7127 (2.1241)	loss 2.7256 (2.6648)	grad_norm 0.4709 (0.4731)	mem 39782MB
[2023-07-07 15:13:03 RepVGG-A0] (main.py 282): INFO Train: [206/300][50/78]	eta 0:00:56 lr 1.411295	time 1.1728 (2.0032)	loss 2.6990 (2.6659)	grad_norm 0.4930 (0.4689)	mem 39782MB
[2023-07-07 15:13:18 RepVGG-A0] (main.py 282): INFO Train: [206/300][60/78]	eta 0:00:34 lr 1.407734	time 1.3227 (1.9338)	loss 2.7256 (2.6718)	grad_norm 0.4478 (0.4682)	mem 39782MB
[2023-07-07 15:13:34 RepVGG-A0] (main.py 282): INFO Train: [206/300][70/78]	eta 0:00:14 lr 1.404177	time 1.5700 (1.8745)	loss 2.7210 (2.6736)	grad_norm 0.5127 (0.4701)	mem 39782MB
[2023-07-07 15:13:45 RepVGG-A0] (main.py 291): INFO EPOCH 206 training takes 0:02:24
[2023-07-07 15:14:07 RepVGG-A0] (main.py 282): INFO Train: [207/300][0/78]	eta 0:28:44 lr 1.401333	time 22.1088 (22.1088)	loss 2.6809 (2.6809)	grad_norm 0.4561 (0.4561)	mem 39782MB
[2023-07-07 15:14:22 RepVGG-A0] (main.py 282): INFO Train: [207/300][10/78]	eta 0:03:48 lr 1.397782	time 1.1966 (3.3644)	loss 2.6635 (2.6355)	grad_norm 0.4834 (0.4459)	mem 39782MB
[2023-07-07 15:14:37 RepVGG-A0] (main.py 282): INFO Train: [207/300][20/78]	eta 0:02:21 lr 1.394233	time 1.4480 (2.4479)	loss 2.6362 (2.6462)	grad_norm 0.4360 (0.4585)	mem 39782MB
[2023-07-07 15:14:51 RepVGG-A0] (main.py 282): INFO Train: [207/300][30/78]	eta 0:01:42 lr 1.390688	time 1.1502 (2.1273)	loss 2.6597 (2.6491)	grad_norm 0.4687 (0.4598)	mem 39782MB
[2023-07-07 15:15:10 RepVGG-A0] (main.py 282): INFO Train: [207/300][40/78]	eta 0:01:18 lr 1.387146	time 3.6562 (2.0628)	loss 2.6350 (2.6501)	grad_norm 0.4621 (0.4605)	mem 39782MB
[2023-07-07 15:15:25 RepVGG-A0] (main.py 282): INFO Train: [207/300][50/78]	eta 0:00:54 lr 1.383607	time 1.1717 (1.9568)	loss 2.6736 (2.6588)	grad_norm 0.4694 (0.4593)	mem 39782MB
[2023-07-07 15:15:39 RepVGG-A0] (main.py 282): INFO Train: [207/300][60/78]	eta 0:00:33 lr 1.380072	time 1.1789 (1.8744)	loss 2.6532 (2.6612)	grad_norm 0.4483 (0.4621)	mem 39782MB
[2023-07-07 15:15:55 RepVGG-A0] (main.py 282): INFO Train: [207/300][70/78]	eta 0:00:14 lr 1.376540	time 1.4370 (1.8270)	loss 2.7450 (2.6635)	grad_norm 0.5273 (0.4610)	mem 39782MB
[2023-07-07 15:16:06 RepVGG-A0] (main.py 291): INFO EPOCH 207 training takes 0:02:20
[2023-07-07 15:16:27 RepVGG-A0] (main.py 282): INFO Train: [208/300][0/78]	eta 0:27:29 lr 1.373717	time 21.1450 (21.1450)	loss 2.6935 (2.6935)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:16:42 RepVGG-A0] (main.py 282): INFO Train: [208/300][10/78]	eta 0:03:40 lr 1.370190	time 1.1723 (3.2415)	loss 2.6323 (2.6472)	grad_norm 0.4304 (0.4576)	mem 39782MB
[2023-07-07 15:16:56 RepVGG-A0] (main.py 282): INFO Train: [208/300][20/78]	eta 0:02:17 lr 1.366668	time 1.1724 (2.3775)	loss 2.7303 (2.6571)	grad_norm 0.5722 (0.4871)	mem 39782MB
[2023-07-07 15:17:10 RepVGG-A0] (main.py 282): INFO Train: [208/300][30/78]	eta 0:01:39 lr 1.363148	time 1.3053 (2.0734)	loss 2.6149 (2.6695)	grad_norm 0.4372 (0.4908)	mem 39782MB
[2023-07-07 15:17:30 RepVGG-A0] (main.py 282): INFO Train: [208/300][40/78]	eta 0:01:17 lr 1.359632	time 5.4410 (2.0448)	loss 2.6931 (2.6679)	grad_norm 0.4529 (0.4803)	mem 39782MB
[2023-07-07 15:17:45 RepVGG-A0] (main.py 282): INFO Train: [208/300][50/78]	eta 0:00:54 lr 1.356119	time 1.1745 (1.9395)	loss 2.6283 (2.6660)	grad_norm 0.4589 (0.4742)	mem 39782MB
[2023-07-07 15:18:00 RepVGG-A0] (main.py 282): INFO Train: [208/300][60/78]	eta 0:00:33 lr 1.352609	time 1.3243 (1.8736)	loss 2.6862 (2.6680)	grad_norm 0.5027 (0.4740)	mem 39782MB
[2023-07-07 15:18:15 RepVGG-A0] (main.py 282): INFO Train: [208/300][70/78]	eta 0:00:14 lr 1.349103	time 1.3023 (1.8158)	loss 2.6478 (2.6695)	grad_norm 0.4364 (0.4734)	mem 39782MB
[2023-07-07 15:18:27 RepVGG-A0] (main.py 291): INFO EPOCH 208 training takes 0:02:20
[2023-07-07 15:18:48 RepVGG-A0] (main.py 282): INFO Train: [209/300][0/78]	eta 0:27:45 lr 1.346300	time 21.3511 (21.3511)	loss 2.6318 (2.6318)	grad_norm 0.4722 (0.4722)	mem 39782MB
[2023-07-07 15:19:04 RepVGG-A0] (main.py 282): INFO Train: [209/300][10/78]	eta 0:03:49 lr 1.342800	time 1.1730 (3.3773)	loss 2.6637 (2.6225)	grad_norm 0.4505 (0.4658)	mem 39782MB
[2023-07-07 15:19:19 RepVGG-A0] (main.py 282): INFO Train: [209/300][20/78]	eta 0:02:23 lr 1.339303	time 1.1440 (2.4827)	loss 2.6263 (2.6294)	grad_norm 0.4839 (0.4602)	mem 39782MB
[2023-07-07 15:19:34 RepVGG-A0] (main.py 282): INFO Train: [209/300][30/78]	eta 0:01:44 lr 1.335809	time 1.6859 (2.1787)	loss 2.6332 (2.6303)	grad_norm 0.4522 (0.4636)	mem 39782MB
[2023-07-07 15:19:53 RepVGG-A0] (main.py 282): INFO Train: [209/300][40/78]	eta 0:01:19 lr 1.332319	time 4.2593 (2.0910)	loss 2.6387 (2.6332)	grad_norm 0.4650 (0.4680)	mem 39782MB
[2023-07-07 15:20:07 RepVGG-A0] (main.py 282): INFO Train: [209/300][50/78]	eta 0:00:54 lr 1.328832	time 1.1761 (1.9637)	loss 2.6717 (2.6405)	grad_norm 0.4505 (0.4659)	mem 39782MB
[2023-07-07 15:20:23 RepVGG-A0] (main.py 282): INFO Train: [209/300][60/78]	eta 0:00:34 lr 1.325349	time 1.2245 (1.8945)	loss 2.6911 (2.6469)	grad_norm 0.4856 (0.4687)	mem 39782MB
[2023-07-07 15:20:38 RepVGG-A0] (main.py 282): INFO Train: [209/300][70/78]	eta 0:00:14 lr 1.321869	time 1.2955 (1.8420)	loss 2.6828 (2.6501)	grad_norm 0.4369 (0.4675)	mem 39782MB
[2023-07-07 15:20:49 RepVGG-A0] (main.py 291): INFO EPOCH 209 training takes 0:02:22
[2023-07-07 15:21:10 RepVGG-A0] (main.py 282): INFO Train: [210/300][0/78]	eta 0:27:10 lr 1.319087	time 20.9092 (20.9092)	loss 2.6930 (2.6930)	grad_norm 0.4836 (0.4836)	mem 39782MB
[2023-07-07 15:21:24 RepVGG-A0] (main.py 282): INFO Train: [210/300][10/78]	eta 0:03:34 lr 1.315613	time 1.1725 (3.1566)	loss 2.5679 (2.6143)	grad_norm 0.4594 (0.4600)	mem 39782MB
[2023-07-07 15:21:38 RepVGG-A0] (main.py 282): INFO Train: [210/300][20/78]	eta 0:02:15 lr 1.312143	time 1.1796 (2.3376)	loss 2.6335 (2.6280)	grad_norm 0.4737 (0.4724)	mem 39782MB
[2023-07-07 15:21:54 RepVGG-A0] (main.py 282): INFO Train: [210/300][30/78]	eta 0:01:39 lr 1.308675	time 1.3708 (2.0749)	loss 2.6280 (2.6354)	grad_norm 0.4746 (0.4716)	mem 39782MB
[2023-07-07 15:22:11 RepVGG-A0] (main.py 282): INFO Train: [210/300][40/78]	eta 0:01:15 lr 1.305212	time 3.0065 (1.9882)	loss 2.6461 (2.6409)	grad_norm 0.4621 (0.4693)	mem 39782MB
[2023-07-07 15:22:27 RepVGG-A0] (main.py 282): INFO Train: [210/300][50/78]	eta 0:00:53 lr 1.301751	time 1.1988 (1.9080)	loss 2.6349 (2.6392)	grad_norm 0.4663 (0.4668)	mem 39782MB
[2023-07-07 15:22:42 RepVGG-A0] (main.py 282): INFO Train: [210/300][60/78]	eta 0:00:33 lr 1.298294	time 1.1747 (1.8502)	loss 2.5275 (2.6417)	grad_norm 0.4484 (0.4675)	mem 39782MB
[2023-07-07 15:22:57 RepVGG-A0] (main.py 282): INFO Train: [210/300][70/78]	eta 0:00:14 lr 1.294841	time 1.1741 (1.8013)	loss 2.7270 (2.6483)	grad_norm 0.5262 (0.4707)	mem 39782MB
[2023-07-07 15:23:10 RepVGG-A0] (main.py 291): INFO EPOCH 210 training takes 0:02:20
[2023-07-07 15:23:31 RepVGG-A0] (main.py 282): INFO Train: [211/300][0/78]	eta 0:27:41 lr 1.292080	time 21.3031 (21.3031)	loss 2.6371 (2.6371)	grad_norm 0.4356 (0.4356)	mem 39782MB
[2023-07-07 15:23:46 RepVGG-A0] (main.py 282): INFO Train: [211/300][10/78]	eta 0:03:41 lr 1.288633	time 1.1750 (3.2593)	loss 2.5417 (2.5990)	grad_norm 0.4630 (0.4541)	mem 39782MB
[2023-07-07 15:24:00 RepVGG-A0] (main.py 282): INFO Train: [211/300][20/78]	eta 0:02:18 lr 1.285189	time 1.1725 (2.3922)	loss 2.6600 (2.6071)	grad_norm 0.4485 (0.4595)	mem 39782MB
[2023-07-07 15:24:15 RepVGG-A0] (main.py 282): INFO Train: [211/300][30/78]	eta 0:01:41 lr 1.281749	time 1.4680 (2.1149)	loss 2.6585 (2.6199)	grad_norm 0.4985 (0.4621)	mem 39782MB
[2023-07-07 15:24:33 RepVGG-A0] (main.py 282): INFO Train: [211/300][40/78]	eta 0:01:17 lr 1.278312	time 4.1986 (2.0389)	loss 2.6289 (2.6212)	grad_norm 0.4584 (0.4635)	mem 39782MB
[2023-07-07 15:24:48 RepVGG-A0] (main.py 282): INFO Train: [211/300][50/78]	eta 0:00:53 lr 1.274878	time 1.1904 (1.9245)	loss 2.6531 (2.6267)	grad_norm 0.5000 (0.4648)	mem 39782MB
[2023-07-07 15:25:03 RepVGG-A0] (main.py 282): INFO Train: [211/300][60/78]	eta 0:00:33 lr 1.271448	time 1.1769 (1.8605)	loss 2.6609 (2.6335)	grad_norm 0.4516 (0.4671)	mem 39782MB
[2023-07-07 15:25:18 RepVGG-A0] (main.py 282): INFO Train: [211/300][70/78]	eta 0:00:14 lr 1.268022	time 1.3976 (1.8090)	loss 2.6947 (2.6357)	grad_norm 0.5160 (0.4688)	mem 39782MB
[2023-07-07 15:25:30 RepVGG-A0] (main.py 291): INFO EPOCH 211 training takes 0:02:20
[2023-07-07 15:25:52 RepVGG-A0] (main.py 282): INFO Train: [212/300][0/78]	eta 0:28:28 lr 1.265283	time 21.9078 (21.9078)	loss 2.6029 (2.6029)	grad_norm 0.4468 (0.4468)	mem 39782MB
[2023-07-07 15:26:06 RepVGG-A0] (main.py 282): INFO Train: [212/300][10/78]	eta 0:03:41 lr 1.261863	time 1.1726 (3.2628)	loss 2.6401 (2.6197)	grad_norm 0.4791 (0.4590)	mem 39782MB
[2023-07-07 15:26:21 RepVGG-A0] (main.py 282): INFO Train: [212/300][20/78]	eta 0:02:21 lr 1.258446	time 1.5003 (2.4329)	loss 2.6374 (2.6242)	grad_norm 0.4377 (0.4671)	mem 39782MB
[2023-07-07 15:26:36 RepVGG-A0] (main.py 282): INFO Train: [212/300][30/78]	eta 0:01:42 lr 1.255032	time 1.4121 (2.1253)	loss 2.6134 (2.6257)	grad_norm 0.4815 (0.4687)	mem 39782MB
[2023-07-07 15:26:54 RepVGG-A0] (main.py 282): INFO Train: [212/300][40/78]	eta 0:01:18 lr 1.251623	time 4.0895 (2.0548)	loss 2.6576 (2.6281)	grad_norm 0.4764 (0.4668)	mem 39782MB
[2023-07-07 15:27:09 RepVGG-A0] (main.py 282): INFO Train: [212/300][50/78]	eta 0:00:54 lr 1.248216	time 1.1717 (1.9396)	loss 2.6810 (2.6366)	grad_norm 0.4431 (0.4696)	mem 39782MB
[2023-07-07 15:27:25 RepVGG-A0] (main.py 282): INFO Train: [212/300][60/78]	eta 0:00:33 lr 1.244814	time 1.3392 (1.8846)	loss 2.6745 (2.6354)	grad_norm 0.4883 (0.4686)	mem 39782MB
[2023-07-07 15:27:39 RepVGG-A0] (main.py 282): INFO Train: [212/300][70/78]	eta 0:00:14 lr 1.241414	time 1.1745 (1.8105)	loss 2.6584 (2.6390)	grad_norm 0.4819 (0.4687)	mem 39782MB
[2023-07-07 15:27:51 RepVGG-A0] (main.py 291): INFO EPOCH 212 training takes 0:02:21
[2023-07-07 15:28:12 RepVGG-A0] (main.py 282): INFO Train: [213/300][0/78]	eta 0:26:50 lr 1.238697	time 20.6487 (20.6487)	loss 2.6314 (2.6314)	grad_norm 0.4698 (0.4698)	mem 39782MB
[2023-07-07 15:28:27 RepVGG-A0] (main.py 282): INFO Train: [213/300][10/78]	eta 0:03:37 lr 1.235305	time 1.1703 (3.1929)	loss 2.6132 (2.6130)	grad_norm 0.4888 (0.4668)	mem 39782MB
[2023-07-07 15:28:42 RepVGG-A0] (main.py 282): INFO Train: [213/300][20/78]	eta 0:02:18 lr 1.231915	time 1.1735 (2.3826)	loss 2.6116 (2.6295)	grad_norm 0.4763 (0.4782)	mem 39782MB
[2023-07-07 15:28:56 RepVGG-A0] (main.py 282): INFO Train: [213/300][30/78]	eta 0:01:40 lr 1.228529	time 1.3010 (2.0972)	loss 2.6440 (2.6315)	grad_norm 0.4601 (0.4699)	mem 39782MB
[2023-07-07 15:29:15 RepVGG-A0] (main.py 282): INFO Train: [213/300][40/78]	eta 0:01:17 lr 1.225147	time 4.1890 (2.0273)	loss 2.6995 (2.6371)	grad_norm 0.5136 (0.4774)	mem 39782MB
[2023-07-07 15:29:30 RepVGG-A0] (main.py 282): INFO Train: [213/300][50/78]	eta 0:00:53 lr 1.221768	time 1.1936 (1.9271)	loss 2.6593 (2.6326)	grad_norm 0.4761 (0.4741)	mem 39782MB
[2023-07-07 15:29:45 RepVGG-A0] (main.py 282): INFO Train: [213/300][60/78]	eta 0:00:33 lr 1.218393	time 1.2331 (1.8658)	loss 2.6288 (2.6340)	grad_norm 0.5029 (0.4761)	mem 39782MB
[2023-07-07 15:30:01 RepVGG-A0] (main.py 282): INFO Train: [213/300][70/78]	eta 0:00:14 lr 1.215022	time 1.2142 (1.8248)	loss 2.6139 (2.6355)	grad_norm 0.4545 (0.4756)	mem 39782MB
[2023-07-07 15:30:13 RepVGG-A0] (main.py 291): INFO EPOCH 213 training takes 0:02:21
[2023-07-07 15:30:33 RepVGG-A0] (main.py 282): INFO Train: [214/300][0/78]	eta 0:25:30 lr 1.212327	time 19.6217 (19.6217)	loss 2.5238 (2.5238)	grad_norm 0.4605 (0.4605)	mem 39782MB
[2023-07-07 15:30:49 RepVGG-A0] (main.py 282): INFO Train: [214/300][10/78]	eta 0:03:40 lr 1.208962	time 1.1706 (3.2423)	loss 2.5730 (2.5928)	grad_norm 0.4649 (0.4605)	mem 39782MB
[2023-07-07 15:31:05 RepVGG-A0] (main.py 282): INFO Train: [214/300][20/78]	eta 0:02:24 lr 1.205600	time 1.3552 (2.4902)	loss 2.6239 (2.6047)	grad_norm 0.5483 (0.4681)	mem 39782MB
[2023-07-07 15:31:19 RepVGG-A0] (main.py 282): INFO Train: [214/300][30/78]	eta 0:01:42 lr 1.202243	time 1.3143 (2.1382)	loss 2.6584 (2.6078)	grad_norm 0.4734 (0.4799)	mem 39782MB
[2023-07-07 15:31:37 RepVGG-A0] (main.py 282): INFO Train: [214/300][40/78]	eta 0:01:17 lr 1.198888	time 3.0970 (2.0508)	loss 2.6324 (2.6100)	grad_norm 0.4667 (0.4781)	mem 39782MB
[2023-07-07 15:31:52 RepVGG-A0] (main.py 282): INFO Train: [214/300][50/78]	eta 0:00:54 lr 1.195538	time 1.1949 (1.9391)	loss 2.6513 (2.6161)	grad_norm 0.4861 (0.4744)	mem 39782MB
[2023-07-07 15:32:07 RepVGG-A0] (main.py 282): INFO Train: [214/300][60/78]	eta 0:00:33 lr 1.192190	time 1.1815 (1.8678)	loss 2.6579 (2.6216)	grad_norm 0.4660 (0.4822)	mem 39782MB
[2023-07-07 15:32:23 RepVGG-A0] (main.py 282): INFO Train: [214/300][70/78]	eta 0:00:14 lr 1.188847	time 1.2782 (1.8305)	loss 2.6860 (2.6221)	grad_norm 0.4832 (0.4792)	mem 39782MB
[2023-07-07 15:32:33 RepVGG-A0] (main.py 291): INFO EPOCH 214 training takes 0:02:20
[2023-07-07 15:32:55 RepVGG-A0] (main.py 282): INFO Train: [215/300][0/78]	eta 0:27:50 lr 1.186175	time 21.4104 (21.4104)	loss 2.6140 (2.6140)	grad_norm 0.4838 (0.4838)	mem 39782MB
[2023-07-07 15:33:09 RepVGG-A0] (main.py 282): INFO Train: [215/300][10/78]	eta 0:03:41 lr 1.182838	time 1.1739 (3.2537)	loss 2.5631 (2.5917)	grad_norm 0.4760 (0.4567)	mem 39782MB
[2023-07-07 15:33:25 RepVGG-A0] (main.py 282): INFO Train: [215/300][20/78]	eta 0:02:23 lr 1.179504	time 1.1737 (2.4712)	loss 2.6239 (2.5944)	grad_norm 0.5156 (0.4638)	mem 39782MB
[2023-07-07 15:33:42 RepVGG-A0] (main.py 282): INFO Train: [215/300][30/78]	eta 0:01:45 lr 1.176175	time 1.5052 (2.1984)	loss 2.6186 (2.5972)	grad_norm 0.4806 (0.4775)	mem 39782MB
[2023-07-07 15:33:59 RepVGG-A0] (main.py 282): INFO Train: [215/300][40/78]	eta 0:01:19 lr 1.172849	time 3.6813 (2.0852)	loss 2.6329 (2.5980)	grad_norm 0.4640 (0.4733)	mem 39782MB
[2023-07-07 15:34:14 RepVGG-A0] (main.py 282): INFO Train: [215/300][50/78]	eta 0:00:55 lr 1.169526	time 1.1728 (1.9806)	loss 2.7030 (2.6001)	grad_norm 0.5113 (0.4762)	mem 39782MB
[2023-07-07 15:34:29 RepVGG-A0] (main.py 282): INFO Train: [215/300][60/78]	eta 0:00:34 lr 1.166208	time 1.1777 (1.8935)	loss 2.6333 (2.6027)	grad_norm 0.4671 (0.4752)	mem 39782MB
[2023-07-07 15:34:44 RepVGG-A0] (main.py 282): INFO Train: [215/300][70/78]	eta 0:00:14 lr 1.162893	time 1.1785 (1.8401)	loss 2.6748 (2.6056)	grad_norm 0.4564 (0.4789)	mem 39782MB
[2023-07-07 15:34:55 RepVGG-A0] (main.py 291): INFO EPOCH 215 training takes 0:02:22
[2023-07-07 15:35:17 RepVGG-A0] (main.py 282): INFO Train: [216/300][0/78]	eta 0:27:26 lr 1.160243	time 21.1105 (21.1105)	loss 2.5752 (2.5752)	grad_norm 0.5179 (0.5179)	mem 39782MB
[2023-07-07 15:35:33 RepVGG-A0] (main.py 282): INFO Train: [216/300][10/78]	eta 0:03:51 lr 1.156935	time 1.1720 (3.4047)	loss 2.6264 (2.5806)	grad_norm 0.4784 (0.4752)	mem 39782MB
[2023-07-07 15:35:47 RepVGG-A0] (main.py 282): INFO Train: [216/300][20/78]	eta 0:02:22 lr 1.153630	time 1.1741 (2.4602)	loss 2.6430 (2.5880)	grad_norm 0.4568 (0.4693)	mem 39782MB
[2023-07-07 15:36:03 RepVGG-A0] (main.py 282): INFO Train: [216/300][30/78]	eta 0:01:44 lr 1.150329	time 1.3428 (2.1769)	loss 2.5984 (2.5976)	grad_norm 0.5016 (0.4759)	mem 39782MB
[2023-07-07 15:36:21 RepVGG-A0] (main.py 282): INFO Train: [216/300][40/78]	eta 0:01:18 lr 1.147032	time 4.3349 (2.0746)	loss 2.6050 (2.5986)	grad_norm 0.4737 (0.4743)	mem 39782MB
[2023-07-07 15:36:36 RepVGG-A0] (main.py 282): INFO Train: [216/300][50/78]	eta 0:00:55 lr 1.143738	time 1.3093 (1.9690)	loss 2.6886 (2.6041)	grad_norm 0.5457 (0.4820)	mem 39782MB
[2023-07-07 15:36:51 RepVGG-A0] (main.py 282): INFO Train: [216/300][60/78]	eta 0:00:34 lr 1.140448	time 1.1956 (1.8920)	loss 2.6083 (2.6067)	grad_norm 0.4538 (0.4853)	mem 39782MB
[2023-07-07 15:37:06 RepVGG-A0] (main.py 282): INFO Train: [216/300][70/78]	eta 0:00:14 lr 1.137162	time 1.4520 (1.8438)	loss 2.6995 (2.6121)	grad_norm 0.4704 (0.4836)	mem 39782MB
[2023-07-07 15:37:16 RepVGG-A0] (main.py 291): INFO EPOCH 216 training takes 0:02:20
[2023-07-07 15:37:38 RepVGG-A0] (main.py 282): INFO Train: [217/300][0/78]	eta 0:28:24 lr 1.134535	time 21.8543 (21.8543)	loss 2.6109 (2.6109)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:37:52 RepVGG-A0] (main.py 282): INFO Train: [217/300][10/78]	eta 0:03:40 lr 1.131256	time 1.1754 (3.2473)	loss 2.5511 (2.5946)	grad_norm 0.4741 (0.4763)	mem 39782MB
[2023-07-07 15:38:07 RepVGG-A0] (main.py 282): INFO Train: [217/300][20/78]	eta 0:02:19 lr 1.127980	time 1.1743 (2.4094)	loss 2.5740 (2.5786)	grad_norm 0.4497 (0.4682)	mem 39782MB
[2023-07-07 15:38:22 RepVGG-A0] (main.py 282): INFO Train: [217/300][30/78]	eta 0:01:41 lr 1.124708	time 1.2364 (2.1155)	loss 2.5468 (2.5802)	grad_norm 0.4814 (0.4721)	mem 39782MB
[2023-07-07 15:38:40 RepVGG-A0] (main.py 282): INFO Train: [217/300][40/78]	eta 0:01:17 lr 1.121440	time 4.2437 (2.0419)	loss 2.5614 (2.5871)	grad_norm 0.4837 (0.4768)	mem 39782MB
[2023-07-07 15:38:55 RepVGG-A0] (main.py 282): INFO Train: [217/300][50/78]	eta 0:00:54 lr 1.118175	time 1.1729 (1.9340)	loss 2.7171 (2.5921)	grad_norm 0.4781 (0.4750)	mem 39782MB
[2023-07-07 15:39:10 RepVGG-A0] (main.py 282): INFO Train: [217/300][60/78]	eta 0:00:33 lr 1.114914	time 1.2022 (1.8576)	loss 2.6055 (2.5965)	grad_norm 0.5024 (0.4758)	mem 39782MB
[2023-07-07 15:39:26 RepVGG-A0] (main.py 282): INFO Train: [217/300][70/78]	eta 0:00:14 lr 1.111657	time 1.2906 (1.8192)	loss 2.6723 (2.6015)	grad_norm 0.4819 (0.4764)	mem 39782MB
[2023-07-07 15:39:37 RepVGG-A0] (main.py 291): INFO EPOCH 217 training takes 0:02:20
[2023-07-07 15:39:59 RepVGG-A0] (main.py 282): INFO Train: [218/300][0/78]	eta 0:28:30 lr 1.109054	time 21.9252 (21.9252)	loss 2.5487 (2.5487)	grad_norm 0.4891 (0.4891)	mem 39782MB
[2023-07-07 15:40:15 RepVGG-A0] (main.py 282): INFO Train: [218/300][10/78]	eta 0:03:53 lr 1.105804	time 1.1723 (3.4281)	loss 2.5916 (2.5541)	grad_norm 0.5280 (0.4843)	mem 39782MB
[2023-07-07 15:40:30 RepVGG-A0] (main.py 282): INFO Train: [218/300][20/78]	eta 0:02:25 lr 1.102557	time 1.4168 (2.5158)	loss 2.6219 (2.5719)	grad_norm 0.4757 (0.4871)	mem 39782MB
[2023-07-07 15:40:45 RepVGG-A0] (main.py 282): INFO Train: [218/300][30/78]	eta 0:01:45 lr 1.099314	time 1.4739 (2.1897)	loss 2.5964 (2.5806)	grad_norm 0.4633 (0.4888)	mem 39782MB
[2023-07-07 15:41:03 RepVGG-A0] (main.py 282): INFO Train: [218/300][40/78]	eta 0:01:19 lr 1.096075	time 3.5097 (2.0893)	loss 2.6022 (2.5809)	grad_norm 0.4775 (0.4850)	mem 39782MB
[2023-07-07 15:41:18 RepVGG-A0] (main.py 282): INFO Train: [218/300][50/78]	eta 0:00:55 lr 1.092840	time 1.1766 (1.9715)	loss 2.6163 (2.5846)	grad_norm 0.4559 (0.4835)	mem 39782MB
[2023-07-07 15:41:33 RepVGG-A0] (main.py 282): INFO Train: [218/300][60/78]	eta 0:00:34 lr 1.089609	time 1.2678 (1.9007)	loss 2.6137 (2.5838)	grad_norm 0.4809 (0.4809)	mem 39782MB
[2023-07-07 15:41:48 RepVGG-A0] (main.py 282): INFO Train: [218/300][70/78]	eta 0:00:14 lr 1.086381	time 1.2175 (1.8460)	loss 2.6124 (2.5880)	grad_norm 0.5080 (0.4838)	mem 39782MB
[2023-07-07 15:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 218 training takes 0:02:22
[2023-07-07 15:42:22 RepVGG-A0] (main.py 282): INFO Train: [219/300][0/78]	eta 0:28:06 lr 1.083802	time 21.6205 (21.6205)	loss 2.5904 (2.5904)	grad_norm 0.4598 (0.4598)	mem 39782MB
[2023-07-07 15:42:36 RepVGG-A0] (main.py 282): INFO Train: [219/300][10/78]	eta 0:03:44 lr 1.080581	time 1.1726 (3.3049)	loss 2.5951 (2.5763)	grad_norm 0.5098 (0.4698)	mem 39782MB
[2023-07-07 15:42:51 RepVGG-A0] (main.py 282): INFO Train: [219/300][20/78]	eta 0:02:21 lr 1.077364	time 1.4921 (2.4346)	loss 2.6226 (2.5839)	grad_norm 0.5126 (0.4855)	mem 39782MB
[2023-07-07 15:43:07 RepVGG-A0] (main.py 282): INFO Train: [219/300][30/78]	eta 0:01:44 lr 1.074151	time 1.7951 (2.1687)	loss 2.5874 (2.5873)	grad_norm 0.4718 (0.4858)	mem 39782MB
[2023-07-07 15:43:24 RepVGG-A0] (main.py 282): INFO Train: [219/300][40/78]	eta 0:01:18 lr 1.070942	time 2.3584 (2.0587)	loss 2.5443 (2.5878)	grad_norm 0.4710 (0.4841)	mem 39782MB
[2023-07-07 15:43:39 RepVGG-A0] (main.py 282): INFO Train: [219/300][50/78]	eta 0:00:54 lr 1.067737	time 1.1939 (1.9496)	loss 2.5864 (2.5898)	grad_norm 0.5241 (0.4860)	mem 39782MB
[2023-07-07 15:43:53 RepVGG-A0] (main.py 282): INFO Train: [219/300][60/78]	eta 0:00:33 lr 1.064535	time 1.1780 (1.8581)	loss 2.6438 (2.5934)	grad_norm 0.4939 (0.4877)	mem 39782MB
[2023-07-07 15:44:09 RepVGG-A0] (main.py 282): INFO Train: [219/300][70/78]	eta 0:00:14 lr 1.061337	time 1.1449 (1.8113)	loss 2.6069 (2.5941)	grad_norm 0.4977 (0.4861)	mem 39782MB
[2023-07-07 15:44:20 RepVGG-A0] (main.py 291): INFO EPOCH 219 training takes 0:02:20
[2023-07-07 15:44:41 RepVGG-A0] (main.py 282): INFO Train: [220/300][0/78]	eta 0:27:30 lr 1.058782	time 21.1553 (21.1553)	loss 2.5194 (2.5194)	grad_norm 0.4640 (0.4640)	mem 39782MB
[2023-07-07 15:44:56 RepVGG-A0] (main.py 282): INFO Train: [220/300][10/78]	eta 0:03:39 lr 1.055591	time 1.1697 (3.2270)	loss 2.5530 (2.5809)	grad_norm 0.4841 (0.4878)	mem 39782MB
[2023-07-07 15:45:10 RepVGG-A0] (main.py 282): INFO Train: [220/300][20/78]	eta 0:02:18 lr 1.052404	time 1.1744 (2.3873)	loss 2.5675 (2.5844)	grad_norm 0.4704 (0.5001)	mem 39782MB
[2023-07-07 15:45:26 RepVGG-A0] (main.py 282): INFO Train: [220/300][30/78]	eta 0:01:41 lr 1.049221	time 1.3974 (2.1222)	loss 2.5548 (2.5839)	grad_norm 0.4838 (0.4927)	mem 39782MB
[2023-07-07 15:45:44 RepVGG-A0] (main.py 282): INFO Train: [220/300][40/78]	eta 0:01:17 lr 1.046042	time 4.3591 (2.0513)	loss 2.6033 (2.5838)	grad_norm 0.4764 (0.4889)	mem 39782MB
[2023-07-07 15:45:59 RepVGG-A0] (main.py 282): INFO Train: [220/300][50/78]	eta 0:00:54 lr 1.042867	time 1.1725 (1.9431)	loss 2.4698 (2.5857)	grad_norm 0.4897 (0.4882)	mem 39782MB
[2023-07-07 15:46:14 RepVGG-A0] (main.py 282): INFO Train: [220/300][60/78]	eta 0:00:33 lr 1.039696	time 1.2609 (1.8715)	loss 2.6507 (2.5872)	grad_norm 0.4994 (0.4913)	mem 39782MB
[2023-07-07 15:46:30 RepVGG-A0] (main.py 282): INFO Train: [220/300][70/78]	eta 0:00:14 lr 1.036528	time 1.2030 (1.8260)	loss 2.6296 (2.5888)	grad_norm 0.4628 (0.4894)	mem 39782MB
[2023-07-07 15:46:41 RepVGG-A0] (main.py 291): INFO EPOCH 220 training takes 0:02:20
[2023-07-07 15:46:58 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.979 (16.979)	Loss 1.8846 (1.8846)	Acc@1 60.229 (60.229)	Acc@5 82.672 (82.672)	Mem 39782MB
[2023-07-07 15:46:59 RepVGG-A0] (main.py 342): INFO  * Acc@1 60.430 Acc@5 82.872
[2023-07-07 15:46:59 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 220: 60.430%
[2023-07-07 15:46:59 RepVGG-A0] (main.py 172): INFO Max accuracy: 60.43%
[2023-07-07 15:47:20 RepVGG-A0] (main.py 282): INFO Train: [221/300][0/78]	eta 0:26:30 lr 1.033997	time 20.3900 (20.3900)	loss 2.4858 (2.4858)	grad_norm 0.4686 (0.4686)	mem 39782MB
[2023-07-07 15:47:35 RepVGG-A0] (main.py 282): INFO Train: [221/300][10/78]	eta 0:03:40 lr 1.030836	time 1.1925 (3.2435)	loss 2.5497 (2.5639)	grad_norm 0.5104 (0.5007)	mem 39782MB
[2023-07-07 15:47:51 RepVGG-A0] (main.py 282): INFO Train: [221/300][20/78]	eta 0:02:21 lr 1.027680	time 1.2033 (2.4427)	loss 2.5257 (2.5723)	grad_norm 0.4605 (0.4899)	mem 39782MB
[2023-07-07 15:48:07 RepVGG-A0] (main.py 282): INFO Train: [221/300][30/78]	eta 0:01:45 lr 1.024527	time 1.8574 (2.1949)	loss 2.6156 (2.5706)	grad_norm 0.5106 (0.4890)	mem 39782MB
[2023-07-07 15:48:24 RepVGG-A0] (main.py 282): INFO Train: [221/300][40/78]	eta 0:01:18 lr 1.021379	time 3.2281 (2.0663)	loss 2.5909 (2.5708)	grad_norm 0.4713 (0.4880)	mem 39782MB
[2023-07-07 15:48:39 RepVGG-A0] (main.py 282): INFO Train: [221/300][50/78]	eta 0:00:54 lr 1.018234	time 1.1379 (1.9600)	loss 2.6343 (2.5749)	grad_norm 0.5240 (0.4871)	mem 39782MB
[2023-07-07 15:48:54 RepVGG-A0] (main.py 282): INFO Train: [221/300][60/78]	eta 0:00:33 lr 1.015093	time 1.1801 (1.8853)	loss 2.5460 (2.5756)	grad_norm 0.4760 (0.4858)	mem 39782MB
[2023-07-07 15:49:10 RepVGG-A0] (main.py 282): INFO Train: [221/300][70/78]	eta 0:00:14 lr 1.011956	time 1.1412 (1.8468)	loss 2.6809 (2.5786)	grad_norm 0.5042 (0.4868)	mem 39782MB
[2023-07-07 15:49:23 RepVGG-A0] (main.py 291): INFO EPOCH 221 training takes 0:02:23
[2023-07-07 15:49:45 RepVGG-A0] (main.py 282): INFO Train: [222/300][0/78]	eta 0:29:39 lr 1.009449	time 22.8096 (22.8096)	loss 2.5392 (2.5392)	grad_norm 0.4914 (0.4914)	mem 39782MB
[2023-07-07 15:50:00 RepVGG-A0] (main.py 282): INFO Train: [222/300][10/78]	eta 0:03:52 lr 1.006319	time 1.1724 (3.4190)	loss 2.5017 (2.5287)	grad_norm 0.4525 (0.4776)	mem 39782MB
[2023-07-07 15:50:14 RepVGG-A0] (main.py 282): INFO Train: [222/300][20/78]	eta 0:02:21 lr 1.003194	time 1.1723 (2.4428)	loss 2.5485 (2.5370)	grad_norm 0.4798 (0.4826)	mem 39782MB
[2023-07-07 15:50:29 RepVGG-A0] (main.py 282): INFO Train: [222/300][30/78]	eta 0:01:42 lr 1.000072	time 1.4964 (2.1310)	loss 2.5178 (2.5497)	grad_norm 0.4730 (0.4815)	mem 39782MB
[2023-07-07 15:50:46 RepVGG-A0] (main.py 282): INFO Train: [222/300][40/78]	eta 0:01:17 lr 0.996954	time 3.1190 (2.0322)	loss 2.5966 (2.5575)	grad_norm 0.5011 (0.4845)	mem 39782MB
[2023-07-07 15:51:01 RepVGG-A0] (main.py 282): INFO Train: [222/300][50/78]	eta 0:00:54 lr 0.993840	time 1.3651 (1.9373)	loss 2.5638 (2.5618)	grad_norm 0.4818 (0.4836)	mem 39782MB
[2023-07-07 15:51:17 RepVGG-A0] (main.py 282): INFO Train: [222/300][60/78]	eta 0:00:33 lr 0.990730	time 1.1767 (1.8805)	loss 2.5882 (2.5632)	grad_norm 0.4855 (0.4862)	mem 39782MB
[2023-07-07 15:51:32 RepVGG-A0] (main.py 282): INFO Train: [222/300][70/78]	eta 0:00:14 lr 0.987624	time 1.3287 (1.8242)	loss 2.5802 (2.5665)	grad_norm 0.4788 (0.4853)	mem 39782MB
[2023-07-07 15:51:44 RepVGG-A0] (main.py 291): INFO EPOCH 222 training takes 0:02:21
[2023-07-07 15:52:07 RepVGG-A0] (main.py 282): INFO Train: [223/300][0/78]	eta 0:29:42 lr 0.985142	time 22.8573 (22.8573)	loss 2.4978 (2.4978)	grad_norm 0.4824 (0.4824)	mem 39782MB
[2023-07-07 15:52:22 RepVGG-A0] (main.py 282): INFO Train: [223/300][10/78]	eta 0:03:54 lr 0.982043	time 1.1953 (3.4419)	loss 2.5223 (2.5505)	grad_norm 0.5013 (0.4981)	mem 39782MB
[2023-07-07 15:52:35 RepVGG-A0] (main.py 282): INFO Train: [223/300][20/78]	eta 0:02:22 lr 0.978948	time 1.1724 (2.4555)	loss 2.4901 (2.5461)	grad_norm 0.4780 (0.5029)	mem 39782MB
[2023-07-07 15:52:52 RepVGG-A0] (main.py 282): INFO Train: [223/300][30/78]	eta 0:01:46 lr 0.975857	time 1.5365 (2.2100)	loss 2.5877 (2.5509)	grad_norm 0.4752 (0.4952)	mem 39782MB
[2023-07-07 15:53:09 RepVGG-A0] (main.py 282): INFO Train: [223/300][40/78]	eta 0:01:19 lr 0.972771	time 2.8173 (2.0815)	loss 2.5402 (2.5579)	grad_norm 0.4764 (0.4953)	mem 39782MB
[2023-07-07 15:53:24 RepVGG-A0] (main.py 282): INFO Train: [223/300][50/78]	eta 0:00:55 lr 0.969688	time 1.1727 (1.9661)	loss 2.5085 (2.5612)	grad_norm 0.4945 (0.4948)	mem 39782MB
[2023-07-07 15:53:39 RepVGG-A0] (main.py 282): INFO Train: [223/300][60/78]	eta 0:00:34 lr 0.966609	time 1.2880 (1.8915)	loss 2.5417 (2.5617)	grad_norm 0.4734 (0.4932)	mem 39782MB
[2023-07-07 15:53:55 RepVGG-A0] (main.py 282): INFO Train: [223/300][70/78]	eta 0:00:14 lr 0.963534	time 1.3966 (1.8429)	loss 2.6737 (2.5637)	grad_norm 0.4944 (0.4923)	mem 39782MB
[2023-07-07 15:54:06 RepVGG-A0] (main.py 291): INFO EPOCH 223 training takes 0:02:22
[2023-07-07 15:54:27 RepVGG-A0] (main.py 282): INFO Train: [224/300][0/78]	eta 0:27:09 lr 0.961077	time 20.8916 (20.8916)	loss 2.5029 (2.5029)	grad_norm 0.4953 (0.4953)	mem 39782MB
[2023-07-07 15:54:41 RepVGG-A0] (main.py 282): INFO Train: [224/300][10/78]	eta 0:03:37 lr 0.958010	time 1.1703 (3.1982)	loss 2.5908 (2.5228)	grad_norm 0.4578 (0.5028)	mem 39782MB
[2023-07-07 15:54:57 RepVGG-A0] (main.py 282): INFO Train: [224/300][20/78]	eta 0:02:20 lr 0.954946	time 1.1926 (2.4265)	loss 2.5933 (2.5409)	grad_norm 0.4992 (0.5000)	mem 39782MB
[2023-07-07 15:55:12 RepVGG-A0] (main.py 282): INFO Train: [224/300][30/78]	eta 0:01:42 lr 0.951887	time 1.1573 (2.1281)	loss 2.6205 (2.5477)	grad_norm 0.4729 (0.4954)	mem 39782MB
[2023-07-07 15:55:31 RepVGG-A0] (main.py 282): INFO Train: [224/300][40/78]	eta 0:01:18 lr 0.948832	time 3.2544 (2.0721)	loss 2.6377 (2.5503)	grad_norm 0.5102 (0.4970)	mem 39782MB
[2023-07-07 15:55:46 RepVGG-A0] (main.py 282): INFO Train: [224/300][50/78]	eta 0:00:54 lr 0.945780	time 1.2083 (1.9581)	loss 2.5949 (2.5552)	grad_norm 0.4963 (0.4969)	mem 39782MB
[2023-07-07 15:56:01 RepVGG-A0] (main.py 282): INFO Train: [224/300][60/78]	eta 0:00:33 lr 0.942733	time 1.4488 (1.8814)	loss 2.5915 (2.5592)	grad_norm 0.4766 (0.4956)	mem 39782MB
[2023-07-07 15:56:16 RepVGG-A0] (main.py 282): INFO Train: [224/300][70/78]	eta 0:00:14 lr 0.939690	time 1.3268 (1.8321)	loss 2.5340 (2.5609)	grad_norm 0.4975 (0.4972)	mem 39782MB
[2023-07-07 15:56:28 RepVGG-A0] (main.py 291): INFO EPOCH 224 training takes 0:02:21
[2023-07-07 15:56:50 RepVGG-A0] (main.py 282): INFO Train: [225/300][0/78]	eta 0:28:28 lr 0.937258	time 21.9079 (21.9079)	loss 2.4860 (2.4860)	grad_norm 0.5075 (0.5075)	mem 39782MB
[2023-07-07 15:57:04 RepVGG-A0] (main.py 282): INFO Train: [225/300][10/78]	eta 0:03:43 lr 0.934222	time 1.1717 (3.2879)	loss 2.4724 (2.5241)	grad_norm 0.4895 (0.4909)	mem 39782MB
[2023-07-07 15:57:18 RepVGG-A0] (main.py 282): INFO Train: [225/300][20/78]	eta 0:02:19 lr 0.931191	time 1.1721 (2.4033)	loss 2.5047 (2.5222)	grad_norm 0.4810 (0.4851)	mem 39782MB
[2023-07-07 15:57:34 RepVGG-A0] (main.py 282): INFO Train: [225/300][30/78]	eta 0:01:42 lr 0.928163	time 1.5087 (2.1388)	loss 2.5578 (2.5284)	grad_norm 0.4985 (0.4874)	mem 39782MB
[2023-07-07 15:57:51 RepVGG-A0] (main.py 282): INFO Train: [225/300][40/78]	eta 0:01:16 lr 0.925140	time 3.4183 (2.0219)	loss 2.5960 (2.5370)	grad_norm 0.5378 (0.4909)	mem 39782MB
[2023-07-07 15:58:07 RepVGG-A0] (main.py 282): INFO Train: [225/300][50/78]	eta 0:00:54 lr 0.922120	time 1.2168 (1.9396)	loss 2.5299 (2.5430)	grad_norm 0.4918 (0.4955)	mem 39782MB
[2023-07-07 15:58:23 RepVGG-A0] (main.py 282): INFO Train: [225/300][60/78]	eta 0:00:33 lr 0.919105	time 1.3391 (1.8819)	loss 2.5279 (2.5453)	grad_norm 0.4952 (0.4940)	mem 39782MB
[2023-07-07 15:58:38 RepVGG-A0] (main.py 282): INFO Train: [225/300][70/78]	eta 0:00:14 lr 0.916093	time 1.2892 (1.8299)	loss 2.5482 (2.5471)	grad_norm 0.5021 (0.4925)	mem 39782MB
[2023-07-07 15:58:50 RepVGG-A0] (main.py 291): INFO EPOCH 225 training takes 0:02:21
[2023-07-07 15:59:10 RepVGG-A0] (main.py 282): INFO Train: [226/300][0/78]	eta 0:26:51 lr 0.913687	time 20.6558 (20.6558)	loss 2.4730 (2.4730)	grad_norm 0.4776 (0.4776)	mem 39782MB
[2023-07-07 15:59:27 RepVGG-A0] (main.py 282): INFO Train: [226/300][10/78]	eta 0:03:49 lr 0.910684	time 1.1699 (3.3778)	loss 2.5136 (2.5242)	grad_norm 0.4954 (0.4838)	mem 39782MB
[2023-07-07 15:59:42 RepVGG-A0] (main.py 282): INFO Train: [226/300][20/78]	eta 0:02:24 lr 0.907684	time 1.1874 (2.4889)	loss 2.4765 (2.5215)	grad_norm 0.4981 (0.4960)	mem 39782MB
[2023-07-07 15:59:56 RepVGG-A0] (main.py 282): INFO Train: [226/300][30/78]	eta 0:01:43 lr 0.904688	time 1.4066 (2.1521)	loss 2.5879 (2.5263)	grad_norm 0.4910 (0.4935)	mem 39782MB
[2023-07-07 16:00:14 RepVGG-A0] (main.py 282): INFO Train: [226/300][40/78]	eta 0:01:18 lr 0.901697	time 2.6906 (2.0590)	loss 2.5739 (2.5332)	grad_norm 0.5053 (0.4947)	mem 39782MB
[2023-07-07 16:00:29 RepVGG-A0] (main.py 282): INFO Train: [226/300][50/78]	eta 0:00:54 lr 0.898710	time 1.1959 (1.9512)	loss 2.5554 (2.5381)	grad_norm 0.5148 (0.4937)	mem 39782MB
[2023-07-07 16:00:45 RepVGG-A0] (main.py 282): INFO Train: [226/300][60/78]	eta 0:00:33 lr 0.895726	time 1.1780 (1.8845)	loss 2.5535 (2.5389)	grad_norm 0.5291 (0.4971)	mem 39782MB
[2023-07-07 16:00:59 RepVGG-A0] (main.py 282): INFO Train: [226/300][70/78]	eta 0:00:14 lr 0.892747	time 1.3947 (1.8254)	loss 2.5545 (2.5416)	grad_norm 0.5015 (0.4992)	mem 39782MB
[2023-07-07 16:01:11 RepVGG-A0] (main.py 291): INFO EPOCH 226 training takes 0:02:21
[2023-07-07 16:01:33 RepVGG-A0] (main.py 282): INFO Train: [227/300][0/78]	eta 0:28:23 lr 0.890367	time 21.8410 (21.8410)	loss 2.5424 (2.5424)	grad_norm 0.4839 (0.4839)	mem 39782MB
[2023-07-07 16:01:47 RepVGG-A0] (main.py 282): INFO Train: [227/300][10/78]	eta 0:03:43 lr 0.887396	time 1.1725 (3.2823)	loss 2.5263 (2.5009)	grad_norm 0.5000 (0.4859)	mem 39782MB
[2023-07-07 16:02:02 RepVGG-A0] (main.py 282): INFO Train: [227/300][20/78]	eta 0:02:21 lr 0.884428	time 1.2433 (2.4342)	loss 2.5365 (2.5091)	grad_norm 0.5048 (0.4904)	mem 39782MB
[2023-07-07 16:02:18 RepVGG-A0] (main.py 282): INFO Train: [227/300][30/78]	eta 0:01:43 lr 0.881465	time 1.2521 (2.1582)	loss 2.5009 (2.5135)	grad_norm 0.5313 (0.4920)	mem 39782MB
[2023-07-07 16:02:35 RepVGG-A0] (main.py 282): INFO Train: [227/300][40/78]	eta 0:01:17 lr 0.878506	time 4.0080 (2.0398)	loss 2.5207 (2.5200)	grad_norm 0.4835 (0.4962)	mem 39782MB
[2023-07-07 16:02:51 RepVGG-A0] (main.py 282): INFO Train: [227/300][50/78]	eta 0:00:54 lr 0.875552	time 1.3036 (1.9606)	loss 2.5814 (2.5224)	grad_norm 0.5101 (0.4968)	mem 39782MB
[2023-07-07 16:03:06 RepVGG-A0] (main.py 282): INFO Train: [227/300][60/78]	eta 0:00:33 lr 0.872601	time 1.3471 (1.8853)	loss 2.5440 (2.5260)	grad_norm 0.5010 (0.4974)	mem 39782MB
[2023-07-07 16:03:21 RepVGG-A0] (main.py 282): INFO Train: [227/300][70/78]	eta 0:00:14 lr 0.869654	time 1.3111 (1.8332)	loss 2.6012 (2.5322)	grad_norm 0.4780 (0.4987)	mem 39782MB
[2023-07-07 16:03:31 RepVGG-A0] (main.py 291): INFO EPOCH 227 training takes 0:02:20
[2023-07-07 16:03:52 RepVGG-A0] (main.py 282): INFO Train: [228/300][0/78]	eta 0:26:31 lr 0.867300	time 20.3993 (20.3993)	loss 2.5489 (2.5489)	grad_norm 0.4888 (0.4888)	mem 39782MB
[2023-07-07 16:04:06 RepVGG-A0] (main.py 282): INFO Train: [228/300][10/78]	eta 0:03:36 lr 0.864362	time 1.1900 (3.1891)	loss 2.5487 (2.5284)	grad_norm 0.5211 (0.5037)	mem 39782MB
[2023-07-07 16:04:21 RepVGG-A0] (main.py 282): INFO Train: [228/300][20/78]	eta 0:02:18 lr 0.861427	time 1.1722 (2.3873)	loss 2.5707 (2.5246)	grad_norm 0.4989 (0.4966)	mem 39782MB
[2023-07-07 16:04:38 RepVGG-A0] (main.py 282): INFO Train: [228/300][30/78]	eta 0:01:42 lr 0.858496	time 1.2311 (2.1372)	loss 2.4281 (2.5255)	grad_norm 0.4733 (0.4940)	mem 39782MB
[2023-07-07 16:04:55 RepVGG-A0] (main.py 282): INFO Train: [228/300][40/78]	eta 0:01:17 lr 0.855570	time 2.3756 (2.0381)	loss 2.5268 (2.5280)	grad_norm 0.5176 (0.4957)	mem 39782MB
[2023-07-07 16:05:10 RepVGG-A0] (main.py 282): INFO Train: [228/300][50/78]	eta 0:00:54 lr 0.852648	time 1.1884 (1.9287)	loss 2.5334 (2.5303)	grad_norm 0.4996 (0.5002)	mem 39782MB
[2023-07-07 16:05:25 RepVGG-A0] (main.py 282): INFO Train: [228/300][60/78]	eta 0:00:33 lr 0.849731	time 1.3618 (1.8613)	loss 2.4680 (2.5325)	grad_norm 0.4959 (0.4983)	mem 39782MB
[2023-07-07 16:05:40 RepVGG-A0] (main.py 282): INFO Train: [228/300][70/78]	eta 0:00:14 lr 0.846817	time 1.3269 (1.8123)	loss 2.5443 (2.5309)	grad_norm 0.5037 (0.4973)	mem 39782MB
[2023-07-07 16:05:51 RepVGG-A0] (main.py 291): INFO EPOCH 228 training takes 0:02:20
[2023-07-07 16:06:13 RepVGG-A0] (main.py 282): INFO Train: [229/300][0/78]	eta 0:28:42 lr 0.844489	time 22.0879 (22.0879)	loss 2.4627 (2.4627)	grad_norm 0.4955 (0.4955)	mem 39782MB
[2023-07-07 16:06:28 RepVGG-A0] (main.py 282): INFO Train: [229/300][10/78]	eta 0:03:46 lr 0.841583	time 1.1733 (3.3271)	loss 2.5126 (2.5048)	grad_norm 0.4885 (0.4975)	mem 39782MB
[2023-07-07 16:06:42 RepVGG-A0] (main.py 282): INFO Train: [229/300][20/78]	eta 0:02:20 lr 0.838682	time 1.1911 (2.4306)	loss 2.5729 (2.5179)	grad_norm 0.5325 (0.5072)	mem 39782MB
[2023-07-07 16:06:58 RepVGG-A0] (main.py 282): INFO Train: [229/300][30/78]	eta 0:01:42 lr 0.835784	time 1.4427 (2.1422)	loss 2.5089 (2.5184)	grad_norm 0.4963 (0.5021)	mem 39782MB
[2023-07-07 16:07:16 RepVGG-A0] (main.py 282): INFO Train: [229/300][40/78]	eta 0:01:18 lr 0.832891	time 2.9793 (2.0674)	loss 2.4650 (2.5174)	grad_norm 0.5258 (0.5019)	mem 39782MB
[2023-07-07 16:07:31 RepVGG-A0] (main.py 282): INFO Train: [229/300][50/78]	eta 0:00:54 lr 0.830003	time 1.1743 (1.9582)	loss 2.5124 (2.5187)	grad_norm 0.5343 (0.5030)	mem 39782MB
[2023-07-07 16:07:46 RepVGG-A0] (main.py 282): INFO Train: [229/300][60/78]	eta 0:00:33 lr 0.827118	time 1.1782 (1.8835)	loss 2.4404 (2.5221)	grad_norm 0.4989 (0.5037)	mem 39782MB
[2023-07-07 16:08:02 RepVGG-A0] (main.py 282): INFO Train: [229/300][70/78]	eta 0:00:14 lr 0.824238	time 1.1494 (1.8358)	loss 2.5676 (2.5276)	grad_norm 0.5166 (0.5035)	mem 39782MB
[2023-07-07 16:08:13 RepVGG-A0] (main.py 291): INFO EPOCH 229 training takes 0:02:21
[2023-07-07 16:08:34 RepVGG-A0] (main.py 282): INFO Train: [230/300][0/78]	eta 0:28:13 lr 0.821937	time 21.7072 (21.7072)	loss 2.4843 (2.4843)	grad_norm 0.4908 (0.4908)	mem 39782MB
[2023-07-07 16:08:49 RepVGG-A0] (main.py 282): INFO Train: [230/300][10/78]	eta 0:03:46 lr 0.819064	time 1.1717 (3.3333)	loss 2.5118 (2.5029)	grad_norm 0.5070 (0.4987)	mem 39782MB
[2023-07-07 16:09:05 RepVGG-A0] (main.py 282): INFO Train: [230/300][20/78]	eta 0:02:24 lr 0.816196	time 1.2206 (2.4986)	loss 2.4267 (2.5045)	grad_norm 0.4918 (0.5001)	mem 39782MB
[2023-07-07 16:09:19 RepVGG-A0] (main.py 282): INFO Train: [230/300][30/78]	eta 0:01:42 lr 0.813332	time 1.3567 (2.1338)	loss 2.5085 (2.5066)	grad_norm 0.4943 (0.5026)	mem 39782MB
[2023-07-07 16:09:36 RepVGG-A0] (main.py 282): INFO Train: [230/300][40/78]	eta 0:01:17 lr 0.810472	time 3.0008 (2.0383)	loss 2.5038 (2.5094)	grad_norm 0.4874 (0.5005)	mem 39782MB
[2023-07-07 16:09:52 RepVGG-A0] (main.py 282): INFO Train: [230/300][50/78]	eta 0:00:54 lr 0.807617	time 1.1729 (1.9510)	loss 2.5320 (2.5086)	grad_norm 0.5224 (0.5003)	mem 39782MB
[2023-07-07 16:10:07 RepVGG-A0] (main.py 282): INFO Train: [230/300][60/78]	eta 0:00:33 lr 0.804766	time 1.3692 (1.8777)	loss 2.5035 (2.5118)	grad_norm 0.5131 (0.5037)	mem 39782MB
[2023-07-07 16:10:22 RepVGG-A0] (main.py 282): INFO Train: [230/300][70/78]	eta 0:00:14 lr 0.801919	time 1.4744 (1.8261)	loss 2.5240 (2.5134)	grad_norm 0.4890 (0.5033)	mem 39782MB
[2023-07-07 16:10:34 RepVGG-A0] (main.py 291): INFO EPOCH 230 training takes 0:02:20
[2023-07-07 16:10:55 RepVGG-A0] (main.py 282): INFO Train: [231/300][0/78]	eta 0:28:26 lr 0.799645	time 21.8731 (21.8731)	loss 2.4282 (2.4282)	grad_norm 0.4890 (0.4890)	mem 39782MB
[2023-07-07 16:11:09 RepVGG-A0] (main.py 282): INFO Train: [231/300][10/78]	eta 0:03:41 lr 0.796806	time 1.1705 (3.2577)	loss 2.5138 (2.4757)	grad_norm 0.5044 (0.4964)	mem 39782MB
[2023-07-07 16:11:25 RepVGG-A0] (main.py 282): INFO Train: [231/300][20/78]	eta 0:02:20 lr 0.793971	time 1.2462 (2.4296)	loss 2.5309 (2.4909)	grad_norm 0.5226 (0.5073)	mem 39782MB
[2023-07-07 16:11:40 RepVGG-A0] (main.py 282): INFO Train: [231/300][30/78]	eta 0:01:43 lr 0.791141	time 1.2431 (2.1503)	loss 2.4865 (2.4930)	grad_norm 0.4892 (0.5057)	mem 39782MB
[2023-07-07 16:11:58 RepVGG-A0] (main.py 282): INFO Train: [231/300][40/78]	eta 0:01:18 lr 0.788315	time 2.8032 (2.0695)	loss 2.5526 (2.5010)	grad_norm 0.4973 (0.5028)	mem 39782MB
[2023-07-07 16:12:13 RepVGG-A0] (main.py 282): INFO Train: [231/300][50/78]	eta 0:00:54 lr 0.785493	time 1.1785 (1.9576)	loss 2.5885 (2.5064)	grad_norm 0.5195 (0.5043)	mem 39782MB
[2023-07-07 16:12:28 RepVGG-A0] (main.py 282): INFO Train: [231/300][60/78]	eta 0:00:33 lr 0.782676	time 1.2658 (1.8770)	loss 2.5244 (2.5085)	grad_norm 0.5058 (0.5039)	mem 39782MB
[2023-07-07 16:12:44 RepVGG-A0] (main.py 282): INFO Train: [231/300][70/78]	eta 0:00:14 lr 0.779863	time 1.4136 (1.8337)	loss 2.5840 (2.5107)	grad_norm 0.4934 (0.5065)	mem 39782MB
[2023-07-07 16:12:55 RepVGG-A0] (main.py 291): INFO EPOCH 231 training takes 0:02:21
[2023-07-07 16:13:17 RepVGG-A0] (main.py 282): INFO Train: [232/300][0/78]	eta 0:28:14 lr 0.777616	time 21.7182 (21.7182)	loss 2.4850 (2.4850)	grad_norm 0.5016 (0.5016)	mem 39782MB
[2023-07-07 16:13:31 RepVGG-A0] (main.py 282): INFO Train: [232/300][10/78]	eta 0:03:45 lr 0.774811	time 1.1706 (3.3174)	loss 2.4281 (2.4727)	grad_norm 0.5215 (0.5087)	mem 39782MB
[2023-07-07 16:13:46 RepVGG-A0] (main.py 282): INFO Train: [232/300][20/78]	eta 0:02:21 lr 0.772010	time 1.1774 (2.4453)	loss 2.5502 (2.4972)	grad_norm 0.5125 (0.5089)	mem 39782MB
[2023-07-07 16:14:00 RepVGG-A0] (main.py 282): INFO Train: [232/300][30/78]	eta 0:01:40 lr 0.769214	time 1.3479 (2.1010)	loss 2.5372 (2.5003)	grad_norm 0.5037 (0.5062)	mem 39782MB
[2023-07-07 16:14:20 RepVGG-A0] (main.py 282): INFO Train: [232/300][40/78]	eta 0:01:18 lr 0.766422	time 3.9499 (2.0667)	loss 2.5478 (2.4991)	grad_norm 0.5148 (0.5051)	mem 39782MB
[2023-07-07 16:14:35 RepVGG-A0] (main.py 282): INFO Train: [232/300][50/78]	eta 0:00:54 lr 0.763634	time 1.2502 (1.9562)	loss 2.5216 (2.5004)	grad_norm 0.4926 (0.5051)	mem 39782MB
[2023-07-07 16:14:51 RepVGG-A0] (main.py 282): INFO Train: [232/300][60/78]	eta 0:00:34 lr 0.760851	time 1.1603 (1.8978)	loss 2.4892 (2.5021)	grad_norm 0.5255 (0.5054)	mem 39782MB
[2023-07-07 16:15:04 RepVGG-A0] (main.py 282): INFO Train: [232/300][70/78]	eta 0:00:14 lr 0.758073	time 1.4793 (1.8180)	loss 2.4888 (2.5028)	grad_norm 0.5199 (0.5059)	mem 39782MB
[2023-07-07 16:15:16 RepVGG-A0] (main.py 291): INFO EPOCH 232 training takes 0:02:21
[2023-07-07 16:15:38 RepVGG-A0] (main.py 282): INFO Train: [233/300][0/78]	eta 0:28:16 lr 0.755853	time 21.7468 (21.7468)	loss 2.4475 (2.4475)	grad_norm 0.4861 (0.4861)	mem 39782MB
[2023-07-07 16:15:52 RepVGG-A0] (main.py 282): INFO Train: [233/300][10/78]	eta 0:03:43 lr 0.753082	time 1.1713 (3.2877)	loss 2.4798 (2.4886)	grad_norm 0.5264 (0.5047)	mem 39782MB
[2023-07-07 16:16:07 RepVGG-A0] (main.py 282): INFO Train: [233/300][20/78]	eta 0:02:19 lr 0.750316	time 1.1772 (2.4121)	loss 2.5545 (2.4980)	grad_norm 0.5059 (0.5057)	mem 39782MB
[2023-07-07 16:16:23 RepVGG-A0] (main.py 282): INFO Train: [233/300][30/78]	eta 0:01:43 lr 0.747554	time 1.2960 (2.1485)	loss 2.5005 (2.4992)	grad_norm 0.5195 (0.5117)	mem 39782MB
[2023-07-07 16:16:40 RepVGG-A0] (main.py 282): INFO Train: [233/300][40/78]	eta 0:01:17 lr 0.744796	time 3.6686 (2.0353)	loss 2.5052 (2.4993)	grad_norm 0.4857 (0.5098)	mem 39782MB
[2023-07-07 16:16:55 RepVGG-A0] (main.py 282): INFO Train: [233/300][50/78]	eta 0:00:53 lr 0.742043	time 1.1737 (1.9278)	loss 2.4972 (2.5022)	grad_norm 0.5036 (0.5124)	mem 39782MB
[2023-07-07 16:17:10 RepVGG-A0] (main.py 282): INFO Train: [233/300][60/78]	eta 0:00:33 lr 0.739294	time 1.1873 (1.8646)	loss 2.5197 (2.5023)	grad_norm 0.4957 (0.5112)	mem 39782MB
[2023-07-07 16:17:25 RepVGG-A0] (main.py 282): INFO Train: [233/300][70/78]	eta 0:00:14 lr 0.736550	time 1.2748 (1.8122)	loss 2.5228 (2.5062)	grad_norm 0.5257 (0.5134)	mem 39782MB
[2023-07-07 16:17:37 RepVGG-A0] (main.py 291): INFO EPOCH 233 training takes 0:02:20
[2023-07-07 16:18:00 RepVGG-A0] (main.py 282): INFO Train: [234/300][0/78]	eta 0:29:10 lr 0.734358	time 22.4415 (22.4415)	loss 2.4672 (2.4672)	grad_norm 0.5111 (0.5111)	mem 39782MB
[2023-07-07 16:18:14 RepVGG-A0] (main.py 282): INFO Train: [234/300][10/78]	eta 0:03:48 lr 0.731621	time 1.1725 (3.3648)	loss 2.4274 (2.4744)	grad_norm 0.5129 (0.5066)	mem 39782MB
[2023-07-07 16:18:29 RepVGG-A0] (main.py 282): INFO Train: [234/300][20/78]	eta 0:02:23 lr 0.728890	time 1.1365 (2.4693)	loss 2.4422 (2.4719)	grad_norm 0.5179 (0.5055)	mem 39782MB
[2023-07-07 16:18:44 RepVGG-A0] (main.py 282): INFO Train: [234/300][30/78]	eta 0:01:42 lr 0.726162	time 1.2101 (2.1422)	loss 2.5000 (2.4758)	grad_norm 0.5414 (0.5103)	mem 39782MB
[2023-07-07 16:19:02 RepVGG-A0] (main.py 282): INFO Train: [234/300][40/78]	eta 0:01:18 lr 0.723439	time 3.8391 (2.0667)	loss 2.4853 (2.4819)	grad_norm 0.5134 (0.5097)	mem 39782MB
[2023-07-07 16:19:18 RepVGG-A0] (main.py 282): INFO Train: [234/300][50/78]	eta 0:00:55 lr 0.720721	time 1.1733 (1.9765)	loss 2.4564 (2.4883)	grad_norm 0.4892 (0.5068)	mem 39782MB
[2023-07-07 16:19:32 RepVGG-A0] (main.py 282): INFO Train: [234/300][60/78]	eta 0:00:33 lr 0.718007	time 1.1540 (1.8779)	loss 2.4946 (2.4915)	grad_norm 0.5074 (0.5100)	mem 39782MB
[2023-07-07 16:19:48 RepVGG-A0] (main.py 282): INFO Train: [234/300][70/78]	eta 0:00:14 lr 0.715297	time 1.1821 (1.8441)	loss 2.5781 (2.4944)	grad_norm 0.5236 (0.5097)	mem 39782MB
[2023-07-07 16:19:59 RepVGG-A0] (main.py 291): INFO EPOCH 234 training takes 0:02:22
[2023-07-07 16:20:21 RepVGG-A0] (main.py 282): INFO Train: [235/300][0/78]	eta 0:27:47 lr 0.713133	time 21.3763 (21.3763)	loss 2.4241 (2.4241)	grad_norm 0.5096 (0.5096)	mem 39782MB
[2023-07-07 16:20:35 RepVGG-A0] (main.py 282): INFO Train: [235/300][10/78]	eta 0:03:43 lr 0.710431	time 1.1741 (3.2908)	loss 2.4459 (2.4598)	grad_norm 0.5333 (0.5153)	mem 39782MB
[2023-07-07 16:20:51 RepVGG-A0] (main.py 282): INFO Train: [235/300][20/78]	eta 0:02:21 lr 0.707735	time 1.1770 (2.4458)	loss 2.4461 (2.4645)	grad_norm 0.5101 (0.5163)	mem 39782MB
[2023-07-07 16:21:07 RepVGG-A0] (main.py 282): INFO Train: [235/300][30/78]	eta 0:01:44 lr 0.705042	time 1.3774 (2.1707)	loss 2.4400 (2.4639)	grad_norm 0.4835 (0.5139)	mem 39782MB
[2023-07-07 16:21:24 RepVGG-A0] (main.py 282): INFO Train: [235/300][40/78]	eta 0:01:18 lr 0.702354	time 3.5521 (2.0751)	loss 2.4199 (2.4695)	grad_norm 0.5222 (0.5125)	mem 39782MB
[2023-07-07 16:21:39 RepVGG-A0] (main.py 282): INFO Train: [235/300][50/78]	eta 0:00:54 lr 0.699671	time 1.1743 (1.9614)	loss 2.4962 (2.4701)	grad_norm 0.5040 (0.5119)	mem 39782MB
[2023-07-07 16:21:54 RepVGG-A0] (main.py 282): INFO Train: [235/300][60/78]	eta 0:00:33 lr 0.696992	time 1.3555 (1.8888)	loss 2.4824 (2.4709)	grad_norm 0.5282 (0.5113)	mem 39782MB
[2023-07-07 16:22:10 RepVGG-A0] (main.py 282): INFO Train: [235/300][70/78]	eta 0:00:14 lr 0.694317	time 1.4576 (1.8428)	loss 2.4969 (2.4761)	grad_norm 0.5023 (0.5132)	mem 39782MB
[2023-07-07 16:22:21 RepVGG-A0] (main.py 291): INFO EPOCH 235 training takes 0:02:22
[2023-07-07 16:22:43 RepVGG-A0] (main.py 282): INFO Train: [236/300][0/78]	eta 0:28:15 lr 0.692181	time 21.7333 (21.7333)	loss 2.4478 (2.4478)	grad_norm 0.5067 (0.5067)	mem 39782MB
[2023-07-07 16:22:58 RepVGG-A0] (main.py 282): INFO Train: [236/300][10/78]	eta 0:03:45 lr 0.689515	time 1.1739 (3.3134)	loss 2.4125 (2.4303)	grad_norm 0.5149 (0.5207)	mem 39782MB
[2023-07-07 16:23:12 RepVGG-A0] (main.py 282): INFO Train: [236/300][20/78]	eta 0:02:20 lr 0.686853	time 1.1736 (2.4154)	loss 2.5039 (2.4504)	grad_norm 0.5042 (0.5174)	mem 39782MB
[2023-07-07 16:23:28 RepVGG-A0] (main.py 282): INFO Train: [236/300][30/78]	eta 0:01:42 lr 0.684196	time 1.3746 (2.1447)	loss 2.5552 (2.4654)	grad_norm 0.5256 (0.5191)	mem 39782MB
[2023-07-07 16:23:45 RepVGG-A0] (main.py 282): INFO Train: [236/300][40/78]	eta 0:01:17 lr 0.681543	time 3.3074 (2.0507)	loss 2.4442 (2.4661)	grad_norm 0.5654 (0.5184)	mem 39782MB
[2023-07-07 16:24:00 RepVGG-A0] (main.py 282): INFO Train: [236/300][50/78]	eta 0:00:54 lr 0.678895	time 1.1743 (1.9397)	loss 2.4975 (2.4708)	grad_norm 0.5100 (0.5184)	mem 39782MB
[2023-07-07 16:24:15 RepVGG-A0] (main.py 282): INFO Train: [236/300][60/78]	eta 0:00:33 lr 0.676251	time 1.1825 (1.8692)	loss 2.5043 (2.4723)	grad_norm 0.5365 (0.5205)	mem 39782MB
[2023-07-07 16:24:31 RepVGG-A0] (main.py 282): INFO Train: [236/300][70/78]	eta 0:00:14 lr 0.673612	time 1.4890 (1.8252)	loss 2.4445 (2.4730)	grad_norm 0.5180 (0.5196)	mem 39782MB
[2023-07-07 16:24:43 RepVGG-A0] (main.py 291): INFO EPOCH 236 training takes 0:02:21
[2023-07-07 16:25:04 RepVGG-A0] (main.py 282): INFO Train: [237/300][0/78]	eta 0:27:26 lr 0.671504	time 21.1117 (21.1117)	loss 2.4476 (2.4476)	grad_norm 0.5018 (0.5018)	mem 39782MB
[2023-07-07 16:25:21 RepVGG-A0] (main.py 282): INFO Train: [237/300][10/78]	eta 0:03:51 lr 0.668873	time 1.1714 (3.4017)	loss 2.4549 (2.4466)	grad_norm 0.5053 (0.5123)	mem 39782MB
[2023-07-07 16:25:35 RepVGG-A0] (main.py 282): INFO Train: [237/300][20/78]	eta 0:02:24 lr 0.666247	time 1.2063 (2.4849)	loss 2.4462 (2.4594)	grad_norm 0.4952 (0.5129)	mem 39782MB
[2023-07-07 16:25:51 RepVGG-A0] (main.py 282): INFO Train: [237/300][30/78]	eta 0:01:44 lr 0.663625	time 1.4239 (2.1750)	loss 2.4260 (2.4630)	grad_norm 0.5083 (0.5118)	mem 39782MB
[2023-07-07 16:26:09 RepVGG-A0] (main.py 282): INFO Train: [237/300][40/78]	eta 0:01:19 lr 0.661008	time 2.8150 (2.0903)	loss 2.4453 (2.4609)	grad_norm 0.5057 (0.5110)	mem 39782MB
[2023-07-07 16:26:24 RepVGG-A0] (main.py 282): INFO Train: [237/300][50/78]	eta 0:00:55 lr 0.658395	time 1.2842 (1.9772)	loss 2.4964 (2.4675)	grad_norm 0.5189 (0.5121)	mem 39782MB
[2023-07-07 16:26:39 RepVGG-A0] (main.py 282): INFO Train: [237/300][60/78]	eta 0:00:34 lr 0.655787	time 1.1389 (1.9044)	loss 2.4944 (2.4756)	grad_norm 0.5117 (0.5155)	mem 39782MB
[2023-07-07 16:26:54 RepVGG-A0] (main.py 282): INFO Train: [237/300][70/78]	eta 0:00:14 lr 0.653184	time 1.1993 (1.8423)	loss 2.5348 (2.4786)	grad_norm 0.4989 (0.5149)	mem 39782MB
[2023-07-07 16:27:06 RepVGG-A0] (main.py 291): INFO EPOCH 237 training takes 0:02:23
[2023-07-07 16:27:27 RepVGG-A0] (main.py 282): INFO Train: [238/300][0/78]	eta 0:27:00 lr 0.651104	time 20.7718 (20.7718)	loss 2.4473 (2.4473)	grad_norm 0.5201 (0.5201)	mem 39782MB
[2023-07-07 16:27:43 RepVGG-A0] (main.py 282): INFO Train: [238/300][10/78]	eta 0:03:48 lr 0.648509	time 1.1715 (3.3659)	loss 2.4181 (2.4421)	grad_norm 0.5409 (0.5316)	mem 39782MB
[2023-07-07 16:27:58 RepVGG-A0] (main.py 282): INFO Train: [238/300][20/78]	eta 0:02:21 lr 0.645919	time 1.2397 (2.4363)	loss 2.5740 (2.4582)	grad_norm 0.5059 (0.5210)	mem 39782MB
[2023-07-07 16:28:13 RepVGG-A0] (main.py 282): INFO Train: [238/300][30/78]	eta 0:01:42 lr 0.643333	time 1.6547 (2.1415)	loss 2.4637 (2.4551)	grad_norm 0.5094 (0.5194)	mem 39782MB
[2023-07-07 16:28:30 RepVGG-A0] (main.py 282): INFO Train: [238/300][40/78]	eta 0:01:17 lr 0.640751	time 2.4589 (2.0358)	loss 2.4862 (2.4587)	grad_norm 0.5411 (0.5217)	mem 39782MB
[2023-07-07 16:28:46 RepVGG-A0] (main.py 282): INFO Train: [238/300][50/78]	eta 0:00:54 lr 0.638174	time 1.1806 (1.9458)	loss 2.4601 (2.4619)	grad_norm 0.5207 (0.5190)	mem 39782MB
[2023-07-07 16:29:01 RepVGG-A0] (main.py 282): INFO Train: [238/300][60/78]	eta 0:00:33 lr 0.635602	time 1.1740 (1.8781)	loss 2.4599 (2.4656)	grad_norm 0.5533 (0.5213)	mem 39782MB
[2023-07-07 16:29:17 RepVGG-A0] (main.py 282): INFO Train: [238/300][70/78]	eta 0:00:14 lr 0.633035	time 1.3607 (1.8425)	loss 2.4531 (2.4699)	grad_norm 0.5158 (0.5216)	mem 39782MB
[2023-07-07 16:29:30 RepVGG-A0] (main.py 291): INFO EPOCH 238 training takes 0:02:24
[2023-07-07 16:29:50 RepVGG-A0] (main.py 282): INFO Train: [239/300][0/78]	eta 0:25:41 lr 0.630984	time 19.7631 (19.7631)	loss 2.4661 (2.4661)	grad_norm 0.5044 (0.5044)	mem 39782MB
[2023-07-07 16:30:08 RepVGG-A0] (main.py 282): INFO Train: [239/300][10/78]	eta 0:03:50 lr 0.628425	time 1.1723 (3.3857)	loss 2.4095 (2.4336)	grad_norm 0.5167 (0.5076)	mem 39782MB
[2023-07-07 16:30:22 RepVGG-A0] (main.py 282): INFO Train: [239/300][20/78]	eta 0:02:22 lr 0.625870	time 1.1732 (2.4583)	loss 2.3442 (2.4303)	grad_norm 0.5082 (0.5065)	mem 39782MB
[2023-07-07 16:30:37 RepVGG-A0] (main.py 282): INFO Train: [239/300][30/78]	eta 0:01:43 lr 0.623320	time 1.4802 (2.1519)	loss 2.4900 (2.4374)	grad_norm 0.5131 (0.5116)	mem 39782MB
[2023-07-07 16:30:52 RepVGG-A0] (main.py 282): INFO Train: [239/300][40/78]	eta 0:01:15 lr 0.620775	time 1.7063 (1.9852)	loss 2.4629 (2.4430)	grad_norm 0.5239 (0.5122)	mem 39782MB
[2023-07-07 16:31:09 RepVGG-A0] (main.py 282): INFO Train: [239/300][50/78]	eta 0:00:53 lr 0.618235	time 1.2016 (1.9275)	loss 2.4785 (2.4512)	grad_norm 0.5131 (0.5181)	mem 39782MB
[2023-07-07 16:31:24 RepVGG-A0] (main.py 282): INFO Train: [239/300][60/78]	eta 0:00:33 lr 0.615699	time 1.1736 (1.8624)	loss 2.4502 (2.4580)	grad_norm 0.5130 (0.5182)	mem 39782MB
[2023-07-07 16:31:39 RepVGG-A0] (main.py 282): INFO Train: [239/300][70/78]	eta 0:00:14 lr 0.613167	time 1.2003 (1.8136)	loss 2.4889 (2.4617)	grad_norm 0.5155 (0.5188)	mem 39782MB
[2023-07-07 16:31:52 RepVGG-A0] (main.py 291): INFO EPOCH 239 training takes 0:02:21
[2023-07-07 16:32:13 RepVGG-A0] (main.py 282): INFO Train: [240/300][0/78]	eta 0:27:47 lr 0.611146	time 21.3806 (21.3806)	loss 2.4199 (2.4199)	grad_norm 0.5347 (0.5347)	mem 39782MB
[2023-07-07 16:32:27 RepVGG-A0] (main.py 282): INFO Train: [240/300][10/78]	eta 0:03:40 lr 0.608623	time 1.1915 (3.2357)	loss 2.4033 (2.4247)	grad_norm 0.5065 (0.5107)	mem 39782MB
[2023-07-07 16:32:42 RepVGG-A0] (main.py 282): INFO Train: [240/300][20/78]	eta 0:02:17 lr 0.606104	time 1.1933 (2.3717)	loss 2.4468 (2.4336)	grad_norm 0.5195 (0.5150)	mem 39782MB
[2023-07-07 16:32:57 RepVGG-A0] (main.py 282): INFO Train: [240/300][30/78]	eta 0:01:40 lr 0.603591	time 1.1755 (2.0885)	loss 2.4696 (2.4418)	grad_norm 0.5357 (0.5225)	mem 39782MB
[2023-07-07 16:33:15 RepVGG-A0] (main.py 282): INFO Train: [240/300][40/78]	eta 0:01:16 lr 0.601082	time 3.8918 (2.0239)	loss 2.4593 (2.4430)	grad_norm 0.5102 (0.5195)	mem 39782MB
[2023-07-07 16:33:30 RepVGG-A0] (main.py 282): INFO Train: [240/300][50/78]	eta 0:00:53 lr 0.598578	time 1.1714 (1.9245)	loss 2.5101 (2.4508)	grad_norm 0.5417 (0.5226)	mem 39782MB
[2023-07-07 16:33:45 RepVGG-A0] (main.py 282): INFO Train: [240/300][60/78]	eta 0:00:33 lr 0.596078	time 1.2592 (1.8569)	loss 2.4661 (2.4547)	grad_norm 0.5251 (0.5232)	mem 39782MB
[2023-07-07 16:34:01 RepVGG-A0] (main.py 282): INFO Train: [240/300][70/78]	eta 0:00:14 lr 0.593584	time 1.1740 (1.8130)	loss 2.4721 (2.4559)	grad_norm 0.5203 (0.5220)	mem 39782MB
[2023-07-07 16:34:12 RepVGG-A0] (main.py 291): INFO EPOCH 240 training takes 0:02:20
[2023-07-07 16:34:29 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.573 (17.573)	Loss 1.6567 (1.6567)	Acc@1 63.867 (63.867)	Acc@5 85.229 (85.229)	Mem 39782MB
[2023-07-07 16:34:31 RepVGG-A0] (main.py 342): INFO  * Acc@1 63.708 Acc@5 85.256
[2023-07-07 16:34:31 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 240: 63.708%
[2023-07-07 16:34:31 RepVGG-A0] (main.py 172): INFO Max accuracy: 63.71%
[2023-07-07 16:34:53 RepVGG-A0] (main.py 282): INFO Train: [241/300][0/78]	eta 0:28:56 lr 0.591591	time 22.2589 (22.2589)	loss 2.4833 (2.4833)	grad_norm 0.5200 (0.5200)	mem 39782MB
[2023-07-07 16:35:09 RepVGG-A0] (main.py 282): INFO Train: [241/300][10/78]	eta 0:03:55 lr 0.589105	time 1.1934 (3.4567)	loss 2.4927 (2.4347)	grad_norm 0.5386 (0.5268)	mem 39782MB
[2023-07-07 16:35:23 RepVGG-A0] (main.py 282): INFO Train: [241/300][20/78]	eta 0:02:23 lr 0.586623	time 1.2894 (2.4812)	loss 2.4289 (2.4350)	grad_norm 0.5181 (0.5230)	mem 39782MB
[2023-07-07 16:35:38 RepVGG-A0] (main.py 282): INFO Train: [241/300][30/78]	eta 0:01:44 lr 0.584146	time 1.6015 (2.1746)	loss 2.4681 (2.4406)	grad_norm 0.5373 (0.5264)	mem 39782MB
[2023-07-07 16:35:56 RepVGG-A0] (main.py 282): INFO Train: [241/300][40/78]	eta 0:01:19 lr 0.581674	time 3.2270 (2.0793)	loss 2.4154 (2.4386)	grad_norm 0.5300 (0.5295)	mem 39782MB
[2023-07-07 16:36:11 RepVGG-A0] (main.py 282): INFO Train: [241/300][50/78]	eta 0:00:54 lr 0.579206	time 1.1816 (1.9622)	loss 2.4105 (2.4407)	grad_norm 0.5122 (0.5267)	mem 39782MB
[2023-07-07 16:36:26 RepVGG-A0] (main.py 282): INFO Train: [241/300][60/78]	eta 0:00:34 lr 0.576744	time 1.3068 (1.8916)	loss 2.4804 (2.4442)	grad_norm 0.5366 (0.5284)	mem 39782MB
[2023-07-07 16:36:41 RepVGG-A0] (main.py 282): INFO Train: [241/300][70/78]	eta 0:00:14 lr 0.574286	time 1.2561 (1.8377)	loss 2.4853 (2.4470)	grad_norm 0.5246 (0.5284)	mem 39782MB
[2023-07-07 16:36:53 RepVGG-A0] (main.py 291): INFO EPOCH 241 training takes 0:02:22
[2023-07-07 16:37:15 RepVGG-A0] (main.py 282): INFO Train: [242/300][0/78]	eta 0:29:09 lr 0.572323	time 22.4270 (22.4270)	loss 2.3986 (2.3986)	grad_norm 0.4983 (0.4983)	mem 39782MB
[2023-07-07 16:37:30 RepVGG-A0] (main.py 282): INFO Train: [242/300][10/78]	eta 0:03:49 lr 0.569873	time 1.1714 (3.3733)	loss 2.3630 (2.4045)	grad_norm 0.5256 (0.5114)	mem 39782MB
[2023-07-07 16:37:45 RepVGG-A0] (main.py 282): INFO Train: [242/300][20/78]	eta 0:02:25 lr 0.567428	time 1.1812 (2.5025)	loss 2.4121 (2.4108)	grad_norm 0.5348 (0.5161)	mem 39782MB
[2023-07-07 16:38:00 RepVGG-A0] (main.py 282): INFO Train: [242/300][30/78]	eta 0:01:43 lr 0.564988	time 1.2374 (2.1633)	loss 2.3898 (2.4159)	grad_norm 0.5473 (0.5234)	mem 39782MB
[2023-07-07 16:38:17 RepVGG-A0] (main.py 282): INFO Train: [242/300][40/78]	eta 0:01:18 lr 0.562553	time 2.9805 (2.0650)	loss 2.4150 (2.4215)	grad_norm 0.5147 (0.5238)	mem 39782MB
[2023-07-07 16:38:33 RepVGG-A0] (main.py 282): INFO Train: [242/300][50/78]	eta 0:00:54 lr 0.560122	time 1.2650 (1.9564)	loss 2.4797 (2.4240)	grad_norm 0.5428 (0.5256)	mem 39782MB
[2023-07-07 16:38:47 RepVGG-A0] (main.py 282): INFO Train: [242/300][60/78]	eta 0:00:33 lr 0.557697	time 1.1721 (1.8795)	loss 2.4818 (2.4290)	grad_norm 0.5336 (0.5258)	mem 39782MB
[2023-07-07 16:39:03 RepVGG-A0] (main.py 282): INFO Train: [242/300][70/78]	eta 0:00:14 lr 0.555276	time 1.3418 (1.8281)	loss 2.5159 (2.4335)	grad_norm 0.5259 (0.5274)	mem 39782MB
[2023-07-07 16:39:15 RepVGG-A0] (main.py 291): INFO EPOCH 242 training takes 0:02:21
[2023-07-07 16:39:37 RepVGG-A0] (main.py 282): INFO Train: [243/300][0/78]	eta 0:28:57 lr 0.553342	time 22.2722 (22.2722)	loss 2.3659 (2.3659)	grad_norm 0.5264 (0.5264)	mem 39782MB
[2023-07-07 16:39:51 RepVGG-A0] (main.py 282): INFO Train: [243/300][10/78]	eta 0:03:45 lr 0.550930	time 1.1725 (3.3214)	loss 2.4474 (2.3956)	grad_norm 0.5474 (0.5210)	mem 39782MB
[2023-07-07 16:40:06 RepVGG-A0] (main.py 282): INFO Train: [243/300][20/78]	eta 0:02:21 lr 0.548522	time 1.1731 (2.4446)	loss 2.4347 (2.4140)	grad_norm 0.5586 (0.5246)	mem 39782MB
[2023-07-07 16:40:21 RepVGG-A0] (main.py 282): INFO Train: [243/300][30/78]	eta 0:01:42 lr 0.546119	time 1.2078 (2.1451)	loss 2.3952 (2.4184)	grad_norm 0.5263 (0.5280)	mem 39782MB
[2023-07-07 16:40:39 RepVGG-A0] (main.py 282): INFO Train: [243/300][40/78]	eta 0:01:18 lr 0.543721	time 3.9304 (2.0693)	loss 2.4275 (2.4247)	grad_norm 0.5355 (0.5277)	mem 39782MB
[2023-07-07 16:40:54 RepVGG-A0] (main.py 282): INFO Train: [243/300][50/78]	eta 0:00:54 lr 0.541328	time 1.1929 (1.9483)	loss 2.4638 (2.4270)	grad_norm 0.5468 (0.5269)	mem 39782MB
[2023-07-07 16:41:09 RepVGG-A0] (main.py 282): INFO Train: [243/300][60/78]	eta 0:00:33 lr 0.538939	time 1.1927 (1.8796)	loss 2.4619 (2.4317)	grad_norm 0.5250 (0.5287)	mem 39782MB
[2023-07-07 16:41:25 RepVGG-A0] (main.py 282): INFO Train: [243/300][70/78]	eta 0:00:14 lr 0.536556	time 1.1519 (1.8328)	loss 2.4843 (2.4336)	grad_norm 0.5215 (0.5294)	mem 39782MB
[2023-07-07 16:41:36 RepVGG-A0] (main.py 291): INFO EPOCH 243 training takes 0:02:21
[2023-07-07 16:41:58 RepVGG-A0] (main.py 282): INFO Train: [244/300][0/78]	eta 0:28:03 lr 0.534652	time 21.5889 (21.5889)	loss 2.3368 (2.3368)	grad_norm 0.5363 (0.5363)	mem 39782MB
[2023-07-07 16:42:12 RepVGG-A0] (main.py 282): INFO Train: [244/300][10/78]	eta 0:03:41 lr 0.532277	time 1.1729 (3.2615)	loss 2.4101 (2.4010)	grad_norm 0.5216 (0.5318)	mem 39782MB
[2023-07-07 16:42:27 RepVGG-A0] (main.py 282): INFO Train: [244/300][20/78]	eta 0:02:20 lr 0.529907	time 1.3117 (2.4146)	loss 2.4080 (2.4030)	grad_norm 0.5616 (0.5337)	mem 39782MB
[2023-07-07 16:42:43 RepVGG-A0] (main.py 282): INFO Train: [244/300][30/78]	eta 0:01:42 lr 0.527541	time 1.3500 (2.1442)	loss 2.3814 (2.4053)	grad_norm 0.5230 (0.5312)	mem 39782MB
[2023-07-07 16:43:01 RepVGG-A0] (main.py 282): INFO Train: [244/300][40/78]	eta 0:01:18 lr 0.525181	time 3.3049 (2.0571)	loss 2.4444 (2.4110)	grad_norm 0.5274 (0.5338)	mem 39782MB
[2023-07-07 16:43:17 RepVGG-A0] (main.py 282): INFO Train: [244/300][50/78]	eta 0:00:55 lr 0.522825	time 1.2118 (1.9672)	loss 2.4283 (2.4147)	grad_norm 0.5291 (0.5338)	mem 39782MB
[2023-07-07 16:43:32 RepVGG-A0] (main.py 282): INFO Train: [244/300][60/78]	eta 0:00:34 lr 0.520474	time 1.3859 (1.9002)	loss 2.3892 (2.4134)	grad_norm 0.5210 (0.5318)	mem 39782MB
[2023-07-07 16:43:47 RepVGG-A0] (main.py 282): INFO Train: [244/300][70/78]	eta 0:00:14 lr 0.518128	time 1.2068 (1.8429)	loss 2.4449 (2.4156)	grad_norm 0.5280 (0.5313)	mem 39782MB
[2023-07-07 16:43:58 RepVGG-A0] (main.py 291): INFO EPOCH 244 training takes 0:02:22
[2023-07-07 16:44:20 RepVGG-A0] (main.py 282): INFO Train: [245/300][0/78]	eta 0:27:44 lr 0.516254	time 21.3416 (21.3416)	loss 2.3800 (2.3800)	grad_norm 0.5272 (0.5272)	mem 39782MB
[2023-07-07 16:44:35 RepVGG-A0] (main.py 282): INFO Train: [245/300][10/78]	eta 0:03:46 lr 0.513917	time 1.1718 (3.3316)	loss 2.4666 (2.4014)	grad_norm 0.5456 (0.5333)	mem 39782MB
[2023-07-07 16:44:49 RepVGG-A0] (main.py 282): INFO Train: [245/300][20/78]	eta 0:02:20 lr 0.511584	time 1.1679 (2.4211)	loss 2.3364 (2.4072)	grad_norm 0.5279 (0.5315)	mem 39782MB
[2023-07-07 16:45:05 RepVGG-A0] (main.py 282): INFO Train: [245/300][30/78]	eta 0:01:42 lr 0.509256	time 1.2436 (2.1457)	loss 2.3519 (2.4077)	grad_norm 0.5196 (0.5296)	mem 39782MB
[2023-07-07 16:45:24 RepVGG-A0] (main.py 282): INFO Train: [245/300][40/78]	eta 0:01:19 lr 0.506933	time 4.8128 (2.0863)	loss 2.4355 (2.4120)	grad_norm 0.5629 (0.5344)	mem 39782MB
[2023-07-07 16:45:38 RepVGG-A0] (main.py 282): INFO Train: [245/300][50/78]	eta 0:00:54 lr 0.504615	time 1.1896 (1.9558)	loss 2.4471 (2.4145)	grad_norm 0.5365 (0.5367)	mem 39782MB
[2023-07-07 16:45:54 RepVGG-A0] (main.py 282): INFO Train: [245/300][60/78]	eta 0:00:34 lr 0.502302	time 1.3721 (1.8896)	loss 2.3458 (2.4131)	grad_norm 0.5408 (0.5354)	mem 39782MB
[2023-07-07 16:46:09 RepVGG-A0] (main.py 282): INFO Train: [245/300][70/78]	eta 0:00:14 lr 0.499994	time 1.4234 (1.8428)	loss 2.5027 (2.4149)	grad_norm 0.5221 (0.5342)	mem 39782MB
[2023-07-07 16:46:20 RepVGG-A0] (main.py 291): INFO EPOCH 245 training takes 0:02:21
[2023-07-07 16:46:40 RepVGG-A0] (main.py 282): INFO Train: [246/300][0/78]	eta 0:27:01 lr 0.498151	time 20.7905 (20.7905)	loss 2.3659 (2.3659)	grad_norm 0.5154 (0.5154)	mem 39782MB
[2023-07-07 16:46:56 RepVGG-A0] (main.py 282): INFO Train: [246/300][10/78]	eta 0:03:42 lr 0.495851	time 1.1744 (3.2651)	loss 2.3706 (2.3845)	grad_norm 0.5220 (0.5350)	mem 39782MB
[2023-07-07 16:47:10 RepVGG-A0] (main.py 282): INFO Train: [246/300][20/78]	eta 0:02:19 lr 0.493556	time 1.3501 (2.4119)	loss 2.3540 (2.3955)	grad_norm 0.5343 (0.5351)	mem 39782MB
[2023-07-07 16:47:25 RepVGG-A0] (main.py 282): INFO Train: [246/300][30/78]	eta 0:01:41 lr 0.491267	time 1.1419 (2.1110)	loss 2.4557 (2.4022)	grad_norm 0.5511 (0.5362)	mem 39782MB
[2023-07-07 16:47:44 RepVGG-A0] (main.py 282): INFO Train: [246/300][40/78]	eta 0:01:17 lr 0.488982	time 4.2968 (2.0495)	loss 2.4652 (2.4052)	grad_norm 0.5395 (0.5391)	mem 39782MB
[2023-07-07 16:47:59 RepVGG-A0] (main.py 282): INFO Train: [246/300][50/78]	eta 0:00:54 lr 0.486702	time 1.2815 (1.9465)	loss 2.4262 (2.4070)	grad_norm 0.5357 (0.5385)	mem 39782MB
[2023-07-07 16:48:14 RepVGG-A0] (main.py 282): INFO Train: [246/300][60/78]	eta 0:00:33 lr 0.484426	time 1.2998 (1.8735)	loss 2.3966 (2.4088)	grad_norm 0.5322 (0.5378)	mem 39782MB
[2023-07-07 16:48:30 RepVGG-A0] (main.py 282): INFO Train: [246/300][70/78]	eta 0:00:14 lr 0.482156	time 1.2741 (1.8326)	loss 2.4957 (2.4101)	grad_norm 0.5437 (0.5383)	mem 39782MB
[2023-07-07 16:48:42 RepVGG-A0] (main.py 291): INFO EPOCH 246 training takes 0:02:22
[2023-07-07 16:49:04 RepVGG-A0] (main.py 282): INFO Train: [247/300][0/78]	eta 0:27:59 lr 0.480343	time 21.5326 (21.5326)	loss 2.4478 (2.4478)	grad_norm 0.5318 (0.5318)	mem 39782MB
[2023-07-07 16:49:19 RepVGG-A0] (main.py 282): INFO Train: [247/300][10/78]	eta 0:03:45 lr 0.478082	time 1.1741 (3.3223)	loss 2.4472 (2.4132)	grad_norm 0.5305 (0.5308)	mem 39782MB
[2023-07-07 16:49:33 RepVGG-A0] (main.py 282): INFO Train: [247/300][20/78]	eta 0:02:20 lr 0.475825	time 1.1862 (2.4270)	loss 2.3257 (2.4019)	grad_norm 0.5342 (0.5354)	mem 39782MB
[2023-07-07 16:49:49 RepVGG-A0] (main.py 282): INFO Train: [247/300][30/78]	eta 0:01:42 lr 0.473574	time 1.4975 (2.1442)	loss 2.4264 (2.4053)	grad_norm 0.5426 (0.5353)	mem 39782MB
[2023-07-07 16:50:06 RepVGG-A0] (main.py 282): INFO Train: [247/300][40/78]	eta 0:01:17 lr 0.471327	time 3.2118 (2.0428)	loss 2.3816 (2.4064)	grad_norm 0.5285 (0.5371)	mem 39782MB
[2023-07-07 16:50:21 RepVGG-A0] (main.py 282): INFO Train: [247/300][50/78]	eta 0:00:54 lr 0.469085	time 1.3112 (1.9356)	loss 2.4457 (2.4053)	grad_norm 0.5415 (0.5373)	mem 39782MB
[2023-07-07 16:50:36 RepVGG-A0] (main.py 282): INFO Train: [247/300][60/78]	eta 0:00:33 lr 0.466848	time 1.2437 (1.8735)	loss 2.4287 (2.4077)	grad_norm 0.5326 (0.5376)	mem 39782MB
[2023-07-07 16:50:52 RepVGG-A0] (main.py 282): INFO Train: [247/300][70/78]	eta 0:00:14 lr 0.464616	time 1.2647 (1.8226)	loss 2.4068 (2.4095)	grad_norm 0.5408 (0.5387)	mem 39782MB
[2023-07-07 16:51:03 RepVGG-A0] (main.py 291): INFO EPOCH 247 training takes 0:02:21
[2023-07-07 16:51:25 RepVGG-A0] (main.py 282): INFO Train: [248/300][0/78]	eta 0:28:20 lr 0.462834	time 21.8028 (21.8028)	loss 2.3797 (2.3797)	grad_norm 0.5286 (0.5286)	mem 39782MB
[2023-07-07 16:51:40 RepVGG-A0] (main.py 282): INFO Train: [248/300][10/78]	eta 0:03:48 lr 0.460611	time 1.1712 (3.3667)	loss 2.3697 (2.3783)	grad_norm 0.5408 (0.5415)	mem 39782MB
[2023-07-07 16:51:56 RepVGG-A0] (main.py 282): INFO Train: [248/300][20/78]	eta 0:02:24 lr 0.458393	time 1.2442 (2.4833)	loss 2.3753 (2.3788)	grad_norm 0.5374 (0.5391)	mem 39782MB
[2023-07-07 16:52:10 RepVGG-A0] (main.py 282): INFO Train: [248/300][30/78]	eta 0:01:43 lr 0.456180	time 1.3323 (2.1534)	loss 2.3437 (2.3835)	grad_norm 0.5345 (0.5420)	mem 39782MB
[2023-07-07 16:52:28 RepVGG-A0] (main.py 282): INFO Train: [248/300][40/78]	eta 0:01:18 lr 0.453972	time 3.8284 (2.0688)	loss 2.4115 (2.3868)	grad_norm 0.5308 (0.5417)	mem 39782MB
[2023-07-07 16:52:44 RepVGG-A0] (main.py 282): INFO Train: [248/300][50/78]	eta 0:00:54 lr 0.451768	time 1.1722 (1.9623)	loss 2.4044 (2.3914)	grad_norm 0.5242 (0.5407)	mem 39782MB
[2023-07-07 16:52:59 RepVGG-A0] (main.py 282): INFO Train: [248/300][60/78]	eta 0:00:34 lr 0.449570	time 1.2925 (1.8958)	loss 2.4205 (2.3956)	grad_norm 0.5247 (0.5394)	mem 39782MB
[2023-07-07 16:53:14 RepVGG-A0] (main.py 282): INFO Train: [248/300][70/78]	eta 0:00:14 lr 0.447377	time 1.5460 (1.8386)	loss 2.3963 (2.3967)	grad_norm 0.5516 (0.5400)	mem 39782MB
[2023-07-07 16:53:25 RepVGG-A0] (main.py 291): INFO EPOCH 248 training takes 0:02:21
[2023-07-07 16:53:47 RepVGG-A0] (main.py 282): INFO Train: [249/300][0/78]	eta 0:28:14 lr 0.445626	time 21.7258 (21.7258)	loss 2.3669 (2.3669)	grad_norm 0.5415 (0.5415)	mem 39782MB
[2023-07-07 16:54:03 RepVGG-A0] (main.py 282): INFO Train: [249/300][10/78]	eta 0:03:52 lr 0.443441	time 1.1709 (3.4238)	loss 2.3716 (2.3697)	grad_norm 0.5613 (0.5463)	mem 39782MB
[2023-07-07 16:54:19 RepVGG-A0] (main.py 282): INFO Train: [249/300][20/78]	eta 0:02:26 lr 0.441262	time 1.1448 (2.5273)	loss 2.4002 (2.3675)	grad_norm 0.5299 (0.5436)	mem 39782MB
[2023-07-07 16:54:33 RepVGG-A0] (main.py 282): INFO Train: [249/300][30/78]	eta 0:01:44 lr 0.439087	time 1.2445 (2.1723)	loss 2.3958 (2.3734)	grad_norm 0.5466 (0.5423)	mem 39782MB
[2023-07-07 16:54:52 RepVGG-A0] (main.py 282): INFO Train: [249/300][40/78]	eta 0:01:20 lr 0.436918	time 3.5683 (2.1085)	loss 2.4607 (2.3809)	grad_norm 0.5560 (0.5440)	mem 39782MB
[2023-07-07 16:55:07 RepVGG-A0] (main.py 282): INFO Train: [249/300][50/78]	eta 0:00:55 lr 0.434753	time 1.1744 (1.9891)	loss 2.3933 (2.3840)	grad_norm 0.5436 (0.5435)	mem 39782MB
[2023-07-07 16:55:23 RepVGG-A0] (main.py 282): INFO Train: [249/300][60/78]	eta 0:00:34 lr 0.432593	time 1.3860 (1.9231)	loss 2.4168 (2.3874)	grad_norm 0.5453 (0.5442)	mem 39782MB
[2023-07-07 16:55:37 RepVGG-A0] (main.py 282): INFO Train: [249/300][70/78]	eta 0:00:14 lr 0.430439	time 1.3219 (1.8599)	loss 2.4350 (2.3919)	grad_norm 0.5415 (0.5455)	mem 39782MB
[2023-07-07 16:55:49 RepVGG-A0] (main.py 291): INFO EPOCH 249 training takes 0:02:23
[2023-07-07 16:56:12 RepVGG-A0] (main.py 282): INFO Train: [250/300][0/78]	eta 0:29:05 lr 0.428719	time 22.3759 (22.3759)	loss 2.3096 (2.3096)	grad_norm 0.5473 (0.5473)	mem 39782MB
[2023-07-07 16:56:25 RepVGG-A0] (main.py 282): INFO Train: [250/300][10/78]	eta 0:03:43 lr 0.426573	time 1.1696 (3.2828)	loss 2.3392 (2.3662)	grad_norm 0.5381 (0.5453)	mem 39782MB
[2023-07-07 16:56:41 RepVGG-A0] (main.py 282): INFO Train: [250/300][20/78]	eta 0:02:24 lr 0.424433	time 1.1381 (2.4882)	loss 2.3890 (2.3680)	grad_norm 0.5433 (0.5451)	mem 39782MB
[2023-07-07 16:56:56 RepVGG-A0] (main.py 282): INFO Train: [250/300][30/78]	eta 0:01:43 lr 0.422297	time 1.4088 (2.1460)	loss 2.3777 (2.3713)	grad_norm 0.5434 (0.5436)	mem 39782MB
[2023-07-07 16:57:13 RepVGG-A0] (main.py 282): INFO Train: [250/300][40/78]	eta 0:01:17 lr 0.420166	time 3.7204 (2.0524)	loss 2.3302 (2.3787)	grad_norm 0.5405 (0.5441)	mem 39782MB
[2023-07-07 16:57:28 RepVGG-A0] (main.py 282): INFO Train: [250/300][50/78]	eta 0:00:54 lr 0.418041	time 1.2924 (1.9434)	loss 2.4505 (2.3845)	grad_norm 0.5372 (0.5442)	mem 39782MB
[2023-07-07 16:57:44 RepVGG-A0] (main.py 282): INFO Train: [250/300][60/78]	eta 0:00:33 lr 0.415920	time 1.1743 (1.8746)	loss 2.3795 (2.3835)	grad_norm 0.5433 (0.5445)	mem 39782MB
[2023-07-07 16:57:59 RepVGG-A0] (main.py 282): INFO Train: [250/300][70/78]	eta 0:00:14 lr 0.413805	time 1.7482 (1.8270)	loss 2.3634 (2.3833)	grad_norm 0.5415 (0.5441)	mem 39782MB
[2023-07-07 16:58:10 RepVGG-A0] (main.py 291): INFO EPOCH 250 training takes 0:02:20
[2023-07-07 16:58:33 RepVGG-A0] (main.py 282): INFO Train: [251/300][0/78]	eta 0:29:29 lr 0.412116	time 22.6807 (22.6807)	loss 2.3687 (2.3687)	grad_norm 0.5354 (0.5354)	mem 39782MB
[2023-07-07 16:58:47 RepVGG-A0] (main.py 282): INFO Train: [251/300][10/78]	eta 0:03:47 lr 0.410009	time 1.1724 (3.3501)	loss 2.3541 (2.3551)	grad_norm 0.5519 (0.5437)	mem 39782MB
[2023-07-07 16:59:03 RepVGG-A0] (main.py 282): INFO Train: [251/300][20/78]	eta 0:02:25 lr 0.407908	time 1.1961 (2.5092)	loss 2.4672 (2.3702)	grad_norm 0.5602 (0.5462)	mem 39782MB
[2023-07-07 16:59:17 RepVGG-A0] (main.py 282): INFO Train: [251/300][30/78]	eta 0:01:44 lr 0.405811	time 1.1565 (2.1715)	loss 2.3517 (2.3700)	grad_norm 0.5405 (0.5464)	mem 39782MB
[2023-07-07 16:59:35 RepVGG-A0] (main.py 282): INFO Train: [251/300][40/78]	eta 0:01:18 lr 0.403720	time 3.7375 (2.0599)	loss 2.3627 (2.3737)	grad_norm 0.5541 (0.5469)	mem 39782MB
[2023-07-07 16:59:50 RepVGG-A0] (main.py 282): INFO Train: [251/300][50/78]	eta 0:00:54 lr 0.401634	time 1.2717 (1.9589)	loss 2.3567 (2.3781)	grad_norm 0.5494 (0.5473)	mem 39782MB
[2023-07-07 17:00:06 RepVGG-A0] (main.py 282): INFO Train: [251/300][60/78]	eta 0:00:34 lr 0.399552	time 1.1947 (1.8912)	loss 2.3955 (2.3816)	grad_norm 0.5450 (0.5477)	mem 39782MB
[2023-07-07 17:00:21 RepVGG-A0] (main.py 282): INFO Train: [251/300][70/78]	eta 0:00:14 lr 0.397476	time 1.5729 (1.8362)	loss 2.3413 (2.3814)	grad_norm 0.5406 (0.5481)	mem 39782MB
[2023-07-07 17:00:32 RepVGG-A0] (main.py 291): INFO EPOCH 251 training takes 0:02:21
[2023-07-07 17:00:54 RepVGG-A0] (main.py 282): INFO Train: [252/300][0/78]	eta 0:28:33 lr 0.395819	time 21.9638 (21.9638)	loss 2.3870 (2.3870)	grad_norm 0.5385 (0.5385)	mem 39782MB
[2023-07-07 17:01:10 RepVGG-A0] (main.py 282): INFO Train: [252/300][10/78]	eta 0:03:55 lr 0.393751	time 1.1738 (3.4589)	loss 2.3868 (2.3690)	grad_norm 0.5492 (0.5555)	mem 39782MB
[2023-07-07 17:01:26 RepVGG-A0] (main.py 282): INFO Train: [252/300][20/78]	eta 0:02:27 lr 0.391689	time 1.3609 (2.5494)	loss 2.3303 (2.3682)	grad_norm 0.5463 (0.5476)	mem 39782MB
[2023-07-07 17:01:41 RepVGG-A0] (main.py 282): INFO Train: [252/300][30/78]	eta 0:01:46 lr 0.389632	time 1.3779 (2.2222)	loss 2.3947 (2.3708)	grad_norm 0.5640 (0.5487)	mem 39782MB
[2023-07-07 17:01:58 RepVGG-A0] (main.py 282): INFO Train: [252/300][40/78]	eta 0:01:19 lr 0.387580	time 2.8267 (2.1009)	loss 2.4150 (2.3691)	grad_norm 0.5449 (0.5482)	mem 39782MB
[2023-07-07 17:02:14 RepVGG-A0] (main.py 282): INFO Train: [252/300][50/78]	eta 0:00:55 lr 0.385533	time 1.4145 (1.9953)	loss 2.4382 (2.3721)	grad_norm 0.5438 (0.5501)	mem 39782MB
[2023-07-07 17:02:29 RepVGG-A0] (main.py 282): INFO Train: [252/300][60/78]	eta 0:00:34 lr 0.383491	time 1.4795 (1.9165)	loss 2.3656 (2.3721)	grad_norm 0.5508 (0.5500)	mem 39782MB
[2023-07-07 17:02:44 RepVGG-A0] (main.py 282): INFO Train: [252/300][70/78]	eta 0:00:14 lr 0.381455	time 1.3772 (1.8609)	loss 2.4414 (2.3736)	grad_norm 0.5554 (0.5510)	mem 39782MB
[2023-07-07 17:02:56 RepVGG-A0] (main.py 291): INFO EPOCH 252 training takes 0:02:23
[2023-07-07 17:03:18 RepVGG-A0] (main.py 282): INFO Train: [253/300][0/78]	eta 0:28:51 lr 0.379829	time 22.1995 (22.1995)	loss 2.3524 (2.3524)	grad_norm 0.5560 (0.5560)	mem 39782MB
[2023-07-07 17:03:33 RepVGG-A0] (main.py 282): INFO Train: [253/300][10/78]	eta 0:03:51 lr 0.377801	time 1.1924 (3.4039)	loss 2.3909 (2.3571)	grad_norm 0.5352 (0.5418)	mem 39782MB
[2023-07-07 17:03:48 RepVGG-A0] (main.py 282): INFO Train: [253/300][20/78]	eta 0:02:23 lr 0.375779	time 1.1759 (2.4790)	loss 2.3339 (2.3572)	grad_norm 0.5387 (0.5432)	mem 39782MB
[2023-07-07 17:04:03 RepVGG-A0] (main.py 282): INFO Train: [253/300][30/78]	eta 0:01:44 lr 0.373761	time 1.3452 (2.1843)	loss 2.3993 (2.3527)	grad_norm 0.5472 (0.5463)	mem 39782MB
[2023-07-07 17:04:22 RepVGG-A0] (main.py 282): INFO Train: [253/300][40/78]	eta 0:01:20 lr 0.371749	time 3.0395 (2.1067)	loss 2.3194 (2.3550)	grad_norm 0.5497 (0.5491)	mem 39782MB
[2023-07-07 17:04:36 RepVGG-A0] (main.py 282): INFO Train: [253/300][50/78]	eta 0:00:55 lr 0.369742	time 1.1734 (1.9719)	loss 2.4042 (2.3604)	grad_norm 0.5633 (0.5515)	mem 39782MB
[2023-07-07 17:04:52 RepVGG-A0] (main.py 282): INFO Train: [253/300][60/78]	eta 0:00:34 lr 0.367740	time 1.3972 (1.9105)	loss 2.3369 (2.3605)	grad_norm 0.5622 (0.5516)	mem 39782MB
[2023-07-07 17:05:07 RepVGG-A0] (main.py 282): INFO Train: [253/300][70/78]	eta 0:00:14 lr 0.365743	time 1.4728 (1.8480)	loss 2.3524 (2.3618)	grad_norm 0.5523 (0.5535)	mem 39782MB
[2023-07-07 17:05:19 RepVGG-A0] (main.py 291): INFO EPOCH 253 training takes 0:02:23
[2023-07-07 17:05:40 RepVGG-A0] (main.py 282): INFO Train: [254/300][0/78]	eta 0:27:31 lr 0.364149	time 21.1775 (21.1775)	loss 2.3811 (2.3811)	grad_norm 0.5703 (0.5703)	mem 39782MB
[2023-07-07 17:05:55 RepVGG-A0] (main.py 282): INFO Train: [254/300][10/78]	eta 0:03:46 lr 0.362161	time 1.1720 (3.3312)	loss 2.3496 (2.3498)	grad_norm 0.5651 (0.5628)	mem 39782MB
[2023-07-07 17:06:11 RepVGG-A0] (main.py 282): INFO Train: [254/300][20/78]	eta 0:02:22 lr 0.360178	time 1.3012 (2.4635)	loss 2.3873 (2.3566)	grad_norm 0.5542 (0.5571)	mem 39782MB
[2023-07-07 17:06:27 RepVGG-A0] (main.py 282): INFO Train: [254/300][30/78]	eta 0:01:45 lr 0.358200	time 2.0398 (2.1909)	loss 2.4038 (2.3584)	grad_norm 0.5460 (0.5571)	mem 39782MB
[2023-07-07 17:06:44 RepVGG-A0] (main.py 282): INFO Train: [254/300][40/78]	eta 0:01:19 lr 0.356228	time 3.0377 (2.0795)	loss 2.3641 (2.3613)	grad_norm 0.5505 (0.5565)	mem 39782MB
[2023-07-07 17:06:58 RepVGG-A0] (main.py 282): INFO Train: [254/300][50/78]	eta 0:00:54 lr 0.354260	time 1.1989 (1.9499)	loss 2.2877 (2.3648)	grad_norm 0.5571 (0.5577)	mem 39782MB
[2023-07-07 17:07:13 RepVGG-A0] (main.py 282): INFO Train: [254/300][60/78]	eta 0:00:33 lr 0.352298	time 1.3055 (1.8757)	loss 2.4218 (2.3682)	grad_norm 0.5771 (0.5577)	mem 39782MB
[2023-07-07 17:07:28 RepVGG-A0] (main.py 282): INFO Train: [254/300][70/78]	eta 0:00:14 lr 0.350341	time 1.1764 (1.8208)	loss 2.3673 (2.3716)	grad_norm 0.5646 (0.5588)	mem 39782MB
[2023-07-07 17:07:40 RepVGG-A0] (main.py 291): INFO EPOCH 254 training takes 0:02:21
[2023-07-07 17:08:02 RepVGG-A0] (main.py 282): INFO Train: [255/300][0/78]	eta 0:28:08 lr 0.348779	time 21.6518 (21.6518)	loss 2.4379 (2.4379)	grad_norm 0.5669 (0.5669)	mem 39782MB
[2023-07-07 17:08:16 RepVGG-A0] (main.py 282): INFO Train: [255/300][10/78]	eta 0:03:40 lr 0.346831	time 1.1714 (3.2359)	loss 2.2937 (2.3409)	grad_norm 0.5479 (0.5538)	mem 39782MB
[2023-07-07 17:08:30 RepVGG-A0] (main.py 282): INFO Train: [255/300][20/78]	eta 0:02:18 lr 0.344889	time 1.1910 (2.3892)	loss 2.3460 (2.3483)	grad_norm 0.5469 (0.5539)	mem 39782MB
[2023-07-07 17:08:46 RepVGG-A0] (main.py 282): INFO Train: [255/300][30/78]	eta 0:01:42 lr 0.342951	time 1.2522 (2.1408)	loss 2.3918 (2.3477)	grad_norm 0.5710 (0.5572)	mem 39782MB
[2023-07-07 17:09:05 RepVGG-A0] (main.py 282): INFO Train: [255/300][40/78]	eta 0:01:19 lr 0.341019	time 3.4334 (2.0821)	loss 2.4194 (2.3556)	grad_norm 0.5662 (0.5588)	mem 39782MB
[2023-07-07 17:09:20 RepVGG-A0] (main.py 282): INFO Train: [255/300][50/78]	eta 0:00:55 lr 0.339091	time 1.3036 (1.9683)	loss 2.3705 (2.3576)	grad_norm 0.5755 (0.5597)	mem 39782MB
[2023-07-07 17:09:36 RepVGG-A0] (main.py 282): INFO Train: [255/300][60/78]	eta 0:00:34 lr 0.337169	time 1.2952 (1.8948)	loss 2.3829 (2.3569)	grad_norm 0.5575 (0.5600)	mem 39782MB
[2023-07-07 17:09:51 RepVGG-A0] (main.py 282): INFO Train: [255/300][70/78]	eta 0:00:14 lr 0.335252	time 1.2415 (1.8422)	loss 2.3563 (2.3583)	grad_norm 0.5533 (0.5602)	mem 39782MB
[2023-07-07 17:10:01 RepVGG-A0] (main.py 291): INFO EPOCH 255 training takes 0:02:21
[2023-07-07 17:10:23 RepVGG-A0] (main.py 282): INFO Train: [256/300][0/78]	eta 0:28:09 lr 0.333722	time 21.6651 (21.6651)	loss 2.3225 (2.3225)	grad_norm 0.5691 (0.5691)	mem 39782MB
[2023-07-07 17:10:38 RepVGG-A0] (main.py 282): INFO Train: [256/300][10/78]	eta 0:03:44 lr 0.331815	time 1.1724 (3.2958)	loss 2.2746 (2.3233)	grad_norm 0.5738 (0.5588)	mem 39782MB
[2023-07-07 17:10:53 RepVGG-A0] (main.py 282): INFO Train: [256/300][20/78]	eta 0:02:22 lr 0.329912	time 1.2179 (2.4559)	loss 2.3266 (2.3348)	grad_norm 0.5591 (0.5602)	mem 39782MB
[2023-07-07 17:11:08 RepVGG-A0] (main.py 282): INFO Train: [256/300][30/78]	eta 0:01:43 lr 0.328015	time 1.7206 (2.1604)	loss 2.4023 (2.3408)	grad_norm 0.5674 (0.5626)	mem 39782MB
[2023-07-07 17:11:26 RepVGG-A0] (main.py 282): INFO Train: [256/300][40/78]	eta 0:01:18 lr 0.326123	time 2.8734 (2.0579)	loss 2.3132 (2.3367)	grad_norm 0.5526 (0.5633)	mem 39782MB
[2023-07-07 17:11:41 RepVGG-A0] (main.py 282): INFO Train: [256/300][50/78]	eta 0:00:54 lr 0.324236	time 1.1730 (1.9460)	loss 2.2979 (2.3373)	grad_norm 0.5577 (0.5630)	mem 39782MB
[2023-07-07 17:11:56 RepVGG-A0] (main.py 282): INFO Train: [256/300][60/78]	eta 0:00:33 lr 0.322354	time 1.2432 (1.8806)	loss 2.4261 (2.3381)	grad_norm 0.5718 (0.5624)	mem 39782MB
[2023-07-07 17:12:12 RepVGG-A0] (main.py 282): INFO Train: [256/300][70/78]	eta 0:00:14 lr 0.320477	time 1.1382 (1.8335)	loss 2.3522 (2.3427)	grad_norm 0.5744 (0.5625)	mem 39782MB
[2023-07-07 17:12:23 RepVGG-A0] (main.py 291): INFO EPOCH 256 training takes 0:02:21
[2023-07-07 17:12:44 RepVGG-A0] (main.py 282): INFO Train: [257/300][0/78]	eta 0:27:47 lr 0.318980	time 21.3807 (21.3807)	loss 2.3066 (2.3066)	grad_norm 0.5496 (0.5496)	mem 39782MB
[2023-07-07 17:13:00 RepVGG-A0] (main.py 282): INFO Train: [257/300][10/78]	eta 0:03:52 lr 0.317113	time 1.1716 (3.4205)	loss 2.2795 (2.3007)	grad_norm 0.5543 (0.5601)	mem 39782MB
[2023-07-07 17:13:15 RepVGG-A0] (main.py 282): INFO Train: [257/300][20/78]	eta 0:02:25 lr 0.315251	time 1.3538 (2.5033)	loss 2.3353 (2.3189)	grad_norm 0.5422 (0.5634)	mem 39782MB
[2023-07-07 17:13:30 RepVGG-A0] (main.py 282): INFO Train: [257/300][30/78]	eta 0:01:44 lr 0.313394	time 1.3216 (2.1822)	loss 2.3225 (2.3255)	grad_norm 0.5773 (0.5651)	mem 39782MB
[2023-07-07 17:13:49 RepVGG-A0] (main.py 282): INFO Train: [257/300][40/78]	eta 0:01:19 lr 0.311542	time 2.4641 (2.0960)	loss 2.3422 (2.3299)	grad_norm 0.5564 (0.5640)	mem 39782MB
[2023-07-07 17:14:04 RepVGG-A0] (main.py 282): INFO Train: [257/300][50/78]	eta 0:00:55 lr 0.309696	time 1.1742 (1.9961)	loss 2.3459 (2.3316)	grad_norm 0.5823 (0.5645)	mem 39782MB
[2023-07-07 17:14:20 RepVGG-A0] (main.py 282): INFO Train: [257/300][60/78]	eta 0:00:34 lr 0.307854	time 1.3569 (1.9213)	loss 2.3245 (2.3331)	grad_norm 0.5753 (0.5650)	mem 39782MB
[2023-07-07 17:14:35 RepVGG-A0] (main.py 282): INFO Train: [257/300][70/78]	eta 0:00:14 lr 0.306018	time 1.5019 (1.8666)	loss 2.3961 (2.3361)	grad_norm 0.5710 (0.5652)	mem 39782MB
[2023-07-07 17:14:46 RepVGG-A0] (main.py 291): INFO EPOCH 257 training takes 0:02:23
[2023-07-07 17:15:07 RepVGG-A0] (main.py 282): INFO Train: [258/300][0/78]	eta 0:28:16 lr 0.304553	time 21.7537 (21.7537)	loss 2.2972 (2.2972)	grad_norm 0.5610 (0.5610)	mem 39782MB
[2023-07-07 17:15:23 RepVGG-A0] (main.py 282): INFO Train: [258/300][10/78]	eta 0:03:47 lr 0.302727	time 1.1706 (3.3527)	loss 2.3071 (2.3232)	grad_norm 0.5682 (0.5617)	mem 39782MB
[2023-07-07 17:15:38 RepVGG-A0] (main.py 282): INFO Train: [258/300][20/78]	eta 0:02:23 lr 0.300905	time 1.1559 (2.4788)	loss 2.2650 (2.3187)	grad_norm 0.5610 (0.5649)	mem 39782MB
[2023-07-07 17:15:53 RepVGG-A0] (main.py 282): INFO Train: [258/300][30/78]	eta 0:01:44 lr 0.299089	time 1.4229 (2.1803)	loss 2.2895 (2.3208)	grad_norm 0.5888 (0.5667)	mem 39782MB
[2023-07-07 17:16:11 RepVGG-A0] (main.py 282): INFO Train: [258/300][40/78]	eta 0:01:19 lr 0.297278	time 3.4860 (2.0861)	loss 2.3422 (2.3239)	grad_norm 0.5585 (0.5660)	mem 39782MB
[2023-07-07 17:16:26 RepVGG-A0] (main.py 282): INFO Train: [258/300][50/78]	eta 0:00:55 lr 0.295473	time 1.1726 (1.9658)	loss 2.3615 (2.3276)	grad_norm 0.5721 (0.5666)	mem 39782MB
[2023-07-07 17:16:41 RepVGG-A0] (main.py 282): INFO Train: [258/300][60/78]	eta 0:00:34 lr 0.293672	time 1.3471 (1.8908)	loss 2.3725 (2.3300)	grad_norm 0.5658 (0.5671)	mem 39782MB
[2023-07-07 17:16:56 RepVGG-A0] (main.py 282): INFO Train: [258/300][70/78]	eta 0:00:14 lr 0.291877	time 1.2897 (1.8370)	loss 2.2785 (2.3334)	grad_norm 0.5701 (0.5676)	mem 39782MB
[2023-07-07 17:17:08 RepVGG-A0] (main.py 291): INFO EPOCH 258 training takes 0:02:22
[2023-07-07 17:17:30 RepVGG-A0] (main.py 282): INFO Train: [259/300][0/78]	eta 0:28:34 lr 0.290444	time 21.9839 (21.9839)	loss 2.3209 (2.3209)	grad_norm 0.5662 (0.5662)	mem 39782MB
[2023-07-07 17:17:45 RepVGG-A0] (main.py 282): INFO Train: [259/300][10/78]	eta 0:03:47 lr 0.288659	time 1.1719 (3.3450)	loss 2.3181 (2.3132)	grad_norm 0.5638 (0.5631)	mem 39782MB
[2023-07-07 17:18:00 RepVGG-A0] (main.py 282): INFO Train: [259/300][20/78]	eta 0:02:24 lr 0.286878	time 1.2990 (2.4900)	loss 2.3255 (2.3103)	grad_norm 0.5729 (0.5700)	mem 39782MB
[2023-07-07 17:18:14 RepVGG-A0] (main.py 282): INFO Train: [259/300][30/78]	eta 0:01:41 lr 0.285103	time 1.2052 (2.1245)	loss 2.2955 (2.3105)	grad_norm 0.5809 (0.5702)	mem 39782MB
[2023-07-07 17:18:32 RepVGG-A0] (main.py 282): INFO Train: [259/300][40/78]	eta 0:01:18 lr 0.283333	time 3.8029 (2.0655)	loss 2.3486 (2.3135)	grad_norm 0.5714 (0.5703)	mem 39782MB
[2023-07-07 17:18:47 RepVGG-A0] (main.py 282): INFO Train: [259/300][50/78]	eta 0:00:54 lr 0.281568	time 1.1712 (1.9404)	loss 2.3688 (2.3187)	grad_norm 0.5831 (0.5699)	mem 39782MB
[2023-07-07 17:19:02 RepVGG-A0] (main.py 282): INFO Train: [259/300][60/78]	eta 0:00:33 lr 0.279808	time 1.3229 (1.8755)	loss 2.3242 (2.3203)	grad_norm 0.5977 (0.5710)	mem 39782MB
[2023-07-07 17:19:17 RepVGG-A0] (main.py 282): INFO Train: [259/300][70/78]	eta 0:00:14 lr 0.278054	time 1.4327 (1.8249)	loss 2.3374 (2.3230)	grad_norm 0.5771 (0.5717)	mem 39782MB
[2023-07-07 17:19:29 RepVGG-A0] (main.py 291): INFO EPOCH 259 training takes 0:02:21
[2023-07-07 17:19:50 RepVGG-A0] (main.py 282): INFO Train: [260/300][0/78]	eta 0:27:19 lr 0.276655	time 21.0201 (21.0201)	loss 2.2874 (2.2874)	grad_norm 0.5650 (0.5650)	mem 39782MB
[2023-07-07 17:20:06 RepVGG-A0] (main.py 282): INFO Train: [260/300][10/78]	eta 0:03:43 lr 0.274910	time 1.1711 (3.2920)	loss 2.2976 (2.2882)	grad_norm 0.5658 (0.5689)	mem 39782MB
[2023-07-07 17:20:20 RepVGG-A0] (main.py 282): INFO Train: [260/300][20/78]	eta 0:02:19 lr 0.273170	time 1.3394 (2.4117)	loss 2.2825 (2.3005)	grad_norm 0.5763 (0.5697)	mem 39782MB
[2023-07-07 17:20:35 RepVGG-A0] (main.py 282): INFO Train: [260/300][30/78]	eta 0:01:41 lr 0.271436	time 1.1905 (2.1042)	loss 2.2810 (2.3049)	grad_norm 0.5676 (0.5700)	mem 39782MB
[2023-07-07 17:20:53 RepVGG-A0] (main.py 282): INFO Train: [260/300][40/78]	eta 0:01:17 lr 0.269707	time 3.6006 (2.0343)	loss 2.3009 (2.3120)	grad_norm 0.5700 (0.5724)	mem 39782MB
[2023-07-07 17:21:08 RepVGG-A0] (main.py 282): INFO Train: [260/300][50/78]	eta 0:00:54 lr 0.267983	time 1.3090 (1.9379)	loss 2.3028 (2.3138)	grad_norm 0.5723 (0.5737)	mem 39782MB
[2023-07-07 17:21:23 RepVGG-A0] (main.py 282): INFO Train: [260/300][60/78]	eta 0:00:33 lr 0.266265	time 1.1688 (1.8639)	loss 2.3117 (2.3152)	grad_norm 0.5727 (0.5749)	mem 39782MB
[2023-07-07 17:21:38 RepVGG-A0] (main.py 282): INFO Train: [260/300][70/78]	eta 0:00:14 lr 0.264552	time 1.1863 (1.8150)	loss 2.3133 (2.3186)	grad_norm 0.5777 (0.5755)	mem 39782MB
[2023-07-07 17:21:51 RepVGG-A0] (main.py 291): INFO EPOCH 260 training takes 0:02:21
[2023-07-07 17:22:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.967 (16.967)	Loss 1.4969 (1.4969)	Acc@1 67.114 (67.114)	Acc@5 87.482 (87.482)	Mem 39782MB
[2023-07-07 17:22:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 67.272 Acc@5 87.486
[2023-07-07 17:22:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 260: 67.272%
[2023-07-07 17:22:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 67.27%
[2023-07-07 17:22:30 RepVGG-A0] (main.py 282): INFO Train: [261/300][0/78]	eta 0:27:46 lr 0.263185	time 21.3651 (21.3651)	loss 2.2925 (2.2925)	grad_norm 0.5742 (0.5742)	mem 39782MB
[2023-07-07 17:22:46 RepVGG-A0] (main.py 282): INFO Train: [261/300][10/78]	eta 0:03:47 lr 0.261482	time 1.1702 (3.3529)	loss 2.3156 (2.2994)	grad_norm 0.5759 (0.5737)	mem 39782MB
[2023-07-07 17:23:00 RepVGG-A0] (main.py 282): INFO Train: [261/300][20/78]	eta 0:02:21 lr 0.259783	time 1.1751 (2.4412)	loss 2.3148 (2.2957)	grad_norm 0.5811 (0.5762)	mem 39782MB
[2023-07-07 17:23:14 RepVGG-A0] (main.py 282): INFO Train: [261/300][30/78]	eta 0:01:41 lr 0.258090	time 1.2560 (2.1167)	loss 2.3265 (2.2991)	grad_norm 0.5711 (0.5770)	mem 39782MB
[2023-07-07 17:23:32 RepVGG-A0] (main.py 282): INFO Train: [261/300][40/78]	eta 0:01:17 lr 0.256403	time 1.9079 (2.0311)	loss 2.2768 (2.3027)	grad_norm 0.5813 (0.5768)	mem 39782MB
[2023-07-07 17:23:48 RepVGG-A0] (main.py 282): INFO Train: [261/300][50/78]	eta 0:00:54 lr 0.254720	time 1.1720 (1.9466)	loss 2.2894 (2.3049)	grad_norm 0.5722 (0.5772)	mem 39782MB
[2023-07-07 17:24:03 RepVGG-A0] (main.py 282): INFO Train: [261/300][60/78]	eta 0:00:33 lr 0.253043	time 1.1950 (1.8657)	loss 2.3567 (2.3057)	grad_norm 0.5751 (0.5766)	mem 39782MB
[2023-07-07 17:24:18 RepVGG-A0] (main.py 282): INFO Train: [261/300][70/78]	eta 0:00:14 lr 0.251371	time 1.1408 (1.8224)	loss 2.2801 (2.3073)	grad_norm 0.5704 (0.5782)	mem 39782MB
[2023-07-07 17:24:30 RepVGG-A0] (main.py 291): INFO EPOCH 261 training takes 0:02:21
[2023-07-07 17:24:52 RepVGG-A0] (main.py 282): INFO Train: [262/300][0/78]	eta 0:28:14 lr 0.250038	time 21.7252 (21.7252)	loss 2.2659 (2.2659)	grad_norm 0.5803 (0.5803)	mem 39782MB
[2023-07-07 17:25:07 RepVGG-A0] (main.py 282): INFO Train: [262/300][10/78]	eta 0:03:44 lr 0.248376	time 1.1904 (3.3021)	loss 2.2876 (2.2897)	grad_norm 0.5728 (0.5734)	mem 39782MB
[2023-07-07 17:25:22 RepVGG-A0] (main.py 282): INFO Train: [262/300][20/78]	eta 0:02:21 lr 0.246719	time 1.2354 (2.4450)	loss 2.2564 (2.2941)	grad_norm 0.5873 (0.5748)	mem 39782MB
[2023-07-07 17:25:38 RepVGG-A0] (main.py 282): INFO Train: [262/300][30/78]	eta 0:01:45 lr 0.245067	time 1.9641 (2.1930)	loss 2.3680 (2.2954)	grad_norm 0.5979 (0.5759)	mem 39782MB
[2023-07-07 17:25:56 RepVGG-A0] (main.py 282): INFO Train: [262/300][40/78]	eta 0:01:18 lr 0.243421	time 3.5217 (2.0772)	loss 2.2736 (2.2980)	grad_norm 0.5793 (0.5774)	mem 39782MB
[2023-07-07 17:26:10 RepVGG-A0] (main.py 282): INFO Train: [262/300][50/78]	eta 0:00:54 lr 0.241780	time 1.1709 (1.9609)	loss 2.3438 (2.3015)	grad_norm 0.5810 (0.5782)	mem 39782MB
[2023-07-07 17:26:26 RepVGG-A0] (main.py 282): INFO Train: [262/300][60/78]	eta 0:00:33 lr 0.240145	time 1.3063 (1.8863)	loss 2.3621 (2.3032)	grad_norm 0.5828 (0.5782)	mem 39782MB
[2023-07-07 17:26:41 RepVGG-A0] (main.py 282): INFO Train: [262/300][70/78]	eta 0:00:14 lr 0.238514	time 1.5167 (1.8345)	loss 2.2796 (2.3054)	grad_norm 0.5824 (0.5790)	mem 39782MB
[2023-07-07 17:26:52 RepVGG-A0] (main.py 291): INFO EPOCH 262 training takes 0:02:21
[2023-07-07 17:27:13 RepVGG-A0] (main.py 282): INFO Train: [263/300][0/78]	eta 0:27:16 lr 0.237214	time 20.9780 (20.9780)	loss 2.2802 (2.2802)	grad_norm 0.6101 (0.6101)	mem 39782MB
[2023-07-07 17:27:28 RepVGG-A0] (main.py 282): INFO Train: [263/300][10/78]	eta 0:03:39 lr 0.235594	time 1.1726 (3.2234)	loss 2.2775 (2.2810)	grad_norm 0.5813 (0.6169)	mem 39782MB
[2023-07-07 17:27:43 RepVGG-A0] (main.py 282): INFO Train: [263/300][20/78]	eta 0:02:20 lr 0.233978	time 1.2791 (2.4255)	loss 2.3303 (2.2927)	grad_norm 0.5791 (0.5982)	mem 39782MB
[2023-07-07 17:28:05 RepVGG-A0] (main.py 282): INFO Train: [263/300][30/78]	eta 0:01:51 lr 0.232368	time 1.1719 (2.3285)	loss 2.3099 (2.2917)	grad_norm 0.5789 (0.5924)	mem 39782MB
[2023-07-07 17:28:21 RepVGG-A0] (main.py 282): INFO Train: [263/300][40/78]	eta 0:01:21 lr 0.230764	time 1.1748 (2.1519)	loss 2.3688 (2.2951)	grad_norm 0.5843 (0.5906)	mem 39782MB
[2023-07-07 17:28:36 RepVGG-A0] (main.py 282): INFO Train: [263/300][50/78]	eta 0:00:57 lr 0.229165	time 1.1790 (2.0362)	loss 2.2982 (2.2976)	grad_norm 0.5638 (0.5889)	mem 39782MB
[2023-07-07 17:28:51 RepVGG-A0] (main.py 282): INFO Train: [263/300][60/78]	eta 0:00:35 lr 0.227571	time 1.2611 (1.9451)	loss 2.2842 (2.2985)	grad_norm 0.5914 (0.5885)	mem 39782MB
[2023-07-07 17:29:06 RepVGG-A0] (main.py 282): INFO Train: [263/300][70/78]	eta 0:00:15 lr 0.225982	time 1.2269 (1.8803)	loss 2.3268 (2.2995)	grad_norm 0.5738 (0.5882)	mem 39782MB
[2023-07-07 17:29:17 RepVGG-A0] (main.py 291): INFO EPOCH 263 training takes 0:02:24
[2023-07-07 17:29:37 RepVGG-A0] (main.py 282): INFO Train: [264/300][0/78]	eta 0:26:51 lr 0.224715	time 20.6581 (20.6581)	loss 2.2684 (2.2684)	grad_norm 0.5828 (0.5828)	mem 39782MB
[2023-07-07 17:29:53 RepVGG-A0] (main.py 282): INFO Train: [264/300][10/78]	eta 0:03:41 lr 0.223136	time 1.1718 (3.2578)	loss 2.3151 (2.2909)	grad_norm 0.5700 (0.5851)	mem 39782MB
[2023-07-07 17:30:07 RepVGG-A0] (main.py 282): INFO Train: [264/300][20/78]	eta 0:02:19 lr 0.221563	time 1.1731 (2.4044)	loss 2.3155 (2.2925)	grad_norm 0.5929 (0.5869)	mem 39782MB
[2023-07-07 17:30:23 RepVGG-A0] (main.py 282): INFO Train: [264/300][30/78]	eta 0:01:41 lr 0.219995	time 1.2665 (2.1202)	loss 2.3197 (2.2944)	grad_norm 0.6009 (0.5866)	mem 39782MB
[2023-07-07 17:30:40 RepVGG-A0] (main.py 282): INFO Train: [264/300][40/78]	eta 0:01:17 lr 0.218432	time 3.1726 (2.0289)	loss 2.3108 (2.2951)	grad_norm 0.5828 (0.5865)	mem 39782MB
[2023-07-07 17:30:55 RepVGG-A0] (main.py 282): INFO Train: [264/300][50/78]	eta 0:00:54 lr 0.216875	time 1.1729 (1.9337)	loss 2.2535 (2.2913)	grad_norm 0.5860 (0.5859)	mem 39782MB
[2023-07-07 17:31:11 RepVGG-A0] (main.py 282): INFO Train: [264/300][60/78]	eta 0:00:33 lr 0.215323	time 1.4957 (1.8747)	loss 2.2790 (2.2922)	grad_norm 0.5947 (0.5869)	mem 39782MB
[2023-07-07 17:31:26 RepVGG-A0] (main.py 282): INFO Train: [264/300][70/78]	eta 0:00:14 lr 0.213776	time 1.2225 (1.8138)	loss 2.3502 (2.2935)	grad_norm 0.5859 (0.5867)	mem 39782MB
[2023-07-07 17:31:38 RepVGG-A0] (main.py 291): INFO EPOCH 264 training takes 0:02:20
[2023-07-07 17:32:00 RepVGG-A0] (main.py 282): INFO Train: [265/300][0/78]	eta 0:28:33 lr 0.212543	time 21.9686 (21.9686)	loss 2.2902 (2.2902)	grad_norm 0.5911 (0.5911)	mem 39782MB
[2023-07-07 17:32:15 RepVGG-A0] (main.py 282): INFO Train: [265/300][10/78]	eta 0:03:49 lr 0.211006	time 1.1913 (3.3690)	loss 2.2723 (2.2769)	grad_norm 0.5899 (0.5860)	mem 39782MB
[2023-07-07 17:32:30 RepVGG-A0] (main.py 282): INFO Train: [265/300][20/78]	eta 0:02:23 lr 0.209474	time 1.3941 (2.4790)	loss 2.2558 (2.2872)	grad_norm 0.5889 (0.5902)	mem 39782MB
[2023-07-07 17:32:44 RepVGG-A0] (main.py 282): INFO Train: [265/300][30/78]	eta 0:01:43 lr 0.207948	time 1.2399 (2.1524)	loss 2.2667 (2.2838)	grad_norm 0.5842 (0.5901)	mem 39782MB
[2023-07-07 17:33:02 RepVGG-A0] (main.py 282): INFO Train: [265/300][40/78]	eta 0:01:18 lr 0.206427	time 3.7173 (2.0650)	loss 2.2931 (2.2821)	grad_norm 0.6056 (0.5899)	mem 39782MB
[2023-07-07 17:33:17 RepVGG-A0] (main.py 282): INFO Train: [265/300][50/78]	eta 0:00:54 lr 0.204912	time 1.1731 (1.9496)	loss 2.2884 (2.2851)	grad_norm 0.5949 (0.5911)	mem 39782MB
[2023-07-07 17:33:32 RepVGG-A0] (main.py 282): INFO Train: [265/300][60/78]	eta 0:00:33 lr 0.203402	time 1.1363 (1.8819)	loss 2.2572 (2.2851)	grad_norm 0.5862 (0.5911)	mem 39782MB
[2023-07-07 17:33:48 RepVGG-A0] (main.py 282): INFO Train: [265/300][70/78]	eta 0:00:14 lr 0.201897	time 1.3206 (1.8416)	loss 2.3485 (2.2892)	grad_norm 0.5918 (0.5905)	mem 39782MB
[2023-07-07 17:33:59 RepVGG-A0] (main.py 291): INFO EPOCH 265 training takes 0:02:21
[2023-07-07 17:34:21 RepVGG-A0] (main.py 282): INFO Train: [266/300][0/78]	eta 0:28:17 lr 0.200698	time 21.7595 (21.7595)	loss 2.2969 (2.2969)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 17:34:36 RepVGG-A0] (main.py 282): INFO Train: [266/300][10/78]	eta 0:03:47 lr 0.199203	time 1.1720 (3.3463)	loss 2.2518 (2.2639)	grad_norm 0.5801 (0.5881)	mem 39782MB
[2023-07-07 17:34:51 RepVGG-A0] (main.py 282): INFO Train: [266/300][20/78]	eta 0:02:22 lr 0.197713	time 1.2477 (2.4655)	loss 2.3134 (2.2667)	grad_norm 0.5976 (0.5885)	mem 39782MB
[2023-07-07 17:35:06 RepVGG-A0] (main.py 282): INFO Train: [266/300][30/78]	eta 0:01:44 lr 0.196229	time 1.2763 (2.1688)	loss 2.2276 (2.2661)	grad_norm 0.5975 (0.5891)	mem 39782MB
[2023-07-07 17:35:23 RepVGG-A0] (main.py 282): INFO Train: [266/300][40/78]	eta 0:01:17 lr 0.194751	time 2.4944 (2.0446)	loss 2.2205 (2.2712)	grad_norm 0.5995 (0.5908)	mem 39782MB
[2023-07-07 17:35:39 RepVGG-A0] (main.py 282): INFO Train: [266/300][50/78]	eta 0:00:54 lr 0.193278	time 1.1725 (1.9515)	loss 2.2504 (2.2711)	grad_norm 0.5956 (0.5913)	mem 39782MB
[2023-07-07 17:35:54 RepVGG-A0] (main.py 282): INFO Train: [266/300][60/78]	eta 0:00:33 lr 0.191810	time 1.2012 (1.8731)	loss 2.3195 (2.2713)	grad_norm 0.5952 (0.5922)	mem 39782MB
[2023-07-07 17:36:09 RepVGG-A0] (main.py 282): INFO Train: [266/300][70/78]	eta 0:00:14 lr 0.190348	time 1.6811 (1.8245)	loss 2.2641 (2.2732)	grad_norm 0.6125 (0.5929)	mem 39782MB
[2023-07-07 17:36:21 RepVGG-A0] (main.py 291): INFO EPOCH 266 training takes 0:02:21
[2023-07-07 17:36:41 RepVGG-A0] (main.py 282): INFO Train: [267/300][0/78]	eta 0:26:06 lr 0.189182	time 20.0785 (20.0785)	loss 2.2569 (2.2569)	grad_norm 0.5900 (0.5900)	mem 39782MB
[2023-07-07 17:36:56 RepVGG-A0] (main.py 282): INFO Train: [267/300][10/78]	eta 0:03:34 lr 0.187729	time 1.1898 (3.1608)	loss 2.2752 (2.2619)	grad_norm 0.5996 (0.5898)	mem 39782MB
[2023-07-07 17:37:12 RepVGG-A0] (main.py 282): INFO Train: [267/300][20/78]	eta 0:02:21 lr 0.186282	time 1.2197 (2.4375)	loss 2.2884 (2.2688)	grad_norm 0.6010 (0.5914)	mem 39782MB
[2023-07-07 17:37:27 RepVGG-A0] (main.py 282): INFO Train: [267/300][30/78]	eta 0:01:42 lr 0.184840	time 1.3362 (2.1253)	loss 2.3074 (2.2757)	grad_norm 0.5988 (0.5931)	mem 39782MB
[2023-07-07 17:37:43 RepVGG-A0] (main.py 282): INFO Train: [267/300][40/78]	eta 0:01:16 lr 0.183404	time 3.3891 (2.0020)	loss 2.2982 (2.2790)	grad_norm 0.5921 (0.5955)	mem 39782MB
[2023-07-07 17:37:58 RepVGG-A0] (main.py 282): INFO Train: [267/300][50/78]	eta 0:00:53 lr 0.181973	time 1.3426 (1.9058)	loss 2.2454 (2.2758)	grad_norm 0.6023 (0.5957)	mem 39782MB
[2023-07-07 17:38:13 RepVGG-A0] (main.py 282): INFO Train: [267/300][60/78]	eta 0:00:33 lr 0.180548	time 1.1728 (1.8385)	loss 2.2928 (2.2774)	grad_norm 0.6014 (0.5958)	mem 39782MB
[2023-07-07 17:38:28 RepVGG-A0] (main.py 282): INFO Train: [267/300][70/78]	eta 0:00:14 lr 0.179128	time 1.3649 (1.7912)	loss 2.2603 (2.2805)	grad_norm 0.6048 (0.5967)	mem 39782MB
[2023-07-07 17:38:40 RepVGG-A0] (main.py 291): INFO EPOCH 267 training takes 0:02:18
[2023-07-07 17:39:00 RepVGG-A0] (main.py 282): INFO Train: [268/300][0/78]	eta 0:26:58 lr 0.177996	time 20.7500 (20.7500)	loss 2.2570 (2.2570)	grad_norm 0.5898 (0.5898)	mem 39782MB
[2023-07-07 17:39:16 RepVGG-A0] (main.py 282): INFO Train: [268/300][10/78]	eta 0:03:42 lr 0.176585	time 1.1716 (3.2658)	loss 2.3239 (2.2463)	grad_norm 0.5931 (0.5918)	mem 39782MB
[2023-07-07 17:39:31 RepVGG-A0] (main.py 282): INFO Train: [268/300][20/78]	eta 0:02:22 lr 0.175181	time 1.2579 (2.4512)	loss 2.2954 (2.2467)	grad_norm 0.5965 (0.5918)	mem 39782MB
[2023-07-07 17:39:46 RepVGG-A0] (main.py 282): INFO Train: [268/300][30/78]	eta 0:01:42 lr 0.173782	time 1.3603 (2.1342)	loss 2.3002 (2.2522)	grad_norm 0.5863 (0.5934)	mem 39782MB
[2023-07-07 17:40:03 RepVGG-A0] (main.py 282): INFO Train: [268/300][40/78]	eta 0:01:17 lr 0.172388	time 3.0117 (2.0413)	loss 2.2808 (2.2549)	grad_norm 0.5968 (0.5946)	mem 39782MB
[2023-07-07 17:40:19 RepVGG-A0] (main.py 282): INFO Train: [268/300][50/78]	eta 0:00:54 lr 0.170999	time 1.1723 (1.9441)	loss 2.2568 (2.2602)	grad_norm 0.5996 (0.5957)	mem 39782MB
[2023-07-07 17:40:34 RepVGG-A0] (main.py 282): INFO Train: [268/300][60/78]	eta 0:00:33 lr 0.169617	time 1.1547 (1.8741)	loss 2.3052 (2.2614)	grad_norm 0.5948 (0.5972)	mem 39782MB
[2023-07-07 17:40:49 RepVGG-A0] (main.py 282): INFO Train: [268/300][70/78]	eta 0:00:14 lr 0.168239	time 1.2755 (1.8170)	loss 2.3105 (2.2646)	grad_norm 0.6081 (0.5977)	mem 39782MB
[2023-07-07 17:41:00 RepVGG-A0] (main.py 291): INFO EPOCH 268 training takes 0:02:20
[2023-07-07 17:41:21 RepVGG-A0] (main.py 282): INFO Train: [269/300][0/78]	eta 0:27:23 lr 0.167141	time 21.0691 (21.0691)	loss 2.2552 (2.2552)	grad_norm 0.5896 (0.5896)	mem 39782MB
[2023-07-07 17:41:36 RepVGG-A0] (main.py 282): INFO Train: [269/300][10/78]	eta 0:03:43 lr 0.165774	time 1.1751 (3.2856)	loss 2.2266 (2.2410)	grad_norm 0.6026 (0.5946)	mem 39782MB
[2023-07-07 17:41:52 RepVGG-A0] (main.py 282): INFO Train: [269/300][20/78]	eta 0:02:21 lr 0.164411	time 1.3255 (2.4459)	loss 2.2307 (2.2427)	grad_norm 0.6027 (0.5969)	mem 39782MB
[2023-07-07 17:42:07 RepVGG-A0] (main.py 282): INFO Train: [269/300][30/78]	eta 0:01:42 lr 0.163055	time 1.1279 (2.1435)	loss 2.2517 (2.2448)	grad_norm 0.5956 (0.5978)	mem 39782MB
[2023-07-07 17:42:26 RepVGG-A0] (main.py 282): INFO Train: [269/300][40/78]	eta 0:01:19 lr 0.161704	time 3.6576 (2.0801)	loss 2.2310 (2.2471)	grad_norm 0.6046 (0.5996)	mem 39782MB
[2023-07-07 17:42:40 RepVGG-A0] (main.py 282): INFO Train: [269/300][50/78]	eta 0:00:54 lr 0.160358	time 1.1782 (1.9593)	loss 2.2513 (2.2489)	grad_norm 0.5963 (0.6004)	mem 39782MB
[2023-07-07 17:42:55 RepVGG-A0] (main.py 282): INFO Train: [269/300][60/78]	eta 0:00:33 lr 0.159018	time 1.1763 (1.8869)	loss 2.2576 (2.2513)	grad_norm 0.6096 (0.6003)	mem 39782MB
[2023-07-07 17:43:10 RepVGG-A0] (main.py 282): INFO Train: [269/300][70/78]	eta 0:00:14 lr 0.157683	time 1.3693 (1.8304)	loss 2.2543 (2.2523)	grad_norm 0.5994 (0.6009)	mem 39782MB
[2023-07-07 17:43:21 RepVGG-A0] (main.py 291): INFO EPOCH 269 training takes 0:02:21
[2023-07-07 17:43:43 RepVGG-A0] (main.py 282): INFO Train: [270/300][0/78]	eta 0:28:48 lr 0.156619	time 22.1592 (22.1592)	loss 2.2643 (2.2643)	grad_norm 0.6002 (0.6002)	mem 39782MB
[2023-07-07 17:43:58 RepVGG-A0] (main.py 282): INFO Train: [270/300][10/78]	eta 0:03:50 lr 0.155294	time 1.1734 (3.3828)	loss 2.2789 (2.2405)	grad_norm 0.5950 (0.6043)	mem 39782MB
[2023-07-07 17:44:14 RepVGG-A0] (main.py 282): INFO Train: [270/300][20/78]	eta 0:02:24 lr 0.153975	time 1.1914 (2.4890)	loss 2.2301 (2.2419)	grad_norm 0.5992 (0.6035)	mem 39782MB
[2023-07-07 17:44:28 RepVGG-A0] (main.py 282): INFO Train: [270/300][30/78]	eta 0:01:44 lr 0.152661	time 1.2925 (2.1677)	loss 2.2811 (2.2462)	grad_norm 0.6050 (0.6041)	mem 39782MB
[2023-07-07 17:44:46 RepVGG-A0] (main.py 282): INFO Train: [270/300][40/78]	eta 0:01:18 lr 0.151353	time 3.2274 (2.0649)	loss 2.2092 (2.2492)	grad_norm 0.6112 (0.6051)	mem 39782MB
[2023-07-07 17:45:01 RepVGG-A0] (main.py 282): INFO Train: [270/300][50/78]	eta 0:00:54 lr 0.150050	time 1.3944 (1.9577)	loss 2.2689 (2.2517)	grad_norm 0.6031 (0.6053)	mem 39782MB
[2023-07-07 17:45:16 RepVGG-A0] (main.py 282): INFO Train: [270/300][60/78]	eta 0:00:33 lr 0.148752	time 1.2197 (1.8789)	loss 2.2516 (2.2516)	grad_norm 0.6040 (0.6058)	mem 39782MB
[2023-07-07 17:45:31 RepVGG-A0] (main.py 282): INFO Train: [270/300][70/78]	eta 0:00:14 lr 0.147460	time 1.2458 (1.8268)	loss 2.3012 (2.2536)	grad_norm 0.6121 (0.6065)	mem 39782MB
[2023-07-07 17:45:42 RepVGG-A0] (main.py 291): INFO EPOCH 270 training takes 0:02:21
[2023-07-07 17:46:02 RepVGG-A0] (main.py 282): INFO Train: [271/300][0/78]	eta 0:25:24 lr 0.146431	time 19.5494 (19.5494)	loss 2.1982 (2.1982)	grad_norm 0.6115 (0.6115)	mem 39782MB
[2023-07-07 17:46:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][10/78]	eta 0:03:49 lr 0.145149	time 1.1705 (3.3779)	loss 2.1992 (2.2216)	grad_norm 0.5993 (0.6003)	mem 39782MB
[2023-07-07 17:46:33 RepVGG-A0] (main.py 282): INFO Train: [271/300][20/78]	eta 0:02:20 lr 0.143872	time 1.2179 (2.4195)	loss 2.1442 (2.2313)	grad_norm 0.5962 (0.6028)	mem 39782MB
[2023-07-07 17:46:48 RepVGG-A0] (main.py 282): INFO Train: [271/300][30/78]	eta 0:01:41 lr 0.142602	time 1.4647 (2.1131)	loss 2.1924 (2.2377)	grad_norm 0.6090 (0.6048)	mem 39782MB
[2023-07-07 17:47:05 RepVGG-A0] (main.py 282): INFO Train: [271/300][40/78]	eta 0:01:16 lr 0.141336	time 3.3189 (2.0124)	loss 2.3136 (2.2368)	grad_norm 0.6036 (0.6051)	mem 39782MB
[2023-07-07 17:47:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][50/78]	eta 0:00:53 lr 0.140076	time 1.1816 (1.9121)	loss 2.2865 (2.2395)	grad_norm 0.6162 (0.6058)	mem 39782MB
[2023-07-07 17:47:36 RepVGG-A0] (main.py 282): INFO Train: [271/300][60/78]	eta 0:00:33 lr 0.138822	time 1.2516 (1.8529)	loss 2.2155 (2.2425)	grad_norm 0.6106 (0.6069)	mem 39782MB
[2023-07-07 17:47:50 RepVGG-A0] (main.py 282): INFO Train: [271/300][70/78]	eta 0:00:14 lr 0.137573	time 1.3903 (1.7997)	loss 2.2798 (2.2451)	grad_norm 0.6113 (0.6073)	mem 39782MB
[2023-07-07 17:48:02 RepVGG-A0] (main.py 291): INFO EPOCH 271 training takes 0:02:19
[2023-07-07 17:48:24 RepVGG-A0] (main.py 282): INFO Train: [272/300][0/78]	eta 0:28:38 lr 0.136578	time 22.0369 (22.0369)	loss 2.1963 (2.1963)	grad_norm 0.6081 (0.6081)	mem 39782MB
[2023-07-07 17:48:39 RepVGG-A0] (main.py 282): INFO Train: [272/300][10/78]	eta 0:03:46 lr 0.135339	time 1.1724 (3.3314)	loss 2.2257 (2.2480)	grad_norm 0.6057 (0.6103)	mem 39782MB
[2023-07-07 17:48:53 RepVGG-A0] (main.py 282): INFO Train: [272/300][20/78]	eta 0:02:21 lr 0.134105	time 1.1808 (2.4395)	loss 2.1951 (2.2455)	grad_norm 0.6070 (0.6112)	mem 39782MB
[2023-07-07 17:49:08 RepVGG-A0] (main.py 282): INFO Train: [272/300][30/78]	eta 0:01:41 lr 0.132877	time 1.2775 (2.1198)	loss 2.1686 (2.2415)	grad_norm 0.6172 (0.6116)	mem 39782MB
[2023-07-07 17:49:26 RepVGG-A0] (main.py 282): INFO Train: [272/300][40/78]	eta 0:01:17 lr 0.131655	time 4.1489 (2.0337)	loss 2.2291 (2.2378)	grad_norm 0.6209 (0.6121)	mem 39782MB
[2023-07-07 17:49:41 RepVGG-A0] (main.py 282): INFO Train: [272/300][50/78]	eta 0:00:54 lr 0.130438	time 1.1429 (1.9336)	loss 2.2175 (2.2397)	grad_norm 0.6034 (0.6133)	mem 39782MB
[2023-07-07 17:49:56 RepVGG-A0] (main.py 282): INFO Train: [272/300][60/78]	eta 0:00:33 lr 0.129227	time 1.2402 (1.8678)	loss 2.1771 (2.2400)	grad_norm 0.6289 (0.6136)	mem 39782MB
[2023-07-07 17:50:12 RepVGG-A0] (main.py 282): INFO Train: [272/300][70/78]	eta 0:00:14 lr 0.128021	time 1.2819 (1.8237)	loss 2.2308 (2.2415)	grad_norm 0.6133 (0.6140)	mem 39782MB
[2023-07-07 17:50:24 RepVGG-A0] (main.py 291): INFO EPOCH 272 training takes 0:02:21
[2023-07-07 17:50:45 RepVGG-A0] (main.py 282): INFO Train: [273/300][0/78]	eta 0:27:06 lr 0.127060	time 20.8555 (20.8555)	loss 2.2412 (2.2412)	grad_norm 0.6025 (0.6025)	mem 39782MB
[2023-07-07 17:51:01 RepVGG-A0] (main.py 282): INFO Train: [273/300][10/78]	eta 0:03:51 lr 0.125864	time 1.1724 (3.4048)	loss 2.2218 (2.2328)	grad_norm 0.6136 (0.6100)	mem 39782MB
[2023-07-07 17:51:17 RepVGG-A0] (main.py 282): INFO Train: [273/300][20/78]	eta 0:02:27 lr 0.124674	time 1.2904 (2.5405)	loss 2.2723 (2.2336)	grad_norm 0.6155 (0.6130)	mem 39782MB
[2023-07-07 17:51:33 RepVGG-A0] (main.py 282): INFO Train: [273/300][30/78]	eta 0:01:47 lr 0.123489	time 1.9187 (2.2292)	loss 2.2171 (2.2301)	grad_norm 0.6181 (0.6123)	mem 39782MB
[2023-07-07 17:51:50 RepVGG-A0] (main.py 282): INFO Train: [273/300][40/78]	eta 0:01:19 lr 0.122310	time 2.4511 (2.1034)	loss 2.3239 (2.2339)	grad_norm 0.6127 (0.6129)	mem 39782MB
[2023-07-07 17:52:05 RepVGG-A0] (main.py 282): INFO Train: [273/300][50/78]	eta 0:00:55 lr 0.121136	time 1.1921 (1.9929)	loss 2.2726 (2.2368)	grad_norm 0.6200 (0.6141)	mem 39782MB
[2023-07-07 17:52:20 RepVGG-A0] (main.py 282): INFO Train: [273/300][60/78]	eta 0:00:34 lr 0.119968	time 1.1752 (1.9064)	loss 2.3041 (2.2392)	grad_norm 0.6246 (0.6147)	mem 39782MB
[2023-07-07 17:52:35 RepVGG-A0] (main.py 282): INFO Train: [273/300][70/78]	eta 0:00:14 lr 0.118806	time 1.7490 (1.8540)	loss 2.2010 (2.2413)	grad_norm 0.6233 (0.6163)	mem 39782MB
[2023-07-07 17:52:46 RepVGG-A0] (main.py 291): INFO EPOCH 273 training takes 0:02:22
[2023-07-07 17:53:07 RepVGG-A0] (main.py 282): INFO Train: [274/300][0/78]	eta 0:26:51 lr 0.117880	time 20.6626 (20.6626)	loss 2.1962 (2.1962)	grad_norm 0.6061 (0.6061)	mem 39782MB
[2023-07-07 17:53:22 RepVGG-A0] (main.py 282): INFO Train: [274/300][10/78]	eta 0:03:39 lr 0.116727	time 1.1901 (3.2276)	loss 2.2480 (2.2181)	grad_norm 0.6169 (0.6088)	mem 39782MB
[2023-07-07 17:53:37 RepVGG-A0] (main.py 282): INFO Train: [274/300][20/78]	eta 0:02:20 lr 0.115580	time 1.1899 (2.4176)	loss 2.2430 (2.2158)	grad_norm 0.6198 (0.6120)	mem 39782MB
[2023-07-07 17:53:52 RepVGG-A0] (main.py 282): INFO Train: [274/300][30/78]	eta 0:01:41 lr 0.114439	time 1.4350 (2.1218)	loss 2.2277 (2.2222)	grad_norm 0.6142 (0.6141)	mem 39782MB
[2023-07-07 17:54:11 RepVGG-A0] (main.py 282): INFO Train: [274/300][40/78]	eta 0:01:18 lr 0.113303	time 3.4124 (2.0566)	loss 2.2211 (2.2207)	grad_norm 0.6123 (0.6146)	mem 39782MB
[2023-07-07 17:54:26 RepVGG-A0] (main.py 282): INFO Train: [274/300][50/78]	eta 0:00:54 lr 0.112173	time 1.2028 (1.9454)	loss 2.2341 (2.2255)	grad_norm 0.6258 (0.6161)	mem 39782MB
[2023-07-07 17:54:40 RepVGG-A0] (main.py 282): INFO Train: [274/300][60/78]	eta 0:00:33 lr 0.111048	time 1.1988 (1.8661)	loss 2.2067 (2.2241)	grad_norm 0.6216 (0.6162)	mem 39782MB
[2023-07-07 17:54:55 RepVGG-A0] (main.py 282): INFO Train: [274/300][70/78]	eta 0:00:14 lr 0.109929	time 1.1720 (1.8107)	loss 2.2638 (2.2280)	grad_norm 0.6171 (0.6171)	mem 39782MB
[2023-07-07 17:55:07 RepVGG-A0] (main.py 291): INFO EPOCH 274 training takes 0:02:20
[2023-07-07 17:55:28 RepVGG-A0] (main.py 282): INFO Train: [275/300][0/78]	eta 0:27:00 lr 0.109037	time 20.7703 (20.7703)	loss 2.1916 (2.1916)	grad_norm 0.6124 (0.6124)	mem 39782MB
[2023-07-07 17:55:43 RepVGG-A0] (main.py 282): INFO Train: [275/300][10/78]	eta 0:03:40 lr 0.107928	time 1.1706 (3.2459)	loss 2.1465 (2.2085)	grad_norm 0.6142 (0.6143)	mem 39782MB
[2023-07-07 17:55:57 RepVGG-A0] (main.py 282): INFO Train: [275/300][20/78]	eta 0:02:18 lr 0.106825	time 1.1720 (2.3946)	loss 2.2302 (2.2114)	grad_norm 0.6073 (0.6151)	mem 39782MB
[2023-07-07 17:56:13 RepVGG-A0] (main.py 282): INFO Train: [275/300][30/78]	eta 0:01:41 lr 0.105727	time 1.2461 (2.1196)	loss 2.1932 (2.2151)	grad_norm 0.6171 (0.6158)	mem 39782MB
[2023-07-07 17:56:30 RepVGG-A0] (main.py 282): INFO Train: [275/300][40/78]	eta 0:01:17 lr 0.104634	time 3.3335 (2.0284)	loss 2.1701 (2.2166)	grad_norm 0.6200 (0.6171)	mem 39782MB
[2023-07-07 17:56:45 RepVGG-A0] (main.py 282): INFO Train: [275/300][50/78]	eta 0:00:53 lr 0.103547	time 1.1728 (1.9181)	loss 2.1971 (2.2182)	grad_norm 0.6284 (0.6182)	mem 39782MB
[2023-07-07 17:57:00 RepVGG-A0] (main.py 282): INFO Train: [275/300][60/78]	eta 0:00:33 lr 0.102466	time 1.3299 (1.8547)	loss 2.2458 (2.2194)	grad_norm 0.6174 (0.6187)	mem 39782MB
[2023-07-07 17:57:15 RepVGG-A0] (main.py 282): INFO Train: [275/300][70/78]	eta 0:00:14 lr 0.101390	time 1.1718 (1.8040)	loss 2.2391 (2.2212)	grad_norm 0.6305 (0.6191)	mem 39782MB
[2023-07-07 17:57:26 RepVGG-A0] (main.py 291): INFO EPOCH 275 training takes 0:02:19
[2023-07-07 17:57:49 RepVGG-A0] (main.py 282): INFO Train: [276/300][0/78]	eta 0:29:19 lr 0.100534	time 22.5640 (22.5640)	loss 2.1719 (2.1719)	grad_norm 0.6158 (0.6158)	mem 39782MB
[2023-07-07 17:58:03 RepVGG-A0] (main.py 282): INFO Train: [276/300][10/78]	eta 0:03:43 lr 0.099468	time 1.1920 (3.2830)	loss 2.2422 (2.2068)	grad_norm 0.6254 (0.6183)	mem 39782MB
[2023-07-07 17:58:17 RepVGG-A0] (main.py 282): INFO Train: [276/300][20/78]	eta 0:02:18 lr 0.098408	time 1.1732 (2.3932)	loss 2.1909 (2.1969)	grad_norm 0.6192 (0.6210)	mem 39782MB
[2023-07-07 17:58:33 RepVGG-A0] (main.py 282): INFO Train: [276/300][30/78]	eta 0:01:43 lr 0.097354	time 1.1587 (2.1504)	loss 2.1931 (2.2006)	grad_norm 0.6238 (0.6215)	mem 39782MB
[2023-07-07 17:58:50 RepVGG-A0] (main.py 282): INFO Train: [276/300][40/78]	eta 0:01:17 lr 0.096305	time 3.4819 (2.0498)	loss 2.2194 (2.2016)	grad_norm 0.6140 (0.6213)	mem 39782MB
[2023-07-07 17:59:06 RepVGG-A0] (main.py 282): INFO Train: [276/300][50/78]	eta 0:00:54 lr 0.095262	time 1.1765 (1.9437)	loss 2.1941 (2.2042)	grad_norm 0.6189 (0.6214)	mem 39782MB
[2023-07-07 17:59:22 RepVGG-A0] (main.py 282): INFO Train: [276/300][60/78]	eta 0:00:34 lr 0.094224	time 1.1554 (1.8937)	loss 2.2371 (2.2069)	grad_norm 0.6191 (0.6219)	mem 39782MB
[2023-07-07 17:59:37 RepVGG-A0] (main.py 282): INFO Train: [276/300][70/78]	eta 0:00:14 lr 0.093192	time 1.2104 (1.8332)	loss 2.2523 (2.2101)	grad_norm 0.6211 (0.6219)	mem 39782MB
[2023-07-07 17:59:49 RepVGG-A0] (main.py 291): INFO EPOCH 276 training takes 0:02:22
[2023-07-07 18:00:11 RepVGG-A0] (main.py 282): INFO Train: [277/300][0/78]	eta 0:28:00 lr 0.092370	time 21.5433 (21.5433)	loss 2.1559 (2.1559)	grad_norm 0.6191 (0.6191)	mem 39782MB
[2023-07-07 18:00:25 RepVGG-A0] (main.py 282): INFO Train: [277/300][10/78]	eta 0:03:44 lr 0.091348	time 1.1720 (3.2956)	loss 2.2669 (2.2003)	grad_norm 0.6192 (0.6209)	mem 39782MB
[2023-07-07 18:00:41 RepVGG-A0] (main.py 282): INFO Train: [277/300][20/78]	eta 0:02:23 lr 0.090332	time 1.2381 (2.4715)	loss 2.1573 (2.2008)	grad_norm 0.6143 (0.6234)	mem 39782MB
[2023-07-07 18:00:56 RepVGG-A0] (main.py 282): INFO Train: [277/300][30/78]	eta 0:01:43 lr 0.089321	time 1.3794 (2.1520)	loss 2.2194 (2.2069)	grad_norm 0.6254 (0.6242)	mem 39782MB
[2023-07-07 18:01:13 RepVGG-A0] (main.py 282): INFO Train: [277/300][40/78]	eta 0:01:18 lr 0.088316	time 2.3351 (2.0535)	loss 2.1845 (2.2068)	grad_norm 0.6309 (0.6240)	mem 39782MB
[2023-07-07 18:01:29 RepVGG-A0] (main.py 282): INFO Train: [277/300][50/78]	eta 0:00:54 lr 0.087316	time 1.1713 (1.9596)	loss 2.2309 (2.2078)	grad_norm 0.6257 (0.6247)	mem 39782MB
[2023-07-07 18:01:44 RepVGG-A0] (main.py 282): INFO Train: [277/300][60/78]	eta 0:00:33 lr 0.086322	time 1.2020 (1.8868)	loss 2.1644 (2.2098)	grad_norm 0.6303 (0.6249)	mem 39782MB
[2023-07-07 18:01:59 RepVGG-A0] (main.py 282): INFO Train: [277/300][70/78]	eta 0:00:14 lr 0.085334	time 1.1741 (1.8294)	loss 2.1823 (2.2133)	grad_norm 0.6297 (0.6249)	mem 39782MB
[2023-07-07 18:02:11 RepVGG-A0] (main.py 291): INFO EPOCH 277 training takes 0:02:21
[2023-07-07 18:02:31 RepVGG-A0] (main.py 282): INFO Train: [278/300][0/78]	eta 0:26:19 lr 0.084548	time 20.2534 (20.2534)	loss 2.1582 (2.1582)	grad_norm 0.6245 (0.6245)	mem 39782MB
[2023-07-07 18:02:47 RepVGG-A0] (main.py 282): INFO Train: [278/300][10/78]	eta 0:03:41 lr 0.083569	time 1.1732 (3.2599)	loss 2.2737 (2.1968)	grad_norm 0.6288 (0.6279)	mem 39782MB
[2023-07-07 18:03:01 RepVGG-A0] (main.py 282): INFO Train: [278/300][20/78]	eta 0:02:18 lr 0.082597	time 1.2336 (2.3898)	loss 2.2183 (2.1989)	grad_norm 0.6294 (0.6258)	mem 39782MB
[2023-07-07 18:03:17 RepVGG-A0] (main.py 282): INFO Train: [278/300][30/78]	eta 0:01:42 lr 0.081630	time 1.4450 (2.1360)	loss 2.1979 (2.1970)	grad_norm 0.6267 (0.6270)	mem 39782MB
[2023-07-07 18:03:34 RepVGG-A0] (main.py 282): INFO Train: [278/300][40/78]	eta 0:01:16 lr 0.080668	time 3.7863 (2.0235)	loss 2.1992 (2.2000)	grad_norm 0.6280 (0.6274)	mem 39782MB
[2023-07-07 18:03:49 RepVGG-A0] (main.py 282): INFO Train: [278/300][50/78]	eta 0:00:53 lr 0.079713	time 1.1742 (1.9210)	loss 2.1761 (2.1992)	grad_norm 0.6328 (0.6273)	mem 39782MB
[2023-07-07 18:04:05 RepVGG-A0] (main.py 282): INFO Train: [278/300][60/78]	eta 0:00:33 lr 0.078762	time 1.2658 (1.8762)	loss 2.2287 (2.1976)	grad_norm 0.6323 (0.6273)	mem 39782MB
[2023-07-07 18:04:20 RepVGG-A0] (main.py 282): INFO Train: [278/300][70/78]	eta 0:00:14 lr 0.077818	time 1.2692 (1.8193)	loss 2.2064 (2.1974)	grad_norm 0.6310 (0.6271)	mem 39782MB
[2023-07-07 18:04:32 RepVGG-A0] (main.py 291): INFO EPOCH 278 training takes 0:02:21
[2023-07-07 18:04:54 RepVGG-A0] (main.py 282): INFO Train: [279/300][0/78]	eta 0:29:12 lr 0.077066	time 22.4649 (22.4649)	loss 2.1992 (2.1992)	grad_norm 0.6333 (0.6333)	mem 39782MB
[2023-07-07 18:05:08 RepVGG-A0] (main.py 282): INFO Train: [279/300][10/78]	eta 0:03:45 lr 0.076132	time 1.1814 (3.3177)	loss 2.2173 (2.1819)	grad_norm 0.6290 (0.6256)	mem 39782MB
[2023-07-07 18:05:22 RepVGG-A0] (main.py 282): INFO Train: [279/300][20/78]	eta 0:02:19 lr 0.075203	time 1.1713 (2.3996)	loss 2.2073 (2.1949)	grad_norm 0.6231 (0.6288)	mem 39782MB
[2023-07-07 18:05:38 RepVGG-A0] (main.py 282): INFO Train: [279/300][30/78]	eta 0:01:42 lr 0.074280	time 1.3663 (2.1288)	loss 2.2182 (2.2011)	grad_norm 0.6293 (0.6302)	mem 39782MB
[2023-07-07 18:05:55 RepVGG-A0] (main.py 282): INFO Train: [279/300][40/78]	eta 0:01:17 lr 0.073363	time 3.3046 (2.0402)	loss 2.2208 (2.2003)	grad_norm 0.6336 (0.6288)	mem 39782MB
[2023-07-07 18:06:11 RepVGG-A0] (main.py 282): INFO Train: [279/300][50/78]	eta 0:00:54 lr 0.072451	time 1.1724 (1.9355)	loss 2.2142 (2.2039)	grad_norm 0.6366 (0.6295)	mem 39782MB
[2023-07-07 18:06:26 RepVGG-A0] (main.py 282): INFO Train: [279/300][60/78]	eta 0:00:33 lr 0.071545	time 1.1804 (1.8636)	loss 2.1599 (2.2030)	grad_norm 0.6231 (0.6301)	mem 39782MB
[2023-07-07 18:06:40 RepVGG-A0] (main.py 282): INFO Train: [279/300][70/78]	eta 0:00:14 lr 0.070644	time 1.1388 (1.8119)	loss 2.2167 (2.2049)	grad_norm 0.6338 (0.6305)	mem 39782MB
[2023-07-07 18:06:52 RepVGG-A0] (main.py 291): INFO EPOCH 279 training takes 0:02:20
[2023-07-07 18:07:14 RepVGG-A0] (main.py 282): INFO Train: [280/300][0/78]	eta 0:28:31 lr 0.069928	time 21.9372 (21.9372)	loss 2.2121 (2.2121)	grad_norm 0.6307 (0.6307)	mem 39782MB
[2023-07-07 18:07:29 RepVGG-A0] (main.py 282): INFO Train: [280/300][10/78]	eta 0:03:46 lr 0.069037	time 1.1906 (3.3297)	loss 2.1771 (2.1999)	grad_norm 0.6386 (0.6312)	mem 39782MB
[2023-07-07 18:07:44 RepVGG-A0] (main.py 282): INFO Train: [280/300][20/78]	eta 0:02:22 lr 0.068153	time 1.3225 (2.4506)	loss 2.2400 (2.1980)	grad_norm 0.6311 (0.6313)	mem 39782MB
[2023-07-07 18:07:58 RepVGG-A0] (main.py 282): INFO Train: [280/300][30/78]	eta 0:01:41 lr 0.067273	time 1.1894 (2.1205)	loss 2.1912 (2.1979)	grad_norm 0.6304 (0.6313)	mem 39782MB
[2023-07-07 18:08:17 RepVGG-A0] (main.py 282): INFO Train: [280/300][40/78]	eta 0:01:19 lr 0.066400	time 5.1074 (2.0807)	loss 2.1973 (2.1967)	grad_norm 0.6321 (0.6312)	mem 39782MB
[2023-07-07 18:08:32 RepVGG-A0] (main.py 282): INFO Train: [280/300][50/78]	eta 0:00:54 lr 0.065532	time 1.1910 (1.9616)	loss 2.1945 (2.1921)	grad_norm 0.6427 (0.6314)	mem 39782MB
[2023-07-07 18:08:47 RepVGG-A0] (main.py 282): INFO Train: [280/300][60/78]	eta 0:00:33 lr 0.064670	time 1.1745 (1.8868)	loss 2.2111 (2.1941)	grad_norm 0.6401 (0.6316)	mem 39782MB
[2023-07-07 18:09:03 RepVGG-A0] (main.py 282): INFO Train: [280/300][70/78]	eta 0:00:14 lr 0.063813	time 1.1801 (1.8364)	loss 2.2360 (2.1961)	grad_norm 0.6405 (0.6322)	mem 39782MB
[2023-07-07 18:09:14 RepVGG-A0] (main.py 291): INFO EPOCH 280 training takes 0:02:22
[2023-07-07 18:09:32 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.571 (17.571)	Loss 1.3635 (1.3635)	Acc@1 69.037 (69.037)	Acc@5 88.812 (88.812)	Mem 39782MB
[2023-07-07 18:09:33 RepVGG-A0] (main.py 342): INFO  * Acc@1 69.638 Acc@5 88.854
[2023-07-07 18:09:33 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 280: 69.638%
[2023-07-07 18:09:33 RepVGG-A0] (main.py 172): INFO Max accuracy: 69.64%
[2023-07-07 18:09:52 RepVGG-A0] (main.py 282): INFO Train: [281/300][0/78]	eta 0:24:45 lr 0.063132	time 19.0489 (19.0489)	loss 2.1741 (2.1741)	grad_norm 0.6216 (0.6216)	mem 39782MB
[2023-07-07 18:10:08 RepVGG-A0] (main.py 282): INFO Train: [281/300][10/78]	eta 0:03:37 lr 0.062286	time 1.1718 (3.1941)	loss 2.1681 (2.1806)	grad_norm 0.6274 (0.6287)	mem 39782MB
[2023-07-07 18:10:24 RepVGG-A0] (main.py 282): INFO Train: [281/300][20/78]	eta 0:02:20 lr 0.061445	time 1.1918 (2.4257)	loss 2.1565 (2.1779)	grad_norm 0.6191 (0.6288)	mem 39782MB
[2023-07-07 18:10:39 RepVGG-A0] (main.py 282): INFO Train: [281/300][30/78]	eta 0:01:42 lr 0.060610	time 1.3017 (2.1328)	loss 2.1375 (2.1826)	grad_norm 0.6321 (0.6304)	mem 39782MB
[2023-07-07 18:10:58 RepVGG-A0] (main.py 282): INFO Train: [281/300][40/78]	eta 0:01:18 lr 0.059781	time 2.9727 (2.0591)	loss 2.2025 (2.1827)	grad_norm 0.6289 (0.6306)	mem 39782MB
[2023-07-07 18:11:12 RepVGG-A0] (main.py 282): INFO Train: [281/300][50/78]	eta 0:00:54 lr 0.058957	time 1.1715 (1.9392)	loss 2.1730 (2.1840)	grad_norm 0.6314 (0.6313)	mem 39782MB
[2023-07-07 18:11:28 RepVGG-A0] (main.py 282): INFO Train: [281/300][60/78]	eta 0:00:33 lr 0.058139	time 1.1782 (1.8751)	loss 2.2202 (2.1871)	grad_norm 0.6353 (0.6314)	mem 39782MB
[2023-07-07 18:11:43 RepVGG-A0] (main.py 282): INFO Train: [281/300][70/78]	eta 0:00:14 lr 0.057327	time 1.1896 (1.8305)	loss 2.2035 (2.1890)	grad_norm 0.6258 (0.6322)	mem 39782MB
[2023-07-07 18:11:54 RepVGG-A0] (main.py 291): INFO EPOCH 281 training takes 0:02:21
[2023-07-07 18:12:15 RepVGG-A0] (main.py 282): INFO Train: [282/300][0/78]	eta 0:27:32 lr 0.056681	time 21.1839 (21.1839)	loss 2.1466 (2.1466)	grad_norm 0.6240 (0.6240)	mem 39782MB
[2023-07-07 18:12:32 RepVGG-A0] (main.py 282): INFO Train: [282/300][10/78]	eta 0:03:51 lr 0.055879	time 1.1713 (3.4041)	loss 2.1687 (2.1651)	grad_norm 0.6307 (0.6304)	mem 39782MB
[2023-07-07 18:12:47 RepVGG-A0] (main.py 282): INFO Train: [282/300][20/78]	eta 0:02:24 lr 0.055082	time 1.4699 (2.4903)	loss 2.1942 (2.1726)	grad_norm 0.6330 (0.6300)	mem 39782MB
[2023-07-07 18:13:02 RepVGG-A0] (main.py 282): INFO Train: [282/300][30/78]	eta 0:01:44 lr 0.054291	time 1.4158 (2.1753)	loss 2.1815 (2.1778)	grad_norm 0.6427 (0.6300)	mem 39782MB
[2023-07-07 18:13:20 RepVGG-A0] (main.py 282): INFO Train: [282/300][40/78]	eta 0:01:19 lr 0.053506	time 4.2251 (2.0933)	loss 2.2005 (2.1816)	grad_norm 0.6304 (0.6312)	mem 39782MB
[2023-07-07 18:13:34 RepVGG-A0] (main.py 282): INFO Train: [282/300][50/78]	eta 0:00:54 lr 0.052727	time 1.1734 (1.9643)	loss 2.1793 (2.1825)	grad_norm 0.6291 (0.6317)	mem 39782MB
[2023-07-07 18:13:50 RepVGG-A0] (main.py 282): INFO Train: [282/300][60/78]	eta 0:00:34 lr 0.051953	time 1.1857 (1.8944)	loss 2.1843 (2.1846)	grad_norm 0.6489 (0.6326)	mem 39782MB
[2023-07-07 18:14:05 RepVGG-A0] (main.py 282): INFO Train: [282/300][70/78]	eta 0:00:14 lr 0.051185	time 1.3548 (1.8415)	loss 2.1754 (2.1865)	grad_norm 0.6391 (0.6338)	mem 39782MB
[2023-07-07 18:14:16 RepVGG-A0] (main.py 291): INFO EPOCH 282 training takes 0:02:21
[2023-07-07 18:14:35 RepVGG-A0] (main.py 282): INFO Train: [283/300][0/78]	eta 0:24:13 lr 0.050574	time 18.6367 (18.6367)	loss 2.2100 (2.2100)	grad_norm 0.6352 (0.6352)	mem 39782MB
[2023-07-07 18:14:52 RepVGG-A0] (main.py 282): INFO Train: [283/300][10/78]	eta 0:03:43 lr 0.049816	time 1.1723 (3.2837)	loss 2.1616 (2.1813)	grad_norm 0.6357 (0.6315)	mem 39782MB
[2023-07-07 18:15:07 RepVGG-A0] (main.py 282): INFO Train: [283/300][20/78]	eta 0:02:20 lr 0.049064	time 1.1754 (2.4175)	loss 2.1652 (2.1817)	grad_norm 0.6375 (0.6325)	mem 39782MB
[2023-07-07 18:15:22 RepVGG-A0] (main.py 282): INFO Train: [283/300][30/78]	eta 0:01:41 lr 0.048317	time 1.3309 (2.1080)	loss 2.1682 (2.1833)	grad_norm 0.6477 (0.6340)	mem 39782MB
[2023-07-07 18:15:40 RepVGG-A0] (main.py 282): INFO Train: [283/300][40/78]	eta 0:01:17 lr 0.047576	time 4.7310 (2.0454)	loss 2.1481 (2.1847)	grad_norm 0.6324 (0.6340)	mem 39782MB
[2023-07-07 18:15:54 RepVGG-A0] (main.py 282): INFO Train: [283/300][50/78]	eta 0:00:53 lr 0.046841	time 1.1743 (1.9249)	loss 2.1219 (2.1862)	grad_norm 0.6307 (0.6344)	mem 39782MB
[2023-07-07 18:16:09 RepVGG-A0] (main.py 282): INFO Train: [283/300][60/78]	eta 0:00:33 lr 0.046112	time 1.1720 (1.8549)	loss 2.1910 (2.1883)	grad_norm 0.6432 (0.6346)	mem 39782MB
[2023-07-07 18:16:25 RepVGG-A0] (main.py 282): INFO Train: [283/300][70/78]	eta 0:00:14 lr 0.045388	time 1.3329 (1.8163)	loss 2.1997 (2.1879)	grad_norm 0.6443 (0.6353)	mem 39782MB
[2023-07-07 18:16:37 RepVGG-A0] (main.py 291): INFO EPOCH 283 training takes 0:02:20
[2023-07-07 18:16:59 RepVGG-A0] (main.py 282): INFO Train: [284/300][0/78]	eta 0:28:39 lr 0.044813	time 22.0453 (22.0453)	loss 2.1695 (2.1695)	grad_norm 0.6296 (0.6296)	mem 39782MB
[2023-07-07 18:17:13 RepVGG-A0] (main.py 282): INFO Train: [284/300][10/78]	eta 0:03:43 lr 0.044099	time 1.1923 (3.2872)	loss 2.1518 (2.1665)	grad_norm 0.6321 (0.6322)	mem 39782MB
[2023-07-07 18:17:28 RepVGG-A0] (main.py 282): INFO Train: [284/300][20/78]	eta 0:02:20 lr 0.043391	time 1.1785 (2.4301)	loss 2.2160 (2.1695)	grad_norm 0.6344 (0.6327)	mem 39782MB
[2023-07-07 18:17:42 RepVGG-A0] (main.py 282): INFO Train: [284/300][30/78]	eta 0:01:41 lr 0.042689	time 1.2107 (2.1150)	loss 2.1665 (2.1690)	grad_norm 0.6331 (0.6334)	mem 39782MB
[2023-07-07 18:18:01 RepVGG-A0] (main.py 282): INFO Train: [284/300][40/78]	eta 0:01:18 lr 0.041992	time 4.5397 (2.0543)	loss 2.1687 (2.1704)	grad_norm 0.6395 (0.6343)	mem 39782MB
[2023-07-07 18:18:16 RepVGG-A0] (main.py 282): INFO Train: [284/300][50/78]	eta 0:00:54 lr 0.041301	time 1.1734 (1.9590)	loss 2.1783 (2.1731)	grad_norm 0.6439 (0.6352)	mem 39782MB
[2023-07-07 18:18:31 RepVGG-A0] (main.py 282): INFO Train: [284/300][60/78]	eta 0:00:33 lr 0.040616	time 1.2875 (1.8712)	loss 2.2106 (2.1766)	grad_norm 0.6367 (0.6358)	mem 39782MB
[2023-07-07 18:18:45 RepVGG-A0] (main.py 282): INFO Train: [284/300][70/78]	eta 0:00:14 lr 0.039937	time 1.1615 (1.8101)	loss 2.1754 (2.1742)	grad_norm 0.6448 (0.6363)	mem 39782MB
[2023-07-07 18:18:57 RepVGG-A0] (main.py 291): INFO EPOCH 284 training takes 0:02:20
[2023-07-07 18:19:19 RepVGG-A0] (main.py 282): INFO Train: [285/300][0/78]	eta 0:28:21 lr 0.039397	time 21.8078 (21.8078)	loss 2.1149 (2.1149)	grad_norm 0.6319 (0.6319)	mem 39782MB
[2023-07-07 18:19:33 RepVGG-A0] (main.py 282): INFO Train: [285/300][10/78]	eta 0:03:41 lr 0.038728	time 1.1719 (3.2566)	loss 2.2282 (2.1633)	grad_norm 0.6371 (0.6377)	mem 39782MB
[2023-07-07 18:19:48 RepVGG-A0] (main.py 282): INFO Train: [285/300][20/78]	eta 0:02:20 lr 0.038065	time 1.1746 (2.4218)	loss 2.1916 (2.1675)	grad_norm 0.6384 (0.6370)	mem 39782MB
[2023-07-07 18:20:04 RepVGG-A0] (main.py 282): INFO Train: [285/300][30/78]	eta 0:01:42 lr 0.037407	time 1.5903 (2.1433)	loss 2.1394 (2.1650)	grad_norm 0.6332 (0.6374)	mem 39782MB
[2023-07-07 18:20:22 RepVGG-A0] (main.py 282): INFO Train: [285/300][40/78]	eta 0:01:18 lr 0.036755	time 2.9921 (2.0590)	loss 2.2201 (2.1685)	grad_norm 0.6368 (0.6371)	mem 39782MB
[2023-07-07 18:20:37 RepVGG-A0] (main.py 282): INFO Train: [285/300][50/78]	eta 0:00:54 lr 0.036108	time 1.2441 (1.9620)	loss 2.1733 (2.1658)	grad_norm 0.6503 (0.6375)	mem 39782MB
[2023-07-07 18:20:52 RepVGG-A0] (main.py 282): INFO Train: [285/300][60/78]	eta 0:00:33 lr 0.035467	time 1.3689 (1.8816)	loss 2.1974 (2.1667)	grad_norm 0.6346 (0.6379)	mem 39782MB
[2023-07-07 18:21:07 RepVGG-A0] (main.py 282): INFO Train: [285/300][70/78]	eta 0:00:14 lr 0.034832	time 1.1538 (1.8331)	loss 2.1523 (2.1664)	grad_norm 0.6494 (0.6384)	mem 39782MB
[2023-07-07 18:21:19 RepVGG-A0] (main.py 291): INFO EPOCH 285 training takes 0:02:21
[2023-07-07 18:21:40 RepVGG-A0] (main.py 282): INFO Train: [286/300][0/78]	eta 0:28:08 lr 0.034329	time 21.6423 (21.6423)	loss 2.1530 (2.1530)	grad_norm 0.6346 (0.6346)	mem 39782MB
[2023-07-07 18:21:55 RepVGG-A0] (main.py 282): INFO Train: [286/300][10/78]	eta 0:03:46 lr 0.033704	time 1.1718 (3.3237)	loss 2.1179 (2.1704)	grad_norm 0.6388 (0.6375)	mem 39782MB
[2023-07-07 18:22:11 RepVGG-A0] (main.py 282): INFO Train: [286/300][20/78]	eta 0:02:24 lr 0.033085	time 1.3893 (2.4839)	loss 2.1689 (2.1594)	grad_norm 0.6456 (0.6377)	mem 39782MB
[2023-07-07 18:22:26 RepVGG-A0] (main.py 282): INFO Train: [286/300][30/78]	eta 0:01:44 lr 0.032471	time 1.2344 (2.1802)	loss 2.1154 (2.1606)	grad_norm 0.6315 (0.6382)	mem 39782MB
[2023-07-07 18:22:43 RepVGG-A0] (main.py 282): INFO Train: [286/300][40/78]	eta 0:01:18 lr 0.031864	time 2.8598 (2.0642)	loss 2.1936 (2.1679)	grad_norm 0.6351 (0.6383)	mem 39782MB
[2023-07-07 18:22:58 RepVGG-A0] (main.py 282): INFO Train: [286/300][50/78]	eta 0:00:54 lr 0.031262	time 1.1728 (1.9544)	loss 2.1635 (2.1704)	grad_norm 0.6456 (0.6389)	mem 39782MB
[2023-07-07 18:23:14 RepVGG-A0] (main.py 282): INFO Train: [286/300][60/78]	eta 0:00:33 lr 0.030666	time 1.1787 (1.8854)	loss 2.1948 (2.1684)	grad_norm 0.6461 (0.6393)	mem 39782MB
[2023-07-07 18:23:29 RepVGG-A0] (main.py 282): INFO Train: [286/300][70/78]	eta 0:00:14 lr 0.030075	time 1.3049 (1.8372)	loss 2.1533 (2.1670)	grad_norm 0.6385 (0.6391)	mem 39782MB
[2023-07-07 18:23:41 RepVGG-A0] (main.py 291): INFO EPOCH 286 training takes 0:02:22
[2023-07-07 18:24:02 RepVGG-A0] (main.py 282): INFO Train: [287/300][0/78]	eta 0:27:24 lr 0.029607	time 21.0865 (21.0865)	loss 2.1417 (2.1417)	grad_norm 0.6271 (0.6271)	mem 39782MB
[2023-07-07 18:24:16 RepVGG-A0] (main.py 282): INFO Train: [287/300][10/78]	eta 0:03:35 lr 0.029027	time 1.1731 (3.1663)	loss 2.1655 (2.1547)	grad_norm 0.6414 (0.6348)	mem 39782MB
[2023-07-07 18:24:30 RepVGG-A0] (main.py 282): INFO Train: [287/300][20/78]	eta 0:02:16 lr 0.028452	time 1.1737 (2.3525)	loss 2.1949 (2.1686)	grad_norm 0.6405 (0.6372)	mem 39782MB
[2023-07-07 18:24:47 RepVGG-A0] (main.py 282): INFO Train: [287/300][30/78]	eta 0:01:42 lr 0.027883	time 1.4972 (2.1377)	loss 2.1137 (2.1694)	grad_norm 0.6416 (0.6386)	mem 39782MB
[2023-07-07 18:25:04 RepVGG-A0] (main.py 282): INFO Train: [287/300][40/78]	eta 0:01:17 lr 0.027320	time 4.3923 (2.0282)	loss 2.1546 (2.1654)	grad_norm 0.6366 (0.6384)	mem 39782MB
[2023-07-07 18:25:19 RepVGG-A0] (main.py 282): INFO Train: [287/300][50/78]	eta 0:00:53 lr 0.026763	time 1.1725 (1.9235)	loss 2.1822 (2.1630)	grad_norm 0.6437 (0.6379)	mem 39782MB
[2023-07-07 18:25:34 RepVGG-A0] (main.py 282): INFO Train: [287/300][60/78]	eta 0:00:33 lr 0.026211	time 1.1783 (1.8543)	loss 2.1755 (2.1643)	grad_norm 0.6364 (0.6377)	mem 39782MB
[2023-07-07 18:25:50 RepVGG-A0] (main.py 282): INFO Train: [287/300][70/78]	eta 0:00:14 lr 0.025666	time 1.5939 (1.8145)	loss 2.1710 (2.1654)	grad_norm 0.6396 (0.6378)	mem 39782MB
[2023-07-07 18:26:02 RepVGG-A0] (main.py 291): INFO EPOCH 287 training takes 0:02:20
[2023-07-07 18:26:23 RepVGG-A0] (main.py 282): INFO Train: [288/300][0/78]	eta 0:28:06 lr 0.025233	time 21.6237 (21.6237)	loss 2.1469 (2.1469)	grad_norm 0.6299 (0.6299)	mem 39782MB
[2023-07-07 18:26:39 RepVGG-A0] (main.py 282): INFO Train: [288/300][10/78]	eta 0:03:49 lr 0.024697	time 1.1885 (3.3701)	loss 2.1275 (2.1568)	grad_norm 0.6283 (0.6344)	mem 39782MB
[2023-07-07 18:26:53 RepVGG-A0] (main.py 282): INFO Train: [288/300][20/78]	eta 0:02:22 lr 0.024167	time 1.3222 (2.4589)	loss 2.1367 (2.1498)	grad_norm 0.6313 (0.6354)	mem 39782MB
[2023-07-07 18:27:09 RepVGG-A0] (main.py 282): INFO Train: [288/300][30/78]	eta 0:01:43 lr 0.023643	time 1.1397 (2.1535)	loss 2.2038 (2.1591)	grad_norm 0.6364 (0.6366)	mem 39782MB
[2023-07-07 18:27:26 RepVGG-A0] (main.py 282): INFO Train: [288/300][40/78]	eta 0:01:18 lr 0.023125	time 3.7321 (2.0570)	loss 2.1836 (2.1592)	grad_norm 0.6396 (0.6369)	mem 39782MB
[2023-07-07 18:27:41 RepVGG-A0] (main.py 282): INFO Train: [288/300][50/78]	eta 0:00:54 lr 0.022612	time 1.1743 (1.9555)	loss 2.2060 (2.1617)	grad_norm 0.6432 (0.6380)	mem 39782MB
[2023-07-07 18:27:57 RepVGG-A0] (main.py 282): INFO Train: [288/300][60/78]	eta 0:00:33 lr 0.022105	time 1.2884 (1.8885)	loss 2.1839 (2.1605)	grad_norm 0.6505 (0.6383)	mem 39782MB
[2023-07-07 18:28:13 RepVGG-A0] (main.py 282): INFO Train: [288/300][70/78]	eta 0:00:14 lr 0.021604	time 1.3868 (1.8463)	loss 2.1398 (2.1606)	grad_norm 0.6443 (0.6382)	mem 39782MB
[2023-07-07 18:28:23 RepVGG-A0] (main.py 291): INFO EPOCH 288 training takes 0:02:21
[2023-07-07 18:28:45 RepVGG-A0] (main.py 282): INFO Train: [289/300][0/78]	eta 0:28:20 lr 0.021207	time 21.8048 (21.8048)	loss 2.1024 (2.1024)	grad_norm 0.6301 (0.6301)	mem 39782MB
[2023-07-07 18:28:59 RepVGG-A0] (main.py 282): INFO Train: [289/300][10/78]	eta 0:03:43 lr 0.020716	time 1.1727 (3.2805)	loss 2.1660 (2.1550)	grad_norm 0.6348 (0.6334)	mem 39782MB
[2023-07-07 18:29:14 RepVGG-A0] (main.py 282): INFO Train: [289/300][20/78]	eta 0:02:18 lr 0.020231	time 1.1712 (2.3926)	loss 2.1004 (2.1538)	grad_norm 0.6334 (0.6342)	mem 39782MB
[2023-07-07 18:29:29 RepVGG-A0] (main.py 282): INFO Train: [289/300][30/78]	eta 0:01:41 lr 0.019752	time 1.4575 (2.1184)	loss 2.1435 (2.1544)	grad_norm 0.6473 (0.6355)	mem 39782MB
[2023-07-07 18:29:47 RepVGG-A0] (main.py 282): INFO Train: [289/300][40/78]	eta 0:01:17 lr 0.019278	time 3.1459 (2.0310)	loss 2.1640 (2.1555)	grad_norm 0.6360 (0.6361)	mem 39782MB
[2023-07-07 18:30:02 RepVGG-A0] (main.py 282): INFO Train: [289/300][50/78]	eta 0:00:54 lr 0.018810	time 1.1727 (1.9327)	loss 2.1141 (2.1559)	grad_norm 0.6379 (0.6367)	mem 39782MB
[2023-07-07 18:30:17 RepVGG-A0] (main.py 282): INFO Train: [289/300][60/78]	eta 0:00:33 lr 0.018348	time 1.1470 (1.8638)	loss 2.1991 (2.1588)	grad_norm 0.6434 (0.6373)	mem 39782MB
[2023-07-07 18:30:32 RepVGG-A0] (main.py 282): INFO Train: [289/300][70/78]	eta 0:00:14 lr 0.017891	time 1.3112 (1.8106)	loss 2.1604 (2.1594)	grad_norm 0.6380 (0.6376)	mem 39782MB
[2023-07-07 18:30:44 RepVGG-A0] (main.py 291): INFO EPOCH 289 training takes 0:02:20
[2023-07-07 18:31:05 RepVGG-A0] (main.py 282): INFO Train: [290/300][0/78]	eta 0:27:58 lr 0.017530	time 21.5142 (21.5142)	loss 2.1605 (2.1605)	grad_norm 0.6331 (0.6331)	mem 39782MB
[2023-07-07 18:31:20 RepVGG-A0] (main.py 282): INFO Train: [290/300][10/78]	eta 0:03:45 lr 0.017084	time 1.1710 (3.3234)	loss 2.1734 (2.1385)	grad_norm 0.6345 (0.6371)	mem 39782MB
[2023-07-07 18:31:36 RepVGG-A0] (main.py 282): INFO Train: [290/300][20/78]	eta 0:02:23 lr 0.016643	time 1.1731 (2.4766)	loss 2.1367 (2.1448)	grad_norm 0.6403 (0.6375)	mem 39782MB
[2023-07-07 18:31:51 RepVGG-A0] (main.py 282): INFO Train: [290/300][30/78]	eta 0:01:43 lr 0.016209	time 1.3464 (2.1599)	loss 2.1720 (2.1446)	grad_norm 0.6392 (0.6381)	mem 39782MB
[2023-07-07 18:32:09 RepVGG-A0] (main.py 282): INFO Train: [290/300][40/78]	eta 0:01:19 lr 0.015780	time 4.0306 (2.0829)	loss 2.1638 (2.1463)	grad_norm 0.6362 (0.6382)	mem 39782MB
[2023-07-07 18:32:24 RepVGG-A0] (main.py 282): INFO Train: [290/300][50/78]	eta 0:00:55 lr 0.015356	time 1.1878 (1.9676)	loss 2.1262 (2.1439)	grad_norm 0.6442 (0.6385)	mem 39782MB
[2023-07-07 18:32:39 RepVGG-A0] (main.py 282): INFO Train: [290/300][60/78]	eta 0:00:33 lr 0.014939	time 1.3576 (1.8880)	loss 2.1880 (2.1475)	grad_norm 0.6374 (0.6388)	mem 39782MB
[2023-07-07 18:32:54 RepVGG-A0] (main.py 282): INFO Train: [290/300][70/78]	eta 0:00:14 lr 0.014527	time 1.1472 (1.8367)	loss 2.1936 (2.1487)	grad_norm 0.6340 (0.6390)	mem 39782MB
[2023-07-07 18:33:06 RepVGG-A0] (main.py 291): INFO EPOCH 290 training takes 0:02:21
[2023-07-07 18:33:23 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.696 (17.696)	Loss 1.3477 (1.3477)	Acc@1 70.551 (70.551)	Acc@5 89.075 (89.075)	Mem 39782MB
[2023-07-07 18:33:24 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.714 Acc@5 89.520
[2023-07-07 18:33:24 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 290: 70.714%
[2023-07-07 18:33:24 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:33:46 RepVGG-A0] (main.py 282): INFO Train: [291/300][0/78]	eta 0:27:55 lr 0.014202	time 21.4828 (21.4828)	loss 2.1632 (2.1632)	grad_norm 0.6434 (0.6434)	mem 39782MB
[2023-07-07 18:34:01 RepVGG-A0] (main.py 282): INFO Train: [291/300][10/78]	eta 0:03:48 lr 0.013800	time 1.1924 (3.3622)	loss 2.1522 (2.1365)	grad_norm 0.6438 (0.6372)	mem 39782MB
[2023-07-07 18:34:15 RepVGG-A0] (main.py 282): INFO Train: [291/300][20/78]	eta 0:02:20 lr 0.013405	time 1.1731 (2.4184)	loss 2.1429 (2.1369)	grad_norm 0.6340 (0.6360)	mem 39782MB
[2023-07-07 18:34:30 RepVGG-A0] (main.py 282): INFO Train: [291/300][30/78]	eta 0:01:41 lr 0.013015	time 1.3672 (2.1072)	loss 2.1846 (2.1429)	grad_norm 0.6422 (0.6367)	mem 39782MB
[2023-07-07 18:34:48 RepVGG-A0] (main.py 282): INFO Train: [291/300][40/78]	eta 0:01:17 lr 0.012630	time 3.3686 (2.0320)	loss 2.1280 (2.1400)	grad_norm 0.6372 (0.6366)	mem 39782MB
[2023-07-07 18:35:03 RepVGG-A0] (main.py 282): INFO Train: [291/300][50/78]	eta 0:00:53 lr 0.012252	time 1.1464 (1.9228)	loss 2.1821 (2.1403)	grad_norm 0.6398 (0.6368)	mem 39782MB
[2023-07-07 18:35:17 RepVGG-A0] (main.py 282): INFO Train: [291/300][60/78]	eta 0:00:33 lr 0.011879	time 1.1750 (1.8417)	loss 2.1368 (2.1457)	grad_norm 0.6288 (0.6369)	mem 39782MB
[2023-07-07 18:35:31 RepVGG-A0] (main.py 282): INFO Train: [291/300][70/78]	eta 0:00:14 lr 0.011512	time 1.1926 (1.7883)	loss 2.1672 (2.1466)	grad_norm 0.6503 (0.6372)	mem 39782MB
[2023-07-07 18:35:44 RepVGG-A0] (main.py 291): INFO EPOCH 291 training takes 0:02:19
[2023-07-07 18:36:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.269 (17.269)	Loss 1.3313 (1.3313)	Acc@1 70.636 (70.636)	Acc@5 89.459 (89.459)	Mem 39782MB
[2023-07-07 18:36:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.680 Acc@5 89.592
[2023-07-07 18:36:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 291: 70.680%
[2023-07-07 18:36:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:36:25 RepVGG-A0] (main.py 282): INFO Train: [292/300][0/78]	eta 0:28:56 lr 0.011223	time 22.2681 (22.2681)	loss 2.1622 (2.1622)	grad_norm 0.6248 (0.6248)	mem 39782MB
[2023-07-07 18:36:39 RepVGG-A0] (main.py 282): INFO Train: [292/300][10/78]	eta 0:03:47 lr 0.010866	time 1.1994 (3.3410)	loss 2.1769 (2.1452)	grad_norm 0.6354 (0.6333)	mem 39782MB
[2023-07-07 18:36:52 RepVGG-A0] (main.py 282): INFO Train: [292/300][20/78]	eta 0:02:17 lr 0.010515	time 1.1722 (2.3657)	loss 2.1004 (2.1483)	grad_norm 0.6346 (0.6351)	mem 39782MB
[2023-07-07 18:37:09 RepVGG-A0] (main.py 282): INFO Train: [292/300][30/78]	eta 0:01:43 lr 0.010170	time 1.4055 (2.1485)	loss 2.1868 (2.1507)	grad_norm 0.6324 (0.6356)	mem 39782MB
[2023-07-07 18:37:24 RepVGG-A0] (main.py 282): INFO Train: [292/300][40/78]	eta 0:01:15 lr 0.009831	time 1.3283 (1.9920)	loss 2.1673 (2.1472)	grad_norm 0.6360 (0.6356)	mem 39782MB
[2023-07-07 18:37:42 RepVGG-A0] (main.py 282): INFO Train: [292/300][50/78]	eta 0:00:54 lr 0.009497	time 1.1746 (1.9498)	loss 2.1769 (2.1477)	grad_norm 0.6320 (0.6359)	mem 39782MB
[2023-07-07 18:37:57 RepVGG-A0] (main.py 282): INFO Train: [292/300][60/78]	eta 0:00:33 lr 0.009169	time 1.3285 (1.8783)	loss 2.2117 (2.1489)	grad_norm 0.6324 (0.6360)	mem 39782MB
[2023-07-07 18:38:12 RepVGG-A0] (main.py 282): INFO Train: [292/300][70/78]	eta 0:00:14 lr 0.008847	time 1.1395 (1.8271)	loss 2.1166 (2.1500)	grad_norm 0.6374 (0.6361)	mem 39782MB
[2023-07-07 18:38:24 RepVGG-A0] (main.py 291): INFO EPOCH 292 training takes 0:02:21
[2023-07-07 18:38:41 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.240 (17.240)	Loss 1.3228 (1.3228)	Acc@1 70.398 (70.398)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:38:42 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.696 Acc@5 89.542
[2023-07-07 18:38:42 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 292: 70.696%
[2023-07-07 18:38:42 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:39:04 RepVGG-A0] (main.py 282): INFO Train: [293/300][0/78]	eta 0:28:25 lr 0.008594	time 21.8671 (21.8671)	loss 2.1485 (2.1485)	grad_norm 0.6353 (0.6353)	mem 39782MB
[2023-07-07 18:39:19 RepVGG-A0] (main.py 282): INFO Train: [293/300][10/78]	eta 0:03:46 lr 0.008282	time 1.1723 (3.3352)	loss 2.1655 (2.1477)	grad_norm 0.6343 (0.6344)	mem 39782MB
[2023-07-07 18:39:34 RepVGG-A0] (main.py 282): INFO Train: [293/300][20/78]	eta 0:02:22 lr 0.007976	time 1.2616 (2.4591)	loss 2.1109 (2.1441)	grad_norm 0.6426 (0.6347)	mem 39782MB
[2023-07-07 18:39:48 RepVGG-A0] (main.py 282): INFO Train: [293/300][30/78]	eta 0:01:42 lr 0.007676	time 1.5598 (2.1355)	loss 2.1201 (2.1399)	grad_norm 0.6335 (0.6353)	mem 39782MB
[2023-07-07 18:40:06 RepVGG-A0] (main.py 282): INFO Train: [293/300][40/78]	eta 0:01:17 lr 0.007381	time 3.0999 (2.0448)	loss 2.0969 (2.1444)	grad_norm 0.6293 (0.6353)	mem 39782MB
[2023-07-07 18:40:21 RepVGG-A0] (main.py 282): INFO Train: [293/300][50/78]	eta 0:00:54 lr 0.007092	time 1.1729 (1.9334)	loss 2.1089 (2.1418)	grad_norm 0.6350 (0.6354)	mem 39782MB
[2023-07-07 18:40:36 RepVGG-A0] (main.py 282): INFO Train: [293/300][60/78]	eta 0:00:33 lr 0.006809	time 1.1783 (1.8725)	loss 2.1363 (2.1408)	grad_norm 0.6328 (0.6346)	mem 39782MB
[2023-07-07 18:40:51 RepVGG-A0] (main.py 282): INFO Train: [293/300][70/78]	eta 0:00:14 lr 0.006532	time 1.4252 (1.8199)	loss 2.1074 (2.1434)	grad_norm 0.6330 (0.6345)	mem 39782MB
[2023-07-07 18:41:04 RepVGG-A0] (main.py 291): INFO EPOCH 293 training takes 0:02:21
[2023-07-07 18:41:21 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.193 (17.193)	Loss 1.3155 (1.3155)	Acc@1 70.862 (70.862)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:41:22 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.908 Acc@5 89.588
[2023-07-07 18:41:22 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 293: 70.908%
[2023-07-07 18:41:22 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:41:45 RepVGG-A0] (main.py 282): INFO Train: [294/300][0/78]	eta 0:29:27 lr 0.006314	time 22.6561 (22.6561)	loss 2.1890 (2.1890)	grad_norm 0.6317 (0.6317)	mem 39782MB
[2023-07-07 18:41:59 RepVGG-A0] (main.py 282): INFO Train: [294/300][10/78]	eta 0:03:49 lr 0.006048	time 1.1711 (3.3748)	loss 2.1482 (2.1329)	grad_norm 0.6324 (0.6331)	mem 39782MB
[2023-07-07 18:42:13 RepVGG-A0] (main.py 282): INFO Train: [294/300][20/78]	eta 0:02:21 lr 0.005786	time 1.1730 (2.4357)	loss 2.1438 (2.1371)	grad_norm 0.6389 (0.6340)	mem 39782MB
[2023-07-07 18:42:29 RepVGG-A0] (main.py 282): INFO Train: [294/300][30/78]	eta 0:01:42 lr 0.005531	time 1.1577 (2.1451)	loss 2.1399 (2.1379)	grad_norm 0.6441 (0.6348)	mem 39782MB
[2023-07-07 18:42:47 RepVGG-A0] (main.py 282): INFO Train: [294/300][40/78]	eta 0:01:18 lr 0.005281	time 3.7284 (2.0666)	loss 2.1837 (2.1412)	grad_norm 0.6303 (0.6342)	mem 39782MB
[2023-07-07 18:43:01 RepVGG-A0] (main.py 282): INFO Train: [294/300][50/78]	eta 0:00:54 lr 0.005038	time 1.1731 (1.9490)	loss 2.1107 (2.1377)	grad_norm 0.6358 (0.6345)	mem 39782MB
[2023-07-07 18:43:16 RepVGG-A0] (main.py 282): INFO Train: [294/300][60/78]	eta 0:00:33 lr 0.004800	time 1.3460 (1.8747)	loss 2.1101 (2.1379)	grad_norm 0.6295 (0.6341)	mem 39782MB
[2023-07-07 18:43:32 RepVGG-A0] (main.py 282): INFO Train: [294/300][70/78]	eta 0:00:14 lr 0.004567	time 1.2908 (1.8276)	loss 2.1032 (2.1366)	grad_norm 0.6185 (0.6338)	mem 39782MB
[2023-07-07 18:43:43 RepVGG-A0] (main.py 291): INFO EPOCH 294 training takes 0:02:20
[2023-07-07 18:44:00 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.453 (17.453)	Loss 1.3250 (1.3250)	Acc@1 70.532 (70.532)	Acc@5 89.752 (89.752)	Mem 39782MB
[2023-07-07 18:44:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.842 Acc@5 89.598
[2023-07-07 18:44:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 294: 70.842%
[2023-07-07 18:44:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:44:23 RepVGG-A0] (main.py 282): INFO Train: [295/300][0/78]	eta 0:27:31 lr 0.004385	time 21.1754 (21.1754)	loss 2.0757 (2.0757)	grad_norm 0.6282 (0.6282)	mem 39782MB
[2023-07-07 18:44:38 RepVGG-A0] (main.py 282): INFO Train: [295/300][10/78]	eta 0:03:42 lr 0.004164	time 1.1714 (3.2753)	loss 2.1295 (2.1313)	grad_norm 0.6271 (0.6331)	mem 39782MB
[2023-07-07 18:44:52 RepVGG-A0] (main.py 282): INFO Train: [295/300][20/78]	eta 0:02:18 lr 0.003947	time 1.1727 (2.3953)	loss 2.1989 (2.1285)	grad_norm 0.6318 (0.6325)	mem 39782MB
[2023-07-07 18:45:07 RepVGG-A0] (main.py 282): INFO Train: [295/300][30/78]	eta 0:01:41 lr 0.003737	time 1.5501 (2.1180)	loss 2.1503 (2.1357)	grad_norm 0.6297 (0.6330)	mem 39782MB
[2023-07-07 18:45:25 RepVGG-A0] (main.py 282): INFO Train: [295/300][40/78]	eta 0:01:17 lr 0.003532	time 3.1130 (2.0294)	loss 2.1262 (2.1346)	grad_norm 0.6445 (0.6335)	mem 39782MB
[2023-07-07 18:45:40 RepVGG-A0] (main.py 282): INFO Train: [295/300][50/78]	eta 0:00:54 lr 0.003333	time 1.1738 (1.9340)	loss 2.1382 (2.1363)	grad_norm 0.6327 (0.6334)	mem 39782MB
[2023-07-07 18:45:55 RepVGG-A0] (main.py 282): INFO Train: [295/300][60/78]	eta 0:00:33 lr 0.003140	time 1.2097 (1.8629)	loss 2.1496 (2.1342)	grad_norm 0.6386 (0.6334)	mem 39782MB
[2023-07-07 18:46:10 RepVGG-A0] (main.py 282): INFO Train: [295/300][70/78]	eta 0:00:14 lr 0.002953	time 1.3131 (1.8046)	loss 2.0980 (2.1351)	grad_norm 0.6326 (0.6333)	mem 39782MB
[2023-07-07 18:46:22 RepVGG-A0] (main.py 291): INFO EPOCH 295 training takes 0:02:20
[2023-07-07 18:46:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.362 (17.362)	Loss 1.3213 (1.3213)	Acc@1 70.807 (70.807)	Acc@5 89.526 (89.526)	Mem 39782MB
[2023-07-07 18:46:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.834 Acc@5 89.672
[2023-07-07 18:46:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 295: 70.834%
[2023-07-07 18:46:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:47:03 RepVGG-A0] (main.py 282): INFO Train: [296/300][0/78]	eta 0:29:08 lr 0.002807	time 22.4110 (22.4110)	loss 2.1159 (2.1159)	grad_norm 0.6409 (0.6409)	mem 39782MB
[2023-07-07 18:47:18 RepVGG-A0] (main.py 282): INFO Train: [296/300][10/78]	eta 0:03:48 lr 0.002630	time 1.1727 (3.3648)	loss 2.1552 (2.1226)	grad_norm 0.6360 (0.6313)	mem 39782MB
[2023-07-07 18:47:32 RepVGG-A0] (main.py 282): INFO Train: [296/300][20/78]	eta 0:02:21 lr 0.002459	time 1.1958 (2.4424)	loss 2.1462 (2.1320)	grad_norm 0.6263 (0.6316)	mem 39782MB
[2023-07-07 18:47:49 RepVGG-A0] (main.py 282): INFO Train: [296/300][30/78]	eta 0:01:45 lr 0.002293	time 2.0657 (2.1900)	loss 2.1398 (2.1326)	grad_norm 0.6213 (0.6309)	mem 39782MB
[2023-07-07 18:48:05 RepVGG-A0] (main.py 282): INFO Train: [296/300][40/78]	eta 0:01:17 lr 0.002133	time 3.7587 (2.0466)	loss 2.1213 (2.1324)	grad_norm 0.6220 (0.6305)	mem 39782MB
[2023-07-07 18:48:20 RepVGG-A0] (main.py 282): INFO Train: [296/300][50/78]	eta 0:00:54 lr 0.001979	time 1.1723 (1.9420)	loss 2.1788 (2.1348)	grad_norm 0.6307 (0.6305)	mem 39782MB
[2023-07-07 18:48:35 RepVGG-A0] (main.py 282): INFO Train: [296/300][60/78]	eta 0:00:33 lr 0.001831	time 1.1748 (1.8775)	loss 2.1522 (2.1356)	grad_norm 0.6358 (0.6309)	mem 39782MB
[2023-07-07 18:48:51 RepVGG-A0] (main.py 282): INFO Train: [296/300][70/78]	eta 0:00:14 lr 0.001689	time 1.4761 (1.8395)	loss 2.0827 (2.1345)	grad_norm 0.6276 (0.6312)	mem 39782MB
[2023-07-07 18:49:02 RepVGG-A0] (main.py 291): INFO EPOCH 296 training takes 0:02:21
[2023-07-07 18:49:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.553 (17.553)	Loss 1.3167 (1.3167)	Acc@1 70.837 (70.837)	Acc@5 89.807 (89.807)	Mem 39782MB
[2023-07-07 18:49:21 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.906 Acc@5 89.658
[2023-07-07 18:49:21 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 296: 70.906%
[2023-07-07 18:49:21 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:49:41 RepVGG-A0] (main.py 282): INFO Train: [297/300][0/78]	eta 0:27:01 lr 0.001579	time 20.7870 (20.7870)	loss 2.1424 (2.1424)	grad_norm 0.6238 (0.6238)	mem 39782MB
[2023-07-07 18:49:57 RepVGG-A0] (main.py 282): INFO Train: [297/300][10/78]	eta 0:03:42 lr 0.001447	time 1.1718 (3.2765)	loss 2.1205 (2.1515)	grad_norm 0.6274 (0.6294)	mem 39782MB
[2023-07-07 18:50:12 RepVGG-A0] (main.py 282): INFO Train: [297/300][20/78]	eta 0:02:21 lr 0.001321	time 1.1745 (2.4317)	loss 2.2041 (2.1500)	grad_norm 0.6337 (0.6296)	mem 39782MB
[2023-07-07 18:50:27 RepVGG-A0] (main.py 282): INFO Train: [297/300][30/78]	eta 0:01:43 lr 0.001200	time 1.5187 (2.1463)	loss 2.1824 (2.1484)	grad_norm 0.6343 (0.6302)	mem 39782MB
[2023-07-07 18:50:44 RepVGG-A0] (main.py 282): INFO Train: [297/300][40/78]	eta 0:01:17 lr 0.001085	time 3.4886 (2.0393)	loss 2.2002 (2.1458)	grad_norm 0.6336 (0.6305)	mem 39782MB
[2023-07-07 18:51:00 RepVGG-A0] (main.py 282): INFO Train: [297/300][50/78]	eta 0:00:54 lr 0.000976	time 1.1893 (1.9428)	loss 2.1429 (2.1445)	grad_norm 0.6287 (0.6300)	mem 39782MB
[2023-07-07 18:51:15 RepVGG-A0] (main.py 282): INFO Train: [297/300][60/78]	eta 0:00:33 lr 0.000873	time 1.3403 (1.8705)	loss 2.1188 (2.1425)	grad_norm 0.6384 (0.6298)	mem 39782MB
[2023-07-07 18:51:31 RepVGG-A0] (main.py 282): INFO Train: [297/300][70/78]	eta 0:00:14 lr 0.000776	time 1.2782 (1.8388)	loss 2.1608 (2.1409)	grad_norm 0.6278 (0.6301)	mem 39782MB
[2023-07-07 18:51:42 RepVGG-A0] (main.py 291): INFO EPOCH 297 training takes 0:02:21
[2023-07-07 18:51:59 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.057 (17.057)	Loss 1.3204 (1.3204)	Acc@1 70.703 (70.703)	Acc@5 89.709 (89.709)	Mem 39782MB
[2023-07-07 18:52:01 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.910 Acc@5 89.666
[2023-07-07 18:52:01 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 297: 70.910%
[2023-07-07 18:52:01 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:52:24 RepVGG-A0] (main.py 282): INFO Train: [298/300][0/78]	eta 0:29:17 lr 0.000702	time 22.5307 (22.5307)	loss 2.1403 (2.1403)	grad_norm 0.6243 (0.6243)	mem 39782MB
[2023-07-07 18:52:37 RepVGG-A0] (main.py 282): INFO Train: [298/300][10/78]	eta 0:03:44 lr 0.000615	time 1.1741 (3.2961)	loss 2.1119 (2.1436)	grad_norm 0.6289 (0.6289)	mem 39782MB
[2023-07-07 18:52:52 RepVGG-A0] (main.py 282): INFO Train: [298/300][20/78]	eta 0:02:20 lr 0.000533	time 1.1724 (2.4158)	loss 2.1136 (2.1352)	grad_norm 0.6324 (0.6287)	mem 39782MB
[2023-07-07 18:53:07 RepVGG-A0] (main.py 282): INFO Train: [298/300][30/78]	eta 0:01:42 lr 0.000458	time 1.4192 (2.1372)	loss 2.1117 (2.1369)	grad_norm 0.6304 (0.6298)	mem 39782MB
[2023-07-07 18:53:26 RepVGG-A0] (main.py 282): INFO Train: [298/300][40/78]	eta 0:01:18 lr 0.000388	time 3.9280 (2.0756)	loss 2.1836 (2.1408)	grad_norm 0.6381 (0.6295)	mem 39782MB
[2023-07-07 18:53:41 RepVGG-A0] (main.py 282): INFO Train: [298/300][50/78]	eta 0:00:55 lr 0.000324	time 1.1808 (1.9649)	loss 2.0997 (2.1385)	grad_norm 0.6352 (0.6292)	mem 39782MB
[2023-07-07 18:53:56 RepVGG-A0] (main.py 282): INFO Train: [298/300][60/78]	eta 0:00:33 lr 0.000266	time 1.2013 (1.8833)	loss 2.1079 (2.1406)	grad_norm 0.6251 (0.6291)	mem 39782MB
[2023-07-07 18:54:11 RepVGG-A0] (main.py 282): INFO Train: [298/300][70/78]	eta 0:00:14 lr 0.000213	time 1.3956 (1.8315)	loss 2.0812 (2.1399)	grad_norm 0.6323 (0.6295)	mem 39782MB
[2023-07-07 18:54:23 RepVGG-A0] (main.py 291): INFO EPOCH 298 training takes 0:02:21
[2023-07-07 18:54:40 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.180 (17.180)	Loss 1.3234 (1.3234)	Acc@1 70.844 (70.844)	Acc@5 89.368 (89.368)	Mem 39782MB
[2023-07-07 18:54:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.926 Acc@5 89.596
[2023-07-07 18:54:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 298: 70.926%
[2023-07-07 18:54:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:55:02 RepVGG-A0] (main.py 282): INFO Train: [299/300][0/78]	eta 0:26:58 lr 0.000175	time 20.7539 (20.7539)	loss 2.1274 (2.1274)	grad_norm 0.6278 (0.6278)	mem 39782MB
[2023-07-07 18:55:18 RepVGG-A0] (main.py 282): INFO Train: [299/300][10/78]	eta 0:03:45 lr 0.000133	time 1.1722 (3.3209)	loss 2.1191 (2.1459)	grad_norm 0.6257 (0.6300)	mem 39782MB
[2023-07-07 18:55:33 RepVGG-A0] (main.py 282): INFO Train: [299/300][20/78]	eta 0:02:21 lr 0.000097	time 1.1961 (2.4478)	loss 2.1836 (2.1471)	grad_norm 0.6276 (0.6300)	mem 39782MB
[2023-07-07 18:55:48 RepVGG-A0] (main.py 282): INFO Train: [299/300][30/78]	eta 0:01:43 lr 0.000066	time 1.3312 (2.1541)	loss 2.1407 (2.1454)	grad_norm 0.6263 (0.6297)	mem 39782MB
[2023-07-07 18:56:06 RepVGG-A0] (main.py 282): INFO Train: [299/300][40/78]	eta 0:01:18 lr 0.000042	time 2.7963 (2.0580)	loss 2.1222 (2.1424)	grad_norm 0.6283 (0.6291)	mem 39782MB
[2023-07-07 18:56:21 RepVGG-A0] (main.py 282): INFO Train: [299/300][50/78]	eta 0:00:54 lr 0.000023	time 1.1727 (1.9429)	loss 2.1552 (2.1382)	grad_norm 0.6304 (0.6295)	mem 39782MB
[2023-07-07 18:56:35 RepVGG-A0] (main.py 282): INFO Train: [299/300][60/78]	eta 0:00:33 lr 0.000009	time 1.1724 (1.8615)	loss 2.1539 (2.1384)	grad_norm 0.6289 (0.6294)	mem 39782MB
[2023-07-07 18:56:50 RepVGG-A0] (main.py 282): INFO Train: [299/300][70/78]	eta 0:00:14 lr 0.000002	time 1.3913 (1.8175)	loss 2.1936 (2.1390)	grad_norm 0.6317 (0.6294)	mem 39782MB
[2023-07-07 18:57:02 RepVGG-A0] (main.py 291): INFO EPOCH 299 training takes 0:02:20
[2023-07-07 18:57:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.166 (17.166)	Loss 1.3233 (1.3233)	Acc@1 70.471 (70.471)	Acc@5 89.478 (89.478)	Mem 39782MB
[2023-07-07 18:57:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.892 Acc@5 89.628
[2023-07-07 18:57:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 299: 70.892%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 194): INFO Training time 11:54:08
