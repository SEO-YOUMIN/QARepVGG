[2023-07-07 06:57:03 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 2
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 06:57:07 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 06:57:07 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 06:57:07 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 06:57:07 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 06:58:00 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 1:08:54 lr 0.000000	time 53.0127 (53.0127)	loss 6.9263 (6.9263)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 06:58:12 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:06:42 lr 0.164103	time 1.2064 (5.9152)	loss 6.8744 (6.9127)	grad_norm 0.3863 (0.4375)	mem 39782MB
[2023-07-07 06:58:25 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:36 lr 0.328205	time 1.4893 (3.7375)	loss 6.8549 (6.8835)	grad_norm 0.6087 (0.4656)	mem 39782MB
[2023-07-07 06:58:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:22 lr 0.492308	time 1.3573 (2.9749)	loss 6.6860 (6.8433)	grad_norm 0.3451 (0.4584)	mem 39782MB
[2023-07-07 06:58:52 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:37 lr 0.656410	time 1.3724 (2.5761)	loss 6.5913 (6.8022)	grad_norm 0.2875 (0.4779)	mem 39782MB
[2023-07-07 06:59:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:06 lr 0.820513	time 1.7712 (2.3583)	loss 6.5869 (6.7555)	grad_norm 0.4756 (0.4584)	mem 39782MB
[2023-07-07 06:59:24 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:40 lr 0.984615	time 2.0103 (2.2529)	loss 6.4865 (6.7185)	grad_norm 0.2836 (0.4587)	mem 39782MB
[2023-07-07 06:59:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:17 lr 1.148718	time 1.3554 (2.1501)	loss 6.3877 (6.6873)	grad_norm 0.2158 (0.4426)	mem 39782MB
[2023-07-07 06:59:50 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:43
[2023-07-07 07:01:01 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 4096
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 4096
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 2
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 12.8
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:01:05 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:01:05 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:01:05 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:01:05 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:09 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 2
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:03:12 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:03:12 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:03:12 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:03:12 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:55 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 0:56:13 lr 0.000000	time 43.2491 (43.2491)	loss 6.9263 (6.9263)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 07:04:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:05:41 lr 0.164103	time 1.1692 (5.0182)	loss 6.8713 (6.9123)	grad_norm 0.3837 (0.4372)	mem 39782MB
[2023-07-07 07:04:20 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:06 lr 0.328205	time 1.1727 (3.2158)	loss 6.8236 (6.8797)	grad_norm 0.6673 (0.4541)	mem 39782MB
[2023-07-07 07:04:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:04 lr 0.492308	time 1.1724 (2.5841)	loss 6.7149 (6.8466)	grad_norm 0.3204 (0.5029)	mem 39782MB
[2023-07-07 07:04:45 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:26 lr 0.656410	time 1.1723 (2.2744)	loss 6.5697 (6.7993)	grad_norm 0.2427 (0.4866)	mem 39782MB
[2023-07-07 07:05:02 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:00 lr 0.820513	time 2.4285 (2.1500)	loss 6.5614 (6.7581)	grad_norm 0.2072 (0.4704)	mem 39782MB
[2023-07-07 07:05:17 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:36 lr 0.984615	time 1.4074 (2.0432)	loss 6.4357 (6.7128)	grad_norm 0.3638 (0.4523)	mem 39782MB
[2023-07-07 07:05:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:15 lr 1.148718	time 1.1708 (1.9721)	loss 6.3265 (6.6714)	grad_norm 0.2930 (0.4425)	mem 39782MB
[2023-07-07 07:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:32
[2023-07-07 07:06:02 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.497 (17.497)	Loss 8.4176 (8.4176)	Acc@1 0.433 (0.433)	Acc@5 1.807 (1.807)	Mem 39782MB
[2023-07-07 07:06:04 RepVGG-A0] (main.py 342): INFO  * Acc@1 0.438 Acc@5 1.750
[2023-07-07 07:06:04 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 0: 0.438%
[2023-07-07 07:06:04 RepVGG-A0] (main.py 172): INFO Max accuracy: 0.44%
[2023-07-07 07:06:25 RepVGG-A0] (main.py 282): INFO Train: [1/300][0/78]	eta 0:27:44 lr 1.280000	time 21.3386 (21.3386)	loss 6.4224 (6.4224)	grad_norm 0.3022 (0.3022)	mem 39782MB
[2023-07-07 07:06:39 RepVGG-A0] (main.py 282): INFO Train: [1/300][10/78]	eta 0:03:36 lr 1.444103	time 1.1720 (3.1878)	loss 6.2262 (6.3470)	grad_norm 0.2858 (0.3078)	mem 39782MB
[2023-07-07 07:06:53 RepVGG-A0] (main.py 282): INFO Train: [1/300][20/78]	eta 0:02:15 lr 1.608205	time 1.1885 (2.3409)	loss 6.3250 (6.3221)	grad_norm 0.3848 (0.3558)	mem 39782MB
[2023-07-07 07:07:09 RepVGG-A0] (main.py 282): INFO Train: [1/300][30/78]	eta 0:01:40 lr 1.772308	time 1.5062 (2.0886)	loss 6.2512 (6.2868)	grad_norm 0.3921 (0.3527)	mem 39782MB
[2023-07-07 07:07:28 RepVGG-A0] (main.py 282): INFO Train: [1/300][40/78]	eta 0:01:17 lr 1.936410	time 4.3354 (2.0525)	loss 6.1281 (6.2506)	grad_norm 0.3742 (0.3538)	mem 39782MB
[2023-07-07 07:07:44 RepVGG-A0] (main.py 282): INFO Train: [1/300][50/78]	eta 0:00:54 lr 2.100513	time 1.1725 (1.9513)	loss 6.1453 (6.2235)	grad_norm 0.5806 (0.3590)	mem 39782MB
[2023-07-07 07:07:59 RepVGG-A0] (main.py 282): INFO Train: [1/300][60/78]	eta 0:00:33 lr 2.264615	time 1.5077 (1.8811)	loss 6.0962 (6.1990)	grad_norm 0.4412 (0.3583)	mem 39782MB
[2023-07-07 07:08:14 RepVGG-A0] (main.py 282): INFO Train: [1/300][70/78]	eta 0:00:14 lr 2.428718	time 1.1600 (1.8334)	loss 6.0137 (6.1700)	grad_norm 0.4348 (0.3595)	mem 39782MB
[2023-07-07 07:08:25 RepVGG-A0] (main.py 291): INFO EPOCH 1 training takes 0:02:21
[2023-07-07 07:08:47 RepVGG-A0] (main.py 282): INFO Train: [2/300][0/78]	eta 0:28:02 lr 2.560000	time 21.5734 (21.5734)	loss 5.8521 (5.8521)	grad_norm 0.3089 (0.3089)	mem 39782MB
[2023-07-07 07:09:01 RepVGG-A0] (main.py 282): INFO Train: [2/300][10/78]	eta 0:03:39 lr 2.724103	time 1.1885 (3.2274)	loss 5.8453 (5.8866)	grad_norm 0.3208 (0.3754)	mem 39782MB
[2023-07-07 07:09:16 RepVGG-A0] (main.py 282): INFO Train: [2/300][20/78]	eta 0:02:19 lr 2.888205	time 1.1730 (2.3988)	loss 5.8757 (5.8603)	grad_norm 0.5859 (0.3874)	mem 39782MB
[2023-07-07 07:09:31 RepVGG-A0] (main.py 282): INFO Train: [2/300][30/78]	eta 0:01:41 lr 3.052308	time 1.4977 (2.1169)	loss 5.7799 (5.8739)	grad_norm 0.3534 (0.3930)	mem 39782MB
[2023-07-07 07:09:49 RepVGG-A0] (main.py 282): INFO Train: [2/300][40/78]	eta 0:01:17 lr 3.216410	time 3.6718 (2.0272)	loss 5.6797 (5.8540)	grad_norm 0.2448 (0.3795)	mem 39782MB
[2023-07-07 07:10:04 RepVGG-A0] (main.py 282): INFO Train: [2/300][50/78]	eta 0:00:54 lr 3.380513	time 1.3518 (1.9304)	loss 5.6185 (5.8239)	grad_norm 0.2856 (0.3737)	mem 39782MB
[2023-07-07 07:10:20 RepVGG-A0] (main.py 282): INFO Train: [2/300][60/78]	eta 0:00:33 lr 3.544615	time 1.3069 (1.8746)	loss 5.5552 (5.7879)	grad_norm 0.3870 (0.3667)	mem 39782MB
[2023-07-07 07:10:35 RepVGG-A0] (main.py 282): INFO Train: [2/300][70/78]	eta 0:00:14 lr 3.708718	time 1.3854 (1.8209)	loss 5.5032 (5.7621)	grad_norm 0.2952 (0.3666)	mem 39782MB
[2023-07-07 07:10:47 RepVGG-A0] (main.py 291): INFO EPOCH 2 training takes 0:02:21
[2023-07-07 07:11:07 RepVGG-A0] (main.py 282): INFO Train: [3/300][0/78]	eta 0:26:31 lr 3.840000	time 20.4026 (20.4026)	loss 5.5140 (5.5140)	grad_norm 0.4211 (0.4211)	mem 39782MB
[2023-07-07 07:11:22 RepVGG-A0] (main.py 282): INFO Train: [3/300][10/78]	eta 0:03:35 lr 4.004103	time 1.1891 (3.1731)	loss 5.6412 (5.7042)	grad_norm 0.3348 (0.4536)	mem 39782MB
[2023-07-07 07:11:37 RepVGG-A0] (main.py 282): INFO Train: [3/300][20/78]	eta 0:02:18 lr 4.168205	time 1.1724 (2.3822)	loss 5.4253 (5.6403)	grad_norm 0.2892 (0.3932)	mem 39782MB
[2023-07-07 07:11:52 RepVGG-A0] (main.py 282): INFO Train: [3/300][30/78]	eta 0:01:40 lr 4.332308	time 1.5029 (2.1022)	loss 5.5000 (5.5657)	grad_norm 0.4183 (0.3690)	mem 39782MB
[2023-07-07 07:12:09 RepVGG-A0] (main.py 282): INFO Train: [3/300][40/78]	eta 0:01:16 lr 4.496410	time 3.7353 (2.0088)	loss 5.4350 (5.5148)	grad_norm 0.4425 (0.3594)	mem 39782MB
[2023-07-07 07:12:24 RepVGG-A0] (main.py 282): INFO Train: [3/300][50/78]	eta 0:00:53 lr 4.660513	time 1.1734 (1.8987)	loss 5.4678 (5.5131)	grad_norm 0.3540 (0.3620)	mem 39782MB
[2023-07-07 07:12:39 RepVGG-A0] (main.py 282): INFO Train: [3/300][60/78]	eta 0:00:33 lr 4.824615	time 1.2741 (1.8387)	loss 5.2659 (5.4759)	grad_norm 0.3398 (0.3547)	mem 39782MB
[2023-07-07 07:12:54 RepVGG-A0] (main.py 282): INFO Train: [3/300][70/78]	eta 0:00:14 lr 4.988718	time 1.6014 (1.7859)	loss 5.1495 (5.4403)	grad_norm 0.3245 (0.3490)	mem 39782MB
[2023-07-07 07:13:05 RepVGG-A0] (main.py 291): INFO EPOCH 3 training takes 0:02:18
[2023-07-07 07:13:26 RepVGG-A0] (main.py 282): INFO Train: [4/300][0/78]	eta 0:27:05 lr 5.120000	time 20.8352 (20.8352)	loss 5.0850 (5.0850)	grad_norm 0.3194 (0.3194)	mem 39782MB
[2023-07-07 07:13:40 RepVGG-A0] (main.py 282): INFO Train: [4/300][10/78]	eta 0:03:38 lr 5.284103	time 1.1925 (3.2123)	loss 5.2534 (5.2297)	grad_norm 0.3480 (0.3871)	mem 39782MB
[2023-07-07 07:13:55 RepVGG-A0] (main.py 282): INFO Train: [4/300][20/78]	eta 0:02:17 lr 5.448205	time 1.1722 (2.3748)	loss 5.0664 (5.1922)	grad_norm 0.3079 (0.3590)	mem 39782MB
[2023-07-07 07:14:10 RepVGG-A0] (main.py 282): INFO Train: [4/300][30/78]	eta 0:01:40 lr 5.612308	time 1.2887 (2.0913)	loss 5.1597 (5.1507)	grad_norm 0.4055 (0.3539)	mem 39782MB
[2023-07-07 07:14:28 RepVGG-A0] (main.py 282): INFO Train: [4/300][40/78]	eta 0:01:16 lr 5.776410	time 4.9591 (2.0260)	loss 5.0663 (5.1828)	grad_norm 0.2796 (0.3646)	mem 39782MB
[2023-07-07 07:14:44 RepVGG-A0] (main.py 282): INFO Train: [4/300][50/78]	eta 0:00:54 lr 5.940513	time 1.3391 (1.9300)	loss 5.0773 (5.1866)	grad_norm 0.2789 (0.3640)	mem 39782MB
[2023-07-07 07:14:59 RepVGG-A0] (main.py 282): INFO Train: [4/300][60/78]	eta 0:00:33 lr 6.104615	time 1.1730 (1.8590)	loss 5.0813 (5.1557)	grad_norm 0.4101 (0.3544)	mem 39782MB
[2023-07-07 07:15:14 RepVGG-A0] (main.py 282): INFO Train: [4/300][70/78]	eta 0:00:14 lr 6.268718	time 1.3741 (1.8150)	loss 4.8956 (5.1301)	grad_norm 0.3424 (0.3485)	mem 39782MB
[2023-07-07 07:15:26 RepVGG-A0] (main.py 291): INFO EPOCH 4 training takes 0:02:20
[2023-07-07 07:15:47 RepVGG-A0] (main.py 282): INFO Train: [5/300][0/78]	eta 0:27:49 lr 6.395615	time 21.4037 (21.4037)	loss 4.9616 (4.9616)	grad_norm 0.3501 (0.3501)	mem 39782MB
[2023-07-07 07:16:03 RepVGG-A0] (main.py 282): INFO Train: [5/300][10/78]	eta 0:03:48 lr 6.395387	time 1.1736 (3.3608)	loss 4.8877 (4.9144)	grad_norm 0.3121 (0.3207)	mem 39782MB
[2023-07-07 07:16:17 RepVGG-A0] (main.py 282): INFO Train: [5/300][20/78]	eta 0:02:20 lr 6.395153	time 1.2859 (2.4277)	loss 4.7959 (4.8735)	grad_norm 0.3066 (0.3194)	mem 39782MB
[2023-07-07 07:16:33 RepVGG-A0] (main.py 282): INFO Train: [5/300][30/78]	eta 0:01:43 lr 6.394914	time 1.2218 (2.1607)	loss 4.8206 (4.8526)	grad_norm 0.3153 (0.3274)	mem 39782MB
[2023-07-07 07:16:50 RepVGG-A0] (main.py 282): INFO Train: [5/300][40/78]	eta 0:01:18 lr 6.394669	time 3.6890 (2.0563)	loss 4.8765 (4.8412)	grad_norm 0.4065 (0.3341)	mem 39782MB
[2023-07-07 07:17:05 RepVGG-A0] (main.py 282): INFO Train: [5/300][50/78]	eta 0:00:54 lr 6.394418	time 1.1707 (1.9396)	loss 4.6574 (4.8327)	grad_norm 0.3186 (0.3363)	mem 39782MB
[2023-07-07 07:17:20 RepVGG-A0] (main.py 282): INFO Train: [5/300][60/78]	eta 0:00:33 lr 6.394162	time 1.3330 (1.8659)	loss 4.5990 (4.8134)	grad_norm 0.2947 (0.3370)	mem 39782MB
[2023-07-07 07:17:35 RepVGG-A0] (main.py 282): INFO Train: [5/300][70/78]	eta 0:00:14 lr 6.393899	time 1.3458 (1.8185)	loss 4.7104 (4.7923)	grad_norm 0.3928 (0.3394)	mem 39782MB
[2023-07-07 07:17:47 RepVGG-A0] (main.py 291): INFO EPOCH 5 training takes 0:02:21
[2023-07-07 07:18:09 RepVGG-A0] (main.py 282): INFO Train: [6/300][0/78]	eta 0:28:33 lr 6.393686	time 21.9687 (21.9687)	loss 4.6012 (4.6012)	grad_norm 0.3199 (0.3199)	mem 39782MB
[2023-07-07 07:18:24 RepVGG-A0] (main.py 282): INFO Train: [6/300][10/78]	eta 0:03:47 lr 6.393413	time 1.1723 (3.3518)	loss 4.6539 (4.5893)	grad_norm 0.3654 (0.3503)	mem 39782MB
[2023-07-07 07:18:38 RepVGG-A0] (main.py 282): INFO Train: [6/300][20/78]	eta 0:02:21 lr 6.393134	time 1.1970 (2.4459)	loss 4.6709 (4.5571)	grad_norm 0.4356 (0.3452)	mem 39782MB
[2023-07-07 07:18:53 RepVGG-A0] (main.py 282): INFO Train: [6/300][30/78]	eta 0:01:41 lr 6.392850	time 1.1270 (2.1232)	loss 4.8385 (4.6798)	grad_norm 0.3324 (0.3829)	mem 39782MB
[2023-07-07 07:19:11 RepVGG-A0] (main.py 282): INFO Train: [6/300][40/78]	eta 0:01:17 lr 6.392560	time 3.2683 (2.0432)	loss 4.6601 (4.6603)	grad_norm 0.3424 (0.3618)	mem 39782MB
[2023-07-07 07:19:27 RepVGG-A0] (main.py 282): INFO Train: [6/300][50/78]	eta 0:00:54 lr 6.392265	time 1.1708 (1.9532)	loss 4.4195 (4.6312)	grad_norm 0.2716 (0.3537)	mem 39782MB
[2023-07-07 07:19:42 RepVGG-A0] (main.py 282): INFO Train: [6/300][60/78]	eta 0:00:33 lr 6.391963	time 1.1942 (1.8825)	loss 4.5625 (4.6019)	grad_norm 0.4000 (0.3523)	mem 39782MB
[2023-07-07 07:19:57 RepVGG-A0] (main.py 282): INFO Train: [6/300][70/78]	eta 0:00:14 lr 6.391656	time 1.2026 (1.8304)	loss 4.4019 (4.5805)	grad_norm 0.3288 (0.3490)	mem 39782MB
[2023-07-07 07:20:09 RepVGG-A0] (main.py 291): INFO EPOCH 6 training takes 0:02:22
[2023-07-07 07:20:31 RepVGG-A0] (main.py 282): INFO Train: [7/300][0/78]	eta 0:27:46 lr 6.391406	time 21.3606 (21.3606)	loss 4.8616 (4.8616)	grad_norm 0.6078 (0.6078)	mem 39782MB
[2023-07-07 07:20:45 RepVGG-A0] (main.py 282): INFO Train: [7/300][10/78]	eta 0:03:38 lr 6.391089	time 1.1714 (3.2192)	loss 5.0230 (5.1966)	grad_norm 0.3224 (0.5314)	mem 39782MB
[2023-07-07 07:20:59 RepVGG-A0] (main.py 282): INFO Train: [7/300][20/78]	eta 0:02:17 lr 6.390766	time 1.1721 (2.3776)	loss 4.5822 (4.9808)	grad_norm 0.2351 (0.4205)	mem 39782MB
[2023-07-07 07:21:14 RepVGG-A0] (main.py 282): INFO Train: [7/300][30/78]	eta 0:01:40 lr 6.390437	time 1.2040 (2.1025)	loss 4.3934 (4.8420)	grad_norm 0.2142 (0.3827)	mem 39782MB
[2023-07-07 07:21:34 RepVGG-A0] (main.py 282): INFO Train: [7/300][40/78]	eta 0:01:18 lr 6.390102	time 3.9619 (2.0557)	loss 4.3393 (4.7238)	grad_norm 0.3031 (0.3593)	mem 39782MB
[2023-07-07 07:21:50 RepVGG-A0] (main.py 282): INFO Train: [7/300][50/78]	eta 0:00:55 lr 6.389761	time 1.1261 (1.9694)	loss 4.3303 (4.6500)	grad_norm 0.3885 (0.3520)	mem 39782MB
[2023-07-07 07:22:05 RepVGG-A0] (main.py 282): INFO Train: [7/300][60/78]	eta 0:00:34 lr 6.389415	time 1.2974 (1.8956)	loss 4.2593 (4.5988)	grad_norm 0.2802 (0.3473)	mem 39782MB
[2023-07-07 07:22:20 RepVGG-A0] (main.py 282): INFO Train: [7/300][70/78]	eta 0:00:14 lr 6.389063	time 1.1755 (1.8372)	loss 4.3951 (4.5649)	grad_norm 0.3772 (0.3502)	mem 39782MB
[2023-07-07 07:22:31 RepVGG-A0] (main.py 291): INFO EPOCH 7 training takes 0:02:21
[2023-07-07 07:22:53 RepVGG-A0] (main.py 282): INFO Train: [8/300][0/78]	eta 0:28:09 lr 6.388777	time 21.6607 (21.6607)	loss 4.2153 (4.2153)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 07:23:06 RepVGG-A0] (main.py 282): INFO Train: [8/300][10/78]	eta 0:03:36 lr 6.388415	time 1.1710 (3.1821)	loss 4.2317 (4.2234)	grad_norm 0.3247 (0.3365)	mem 39782MB
[2023-07-07 07:23:20 RepVGG-A0] (main.py 282): INFO Train: [8/300][20/78]	eta 0:02:15 lr 6.388047	time 1.1895 (2.3431)	loss 4.3633 (4.2620)	grad_norm 0.3676 (0.3602)	mem 39782MB
[2023-07-07 07:23:35 RepVGG-A0] (main.py 282): INFO Train: [8/300][30/78]	eta 0:01:39 lr 6.387673	time 1.4750 (2.0808)	loss 4.2324 (4.2568)	grad_norm 0.3572 (0.3583)	mem 39782MB
[2023-07-07 07:23:54 RepVGG-A0] (main.py 282): INFO Train: [8/300][40/78]	eta 0:01:16 lr 6.387293	time 4.0554 (2.0151)	loss 4.1607 (4.2356)	grad_norm 0.3285 (0.3522)	mem 39782MB
[2023-07-07 07:24:09 RepVGG-A0] (main.py 282): INFO Train: [8/300][50/78]	eta 0:00:53 lr 6.386908	time 1.1727 (1.9164)	loss 4.0968 (4.2368)	grad_norm 0.3480 (0.3560)	mem 39782MB
[2023-07-07 07:24:23 RepVGG-A0] (main.py 282): INFO Train: [8/300][60/78]	eta 0:00:33 lr 6.386517	time 1.2020 (1.8408)	loss 4.1077 (4.2234)	grad_norm 0.3056 (0.3526)	mem 39782MB
[2023-07-07 07:24:39 RepVGG-A0] (main.py 282): INFO Train: [8/300][70/78]	eta 0:00:14 lr 6.386120	time 1.4636 (1.8044)	loss 4.6837 (4.2438)	grad_norm 0.5369 (0.3675)	mem 39782MB
[2023-07-07 07:24:51 RepVGG-A0] (main.py 291): INFO EPOCH 8 training takes 0:02:20
[2023-07-07 07:25:13 RepVGG-A0] (main.py 282): INFO Train: [9/300][0/78]	eta 0:28:39 lr 6.385798	time 22.0435 (22.0435)	loss 4.5794 (4.5794)	grad_norm 0.3629 (0.3629)	mem 39782MB
[2023-07-07 07:25:27 RepVGG-A0] (main.py 282): INFO Train: [9/300][10/78]	eta 0:03:40 lr 6.385391	time 1.1727 (3.2466)	loss 4.0790 (4.3029)	grad_norm 0.2382 (0.2936)	mem 39782MB
[2023-07-07 07:25:43 RepVGG-A0] (main.py 282): INFO Train: [9/300][20/78]	eta 0:02:21 lr 6.384978	time 1.1814 (2.4465)	loss 4.1610 (4.2245)	grad_norm 0.3011 (0.2995)	mem 39782MB
[2023-07-07 07:25:57 RepVGG-A0] (main.py 282): INFO Train: [9/300][30/78]	eta 0:01:42 lr 6.384560	time 1.4524 (2.1270)	loss 3.9863 (4.1860)	grad_norm 0.2605 (0.3031)	mem 39782MB
[2023-07-07 07:26:14 RepVGG-A0] (main.py 282): INFO Train: [9/300][40/78]	eta 0:01:16 lr 6.384135	time 2.7881 (2.0242)	loss 4.0315 (4.1610)	grad_norm 0.3226 (0.3117)	mem 39782MB
[2023-07-07 07:26:30 RepVGG-A0] (main.py 282): INFO Train: [9/300][50/78]	eta 0:00:54 lr 6.383705	time 1.1737 (1.9361)	loss 4.3804 (4.1756)	grad_norm 0.4367 (0.3327)	mem 39782MB
[2023-07-07 07:26:45 RepVGG-A0] (main.py 282): INFO Train: [9/300][60/78]	eta 0:00:33 lr 6.383269	time 1.1768 (1.8656)	loss 4.1031 (4.1615)	grad_norm 0.3265 (0.3286)	mem 39782MB
[2023-07-07 07:27:00 RepVGG-A0] (main.py 282): INFO Train: [9/300][70/78]	eta 0:00:14 lr 6.382827	time 1.4227 (1.8119)	loss 4.1264 (4.1409)	grad_norm 0.3517 (0.3280)	mem 39782MB
[2023-07-07 07:27:11 RepVGG-A0] (main.py 291): INFO EPOCH 9 training takes 0:02:19
[2023-07-07 07:27:32 RepVGG-A0] (main.py 282): INFO Train: [10/300][0/78]	eta 0:27:10 lr 6.382470	time 20.9096 (20.9096)	loss 4.1971 (4.1971)	grad_norm 0.4651 (0.4651)	mem 39782MB
[2023-07-07 07:27:47 RepVGG-A0] (main.py 282): INFO Train: [10/300][10/78]	eta 0:03:40 lr 6.382018	time 1.1714 (3.2444)	loss 3.9404 (4.0822)	grad_norm 0.3140 (0.3522)	mem 39782MB
[2023-07-07 07:28:02 RepVGG-A0] (main.py 282): INFO Train: [10/300][20/78]	eta 0:02:20 lr 6.381560	time 1.3926 (2.4239)	loss 4.1064 (4.0491)	grad_norm 0.3932 (0.3513)	mem 39782MB
[2023-07-07 07:28:16 RepVGG-A0] (main.py 282): INFO Train: [10/300][30/78]	eta 0:01:41 lr 6.381097	time 1.1605 (2.1119)	loss 4.1409 (4.0199)	grad_norm 0.4598 (0.3468)	mem 39782MB
[2023-07-07 07:28:34 RepVGG-A0] (main.py 282): INFO Train: [10/300][40/78]	eta 0:01:17 lr 6.380628	time 4.0560 (2.0354)	loss 3.9527 (4.0353)	grad_norm 0.3532 (0.3555)	mem 39782MB
[2023-07-07 07:28:50 RepVGG-A0] (main.py 282): INFO Train: [10/300][50/78]	eta 0:00:54 lr 6.380153	time 1.1747 (1.9415)	loss 3.9150 (4.0278)	grad_norm 0.3167 (0.3534)	mem 39782MB
[2023-07-07 07:29:05 RepVGG-A0] (main.py 282): INFO Train: [10/300][60/78]	eta 0:00:33 lr 6.379672	time 1.1846 (1.8760)	loss 4.0180 (4.0190)	grad_norm 0.3627 (0.3533)	mem 39782MB
[2023-07-07 07:29:21 RepVGG-A0] (main.py 282): INFO Train: [10/300][70/78]	eta 0:00:14 lr 6.379186	time 1.3854 (1.8348)	loss 3.8959 (4.0092)	grad_norm 0.3247 (0.3522)	mem 39782MB
[2023-07-07 07:29:33 RepVGG-A0] (main.py 291): INFO EPOCH 10 training takes 0:02:21
[2023-07-07 07:29:55 RepVGG-A0] (main.py 282): INFO Train: [11/300][0/78]	eta 0:28:44 lr 6.378793	time 22.1060 (22.1060)	loss 4.2903 (4.2903)	grad_norm 0.4965 (0.4965)	mem 39782MB
[2023-07-07 07:30:09 RepVGG-A0] (main.py 282): INFO Train: [11/300][10/78]	eta 0:03:45 lr 6.378296	time 1.1906 (3.3184)	loss 4.5705 (4.6086)	grad_norm 0.4137 (0.5417)	mem 39782MB
[2023-07-07 07:30:24 RepVGG-A0] (main.py 282): INFO Train: [11/300][20/78]	eta 0:02:20 lr 6.377794	time 1.3439 (2.4186)	loss 3.9765 (4.4122)	grad_norm 0.2363 (0.4263)	mem 39782MB
[2023-07-07 07:30:39 RepVGG-A0] (main.py 282): INFO Train: [11/300][30/78]	eta 0:01:42 lr 6.377286	time 1.3716 (2.1453)	loss 3.8603 (4.2791)	grad_norm 0.2683 (0.3847)	mem 39782MB
[2023-07-07 07:30:57 RepVGG-A0] (main.py 282): INFO Train: [11/300][40/78]	eta 0:01:18 lr 6.376772	time 3.5703 (2.0597)	loss 3.8557 (4.1860)	grad_norm 0.3163 (0.3636)	mem 39782MB
[2023-07-07 07:31:12 RepVGG-A0] (main.py 282): INFO Train: [11/300][50/78]	eta 0:00:54 lr 6.376252	time 1.1721 (1.9442)	loss 3.8912 (4.1189)	grad_norm 0.3426 (0.3517)	mem 39782MB
[2023-07-07 07:31:28 RepVGG-A0] (main.py 282): INFO Train: [11/300][60/78]	eta 0:00:33 lr 6.375727	time 1.2859 (1.8827)	loss 3.8382 (4.0978)	grad_norm 0.3005 (0.3552)	mem 39782MB
[2023-07-07 07:31:42 RepVGG-A0] (main.py 282): INFO Train: [11/300][70/78]	eta 0:00:14 lr 6.375196	time 1.3167 (1.8247)	loss 4.3268 (4.0825)	grad_norm 0.5178 (0.3610)	mem 39782MB
[2023-07-07 07:31:54 RepVGG-A0] (main.py 291): INFO EPOCH 11 training takes 0:02:21
[2023-07-07 07:32:16 RepVGG-A0] (main.py 282): INFO Train: [12/300][0/78]	eta 0:28:04 lr 6.374767	time 21.6021 (21.6021)	loss 3.9834 (3.9834)	grad_norm 0.3421 (0.3421)	mem 39782MB
[2023-07-07 07:32:30 RepVGG-A0] (main.py 282): INFO Train: [12/300][10/78]	eta 0:03:42 lr 6.374226	time 1.1722 (3.2769)	loss 3.7874 (3.8713)	grad_norm 0.3571 (0.3158)	mem 39782MB
[2023-07-07 07:32:45 RepVGG-A0] (main.py 282): INFO Train: [12/300][20/78]	eta 0:02:20 lr 6.373679	time 1.2082 (2.4232)	loss 3.8191 (3.8686)	grad_norm 0.3231 (0.3243)	mem 39782MB
[2023-07-07 07:33:00 RepVGG-A0] (main.py 282): INFO Train: [12/300][30/78]	eta 0:01:42 lr 6.373126	time 1.2244 (2.1397)	loss 4.1374 (3.8813)	grad_norm 0.4718 (0.3424)	mem 39782MB
[2023-07-07 07:33:18 RepVGG-A0] (main.py 282): INFO Train: [12/300][40/78]	eta 0:01:17 lr 6.372567	time 3.3642 (2.0397)	loss 3.7870 (3.8904)	grad_norm 0.2953 (0.3434)	mem 39782MB
[2023-07-07 07:33:33 RepVGG-A0] (main.py 282): INFO Train: [12/300][50/78]	eta 0:00:54 lr 6.372003	time 1.3822 (1.9397)	loss 3.9455 (3.8834)	grad_norm 0.3674 (0.3439)	mem 39782MB
[2023-07-07 07:33:49 RepVGG-A0] (main.py 282): INFO Train: [12/300][60/78]	eta 0:00:33 lr 6.371433	time 1.2308 (1.8817)	loss 3.9597 (3.8799)	grad_norm 0.3711 (0.3458)	mem 39782MB
[2023-07-07 07:34:03 RepVGG-A0] (main.py 282): INFO Train: [12/300][70/78]	eta 0:00:14 lr 6.370858	time 1.4761 (1.8179)	loss 4.2105 (3.8847)	grad_norm 0.5503 (0.3526)	mem 39782MB
[2023-07-07 07:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 12 training takes 0:02:20
[2023-07-07 07:34:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][0/78]	eta 0:28:26 lr 6.370393	time 21.8733 (21.8733)	loss 4.5967 (4.5967)	grad_norm 0.5121 (0.5121)	mem 39782MB
[2023-07-07 07:34:50 RepVGG-A0] (main.py 282): INFO Train: [13/300][10/78]	eta 0:03:42 lr 6.369807	time 1.1704 (3.2703)	loss 3.9684 (4.2485)	grad_norm 0.3029 (0.3710)	mem 39782MB
[2023-07-07 07:35:05 RepVGG-A0] (main.py 282): INFO Train: [13/300][20/78]	eta 0:02:18 lr 6.369216	time 1.1735 (2.3954)	loss 3.8317 (4.0675)	grad_norm 0.2852 (0.3273)	mem 39782MB
[2023-07-07 07:35:19 RepVGG-A0] (main.py 282): INFO Train: [13/300][30/78]	eta 0:01:40 lr 6.368618	time 1.2979 (2.0941)	loss 3.8921 (3.9857)	grad_norm 0.3547 (0.3255)	mem 39782MB
[2023-07-07 07:35:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][40/78]	eta 0:01:15 lr 6.368015	time 2.8525 (1.9954)	loss 3.7981 (3.9476)	grad_norm 0.3138 (0.3253)	mem 39782MB
[2023-07-07 07:35:52 RepVGG-A0] (main.py 282): INFO Train: [13/300][50/78]	eta 0:00:53 lr 6.367406	time 1.3424 (1.9134)	loss 3.9972 (3.9348)	grad_norm 0.4586 (0.3365)	mem 39782MB
[2023-07-07 07:36:07 RepVGG-A0] (main.py 282): INFO Train: [13/300][60/78]	eta 0:00:33 lr 6.366792	time 1.1736 (1.8426)	loss 3.7913 (3.9171)	grad_norm 0.3021 (0.3360)	mem 39782MB
[2023-07-07 07:36:22 RepVGG-A0] (main.py 282): INFO Train: [13/300][70/78]	eta 0:00:14 lr 6.366172	time 1.5482 (1.8022)	loss 3.8061 (3.8947)	grad_norm 0.3652 (0.3343)	mem 39782MB
[2023-07-07 07:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 13 training takes 0:02:19
[2023-07-07 07:36:55 RepVGG-A0] (main.py 282): INFO Train: [14/300][0/78]	eta 0:27:03 lr 6.365671	time 20.8181 (20.8181)	loss 3.9117 (3.9117)	grad_norm 0.3951 (0.3951)	mem 39782MB
[2023-07-07 07:37:10 RepVGG-A0] (main.py 282): INFO Train: [14/300][10/78]	eta 0:03:42 lr 6.365041	time 1.1758 (3.2767)	loss 3.7760 (3.8152)	grad_norm 0.3136 (0.3536)	mem 39782MB
[2023-07-07 07:37:25 RepVGG-A0] (main.py 282): INFO Train: [14/300][20/78]	eta 0:02:20 lr 6.364405	time 1.1729 (2.4242)	loss 3.7877 (3.7803)	grad_norm 0.3702 (0.3490)	mem 39782MB
[2023-07-07 07:37:40 RepVGG-A0] (main.py 282): INFO Train: [14/300][30/78]	eta 0:01:42 lr 6.363763	time 1.1822 (2.1261)	loss 3.8491 (3.7891)	grad_norm 0.3959 (0.3608)	mem 39782MB
[2023-07-07 07:37:59 RepVGG-A0] (main.py 282): INFO Train: [14/300][40/78]	eta 0:01:18 lr 6.363115	time 4.0185 (2.0616)	loss 3.7765 (3.7917)	grad_norm 0.3423 (0.3600)	mem 39782MB
[2023-07-07 07:38:14 RepVGG-A0] (main.py 282): INFO Train: [14/300][50/78]	eta 0:00:54 lr 6.362462	time 1.1270 (1.9523)	loss 3.8114 (3.7869)	grad_norm 0.3715 (0.3569)	mem 39782MB
[2023-07-07 07:38:29 RepVGG-A0] (main.py 282): INFO Train: [14/300][60/78]	eta 0:00:33 lr 6.361803	time 1.2513 (1.8793)	loss 4.2949 (3.8460)	grad_norm 0.5011 (0.3816)	mem 39782MB
[2023-07-07 07:38:44 RepVGG-A0] (main.py 282): INFO Train: [14/300][70/78]	eta 0:00:14 lr 6.361139	time 1.4321 (1.8300)	loss 3.7609 (3.8766)	grad_norm 0.2397 (0.3792)	mem 39782MB
[2023-07-07 07:38:56 RepVGG-A0] (main.py 291): INFO EPOCH 14 training takes 0:02:21
[2023-07-07 07:39:16 RepVGG-A0] (main.py 282): INFO Train: [15/300][0/78]	eta 0:26:14 lr 6.360603	time 20.1819 (20.1819)	loss 3.7022 (3.7022)	grad_norm 0.2818 (0.2818)	mem 39782MB
[2023-07-07 07:39:32 RepVGG-A0] (main.py 282): INFO Train: [15/300][10/78]	eta 0:03:45 lr 6.359928	time 1.1745 (3.3190)	loss 3.6944 (3.7676)	grad_norm 0.2760 (0.3218)	mem 39782MB
[2023-07-07 07:39:46 RepVGG-A0] (main.py 282): INFO Train: [15/300][20/78]	eta 0:02:20 lr 6.359247	time 1.1903 (2.4180)	loss 3.7309 (3.7275)	grad_norm 0.3307 (0.3248)	mem 39782MB
[2023-07-07 07:40:02 RepVGG-A0] (main.py 282): INFO Train: [15/300][30/78]	eta 0:01:42 lr 6.358561	time 1.5970 (2.1362)	loss 3.6937 (3.6988)	grad_norm 0.3374 (0.3216)	mem 39782MB
[2023-07-07 07:40:20 RepVGG-A0] (main.py 282): INFO Train: [15/300][40/78]	eta 0:01:17 lr 6.357869	time 3.6491 (2.0489)	loss 3.6963 (3.7041)	grad_norm 0.3651 (0.3323)	mem 39782MB
[2023-07-07 07:40:35 RepVGG-A0] (main.py 282): INFO Train: [15/300][50/78]	eta 0:00:54 lr 6.357171	time 1.1736 (1.9407)	loss 4.3273 (3.7442)	grad_norm 0.6949 (0.3576)	mem 39782MB
[2023-07-07 07:40:50 RepVGG-A0] (main.py 282): INFO Train: [15/300][60/78]	eta 0:00:33 lr 6.356468	time 1.1258 (1.8704)	loss 5.2868 (4.0166)	grad_norm 0.4850 (0.4067)	mem 39782MB
[2023-07-07 07:41:05 RepVGG-A0] (main.py 282): INFO Train: [15/300][70/78]	eta 0:00:14 lr 6.355759	time 1.2067 (1.8171)	loss 4.4205 (4.1194)	grad_norm 0.2292 (0.3932)	mem 39782MB
[2023-07-07 07:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 15 training takes 0:02:21
[2023-07-07 07:41:37 RepVGG-A0] (main.py 282): INFO Train: [16/300][0/78]	eta 0:25:55 lr 6.355187	time 19.9438 (19.9438)	loss 4.2599 (4.2599)	grad_norm 0.2985 (0.2985)	mem 39782MB
[2023-07-07 07:41:53 RepVGG-A0] (main.py 282): INFO Train: [16/300][10/78]	eta 0:03:43 lr 6.354468	time 1.1706 (3.2828)	loss 3.9067 (4.0587)	grad_norm 0.2392 (0.2544)	mem 39782MB
[2023-07-07 07:42:07 RepVGG-A0] (main.py 282): INFO Train: [16/300][20/78]	eta 0:02:19 lr 6.353743	time 1.1718 (2.4011)	loss 3.9075 (3.9983)	grad_norm 0.3623 (0.2789)	mem 39782MB
[2023-07-07 07:42:23 RepVGG-A0] (main.py 282): INFO Train: [16/300][30/78]	eta 0:01:42 lr 6.353012	time 1.6098 (2.1297)	loss 3.7830 (3.9682)	grad_norm 0.2343 (0.2871)	mem 39782MB
[2023-07-07 07:42:40 RepVGG-A0] (main.py 282): INFO Train: [16/300][40/78]	eta 0:01:17 lr 6.352276	time 3.4351 (2.0372)	loss 3.9660 (3.9391)	grad_norm 0.4042 (0.2984)	mem 39782MB
[2023-07-07 07:42:55 RepVGG-A0] (main.py 282): INFO Train: [16/300][50/78]	eta 0:00:54 lr 6.351534	time 1.1723 (1.9318)	loss 3.7840 (3.9141)	grad_norm 0.3138 (0.2998)	mem 39782MB
[2023-07-07 07:43:11 RepVGG-A0] (main.py 282): INFO Train: [16/300][60/78]	eta 0:00:33 lr 6.350786	time 1.2720 (1.8750)	loss 4.0155 (3.9061)	grad_norm 0.4180 (0.3114)	mem 39782MB
[2023-07-07 07:43:26 RepVGG-A0] (main.py 282): INFO Train: [16/300][70/78]	eta 0:00:14 lr 6.350033	time 1.1763 (1.8208)	loss 3.7193 (3.8958)	grad_norm 0.3425 (0.3142)	mem 39782MB
[2023-07-07 07:43:38 RepVGG-A0] (main.py 291): INFO EPOCH 16 training takes 0:02:20
[2023-07-07 07:43:58 RepVGG-A0] (main.py 282): INFO Train: [17/300][0/78]	eta 0:26:25 lr 6.349426	time 20.3303 (20.3303)	loss 3.7057 (3.7057)	grad_norm 0.3172 (0.3172)	mem 39782MB
[2023-07-07 07:44:14 RepVGG-A0] (main.py 282): INFO Train: [17/300][10/78]	eta 0:03:43 lr 6.348662	time 1.1704 (3.2821)	loss 3.8329 (3.7619)	grad_norm 0.3768 (0.3612)	mem 39782MB
[2023-07-07 07:44:29 RepVGG-A0] (main.py 282): INFO Train: [17/300][20/78]	eta 0:02:21 lr 6.347893	time 1.1771 (2.4340)	loss 3.8062 (3.7352)	grad_norm 0.3442 (0.3521)	mem 39782MB
[2023-07-07 07:44:44 RepVGG-A0] (main.py 282): INFO Train: [17/300][30/78]	eta 0:01:43 lr 6.347118	time 1.4786 (2.1476)	loss 3.7709 (3.7373)	grad_norm 0.3819 (0.3557)	mem 39782MB
[2023-07-07 07:45:02 RepVGG-A0] (main.py 282): INFO Train: [17/300][40/78]	eta 0:01:18 lr 6.346337	time 3.9557 (2.0565)	loss 3.6515 (3.7389)	grad_norm 0.3219 (0.3521)	mem 39782MB
[2023-07-07 07:45:18 RepVGG-A0] (main.py 282): INFO Train: [17/300][50/78]	eta 0:00:54 lr 6.345551	time 1.2802 (1.9621)	loss 3.9722 (3.7491)	grad_norm 0.4348 (0.3601)	mem 39782MB
[2023-07-07 07:45:32 RepVGG-A0] (main.py 282): INFO Train: [17/300][60/78]	eta 0:00:33 lr 6.344759	time 1.1850 (1.8777)	loss 3.6322 (3.7634)	grad_norm 0.2790 (0.3611)	mem 39782MB
[2023-07-07 07:45:47 RepVGG-A0] (main.py 282): INFO Train: [17/300][70/78]	eta 0:00:14 lr 6.343961	time 1.1620 (1.8248)	loss 3.6363 (3.7495)	grad_norm 0.3194 (0.3548)	mem 39782MB
[2023-07-07 07:46:00 RepVGG-A0] (main.py 291): INFO EPOCH 17 training takes 0:02:22
[2023-07-07 07:46:22 RepVGG-A0] (main.py 282): INFO Train: [18/300][0/78]	eta 0:27:30 lr 6.343319	time 21.1568 (21.1568)	loss 6.2825 (6.2825)	grad_norm 1.0156 (1.0156)	mem 39782MB
[2023-07-07 07:46:36 RepVGG-A0] (main.py 282): INFO Train: [18/300][10/78]	eta 0:03:42 lr 6.342511	time 1.1911 (3.2663)	loss 5.4426 (5.8257)	grad_norm 0.4270 (0.5488)	mem 39782MB
[2023-07-07 07:46:51 RepVGG-A0] (main.py 282): INFO Train: [18/300][20/78]	eta 0:02:18 lr 6.341698	time 1.1718 (2.3964)	loss 4.7400 (5.4212)	grad_norm 0.3467 (0.4279)	mem 39782MB
[2023-07-07 07:47:06 RepVGG-A0] (main.py 282): INFO Train: [18/300][30/78]	eta 0:01:41 lr 6.340879	time 1.5927 (2.1125)	loss 4.4705 (5.1621)	grad_norm 0.2444 (0.3872)	mem 39782MB
[2023-07-07 07:47:24 RepVGG-A0] (main.py 282): INFO Train: [18/300][40/78]	eta 0:01:17 lr 6.340054	time 4.2983 (2.0451)	loss 4.2407 (4.9483)	grad_norm 0.3201 (0.3564)	mem 39782MB
[2023-07-07 07:47:39 RepVGG-A0] (main.py 282): INFO Train: [18/300][50/78]	eta 0:00:54 lr 6.339223	time 1.1717 (1.9422)	loss 4.0462 (4.7993)	grad_norm 0.2617 (0.3466)	mem 39782MB
[2023-07-07 07:47:55 RepVGG-A0] (main.py 282): INFO Train: [18/300][60/78]	eta 0:00:33 lr 6.338387	time 1.3007 (1.8794)	loss 4.1515 (4.6813)	grad_norm 0.3505 (0.3408)	mem 39782MB
[2023-07-07 07:48:11 RepVGG-A0] (main.py 282): INFO Train: [18/300][70/78]	eta 0:00:14 lr 6.337545	time 1.5941 (1.8409)	loss 4.0274 (4.5833)	grad_norm 0.3598 (0.3366)	mem 39782MB
[2023-07-07 07:48:22 RepVGG-A0] (main.py 291): INFO EPOCH 18 training takes 0:02:21
[2023-07-07 07:48:43 RepVGG-A0] (main.py 282): INFO Train: [19/300][0/78]	eta 0:27:29 lr 6.336868	time 21.1523 (21.1523)	loss 3.8932 (3.8932)	grad_norm 0.3231 (0.3231)	mem 39782MB
[2023-07-07 07:48:57 RepVGG-A0] (main.py 282): INFO Train: [19/300][10/78]	eta 0:03:36 lr 6.336016	time 1.1709 (3.1864)	loss 3.9268 (3.9379)	grad_norm 0.3505 (0.3401)	mem 39782MB
[2023-07-07 07:49:12 RepVGG-A0] (main.py 282): INFO Train: [19/300][20/78]	eta 0:02:18 lr 6.335158	time 1.1918 (2.3951)	loss 3.9450 (3.9214)	grad_norm 0.3872 (0.3436)	mem 39782MB
[2023-07-07 07:49:27 RepVGG-A0] (main.py 282): INFO Train: [19/300][30/78]	eta 0:01:40 lr 6.334295	time 1.4364 (2.0909)	loss 3.8463 (3.9183)	grad_norm 0.3336 (0.3445)	mem 39782MB
[2023-07-07 07:49:44 RepVGG-A0] (main.py 282): INFO Train: [19/300][40/78]	eta 0:01:16 lr 6.333426	time 4.0418 (2.0016)	loss 3.9506 (3.8985)	grad_norm 0.4114 (0.3415)	mem 39782MB
[2023-07-07 07:50:00 RepVGG-A0] (main.py 282): INFO Train: [19/300][50/78]	eta 0:00:53 lr 6.332551	time 1.1731 (1.9092)	loss 3.7312 (3.8849)	grad_norm 0.3259 (0.3416)	mem 39782MB
[2023-07-07 07:50:14 RepVGG-A0] (main.py 282): INFO Train: [19/300][60/78]	eta 0:00:33 lr 6.331671	time 1.1932 (1.8415)	loss 3.8488 (3.8742)	grad_norm 0.3858 (0.3434)	mem 39782MB
[2023-07-07 07:50:30 RepVGG-A0] (main.py 282): INFO Train: [19/300][70/78]	eta 0:00:14 lr 6.330785	time 1.3505 (1.8002)	loss 3.9985 (3.8733)	grad_norm 0.4791 (0.3495)	mem 39782MB
[2023-07-07 07:50:41 RepVGG-A0] (main.py 291): INFO EPOCH 19 training takes 0:02:19
[2023-07-07 07:51:03 RepVGG-A0] (main.py 282): INFO Train: [20/300][0/78]	eta 0:28:09 lr 6.330072	time 21.6561 (21.6561)	loss 3.7670 (3.7670)	grad_norm 0.2921 (0.2921)	mem 39782MB
[2023-07-07 07:51:17 RepVGG-A0] (main.py 282): INFO Train: [20/300][10/78]	eta 0:03:42 lr 6.329176	time 1.1772 (3.2709)	loss 4.0990 (3.8330)	grad_norm 0.4776 (0.3881)	mem 39782MB
[2023-07-07 07:51:33 RepVGG-A0] (main.py 282): INFO Train: [20/300][20/78]	eta 0:02:22 lr 6.328275	time 1.3282 (2.4628)	loss 3.7477 (3.8563)	grad_norm 0.3171 (0.3670)	mem 39782MB
[2023-07-07 07:51:48 RepVGG-A0] (main.py 282): INFO Train: [20/300][30/78]	eta 0:01:43 lr 6.327367	time 1.3907 (2.1630)	loss 3.8105 (3.8638)	grad_norm 0.3293 (0.3753)	mem 39782MB
[2023-07-07 07:52:06 RepVGG-A0] (main.py 282): INFO Train: [20/300][40/78]	eta 0:01:18 lr 6.326454	time 3.6670 (2.0662)	loss 3.8126 (3.8274)	grad_norm 0.3773 (0.3609)	mem 39782MB
[2023-07-07 07:52:21 RepVGG-A0] (main.py 282): INFO Train: [20/300][50/78]	eta 0:00:54 lr 6.325536	time 1.3820 (1.9545)	loss 3.7112 (3.8040)	grad_norm 0.2934 (0.3514)	mem 39782MB
[2023-07-07 07:52:36 RepVGG-A0] (main.py 282): INFO Train: [20/300][60/78]	eta 0:00:33 lr 6.324611	time 1.3659 (1.8816)	loss 3.9003 (3.8009)	grad_norm 0.4276 (0.3578)	mem 39782MB
[2023-07-07 07:52:51 RepVGG-A0] (main.py 282): INFO Train: [20/300][70/78]	eta 0:00:14 lr 6.323682	time 1.1827 (1.8266)	loss 3.6953 (3.7983)	grad_norm 0.3177 (0.3581)	mem 39782MB
[2023-07-07 07:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 20 training takes 0:02:20
[2023-07-07 07:53:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.623 (17.623)	Loss 3.2837 (3.2837)	Acc@1 32.971 (32.971)	Acc@5 57.623 (57.623)	Mem 39782MB
[2023-07-07 07:53:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 32.742 Acc@5 57.506
[2023-07-07 07:53:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 20: 32.742%
[2023-07-07 07:53:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 07:53:42 RepVGG-A0] (main.py 282): INFO Train: [21/300][0/78]	eta 0:27:34 lr 6.322934	time 21.2112 (21.2112)	loss 3.6104 (3.6104)	grad_norm 0.3284 (0.3284)	mem 39782MB
[2023-07-07 07:53:57 RepVGG-A0] (main.py 282): INFO Train: [21/300][10/78]	eta 0:03:45 lr 6.321994	time 1.1733 (3.3116)	loss 3.7980 (3.6877)	grad_norm 0.4108 (0.3748)	mem 39782MB
[2023-07-07 07:54:12 RepVGG-A0] (main.py 282): INFO Train: [21/300][20/78]	eta 0:02:21 lr 6.321048	time 1.3174 (2.4394)	loss 3.8053 (3.7237)	grad_norm 0.3869 (0.3783)	mem 39782MB
[2023-07-07 07:54:27 RepVGG-A0] (main.py 282): INFO Train: [21/300][30/78]	eta 0:01:42 lr 6.320097	time 1.3332 (2.1392)	loss 3.6089 (3.7170)	grad_norm 0.3176 (0.3678)	mem 39782MB
[2023-07-07 07:54:44 RepVGG-A0] (main.py 282): INFO Train: [21/300][40/78]	eta 0:01:17 lr 6.319140	time 3.2070 (2.0434)	loss 3.7443 (3.6990)	grad_norm 0.4025 (0.3611)	mem 39782MB
[2023-07-07 07:55:00 RepVGG-A0] (main.py 282): INFO Train: [21/300][50/78]	eta 0:00:54 lr 6.318177	time 1.2964 (1.9433)	loss 3.5783 (3.6974)	grad_norm 0.3152 (0.3574)	mem 39782MB
[2023-07-07 07:55:15 RepVGG-A0] (main.py 282): INFO Train: [21/300][60/78]	eta 0:00:33 lr 6.317209	time 1.1860 (1.8723)	loss 3.6912 (3.6955)	grad_norm 0.3534 (0.3590)	mem 39782MB
[2023-07-07 07:55:30 RepVGG-A0] (main.py 282): INFO Train: [21/300][70/78]	eta 0:00:14 lr 6.316236	time 1.4060 (1.8232)	loss 3.8286 (3.7038)	grad_norm 0.4265 (0.3649)	mem 39782MB
[2023-07-07 07:55:42 RepVGG-A0] (main.py 291): INFO EPOCH 21 training takes 0:02:21
[2023-07-07 07:56:03 RepVGG-A0] (main.py 282): INFO Train: [22/300][0/78]	eta 0:27:59 lr 6.315452	time 21.5347 (21.5347)	loss 4.4281 (4.4281)	grad_norm 0.5225 (0.5225)	mem 39782MB
[2023-07-07 07:56:18 RepVGG-A0] (main.py 282): INFO Train: [22/300][10/78]	eta 0:03:43 lr 6.314469	time 1.1968 (3.2827)	loss 3.7630 (4.1023)	grad_norm 0.3035 (0.3728)	mem 39782MB
[2023-07-07 07:56:32 RepVGG-A0] (main.py 282): INFO Train: [22/300][20/78]	eta 0:02:19 lr 6.313479	time 1.1736 (2.4028)	loss 3.6175 (3.9148)	grad_norm 0.2631 (0.3263)	mem 39782MB
[2023-07-07 07:56:48 RepVGG-A0] (main.py 282): INFO Train: [22/300][30/78]	eta 0:01:43 lr 6.312484	time 1.1829 (2.1484)	loss 3.6473 (3.8204)	grad_norm 0.3040 (0.3154)	mem 39782MB
[2023-07-07 07:57:06 RepVGG-A0] (main.py 282): INFO Train: [22/300][40/78]	eta 0:01:17 lr 6.311483	time 3.7330 (2.0506)	loss 3.5205 (3.7693)	grad_norm 0.3168 (0.3164)	mem 39782MB
[2023-07-07 07:57:20 RepVGG-A0] (main.py 282): INFO Train: [22/300][50/78]	eta 0:00:54 lr 6.310477	time 1.3178 (1.9379)	loss 3.7026 (3.7438)	grad_norm 0.3499 (0.3246)	mem 39782MB
[2023-07-07 07:57:35 RepVGG-A0] (main.py 282): INFO Train: [22/300][60/78]	eta 0:00:33 lr 6.309465	time 1.1713 (1.8633)	loss 3.5824 (3.7203)	grad_norm 0.3477 (0.3247)	mem 39782MB
[2023-07-07 07:57:51 RepVGG-A0] (main.py 282): INFO Train: [22/300][70/78]	eta 0:00:14 lr 6.308448	time 1.3511 (1.8179)	loss 3.5709 (3.7079)	grad_norm 0.3597 (0.3286)	mem 39782MB
[2023-07-07 07:58:03 RepVGG-A0] (main.py 291): INFO EPOCH 22 training takes 0:02:21
[2023-07-07 07:58:24 RepVGG-A0] (main.py 282): INFO Train: [23/300][0/78]	eta 0:27:22 lr 6.307630	time 21.0584 (21.0584)	loss 3.5229 (3.5229)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 07:58:39 RepVGG-A0] (main.py 282): INFO Train: [23/300][10/78]	eta 0:03:41 lr 6.306602	time 1.1720 (3.2513)	loss 3.6574 (3.6176)	grad_norm 0.3604 (0.3686)	mem 39782MB
[2023-07-07 07:58:54 RepVGG-A0] (main.py 282): INFO Train: [23/300][20/78]	eta 0:02:22 lr 6.305569	time 1.3830 (2.4491)	loss 3.5664 (3.6217)	grad_norm 0.3414 (0.3583)	mem 39782MB
[2023-07-07 07:59:09 RepVGG-A0] (main.py 282): INFO Train: [23/300][30/78]	eta 0:01:43 lr 6.304530	time 1.5060 (2.1485)	loss 3.5458 (3.6135)	grad_norm 0.3500 (0.3585)	mem 39782MB
[2023-07-07 07:59:27 RepVGG-A0] (main.py 282): INFO Train: [23/300][40/78]	eta 0:01:18 lr 6.303486	time 3.5104 (2.0535)	loss 3.5837 (3.6115)	grad_norm 0.3400 (0.3606)	mem 39782MB
[2023-07-07 07:59:42 RepVGG-A0] (main.py 282): INFO Train: [23/300][50/78]	eta 0:00:54 lr 6.302436	time 1.1948 (1.9449)	loss 3.5649 (3.6017)	grad_norm 0.3568 (0.3566)	mem 39782MB
[2023-07-07 07:59:57 RepVGG-A0] (main.py 282): INFO Train: [23/300][60/78]	eta 0:00:33 lr 6.301380	time 1.1806 (1.8768)	loss 3.6428 (3.6107)	grad_norm 0.3734 (0.3597)	mem 39782MB
[2023-07-07 08:00:13 RepVGG-A0] (main.py 282): INFO Train: [23/300][70/78]	eta 0:00:14 lr 6.300319	time 1.5969 (1.8308)	loss 3.6892 (3.6101)	grad_norm 0.3992 (0.3592)	mem 39782MB
[2023-07-07 08:00:24 RepVGG-A0] (main.py 291): INFO EPOCH 23 training takes 0:02:20
[2023-07-07 08:00:46 RepVGG-A0] (main.py 282): INFO Train: [24/300][0/78]	eta 0:28:26 lr 6.299466	time 21.8780 (21.8780)	loss 3.5216 (3.5216)	grad_norm 0.3645 (0.3645)	mem 39782MB
[2023-07-07 08:00:59 RepVGG-A0] (main.py 282): INFO Train: [24/300][10/78]	eta 0:03:40 lr 6.298395	time 1.1694 (3.2401)	loss 3.5293 (3.5003)	grad_norm 0.3359 (0.3254)	mem 39782MB
[2023-07-07 08:01:14 RepVGG-A0] (main.py 282): INFO Train: [24/300][20/78]	eta 0:02:18 lr 6.297318	time 1.1721 (2.3924)	loss 4.4649 (3.6534)	grad_norm 0.7927 (0.4109)	mem 39782MB
[2023-07-07 08:01:29 RepVGG-A0] (main.py 282): INFO Train: [24/300][30/78]	eta 0:01:41 lr 6.296236	time 1.3137 (2.1050)	loss 5.5815 (4.3588)	grad_norm 0.3807 (0.4860)	mem 39782MB
[2023-07-07 08:01:47 RepVGG-A0] (main.py 282): INFO Train: [24/300][40/78]	eta 0:01:16 lr 6.295148	time 3.0050 (2.0256)	loss 4.8035 (4.5664)	grad_norm 0.2415 (0.4467)	mem 39782MB
[2023-07-07 08:02:02 RepVGG-A0] (main.py 282): INFO Train: [24/300][50/78]	eta 0:00:53 lr 6.294054	time 1.1902 (1.9178)	loss 4.4085 (4.5805)	grad_norm 0.2658 (0.4163)	mem 39782MB
[2023-07-07 08:02:17 RepVGG-A0] (main.py 282): INFO Train: [24/300][60/78]	eta 0:00:33 lr 6.292955	time 1.1794 (1.8498)	loss 4.3140 (4.5435)	grad_norm 0.3431 (0.3977)	mem 39782MB
[2023-07-07 08:02:32 RepVGG-A0] (main.py 282): INFO Train: [24/300][70/78]	eta 0:00:14 lr 6.291850	time 1.1717 (1.8007)	loss 4.2410 (4.4948)	grad_norm 0.4236 (0.3862)	mem 39782MB
[2023-07-07 08:02:44 RepVGG-A0] (main.py 291): INFO EPOCH 24 training takes 0:02:19
[2023-07-07 08:03:04 RepVGG-A0] (main.py 282): INFO Train: [25/300][0/78]	eta 0:26:46 lr 6.290963	time 20.6000 (20.6000)	loss 3.9671 (3.9671)	grad_norm 0.2841 (0.2841)	mem 39782MB
[2023-07-07 08:03:21 RepVGG-A0] (main.py 282): INFO Train: [25/300][10/78]	eta 0:03:49 lr 6.289848	time 1.1720 (3.3701)	loss 3.9648 (3.9400)	grad_norm 0.3544 (0.3094)	mem 39782MB
[2023-07-07 08:03:35 RepVGG-A0] (main.py 282): INFO Train: [25/300][20/78]	eta 0:02:21 lr 6.288728	time 1.1860 (2.4366)	loss 3.8380 (3.9137)	grad_norm 0.2953 (0.3101)	mem 39782MB
[2023-07-07 08:03:50 RepVGG-A0] (main.py 282): INFO Train: [25/300][30/78]	eta 0:01:42 lr 6.287602	time 1.3805 (2.1343)	loss 3.8453 (3.8950)	grad_norm 0.3473 (0.3172)	mem 39782MB
[2023-07-07 08:04:07 RepVGG-A0] (main.py 282): INFO Train: [25/300][40/78]	eta 0:01:17 lr 6.286470	time 4.1349 (2.0384)	loss 3.8995 (3.8990)	grad_norm 0.3601 (0.3316)	mem 39782MB
[2023-07-07 08:04:22 RepVGG-A0] (main.py 282): INFO Train: [25/300][50/78]	eta 0:00:54 lr 6.285333	time 1.1741 (1.9386)	loss 3.8968 (3.8799)	grad_norm 0.3959 (0.3312)	mem 39782MB
[2023-07-07 08:04:38 RepVGG-A0] (main.py 282): INFO Train: [25/300][60/78]	eta 0:00:33 lr 6.284191	time 1.1724 (1.8729)	loss 3.7563 (3.8671)	grad_norm 0.3242 (0.3322)	mem 39782MB
[2023-07-07 08:04:54 RepVGG-A0] (main.py 282): INFO Train: [25/300][70/78]	eta 0:00:14 lr 6.283043	time 1.2752 (1.8298)	loss 4.0196 (3.8548)	grad_norm 0.4574 (0.3368)	mem 39782MB
[2023-07-07 08:05:06 RepVGG-A0] (main.py 291): INFO EPOCH 25 training takes 0:02:21
[2023-07-07 08:05:27 RepVGG-A0] (main.py 282): INFO Train: [26/300][0/78]	eta 0:27:31 lr 6.282120	time 21.1687 (21.1687)	loss 3.6688 (3.6688)	grad_norm 0.3104 (0.3104)	mem 39782MB
[2023-07-07 08:05:42 RepVGG-A0] (main.py 282): INFO Train: [26/300][10/78]	eta 0:03:44 lr 6.280962	time 1.1720 (3.3018)	loss 4.3522 (3.7955)	grad_norm 0.7122 (0.4144)	mem 39782MB
[2023-07-07 08:05:56 RepVGG-A0] (main.py 282): INFO Train: [26/300][20/78]	eta 0:02:18 lr 6.279798	time 1.1739 (2.3953)	loss 4.8371 (4.3994)	grad_norm 0.3648 (0.5107)	mem 39782MB
[2023-07-07 08:06:11 RepVGG-A0] (main.py 282): INFO Train: [26/300][30/78]	eta 0:01:41 lr 6.278629	time 1.2955 (2.1172)	loss 4.2454 (4.3827)	grad_norm 0.3739 (0.4444)	mem 39782MB
[2023-07-07 08:06:30 RepVGG-A0] (main.py 282): INFO Train: [26/300][40/78]	eta 0:01:18 lr 6.277454	time 4.5095 (2.0534)	loss 3.9883 (4.3134)	grad_norm 0.2316 (0.4091)	mem 39782MB
[2023-07-07 08:06:45 RepVGG-A0] (main.py 282): INFO Train: [26/300][50/78]	eta 0:00:54 lr 6.276274	time 1.1747 (1.9408)	loss 3.8284 (4.2316)	grad_norm 0.2624 (0.3826)	mem 39782MB
[2023-07-07 08:07:00 RepVGG-A0] (main.py 282): INFO Train: [26/300][60/78]	eta 0:00:33 lr 6.275088	time 1.1803 (1.8737)	loss 3.8603 (4.1581)	grad_norm 0.3173 (0.3659)	mem 39782MB
[2023-07-07 08:07:14 RepVGG-A0] (main.py 282): INFO Train: [26/300][70/78]	eta 0:00:14 lr 6.273897	time 1.1714 (1.8125)	loss 3.6785 (4.0962)	grad_norm 0.3091 (0.3571)	mem 39782MB
[2023-07-07 08:07:26 RepVGG-A0] (main.py 291): INFO EPOCH 26 training takes 0:02:20
[2023-07-07 08:07:48 RepVGG-A0] (main.py 282): INFO Train: [27/300][0/78]	eta 0:27:51 lr 6.272940	time 21.4231 (21.4231)	loss 3.6281 (3.6281)	grad_norm 0.3342 (0.3342)	mem 39782MB
[2023-07-07 08:08:03 RepVGG-A0] (main.py 282): INFO Train: [27/300][10/78]	eta 0:03:43 lr 6.271738	time 1.1695 (3.2935)	loss 3.8324 (3.7083)	grad_norm 0.3630 (0.3613)	mem 39782MB
[2023-07-07 08:08:17 RepVGG-A0] (main.py 282): INFO Train: [27/300][20/78]	eta 0:02:20 lr 6.270532	time 1.1786 (2.4283)	loss 3.7502 (3.7303)	grad_norm 0.3418 (0.3543)	mem 39782MB
[2023-07-07 08:08:32 RepVGG-A0] (main.py 282): INFO Train: [27/300][30/78]	eta 0:01:41 lr 6.269319	time 1.1358 (2.1203)	loss 3.6024 (3.6985)	grad_norm 0.3159 (0.3384)	mem 39782MB
[2023-07-07 08:08:50 RepVGG-A0] (main.py 282): INFO Train: [27/300][40/78]	eta 0:01:17 lr 6.268101	time 3.0167 (2.0451)	loss 4.0429 (3.7131)	grad_norm 0.5404 (0.3534)	mem 39782MB
[2023-07-07 08:09:05 RepVGG-A0] (main.py 282): INFO Train: [27/300][50/78]	eta 0:00:54 lr 6.266878	time 1.3052 (1.9359)	loss 4.0170 (3.8141)	grad_norm 0.3163 (0.3780)	mem 39782MB
[2023-07-07 08:09:20 RepVGG-A0] (main.py 282): INFO Train: [27/300][60/78]	eta 0:00:33 lr 6.265649	time 1.1768 (1.8607)	loss 3.6931 (3.8082)	grad_norm 0.2731 (0.3623)	mem 39782MB
[2023-07-07 08:09:35 RepVGG-A0] (main.py 282): INFO Train: [27/300][70/78]	eta 0:00:14 lr 6.264414	time 1.1712 (1.8121)	loss 3.6353 (3.7845)	grad_norm 0.3163 (0.3513)	mem 39782MB
[2023-07-07 08:09:47 RepVGG-A0] (main.py 291): INFO EPOCH 27 training takes 0:02:20
[2023-07-07 08:10:09 RepVGG-A0] (main.py 282): INFO Train: [28/300][0/78]	eta 0:28:16 lr 6.263422	time 21.7554 (21.7554)	loss 3.6096 (3.6096)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 08:10:24 RepVGG-A0] (main.py 282): INFO Train: [28/300][10/78]	eta 0:03:48 lr 6.262178	time 1.1716 (3.3633)	loss 3.5381 (3.5727)	grad_norm 0.3147 (0.2939)	mem 39782MB
[2023-07-07 08:10:39 RepVGG-A0] (main.py 282): INFO Train: [28/300][20/78]	eta 0:02:21 lr 6.260928	time 1.3876 (2.4479)	loss 3.6768 (3.5930)	grad_norm 0.3378 (0.3093)	mem 39782MB
[2023-07-07 08:10:53 RepVGG-A0] (main.py 282): INFO Train: [28/300][30/78]	eta 0:01:41 lr 6.259672	time 1.1710 (2.1218)	loss 3.6992 (3.6319)	grad_norm 0.3801 (0.3378)	mem 39782MB
[2023-07-07 08:11:11 RepVGG-A0] (main.py 282): INFO Train: [28/300][40/78]	eta 0:01:17 lr 6.258411	time 3.5861 (2.0493)	loss 3.6049 (3.6333)	grad_norm 0.3011 (0.3368)	mem 39782MB
[2023-07-07 08:11:26 RepVGG-A0] (main.py 282): INFO Train: [28/300][50/78]	eta 0:00:54 lr 6.257145	time 1.1713 (1.9394)	loss 3.7070 (3.6291)	grad_norm 0.3926 (0.3398)	mem 39782MB
[2023-07-07 08:11:41 RepVGG-A0] (main.py 282): INFO Train: [28/300][60/78]	eta 0:00:33 lr 6.255873	time 1.2758 (1.8638)	loss 3.5966 (3.6330)	grad_norm 0.3168 (0.3440)	mem 39782MB
[2023-07-07 08:11:56 RepVGG-A0] (main.py 282): INFO Train: [28/300][70/78]	eta 0:00:14 lr 6.254595	time 1.1256 (1.8183)	loss 3.5780 (3.6221)	grad_norm 0.3334 (0.3408)	mem 39782MB
[2023-07-07 08:12:09 RepVGG-A0] (main.py 291): INFO EPOCH 28 training takes 0:02:21
[2023-07-07 08:12:31 RepVGG-A0] (main.py 282): INFO Train: [29/300][0/78]	eta 0:28:40 lr 6.253569	time 22.0604 (22.0604)	loss 3.5287 (3.5287)	grad_norm 0.3577 (0.3577)	mem 39782MB
[2023-07-07 08:12:45 RepVGG-A0] (main.py 282): INFO Train: [29/300][10/78]	eta 0:03:45 lr 6.252282	time 1.1717 (3.3178)	loss 6.1370 (4.6389)	grad_norm 0.7011 (0.6846)	mem 39782MB
[2023-07-07 08:13:00 RepVGG-A0] (main.py 282): INFO Train: [29/300][20/78]	eta 0:02:20 lr 6.250989	time 1.1897 (2.4176)	loss 5.0136 (5.0578)	grad_norm 0.3091 (0.5526)	mem 39782MB
[2023-07-07 08:13:15 RepVGG-A0] (main.py 282): INFO Train: [29/300][30/78]	eta 0:01:42 lr 6.249690	time 1.5373 (2.1269)	loss 4.5139 (4.9457)	grad_norm 0.3007 (0.4655)	mem 39782MB
[2023-07-07 08:13:33 RepVGG-A0] (main.py 282): INFO Train: [29/300][40/78]	eta 0:01:18 lr 6.248386	time 4.6186 (2.0596)	loss 4.2161 (4.7945)	grad_norm 0.2924 (0.4179)	mem 39782MB
[2023-07-07 08:13:48 RepVGG-A0] (main.py 282): INFO Train: [29/300][50/78]	eta 0:00:54 lr 6.247077	time 1.1742 (1.9463)	loss 4.0907 (4.6651)	grad_norm 0.3205 (0.3931)	mem 39782MB
[2023-07-07 08:14:04 RepVGG-A0] (main.py 282): INFO Train: [29/300][60/78]	eta 0:00:33 lr 6.245762	time 1.2825 (1.8841)	loss 3.8540 (4.5569)	grad_norm 0.3041 (0.3779)	mem 39782MB
[2023-07-07 08:14:18 RepVGG-A0] (main.py 282): INFO Train: [29/300][70/78]	eta 0:00:14 lr 6.244441	time 1.2719 (1.8195)	loss 3.8775 (4.4693)	grad_norm 0.2823 (0.3697)	mem 39782MB
[2023-07-07 08:14:31 RepVGG-A0] (main.py 291): INFO EPOCH 29 training takes 0:02:21
[2023-07-07 08:14:51 RepVGG-A0] (main.py 282): INFO Train: [30/300][0/78]	eta 0:27:09 lr 6.243381	time 20.8902 (20.8902)	loss 3.8530 (3.8530)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 08:15:06 RepVGG-A0] (main.py 282): INFO Train: [30/300][10/78]	eta 0:03:38 lr 6.242051	time 1.1704 (3.2170)	loss 3.8306 (3.8160)	grad_norm 0.3725 (0.3390)	mem 39782MB
[2023-07-07 08:15:20 RepVGG-A0] (main.py 282): INFO Train: [30/300][20/78]	eta 0:02:17 lr 6.240715	time 1.1910 (2.3771)	loss 3.7954 (3.8185)	grad_norm 0.3284 (0.3372)	mem 39782MB
[2023-07-07 08:15:35 RepVGG-A0] (main.py 282): INFO Train: [30/300][30/78]	eta 0:01:39 lr 6.239373	time 1.2286 (2.0714)	loss 3.7428 (3.8080)	grad_norm 0.3047 (0.3383)	mem 39782MB
[2023-07-07 08:15:53 RepVGG-A0] (main.py 282): INFO Train: [30/300][40/78]	eta 0:01:16 lr 6.238027	time 5.4882 (2.0211)	loss 3.8397 (3.7998)	grad_norm 0.3972 (0.3407)	mem 39782MB
[2023-07-07 08:16:08 RepVGG-A0] (main.py 282): INFO Train: [30/300][50/78]	eta 0:00:53 lr 6.236674	time 1.1730 (1.9156)	loss 3.6713 (3.7869)	grad_norm 0.3080 (0.3382)	mem 39782MB
[2023-07-07 08:16:24 RepVGG-A0] (main.py 282): INFO Train: [30/300][60/78]	eta 0:00:33 lr 6.235317	time 1.1802 (1.8629)	loss 3.7609 (3.7844)	grad_norm 0.3292 (0.3433)	mem 39782MB
[2023-07-07 08:16:38 RepVGG-A0] (main.py 282): INFO Train: [30/300][70/78]	eta 0:00:14 lr 6.233953	time 1.4133 (1.8018)	loss 3.9999 (3.7823)	grad_norm 0.4951 (0.3462)	mem 39782MB
[2023-07-07 08:16:50 RepVGG-A0] (main.py 291): INFO EPOCH 30 training takes 0:02:19
[2023-07-07 08:17:12 RepVGG-A0] (main.py 282): INFO Train: [31/300][0/78]	eta 0:28:23 lr 6.232859	time 21.8361 (21.8361)	loss 5.2665 (5.2665)	grad_norm 0.5897 (0.5897)	mem 39782MB
[2023-07-07 08:17:27 RepVGG-A0] (main.py 282): INFO Train: [31/300][10/78]	eta 0:03:49 lr 6.231486	time 1.1722 (3.3797)	loss 4.1940 (4.6335)	grad_norm 0.2788 (0.3600)	mem 39782MB
[2023-07-07 08:17:42 RepVGG-A0] (main.py 282): INFO Train: [31/300][20/78]	eta 0:02:22 lr 6.230107	time 1.1264 (2.4643)	loss 3.9899 (4.3932)	grad_norm 0.3201 (0.3397)	mem 39782MB
[2023-07-07 08:17:57 RepVGG-A0] (main.py 282): INFO Train: [31/300][30/78]	eta 0:01:44 lr 6.228723	time 1.2290 (2.1694)	loss 3.7481 (4.2192)	grad_norm 0.2599 (0.3074)	mem 39782MB
[2023-07-07 08:18:15 RepVGG-A0] (main.py 282): INFO Train: [31/300][40/78]	eta 0:01:18 lr 6.227334	time 3.1904 (2.0717)	loss 3.7355 (4.1006)	grad_norm 0.3200 (0.2997)	mem 39782MB
[2023-07-07 08:18:30 RepVGG-A0] (main.py 282): INFO Train: [31/300][50/78]	eta 0:00:54 lr 6.225939	time 1.1708 (1.9580)	loss 3.6764 (4.0346)	grad_norm 0.3230 (0.3059)	mem 39782MB
[2023-07-07 08:18:45 RepVGG-A0] (main.py 282): INFO Train: [31/300][60/78]	eta 0:00:33 lr 6.224539	time 1.1789 (1.8820)	loss 3.7164 (3.9804)	grad_norm 0.3415 (0.3073)	mem 39782MB
[2023-07-07 08:19:00 RepVGG-A0] (main.py 282): INFO Train: [31/300][70/78]	eta 0:00:14 lr 6.223133	time 1.2259 (1.8338)	loss 3.6850 (3.9380)	grad_norm 0.3307 (0.3094)	mem 39782MB
[2023-07-07 08:19:11 RepVGG-A0] (main.py 291): INFO EPOCH 31 training takes 0:02:21
[2023-07-07 08:19:32 RepVGG-A0] (main.py 282): INFO Train: [32/300][0/78]	eta 0:27:11 lr 6.222004	time 20.9114 (20.9114)	loss 3.6912 (3.6912)	grad_norm 0.3058 (0.3058)	mem 39782MB
[2023-07-07 08:19:46 RepVGG-A0] (main.py 282): INFO Train: [32/300][10/78]	eta 0:03:35 lr 6.220589	time 1.1720 (3.1645)	loss 3.7049 (3.7247)	grad_norm 0.3673 (0.3759)	mem 39782MB
[2023-07-07 08:20:02 RepVGG-A0] (main.py 282): INFO Train: [32/300][20/78]	eta 0:02:19 lr 6.219168	time 1.1753 (2.4014)	loss 3.6097 (3.6870)	grad_norm 0.2875 (0.3475)	mem 39782MB
[2023-07-07 08:20:17 RepVGG-A0] (main.py 282): INFO Train: [32/300][30/78]	eta 0:01:42 lr 6.217741	time 1.4200 (2.1341)	loss 3.4896 (3.6680)	grad_norm 0.3112 (0.3431)	mem 39782MB
[2023-07-07 08:20:35 RepVGG-A0] (main.py 282): INFO Train: [32/300][40/78]	eta 0:01:17 lr 6.216309	time 4.7973 (2.0498)	loss 3.8549 (3.6735)	grad_norm 0.4289 (0.3510)	mem 39782MB
[2023-07-07 08:20:50 RepVGG-A0] (main.py 282): INFO Train: [32/300][50/78]	eta 0:00:54 lr 6.214872	time 1.1739 (1.9413)	loss 3.7816 (3.6728)	grad_norm 0.4604 (0.3518)	mem 39782MB
[2023-07-07 08:21:05 RepVGG-A0] (main.py 282): INFO Train: [32/300][60/78]	eta 0:00:33 lr 6.213429	time 1.3372 (1.8707)	loss 3.6613 (3.6861)	grad_norm 0.3088 (0.3563)	mem 39782MB
[2023-07-07 08:21:20 RepVGG-A0] (main.py 282): INFO Train: [32/300][70/78]	eta 0:00:14 lr 6.211981	time 1.1249 (1.8180)	loss 3.5388 (3.6677)	grad_norm 0.3149 (0.3469)	mem 39782MB
[2023-07-07 08:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 32 training takes 0:02:21
[2023-07-07 08:21:54 RepVGG-A0] (main.py 282): INFO Train: [33/300][0/78]	eta 0:27:58 lr 6.210818	time 21.5180 (21.5180)	loss 4.0180 (4.0180)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 08:22:09 RepVGG-A0] (main.py 282): INFO Train: [33/300][10/78]	eta 0:03:45 lr 6.209360	time 1.1727 (3.3136)	loss 5.4979 (4.9000)	grad_norm 0.5298 (0.7022)	mem 39782MB
[2023-07-07 08:22:24 RepVGG-A0] (main.py 282): INFO Train: [33/300][20/78]	eta 0:02:21 lr 6.207897	time 1.2864 (2.4470)	loss 4.3870 (4.8392)	grad_norm 0.2923 (0.5366)	mem 39782MB
[2023-07-07 08:22:39 RepVGG-A0] (main.py 282): INFO Train: [33/300][30/78]	eta 0:01:43 lr 6.206428	time 1.1884 (2.1519)	loss 3.9933 (4.6184)	grad_norm 0.2446 (0.4461)	mem 39782MB
[2023-07-07 08:22:57 RepVGG-A0] (main.py 282): INFO Train: [33/300][40/78]	eta 0:01:18 lr 6.204954	time 3.4797 (2.0635)	loss 4.0141 (4.4581)	grad_norm 0.3565 (0.4098)	mem 39782MB
[2023-07-07 08:23:12 RepVGG-A0] (main.py 282): INFO Train: [33/300][50/78]	eta 0:00:54 lr 6.203474	time 1.2416 (1.9550)	loss 3.8094 (4.3370)	grad_norm 0.2677 (0.3821)	mem 39782MB
[2023-07-07 08:23:27 RepVGG-A0] (main.py 282): INFO Train: [33/300][60/78]	eta 0:00:33 lr 6.201989	time 1.3372 (1.8789)	loss 3.7666 (4.2407)	grad_norm 0.3083 (0.3665)	mem 39782MB
[2023-07-07 08:23:42 RepVGG-A0] (main.py 282): INFO Train: [33/300][70/78]	eta 0:00:14 lr 6.200499	time 1.2388 (1.8299)	loss 3.6920 (4.1687)	grad_norm 0.3201 (0.3605)	mem 39782MB
[2023-07-07 08:23:54 RepVGG-A0] (main.py 291): INFO EPOCH 33 training takes 0:02:21
[2023-07-07 08:24:16 RepVGG-A0] (main.py 282): INFO Train: [34/300][0/78]	eta 0:29:19 lr 6.199302	time 22.5593 (22.5593)	loss 3.5786 (3.5786)	grad_norm 0.2979 (0.2979)	mem 39782MB
[2023-07-07 08:24:31 RepVGG-A0] (main.py 282): INFO Train: [34/300][10/78]	eta 0:03:49 lr 6.197802	time 1.1731 (3.3769)	loss 3.6688 (3.6295)	grad_norm 0.3314 (0.3289)	mem 39782MB
[2023-07-07 08:24:46 RepVGG-A0] (main.py 282): INFO Train: [34/300][20/78]	eta 0:02:23 lr 6.196296	time 1.5274 (2.4783)	loss 3.8616 (3.7064)	grad_norm 0.4196 (0.3657)	mem 39782MB
[2023-07-07 08:25:00 RepVGG-A0] (main.py 282): INFO Train: [34/300][30/78]	eta 0:01:43 lr 6.194785	time 1.1811 (2.1474)	loss 3.6362 (3.6943)	grad_norm 0.3606 (0.3504)	mem 39782MB
[2023-07-07 08:25:17 RepVGG-A0] (main.py 282): INFO Train: [34/300][40/78]	eta 0:01:17 lr 6.193269	time 3.3720 (2.0351)	loss 3.6532 (3.6873)	grad_norm 0.3824 (0.3458)	mem 39782MB
[2023-07-07 08:25:32 RepVGG-A0] (main.py 282): INFO Train: [34/300][50/78]	eta 0:00:54 lr 6.191747	time 1.1772 (1.9326)	loss 3.6942 (3.6773)	grad_norm 0.3597 (0.3452)	mem 39782MB
[2023-07-07 08:25:47 RepVGG-A0] (main.py 282): INFO Train: [34/300][60/78]	eta 0:00:33 lr 6.190220	time 1.3179 (1.8590)	loss 3.6198 (3.6685)	grad_norm 0.3250 (0.3445)	mem 39782MB
[2023-07-07 08:26:02 RepVGG-A0] (main.py 282): INFO Train: [34/300][70/78]	eta 0:00:14 lr 6.188687	time 1.1718 (1.8013)	loss 3.7023 (3.6590)	grad_norm 0.4421 (0.3453)	mem 39782MB
[2023-07-07 08:26:14 RepVGG-A0] (main.py 291): INFO EPOCH 34 training takes 0:02:20
[2023-07-07 08:26:35 RepVGG-A0] (main.py 282): INFO Train: [35/300][0/78]	eta 0:27:19 lr 6.187457	time 21.0136 (21.0136)	loss 3.5949 (3.5949)	grad_norm 0.3010 (0.3010)	mem 39782MB
[2023-07-07 08:26:51 RepVGG-A0] (main.py 282): INFO Train: [35/300][10/78]	eta 0:03:46 lr 6.185915	time 1.1713 (3.3331)	loss 3.7783 (3.5775)	grad_norm 0.4171 (0.3401)	mem 39782MB
[2023-07-07 08:27:05 RepVGG-A0] (main.py 282): INFO Train: [35/300][20/78]	eta 0:02:22 lr 6.184367	time 1.1928 (2.4487)	loss 3.5072 (3.5871)	grad_norm 0.3161 (0.3442)	mem 39782MB
[2023-07-07 08:27:20 RepVGG-A0] (main.py 282): INFO Train: [35/300][30/78]	eta 0:01:42 lr 6.182814	time 1.2659 (2.1329)	loss 3.6038 (3.5678)	grad_norm 0.3487 (0.3416)	mem 39782MB
[2023-07-07 08:27:39 RepVGG-A0] (main.py 282): INFO Train: [35/300][40/78]	eta 0:01:18 lr 6.181256	time 3.2799 (2.0602)	loss 3.5462 (3.5693)	grad_norm 0.3401 (0.3428)	mem 39782MB
[2023-07-07 08:27:53 RepVGG-A0] (main.py 282): INFO Train: [35/300][50/78]	eta 0:00:54 lr 6.179692	time 1.1836 (1.9494)	loss 3.5565 (3.5808)	grad_norm 0.2910 (0.3484)	mem 39782MB
[2023-07-07 08:28:10 RepVGG-A0] (main.py 282): INFO Train: [35/300][60/78]	eta 0:00:34 lr 6.178123	time 1.3545 (1.9021)	loss 3.7033 (3.5749)	grad_norm 0.4451 (0.3473)	mem 39782MB
[2023-07-07 08:28:24 RepVGG-A0] (main.py 282): INFO Train: [35/300][70/78]	eta 0:00:14 lr 6.176548	time 1.1262 (1.8233)	loss 5.9431 (3.7929)	grad_norm 0.6339 (0.4042)	mem 39782MB
[2023-07-07 08:28:36 RepVGG-A0] (main.py 291): INFO EPOCH 35 training takes 0:02:22
[2023-07-07 08:28:57 RepVGG-A0] (main.py 282): INFO Train: [36/300][0/78]	eta 0:27:33 lr 6.175285	time 21.1970 (21.1970)	loss 5.1452 (5.1452)	grad_norm 0.3020 (0.3020)	mem 39782MB
[2023-07-07 08:29:13 RepVGG-A0] (main.py 282): INFO Train: [36/300][10/78]	eta 0:03:49 lr 6.173701	time 1.1727 (3.3738)	loss 4.5175 (4.8161)	grad_norm 0.2546 (0.2981)	mem 39782MB
[2023-07-07 08:29:29 RepVGG-A0] (main.py 282): INFO Train: [36/300][20/78]	eta 0:02:25 lr 6.172111	time 1.1792 (2.5075)	loss 4.1973 (4.5953)	grad_norm 0.2571 (0.2900)	mem 39782MB
[2023-07-07 08:29:45 RepVGG-A0] (main.py 282): INFO Train: [36/300][30/78]	eta 0:01:45 lr 6.170516	time 1.3836 (2.2055)	loss 4.0762 (4.4670)	grad_norm 0.2667 (0.2970)	mem 39782MB
[2023-07-07 08:30:02 RepVGG-A0] (main.py 282): INFO Train: [36/300][40/78]	eta 0:01:19 lr 6.168916	time 2.8424 (2.0950)	loss 3.8875 (4.3440)	grad_norm 0.2985 (0.2937)	mem 39782MB
[2023-07-07 08:30:17 RepVGG-A0] (main.py 282): INFO Train: [36/300][50/78]	eta 0:00:55 lr 6.167310	time 1.1718 (1.9846)	loss 3.8711 (4.2629)	grad_norm 0.2791 (0.2976)	mem 39782MB
[2023-07-07 08:30:32 RepVGG-A0] (main.py 282): INFO Train: [36/300][60/78]	eta 0:00:34 lr 6.165699	time 1.1734 (1.8949)	loss 3.7107 (4.1960)	grad_norm 0.2899 (0.3001)	mem 39782MB
[2023-07-07 08:30:47 RepVGG-A0] (main.py 282): INFO Train: [36/300][70/78]	eta 0:00:14 lr 6.164083	time 1.5064 (1.8481)	loss 3.9627 (4.1514)	grad_norm 0.3755 (0.3072)	mem 39782MB
[2023-07-07 08:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 36 training takes 0:02:21
[2023-07-07 08:31:20 RepVGG-A0] (main.py 282): INFO Train: [37/300][0/78]	eta 0:27:48 lr 6.162786	time 21.3926 (21.3926)	loss 3.6945 (3.6945)	grad_norm 0.2641 (0.2641)	mem 39782MB
[2023-07-07 08:31:35 RepVGG-A0] (main.py 282): INFO Train: [37/300][10/78]	eta 0:03:50 lr 6.161160	time 1.1716 (3.3844)	loss 4.2034 (3.8633)	grad_norm 0.5285 (0.3896)	mem 39782MB
[2023-07-07 08:31:51 RepVGG-A0] (main.py 282): INFO Train: [37/300][20/78]	eta 0:02:24 lr 6.159529	time 1.2102 (2.4925)	loss 3.7974 (3.8765)	grad_norm 0.2866 (0.3609)	mem 39782MB
[2023-07-07 08:32:05 RepVGG-A0] (main.py 282): INFO Train: [37/300][30/78]	eta 0:01:44 lr 6.157892	time 1.2202 (2.1689)	loss 3.6929 (3.8167)	grad_norm 0.3098 (0.3445)	mem 39782MB
[2023-07-07 08:32:24 RepVGG-A0] (main.py 282): INFO Train: [37/300][40/78]	eta 0:01:19 lr 6.156250	time 4.1150 (2.0816)	loss 3.8981 (3.7956)	grad_norm 0.4558 (0.3483)	mem 39782MB
[2023-07-07 08:32:38 RepVGG-A0] (main.py 282): INFO Train: [37/300][50/78]	eta 0:00:55 lr 6.154603	time 1.1739 (1.9646)	loss 3.6571 (3.7794)	grad_norm 0.3601 (0.3421)	mem 39782MB
[2023-07-07 08:32:54 RepVGG-A0] (main.py 282): INFO Train: [37/300][60/78]	eta 0:00:34 lr 6.152950	time 1.1753 (1.8958)	loss 3.4863 (3.7656)	grad_norm 0.2920 (0.3431)	mem 39782MB
[2023-07-07 08:33:09 RepVGG-A0] (main.py 282): INFO Train: [37/300][70/78]	eta 0:00:14 lr 6.151292	time 1.3201 (1.8461)	loss 3.7442 (3.7484)	grad_norm 0.3624 (0.3397)	mem 39782MB
[2023-07-07 08:33:21 RepVGG-A0] (main.py 291): INFO EPOCH 37 training takes 0:02:22
[2023-07-07 08:33:41 RepVGG-A0] (main.py 282): INFO Train: [38/300][0/78]	eta 0:26:34 lr 6.149962	time 20.4363 (20.4363)	loss 4.0880 (4.0880)	grad_norm 0.4791 (0.4791)	mem 39782MB
[2023-07-07 08:33:55 RepVGG-A0] (main.py 282): INFO Train: [38/300][10/78]	eta 0:03:34 lr 6.148295	time 1.1955 (3.1526)	loss 3.6697 (3.8304)	grad_norm 0.3382 (0.3775)	mem 39782MB
[2023-07-07 08:34:11 RepVGG-A0] (main.py 282): INFO Train: [38/300][20/78]	eta 0:02:17 lr 6.146622	time 1.1702 (2.3765)	loss 3.6414 (3.8252)	grad_norm 0.3023 (0.3812)	mem 39782MB
[2023-07-07 08:34:27 RepVGG-A0] (main.py 282): INFO Train: [38/300][30/78]	eta 0:01:42 lr 6.144944	time 1.3991 (2.1288)	loss 3.6524 (3.7474)	grad_norm 0.3173 (0.3514)	mem 39782MB
[2023-07-07 08:34:44 RepVGG-A0] (main.py 282): INFO Train: [38/300][40/78]	eta 0:01:17 lr 6.143260	time 3.2543 (2.0435)	loss 3.7609 (3.7199)	grad_norm 0.4193 (0.3488)	mem 39782MB
[2023-07-07 08:35:00 RepVGG-A0] (main.py 282): INFO Train: [38/300][50/78]	eta 0:00:54 lr 6.141571	time 1.1736 (1.9398)	loss 3.5478 (3.7180)	grad_norm 0.2784 (0.3514)	mem 39782MB
[2023-07-07 08:35:14 RepVGG-A0] (main.py 282): INFO Train: [38/300][60/78]	eta 0:00:33 lr 6.139877	time 1.2932 (1.8574)	loss 3.6719 (3.6960)	grad_norm 0.4043 (0.3475)	mem 39782MB
[2023-07-07 08:35:29 RepVGG-A0] (main.py 282): INFO Train: [38/300][70/78]	eta 0:00:14 lr 6.138178	time 1.3520 (1.8027)	loss 3.5405 (3.6860)	grad_norm 0.3260 (0.3473)	mem 39782MB
[2023-07-07 08:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 38 training takes 0:02:19
[2023-07-07 08:36:00 RepVGG-A0] (main.py 282): INFO Train: [39/300][0/78]	eta 0:25:37 lr 6.136815	time 19.7141 (19.7141)	loss 3.5508 (3.5508)	grad_norm 0.3211 (0.3211)	mem 39782MB
[2023-07-07 08:36:16 RepVGG-A0] (main.py 282): INFO Train: [39/300][10/78]	eta 0:03:42 lr 6.135106	time 1.1715 (3.2736)	loss 3.9544 (3.7099)	grad_norm 0.5231 (0.4356)	mem 39782MB
[2023-07-07 08:36:32 RepVGG-A0] (main.py 282): INFO Train: [39/300][20/78]	eta 0:02:21 lr 6.133392	time 1.1829 (2.4403)	loss 3.6096 (3.7364)	grad_norm 0.2831 (0.4031)	mem 39782MB
[2023-07-07 08:36:47 RepVGG-A0] (main.py 282): INFO Train: [39/300][30/78]	eta 0:01:43 lr 6.131672	time 1.2304 (2.1496)	loss 3.4917 (3.6669)	grad_norm 0.3069 (0.3710)	mem 39782MB
[2023-07-07 08:37:05 RepVGG-A0] (main.py 282): INFO Train: [39/300][40/78]	eta 0:01:18 lr 6.129948	time 3.7468 (2.0633)	loss 3.5782 (3.6466)	grad_norm 0.3971 (0.3680)	mem 39782MB
[2023-07-07 08:37:20 RepVGG-A0] (main.py 282): INFO Train: [39/300][50/78]	eta 0:00:54 lr 6.128218	time 1.2062 (1.9574)	loss 3.4618 (3.6254)	grad_norm 0.3044 (0.3579)	mem 39782MB
[2023-07-07 08:37:35 RepVGG-A0] (main.py 282): INFO Train: [39/300][60/78]	eta 0:00:33 lr 6.126482	time 1.2489 (1.8844)	loss 3.6712 (3.6200)	grad_norm 0.4063 (0.3590)	mem 39782MB
[2023-07-07 08:37:50 RepVGG-A0] (main.py 282): INFO Train: [39/300][70/78]	eta 0:00:14 lr 6.124742	time 1.2409 (1.8263)	loss 5.9884 (3.7876)	grad_norm 0.7251 (0.4069)	mem 39782MB
[2023-07-07 08:38:02 RepVGG-A0] (main.py 291): INFO EPOCH 39 training takes 0:02:21
[2023-07-07 08:38:24 RepVGG-A0] (main.py 282): INFO Train: [40/300][0/78]	eta 0:28:12 lr 6.123345	time 21.6964 (21.6964)	loss 4.9534 (4.9534)	grad_norm 0.3385 (0.3385)	mem 39782MB
[2023-07-07 08:38:38 RepVGG-A0] (main.py 282): INFO Train: [40/300][10/78]	eta 0:03:44 lr 6.121595	time 1.1909 (3.2949)	loss 4.3665 (4.7123)	grad_norm 0.2171 (0.3292)	mem 39782MB
[2023-07-07 08:38:54 RepVGG-A0] (main.py 282): INFO Train: [40/300][20/78]	eta 0:02:22 lr 6.119840	time 1.2022 (2.4641)	loss 4.1585 (4.4733)	grad_norm 0.2960 (0.2941)	mem 39782MB
[2023-07-07 08:39:09 RepVGG-A0] (main.py 282): INFO Train: [40/300][30/78]	eta 0:01:43 lr 6.118080	time 1.1859 (2.1490)	loss 4.0169 (4.3241)	grad_norm 0.3498 (0.2936)	mem 39782MB
[2023-07-07 08:39:26 RepVGG-A0] (main.py 282): INFO Train: [40/300][40/78]	eta 0:01:18 lr 6.116314	time 4.2737 (2.0583)	loss 3.8446 (4.2210)	grad_norm 0.2709 (0.2886)	mem 39782MB
[2023-07-07 08:39:42 RepVGG-A0] (main.py 282): INFO Train: [40/300][50/78]	eta 0:00:54 lr 6.114543	time 1.1723 (1.9532)	loss 3.9626 (4.1524)	grad_norm 0.3507 (0.2931)	mem 39782MB
[2023-07-07 08:39:56 RepVGG-A0] (main.py 282): INFO Train: [40/300][60/78]	eta 0:00:33 lr 6.112766	time 1.2663 (1.8615)	loss 3.7555 (4.0992)	grad_norm 0.2797 (0.2978)	mem 39782MB
[2023-07-07 08:40:11 RepVGG-A0] (main.py 282): INFO Train: [40/300][70/78]	eta 0:00:14 lr 6.110985	time 1.1771 (1.8150)	loss 3.9953 (4.0594)	grad_norm 0.4053 (0.3037)	mem 39782MB
[2023-07-07 08:40:22 RepVGG-A0] (main.py 291): INFO EPOCH 40 training takes 0:02:20
[2023-07-07 08:40:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.009 (17.009)	Loss 3.4978 (3.4978)	Acc@1 30.176 (30.176)	Acc@5 54.333 (54.333)	Mem 39782MB
[2023-07-07 08:40:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 30.152 Acc@5 53.964
[2023-07-07 08:40:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 40: 30.152%
[2023-07-07 08:40:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 08:41:03 RepVGG-A0] (main.py 282): INFO Train: [41/300][0/78]	eta 0:28:13 lr 6.109556	time 21.7121 (21.7121)	loss 3.6493 (3.6493)	grad_norm 0.2828 (0.2828)	mem 39782MB
[2023-07-07 08:41:17 RepVGG-A0] (main.py 282): INFO Train: [41/300][10/78]	eta 0:03:43 lr 6.107765	time 1.1714 (3.2877)	loss 3.6738 (3.6767)	grad_norm 0.3373 (0.3208)	mem 39782MB
[2023-07-07 08:41:33 RepVGG-A0] (main.py 282): INFO Train: [41/300][20/78]	eta 0:02:23 lr 6.105968	time 1.3569 (2.4781)	loss 3.6233 (3.6619)	grad_norm 0.3243 (0.3212)	mem 39782MB
[2023-07-07 08:41:48 RepVGG-A0] (main.py 282): INFO Train: [41/300][30/78]	eta 0:01:42 lr 6.104167	time 1.6795 (2.1438)	loss 3.6720 (3.6895)	grad_norm 0.3527 (0.3398)	mem 39782MB
[2023-07-07 08:42:06 RepVGG-A0] (main.py 282): INFO Train: [41/300][40/78]	eta 0:01:18 lr 6.102360	time 4.4624 (2.0710)	loss 4.7723 (3.7865)	grad_norm 0.7509 (0.3882)	mem 39782MB
[2023-07-07 08:42:21 RepVGG-A0] (main.py 282): INFO Train: [41/300][50/78]	eta 0:00:54 lr 6.100548	time 1.1842 (1.9571)	loss 4.1560 (3.9364)	grad_norm 0.2980 (0.4007)	mem 39782MB
[2023-07-07 08:42:36 RepVGG-A0] (main.py 282): INFO Train: [41/300][60/78]	eta 0:00:33 lr 6.098731	time 1.3618 (1.8812)	loss 3.8379 (3.9328)	grad_norm 0.2564 (0.3769)	mem 39782MB
[2023-07-07 08:42:51 RepVGG-A0] (main.py 282): INFO Train: [41/300][70/78]	eta 0:00:14 lr 6.096908	time 1.1783 (1.8247)	loss 3.7875 (3.9131)	grad_norm 0.2968 (0.3665)	mem 39782MB
[2023-07-07 08:43:03 RepVGG-A0] (main.py 291): INFO EPOCH 41 training takes 0:02:21
[2023-07-07 08:43:23 RepVGG-A0] (main.py 282): INFO Train: [42/300][0/78]	eta 0:26:06 lr 6.095447	time 20.0849 (20.0849)	loss 3.5871 (3.5871)	grad_norm 0.2683 (0.2683)	mem 39782MB
[2023-07-07 08:43:39 RepVGG-A0] (main.py 282): INFO Train: [42/300][10/78]	eta 0:03:45 lr 6.093615	time 1.1711 (3.3113)	loss 3.6040 (3.6281)	grad_norm 0.3046 (0.3101)	mem 39782MB
[2023-07-07 08:43:54 RepVGG-A0] (main.py 282): INFO Train: [42/300][20/78]	eta 0:02:22 lr 6.091778	time 1.2062 (2.4546)	loss 3.6690 (3.6327)	grad_norm 0.3314 (0.3194)	mem 39782MB
[2023-07-07 08:44:10 RepVGG-A0] (main.py 282): INFO Train: [42/300][30/78]	eta 0:01:43 lr 6.089935	time 2.0507 (2.1658)	loss 3.6708 (3.6199)	grad_norm 0.3844 (0.3224)	mem 39782MB
[2023-07-07 08:44:27 RepVGG-A0] (main.py 282): INFO Train: [42/300][40/78]	eta 0:01:18 lr 6.088088	time 2.5243 (2.0634)	loss 3.6878 (3.6303)	grad_norm 0.3619 (0.3305)	mem 39782MB
[2023-07-07 08:44:43 RepVGG-A0] (main.py 282): INFO Train: [42/300][50/78]	eta 0:00:54 lr 6.086235	time 1.1657 (1.9584)	loss 3.5578 (3.6216)	grad_norm 0.3298 (0.3319)	mem 39782MB
[2023-07-07 08:44:58 RepVGG-A0] (main.py 282): INFO Train: [42/300][60/78]	eta 0:00:34 lr 6.084377	time 1.1997 (1.8931)	loss 3.5761 (3.6093)	grad_norm 0.3289 (0.3301)	mem 39782MB
[2023-07-07 08:45:13 RepVGG-A0] (main.py 282): INFO Train: [42/300][70/78]	eta 0:00:14 lr 6.082514	time 1.7017 (1.8363)	loss 5.4205 (3.7389)	grad_norm 0.6171 (0.3765)	mem 39782MB
[2023-07-07 08:45:25 RepVGG-A0] (main.py 291): INFO EPOCH 42 training takes 0:02:22
[2023-07-07 08:45:48 RepVGG-A0] (main.py 282): INFO Train: [43/300][0/78]	eta 0:30:00 lr 6.081020	time 23.0772 (23.0772)	loss 4.3660 (4.3660)	grad_norm 0.2995 (0.2995)	mem 39782MB
[2023-07-07 08:46:03 RepVGG-A0] (main.py 282): INFO Train: [43/300][10/78]	eta 0:03:54 lr 6.079148	time 1.1731 (3.4540)	loss 4.0902 (4.1647)	grad_norm 0.3257 (0.2908)	mem 39782MB
[2023-07-07 08:46:19 RepVGG-A0] (main.py 282): INFO Train: [43/300][20/78]	eta 0:02:30 lr 6.077270	time 1.1728 (2.5886)	loss 3.7741 (4.0341)	grad_norm 0.2543 (0.2742)	mem 39782MB
[2023-07-07 08:46:34 RepVGG-A0] (main.py 282): INFO Train: [43/300][30/78]	eta 0:01:46 lr 6.075387	time 1.1999 (2.2145)	loss 3.7996 (3.9687)	grad_norm 0.2847 (0.2890)	mem 39782MB
[2023-07-07 08:46:52 RepVGG-A0] (main.py 282): INFO Train: [43/300][40/78]	eta 0:01:20 lr 6.073499	time 4.2272 (2.1302)	loss 3.6536 (3.8969)	grad_norm 0.2838 (0.2848)	mem 39782MB
[2023-07-07 08:47:07 RepVGG-A0] (main.py 282): INFO Train: [43/300][50/78]	eta 0:00:55 lr 6.071606	time 1.1744 (1.9981)	loss 3.6270 (3.8469)	grad_norm 0.3253 (0.2884)	mem 39782MB
[2023-07-07 08:47:24 RepVGG-A0] (main.py 282): INFO Train: [43/300][60/78]	eta 0:00:34 lr 6.069708	time 1.3980 (1.9441)	loss 3.5833 (3.8149)	grad_norm 0.3038 (0.2949)	mem 39782MB
[2023-07-07 08:47:40 RepVGG-A0] (main.py 282): INFO Train: [43/300][70/78]	eta 0:00:15 lr 6.067804	time 1.3540 (1.8975)	loss 3.6750 (3.7848)	grad_norm 0.3611 (0.2987)	mem 39782MB
[2023-07-07 08:47:50 RepVGG-A0] (main.py 291): INFO EPOCH 43 training takes 0:02:24
[2023-07-07 08:48:14 RepVGG-A0] (main.py 282): INFO Train: [44/300][0/78]	eta 0:31:02 lr 6.066278	time 23.8784 (23.8784)	loss 3.5138 (3.5138)	grad_norm 0.2954 (0.2954)	mem 39782MB
[2023-07-07 08:48:29 RepVGG-A0] (main.py 282): INFO Train: [44/300][10/78]	eta 0:03:59 lr 6.064365	time 1.1987 (3.5284)	loss 3.8271 (3.6488)	grad_norm 0.4345 (0.3724)	mem 39782MB
[2023-07-07 08:48:42 RepVGG-A0] (main.py 282): INFO Train: [44/300][20/78]	eta 0:02:25 lr 6.062447	time 1.1737 (2.5114)	loss 3.6162 (3.6510)	grad_norm 0.2973 (0.3572)	mem 39782MB
[2023-07-07 08:48:59 RepVGG-A0] (main.py 282): INFO Train: [44/300][30/78]	eta 0:01:47 lr 6.060524	time 1.5015 (2.2354)	loss 3.5274 (3.6174)	grad_norm 0.3415 (0.3459)	mem 39782MB
[2023-07-07 08:49:17 RepVGG-A0] (main.py 282): INFO Train: [44/300][40/78]	eta 0:01:20 lr 6.058595	time 3.1765 (2.1256)	loss 3.4522 (3.6014)	grad_norm 0.3129 (0.3475)	mem 39782MB
[2023-07-07 08:49:32 RepVGG-A0] (main.py 282): INFO Train: [44/300][50/78]	eta 0:00:56 lr 6.056662	time 1.1777 (2.0116)	loss 3.6502 (3.5894)	grad_norm 0.3771 (0.3424)	mem 39782MB
[2023-07-07 08:49:47 RepVGG-A0] (main.py 282): INFO Train: [44/300][60/78]	eta 0:00:34 lr 6.054723	time 1.1765 (1.9257)	loss 6.1177 (3.8331)	grad_norm 0.5306 (0.4077)	mem 39782MB
[2023-07-07 08:50:02 RepVGG-A0] (main.py 282): INFO Train: [44/300][70/78]	eta 0:00:14 lr 6.052780	time 1.6261 (1.8665)	loss 5.0469 (4.0681)	grad_norm 0.2979 (0.4005)	mem 39782MB
[2023-07-07 08:50:14 RepVGG-A0] (main.py 291): INFO EPOCH 44 training takes 0:02:24
[2023-07-07 08:50:34 RepVGG-A0] (main.py 282): INFO Train: [45/300][0/78]	eta 0:26:23 lr 6.051221	time 20.3015 (20.3015)	loss 4.8594 (4.8594)	grad_norm 0.4593 (0.4593)	mem 39782MB
[2023-07-07 08:50:49 RepVGG-A0] (main.py 282): INFO Train: [45/300][10/78]	eta 0:03:37 lr 6.049268	time 1.1708 (3.2020)	loss 4.2245 (4.4596)	grad_norm 0.2622 (0.2962)	mem 39782MB
[2023-07-07 08:51:03 RepVGG-A0] (main.py 282): INFO Train: [45/300][20/78]	eta 0:02:16 lr 6.047310	time 1.1899 (2.3461)	loss 4.1213 (4.3242)	grad_norm 0.3535 (0.3022)	mem 39782MB
[2023-07-07 08:51:18 RepVGG-A0] (main.py 282): INFO Train: [45/300][30/78]	eta 0:01:39 lr 6.045346	time 1.4488 (2.0770)	loss 4.0551 (4.2298)	grad_norm 0.3194 (0.2951)	mem 39782MB
[2023-07-07 08:51:37 RepVGG-A0] (main.py 282): INFO Train: [45/300][40/78]	eta 0:01:16 lr 6.043378	time 4.4177 (2.0145)	loss 3.9341 (4.1668)	grad_norm 0.2758 (0.3002)	mem 39782MB
[2023-07-07 08:51:51 RepVGG-A0] (main.py 282): INFO Train: [45/300][50/78]	eta 0:00:53 lr 6.041405	time 1.1718 (1.9069)	loss 3.7908 (4.1063)	grad_norm 0.3430 (0.3055)	mem 39782MB
[2023-07-07 08:52:07 RepVGG-A0] (main.py 282): INFO Train: [45/300][60/78]	eta 0:00:33 lr 6.039426	time 1.2627 (1.8488)	loss 4.3823 (4.0760)	grad_norm 0.6054 (0.3205)	mem 39782MB
[2023-07-07 08:52:22 RepVGG-A0] (main.py 282): INFO Train: [45/300][70/78]	eta 0:00:14 lr 6.037442	time 1.2324 (1.8024)	loss 4.0221 (4.1108)	grad_norm 0.2760 (0.3360)	mem 39782MB
[2023-07-07 08:52:34 RepVGG-A0] (main.py 291): INFO EPOCH 45 training takes 0:02:19
[2023-07-07 08:52:55 RepVGG-A0] (main.py 282): INFO Train: [46/300][0/78]	eta 0:27:07 lr 6.035851	time 20.8655 (20.8655)	loss 3.8060 (3.8060)	grad_norm 0.2596 (0.2596)	mem 39782MB
[2023-07-07 08:53:10 RepVGG-A0] (main.py 282): INFO Train: [46/300][10/78]	eta 0:03:45 lr 6.033858	time 1.1724 (3.3142)	loss 3.7707 (3.7690)	grad_norm 0.3166 (0.2873)	mem 39782MB
[2023-07-07 08:53:26 RepVGG-A0] (main.py 282): INFO Train: [46/300][20/78]	eta 0:02:22 lr 6.031860	time 1.2565 (2.4573)	loss 3.6714 (3.7528)	grad_norm 0.2918 (0.3043)	mem 39782MB
[2023-07-07 08:53:42 RepVGG-A0] (main.py 282): INFO Train: [46/300][30/78]	eta 0:01:45 lr 6.029857	time 1.4710 (2.1920)	loss 3.8471 (3.7379)	grad_norm 0.3898 (0.3162)	mem 39782MB
[2023-07-07 08:54:00 RepVGG-A0] (main.py 282): INFO Train: [46/300][40/78]	eta 0:01:19 lr 6.027849	time 3.5300 (2.0870)	loss 3.6788 (3.7336)	grad_norm 0.3323 (0.3213)	mem 39782MB
[2023-07-07 08:54:14 RepVGG-A0] (main.py 282): INFO Train: [46/300][50/78]	eta 0:00:55 lr 6.025836	time 1.1737 (1.9656)	loss 3.6258 (3.7263)	grad_norm 0.3697 (0.3247)	mem 39782MB
[2023-07-07 08:54:29 RepVGG-A0] (main.py 282): INFO Train: [46/300][60/78]	eta 0:00:33 lr 6.023817	time 1.3042 (1.8812)	loss 3.6902 (3.7366)	grad_norm 0.3131 (0.3347)	mem 39782MB
[2023-07-07 08:54:45 RepVGG-A0] (main.py 282): INFO Train: [46/300][70/78]	eta 0:00:14 lr 6.021794	time 1.3338 (1.8420)	loss 3.8165 (3.7355)	grad_norm 0.4250 (0.3374)	mem 39782MB
[2023-07-07 08:54:56 RepVGG-A0] (main.py 291): INFO EPOCH 46 training takes 0:02:22
[2023-07-07 08:55:19 RepVGG-A0] (main.py 282): INFO Train: [47/300][0/78]	eta 0:28:52 lr 6.020171	time 22.2104 (22.2104)	loss 3.5636 (3.5636)	grad_norm 0.2796 (0.2796)	mem 39782MB
[2023-07-07 08:55:32 RepVGG-A0] (main.py 282): INFO Train: [47/300][10/78]	eta 0:03:39 lr 6.018138	time 1.1881 (3.2333)	loss 3.6491 (3.6583)	grad_norm 0.3517 (0.3406)	mem 39782MB
[2023-07-07 08:55:48 RepVGG-A0] (main.py 282): INFO Train: [47/300][20/78]	eta 0:02:22 lr 6.016101	time 1.1827 (2.4514)	loss 3.6267 (3.6449)	grad_norm 0.3655 (0.3468)	mem 39782MB
[2023-07-07 08:56:02 RepVGG-A0] (main.py 282): INFO Train: [47/300][30/78]	eta 0:01:41 lr 6.014058	time 1.3506 (2.1178)	loss 3.9106 (3.6486)	grad_norm 0.5037 (0.3573)	mem 39782MB
[2023-07-07 08:56:20 RepVGG-A0] (main.py 282): INFO Train: [47/300][40/78]	eta 0:01:17 lr 6.012010	time 3.5967 (2.0358)	loss 3.7312 (3.7307)	grad_norm 0.2925 (0.3810)	mem 39782MB
[2023-07-07 08:56:34 RepVGG-A0] (main.py 282): INFO Train: [47/300][50/78]	eta 0:00:53 lr 6.009957	time 1.1719 (1.9175)	loss 3.8028 (3.7132)	grad_norm 0.4113 (0.3637)	mem 39782MB
[2023-07-07 08:56:49 RepVGG-A0] (main.py 282): INFO Train: [47/300][60/78]	eta 0:00:33 lr 6.007899	time 1.2631 (1.8530)	loss 3.5629 (3.7048)	grad_norm 0.2575 (0.3587)	mem 39782MB
[2023-07-07 08:57:04 RepVGG-A0] (main.py 282): INFO Train: [47/300][70/78]	eta 0:00:14 lr 6.005836	time 1.1249 (1.8023)	loss 3.6489 (3.6882)	grad_norm 0.3760 (0.3543)	mem 39782MB
[2023-07-07 08:57:16 RepVGG-A0] (main.py 291): INFO EPOCH 47 training takes 0:02:19
[2023-07-07 08:57:38 RepVGG-A0] (main.py 282): INFO Train: [48/300][0/78]	eta 0:27:28 lr 6.004181	time 21.1310 (21.1310)	loss 3.4436 (3.4436)	grad_norm 0.3321 (0.3321)	mem 39782MB
[2023-07-07 08:57:52 RepVGG-A0] (main.py 282): INFO Train: [48/300][10/78]	eta 0:03:41 lr 6.002109	time 1.1715 (3.2539)	loss 3.5572 (3.5549)	grad_norm 0.3679 (0.3627)	mem 39782MB
[2023-07-07 08:58:07 RepVGG-A0] (main.py 282): INFO Train: [48/300][20/78]	eta 0:02:20 lr 6.000032	time 1.1743 (2.4239)	loss 3.5189 (3.5593)	grad_norm 0.3330 (0.3525)	mem 39782MB
[2023-07-07 08:58:22 RepVGG-A0] (main.py 282): INFO Train: [48/300][30/78]	eta 0:01:42 lr 5.997950	time 1.4022 (2.1252)	loss 3.4814 (3.5485)	grad_norm 0.3271 (0.3473)	mem 39782MB
[2023-07-07 08:58:41 RepVGG-A0] (main.py 282): INFO Train: [48/300][40/78]	eta 0:01:18 lr 5.995862	time 4.1593 (2.0705)	loss 6.0498 (3.6890)	grad_norm 1.0851 (0.4075)	mem 39782MB
[2023-07-07 08:58:55 RepVGG-A0] (main.py 282): INFO Train: [48/300][50/78]	eta 0:00:54 lr 5.993770	time 1.1720 (1.9386)	loss 5.4461 (4.1371)	grad_norm 0.3712 (0.4201)	mem 39782MB
[2023-07-07 08:59:11 RepVGG-A0] (main.py 282): INFO Train: [48/300][60/78]	eta 0:00:33 lr 5.991672	time 1.1269 (1.8771)	loss 4.6441 (4.2795)	grad_norm 0.2745 (0.4012)	mem 39782MB
[2023-07-07 08:59:26 RepVGG-A0] (main.py 282): INFO Train: [48/300][70/78]	eta 0:00:14 lr 5.989570	time 1.2248 (1.8228)	loss 4.3175 (4.3091)	grad_norm 0.2977 (0.3865)	mem 39782MB
[2023-07-07 08:59:37 RepVGG-A0] (main.py 291): INFO EPOCH 48 training takes 0:02:20
[2023-07-07 08:59:58 RepVGG-A0] (main.py 282): INFO Train: [49/300][0/78]	eta 0:27:25 lr 5.987884	time 21.0961 (21.0961)	loss 4.1706 (4.1706)	grad_norm 0.3038 (0.3038)	mem 39782MB
[2023-07-07 09:00:13 RepVGG-A0] (main.py 282): INFO Train: [49/300][10/78]	eta 0:03:41 lr 5.985773	time 1.1722 (3.2589)	loss 4.0879 (4.0816)	grad_norm 0.4388 (0.3053)	mem 39782MB
[2023-07-07 09:00:28 RepVGG-A0] (main.py 282): INFO Train: [49/300][20/78]	eta 0:02:21 lr 5.983656	time 1.3795 (2.4452)	loss 3.9278 (4.0988)	grad_norm 0.2403 (0.3206)	mem 39782MB
[2023-07-07 09:00:44 RepVGG-A0] (main.py 282): INFO Train: [49/300][30/78]	eta 0:01:43 lr 5.981535	time 1.6696 (2.1651)	loss 3.9069 (4.0255)	grad_norm 0.3422 (0.3050)	mem 39782MB
[2023-07-07 09:01:02 RepVGG-A0] (main.py 282): INFO Train: [49/300][40/78]	eta 0:01:19 lr 5.979408	time 2.7602 (2.0794)	loss 3.9066 (3.9863)	grad_norm 0.3663 (0.3073)	mem 39782MB
[2023-07-07 09:01:17 RepVGG-A0] (main.py 282): INFO Train: [49/300][50/78]	eta 0:00:54 lr 5.977276	time 1.2180 (1.9611)	loss 3.7447 (3.9516)	grad_norm 0.2899 (0.3088)	mem 39782MB
[2023-07-07 09:01:32 RepVGG-A0] (main.py 282): INFO Train: [49/300][60/78]	eta 0:00:34 lr 5.975140	time 1.2966 (1.8891)	loss 3.9016 (3.9311)	grad_norm 0.4693 (0.3180)	mem 39782MB
[2023-07-07 09:01:47 RepVGG-A0] (main.py 282): INFO Train: [49/300][70/78]	eta 0:00:14 lr 5.972998	time 1.1799 (1.8230)	loss 3.9715 (3.9688)	grad_norm 0.3394 (0.3382)	mem 39782MB
[2023-07-07 09:01:59 RepVGG-A0] (main.py 291): INFO EPOCH 49 training takes 0:02:21
[2023-07-07 09:02:20 RepVGG-A0] (main.py 282): INFO Train: [50/300][0/78]	eta 0:26:56 lr 5.971281	time 20.7294 (20.7294)	loss 3.7536 (3.7536)	grad_norm 0.2950 (0.2950)	mem 39782MB
[2023-07-07 09:02:35 RepVGG-A0] (main.py 282): INFO Train: [50/300][10/78]	eta 0:03:42 lr 5.969131	time 1.1919 (3.2737)	loss 3.6319 (3.6985)	grad_norm 0.2737 (0.2964)	mem 39782MB
[2023-07-07 09:02:50 RepVGG-A0] (main.py 282): INFO Train: [50/300][20/78]	eta 0:02:21 lr 5.966975	time 1.1935 (2.4345)	loss 3.7800 (3.7062)	grad_norm 0.3660 (0.3141)	mem 39782MB
[2023-07-07 09:03:06 RepVGG-A0] (main.py 282): INFO Train: [50/300][30/78]	eta 0:01:43 lr 5.964815	time 1.2652 (2.1622)	loss 3.7168 (3.7105)	grad_norm 0.3405 (0.3242)	mem 39782MB
[2023-07-07 09:03:23 RepVGG-A0] (main.py 282): INFO Train: [50/300][40/78]	eta 0:01:18 lr 5.962649	time 2.5400 (2.0542)	loss 3.6238 (3.6914)	grad_norm 0.3403 (0.3205)	mem 39782MB
[2023-07-07 09:03:37 RepVGG-A0] (main.py 282): INFO Train: [50/300][50/78]	eta 0:00:53 lr 5.960478	time 1.1912 (1.9219)	loss 3.7691 (3.7247)	grad_norm 0.3356 (0.3412)	mem 39782MB
[2023-07-07 09:03:53 RepVGG-A0] (main.py 282): INFO Train: [50/300][60/78]	eta 0:00:33 lr 5.958303	time 1.3135 (1.8696)	loss 3.6301 (3.7107)	grad_norm 0.3280 (0.3350)	mem 39782MB
[2023-07-07 09:04:07 RepVGG-A0] (main.py 282): INFO Train: [50/300][70/78]	eta 0:00:14 lr 5.956122	time 1.4048 (1.8054)	loss 3.6282 (3.7023)	grad_norm 0.3263 (0.3350)	mem 39782MB
[2023-07-07 09:04:19 RepVGG-A0] (main.py 291): INFO EPOCH 50 training takes 0:02:20
[2023-07-07 09:04:40 RepVGG-A0] (main.py 282): INFO Train: [51/300][0/78]	eta 0:26:52 lr 5.954374	time 20.6677 (20.6677)	loss 3.6856 (3.6856)	grad_norm 0.3777 (0.3777)	mem 39782MB
[2023-07-07 09:04:54 RepVGG-A0] (main.py 282): INFO Train: [51/300][10/78]	eta 0:03:37 lr 5.952185	time 1.1711 (3.1913)	loss 3.5860 (3.6685)	grad_norm 0.3116 (0.3741)	mem 39782MB
[2023-07-07 09:05:09 RepVGG-A0] (main.py 282): INFO Train: [51/300][20/78]	eta 0:02:18 lr 5.949991	time 1.1758 (2.3949)	loss 3.5925 (3.6420)	grad_norm 0.3179 (0.3613)	mem 39782MB
[2023-07-07 09:05:25 RepVGG-A0] (main.py 282): INFO Train: [51/300][30/78]	eta 0:01:41 lr 5.947791	time 1.5661 (2.1155)	loss 3.6864 (3.6282)	grad_norm 0.3729 (0.3550)	mem 39782MB
[2023-07-07 09:05:43 RepVGG-A0] (main.py 282): INFO Train: [51/300][40/78]	eta 0:01:17 lr 5.945587	time 3.9002 (2.0393)	loss 3.5914 (3.6269)	grad_norm 0.3457 (0.3568)	mem 39782MB
[2023-07-07 09:05:57 RepVGG-A0] (main.py 282): INFO Train: [51/300][50/78]	eta 0:00:53 lr 5.943378	time 1.1710 (1.9282)	loss 3.6014 (3.6219)	grad_norm 0.3412 (0.3562)	mem 39782MB
[2023-07-07 09:06:13 RepVGG-A0] (main.py 282): INFO Train: [51/300][60/78]	eta 0:00:33 lr 5.941164	time 1.2359 (1.8611)	loss 6.0616 (3.8084)	grad_norm 0.5566 (0.4047)	mem 39782MB
[2023-07-07 09:06:27 RepVGG-A0] (main.py 282): INFO Train: [51/300][70/78]	eta 0:00:14 lr 5.938944	time 1.2585 (1.8029)	loss 5.1584 (4.0801)	grad_norm 0.2728 (0.4118)	mem 39782MB
[2023-07-07 09:06:39 RepVGG-A0] (main.py 291): INFO EPOCH 51 training takes 0:02:19
[2023-07-07 09:07:00 RepVGG-A0] (main.py 282): INFO Train: [52/300][0/78]	eta 0:27:28 lr 5.937166	time 21.1309 (21.1309)	loss 4.6489 (4.6489)	grad_norm 0.3029 (0.3029)	mem 39782MB
[2023-07-07 09:07:15 RepVGG-A0] (main.py 282): INFO Train: [52/300][10/78]	eta 0:03:42 lr 5.934938	time 1.1718 (3.2699)	loss 4.4505 (4.5038)	grad_norm 0.3327 (0.2876)	mem 39782MB
[2023-07-07 09:07:29 RepVGG-A0] (main.py 282): INFO Train: [52/300][20/78]	eta 0:02:18 lr 5.932705	time 1.1745 (2.3926)	loss 4.2001 (4.3774)	grad_norm 0.3075 (0.2900)	mem 39782MB
[2023-07-07 09:07:44 RepVGG-A0] (main.py 282): INFO Train: [52/300][30/78]	eta 0:01:41 lr 5.930467	time 1.1961 (2.1094)	loss 4.0082 (4.2906)	grad_norm 0.2978 (0.2967)	mem 39782MB
[2023-07-07 09:08:03 RepVGG-A0] (main.py 282): INFO Train: [52/300][40/78]	eta 0:01:17 lr 5.928224	time 3.7032 (2.0460)	loss 3.9757 (4.2181)	grad_norm 0.2919 (0.2976)	mem 39782MB
[2023-07-07 09:08:18 RepVGG-A0] (main.py 282): INFO Train: [52/300][50/78]	eta 0:00:54 lr 5.925976	time 1.1756 (1.9445)	loss 3.8751 (4.1525)	grad_norm 0.3220 (0.2993)	mem 39782MB
[2023-07-07 09:08:33 RepVGG-A0] (main.py 282): INFO Train: [52/300][60/78]	eta 0:00:33 lr 5.923724	time 1.2367 (1.8775)	loss 3.8579 (4.1134)	grad_norm 0.3542 (0.3089)	mem 39782MB
[2023-07-07 09:08:48 RepVGG-A0] (main.py 282): INFO Train: [52/300][70/78]	eta 0:00:14 lr 5.921466	time 1.1820 (1.8168)	loss 4.5373 (4.0835)	grad_norm 0.7432 (0.3164)	mem 39782MB
[2023-07-07 09:09:01 RepVGG-A0] (main.py 291): INFO EPOCH 52 training takes 0:02:21
[2023-07-07 09:09:21 RepVGG-A0] (main.py 282): INFO Train: [53/300][0/78]	eta 0:26:09 lr 5.919657	time 20.1232 (20.1232)	loss 5.2108 (5.2108)	grad_norm 0.4777 (0.4777)	mem 39782MB
[2023-07-07 09:09:36 RepVGG-A0] (main.py 282): INFO Train: [53/300][10/78]	eta 0:03:39 lr 5.917390	time 1.1710 (3.2313)	loss 4.2519 (4.5028)	grad_norm 0.3043 (0.3298)	mem 39782MB
[2023-07-07 09:09:50 RepVGG-A0] (main.py 282): INFO Train: [53/300][20/78]	eta 0:02:17 lr 5.915119	time 1.1709 (2.3654)	loss 3.9366 (4.2865)	grad_norm 0.2308 (0.3019)	mem 39782MB
[2023-07-07 09:10:06 RepVGG-A0] (main.py 282): INFO Train: [53/300][30/78]	eta 0:01:40 lr 5.912843	time 1.3758 (2.0970)	loss 3.9070 (4.1664)	grad_norm 0.3032 (0.2942)	mem 39782MB
[2023-07-07 09:10:24 RepVGG-A0] (main.py 282): INFO Train: [53/300][40/78]	eta 0:01:16 lr 5.910562	time 3.4788 (2.0214)	loss 3.8036 (4.0852)	grad_norm 0.2973 (0.2907)	mem 39782MB
[2023-07-07 09:10:39 RepVGG-A0] (main.py 282): INFO Train: [53/300][50/78]	eta 0:00:53 lr 5.908276	time 1.1778 (1.9228)	loss 3.8050 (4.0337)	grad_norm 0.3332 (0.2959)	mem 39782MB
[2023-07-07 09:10:54 RepVGG-A0] (main.py 282): INFO Train: [53/300][60/78]	eta 0:00:33 lr 5.905985	time 1.2769 (1.8505)	loss 3.7491 (4.0012)	grad_norm 0.2992 (0.3058)	mem 39782MB
[2023-07-07 09:11:08 RepVGG-A0] (main.py 282): INFO Train: [53/300][70/78]	eta 0:00:14 lr 5.903689	time 1.2113 (1.7971)	loss 3.6908 (3.9626)	grad_norm 0.3184 (0.3045)	mem 39782MB
[2023-07-07 09:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 53 training takes 0:02:19
[2023-07-07 09:11:41 RepVGG-A0] (main.py 282): INFO Train: [54/300][0/78]	eta 0:27:00 lr 5.901849	time 20.7783 (20.7783)	loss 3.7429 (3.7429)	grad_norm 0.4143 (0.4143)	mem 39782MB
[2023-07-07 09:11:57 RepVGG-A0] (main.py 282): INFO Train: [54/300][10/78]	eta 0:03:47 lr 5.899545	time 1.1718 (3.3462)	loss 3.7354 (3.9260)	grad_norm 0.2811 (0.4191)	mem 39782MB
[2023-07-07 09:12:12 RepVGG-A0] (main.py 282): INFO Train: [54/300][20/78]	eta 0:02:23 lr 5.897236	time 1.3369 (2.4738)	loss 3.7389 (3.8231)	grad_norm 0.3360 (0.3612)	mem 39782MB
[2023-07-07 09:12:28 RepVGG-A0] (main.py 282): INFO Train: [54/300][30/78]	eta 0:01:44 lr 5.894921	time 1.5592 (2.1820)	loss 3.7794 (3.7864)	grad_norm 0.3742 (0.3560)	mem 39782MB
[2023-07-07 09:12:45 RepVGG-A0] (main.py 282): INFO Train: [54/300][40/78]	eta 0:01:19 lr 5.892602	time 3.0928 (2.0806)	loss 3.5694 (3.7527)	grad_norm 0.3055 (0.3458)	mem 39782MB
[2023-07-07 09:13:00 RepVGG-A0] (main.py 282): INFO Train: [54/300][50/78]	eta 0:00:54 lr 5.890278	time 1.1724 (1.9633)	loss 3.6863 (3.7376)	grad_norm 0.3613 (0.3470)	mem 39782MB
[2023-07-07 09:13:16 RepVGG-A0] (main.py 282): INFO Train: [54/300][60/78]	eta 0:00:34 lr 5.887950	time 1.3054 (1.9001)	loss 4.1432 (3.7354)	grad_norm 0.5986 (0.3528)	mem 39782MB
[2023-07-07 09:13:31 RepVGG-A0] (main.py 282): INFO Train: [54/300][70/78]	eta 0:00:14 lr 5.885616	time 1.1255 (1.8412)	loss 3.8602 (3.7852)	grad_norm 0.2966 (0.3676)	mem 39782MB
[2023-07-07 09:13:42 RepVGG-A0] (main.py 291): INFO EPOCH 54 training takes 0:02:22
[2023-07-07 09:14:04 RepVGG-A0] (main.py 282): INFO Train: [55/300][0/78]	eta 0:29:00 lr 5.883746	time 22.3172 (22.3172)	loss 3.6046 (3.6046)	grad_norm 0.3142 (0.3142)	mem 39782MB
[2023-07-07 09:14:18 RepVGG-A0] (main.py 282): INFO Train: [55/300][10/78]	eta 0:03:44 lr 5.881404	time 1.1701 (3.3012)	loss 3.5515 (3.6512)	grad_norm 0.2664 (0.3141)	mem 39782MB
[2023-07-07 09:14:32 RepVGG-A0] (main.py 282): INFO Train: [55/300][20/78]	eta 0:02:18 lr 5.879056	time 1.1918 (2.3944)	loss 3.6702 (3.6181)	grad_norm 0.3742 (0.3193)	mem 39782MB
[2023-07-07 09:14:48 RepVGG-A0] (main.py 282): INFO Train: [55/300][30/78]	eta 0:01:41 lr 5.876704	time 1.4848 (2.1167)	loss 3.6491 (3.6139)	grad_norm 0.3462 (0.3244)	mem 39782MB
[2023-07-07 09:15:05 RepVGG-A0] (main.py 282): INFO Train: [55/300][40/78]	eta 0:01:16 lr 5.874348	time 3.7632 (2.0194)	loss 3.7571 (3.6097)	grad_norm 0.4316 (0.3270)	mem 39782MB
[2023-07-07 09:15:22 RepVGG-A0] (main.py 282): INFO Train: [55/300][50/78]	eta 0:00:54 lr 5.871986	time 1.1725 (1.9533)	loss 3.5502 (3.6219)	grad_norm 0.3439 (0.3371)	mem 39782MB
[2023-07-07 09:15:37 RepVGG-A0] (main.py 282): INFO Train: [55/300][60/78]	eta 0:00:33 lr 5.869620	time 1.3266 (1.8833)	loss 3.6230 (3.6180)	grad_norm 0.3490 (0.3377)	mem 39782MB
[2023-07-07 09:15:52 RepVGG-A0] (main.py 282): INFO Train: [55/300][70/78]	eta 0:00:14 lr 5.867248	time 1.2960 (1.8282)	loss 4.2214 (3.6687)	grad_norm 0.5416 (0.3622)	mem 39782MB
[2023-07-07 09:16:03 RepVGG-A0] (main.py 291): INFO EPOCH 55 training takes 0:02:20
[2023-07-07 09:16:24 RepVGG-A0] (main.py 282): INFO Train: [56/300][0/78]	eta 0:27:25 lr 5.865348	time 21.0912 (21.0912)	loss 3.6759 (3.6759)	grad_norm 0.2869 (0.2869)	mem 39782MB
[2023-07-07 09:16:40 RepVGG-A0] (main.py 282): INFO Train: [56/300][10/78]	eta 0:03:47 lr 5.862968	time 1.1702 (3.3505)	loss 3.5569 (3.6042)	grad_norm 0.2982 (0.2909)	mem 39782MB
[2023-07-07 09:16:54 RepVGG-A0] (main.py 282): INFO Train: [56/300][20/78]	eta 0:02:21 lr 5.860583	time 1.3318 (2.4368)	loss 3.6261 (3.5648)	grad_norm 0.3235 (0.3030)	mem 39782MB
[2023-07-07 09:17:10 RepVGG-A0] (main.py 282): INFO Train: [56/300][30/78]	eta 0:01:42 lr 5.858194	time 1.1845 (2.1450)	loss 3.5785 (3.5560)	grad_norm 0.3312 (0.3073)	mem 39782MB
[2023-07-07 09:17:27 RepVGG-A0] (main.py 282): INFO Train: [56/300][40/78]	eta 0:01:17 lr 5.855800	time 2.6780 (2.0524)	loss 3.5643 (3.5520)	grad_norm 0.3846 (0.3146)	mem 39782MB
[2023-07-07 09:17:43 RepVGG-A0] (main.py 282): INFO Train: [56/300][50/78]	eta 0:00:54 lr 5.853401	time 1.2893 (1.9552)	loss 4.3071 (3.6270)	grad_norm 0.6707 (0.3569)	mem 39782MB
[2023-07-07 09:17:59 RepVGG-A0] (main.py 282): INFO Train: [56/300][60/78]	eta 0:00:34 lr 5.850997	time 1.4343 (1.8965)	loss 3.8042 (3.7167)	grad_norm 0.2702 (0.3711)	mem 39782MB
[2023-07-07 09:18:14 RepVGG-A0] (main.py 282): INFO Train: [56/300][70/78]	eta 0:00:14 lr 5.848588	time 1.2279 (1.8387)	loss 3.6872 (3.7186)	grad_norm 0.3020 (0.3574)	mem 39782MB
[2023-07-07 09:18:24 RepVGG-A0] (main.py 291): INFO EPOCH 56 training takes 0:02:21
[2023-07-07 09:18:46 RepVGG-A0] (main.py 282): INFO Train: [57/300][0/78]	eta 0:28:00 lr 5.846658	time 21.5418 (21.5418)	loss 3.4802 (3.4802)	grad_norm 0.2411 (0.2411)	mem 39782MB
[2023-07-07 09:19:00 RepVGG-A0] (main.py 282): INFO Train: [57/300][10/78]	eta 0:03:37 lr 5.844241	time 1.1726 (3.1946)	loss 3.5190 (3.4814)	grad_norm 0.3036 (0.2740)	mem 39782MB
[2023-07-07 09:19:15 RepVGG-A0] (main.py 282): INFO Train: [57/300][20/78]	eta 0:02:18 lr 5.841819	time 1.1920 (2.3934)	loss 3.5730 (3.5041)	grad_norm 0.3639 (0.3037)	mem 39782MB
[2023-07-07 09:19:31 RepVGG-A0] (main.py 282): INFO Train: [57/300][30/78]	eta 0:01:43 lr 5.839392	time 1.5884 (2.1496)	loss 3.4987 (3.5261)	grad_norm 0.3151 (0.3156)	mem 39782MB
[2023-07-07 09:19:48 RepVGG-A0] (main.py 282): INFO Train: [57/300][40/78]	eta 0:01:17 lr 5.836960	time 2.5398 (2.0372)	loss 3.4652 (3.5175)	grad_norm 0.3532 (0.3159)	mem 39782MB
[2023-07-07 09:20:03 RepVGG-A0] (main.py 282): INFO Train: [57/300][50/78]	eta 0:00:54 lr 5.834524	time 1.1720 (1.9353)	loss 3.5153 (3.5223)	grad_norm 0.3171 (0.3222)	mem 39782MB
[2023-07-07 09:20:19 RepVGG-A0] (main.py 282): INFO Train: [57/300][60/78]	eta 0:00:33 lr 5.832083	time 1.3551 (1.8716)	loss 3.7687 (3.5350)	grad_norm 0.4287 (0.3322)	mem 39782MB
[2023-07-07 09:20:35 RepVGG-A0] (main.py 282): INFO Train: [57/300][70/78]	eta 0:00:14 lr 5.829637	time 1.4221 (1.8346)	loss 3.5363 (3.5444)	grad_norm 0.3394 (0.3365)	mem 39782MB
[2023-07-07 09:20:46 RepVGG-A0] (main.py 291): INFO EPOCH 57 training takes 0:02:21
[2023-07-07 09:21:07 RepVGG-A0] (main.py 282): INFO Train: [58/300][0/78]	eta 0:28:08 lr 5.827677	time 21.6469 (21.6469)	loss 3.5113 (3.5113)	grad_norm 0.3257 (0.3257)	mem 39782MB
[2023-07-07 09:21:22 RepVGG-A0] (main.py 282): INFO Train: [58/300][10/78]	eta 0:03:41 lr 5.825223	time 1.2018 (3.2643)	loss 3.5960 (3.4884)	grad_norm 0.4379 (0.3458)	mem 39782MB
[2023-07-07 09:21:37 RepVGG-A0] (main.py 282): INFO Train: [58/300][20/78]	eta 0:02:21 lr 5.822764	time 1.1729 (2.4374)	loss 5.8699 (4.0097)	grad_norm 0.8552 (0.5332)	mem 39782MB
[2023-07-07 09:21:51 RepVGG-A0] (main.py 282): INFO Train: [58/300][30/78]	eta 0:01:41 lr 5.820300	time 1.3533 (2.1182)	loss 4.3596 (4.2762)	grad_norm 0.2507 (0.4912)	mem 39782MB
[2023-07-07 09:22:09 RepVGG-A0] (main.py 282): INFO Train: [58/300][40/78]	eta 0:01:17 lr 5.817832	time 3.9902 (2.0418)	loss 3.9416 (4.2398)	grad_norm 0.2199 (0.4393)	mem 39782MB
[2023-07-07 09:22:24 RepVGG-A0] (main.py 282): INFO Train: [58/300][50/78]	eta 0:00:54 lr 5.815359	time 1.1733 (1.9353)	loss 3.7930 (4.1669)	grad_norm 0.2943 (0.4105)	mem 39782MB
[2023-07-07 09:22:40 RepVGG-A0] (main.py 282): INFO Train: [58/300][60/78]	eta 0:00:33 lr 5.812881	time 1.3732 (1.8781)	loss 3.6368 (4.0894)	grad_norm 0.2548 (0.3863)	mem 39782MB
[2023-07-07 09:22:56 RepVGG-A0] (main.py 282): INFO Train: [58/300][70/78]	eta 0:00:14 lr 5.810398	time 1.1258 (1.8301)	loss 3.5641 (4.0308)	grad_norm 0.2529 (0.3735)	mem 39782MB
[2023-07-07 09:23:07 RepVGG-A0] (main.py 291): INFO EPOCH 58 training takes 0:02:21
[2023-07-07 09:23:27 RepVGG-A0] (main.py 282): INFO Train: [59/300][0/78]	eta 0:26:25 lr 5.808409	time 20.3234 (20.3234)	loss 3.7118 (3.7118)	grad_norm 0.4193 (0.4193)	mem 39782MB
[2023-07-07 09:23:43 RepVGG-A0] (main.py 282): INFO Train: [59/300][10/78]	eta 0:03:40 lr 5.805918	time 1.1917 (3.2402)	loss 3.4711 (3.6063)	grad_norm 0.2791 (0.3217)	mem 39782MB
[2023-07-07 09:23:58 RepVGG-A0] (main.py 282): INFO Train: [59/300][20/78]	eta 0:02:21 lr 5.803422	time 1.1739 (2.4335)	loss 3.6339 (3.5971)	grad_norm 0.3507 (0.3272)	mem 39782MB
[2023-07-07 09:24:14 RepVGG-A0] (main.py 282): INFO Train: [59/300][30/78]	eta 0:01:44 lr 5.800922	time 1.5482 (2.1745)	loss 3.4757 (3.5965)	grad_norm 0.2843 (0.3336)	mem 39782MB
[2023-07-07 09:24:32 RepVGG-A0] (main.py 282): INFO Train: [59/300][40/78]	eta 0:01:19 lr 5.798417	time 3.4252 (2.0868)	loss 3.4640 (3.5782)	grad_norm 0.3075 (0.3316)	mem 39782MB
[2023-07-07 09:24:47 RepVGG-A0] (main.py 282): INFO Train: [59/300][50/78]	eta 0:00:55 lr 5.795907	time 1.1754 (1.9707)	loss 3.5157 (3.5699)	grad_norm 0.3520 (0.3340)	mem 39782MB
[2023-07-07 09:25:02 RepVGG-A0] (main.py 282): INFO Train: [59/300][60/78]	eta 0:00:34 lr 5.793392	time 1.2817 (1.8940)	loss 3.5756 (3.5700)	grad_norm 0.3667 (0.3382)	mem 39782MB
[2023-07-07 09:25:18 RepVGG-A0] (main.py 282): INFO Train: [59/300][70/78]	eta 0:00:14 lr 5.790873	time 1.1253 (1.8522)	loss 3.4252 (3.5669)	grad_norm 0.2880 (0.3382)	mem 39782MB
[2023-07-07 09:25:29 RepVGG-A0] (main.py 291): INFO EPOCH 59 training takes 0:02:22
[2023-07-07 09:25:51 RepVGG-A0] (main.py 282): INFO Train: [60/300][0/78]	eta 0:28:33 lr 5.788854	time 21.9699 (21.9699)	loss 3.4779 (3.4779)	grad_norm 0.3800 (0.3800)	mem 39782MB
[2023-07-07 09:26:05 RepVGG-A0] (main.py 282): INFO Train: [60/300][10/78]	eta 0:03:41 lr 5.786327	time 1.1732 (3.2609)	loss 3.8866 (3.7465)	grad_norm 0.4371 (0.4711)	mem 39782MB
[2023-07-07 09:26:20 RepVGG-A0] (main.py 282): INFO Train: [60/300][20/78]	eta 0:02:20 lr 5.783795	time 1.2574 (2.4146)	loss 3.4891 (3.6552)	grad_norm 0.3213 (0.3947)	mem 39782MB
[2023-07-07 09:26:35 RepVGG-A0] (main.py 282): INFO Train: [60/300][30/78]	eta 0:01:41 lr 5.781258	time 1.1854 (2.1133)	loss 3.4105 (3.6099)	grad_norm 0.2783 (0.3676)	mem 39782MB
[2023-07-07 09:26:54 RepVGG-A0] (main.py 282): INFO Train: [60/300][40/78]	eta 0:01:18 lr 5.778716	time 4.6826 (2.0589)	loss 3.5612 (3.5783)	grad_norm 0.3812 (0.3604)	mem 39782MB
[2023-07-07 09:27:09 RepVGG-A0] (main.py 282): INFO Train: [60/300][50/78]	eta 0:00:54 lr 5.776170	time 1.3141 (1.9498)	loss 3.5523 (3.5911)	grad_norm 0.3176 (0.3683)	mem 39782MB
[2023-07-07 09:27:23 RepVGG-A0] (main.py 282): INFO Train: [60/300][60/78]	eta 0:00:33 lr 5.773619	time 1.3999 (1.8669)	loss 3.5008 (3.5699)	grad_norm 0.3014 (0.3571)	mem 39782MB
[2023-07-07 09:27:38 RepVGG-A0] (main.py 282): INFO Train: [60/300][70/78]	eta 0:00:14 lr 5.771064	time 1.3718 (1.8172)	loss 4.6736 (3.6183)	grad_norm 0.9074 (0.3854)	mem 39782MB
[2023-07-07 09:27:50 RepVGG-A0] (main.py 291): INFO EPOCH 60 training takes 0:02:21
[2023-07-07 09:28:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.399 (17.399)	Loss 9.5352 (9.5352)	Acc@1 1.117 (1.117)	Acc@5 4.065 (4.065)	Mem 39782MB
[2023-07-07 09:28:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 1.154 Acc@5 3.944
[2023-07-07 09:28:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 60: 1.154%
[2023-07-07 09:28:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 09:28:31 RepVGG-A0] (main.py 282): INFO Train: [61/300][0/78]	eta 0:28:34 lr 5.769016	time 21.9748 (21.9748)	loss 4.3975 (4.3975)	grad_norm 0.3837 (0.3837)	mem 39782MB
[2023-07-07 09:28:48 RepVGG-A0] (main.py 282): INFO Train: [61/300][10/78]	eta 0:04:00 lr 5.766452	time 1.1781 (3.5349)	loss 3.8365 (4.0696)	grad_norm 0.2932 (0.3212)	mem 39782MB
[2023-07-07 09:29:02 RepVGG-A0] (main.py 282): INFO Train: [61/300][20/78]	eta 0:02:26 lr 5.763884	time 1.1741 (2.5239)	loss 3.6609 (3.9148)	grad_norm 0.2410 (0.3010)	mem 39782MB
[2023-07-07 09:29:17 RepVGG-A0] (main.py 282): INFO Train: [61/300][30/78]	eta 0:01:44 lr 5.761311	time 1.4143 (2.1847)	loss 3.6031 (3.8027)	grad_norm 0.2852 (0.2923)	mem 39782MB
[2023-07-07 09:29:34 RepVGG-A0] (main.py 282): INFO Train: [61/300][40/78]	eta 0:01:18 lr 5.758733	time 2.7975 (2.0712)	loss 3.5297 (3.7380)	grad_norm 0.3038 (0.2913)	mem 39782MB
[2023-07-07 09:29:49 RepVGG-A0] (main.py 282): INFO Train: [61/300][50/78]	eta 0:00:54 lr 5.756151	time 1.2176 (1.9581)	loss 3.4519 (3.6904)	grad_norm 0.3334 (0.2957)	mem 39782MB
[2023-07-07 09:30:04 RepVGG-A0] (main.py 282): INFO Train: [61/300][60/78]	eta 0:00:34 lr 5.753564	time 1.2126 (1.8927)	loss 3.4661 (3.6557)	grad_norm 0.2989 (0.2962)	mem 39782MB
[2023-07-07 09:30:20 RepVGG-A0] (main.py 282): INFO Train: [61/300][70/78]	eta 0:00:14 lr 5.750972	time 1.2131 (1.8454)	loss 3.6360 (3.6396)	grad_norm 0.4232 (0.3059)	mem 39782MB
[2023-07-07 09:30:31 RepVGG-A0] (main.py 291): INFO EPOCH 61 training takes 0:02:22
[2023-07-07 09:30:52 RepVGG-A0] (main.py 282): INFO Train: [62/300][0/78]	eta 0:26:59 lr 5.748896	time 20.7592 (20.7592)	loss 3.4601 (3.4601)	grad_norm 0.3303 (0.3303)	mem 39782MB
[2023-07-07 09:31:06 RepVGG-A0] (main.py 282): INFO Train: [62/300][10/78]	eta 0:03:32 lr 5.746296	time 1.1729 (3.1243)	loss 3.4745 (3.4176)	grad_norm 0.3172 (0.3186)	mem 39782MB
[2023-07-07 09:31:21 RepVGG-A0] (main.py 282): INFO Train: [62/300][20/78]	eta 0:02:17 lr 5.743692	time 1.2824 (2.3778)	loss 3.5107 (3.4349)	grad_norm 0.3536 (0.3274)	mem 39782MB
[2023-07-07 09:31:37 RepVGG-A0] (main.py 282): INFO Train: [62/300][30/78]	eta 0:01:42 lr 5.741083	time 1.5309 (2.1271)	loss 3.6084 (3.4653)	grad_norm 0.4112 (0.3466)	mem 39782MB
[2023-07-07 09:31:55 RepVGG-A0] (main.py 282): INFO Train: [62/300][40/78]	eta 0:01:17 lr 5.738469	time 3.5578 (2.0304)	loss 3.6723 (3.5513)	grad_norm 0.3568 (0.3771)	mem 39782MB
[2023-07-07 09:32:10 RepVGG-A0] (main.py 282): INFO Train: [62/300][50/78]	eta 0:00:54 lr 5.735851	time 1.1718 (1.9298)	loss 3.3770 (3.5407)	grad_norm 0.2826 (0.3600)	mem 39782MB
[2023-07-07 09:32:25 RepVGG-A0] (main.py 282): INFO Train: [62/300][60/78]	eta 0:00:33 lr 5.733228	time 1.3083 (1.8603)	loss 3.4896 (3.5278)	grad_norm 0.3257 (0.3530)	mem 39782MB
[2023-07-07 09:32:40 RepVGG-A0] (main.py 282): INFO Train: [62/300][70/78]	eta 0:00:14 lr 5.730601	time 1.2881 (1.8086)	loss 3.4155 (3.5211)	grad_norm 0.3370 (0.3522)	mem 39782MB
[2023-07-07 09:32:52 RepVGG-A0] (main.py 291): INFO EPOCH 62 training takes 0:02:20
[2023-07-07 09:33:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][0/78]	eta 0:28:28 lr 5.728496	time 21.9036 (21.9036)	loss 3.3550 (3.3550)	grad_norm 0.3240 (0.3240)	mem 39782MB
[2023-07-07 09:33:28 RepVGG-A0] (main.py 282): INFO Train: [63/300][10/78]	eta 0:03:41 lr 5.725861	time 1.1738 (3.2583)	loss 3.4966 (3.4126)	grad_norm 0.4217 (0.3436)	mem 39782MB
[2023-07-07 09:33:42 RepVGG-A0] (main.py 282): INFO Train: [63/300][20/78]	eta 0:02:17 lr 5.723221	time 1.2887 (2.3792)	loss 5.2475 (3.9040)	grad_norm 0.7453 (0.5193)	mem 39782MB
[2023-07-07 09:33:57 RepVGG-A0] (main.py 282): INFO Train: [63/300][30/78]	eta 0:01:40 lr 5.720576	time 1.4742 (2.0937)	loss 4.2436 (4.1593)	grad_norm 0.2767 (0.4875)	mem 39782MB
[2023-07-07 09:34:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][40/78]	eta 0:01:15 lr 5.717927	time 2.8636 (1.9984)	loss 3.8471 (4.1180)	grad_norm 0.2881 (0.4358)	mem 39782MB
[2023-07-07 09:34:29 RepVGG-A0] (main.py 282): INFO Train: [63/300][50/78]	eta 0:00:53 lr 5.715273	time 1.3433 (1.9171)	loss 3.6618 (4.0444)	grad_norm 0.3010 (0.4041)	mem 39782MB
[2023-07-07 09:34:45 RepVGG-A0] (main.py 282): INFO Train: [63/300][60/78]	eta 0:00:33 lr 5.712615	time 1.1737 (1.8534)	loss 3.4961 (3.9742)	grad_norm 0.2600 (0.3830)	mem 39782MB
[2023-07-07 09:35:00 RepVGG-A0] (main.py 282): INFO Train: [63/300][70/78]	eta 0:00:14 lr 5.709952	time 1.3309 (1.8115)	loss 3.5662 (3.9151)	grad_norm 0.3287 (0.3677)	mem 39782MB
[2023-07-07 09:35:11 RepVGG-A0] (main.py 291): INFO EPOCH 63 training takes 0:02:19
[2023-07-07 09:35:33 RepVGG-A0] (main.py 282): INFO Train: [64/300][0/78]	eta 0:28:05 lr 5.707819	time 21.6037 (21.6037)	loss 3.4373 (3.4373)	grad_norm 0.3458 (0.3458)	mem 39782MB
[2023-07-07 09:35:49 RepVGG-A0] (main.py 282): INFO Train: [64/300][10/78]	eta 0:03:50 lr 5.705148	time 1.1706 (3.3949)	loss 3.4384 (3.4710)	grad_norm 0.2726 (0.3107)	mem 39782MB
[2023-07-07 09:36:04 RepVGG-A0] (main.py 282): INFO Train: [64/300][20/78]	eta 0:02:26 lr 5.702473	time 1.2406 (2.5219)	loss 3.6498 (3.4775)	grad_norm 0.4396 (0.3233)	mem 39782MB
[2023-07-07 09:36:20 RepVGG-A0] (main.py 282): INFO Train: [64/300][30/78]	eta 0:01:45 lr 5.699793	time 1.5735 (2.2009)	loss 3.4063 (3.5088)	grad_norm 0.2986 (0.3359)	mem 39782MB
[2023-07-07 09:36:38 RepVGG-A0] (main.py 282): INFO Train: [64/300][40/78]	eta 0:01:19 lr 5.697109	time 2.4330 (2.0987)	loss 3.5223 (3.5018)	grad_norm 0.3475 (0.3318)	mem 39782MB
[2023-07-07 09:36:53 RepVGG-A0] (main.py 282): INFO Train: [64/300][50/78]	eta 0:00:55 lr 5.694420	time 1.1763 (1.9885)	loss 3.5039 (3.4853)	grad_norm 0.3971 (0.3264)	mem 39782MB
[2023-07-07 09:37:07 RepVGG-A0] (main.py 282): INFO Train: [64/300][60/78]	eta 0:00:34 lr 5.691726	time 1.1754 (1.8950)	loss 3.5885 (3.5146)	grad_norm 0.3464 (0.3421)	mem 39782MB
[2023-07-07 09:37:22 RepVGG-A0] (main.py 282): INFO Train: [64/300][70/78]	eta 0:00:14 lr 5.689029	time 1.1262 (1.8377)	loss 3.4466 (3.5093)	grad_norm 0.3460 (0.3384)	mem 39782MB
[2023-07-07 09:37:34 RepVGG-A0] (main.py 291): INFO EPOCH 64 training takes 0:02:22
[2023-07-07 09:37:55 RepVGG-A0] (main.py 282): INFO Train: [65/300][0/78]	eta 0:27:27 lr 5.686867	time 21.1214 (21.1214)	loss 3.4530 (3.4530)	grad_norm 0.3390 (0.3390)	mem 39782MB
[2023-07-07 09:38:09 RepVGG-A0] (main.py 282): INFO Train: [65/300][10/78]	eta 0:03:39 lr 5.684161	time 1.1742 (3.2212)	loss 3.4844 (3.4695)	grad_norm 0.3396 (0.3593)	mem 39782MB
[2023-07-07 09:38:25 RepVGG-A0] (main.py 282): INFO Train: [65/300][20/78]	eta 0:02:21 lr 5.681451	time 1.1856 (2.4480)	loss 3.5079 (3.4380)	grad_norm 0.3700 (0.3420)	mem 39782MB
[2023-07-07 09:38:40 RepVGG-A0] (main.py 282): INFO Train: [65/300][30/78]	eta 0:01:43 lr 5.678736	time 1.6985 (2.1546)	loss 3.4985 (3.4591)	grad_norm 0.3616 (0.3542)	mem 39782MB
[2023-07-07 09:38:58 RepVGG-A0] (main.py 282): INFO Train: [65/300][40/78]	eta 0:01:17 lr 5.676017	time 3.4240 (2.0509)	loss 3.5833 (3.4582)	grad_norm 0.4233 (0.3501)	mem 39782MB
[2023-07-07 09:39:13 RepVGG-A0] (main.py 282): INFO Train: [65/300][50/78]	eta 0:00:54 lr 5.673293	time 1.1739 (1.9461)	loss 4.7927 (3.6350)	grad_norm 0.6230 (0.4151)	mem 39782MB
[2023-07-07 09:39:28 RepVGG-A0] (main.py 282): INFO Train: [65/300][60/78]	eta 0:00:33 lr 5.670564	time 1.2094 (1.8710)	loss 4.2725 (3.8026)	grad_norm 0.3560 (0.4301)	mem 39782MB
[2023-07-07 09:39:43 RepVGG-A0] (main.py 282): INFO Train: [65/300][70/78]	eta 0:00:14 lr 5.667832	time 1.1256 (1.8162)	loss 3.8386 (3.8235)	grad_norm 0.3073 (0.4077)	mem 39782MB
[2023-07-07 09:39:55 RepVGG-A0] (main.py 291): INFO EPOCH 65 training takes 0:02:21
[2023-07-07 09:40:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][0/78]	eta 0:27:10 lr 5.665642	time 20.9010 (20.9010)	loss 3.6134 (3.6134)	grad_norm 0.2577 (0.2577)	mem 39782MB
[2023-07-07 09:40:30 RepVGG-A0] (main.py 282): INFO Train: [66/300][10/78]	eta 0:03:34 lr 5.662902	time 1.1917 (3.1513)	loss 3.5598 (3.5718)	grad_norm 0.2528 (0.2668)	mem 39782MB
[2023-07-07 09:40:44 RepVGG-A0] (main.py 282): INFO Train: [66/300][20/78]	eta 0:02:14 lr 5.660156	time 1.1917 (2.3270)	loss 3.5029 (3.5252)	grad_norm 0.2966 (0.2720)	mem 39782MB
[2023-07-07 09:40:59 RepVGG-A0] (main.py 282): INFO Train: [66/300][30/78]	eta 0:01:38 lr 5.657407	time 1.1761 (2.0478)	loss 3.5061 (3.5082)	grad_norm 0.3068 (0.2793)	mem 39782MB
[2023-07-07 09:41:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][40/78]	eta 0:01:15 lr 5.654653	time 3.4618 (1.9738)	loss 3.4360 (3.5048)	grad_norm 0.2734 (0.2895)	mem 39782MB
[2023-07-07 09:41:32 RepVGG-A0] (main.py 282): INFO Train: [66/300][50/78]	eta 0:00:53 lr 5.651894	time 2.1477 (1.8946)	loss 3.4842 (3.4977)	grad_norm 0.3489 (0.2950)	mem 39782MB
[2023-07-07 09:41:47 RepVGG-A0] (main.py 282): INFO Train: [66/300][60/78]	eta 0:00:32 lr 5.649132	time 1.1767 (1.8292)	loss 5.1930 (3.6622)	grad_norm 0.5786 (0.3609)	mem 39782MB
[2023-07-07 09:42:02 RepVGG-A0] (main.py 282): INFO Train: [66/300][70/78]	eta 0:00:14 lr 5.646364	time 1.1264 (1.7923)	loss 4.4682 (3.8192)	grad_norm 0.3216 (0.3730)	mem 39782MB
[2023-07-07 09:42:15 RepVGG-A0] (main.py 291): INFO EPOCH 66 training takes 0:02:19
[2023-07-07 09:42:36 RepVGG-A0] (main.py 282): INFO Train: [67/300][0/78]	eta 0:27:44 lr 5.644147	time 21.3360 (21.3360)	loss 3.9897 (3.9897)	grad_norm 0.2578 (0.2578)	mem 39782MB
[2023-07-07 09:42:50 RepVGG-A0] (main.py 282): INFO Train: [67/300][10/78]	eta 0:03:40 lr 5.641372	time 1.1931 (3.2451)	loss 3.7027 (3.8760)	grad_norm 0.2625 (0.2836)	mem 39782MB
[2023-07-07 09:43:04 RepVGG-A0] (main.py 282): INFO Train: [67/300][20/78]	eta 0:02:16 lr 5.638592	time 1.1720 (2.3564)	loss 3.6486 (3.7781)	grad_norm 0.2765 (0.2761)	mem 39782MB
[2023-07-07 09:43:19 RepVGG-A0] (main.py 282): INFO Train: [67/300][30/78]	eta 0:01:39 lr 5.635808	time 1.1848 (2.0740)	loss 3.6376 (3.7302)	grad_norm 0.2977 (0.2811)	mem 39782MB
[2023-07-07 09:43:37 RepVGG-A0] (main.py 282): INFO Train: [67/300][40/78]	eta 0:01:16 lr 5.633020	time 3.8092 (2.0187)	loss 3.5788 (3.7093)	grad_norm 0.2655 (0.2931)	mem 39782MB
[2023-07-07 09:43:53 RepVGG-A0] (main.py 282): INFO Train: [67/300][50/78]	eta 0:00:53 lr 5.630227	time 1.1730 (1.9271)	loss 3.5657 (3.6784)	grad_norm 0.3324 (0.2952)	mem 39782MB
[2023-07-07 09:44:07 RepVGG-A0] (main.py 282): INFO Train: [67/300][60/78]	eta 0:00:33 lr 5.627430	time 1.3098 (1.8497)	loss 3.6365 (3.6566)	grad_norm 0.3992 (0.3004)	mem 39782MB
[2023-07-07 09:44:23 RepVGG-A0] (main.py 282): INFO Train: [67/300][70/78]	eta 0:00:14 lr 5.624629	time 1.3460 (1.8064)	loss 3.7113 (3.6477)	grad_norm 0.3790 (0.3068)	mem 39782MB
[2023-07-07 09:44:35 RepVGG-A0] (main.py 291): INFO EPOCH 67 training takes 0:02:20
[2023-07-07 09:44:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][0/78]	eta 0:27:53 lr 5.622384	time 21.4535 (21.4535)	loss 3.4211 (3.4211)	grad_norm 0.2924 (0.2924)	mem 39782MB
[2023-07-07 09:45:10 RepVGG-A0] (main.py 282): INFO Train: [68/300][10/78]	eta 0:03:36 lr 5.619575	time 1.1720 (3.1870)	loss 3.5336 (3.5114)	grad_norm 0.3247 (0.3421)	mem 39782MB
[2023-07-07 09:45:25 RepVGG-A0] (main.py 282): INFO Train: [68/300][20/78]	eta 0:02:18 lr 5.616761	time 1.1737 (2.3929)	loss 3.4954 (3.4929)	grad_norm 0.3365 (0.3351)	mem 39782MB
[2023-07-07 09:45:41 RepVGG-A0] (main.py 282): INFO Train: [68/300][30/78]	eta 0:01:41 lr 5.613943	time 1.7092 (2.1224)	loss 3.4994 (3.4980)	grad_norm 0.3669 (0.3429)	mem 39782MB
[2023-07-07 09:45:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][40/78]	eta 0:01:15 lr 5.611120	time 1.9894 (1.9882)	loss 3.5224 (3.5081)	grad_norm 0.3171 (0.3462)	mem 39782MB
[2023-07-07 09:46:13 RepVGG-A0] (main.py 282): INFO Train: [68/300][50/78]	eta 0:00:54 lr 5.608294	time 1.1727 (1.9340)	loss 3.5796 (3.5093)	grad_norm 0.3760 (0.3501)	mem 39782MB
[2023-07-07 09:46:29 RepVGG-A0] (main.py 282): INFO Train: [68/300][60/78]	eta 0:00:33 lr 5.605462	time 1.1280 (1.8650)	loss 3.5282 (3.5169)	grad_norm 0.3654 (0.3540)	mem 39782MB
[2023-07-07 09:46:44 RepVGG-A0] (main.py 282): INFO Train: [68/300][70/78]	eta 0:00:14 lr 5.602627	time 1.1793 (1.8188)	loss 3.4677 (3.5112)	grad_norm 0.3921 (0.3495)	mem 39782MB
[2023-07-07 09:46:56 RepVGG-A0] (main.py 291): INFO EPOCH 68 training takes 0:02:20
[2023-07-07 09:47:17 RepVGG-A0] (main.py 282): INFO Train: [69/300][0/78]	eta 0:28:13 lr 5.600355	time 21.7105 (21.7105)	loss 3.5722 (3.5722)	grad_norm 0.4097 (0.4097)	mem 39782MB
[2023-07-07 09:47:32 RepVGG-A0] (main.py 282): INFO Train: [69/300][10/78]	eta 0:03:45 lr 5.597512	time 1.1706 (3.3090)	loss 3.4756 (3.5467)	grad_norm 0.3140 (0.3957)	mem 39782MB
[2023-07-07 09:47:46 RepVGG-A0] (main.py 282): INFO Train: [69/300][20/78]	eta 0:02:19 lr 5.594665	time 1.2085 (2.4115)	loss 3.3988 (3.4916)	grad_norm 0.3201 (0.3725)	mem 39782MB
[2023-07-07 09:48:02 RepVGG-A0] (main.py 282): INFO Train: [69/300][30/78]	eta 0:01:42 lr 5.591813	time 1.5841 (2.1404)	loss 3.4913 (3.4700)	grad_norm 0.3596 (0.3596)	mem 39782MB
[2023-07-07 09:48:20 RepVGG-A0] (main.py 282): INFO Train: [69/300][40/78]	eta 0:01:17 lr 5.588956	time 3.6027 (2.0502)	loss 3.6296 (3.4640)	grad_norm 0.4635 (0.3623)	mem 39782MB
[2023-07-07 09:48:35 RepVGG-A0] (main.py 282): INFO Train: [69/300][50/78]	eta 0:00:54 lr 5.586096	time 1.1723 (1.9504)	loss 6.2264 (3.7744)	grad_norm 0.6966 (0.4551)	mem 39782MB
[2023-07-07 09:48:50 RepVGG-A0] (main.py 282): INFO Train: [69/300][60/78]	eta 0:00:33 lr 5.583231	time 1.2216 (1.8722)	loss 4.9952 (4.0656)	grad_norm 0.3042 (0.4439)	mem 39782MB
[2023-07-07 09:49:05 RepVGG-A0] (main.py 282): INFO Train: [69/300][70/78]	eta 0:00:14 lr 5.580362	time 1.1397 (1.8220)	loss 4.4806 (4.1539)	grad_norm 0.3020 (0.4236)	mem 39782MB
[2023-07-07 09:49:17 RepVGG-A0] (main.py 291): INFO EPOCH 69 training takes 0:02:21
[2023-07-07 09:49:39 RepVGG-A0] (main.py 282): INFO Train: [70/300][0/78]	eta 0:28:40 lr 5.578063	time 22.0551 (22.0551)	loss 4.1495 (4.1495)	grad_norm 0.2419 (0.2419)	mem 39782MB
[2023-07-07 09:49:53 RepVGG-A0] (main.py 282): INFO Train: [70/300][10/78]	eta 0:03:42 lr 5.575187	time 1.1717 (3.2659)	loss 4.0628 (4.1025)	grad_norm 0.3224 (0.2928)	mem 39782MB
[2023-07-07 09:50:09 RepVGG-A0] (main.py 282): INFO Train: [70/300][20/78]	eta 0:02:22 lr 5.572305	time 1.3414 (2.4628)	loss 3.8765 (4.0263)	grad_norm 0.2858 (0.2949)	mem 39782MB
[2023-07-07 09:50:24 RepVGG-A0] (main.py 282): INFO Train: [70/300][30/78]	eta 0:01:44 lr 5.569420	time 1.1839 (2.1713)	loss 3.7241 (3.9543)	grad_norm 0.2641 (0.2913)	mem 39782MB
[2023-07-07 09:50:41 RepVGG-A0] (main.py 282): INFO Train: [70/300][40/78]	eta 0:01:18 lr 5.566530	time 3.2637 (2.0612)	loss 3.8460 (3.9181)	grad_norm 0.3403 (0.3055)	mem 39782MB
[2023-07-07 09:50:56 RepVGG-A0] (main.py 282): INFO Train: [70/300][50/78]	eta 0:00:54 lr 5.563636	time 1.1737 (1.9416)	loss 3.6000 (3.8721)	grad_norm 0.2810 (0.3034)	mem 39782MB
[2023-07-07 09:51:11 RepVGG-A0] (main.py 282): INFO Train: [70/300][60/78]	eta 0:00:33 lr 5.560738	time 1.3572 (1.8727)	loss 3.8369 (3.8452)	grad_norm 0.4148 (0.3113)	mem 39782MB
[2023-07-07 09:51:25 RepVGG-A0] (main.py 282): INFO Train: [70/300][70/78]	eta 0:00:14 lr 5.557836	time 1.1402 (1.7997)	loss 3.6658 (3.8265)	grad_norm 0.2909 (0.3134)	mem 39782MB
[2023-07-07 09:51:36 RepVGG-A0] (main.py 291): INFO EPOCH 70 training takes 0:02:19
[2023-07-07 09:51:58 RepVGG-A0] (main.py 282): INFO Train: [71/300][0/78]	eta 0:28:24 lr 5.555511	time 21.8578 (21.8578)	loss 3.5137 (3.5137)	grad_norm 0.2949 (0.2949)	mem 39782MB
[2023-07-07 09:52:12 RepVGG-A0] (main.py 282): INFO Train: [71/300][10/78]	eta 0:03:42 lr 5.552601	time 1.1731 (3.2705)	loss 3.5869 (3.6613)	grad_norm 0.2917 (0.3733)	mem 39782MB
[2023-07-07 09:52:26 RepVGG-A0] (main.py 282): INFO Train: [71/300][20/78]	eta 0:02:17 lr 5.549686	time 1.1720 (2.3651)	loss 3.5700 (3.6075)	grad_norm 0.2888 (0.3414)	mem 39782MB
[2023-07-07 09:52:42 RepVGG-A0] (main.py 282): INFO Train: [71/300][30/78]	eta 0:01:41 lr 5.546768	time 1.3076 (2.1093)	loss 3.5624 (3.5946)	grad_norm 0.3619 (0.3468)	mem 39782MB
[2023-07-07 09:53:00 RepVGG-A0] (main.py 282): INFO Train: [71/300][40/78]	eta 0:01:17 lr 5.543845	time 4.2930 (2.0370)	loss 3.5833 (3.5839)	grad_norm 0.3471 (0.3410)	mem 39782MB
[2023-07-07 09:53:15 RepVGG-A0] (main.py 282): INFO Train: [71/300][50/78]	eta 0:00:53 lr 5.540918	time 1.1724 (1.9251)	loss 3.8420 (3.6516)	grad_norm 0.3041 (0.3686)	mem 39782MB
[2023-07-07 09:53:29 RepVGG-A0] (main.py 282): INFO Train: [71/300][60/78]	eta 0:00:33 lr 5.537986	time 1.1754 (1.8536)	loss 3.6664 (3.6507)	grad_norm 0.3630 (0.3598)	mem 39782MB
[2023-07-07 09:53:45 RepVGG-A0] (main.py 282): INFO Train: [71/300][70/78]	eta 0:00:14 lr 5.535051	time 1.2875 (1.8047)	loss 3.5607 (3.6333)	grad_norm 0.3185 (0.3501)	mem 39782MB
[2023-07-07 09:53:56 RepVGG-A0] (main.py 291): INFO EPOCH 71 training takes 0:02:20
[2023-07-07 09:54:18 RepVGG-A0] (main.py 282): INFO Train: [72/300][0/78]	eta 0:28:04 lr 5.532700	time 21.6007 (21.6007)	loss 3.3924 (3.3924)	grad_norm 0.2911 (0.2911)	mem 39782MB
[2023-07-07 09:54:32 RepVGG-A0] (main.py 282): INFO Train: [72/300][10/78]	eta 0:03:42 lr 5.529757	time 1.1723 (3.2677)	loss 3.4898 (3.4359)	grad_norm 0.3112 (0.3135)	mem 39782MB
[2023-07-07 09:54:48 RepVGG-A0] (main.py 282): INFO Train: [72/300][20/78]	eta 0:02:22 lr 5.526809	time 1.2341 (2.4512)	loss 3.6361 (3.5109)	grad_norm 0.3500 (0.3556)	mem 39782MB
[2023-07-07 09:55:04 RepVGG-A0] (main.py 282): INFO Train: [72/300][30/78]	eta 0:01:44 lr 5.523858	time 1.7239 (2.1722)	loss 3.4771 (3.5010)	grad_norm 0.3324 (0.3452)	mem 39782MB
[2023-07-07 09:55:21 RepVGG-A0] (main.py 282): INFO Train: [72/300][40/78]	eta 0:01:18 lr 5.520902	time 3.9176 (2.0559)	loss 3.5282 (3.5071)	grad_norm 0.3531 (0.3500)	mem 39782MB
[2023-07-07 09:55:36 RepVGG-A0] (main.py 282): INFO Train: [72/300][50/78]	eta 0:00:54 lr 5.517942	time 1.1718 (1.9454)	loss 3.4220 (3.4933)	grad_norm 0.3320 (0.3453)	mem 39782MB
[2023-07-07 09:55:50 RepVGG-A0] (main.py 282): INFO Train: [72/300][60/78]	eta 0:00:33 lr 5.514978	time 1.3346 (1.8670)	loss 3.5094 (3.4938)	grad_norm 0.4239 (0.3478)	mem 39782MB
[2023-07-07 09:56:06 RepVGG-A0] (main.py 282): INFO Train: [72/300][70/78]	eta 0:00:14 lr 5.512010	time 1.2828 (1.8237)	loss 5.5169 (3.6356)	grad_norm 0.8740 (0.4036)	mem 39782MB
[2023-07-07 09:56:18 RepVGG-A0] (main.py 291): INFO EPOCH 72 training takes 0:02:21
[2023-07-07 09:56:39 RepVGG-A0] (main.py 282): INFO Train: [73/300][0/78]	eta 0:28:15 lr 5.509633	time 21.7398 (21.7398)	loss 4.6864 (4.6864)	grad_norm 0.3197 (0.3197)	mem 39782MB
[2023-07-07 09:56:54 RepVGG-A0] (main.py 282): INFO Train: [73/300][10/78]	eta 0:03:45 lr 5.506657	time 1.1905 (3.3109)	loss 4.0948 (4.3900)	grad_norm 0.2373 (0.2861)	mem 39782MB
[2023-07-07 09:57:09 RepVGG-A0] (main.py 282): INFO Train: [73/300][20/78]	eta 0:02:21 lr 5.503677	time 1.1739 (2.4311)	loss 3.9748 (4.2396)	grad_norm 0.2448 (0.3022)	mem 39782MB
[2023-07-07 09:57:24 RepVGG-A0] (main.py 282): INFO Train: [73/300][30/78]	eta 0:01:42 lr 5.500693	time 1.1281 (2.1321)	loss 3.7355 (4.0942)	grad_norm 0.2543 (0.2828)	mem 39782MB
[2023-07-07 09:57:42 RepVGG-A0] (main.py 282): INFO Train: [73/300][40/78]	eta 0:01:18 lr 5.497705	time 3.8230 (2.0558)	loss 3.6673 (3.9923)	grad_norm 0.2672 (0.2799)	mem 39782MB
[2023-07-07 09:57:57 RepVGG-A0] (main.py 282): INFO Train: [73/300][50/78]	eta 0:00:54 lr 5.494713	time 1.1722 (1.9437)	loss 3.5668 (3.9205)	grad_norm 0.3221 (0.2826)	mem 39782MB
[2023-07-07 09:58:11 RepVGG-A0] (main.py 282): INFO Train: [73/300][60/78]	eta 0:00:33 lr 5.491716	time 1.1793 (1.8650)	loss 3.6115 (3.8682)	grad_norm 0.2941 (0.2880)	mem 39782MB
[2023-07-07 09:58:26 RepVGG-A0] (main.py 282): INFO Train: [73/300][70/78]	eta 0:00:14 lr 5.488716	time 1.1709 (1.8100)	loss 3.6193 (3.8251)	grad_norm 0.3572 (0.2900)	mem 39782MB
[2023-07-07 09:58:38 RepVGG-A0] (main.py 291): INFO EPOCH 73 training takes 0:02:20
[2023-07-07 09:59:00 RepVGG-A0] (main.py 282): INFO Train: [74/300][0/78]	eta 0:27:56 lr 5.486313	time 21.4963 (21.4963)	loss 3.5889 (3.5889)	grad_norm 0.3862 (0.3862)	mem 39782MB
[2023-07-07 09:59:15 RepVGG-A0] (main.py 282): INFO Train: [74/300][10/78]	eta 0:03:48 lr 5.483305	time 1.1715 (3.3596)	loss 3.4193 (3.5401)	grad_norm 0.2935 (0.3335)	mem 39782MB
[2023-07-07 09:59:30 RepVGG-A0] (main.py 282): INFO Train: [74/300][20/78]	eta 0:02:23 lr 5.480293	time 1.3496 (2.4684)	loss 3.6078 (3.5252)	grad_norm 0.3946 (0.3368)	mem 39782MB
[2023-07-07 09:59:46 RepVGG-A0] (main.py 282): INFO Train: [74/300][30/78]	eta 0:01:44 lr 5.477276	time 1.3321 (2.1780)	loss 3.5072 (3.5310)	grad_norm 0.2881 (0.3353)	mem 39782MB
[2023-07-07 10:00:04 RepVGG-A0] (main.py 282): INFO Train: [74/300][40/78]	eta 0:01:19 lr 5.474256	time 3.6810 (2.0886)	loss 3.3937 (3.5217)	grad_norm 0.3264 (0.3352)	mem 39782MB
[2023-07-07 10:00:18 RepVGG-A0] (main.py 282): INFO Train: [74/300][50/78]	eta 0:00:54 lr 5.471232	time 1.2932 (1.9627)	loss 3.5376 (3.5227)	grad_norm 0.3907 (0.3412)	mem 39782MB
[2023-07-07 10:00:34 RepVGG-A0] (main.py 282): INFO Train: [74/300][60/78]	eta 0:00:33 lr 5.468203	time 1.2822 (1.8879)	loss 3.5703 (3.5240)	grad_norm 0.3227 (0.3421)	mem 39782MB
[2023-07-07 10:00:50 RepVGG-A0] (main.py 282): INFO Train: [74/300][70/78]	eta 0:00:14 lr 5.465171	time 1.3073 (1.8516)	loss 3.6461 (3.5268)	grad_norm 0.4644 (0.3466)	mem 39782MB
[2023-07-07 10:01:01 RepVGG-A0] (main.py 291): INFO EPOCH 74 training takes 0:02:22
[2023-07-07 10:01:22 RepVGG-A0] (main.py 282): INFO Train: [75/300][0/78]	eta 0:27:02 lr 5.462742	time 20.8075 (20.8075)	loss 3.4917 (3.4917)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 10:01:36 RepVGG-A0] (main.py 282): INFO Train: [75/300][10/78]	eta 0:03:39 lr 5.459702	time 1.1720 (3.2250)	loss 3.5963 (3.5038)	grad_norm 0.3977 (0.3616)	mem 39782MB
[2023-07-07 10:01:51 RepVGG-A0] (main.py 282): INFO Train: [75/300][20/78]	eta 0:02:18 lr 5.456658	time 1.1708 (2.3826)	loss 3.3624 (3.4659)	grad_norm 0.3402 (0.3409)	mem 39782MB
[2023-07-07 10:02:07 RepVGG-A0] (main.py 282): INFO Train: [75/300][30/78]	eta 0:01:41 lr 5.453610	time 1.2849 (2.1143)	loss 3.6230 (3.5014)	grad_norm 0.4109 (0.3673)	mem 39782MB
[2023-07-07 10:02:24 RepVGG-A0] (main.py 282): INFO Train: [75/300][40/78]	eta 0:01:16 lr 5.450558	time 2.7842 (2.0172)	loss 3.4045 (3.4921)	grad_norm 0.2769 (0.3562)	mem 39782MB
[2023-07-07 10:02:41 RepVGG-A0] (main.py 282): INFO Train: [75/300][50/78]	eta 0:00:55 lr 5.447501	time 1.2321 (1.9657)	loss 3.5101 (3.4826)	grad_norm 0.3503 (0.3551)	mem 39782MB
[2023-07-07 10:02:57 RepVGG-A0] (main.py 282): INFO Train: [75/300][60/78]	eta 0:00:34 lr 5.444441	time 1.2525 (1.8969)	loss 3.4167 (3.4723)	grad_norm 0.3656 (0.3504)	mem 39782MB
[2023-07-07 10:03:12 RepVGG-A0] (main.py 282): INFO Train: [75/300][70/78]	eta 0:00:14 lr 5.441377	time 1.1709 (1.8455)	loss 3.5680 (3.5041)	grad_norm 0.3341 (0.3662)	mem 39782MB
[2023-07-07 10:03:23 RepVGG-A0] (main.py 291): INFO EPOCH 75 training takes 0:02:22
[2023-07-07 10:03:44 RepVGG-A0] (main.py 282): INFO Train: [76/300][0/78]	eta 0:27:42 lr 5.438923	time 21.3133 (21.3133)	loss 3.3484 (3.3484)	grad_norm 0.2974 (0.2974)	mem 39782MB
[2023-07-07 10:04:01 RepVGG-A0] (main.py 282): INFO Train: [76/300][10/78]	eta 0:03:52 lr 5.435851	time 1.1976 (3.4197)	loss 3.4173 (3.3936)	grad_norm 0.3213 (0.3309)	mem 39782MB
[2023-07-07 10:04:15 RepVGG-A0] (main.py 282): INFO Train: [76/300][20/78]	eta 0:02:22 lr 5.432776	time 1.3132 (2.4547)	loss 3.3408 (3.3845)	grad_norm 0.3448 (0.3281)	mem 39782MB
[2023-07-07 10:04:30 RepVGG-A0] (main.py 282): INFO Train: [76/300][30/78]	eta 0:01:43 lr 5.429696	time 1.5537 (2.1586)	loss 3.6306 (3.4243)	grad_norm 0.4127 (0.3527)	mem 39782MB
[2023-07-07 10:04:47 RepVGG-A0] (main.py 282): INFO Train: [76/300][40/78]	eta 0:01:18 lr 5.426612	time 3.4097 (2.0591)	loss 3.4226 (3.4289)	grad_norm 0.3175 (0.3496)	mem 39782MB
[2023-07-07 10:05:02 RepVGG-A0] (main.py 282): INFO Train: [76/300][50/78]	eta 0:00:54 lr 5.423525	time 1.1726 (1.9436)	loss 3.5124 (3.4332)	grad_norm 0.3627 (0.3508)	mem 39782MB
[2023-07-07 10:05:18 RepVGG-A0] (main.py 282): INFO Train: [76/300][60/78]	eta 0:00:33 lr 5.420433	time 1.1851 (1.8800)	loss 3.4228 (3.4272)	grad_norm 0.3779 (0.3503)	mem 39782MB
[2023-07-07 10:05:32 RepVGG-A0] (main.py 282): INFO Train: [76/300][70/78]	eta 0:00:14 lr 5.417338	time 1.3349 (1.8197)	loss 5.4897 (3.5120)	grad_norm 1.0900 (0.3931)	mem 39782MB
[2023-07-07 10:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 76 training takes 0:02:20
[2023-07-07 10:06:06 RepVGG-A0] (main.py 282): INFO Train: [77/300][0/78]	eta 0:28:57 lr 5.414858	time 22.2708 (22.2708)	loss 5.1859 (5.1859)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 10:06:20 RepVGG-A0] (main.py 282): INFO Train: [77/300][10/78]	eta 0:03:41 lr 5.411755	time 1.1712 (3.2577)	loss 4.4997 (4.8341)	grad_norm 0.3152 (0.3642)	mem 39782MB
[2023-07-07 10:06:34 RepVGG-A0] (main.py 282): INFO Train: [77/300][20/78]	eta 0:02:18 lr 5.408649	time 1.1915 (2.3812)	loss 4.0291 (4.5285)	grad_norm 0.2650 (0.3186)	mem 39782MB
[2023-07-07 10:06:50 RepVGG-A0] (main.py 282): INFO Train: [77/300][30/78]	eta 0:01:42 lr 5.405538	time 1.2482 (2.1253)	loss 3.9064 (4.3378)	grad_norm 0.3430 (0.3121)	mem 39782MB
[2023-07-07 10:07:08 RepVGG-A0] (main.py 282): INFO Train: [77/300][40/78]	eta 0:01:18 lr 5.402423	time 4.0868 (2.0602)	loss 3.7229 (4.1977)	grad_norm 0.3259 (0.3036)	mem 39782MB
[2023-07-07 10:07:23 RepVGG-A0] (main.py 282): INFO Train: [77/300][50/78]	eta 0:00:54 lr 5.399304	time 1.1729 (1.9347)	loss 3.7588 (4.1085)	grad_norm 0.3076 (0.3064)	mem 39782MB
[2023-07-07 10:07:39 RepVGG-A0] (main.py 282): INFO Train: [77/300][60/78]	eta 0:00:33 lr 5.396182	time 1.1976 (1.8798)	loss 3.6518 (4.0266)	grad_norm 0.3446 (0.3027)	mem 39782MB
[2023-07-07 10:07:54 RepVGG-A0] (main.py 282): INFO Train: [77/300][70/78]	eta 0:00:14 lr 5.393055	time 1.2189 (1.8308)	loss 3.5446 (3.9708)	grad_norm 0.2742 (0.3071)	mem 39782MB
[2023-07-07 10:08:06 RepVGG-A0] (main.py 291): INFO EPOCH 77 training takes 0:02:21
[2023-07-07 10:08:27 RepVGG-A0] (main.py 282): INFO Train: [78/300][0/78]	eta 0:28:17 lr 5.390551	time 21.7685 (21.7685)	loss 3.5845 (3.5845)	grad_norm 0.3382 (0.3382)	mem 39782MB
[2023-07-07 10:08:42 RepVGG-A0] (main.py 282): INFO Train: [78/300][10/78]	eta 0:03:43 lr 5.387417	time 1.1711 (3.2882)	loss 3.4915 (3.5466)	grad_norm 0.2988 (0.3343)	mem 39782MB
[2023-07-07 10:08:57 RepVGG-A0] (main.py 282): INFO Train: [78/300][20/78]	eta 0:02:21 lr 5.384279	time 1.2008 (2.4412)	loss 3.6411 (3.5556)	grad_norm 0.3817 (0.3522)	mem 39782MB
[2023-07-07 10:09:11 RepVGG-A0] (main.py 282): INFO Train: [78/300][30/78]	eta 0:01:41 lr 5.381138	time 1.1912 (2.1161)	loss 3.4872 (3.5293)	grad_norm 0.3380 (0.3396)	mem 39782MB
[2023-07-07 10:09:30 RepVGG-A0] (main.py 282): INFO Train: [78/300][40/78]	eta 0:01:18 lr 5.377992	time 3.3259 (2.0598)	loss 3.5072 (3.5208)	grad_norm 0.3562 (0.3401)	mem 39782MB
[2023-07-07 10:09:46 RepVGG-A0] (main.py 282): INFO Train: [78/300][50/78]	eta 0:00:54 lr 5.374843	time 1.1730 (1.9608)	loss 3.5728 (3.5254)	grad_norm 0.3894 (0.3455)	mem 39782MB
[2023-07-07 10:10:01 RepVGG-A0] (main.py 282): INFO Train: [78/300][60/78]	eta 0:00:33 lr 5.371689	time 1.1260 (1.8857)	loss 3.5292 (3.5263)	grad_norm 0.3290 (0.3454)	mem 39782MB
[2023-07-07 10:10:15 RepVGG-A0] (main.py 282): INFO Train: [78/300][70/78]	eta 0:00:14 lr 5.368532	time 1.1794 (1.8255)	loss 3.7045 (3.5228)	grad_norm 0.5386 (0.3483)	mem 39782MB
[2023-07-07 10:10:27 RepVGG-A0] (main.py 291): INFO EPOCH 78 training takes 0:02:21
[2023-07-07 10:10:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][0/78]	eta 0:28:32 lr 5.366003	time 21.9542 (21.9542)	loss 3.7641 (3.7641)	grad_norm 0.3883 (0.3883)	mem 39782MB
[2023-07-07 10:11:03 RepVGG-A0] (main.py 282): INFO Train: [79/300][10/78]	eta 0:03:42 lr 5.362839	time 1.1696 (3.2682)	loss 3.4265 (3.5538)	grad_norm 0.2665 (0.3224)	mem 39782MB
[2023-07-07 10:11:17 RepVGG-A0] (main.py 282): INFO Train: [79/300][20/78]	eta 0:02:16 lr 5.359670	time 1.1905 (2.3558)	loss 3.3284 (3.4846)	grad_norm 0.3262 (0.3080)	mem 39782MB
[2023-07-07 10:11:32 RepVGG-A0] (main.py 282): INFO Train: [79/300][30/78]	eta 0:01:40 lr 5.356498	time 1.1817 (2.0900)	loss 3.4799 (3.4815)	grad_norm 0.3432 (0.3223)	mem 39782MB
[2023-07-07 10:11:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][40/78]	eta 0:01:15 lr 5.353322	time 1.9109 (1.9986)	loss 3.3790 (3.4749)	grad_norm 0.3033 (0.3284)	mem 39782MB
[2023-07-07 10:12:05 RepVGG-A0] (main.py 282): INFO Train: [79/300][50/78]	eta 0:00:53 lr 5.350142	time 1.3030 (1.9199)	loss 3.4630 (3.4731)	grad_norm 0.3717 (0.3329)	mem 39782MB
[2023-07-07 10:12:21 RepVGG-A0] (main.py 282): INFO Train: [79/300][60/78]	eta 0:00:33 lr 5.346959	time 1.2230 (1.8642)	loss 3.3406 (3.4653)	grad_norm 0.3667 (0.3314)	mem 39782MB
[2023-07-07 10:12:36 RepVGG-A0] (main.py 282): INFO Train: [79/300][70/78]	eta 0:00:14 lr 5.343771	time 1.2695 (1.8176)	loss 4.1524 (3.5034)	grad_norm 0.7083 (0.3583)	mem 39782MB
[2023-07-07 10:12:47 RepVGG-A0] (main.py 291): INFO EPOCH 79 training takes 0:02:20
[2023-07-07 10:13:07 RepVGG-A0] (main.py 282): INFO Train: [80/300][0/78]	eta 0:25:58 lr 5.341218	time 19.9760 (19.9760)	loss 3.7558 (3.7558)	grad_norm 0.3243 (0.3243)	mem 39782MB
[2023-07-07 10:13:22 RepVGG-A0] (main.py 282): INFO Train: [80/300][10/78]	eta 0:03:36 lr 5.338023	time 1.1893 (3.1814)	loss 3.5604 (3.5882)	grad_norm 0.2977 (0.2853)	mem 39782MB
[2023-07-07 10:13:38 RepVGG-A0] (main.py 282): INFO Train: [80/300][20/78]	eta 0:02:19 lr 5.334825	time 1.3541 (2.4099)	loss 3.5450 (3.5398)	grad_norm 0.3072 (0.2960)	mem 39782MB
[2023-07-07 10:13:53 RepVGG-A0] (main.py 282): INFO Train: [80/300][30/78]	eta 0:01:42 lr 5.331623	time 1.3879 (2.1264)	loss 3.3716 (3.4866)	grad_norm 0.2722 (0.2921)	mem 39782MB
[2023-07-07 10:14:11 RepVGG-A0] (main.py 282): INFO Train: [80/300][40/78]	eta 0:01:17 lr 5.328416	time 4.3060 (2.0497)	loss 3.3678 (3.4536)	grad_norm 0.3658 (0.2937)	mem 39782MB
[2023-07-07 10:14:27 RepVGG-A0] (main.py 282): INFO Train: [80/300][50/78]	eta 0:00:54 lr 5.325206	time 1.1721 (1.9427)	loss 3.3994 (3.4559)	grad_norm 0.3275 (0.3082)	mem 39782MB
[2023-07-07 10:14:41 RepVGG-A0] (main.py 282): INFO Train: [80/300][60/78]	eta 0:00:33 lr 5.321993	time 1.2721 (1.8666)	loss 3.5016 (3.4446)	grad_norm 0.4813 (0.3119)	mem 39782MB
[2023-07-07 10:14:56 RepVGG-A0] (main.py 282): INFO Train: [80/300][70/78]	eta 0:00:14 lr 5.318775	time 1.3839 (1.8154)	loss 4.7642 (3.6051)	grad_norm 0.5154 (0.3707)	mem 39782MB
[2023-07-07 10:15:08 RepVGG-A0] (main.py 291): INFO EPOCH 80 training takes 0:02:20
[2023-07-07 10:15:25 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.000 (17.000)	Loss 5.1657 (5.1657)	Acc@1 11.731 (11.731)	Acc@5 27.191 (27.191)	Mem 39782MB
[2023-07-07 10:15:26 RepVGG-A0] (main.py 342): INFO  * Acc@1 11.640 Acc@5 26.608
[2023-07-07 10:15:26 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 80: 11.640%
[2023-07-07 10:15:26 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 10:15:46 RepVGG-A0] (main.py 282): INFO Train: [81/300][0/78]	eta 0:25:21 lr 5.316198	time 19.5037 (19.5037)	loss 3.8926 (3.8926)	grad_norm 0.2790 (0.2790)	mem 39782MB
[2023-07-07 10:16:01 RepVGG-A0] (main.py 282): INFO Train: [81/300][10/78]	eta 0:03:37 lr 5.312973	time 1.1700 (3.1925)	loss 3.7246 (3.7273)	grad_norm 0.2627 (0.2694)	mem 39782MB
[2023-07-07 10:16:16 RepVGG-A0] (main.py 282): INFO Train: [81/300][20/78]	eta 0:02:16 lr 5.309745	time 1.1910 (2.3554)	loss 3.4850 (3.6446)	grad_norm 0.2382 (0.2740)	mem 39782MB
[2023-07-07 10:16:31 RepVGG-A0] (main.py 282): INFO Train: [81/300][30/78]	eta 0:01:40 lr 5.306513	time 1.2244 (2.0850)	loss 3.4089 (3.5849)	grad_norm 0.2845 (0.2751)	mem 39782MB
[2023-07-07 10:16:49 RepVGG-A0] (main.py 282): INFO Train: [81/300][40/78]	eta 0:01:16 lr 5.303277	time 2.5279 (2.0192)	loss 3.4239 (3.5407)	grad_norm 0.2972 (0.2759)	mem 39782MB
[2023-07-07 10:17:06 RepVGG-A0] (main.py 282): INFO Train: [81/300][50/78]	eta 0:00:54 lr 5.300037	time 2.6887 (1.9510)	loss 3.4356 (3.5215)	grad_norm 0.3083 (0.2858)	mem 39782MB
[2023-07-07 10:17:21 RepVGG-A0] (main.py 282): INFO Train: [81/300][60/78]	eta 0:00:33 lr 5.296794	time 1.1966 (1.8734)	loss 3.3501 (3.4993)	grad_norm 0.3078 (0.2882)	mem 39782MB
[2023-07-07 10:17:36 RepVGG-A0] (main.py 282): INFO Train: [81/300][70/78]	eta 0:00:14 lr 5.293546	time 1.1724 (1.8221)	loss 3.4160 (3.4879)	grad_norm 0.3443 (0.2952)	mem 39782MB
[2023-07-07 10:17:48 RepVGG-A0] (main.py 291): INFO EPOCH 81 training takes 0:02:21
[2023-07-07 10:18:08 RepVGG-A0] (main.py 282): INFO Train: [82/300][0/78]	eta 0:26:52 lr 5.290946	time 20.6685 (20.6685)	loss 3.4345 (3.4345)	grad_norm 0.3601 (0.3601)	mem 39782MB
[2023-07-07 10:18:23 RepVGG-A0] (main.py 282): INFO Train: [82/300][10/78]	eta 0:03:37 lr 5.287692	time 1.1711 (3.2001)	loss 3.2648 (3.3835)	grad_norm 0.2981 (0.3495)	mem 39782MB
[2023-07-07 10:18:38 RepVGG-A0] (main.py 282): INFO Train: [82/300][20/78]	eta 0:02:19 lr 5.284434	time 1.1733 (2.4044)	loss 3.3285 (3.3681)	grad_norm 0.3628 (0.3463)	mem 39782MB
[2023-07-07 10:18:52 RepVGG-A0] (main.py 282): INFO Train: [82/300][30/78]	eta 0:01:40 lr 5.281172	time 1.2589 (2.0838)	loss 3.3521 (3.3568)	grad_norm 0.3732 (0.3417)	mem 39782MB
[2023-07-07 10:19:11 RepVGG-A0] (main.py 282): INFO Train: [82/300][40/78]	eta 0:01:16 lr 5.277907	time 3.9547 (2.0260)	loss 4.6535 (3.4738)	grad_norm 0.8830 (0.4006)	mem 39782MB
[2023-07-07 10:19:26 RepVGG-A0] (main.py 282): INFO Train: [82/300][50/78]	eta 0:00:53 lr 5.274638	time 1.1725 (1.9245)	loss 3.8235 (3.6267)	grad_norm 0.3246 (0.4212)	mem 39782MB
[2023-07-07 10:19:42 RepVGG-A0] (main.py 282): INFO Train: [82/300][60/78]	eta 0:00:33 lr 5.271365	time 1.6133 (1.8707)	loss 3.5651 (3.6329)	grad_norm 0.2857 (0.3992)	mem 39782MB
[2023-07-07 10:19:55 RepVGG-A0] (main.py 282): INFO Train: [82/300][70/78]	eta 0:00:14 lr 5.268089	time 1.1730 (1.7972)	loss 3.3863 (3.6160)	grad_norm 0.2560 (0.3825)	mem 39782MB
[2023-07-07 10:20:08 RepVGG-A0] (main.py 291): INFO EPOCH 82 training takes 0:02:20
[2023-07-07 10:20:29 RepVGG-A0] (main.py 282): INFO Train: [83/300][0/78]	eta 0:28:00 lr 5.265465	time 21.5492 (21.5492)	loss 3.3720 (3.3720)	grad_norm 0.3216 (0.3216)	mem 39782MB
[2023-07-07 10:20:44 RepVGG-A0] (main.py 282): INFO Train: [83/300][10/78]	eta 0:03:42 lr 5.262181	time 1.1720 (3.2733)	loss 3.3497 (3.3506)	grad_norm 0.3384 (0.3006)	mem 39782MB
[2023-07-07 10:20:58 RepVGG-A0] (main.py 282): INFO Train: [83/300][20/78]	eta 0:02:18 lr 5.258894	time 1.1731 (2.3935)	loss 3.4082 (3.3640)	grad_norm 0.3841 (0.3199)	mem 39782MB
[2023-07-07 10:21:14 RepVGG-A0] (main.py 282): INFO Train: [83/300][30/78]	eta 0:01:42 lr 5.255604	time 1.1872 (2.1256)	loss 3.4579 (3.3867)	grad_norm 0.3160 (0.3292)	mem 39782MB
[2023-07-07 10:21:32 RepVGG-A0] (main.py 282): INFO Train: [83/300][40/78]	eta 0:01:18 lr 5.252309	time 4.2959 (2.0624)	loss 3.4611 (3.3761)	grad_norm 0.3920 (0.3250)	mem 39782MB
[2023-07-07 10:21:46 RepVGG-A0] (main.py 282): INFO Train: [83/300][50/78]	eta 0:00:54 lr 5.249011	time 1.1903 (1.9286)	loss 3.3717 (3.3795)	grad_norm 0.3291 (0.3297)	mem 39782MB
[2023-07-07 10:22:02 RepVGG-A0] (main.py 282): INFO Train: [83/300][60/78]	eta 0:00:33 lr 5.245709	time 1.3592 (1.8680)	loss 3.3823 (3.3848)	grad_norm 0.3200 (0.3347)	mem 39782MB
[2023-07-07 10:22:16 RepVGG-A0] (main.py 282): INFO Train: [83/300][70/78]	eta 0:00:14 lr 5.242404	time 1.3413 (1.8111)	loss 3.4371 (3.3834)	grad_norm 0.3974 (0.3345)	mem 39782MB
[2023-07-07 10:22:28 RepVGG-A0] (main.py 291): INFO EPOCH 83 training takes 0:02:20
[2023-07-07 10:22:49 RepVGG-A0] (main.py 282): INFO Train: [84/300][0/78]	eta 0:27:31 lr 5.239757	time 21.1734 (21.1734)	loss 3.6480 (3.6480)	grad_norm 0.5047 (0.5047)	mem 39782MB
[2023-07-07 10:23:03 RepVGG-A0] (main.py 282): INFO Train: [84/300][10/78]	eta 0:03:37 lr 5.236445	time 1.1721 (3.2020)	loss 3.2872 (3.4220)	grad_norm 0.2995 (0.3506)	mem 39782MB
[2023-07-07 10:23:18 RepVGG-A0] (main.py 282): INFO Train: [84/300][20/78]	eta 0:02:19 lr 5.233129	time 1.1723 (2.3997)	loss 3.3273 (3.3722)	grad_norm 0.3304 (0.3447)	mem 39782MB
[2023-07-07 10:23:33 RepVGG-A0] (main.py 282): INFO Train: [84/300][30/78]	eta 0:01:41 lr 5.229809	time 1.1983 (2.1061)	loss 3.4441 (3.3671)	grad_norm 0.4088 (0.3489)	mem 39782MB
[2023-07-07 10:23:51 RepVGG-A0] (main.py 282): INFO Train: [84/300][40/78]	eta 0:01:17 lr 5.226486	time 4.7087 (2.0389)	loss 3.3084 (3.3618)	grad_norm 0.3027 (0.3448)	mem 39782MB
[2023-07-07 10:24:06 RepVGG-A0] (main.py 282): INFO Train: [84/300][50/78]	eta 0:00:53 lr 5.223160	time 1.3524 (1.9276)	loss 3.3994 (3.3656)	grad_norm 0.3730 (0.3488)	mem 39782MB
[2023-07-07 10:24:21 RepVGG-A0] (main.py 282): INFO Train: [84/300][60/78]	eta 0:00:33 lr 5.219829	time 1.1855 (1.8563)	loss 3.4472 (3.3645)	grad_norm 0.4371 (0.3504)	mem 39782MB
[2023-07-07 10:24:36 RepVGG-A0] (main.py 282): INFO Train: [84/300][70/78]	eta 0:00:14 lr 5.216495	time 1.3294 (1.8050)	loss 3.2959 (3.3707)	grad_norm 0.2982 (0.3514)	mem 39782MB
[2023-07-07 10:24:47 RepVGG-A0] (main.py 291): INFO EPOCH 84 training takes 0:02:19
[2023-07-07 10:25:09 RepVGG-A0] (main.py 282): INFO Train: [85/300][0/78]	eta 0:27:58 lr 5.213825	time 21.5219 (21.5219)	loss 3.4262 (3.4262)	grad_norm 0.4159 (0.4159)	mem 39782MB
[2023-07-07 10:25:22 RepVGG-A0] (main.py 282): INFO Train: [85/300][10/78]	eta 0:03:36 lr 5.210485	time 1.1884 (3.1896)	loss 3.9440 (3.6279)	grad_norm 0.5796 (0.5154)	mem 39782MB
[2023-07-07 10:25:37 RepVGG-A0] (main.py 282): INFO Train: [85/300][20/78]	eta 0:02:17 lr 5.207140	time 1.1719 (2.3782)	loss 3.3582 (3.5901)	grad_norm 0.2774 (0.4386)	mem 39782MB
[2023-07-07 10:25:52 RepVGG-A0] (main.py 282): INFO Train: [85/300][30/78]	eta 0:01:40 lr 5.203793	time 1.5988 (2.0960)	loss 3.3331 (3.5133)	grad_norm 0.3069 (0.3939)	mem 39782MB
[2023-07-07 10:26:10 RepVGG-A0] (main.py 282): INFO Train: [85/300][40/78]	eta 0:01:16 lr 5.200441	time 3.4589 (2.0255)	loss 3.3059 (3.4569)	grad_norm 0.3181 (0.3711)	mem 39782MB
[2023-07-07 10:26:25 RepVGG-A0] (main.py 282): INFO Train: [85/300][50/78]	eta 0:00:53 lr 5.197086	time 1.1728 (1.9269)	loss 3.3394 (3.4342)	grad_norm 0.3898 (0.3666)	mem 39782MB
[2023-07-07 10:26:41 RepVGG-A0] (main.py 282): INFO Train: [85/300][60/78]	eta 0:00:33 lr 5.193728	time 1.4662 (1.8665)	loss 3.3463 (3.4219)	grad_norm 0.3192 (0.3636)	mem 39782MB
[2023-07-07 10:26:56 RepVGG-A0] (main.py 282): INFO Train: [85/300][70/78]	eta 0:00:14 lr 5.190365	time 1.1723 (1.8165)	loss 3.3334 (3.4067)	grad_norm 0.3511 (0.3602)	mem 39782MB
[2023-07-07 10:27:07 RepVGG-A0] (main.py 291): INFO EPOCH 85 training takes 0:02:20
[2023-07-07 10:27:29 RepVGG-A0] (main.py 282): INFO Train: [86/300][0/78]	eta 0:27:23 lr 5.187673	time 21.0712 (21.0712)	loss 3.7261 (3.7261)	grad_norm 0.5963 (0.5963)	mem 39782MB
[2023-07-07 10:27:44 RepVGG-A0] (main.py 282): INFO Train: [86/300][10/78]	eta 0:03:45 lr 5.184304	time 1.1705 (3.3187)	loss 5.3071 (4.5041)	grad_norm 0.7889 (0.7841)	mem 39782MB
[2023-07-07 10:27:59 RepVGG-A0] (main.py 282): INFO Train: [86/300][20/78]	eta 0:02:21 lr 5.180932	time 1.3185 (2.4432)	loss 4.1476 (4.5584)	grad_norm 0.2884 (0.6187)	mem 39782MB
[2023-07-07 10:28:13 RepVGG-A0] (main.py 282): INFO Train: [86/300][30/78]	eta 0:01:42 lr 5.177556	time 1.1826 (2.1268)	loss 3.9377 (4.3612)	grad_norm 0.3546 (0.5155)	mem 39782MB
[2023-07-07 10:28:33 RepVGG-A0] (main.py 282): INFO Train: [86/300][40/78]	eta 0:01:18 lr 5.174177	time 3.9620 (2.0781)	loss 3.6798 (4.1863)	grad_norm 0.2587 (0.4501)	mem 39782MB
[2023-07-07 10:28:48 RepVGG-A0] (main.py 282): INFO Train: [86/300][50/78]	eta 0:00:54 lr 5.170794	time 1.3007 (1.9632)	loss 3.4911 (4.0549)	grad_norm 0.2524 (0.4154)	mem 39782MB
[2023-07-07 10:29:03 RepVGG-A0] (main.py 282): INFO Train: [86/300][60/78]	eta 0:00:34 lr 5.167407	time 1.3205 (1.8908)	loss 3.4522 (3.9551)	grad_norm 0.2897 (0.3935)	mem 39782MB
[2023-07-07 10:29:17 RepVGG-A0] (main.py 282): INFO Train: [86/300][70/78]	eta 0:00:14 lr 5.164017	time 1.3213 (1.8224)	loss 3.5153 (3.8823)	grad_norm 0.3005 (0.3827)	mem 39782MB
[2023-07-07 10:29:29 RepVGG-A0] (main.py 291): INFO EPOCH 86 training takes 0:02:21
[2023-07-07 10:29:50 RepVGG-A0] (main.py 282): INFO Train: [87/300][0/78]	eta 0:28:03 lr 5.161303	time 21.5834 (21.5834)	loss 3.3599 (3.3599)	grad_norm 0.3264 (0.3264)	mem 39782MB
[2023-07-07 10:30:06 RepVGG-A0] (main.py 282): INFO Train: [87/300][10/78]	eta 0:03:49 lr 5.157906	time 1.1887 (3.3708)	loss 3.3083 (3.3419)	grad_norm 0.3041 (0.3253)	mem 39782MB
[2023-07-07 10:30:21 RepVGG-A0] (main.py 282): INFO Train: [87/300][20/78]	eta 0:02:23 lr 5.154506	time 1.2145 (2.4732)	loss 3.6212 (3.3582)	grad_norm 0.4556 (0.3385)	mem 39782MB
[2023-07-07 10:30:36 RepVGG-A0] (main.py 282): INFO Train: [87/300][30/78]	eta 0:01:43 lr 5.151103	time 1.5843 (2.1656)	loss 3.3424 (3.3642)	grad_norm 0.3088 (0.3321)	mem 39782MB
[2023-07-07 10:30:54 RepVGG-A0] (main.py 282): INFO Train: [87/300][40/78]	eta 0:01:18 lr 5.147696	time 4.2334 (2.0749)	loss 3.4401 (3.3635)	grad_norm 0.3761 (0.3334)	mem 39782MB
[2023-07-07 10:31:08 RepVGG-A0] (main.py 282): INFO Train: [87/300][50/78]	eta 0:00:54 lr 5.144285	time 1.1905 (1.9578)	loss 3.2744 (3.3593)	grad_norm 0.2973 (0.3326)	mem 39782MB
[2023-07-07 10:31:23 RepVGG-A0] (main.py 282): INFO Train: [87/300][60/78]	eta 0:00:33 lr 5.140871	time 1.1749 (1.8803)	loss 3.3527 (3.3729)	grad_norm 0.3193 (0.3411)	mem 39782MB
[2023-07-07 10:31:39 RepVGG-A0] (main.py 282): INFO Train: [87/300][70/78]	eta 0:00:14 lr 5.137454	time 1.2929 (1.8352)	loss 3.3767 (3.3672)	grad_norm 0.3821 (0.3391)	mem 39782MB
[2023-07-07 10:31:50 RepVGG-A0] (main.py 291): INFO EPOCH 87 training takes 0:02:21
[2023-07-07 10:32:13 RepVGG-A0] (main.py 282): INFO Train: [88/300][0/78]	eta 0:28:45 lr 5.134717	time 22.1205 (22.1205)	loss 3.2656 (3.2656)	grad_norm 0.3599 (0.3599)	mem 39782MB
[2023-07-07 10:32:28 RepVGG-A0] (main.py 282): INFO Train: [88/300][10/78]	eta 0:03:53 lr 5.131293	time 1.1889 (3.4378)	loss 3.3359 (3.3342)	grad_norm 0.3363 (0.3783)	mem 39782MB
[2023-07-07 10:32:43 RepVGG-A0] (main.py 282): INFO Train: [88/300][20/78]	eta 0:02:25 lr 5.127866	time 1.1837 (2.5072)	loss 3.2627 (3.3172)	grad_norm 0.3279 (0.3545)	mem 39782MB
[2023-07-07 10:32:58 RepVGG-A0] (main.py 282): INFO Train: [88/300][30/78]	eta 0:01:44 lr 5.124435	time 1.3844 (2.1773)	loss 3.3093 (3.3255)	grad_norm 0.3467 (0.3561)	mem 39782MB
[2023-07-07 10:33:16 RepVGG-A0] (main.py 282): INFO Train: [88/300][40/78]	eta 0:01:19 lr 5.121001	time 4.8547 (2.0932)	loss 3.4860 (3.3282)	grad_norm 0.4504 (0.3562)	mem 39782MB
[2023-07-07 10:33:30 RepVGG-A0] (main.py 282): INFO Train: [88/300][50/78]	eta 0:00:54 lr 5.117563	time 1.1764 (1.9611)	loss 5.6311 (3.6039)	grad_norm 0.5972 (0.4390)	mem 39782MB
[2023-07-07 10:33:46 RepVGG-A0] (main.py 282): INFO Train: [88/300][60/78]	eta 0:00:34 lr 5.114122	time 1.1865 (1.8961)	loss 4.4409 (3.8358)	grad_norm 0.2926 (0.4385)	mem 39782MB
[2023-07-07 10:34:01 RepVGG-A0] (main.py 282): INFO Train: [88/300][70/78]	eta 0:00:14 lr 5.110678	time 1.2932 (1.8377)	loss 4.0288 (3.8884)	grad_norm 0.2949 (0.4208)	mem 39782MB
[2023-07-07 10:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 88 training takes 0:02:23
[2023-07-07 10:34:36 RepVGG-A0] (main.py 282): INFO Train: [89/300][0/78]	eta 0:28:37 lr 5.107920	time 22.0139 (22.0139)	loss 3.7179 (3.7179)	grad_norm 0.2494 (0.2494)	mem 39782MB
[2023-07-07 10:34:50 RepVGG-A0] (main.py 282): INFO Train: [89/300][10/78]	eta 0:03:46 lr 5.104469	time 1.1910 (3.3335)	loss 3.6247 (3.6813)	grad_norm 0.2979 (0.2737)	mem 39782MB
[2023-07-07 10:35:05 RepVGG-A0] (main.py 282): INFO Train: [89/300][20/78]	eta 0:02:22 lr 5.101015	time 1.3321 (2.4494)	loss 3.6159 (3.6349)	grad_norm 0.3213 (0.2793)	mem 39782MB
[2023-07-07 10:35:19 RepVGG-A0] (main.py 282): INFO Train: [89/300][30/78]	eta 0:01:41 lr 5.097557	time 1.4643 (2.1215)	loss 3.4744 (3.5982)	grad_norm 0.3384 (0.2874)	mem 39782MB
[2023-07-07 10:35:37 RepVGG-A0] (main.py 282): INFO Train: [89/300][40/78]	eta 0:01:17 lr 5.094096	time 3.2334 (2.0426)	loss 3.4193 (3.5738)	grad_norm 0.2683 (0.2941)	mem 39782MB
[2023-07-07 10:35:52 RepVGG-A0] (main.py 282): INFO Train: [89/300][50/78]	eta 0:00:54 lr 5.090631	time 1.1898 (1.9335)	loss 3.4856 (3.5474)	grad_norm 0.3317 (0.2978)	mem 39782MB
[2023-07-07 10:36:08 RepVGG-A0] (main.py 282): INFO Train: [89/300][60/78]	eta 0:00:33 lr 5.087164	time 1.3171 (1.8688)	loss 3.4011 (3.5290)	grad_norm 0.3111 (0.3032)	mem 39782MB
[2023-07-07 10:36:23 RepVGG-A0] (main.py 282): INFO Train: [89/300][70/78]	eta 0:00:14 lr 5.083692	time 1.4697 (1.8232)	loss 3.3920 (3.5128)	grad_norm 0.3837 (0.3085)	mem 39782MB
[2023-07-07 10:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 89 training takes 0:02:20
[2023-07-07 10:36:55 RepVGG-A0] (main.py 282): INFO Train: [90/300][0/78]	eta 0:27:57 lr 5.080913	time 21.5036 (21.5036)	loss 3.3146 (3.3146)	grad_norm 0.2854 (0.2854)	mem 39782MB
[2023-07-07 10:37:11 RepVGG-A0] (main.py 282): INFO Train: [90/300][10/78]	eta 0:03:49 lr 5.077435	time 1.1715 (3.3703)	loss 3.5887 (3.4764)	grad_norm 0.4454 (0.4168)	mem 39782MB
[2023-07-07 10:37:25 RepVGG-A0] (main.py 282): INFO Train: [90/300][20/78]	eta 0:02:21 lr 5.073955	time 1.1969 (2.4323)	loss 3.3897 (3.4677)	grad_norm 0.2934 (0.3839)	mem 39782MB
[2023-07-07 10:37:40 RepVGG-A0] (main.py 282): INFO Train: [90/300][30/78]	eta 0:01:42 lr 5.070470	time 1.3013 (2.1407)	loss 3.3930 (3.4348)	grad_norm 0.3416 (0.3664)	mem 39782MB
[2023-07-07 10:37:58 RepVGG-A0] (main.py 282): INFO Train: [90/300][40/78]	eta 0:01:18 lr 5.066983	time 3.7081 (2.0603)	loss 3.3160 (3.4123)	grad_norm 0.2938 (0.3541)	mem 39782MB
[2023-07-07 10:38:14 RepVGG-A0] (main.py 282): INFO Train: [90/300][50/78]	eta 0:00:54 lr 5.063492	time 1.1727 (1.9551)	loss 3.5511 (3.4078)	grad_norm 0.4873 (0.3578)	mem 39782MB
[2023-07-07 10:38:28 RepVGG-A0] (main.py 282): INFO Train: [90/300][60/78]	eta 0:00:33 lr 5.059998	time 1.2985 (1.8720)	loss 5.1939 (3.5920)	grad_norm 0.6534 (0.4244)	mem 39782MB
[2023-07-07 10:38:43 RepVGG-A0] (main.py 282): INFO Train: [90/300][70/78]	eta 0:00:14 lr 5.056500	time 1.1250 (1.8228)	loss 4.0426 (3.7149)	grad_norm 0.2893 (0.4222)	mem 39782MB
[2023-07-07 10:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 90 training takes 0:02:20
[2023-07-07 10:39:17 RepVGG-A0] (main.py 282): INFO Train: [91/300][0/78]	eta 0:28:41 lr 5.053700	time 22.0700 (22.0700)	loss 3.7286 (3.7286)	grad_norm 0.2900 (0.2900)	mem 39782MB
[2023-07-07 10:39:31 RepVGG-A0] (main.py 282): INFO Train: [91/300][10/78]	eta 0:03:42 lr 5.050196	time 1.1731 (3.2739)	loss 3.5769 (3.6513)	grad_norm 0.3048 (0.2744)	mem 39782MB
[2023-07-07 10:39:46 RepVGG-A0] (main.py 282): INFO Train: [91/300][20/78]	eta 0:02:20 lr 5.046689	time 1.3494 (2.4199)	loss 3.4872 (3.5966)	grad_norm 0.2436 (0.2787)	mem 39782MB
[2023-07-07 10:40:03 RepVGG-A0] (main.py 282): INFO Train: [91/300][30/78]	eta 0:01:44 lr 5.043179	time 1.6180 (2.1854)	loss 3.4017 (3.5445)	grad_norm 0.2710 (0.2819)	mem 39782MB
[2023-07-07 10:40:18 RepVGG-A0] (main.py 282): INFO Train: [91/300][40/78]	eta 0:01:17 lr 5.039665	time 2.8671 (2.0316)	loss 3.4540 (3.5123)	grad_norm 0.2918 (0.2888)	mem 39782MB
[2023-07-07 10:40:33 RepVGG-A0] (main.py 282): INFO Train: [91/300][50/78]	eta 0:00:53 lr 5.036148	time 1.1727 (1.9241)	loss 3.4901 (3.4888)	grad_norm 0.3607 (0.2909)	mem 39782MB
[2023-07-07 10:40:48 RepVGG-A0] (main.py 282): INFO Train: [91/300][60/78]	eta 0:00:33 lr 5.032628	time 1.1992 (1.8503)	loss 3.4544 (3.4811)	grad_norm 0.3677 (0.3011)	mem 39782MB
[2023-07-07 10:41:03 RepVGG-A0] (main.py 282): INFO Train: [91/300][70/78]	eta 0:00:14 lr 5.029105	time 1.3198 (1.8078)	loss 3.3105 (3.4616)	grad_norm 0.3018 (0.3001)	mem 39782MB
[2023-07-07 10:41:15 RepVGG-A0] (main.py 291): INFO EPOCH 91 training takes 0:02:20
[2023-07-07 10:41:36 RepVGG-A0] (main.py 282): INFO Train: [92/300][0/78]	eta 0:27:24 lr 5.026283	time 21.0781 (21.0781)	loss 3.5226 (3.5226)	grad_norm 0.4467 (0.4467)	mem 39782MB
[2023-07-07 10:41:51 RepVGG-A0] (main.py 282): INFO Train: [92/300][10/78]	eta 0:03:42 lr 5.022754	time 1.1717 (3.2673)	loss 3.3644 (3.4170)	grad_norm 0.3085 (0.3474)	mem 39782MB
[2023-07-07 10:42:05 RepVGG-A0] (main.py 282): INFO Train: [92/300][20/78]	eta 0:02:18 lr 5.019221	time 1.1720 (2.3876)	loss 3.4381 (3.3904)	grad_norm 0.3563 (0.3408)	mem 39782MB
[2023-07-07 10:42:20 RepVGG-A0] (main.py 282): INFO Train: [92/300][30/78]	eta 0:01:40 lr 5.015685	time 1.2190 (2.1037)	loss 3.3955 (3.3735)	grad_norm 0.3890 (0.3458)	mem 39782MB
[2023-07-07 10:42:38 RepVGG-A0] (main.py 282): INFO Train: [92/300][40/78]	eta 0:01:16 lr 5.012146	time 4.2059 (2.0245)	loss 3.3203 (3.3684)	grad_norm 0.3086 (0.3479)	mem 39782MB
[2023-07-07 10:42:53 RepVGG-A0] (main.py 282): INFO Train: [92/300][50/78]	eta 0:00:53 lr 5.008603	time 1.1735 (1.9231)	loss 3.3195 (3.3573)	grad_norm 0.3969 (0.3440)	mem 39782MB
[2023-07-07 10:43:08 RepVGG-A0] (main.py 282): INFO Train: [92/300][60/78]	eta 0:00:33 lr 5.005057	time 1.1953 (1.8580)	loss 3.3773 (3.3752)	grad_norm 0.3106 (0.3543)	mem 39782MB
[2023-07-07 10:43:23 RepVGG-A0] (main.py 282): INFO Train: [92/300][70/78]	eta 0:00:14 lr 5.001508	time 1.2914 (1.8083)	loss 3.3509 (3.3698)	grad_norm 0.3792 (0.3507)	mem 39782MB
[2023-07-07 10:43:35 RepVGG-A0] (main.py 291): INFO EPOCH 92 training takes 0:02:20
[2023-07-07 10:43:57 RepVGG-A0] (main.py 282): INFO Train: [93/300][0/78]	eta 0:28:38 lr 4.998667	time 22.0348 (22.0348)	loss 3.5261 (3.5261)	grad_norm 0.4690 (0.4690)	mem 39782MB
[2023-07-07 10:44:12 RepVGG-A0] (main.py 282): INFO Train: [93/300][10/78]	eta 0:03:47 lr 4.995112	time 1.1722 (3.3383)	loss 3.2938 (3.3512)	grad_norm 0.3758 (0.3627)	mem 39782MB
[2023-07-07 10:44:26 RepVGG-A0] (main.py 282): INFO Train: [93/300][20/78]	eta 0:02:18 lr 4.991554	time 1.1722 (2.3948)	loss 3.2901 (3.3154)	grad_norm 0.3243 (0.3417)	mem 39782MB
[2023-07-07 10:44:42 RepVGG-A0] (main.py 282): INFO Train: [93/300][30/78]	eta 0:01:42 lr 4.987992	time 1.7636 (2.1441)	loss 3.4515 (3.3279)	grad_norm 0.3700 (0.3540)	mem 39782MB
[2023-07-07 10:44:59 RepVGG-A0] (main.py 282): INFO Train: [93/300][40/78]	eta 0:01:17 lr 4.984428	time 3.4641 (2.0383)	loss 3.2908 (3.3181)	grad_norm 0.3630 (0.3527)	mem 39782MB
[2023-07-07 10:45:14 RepVGG-A0] (main.py 282): INFO Train: [93/300][50/78]	eta 0:00:54 lr 4.980860	time 1.1735 (1.9333)	loss 3.2946 (3.3162)	grad_norm 0.3187 (0.3509)	mem 39782MB
[2023-07-07 10:45:29 RepVGG-A0] (main.py 282): INFO Train: [93/300][60/78]	eta 0:00:33 lr 4.977289	time 1.3001 (1.8635)	loss 3.7642 (3.3534)	grad_norm 0.5721 (0.3726)	mem 39782MB
[2023-07-07 10:45:44 RepVGG-A0] (main.py 282): INFO Train: [93/300][70/78]	eta 0:00:14 lr 4.973715	time 1.3835 (1.8172)	loss 3.4251 (3.3890)	grad_norm 0.2790 (0.3798)	mem 39782MB
[2023-07-07 10:45:56 RepVGG-A0] (main.py 291): INFO EPOCH 93 training takes 0:02:20
[2023-07-07 10:46:16 RepVGG-A0] (main.py 282): INFO Train: [94/300][0/78]	eta 0:26:05 lr 4.970853	time 20.0751 (20.0751)	loss 3.2433 (3.2433)	grad_norm 0.2970 (0.2970)	mem 39782MB
[2023-07-07 10:46:33 RepVGG-A0] (main.py 282): INFO Train: [94/300][10/78]	eta 0:03:47 lr 4.967273	time 1.1718 (3.3481)	loss 3.2802 (3.2434)	grad_norm 0.3257 (0.3105)	mem 39782MB
[2023-07-07 10:46:49 RepVGG-A0] (main.py 282): INFO Train: [94/300][20/78]	eta 0:02:25 lr 4.963690	time 1.1781 (2.5078)	loss 3.2942 (3.2686)	grad_norm 0.3192 (0.3282)	mem 39782MB
[2023-07-07 10:47:05 RepVGG-A0] (main.py 282): INFO Train: [94/300][30/78]	eta 0:01:47 lr 4.960103	time 1.7748 (2.2336)	loss 3.3379 (3.2677)	grad_norm 0.3676 (0.3276)	mem 39782MB
[2023-07-07 10:47:21 RepVGG-A0] (main.py 282): INFO Train: [94/300][40/78]	eta 0:01:18 lr 4.956514	time 1.8054 (2.0750)	loss 3.3975 (3.3116)	grad_norm 0.3815 (0.3565)	mem 39782MB
[2023-07-07 10:47:36 RepVGG-A0] (main.py 282): INFO Train: [94/300][50/78]	eta 0:00:54 lr 4.952921	time 1.1944 (1.9634)	loss 3.2241 (3.3022)	grad_norm 0.3048 (0.3481)	mem 39782MB
[2023-07-07 10:47:51 RepVGG-A0] (main.py 282): INFO Train: [94/300][60/78]	eta 0:00:33 lr 4.949325	time 1.1869 (1.8839)	loss 3.3141 (3.2982)	grad_norm 0.3780 (0.3469)	mem 39782MB
[2023-07-07 10:48:06 RepVGG-A0] (main.py 282): INFO Train: [94/300][70/78]	eta 0:00:14 lr 4.945726	time 1.4555 (1.8256)	loss 3.2119 (3.2947)	grad_norm 0.3318 (0.3462)	mem 39782MB
[2023-07-07 10:48:18 RepVGG-A0] (main.py 291): INFO EPOCH 94 training takes 0:02:21
[2023-07-07 10:48:40 RepVGG-A0] (main.py 282): INFO Train: [95/300][0/78]	eta 0:28:41 lr 4.942845	time 22.0702 (22.0702)	loss 3.3788 (3.3788)	grad_norm 0.4473 (0.4473)	mem 39782MB
[2023-07-07 10:48:54 RepVGG-A0] (main.py 282): INFO Train: [95/300][10/78]	eta 0:03:44 lr 4.939240	time 1.1720 (3.3049)	loss 3.2247 (3.3487)	grad_norm 0.3206 (0.3940)	mem 39782MB
[2023-07-07 10:49:10 RepVGG-A0] (main.py 282): INFO Train: [95/300][20/78]	eta 0:02:23 lr 4.935632	time 1.1280 (2.4720)	loss 3.2115 (3.2931)	grad_norm 0.3305 (0.3543)	mem 39782MB
[2023-07-07 10:49:25 RepVGG-A0] (main.py 282): INFO Train: [95/300][30/78]	eta 0:01:44 lr 4.932022	time 1.4717 (2.1711)	loss 3.3255 (3.2968)	grad_norm 0.4079 (0.3655)	mem 39782MB
[2023-07-07 10:49:42 RepVGG-A0] (main.py 282): INFO Train: [95/300][40/78]	eta 0:01:17 lr 4.928407	time 2.4127 (2.0474)	loss 3.2683 (3.3011)	grad_norm 0.3472 (0.3665)	mem 39782MB
[2023-07-07 10:49:57 RepVGG-A0] (main.py 282): INFO Train: [95/300][50/78]	eta 0:00:54 lr 4.924790	time 1.1722 (1.9472)	loss 3.3505 (3.2946)	grad_norm 0.4050 (0.3629)	mem 39782MB
[2023-07-07 10:50:12 RepVGG-A0] (main.py 282): INFO Train: [95/300][60/78]	eta 0:00:33 lr 4.921170	time 1.4023 (1.8676)	loss 3.2599 (3.3032)	grad_norm 0.2904 (0.3676)	mem 39782MB
[2023-07-07 10:50:26 RepVGG-A0] (main.py 282): INFO Train: [95/300][70/78]	eta 0:00:14 lr 4.917547	time 1.3819 (1.8124)	loss 3.2654 (3.2990)	grad_norm 0.3459 (0.3644)	mem 39782MB
[2023-07-07 10:50:38 RepVGG-A0] (main.py 291): INFO EPOCH 95 training takes 0:02:20
[2023-07-07 10:50:59 RepVGG-A0] (main.py 282): INFO Train: [96/300][0/78]	eta 0:27:10 lr 4.914646	time 20.8996 (20.8996)	loss 3.3319 (3.3319)	grad_norm 0.4653 (0.4653)	mem 39782MB
[2023-07-07 10:51:14 RepVGG-A0] (main.py 282): INFO Train: [96/300][10/78]	eta 0:03:40 lr 4.911017	time 1.1912 (3.2447)	loss 6.4072 (4.4671)	grad_norm 0.8510 (0.8143)	mem 39782MB
[2023-07-07 10:51:29 RepVGG-A0] (main.py 282): INFO Train: [96/300][20/78]	eta 0:02:19 lr 4.907385	time 1.1723 (2.4007)	loss 5.2152 (5.1176)	grad_norm 0.2901 (0.6619)	mem 39782MB
[2023-07-07 10:51:43 RepVGG-A0] (main.py 282): INFO Train: [96/300][30/78]	eta 0:01:40 lr 4.903750	time 1.1838 (2.0925)	loss 4.4740 (5.0162)	grad_norm 0.2770 (0.5503)	mem 39782MB
[2023-07-07 10:52:02 RepVGG-A0] (main.py 282): INFO Train: [96/300][40/78]	eta 0:01:17 lr 4.900111	time 4.2547 (2.0292)	loss 4.1644 (4.8469)	grad_norm 0.2482 (0.4951)	mem 39782MB
[2023-07-07 10:52:16 RepVGG-A0] (main.py 282): INFO Train: [96/300][50/78]	eta 0:00:53 lr 4.896470	time 1.1715 (1.9158)	loss 3.8858 (4.6830)	grad_norm 0.2669 (0.4522)	mem 39782MB
[2023-07-07 10:52:31 RepVGG-A0] (main.py 282): INFO Train: [96/300][60/78]	eta 0:00:33 lr 4.892826	time 1.2328 (1.8457)	loss 3.7846 (4.5411)	grad_norm 0.3133 (0.4259)	mem 39782MB
[2023-07-07 10:52:47 RepVGG-A0] (main.py 282): INFO Train: [96/300][70/78]	eta 0:00:14 lr 4.889179	time 1.3914 (1.8087)	loss 3.6748 (4.4276)	grad_norm 0.3464 (0.4095)	mem 39782MB
[2023-07-07 10:52:58 RepVGG-A0] (main.py 291): INFO EPOCH 96 training takes 0:02:19
[2023-07-07 10:53:20 RepVGG-A0] (main.py 282): INFO Train: [97/300][0/78]	eta 0:28:42 lr 4.886259	time 22.0770 (22.0770)	loss 3.5866 (3.5866)	grad_norm 0.2730 (0.2730)	mem 39782MB
[2023-07-07 10:53:35 RepVGG-A0] (main.py 282): INFO Train: [97/300][10/78]	eta 0:03:44 lr 4.882606	time 1.1892 (3.3021)	loss 3.5700 (3.5697)	grad_norm 0.3142 (0.3169)	mem 39782MB
[2023-07-07 10:53:49 RepVGG-A0] (main.py 282): INFO Train: [97/300][20/78]	eta 0:02:19 lr 4.878950	time 1.2572 (2.4024)	loss 3.5478 (3.5603)	grad_norm 0.3494 (0.3215)	mem 39782MB
[2023-07-07 10:54:05 RepVGG-A0] (main.py 282): INFO Train: [97/300][30/78]	eta 0:01:43 lr 4.875291	time 1.8300 (2.1556)	loss 3.6845 (3.5627)	grad_norm 0.3804 (0.3323)	mem 39782MB
[2023-07-07 10:54:23 RepVGG-A0] (main.py 282): INFO Train: [97/300][40/78]	eta 0:01:17 lr 4.871629	time 3.5378 (2.0524)	loss 3.4523 (3.5468)	grad_norm 0.3200 (0.3301)	mem 39782MB
[2023-07-07 10:54:37 RepVGG-A0] (main.py 282): INFO Train: [97/300][50/78]	eta 0:00:54 lr 4.867964	time 1.1778 (1.9362)	loss 3.4659 (3.5431)	grad_norm 0.3250 (0.3386)	mem 39782MB
[2023-07-07 10:54:52 RepVGG-A0] (main.py 282): INFO Train: [97/300][60/78]	eta 0:00:33 lr 4.864296	time 1.1804 (1.8688)	loss 3.4271 (3.5267)	grad_norm 0.3264 (0.3380)	mem 39782MB
[2023-07-07 10:55:07 RepVGG-A0] (main.py 282): INFO Train: [97/300][70/78]	eta 0:00:14 lr 4.860625	time 1.1955 (1.8146)	loss 3.5593 (3.5225)	grad_norm 0.3968 (0.3426)	mem 39782MB
[2023-07-07 10:55:19 RepVGG-A0] (main.py 291): INFO EPOCH 97 training takes 0:02:20
[2023-07-07 10:55:40 RepVGG-A0] (main.py 282): INFO Train: [98/300][0/78]	eta 0:27:50 lr 4.857686	time 21.4141 (21.4141)	loss 3.3725 (3.3725)	grad_norm 0.3202 (0.3202)	mem 39782MB
[2023-07-07 10:55:54 RepVGG-A0] (main.py 282): INFO Train: [98/300][10/78]	eta 0:03:39 lr 4.854010	time 1.1922 (3.2267)	loss 3.4985 (3.5032)	grad_norm 0.3928 (0.4157)	mem 39782MB
[2023-07-07 10:56:09 RepVGG-A0] (main.py 282): INFO Train: [98/300][20/78]	eta 0:02:20 lr 4.850331	time 1.1724 (2.4154)	loss 3.3178 (3.4510)	grad_norm 0.3147 (0.3766)	mem 39782MB
[2023-07-07 10:56:24 RepVGG-A0] (main.py 282): INFO Train: [98/300][30/78]	eta 0:01:41 lr 4.846649	time 1.4358 (2.1172)	loss 3.4511 (3.4181)	grad_norm 0.3499 (0.3597)	mem 39782MB
[2023-07-07 10:56:42 RepVGG-A0] (main.py 282): INFO Train: [98/300][40/78]	eta 0:01:17 lr 4.842963	time 3.7182 (2.0455)	loss 3.4759 (3.4084)	grad_norm 0.4264 (0.3585)	mem 39782MB
[2023-07-07 10:56:58 RepVGG-A0] (main.py 282): INFO Train: [98/300][50/78]	eta 0:00:54 lr 4.839275	time 1.2542 (1.9401)	loss 3.4990 (3.4335)	grad_norm 0.3982 (0.3720)	mem 39782MB
[2023-07-07 10:57:12 RepVGG-A0] (main.py 282): INFO Train: [98/300][60/78]	eta 0:00:33 lr 4.835584	time 1.2931 (1.8670)	loss 3.3627 (3.4242)	grad_norm 0.3177 (0.3655)	mem 39782MB
[2023-07-07 10:57:28 RepVGG-A0] (main.py 282): INFO Train: [98/300][70/78]	eta 0:00:14 lr 4.831890	time 1.3531 (1.8182)	loss 3.3378 (3.4124)	grad_norm 0.3478 (0.3604)	mem 39782MB
[2023-07-07 10:57:40 RepVGG-A0] (main.py 291): INFO EPOCH 98 training takes 0:02:21
[2023-07-07 10:58:02 RepVGG-A0] (main.py 282): INFO Train: [99/300][0/78]	eta 0:28:06 lr 4.828933	time 21.6217 (21.6217)	loss 3.3455 (3.3455)	grad_norm 0.4066 (0.4066)	mem 39782MB
[2023-07-07 10:58:16 RepVGG-A0] (main.py 282): INFO Train: [99/300][10/78]	eta 0:03:40 lr 4.825233	time 1.1714 (3.2431)	loss 3.3686 (3.4282)	grad_norm 0.3805 (0.4299)	mem 39782MB
[2023-07-07 10:58:29 RepVGG-A0] (main.py 282): INFO Train: [99/300][20/78]	eta 0:02:15 lr 4.821531	time 1.1720 (2.3406)	loss 3.2526 (3.3591)	grad_norm 0.3074 (0.3755)	mem 39782MB
[2023-07-07 10:58:44 RepVGG-A0] (main.py 282): INFO Train: [99/300][30/78]	eta 0:01:39 lr 4.817826	time 1.3026 (2.0625)	loss 3.4042 (3.3535)	grad_norm 0.3995 (0.3717)	mem 39782MB
[2023-07-07 10:59:03 RepVGG-A0] (main.py 282): INFO Train: [99/300][40/78]	eta 0:01:16 lr 4.814117	time 4.1367 (2.0128)	loss 3.7515 (3.4071)	grad_norm 0.5800 (0.4067)	mem 39782MB
[2023-07-07 10:59:17 RepVGG-A0] (main.py 282): INFO Train: [99/300][50/78]	eta 0:00:53 lr 4.810406	time 1.2292 (1.9034)	loss 3.4412 (3.4308)	grad_norm 0.3095 (0.3978)	mem 39782MB
[2023-07-07 10:59:33 RepVGG-A0] (main.py 282): INFO Train: [99/300][60/78]	eta 0:00:33 lr 4.806692	time 1.1880 (1.8416)	loss 3.3027 (3.4200)	grad_norm 0.3078 (0.3838)	mem 39782MB
[2023-07-07 10:59:48 RepVGG-A0] (main.py 282): INFO Train: [99/300][70/78]	eta 0:00:14 lr 4.802976	time 1.4935 (1.7987)	loss 3.3194 (3.4056)	grad_norm 0.3218 (0.3770)	mem 39782MB
[2023-07-07 10:59:59 RepVGG-A0] (main.py 291): INFO EPOCH 99 training takes 0:02:18
[2023-07-07 11:00:20 RepVGG-A0] (main.py 282): INFO Train: [100/300][0/78]	eta 0:27:03 lr 4.800000	time 20.8150 (20.8150)	loss 3.2848 (3.2848)	grad_norm 0.3370 (0.3370)	mem 39782MB
[2023-07-07 11:00:33 RepVGG-A0] (main.py 282): INFO Train: [100/300][10/78]	eta 0:03:33 lr 4.796278	time 1.1726 (3.1328)	loss 3.2705 (3.2893)	grad_norm 0.3589 (0.3672)	mem 39782MB
[2023-07-07 11:00:48 RepVGG-A0] (main.py 282): INFO Train: [100/300][20/78]	eta 0:02:15 lr 4.792553	time 1.1717 (2.3344)	loss 3.2757 (3.2742)	grad_norm 0.3386 (0.3572)	mem 39782MB
[2023-07-07 11:01:03 RepVGG-A0] (main.py 282): INFO Train: [100/300][30/78]	eta 0:01:39 lr 4.788825	time 1.2669 (2.0796)	loss 3.3002 (3.2908)	grad_norm 0.3677 (0.3633)	mem 39782MB
[2023-07-07 11:01:21 RepVGG-A0] (main.py 282): INFO Train: [100/300][40/78]	eta 0:01:16 lr 4.785095	time 3.1208 (2.0030)	loss 3.2788 (3.2922)	grad_norm 0.3622 (0.3610)	mem 39782MB
[2023-07-07 11:01:36 RepVGG-A0] (main.py 282): INFO Train: [100/300][50/78]	eta 0:00:53 lr 4.781361	time 1.2915 (1.9045)	loss 3.3285 (3.2901)	grad_norm 0.3899 (0.3616)	mem 39782MB
[2023-07-07 11:01:51 RepVGG-A0] (main.py 282): INFO Train: [100/300][60/78]	eta 0:00:33 lr 4.777625	time 1.1930 (1.8358)	loss 3.2945 (3.2915)	grad_norm 0.3464 (0.3632)	mem 39782MB
[2023-07-07 11:02:06 RepVGG-A0] (main.py 282): INFO Train: [100/300][70/78]	eta 0:00:14 lr 4.773885	time 1.2159 (1.7930)	loss 3.3147 (3.2958)	grad_norm 0.4160 (0.3661)	mem 39782MB
[2023-07-07 11:02:18 RepVGG-A0] (main.py 291): INFO EPOCH 100 training takes 0:02:19
[2023-07-07 11:02:36 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.360 (17.360)	Loss 2.8196 (2.8196)	Acc@1 40.741 (40.741)	Acc@5 66.449 (66.449)	Mem 39782MB
[2023-07-07 11:02:37 RepVGG-A0] (main.py 342): INFO  * Acc@1 40.988 Acc@5 66.530
[2023-07-07 11:02:37 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 100: 40.988%
[2023-07-07 11:02:37 RepVGG-A0] (main.py 172): INFO Max accuracy: 40.99%
[2023-07-07 11:02:58 RepVGG-A0] (main.py 282): INFO Train: [101/300][0/78]	eta 0:27:36 lr 4.770892	time 21.2367 (21.2367)	loss 3.1766 (3.1766)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 11:03:15 RepVGG-A0] (main.py 282): INFO Train: [101/300][10/78]	eta 0:03:58 lr 4.767148	time 1.1759 (3.5089)	loss 3.2377 (3.2320)	grad_norm 0.3965 (0.3596)	mem 39782MB
[2023-07-07 11:03:29 RepVGG-A0] (main.py 282): INFO Train: [101/300][20/78]	eta 0:02:24 lr 4.763401	time 1.1763 (2.4951)	loss 3.2945 (3.2573)	grad_norm 0.3963 (0.3756)	mem 39782MB
[2023-07-07 11:03:45 RepVGG-A0] (main.py 282): INFO Train: [101/300][30/78]	eta 0:01:45 lr 4.759651	time 1.6927 (2.1985)	loss 3.2941 (3.2754)	grad_norm 0.3679 (0.3772)	mem 39782MB
[2023-07-07 11:04:03 RepVGG-A0] (main.py 282): INFO Train: [101/300][40/78]	eta 0:01:20 lr 4.755898	time 4.5352 (2.1069)	loss 3.1886 (3.2679)	grad_norm 0.3157 (0.3655)	mem 39782MB
[2023-07-07 11:04:17 RepVGG-A0] (main.py 282): INFO Train: [101/300][50/78]	eta 0:00:55 lr 4.752142	time 1.3044 (1.9728)	loss 6.5074 (3.5021)	grad_norm 0.9319 (0.4543)	mem 39782MB
[2023-07-07 11:04:33 RepVGG-A0] (main.py 282): INFO Train: [101/300][60/78]	eta 0:00:34 lr 4.748384	time 1.1945 (1.8983)	loss 5.4677 (3.9064)	grad_norm 0.3905 (0.4563)	mem 39782MB
[2023-07-07 11:04:48 RepVGG-A0] (main.py 282): INFO Train: [101/300][70/78]	eta 0:00:14 lr 4.744623	time 1.2887 (1.8485)	loss 4.8046 (4.0817)	grad_norm 0.2919 (0.4443)	mem 39782MB
[2023-07-07 11:04:59 RepVGG-A0] (main.py 291): INFO EPOCH 101 training takes 0:02:21
[2023-07-07 11:05:20 RepVGG-A0] (main.py 282): INFO Train: [102/300][0/78]	eta 0:27:34 lr 4.741612	time 21.2057 (21.2057)	loss 4.3811 (4.3811)	grad_norm 0.2890 (0.2890)	mem 39782MB
[2023-07-07 11:05:34 RepVGG-A0] (main.py 282): INFO Train: [102/300][10/78]	eta 0:03:41 lr 4.737846	time 1.1716 (3.2533)	loss 4.2305 (4.2983)	grad_norm 0.3381 (0.3161)	mem 39782MB
[2023-07-07 11:05:49 RepVGG-A0] (main.py 282): INFO Train: [102/300][20/78]	eta 0:02:18 lr 4.734077	time 1.1727 (2.3916)	loss 3.9360 (4.1882)	grad_norm 0.3016 (0.3182)	mem 39782MB
[2023-07-07 11:06:04 RepVGG-A0] (main.py 282): INFO Train: [102/300][30/78]	eta 0:01:41 lr 4.730305	time 1.1287 (2.1197)	loss 3.8977 (4.0861)	grad_norm 0.4031 (0.3212)	mem 39782MB
[2023-07-07 11:06:23 RepVGG-A0] (main.py 282): INFO Train: [102/300][40/78]	eta 0:01:18 lr 4.726530	time 3.8079 (2.0600)	loss 3.7570 (4.0201)	grad_norm 0.3427 (0.3224)	mem 39782MB
[2023-07-07 11:06:38 RepVGG-A0] (main.py 282): INFO Train: [102/300][50/78]	eta 0:00:54 lr 4.722753	time 1.1729 (1.9432)	loss 3.6525 (3.9544)	grad_norm 0.3630 (0.3240)	mem 39782MB
[2023-07-07 11:06:53 RepVGG-A0] (main.py 282): INFO Train: [102/300][60/78]	eta 0:00:33 lr 4.718973	time 1.5152 (1.8761)	loss 3.6422 (3.9103)	grad_norm 0.3410 (0.3284)	mem 39782MB
[2023-07-07 11:07:07 RepVGG-A0] (main.py 282): INFO Train: [102/300][70/78]	eta 0:00:14 lr 4.715191	time 1.3876 (1.8139)	loss 3.5693 (3.8669)	grad_norm 0.3241 (0.3260)	mem 39782MB
[2023-07-07 11:07:19 RepVGG-A0] (main.py 291): INFO EPOCH 102 training takes 0:02:20
[2023-07-07 11:07:42 RepVGG-A0] (main.py 282): INFO Train: [103/300][0/78]	eta 0:30:07 lr 4.712162	time 23.1685 (23.1685)	loss 3.5891 (3.5891)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 11:07:58 RepVGG-A0] (main.py 282): INFO Train: [103/300][10/78]	eta 0:04:02 lr 4.708375	time 1.2902 (3.5709)	loss 3.4884 (3.5242)	grad_norm 0.3307 (0.3436)	mem 39782MB
[2023-07-07 11:08:12 RepVGG-A0] (main.py 282): INFO Train: [103/300][20/78]	eta 0:02:28 lr 4.704585	time 1.1726 (2.5540)	loss 3.6203 (3.5107)	grad_norm 0.4160 (0.3458)	mem 39782MB
[2023-07-07 11:08:29 RepVGG-A0] (main.py 282): INFO Train: [103/300][30/78]	eta 0:01:48 lr 4.700791	time 1.6187 (2.2542)	loss 3.4482 (3.5057)	grad_norm 0.3507 (0.3477)	mem 39782MB
[2023-07-07 11:08:46 RepVGG-A0] (main.py 282): INFO Train: [103/300][40/78]	eta 0:01:20 lr 4.696996	time 4.1501 (2.1224)	loss 3.5611 (3.5071)	grad_norm 0.4226 (0.3557)	mem 39782MB
[2023-07-07 11:09:02 RepVGG-A0] (main.py 282): INFO Train: [103/300][50/78]	eta 0:00:56 lr 4.693197	time 1.3066 (2.0169)	loss 3.4245 (3.5047)	grad_norm 0.3632 (0.3557)	mem 39782MB
[2023-07-07 11:09:17 RepVGG-A0] (main.py 282): INFO Train: [103/300][60/78]	eta 0:00:34 lr 4.689396	time 1.3378 (1.9339)	loss 3.5287 (3.5003)	grad_norm 0.3377 (0.3563)	mem 39782MB
[2023-07-07 11:09:31 RepVGG-A0] (main.py 282): INFO Train: [103/300][70/78]	eta 0:00:14 lr 4.685592	time 1.3422 (1.8708)	loss 3.8729 (3.5190)	grad_norm 0.6074 (0.3754)	mem 39782MB
[2023-07-07 11:09:43 RepVGG-A0] (main.py 291): INFO EPOCH 103 training takes 0:02:24
[2023-07-07 11:10:05 RepVGG-A0] (main.py 282): INFO Train: [104/300][0/78]	eta 0:28:36 lr 4.682547	time 22.0053 (22.0053)	loss 3.5695 (3.5695)	grad_norm 0.3481 (0.3481)	mem 39782MB
[2023-07-07 11:10:21 RepVGG-A0] (main.py 282): INFO Train: [104/300][10/78]	eta 0:03:51 lr 4.678739	time 1.1726 (3.3986)	loss 3.3385 (3.4549)	grad_norm 0.2905 (0.3089)	mem 39782MB
[2023-07-07 11:10:36 RepVGG-A0] (main.py 282): INFO Train: [104/300][20/78]	eta 0:02:25 lr 4.674927	time 1.2042 (2.5087)	loss 3.3418 (3.4251)	grad_norm 0.3190 (0.3227)	mem 39782MB
[2023-07-07 11:10:52 RepVGG-A0] (main.py 282): INFO Train: [104/300][30/78]	eta 0:01:45 lr 4.671113	time 1.3603 (2.1970)	loss 3.4734 (3.4135)	grad_norm 0.4319 (0.3306)	mem 39782MB
[2023-07-07 11:11:09 RepVGG-A0] (main.py 282): INFO Train: [104/300][40/78]	eta 0:01:19 lr 4.667297	time 3.5080 (2.0792)	loss 3.4252 (3.4025)	grad_norm 0.3650 (0.3313)	mem 39782MB
[2023-07-07 11:11:23 RepVGG-A0] (main.py 282): INFO Train: [104/300][50/78]	eta 0:00:54 lr 4.663478	time 1.1740 (1.9607)	loss 3.3913 (3.3972)	grad_norm 0.3621 (0.3355)	mem 39782MB
[2023-07-07 11:11:39 RepVGG-A0] (main.py 282): INFO Train: [104/300][60/78]	eta 0:00:34 lr 4.659656	time 1.1754 (1.8972)	loss 3.4693 (3.3923)	grad_norm 0.4318 (0.3407)	mem 39782MB
[2023-07-07 11:11:54 RepVGG-A0] (main.py 282): INFO Train: [104/300][70/78]	eta 0:00:14 lr 4.655831	time 1.2900 (1.8421)	loss 5.5489 (3.5194)	grad_norm 0.8881 (0.3996)	mem 39782MB
[2023-07-07 11:12:06 RepVGG-A0] (main.py 291): INFO EPOCH 104 training takes 0:02:22
[2023-07-07 11:12:26 RepVGG-A0] (main.py 282): INFO Train: [105/300][0/78]	eta 0:26:12 lr 4.652770	time 20.1637 (20.1637)	loss 4.1268 (4.1268)	grad_norm 0.3295 (0.3295)	mem 39782MB
[2023-07-07 11:12:41 RepVGG-A0] (main.py 282): INFO Train: [105/300][10/78]	eta 0:03:35 lr 4.648940	time 1.1729 (3.1723)	loss 3.7253 (3.8998)	grad_norm 0.2783 (0.2920)	mem 39782MB
[2023-07-07 11:12:55 RepVGG-A0] (main.py 282): INFO Train: [105/300][20/78]	eta 0:02:15 lr 4.645108	time 1.1717 (2.3443)	loss 3.5705 (3.7619)	grad_norm 0.2957 (0.2914)	mem 39782MB
[2023-07-07 11:13:09 RepVGG-A0] (main.py 282): INFO Train: [105/300][30/78]	eta 0:01:38 lr 4.641274	time 1.2239 (2.0544)	loss 3.4851 (3.6779)	grad_norm 0.3138 (0.2870)	mem 39782MB
[2023-07-07 11:13:28 RepVGG-A0] (main.py 282): INFO Train: [105/300][40/78]	eta 0:01:15 lr 4.637437	time 3.7940 (1.9956)	loss 3.4678 (3.6204)	grad_norm 0.3247 (0.2892)	mem 39782MB
[2023-07-07 11:13:43 RepVGG-A0] (main.py 282): INFO Train: [105/300][50/78]	eta 0:00:53 lr 4.633597	time 1.1726 (1.9118)	loss 3.4065 (3.5762)	grad_norm 0.3176 (0.2935)	mem 39782MB
[2023-07-07 11:13:58 RepVGG-A0] (main.py 282): INFO Train: [105/300][60/78]	eta 0:00:33 lr 4.629755	time 1.1751 (1.8399)	loss 3.3880 (3.5445)	grad_norm 0.3564 (0.2974)	mem 39782MB
[2023-07-07 11:14:13 RepVGG-A0] (main.py 282): INFO Train: [105/300][70/78]	eta 0:00:14 lr 4.625910	time 1.5692 (1.7918)	loss 3.2993 (3.5186)	grad_norm 0.3480 (0.3017)	mem 39782MB
[2023-07-07 11:14:25 RepVGG-A0] (main.py 291): INFO EPOCH 105 training takes 0:02:19
[2023-07-07 11:14:46 RepVGG-A0] (main.py 282): INFO Train: [106/300][0/78]	eta 0:27:27 lr 4.622833	time 21.1227 (21.1227)	loss 3.4644 (3.4644)	grad_norm 0.4038 (0.4038)	mem 39782MB
[2023-07-07 11:15:01 RepVGG-A0] (main.py 282): INFO Train: [106/300][10/78]	eta 0:03:42 lr 4.618983	time 1.1726 (3.2791)	loss 3.3538 (3.3682)	grad_norm 0.3277 (0.3555)	mem 39782MB
[2023-07-07 11:15:15 RepVGG-A0] (main.py 282): INFO Train: [106/300][20/78]	eta 0:02:18 lr 4.615131	time 1.1723 (2.3917)	loss 3.3864 (3.3432)	grad_norm 0.3653 (0.3493)	mem 39782MB
[2023-07-07 11:15:31 RepVGG-A0] (main.py 282): INFO Train: [106/300][30/78]	eta 0:01:42 lr 4.611277	time 1.4229 (2.1373)	loss 3.3477 (3.3332)	grad_norm 0.3596 (0.3467)	mem 39782MB
[2023-07-07 11:15:49 RepVGG-A0] (main.py 282): INFO Train: [106/300][40/78]	eta 0:01:17 lr 4.607420	time 4.2317 (2.0462)	loss 3.2704 (3.3375)	grad_norm 0.3452 (0.3519)	mem 39782MB
[2023-07-07 11:16:04 RepVGG-A0] (main.py 282): INFO Train: [106/300][50/78]	eta 0:00:54 lr 4.603560	time 1.1722 (1.9429)	loss 3.3991 (3.3497)	grad_norm 0.3828 (0.3579)	mem 39782MB
[2023-07-07 11:16:19 RepVGG-A0] (main.py 282): INFO Train: [106/300][60/78]	eta 0:00:33 lr 4.599698	time 1.2925 (1.8772)	loss 3.3008 (3.3540)	grad_norm 0.3683 (0.3593)	mem 39782MB
[2023-07-07 11:16:34 RepVGG-A0] (main.py 282): INFO Train: [106/300][70/78]	eta 0:00:14 lr 4.595833	time 1.1718 (1.8205)	loss 3.2868 (3.3480)	grad_norm 0.3370 (0.3559)	mem 39782MB
[2023-07-07 11:16:47 RepVGG-A0] (main.py 291): INFO EPOCH 106 training takes 0:02:21
[2023-07-07 11:17:10 RepVGG-A0] (main.py 282): INFO Train: [107/300][0/78]	eta 0:29:43 lr 4.592740	time 22.8702 (22.8702)	loss 3.4813 (3.4813)	grad_norm 0.5276 (0.5276)	mem 39782MB
[2023-07-07 11:17:25 RepVGG-A0] (main.py 282): INFO Train: [107/300][10/78]	eta 0:03:55 lr 4.588870	time 1.1770 (3.4629)	loss 3.2013 (3.4311)	grad_norm 0.3273 (0.4080)	mem 39782MB
[2023-07-07 11:17:39 RepVGG-A0] (main.py 282): INFO Train: [107/300][20/78]	eta 0:02:24 lr 4.584999	time 1.1751 (2.4940)	loss 3.3457 (3.3573)	grad_norm 0.3680 (0.3765)	mem 39782MB
[2023-07-07 11:17:54 RepVGG-A0] (main.py 282): INFO Train: [107/300][30/78]	eta 0:01:44 lr 4.581124	time 1.2144 (2.1854)	loss 3.1857 (3.3254)	grad_norm 0.2996 (0.3620)	mem 39782MB
[2023-07-07 11:18:13 RepVGG-A0] (main.py 282): INFO Train: [107/300][40/78]	eta 0:01:19 lr 4.577248	time 3.2934 (2.1001)	loss 3.5134 (3.3417)	grad_norm 0.4557 (0.3777)	mem 39782MB
[2023-07-07 11:18:28 RepVGG-A0] (main.py 282): INFO Train: [107/300][50/78]	eta 0:00:55 lr 4.573369	time 1.1728 (1.9915)	loss 3.3307 (3.3582)	grad_norm 0.3145 (0.3829)	mem 39782MB
[2023-07-07 11:18:43 RepVGG-A0] (main.py 282): INFO Train: [107/300][60/78]	eta 0:00:34 lr 4.569487	time 1.2174 (1.9051)	loss 3.2913 (3.3461)	grad_norm 0.3167 (0.3693)	mem 39782MB
[2023-07-07 11:18:58 RepVGG-A0] (main.py 282): INFO Train: [107/300][70/78]	eta 0:00:14 lr 4.565603	time 1.1954 (1.8512)	loss 3.3796 (3.3422)	grad_norm 0.3865 (0.3690)	mem 39782MB
[2023-07-07 11:19:10 RepVGG-A0] (main.py 291): INFO EPOCH 107 training takes 0:02:23
[2023-07-07 11:19:32 RepVGG-A0] (main.py 282): INFO Train: [108/300][0/78]	eta 0:28:13 lr 4.562494	time 21.7112 (21.7112)	loss 3.1890 (3.1890)	grad_norm 0.3557 (0.3557)	mem 39782MB
[2023-07-07 11:19:46 RepVGG-A0] (main.py 282): INFO Train: [108/300][10/78]	eta 0:03:44 lr 4.558605	time 1.1716 (3.3043)	loss 3.3097 (3.2747)	grad_norm 0.3630 (0.3826)	mem 39782MB
[2023-07-07 11:20:02 RepVGG-A0] (main.py 282): INFO Train: [108/300][20/78]	eta 0:02:22 lr 4.554714	time 1.4855 (2.4519)	loss 3.2065 (3.2690)	grad_norm 0.3497 (0.3675)	mem 39782MB
[2023-07-07 11:20:17 RepVGG-A0] (main.py 282): INFO Train: [108/300][30/78]	eta 0:01:43 lr 4.550821	time 1.4177 (2.1651)	loss 3.6417 (3.2943)	grad_norm 0.6360 (0.3946)	mem 39782MB
[2023-07-07 11:20:34 RepVGG-A0] (main.py 282): INFO Train: [108/300][40/78]	eta 0:01:17 lr 4.546925	time 3.5717 (2.0521)	loss 6.1437 (3.7250)	grad_norm 0.7834 (0.5315)	mem 39782MB
[2023-07-07 11:20:49 RepVGG-A0] (main.py 282): INFO Train: [108/300][50/78]	eta 0:00:54 lr 4.543027	time 1.1891 (1.9316)	loss 4.8152 (4.0262)	grad_norm 0.3638 (0.5098)	mem 39782MB
[2023-07-07 11:21:03 RepVGG-A0] (main.py 282): INFO Train: [108/300][60/78]	eta 0:00:33 lr 4.539126	time 1.1991 (1.8562)	loss 4.1520 (4.0825)	grad_norm 0.3112 (0.4736)	mem 39782MB
[2023-07-07 11:21:19 RepVGG-A0] (main.py 282): INFO Train: [108/300][70/78]	eta 0:00:14 lr 4.535223	time 1.2178 (1.8117)	loss 3.9083 (4.0790)	grad_norm 0.3120 (0.4521)	mem 39782MB
[2023-07-07 11:21:31 RepVGG-A0] (main.py 291): INFO EPOCH 108 training takes 0:02:20
[2023-07-07 11:21:52 RepVGG-A0] (main.py 282): INFO Train: [109/300][0/78]	eta 0:27:26 lr 4.532099	time 21.1059 (21.1059)	loss 3.7131 (3.7131)	grad_norm 0.3026 (0.3026)	mem 39782MB
[2023-07-07 11:22:07 RepVGG-A0] (main.py 282): INFO Train: [109/300][10/78]	eta 0:03:43 lr 4.528191	time 1.1910 (3.2913)	loss 3.6523 (3.6608)	grad_norm 0.2990 (0.2913)	mem 39782MB
[2023-07-07 11:22:22 RepVGG-A0] (main.py 282): INFO Train: [109/300][20/78]	eta 0:02:20 lr 4.524281	time 1.1742 (2.4306)	loss 3.7478 (3.6333)	grad_norm 0.3674 (0.3030)	mem 39782MB
[2023-07-07 11:22:37 RepVGG-A0] (main.py 282): INFO Train: [109/300][30/78]	eta 0:01:42 lr 4.520369	time 1.3678 (2.1456)	loss 3.6028 (3.6236)	grad_norm 0.3363 (0.3214)	mem 39782MB
[2023-07-07 11:22:55 RepVGG-A0] (main.py 282): INFO Train: [109/300][40/78]	eta 0:01:18 lr 4.516454	time 2.6409 (2.0569)	loss 3.5223 (3.5943)	grad_norm 0.2979 (0.3182)	mem 39782MB
[2023-07-07 11:23:10 RepVGG-A0] (main.py 282): INFO Train: [109/300][50/78]	eta 0:00:54 lr 4.512537	time 1.2393 (1.9420)	loss 3.4623 (3.5634)	grad_norm 0.3396 (0.3165)	mem 39782MB
[2023-07-07 11:23:25 RepVGG-A0] (main.py 282): INFO Train: [109/300][60/78]	eta 0:00:33 lr 4.508618	time 1.1731 (1.8731)	loss 3.4431 (3.5517)	grad_norm 0.3085 (0.3234)	mem 39782MB
[2023-07-07 11:23:39 RepVGG-A0] (main.py 282): INFO Train: [109/300][70/78]	eta 0:00:14 lr 4.504696	time 1.1870 (1.8118)	loss 3.4182 (3.5354)	grad_norm 0.3000 (0.3251)	mem 39782MB
[2023-07-07 11:23:52 RepVGG-A0] (main.py 291): INFO EPOCH 109 training takes 0:02:20
[2023-07-07 11:24:11 RepVGG-A0] (main.py 282): INFO Train: [110/300][0/78]	eta 0:25:46 lr 4.501557	time 19.8303 (19.8303)	loss 3.3638 (3.3638)	grad_norm 0.3769 (0.3769)	mem 39782MB
[2023-07-07 11:24:28 RepVGG-A0] (main.py 282): INFO Train: [110/300][10/78]	eta 0:03:44 lr 4.497631	time 1.1714 (3.2997)	loss 3.3786 (3.4116)	grad_norm 0.3576 (0.3923)	mem 39782MB
[2023-07-07 11:24:43 RepVGG-A0] (main.py 282): INFO Train: [110/300][20/78]	eta 0:02:22 lr 4.493703	time 1.1753 (2.4611)	loss 3.3201 (3.3854)	grad_norm 0.3262 (0.3626)	mem 39782MB
[2023-07-07 11:24:58 RepVGG-A0] (main.py 282): INFO Train: [110/300][30/78]	eta 0:01:42 lr 4.489772	time 1.2667 (2.1451)	loss 3.4615 (3.3912)	grad_norm 0.3733 (0.3650)	mem 39782MB
[2023-07-07 11:25:16 RepVGG-A0] (main.py 282): INFO Train: [110/300][40/78]	eta 0:01:18 lr 4.485839	time 2.9954 (2.0717)	loss 3.2980 (3.3858)	grad_norm 0.3394 (0.3637)	mem 39782MB
[2023-07-07 11:25:30 RepVGG-A0] (main.py 282): INFO Train: [110/300][50/78]	eta 0:00:54 lr 4.481904	time 1.1919 (1.9334)	loss 3.2823 (3.3852)	grad_norm 0.3152 (0.3632)	mem 39782MB
[2023-07-07 11:25:45 RepVGG-A0] (main.py 282): INFO Train: [110/300][60/78]	eta 0:00:33 lr 4.477967	time 1.3995 (1.8605)	loss 3.4161 (3.3774)	grad_norm 0.4600 (0.3634)	mem 39782MB
[2023-07-07 11:26:01 RepVGG-A0] (main.py 282): INFO Train: [110/300][70/78]	eta 0:00:14 lr 4.474027	time 1.7097 (1.8167)	loss 5.7116 (3.5727)	grad_norm 0.7272 (0.4327)	mem 39782MB
[2023-07-07 11:26:11 RepVGG-A0] (main.py 291): INFO EPOCH 110 training takes 0:02:19
[2023-07-07 11:26:32 RepVGG-A0] (main.py 282): INFO Train: [111/300][0/78]	eta 0:28:07 lr 4.470873	time 21.6293 (21.6293)	loss 4.4873 (4.4873)	grad_norm 0.3477 (0.3477)	mem 39782MB
[2023-07-07 11:26:47 RepVGG-A0] (main.py 282): INFO Train: [111/300][10/78]	eta 0:03:41 lr 4.466929	time 1.1720 (3.2573)	loss 3.9311 (4.2303)	grad_norm 0.2552 (0.3349)	mem 39782MB
[2023-07-07 11:27:01 RepVGG-A0] (main.py 282): INFO Train: [111/300][20/78]	eta 0:02:18 lr 4.462983	time 1.1734 (2.3922)	loss 3.8364 (4.0616)	grad_norm 0.3483 (0.3131)	mem 39782MB
[2023-07-07 11:27:17 RepVGG-A0] (main.py 282): INFO Train: [111/300][30/78]	eta 0:01:43 lr 4.459034	time 2.0058 (2.1527)	loss 3.6932 (3.9454)	grad_norm 0.3363 (0.3081)	mem 39782MB
[2023-07-07 11:27:35 RepVGG-A0] (main.py 282): INFO Train: [111/300][40/78]	eta 0:01:17 lr 4.455084	time 4.3982 (2.0464)	loss 3.5089 (3.8621)	grad_norm 0.2866 (0.3069)	mem 39782MB
[2023-07-07 11:27:49 RepVGG-A0] (main.py 282): INFO Train: [111/300][50/78]	eta 0:00:54 lr 4.451130	time 1.3011 (1.9340)	loss 3.7028 (3.8007)	grad_norm 0.4533 (0.3089)	mem 39782MB
[2023-07-07 11:28:05 RepVGG-A0] (main.py 282): INFO Train: [111/300][60/78]	eta 0:00:33 lr 4.447175	time 1.2685 (1.8695)	loss 3.4670 (3.7552)	grad_norm 0.2819 (0.3109)	mem 39782MB
[2023-07-07 11:28:20 RepVGG-A0] (main.py 282): INFO Train: [111/300][70/78]	eta 0:00:14 lr 4.443218	time 1.3243 (1.8168)	loss 3.4761 (3.7119)	grad_norm 0.3564 (0.3111)	mem 39782MB
[2023-07-07 11:28:31 RepVGG-A0] (main.py 291): INFO EPOCH 111 training takes 0:02:20
[2023-07-07 11:28:52 RepVGG-A0] (main.py 282): INFO Train: [112/300][0/78]	eta 0:26:44 lr 4.440050	time 20.5748 (20.5748)	loss 3.4172 (3.4172)	grad_norm 0.2872 (0.2872)	mem 39782MB
[2023-07-07 11:29:08 RepVGG-A0] (main.py 282): INFO Train: [112/300][10/78]	eta 0:03:44 lr 4.436088	time 1.1734 (3.3018)	loss 3.4200 (3.3676)	grad_norm 0.2874 (0.3194)	mem 39782MB
[2023-07-07 11:29:23 RepVGG-A0] (main.py 282): INFO Train: [112/300][20/78]	eta 0:02:22 lr 4.432124	time 1.2088 (2.4637)	loss 3.5947 (3.4213)	grad_norm 0.4420 (0.3740)	mem 39782MB
[2023-07-07 11:29:39 RepVGG-A0] (main.py 282): INFO Train: [112/300][30/78]	eta 0:01:45 lr 4.428158	time 1.9698 (2.1921)	loss 3.4210 (3.4201)	grad_norm 0.3504 (0.3588)	mem 39782MB
[2023-07-07 11:29:57 RepVGG-A0] (main.py 282): INFO Train: [112/300][40/78]	eta 0:01:19 lr 4.424190	time 4.6894 (2.0799)	loss 3.3965 (3.4084)	grad_norm 0.3638 (0.3531)	mem 39782MB
[2023-07-07 11:30:11 RepVGG-A0] (main.py 282): INFO Train: [112/300][50/78]	eta 0:00:54 lr 4.420220	time 1.1746 (1.9437)	loss 3.3579 (3.4002)	grad_norm 0.3132 (0.3519)	mem 39782MB
[2023-07-07 11:30:26 RepVGG-A0] (main.py 282): INFO Train: [112/300][60/78]	eta 0:00:33 lr 4.416247	time 1.2104 (1.8739)	loss 3.4857 (3.3970)	grad_norm 0.4104 (0.3566)	mem 39782MB
[2023-07-07 11:30:42 RepVGG-A0] (main.py 282): INFO Train: [112/300][70/78]	eta 0:00:14 lr 4.412272	time 1.6299 (1.8329)	loss 3.3360 (3.3924)	grad_norm 0.3236 (0.3543)	mem 39782MB
[2023-07-07 11:30:53 RepVGG-A0] (main.py 291): INFO EPOCH 112 training takes 0:02:21
[2023-07-07 11:31:15 RepVGG-A0] (main.py 282): INFO Train: [113/300][0/78]	eta 0:29:16 lr 4.409091	time 22.5131 (22.5131)	loss 3.3694 (3.3694)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:31:29 RepVGG-A0] (main.py 282): INFO Train: [113/300][10/78]	eta 0:03:45 lr 4.405112	time 1.1723 (3.3131)	loss 3.4095 (3.3333)	grad_norm 0.4377 (0.3845)	mem 39782MB
[2023-07-07 11:31:44 RepVGG-A0] (main.py 282): INFO Train: [113/300][20/78]	eta 0:02:20 lr 4.401131	time 1.1733 (2.4279)	loss 3.2953 (3.3417)	grad_norm 0.3471 (0.3794)	mem 39782MB
[2023-07-07 11:31:58 RepVGG-A0] (main.py 282): INFO Train: [113/300][30/78]	eta 0:01:41 lr 4.397148	time 1.3093 (2.1137)	loss 3.3241 (3.3313)	grad_norm 0.3474 (0.3720)	mem 39782MB
[2023-07-07 11:32:17 RepVGG-A0] (main.py 282): INFO Train: [113/300][40/78]	eta 0:01:17 lr 4.393162	time 3.3966 (2.0445)	loss 3.3504 (3.3316)	grad_norm 0.3684 (0.3746)	mem 39782MB
[2023-07-07 11:32:32 RepVGG-A0] (main.py 282): INFO Train: [113/300][50/78]	eta 0:00:54 lr 4.389175	time 1.1800 (1.9398)	loss 3.4090 (3.3296)	grad_norm 0.3695 (0.3714)	mem 39782MB
[2023-07-07 11:32:47 RepVGG-A0] (main.py 282): INFO Train: [113/300][60/78]	eta 0:00:33 lr 4.385185	time 1.1779 (1.8650)	loss 3.3809 (3.3301)	grad_norm 0.4120 (0.3745)	mem 39782MB
[2023-07-07 11:33:02 RepVGG-A0] (main.py 282): INFO Train: [113/300][70/78]	eta 0:00:14 lr 4.381193	time 1.5315 (1.8200)	loss 3.2612 (3.3295)	grad_norm 0.3438 (0.3746)	mem 39782MB
[2023-07-07 11:33:13 RepVGG-A0] (main.py 291): INFO EPOCH 113 training takes 0:02:20
[2023-07-07 11:33:34 RepVGG-A0] (main.py 282): INFO Train: [114/300][0/78]	eta 0:27:37 lr 4.377999	time 21.2536 (21.2536)	loss 3.3336 (3.3336)	grad_norm 0.4531 (0.4531)	mem 39782MB
[2023-07-07 11:33:49 RepVGG-A0] (main.py 282): INFO Train: [114/300][10/78]	eta 0:03:43 lr 4.374003	time 1.1704 (3.2843)	loss 3.3271 (3.3369)	grad_norm 0.4236 (0.4216)	mem 39782MB
[2023-07-07 11:34:05 RepVGG-A0] (main.py 282): INFO Train: [114/300][20/78]	eta 0:02:23 lr 4.370005	time 1.3652 (2.4698)	loss 3.2839 (3.3224)	grad_norm 0.3482 (0.3937)	mem 39782MB
[2023-07-07 11:34:20 RepVGG-A0] (main.py 282): INFO Train: [114/300][30/78]	eta 0:01:42 lr 4.366006	time 1.4765 (2.1408)	loss 3.2553 (3.2948)	grad_norm 0.3508 (0.3768)	mem 39782MB
[2023-07-07 11:34:37 RepVGG-A0] (main.py 282): INFO Train: [114/300][40/78]	eta 0:01:17 lr 4.362004	time 3.1501 (2.0388)	loss 3.4558 (3.3024)	grad_norm 0.5292 (0.3844)	mem 39782MB
[2023-07-07 11:34:52 RepVGG-A0] (main.py 282): INFO Train: [114/300][50/78]	eta 0:00:54 lr 4.358000	time 1.1723 (1.9287)	loss 5.6943 (3.7090)	grad_norm 0.5064 (0.4853)	mem 39782MB
[2023-07-07 11:35:07 RepVGG-A0] (main.py 282): INFO Train: [114/300][60/78]	eta 0:00:33 lr 4.353994	time 1.1885 (1.8655)	loss 4.5040 (3.9120)	grad_norm 0.3221 (0.4664)	mem 39782MB
[2023-07-07 11:35:22 RepVGG-A0] (main.py 282): INFO Train: [114/300][70/78]	eta 0:00:14 lr 4.349985	time 1.3180 (1.8089)	loss 4.0814 (3.9660)	grad_norm 0.2630 (0.4472)	mem 39782MB
[2023-07-07 11:35:33 RepVGG-A0] (main.py 291): INFO EPOCH 114 training takes 0:02:20
[2023-07-07 11:35:55 RepVGG-A0] (main.py 282): INFO Train: [115/300][0/78]	eta 0:28:14 lr 4.346777	time 21.7290 (21.7290)	loss 3.8387 (3.8387)	grad_norm 0.3248 (0.3248)	mem 39782MB
[2023-07-07 11:36:11 RepVGG-A0] (main.py 282): INFO Train: [115/300][10/78]	eta 0:03:52 lr 4.342766	time 1.1705 (3.4252)	loss 3.7245 (3.7940)	grad_norm 0.3051 (0.3070)	mem 39782MB
[2023-07-07 11:36:25 RepVGG-A0] (main.py 282): INFO Train: [115/300][20/78]	eta 0:02:23 lr 4.338752	time 1.1857 (2.4702)	loss 3.6104 (3.7284)	grad_norm 0.2789 (0.3140)	mem 39782MB
[2023-07-07 11:36:43 RepVGG-A0] (main.py 282): INFO Train: [115/300][30/78]	eta 0:01:47 lr 4.334736	time 1.7643 (2.2350)	loss 3.4832 (3.6693)	grad_norm 0.3284 (0.3023)	mem 39782MB
[2023-07-07 11:36:58 RepVGG-A0] (main.py 282): INFO Train: [115/300][40/78]	eta 0:01:18 lr 4.330718	time 3.8080 (2.0727)	loss 3.5258 (3.6476)	grad_norm 0.3425 (0.3178)	mem 39782MB
[2023-07-07 11:37:13 RepVGG-A0] (main.py 282): INFO Train: [115/300][50/78]	eta 0:00:54 lr 4.326698	time 1.1725 (1.9561)	loss 3.5134 (3.6162)	grad_norm 0.3487 (0.3182)	mem 39782MB
[2023-07-07 11:37:28 RepVGG-A0] (main.py 282): INFO Train: [115/300][60/78]	eta 0:00:33 lr 4.322675	time 1.1836 (1.8749)	loss 3.4473 (3.5874)	grad_norm 0.3808 (0.3186)	mem 39782MB
[2023-07-07 11:37:43 RepVGG-A0] (main.py 282): INFO Train: [115/300][70/78]	eta 0:00:14 lr 4.318651	time 1.1719 (1.8286)	loss 3.4554 (3.5747)	grad_norm 0.3352 (0.3265)	mem 39782MB
[2023-07-07 11:37:55 RepVGG-A0] (main.py 291): INFO EPOCH 115 training takes 0:02:21
[2023-07-07 11:38:18 RepVGG-A0] (main.py 282): INFO Train: [116/300][0/78]	eta 0:29:24 lr 4.315431	time 22.6193 (22.6193)	loss 3.3736 (3.3736)	grad_norm 0.3650 (0.3650)	mem 39782MB
[2023-07-07 11:38:32 RepVGG-A0] (main.py 282): INFO Train: [116/300][10/78]	eta 0:03:49 lr 4.311403	time 1.1749 (3.3716)	loss 3.2515 (3.3860)	grad_norm 0.3171 (0.3505)	mem 39782MB
[2023-07-07 11:38:47 RepVGG-A0] (main.py 282): INFO Train: [116/300][20/78]	eta 0:02:23 lr 4.307373	time 1.1850 (2.4784)	loss 3.3276 (3.3751)	grad_norm 0.3678 (0.3540)	mem 39782MB
[2023-07-07 11:39:03 RepVGG-A0] (main.py 282): INFO Train: [116/300][30/78]	eta 0:01:44 lr 4.303341	time 1.6070 (2.1822)	loss 3.5553 (3.3644)	grad_norm 0.4433 (0.3512)	mem 39782MB
[2023-07-07 11:39:20 RepVGG-A0] (main.py 282): INFO Train: [116/300][40/78]	eta 0:01:19 lr 4.299308	time 3.7113 (2.0810)	loss 3.4416 (3.3795)	grad_norm 0.3991 (0.3630)	mem 39782MB
[2023-07-07 11:39:35 RepVGG-A0] (main.py 282): INFO Train: [116/300][50/78]	eta 0:00:54 lr 4.295272	time 1.1728 (1.9587)	loss 3.4731 (3.3825)	grad_norm 0.4535 (0.3668)	mem 39782MB
[2023-07-07 11:39:50 RepVGG-A0] (main.py 282): INFO Train: [116/300][60/78]	eta 0:00:34 lr 4.291234	time 1.2906 (1.8905)	loss 3.3748 (3.3849)	grad_norm 0.3718 (0.3664)	mem 39782MB
[2023-07-07 11:40:06 RepVGG-A0] (main.py 282): INFO Train: [116/300][70/78]	eta 0:00:14 lr 4.287194	time 1.1270 (1.8430)	loss 3.3248 (3.3761)	grad_norm 0.3259 (0.3620)	mem 39782MB
[2023-07-07 11:40:17 RepVGG-A0] (main.py 291): INFO EPOCH 116 training takes 0:02:22
[2023-07-07 11:40:39 RepVGG-A0] (main.py 282): INFO Train: [117/300][0/78]	eta 0:28:16 lr 4.283961	time 21.7442 (21.7442)	loss 3.2247 (3.2247)	grad_norm 0.3688 (0.3688)	mem 39782MB
[2023-07-07 11:40:53 RepVGG-A0] (main.py 282): INFO Train: [117/300][10/78]	eta 0:03:41 lr 4.279918	time 1.1722 (3.2630)	loss 3.4565 (3.2861)	grad_norm 0.5023 (0.3819)	mem 39782MB
[2023-07-07 11:41:08 RepVGG-A0] (main.py 282): INFO Train: [117/300][20/78]	eta 0:02:19 lr 4.275873	time 1.1739 (2.4058)	loss 3.8841 (3.5226)	grad_norm 0.5983 (0.4939)	mem 39782MB
[2023-07-07 11:41:23 RepVGG-A0] (main.py 282): INFO Train: [117/300][30/78]	eta 0:01:41 lr 4.271826	time 1.6486 (2.1220)	loss 3.3736 (3.5247)	grad_norm 0.2836 (0.4522)	mem 39782MB
[2023-07-07 11:41:42 RepVGG-A0] (main.py 282): INFO Train: [117/300][40/78]	eta 0:01:18 lr 4.267777	time 4.6557 (2.0693)	loss 3.3734 (3.4789)	grad_norm 0.3041 (0.4120)	mem 39782MB
[2023-07-07 11:41:56 RepVGG-A0] (main.py 282): INFO Train: [117/300][50/78]	eta 0:00:54 lr 4.263726	time 1.1759 (1.9403)	loss 3.3293 (3.4433)	grad_norm 0.3454 (0.3936)	mem 39782MB
[2023-07-07 11:42:12 RepVGG-A0] (main.py 282): INFO Train: [117/300][60/78]	eta 0:00:33 lr 4.259673	time 1.2682 (1.8810)	loss 3.2613 (3.4133)	grad_norm 0.3274 (0.3820)	mem 39782MB
[2023-07-07 11:42:27 RepVGG-A0] (main.py 282): INFO Train: [117/300][70/78]	eta 0:00:14 lr 4.255618	time 1.5273 (1.8284)	loss 3.3010 (3.3924)	grad_norm 0.3250 (0.3736)	mem 39782MB
[2023-07-07 11:42:38 RepVGG-A0] (main.py 291): INFO EPOCH 117 training takes 0:02:21
[2023-07-07 11:43:00 RepVGG-A0] (main.py 282): INFO Train: [118/300][0/78]	eta 0:28:07 lr 4.252373	time 21.6346 (21.6346)	loss 3.2726 (3.2726)	grad_norm 0.4037 (0.4037)	mem 39782MB
[2023-07-07 11:43:14 RepVGG-A0] (main.py 282): INFO Train: [118/300][10/78]	eta 0:03:39 lr 4.248315	time 1.1732 (3.2351)	loss 3.2525 (3.2679)	grad_norm 0.3842 (0.3773)	mem 39782MB
[2023-07-07 11:43:29 RepVGG-A0] (main.py 282): INFO Train: [118/300][20/78]	eta 0:02:20 lr 4.244255	time 1.1737 (2.4244)	loss 3.2860 (3.2642)	grad_norm 0.4043 (0.3773)	mem 39782MB
[2023-07-07 11:43:45 RepVGG-A0] (main.py 282): INFO Train: [118/300][30/78]	eta 0:01:42 lr 4.240193	time 1.7376 (2.1388)	loss 3.3010 (3.2682)	grad_norm 0.3339 (0.3742)	mem 39782MB
[2023-07-07 11:44:02 RepVGG-A0] (main.py 282): INFO Train: [118/300][40/78]	eta 0:01:17 lr 4.236129	time 3.3758 (2.0397)	loss 3.4059 (3.2727)	grad_norm 0.4177 (0.3778)	mem 39782MB
[2023-07-07 11:44:17 RepVGG-A0] (main.py 282): INFO Train: [118/300][50/78]	eta 0:00:54 lr 4.232064	time 1.1678 (1.9407)	loss 3.3578 (3.2807)	grad_norm 0.4319 (0.3776)	mem 39782MB
[2023-07-07 11:44:32 RepVGG-A0] (main.py 282): INFO Train: [118/300][60/78]	eta 0:00:33 lr 4.227996	time 1.3597 (1.8713)	loss 3.2796 (3.2874)	grad_norm 0.3622 (0.3796)	mem 39782MB
[2023-07-07 11:44:48 RepVGG-A0] (main.py 282): INFO Train: [118/300][70/78]	eta 0:00:14 lr 4.223927	time 1.1715 (1.8205)	loss 3.2399 (3.2801)	grad_norm 0.3388 (0.3744)	mem 39782MB
[2023-07-07 11:45:00 RepVGG-A0] (main.py 291): INFO EPOCH 118 training takes 0:02:21
[2023-07-07 11:45:21 RepVGG-A0] (main.py 282): INFO Train: [119/300][0/78]	eta 0:27:44 lr 4.220670	time 21.3377 (21.3377)	loss 3.2624 (3.2624)	grad_norm 0.4124 (0.4124)	mem 39782MB
[2023-07-07 11:45:36 RepVGG-A0] (main.py 282): INFO Train: [119/300][10/78]	eta 0:03:45 lr 4.216597	time 1.1961 (3.3202)	loss 3.3435 (3.3143)	grad_norm 0.4046 (0.4327)	mem 39782MB
[2023-07-07 11:45:52 RepVGG-A0] (main.py 282): INFO Train: [119/300][20/78]	eta 0:02:24 lr 4.212523	time 1.2833 (2.4912)	loss 3.2342 (3.2690)	grad_norm 0.3663 (0.3993)	mem 39782MB
[2023-07-07 11:46:07 RepVGG-A0] (main.py 282): INFO Train: [119/300][30/78]	eta 0:01:43 lr 4.208446	time 1.1476 (2.1602)	loss 3.1792 (3.2529)	grad_norm 0.3449 (0.3821)	mem 39782MB
[2023-07-07 11:46:25 RepVGG-A0] (main.py 282): INFO Train: [119/300][40/78]	eta 0:01:19 lr 4.204368	time 3.7763 (2.0832)	loss 3.8204 (3.3056)	grad_norm 0.7106 (0.4147)	mem 39782MB
[2023-07-07 11:46:40 RepVGG-A0] (main.py 282): INFO Train: [119/300][50/78]	eta 0:00:55 lr 4.200288	time 1.1781 (1.9674)	loss 4.5552 (3.5566)	grad_norm 0.5672 (0.4931)	mem 39782MB
[2023-07-07 11:46:55 RepVGG-A0] (main.py 282): INFO Train: [119/300][60/78]	eta 0:00:33 lr 4.196206	time 1.4420 (1.8874)	loss 3.6366 (3.6146)	grad_norm 0.2740 (0.4655)	mem 39782MB
[2023-07-07 11:47:10 RepVGG-A0] (main.py 282): INFO Train: [119/300][70/78]	eta 0:00:14 lr 4.192123	time 1.4795 (1.8356)	loss 3.5661 (3.6123)	grad_norm 0.2807 (0.4434)	mem 39782MB
[2023-07-07 11:47:23 RepVGG-A0] (main.py 291): INFO EPOCH 119 training takes 0:02:22
[2023-07-07 11:47:44 RepVGG-A0] (main.py 282): INFO Train: [120/300][0/78]	eta 0:27:28 lr 4.188854	time 21.1356 (21.1356)	loss 3.4153 (3.4153)	grad_norm 0.2635 (0.2635)	mem 39782MB
[2023-07-07 11:48:00 RepVGG-A0] (main.py 282): INFO Train: [120/300][10/78]	eta 0:03:47 lr 4.184768	time 1.1892 (3.3515)	loss 3.3190 (3.3248)	grad_norm 0.2956 (0.2783)	mem 39782MB
[2023-07-07 11:48:14 RepVGG-A0] (main.py 282): INFO Train: [120/300][20/78]	eta 0:02:20 lr 4.180679	time 1.1990 (2.4203)	loss 3.2799 (3.2852)	grad_norm 0.3431 (0.2922)	mem 39782MB
[2023-07-07 11:48:29 RepVGG-A0] (main.py 282): INFO Train: [120/300][30/78]	eta 0:01:41 lr 4.176589	time 1.4340 (2.1218)	loss 3.3090 (3.2738)	grad_norm 0.2969 (0.2938)	mem 39782MB
[2023-07-07 11:48:46 RepVGG-A0] (main.py 282): INFO Train: [120/300][40/78]	eta 0:01:17 lr 4.172497	time 4.0754 (2.0353)	loss 3.2153 (3.2634)	grad_norm 0.3494 (0.3035)	mem 39782MB
[2023-07-07 11:49:02 RepVGG-A0] (main.py 282): INFO Train: [120/300][50/78]	eta 0:00:54 lr 4.168403	time 1.1905 (1.9389)	loss 3.2846 (3.2619)	grad_norm 0.3221 (0.3095)	mem 39782MB
[2023-07-07 11:49:16 RepVGG-A0] (main.py 282): INFO Train: [120/300][60/78]	eta 0:00:33 lr 4.164307	time 1.3112 (1.8630)	loss 3.2338 (3.2545)	grad_norm 0.3574 (0.3145)	mem 39782MB
[2023-07-07 11:49:31 RepVGG-A0] (main.py 282): INFO Train: [120/300][70/78]	eta 0:00:14 lr 4.160210	time 1.3965 (1.8097)	loss 3.2744 (3.2566)	grad_norm 0.3350 (0.3239)	mem 39782MB
[2023-07-07 11:49:43 RepVGG-A0] (main.py 291): INFO EPOCH 120 training takes 0:02:19
[2023-07-07 11:50:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.829 (17.829)	Loss 2.7981 (2.7981)	Acc@1 41.357 (41.357)	Acc@5 67.542 (67.542)	Mem 39782MB
[2023-07-07 11:50:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 41.654 Acc@5 67.390
[2023-07-07 11:50:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 120: 41.654%
[2023-07-07 11:50:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 11:50:24 RepVGG-A0] (main.py 282): INFO Train: [121/300][0/78]	eta 0:28:51 lr 4.156931	time 22.1949 (22.1949)	loss 3.2084 (3.2084)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:50:39 RepVGG-A0] (main.py 282): INFO Train: [121/300][10/78]	eta 0:03:49 lr 4.152830	time 1.1731 (3.3817)	loss 3.1498 (3.2103)	grad_norm 0.3425 (0.3579)	mem 39782MB
[2023-07-07 11:50:54 RepVGG-A0] (main.py 282): INFO Train: [121/300][20/78]	eta 0:02:25 lr 4.148728	time 1.1793 (2.5064)	loss 3.3125 (3.2342)	grad_norm 0.4370 (0.3791)	mem 39782MB
[2023-07-07 11:51:10 RepVGG-A0] (main.py 282): INFO Train: [121/300][30/78]	eta 0:01:45 lr 4.144624	time 1.4623 (2.1905)	loss 3.2463 (3.2220)	grad_norm 0.3754 (0.3653)	mem 39782MB
[2023-07-07 11:51:28 RepVGG-A0] (main.py 282): INFO Train: [121/300][40/78]	eta 0:01:19 lr 4.140518	time 2.5108 (2.1040)	loss 3.1246 (3.2187)	grad_norm 0.3326 (0.3670)	mem 39782MB
[2023-07-07 11:51:43 RepVGG-A0] (main.py 282): INFO Train: [121/300][50/78]	eta 0:00:55 lr 4.136411	time 1.2894 (1.9884)	loss 3.2071 (3.2128)	grad_norm 0.3987 (0.3655)	mem 39782MB
[2023-07-07 11:51:58 RepVGG-A0] (main.py 282): INFO Train: [121/300][60/78]	eta 0:00:34 lr 4.132302	time 1.1748 (1.9024)	loss 3.2310 (3.2232)	grad_norm 0.3280 (0.3717)	mem 39782MB
[2023-07-07 11:52:12 RepVGG-A0] (main.py 282): INFO Train: [121/300][70/78]	eta 0:00:14 lr 4.128191	time 1.4289 (1.8315)	loss 3.2795 (3.2237)	grad_norm 0.4218 (0.3689)	mem 39782MB
[2023-07-07 11:52:23 RepVGG-A0] (main.py 291): INFO EPOCH 121 training takes 0:02:21
[2023-07-07 11:52:43 RepVGG-A0] (main.py 282): INFO Train: [122/300][0/78]	eta 0:26:38 lr 4.124902	time 20.4875 (20.4875)	loss 3.1869 (3.1869)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 11:52:59 RepVGG-A0] (main.py 282): INFO Train: [122/300][10/78]	eta 0:03:40 lr 4.120788	time 1.1704 (3.2440)	loss 3.1660 (3.2437)	grad_norm 0.3633 (0.4267)	mem 39782MB
[2023-07-07 11:53:15 RepVGG-A0] (main.py 282): INFO Train: [122/300][20/78]	eta 0:02:22 lr 4.116673	time 1.1814 (2.4550)	loss 3.2201 (3.2322)	grad_norm 0.3262 (0.3902)	mem 39782MB
[2023-07-07 11:53:29 RepVGG-A0] (main.py 282): INFO Train: [122/300][30/78]	eta 0:01:42 lr 4.112556	time 1.2260 (2.1338)	loss 3.3290 (3.2243)	grad_norm 0.4414 (0.3851)	mem 39782MB
[2023-07-07 11:53:49 RepVGG-A0] (main.py 282): INFO Train: [122/300][40/78]	eta 0:01:19 lr 4.108437	time 5.4857 (2.0893)	loss 3.2558 (3.2258)	grad_norm 0.3652 (0.3833)	mem 39782MB
[2023-07-07 11:54:03 RepVGG-A0] (main.py 282): INFO Train: [122/300][50/78]	eta 0:00:55 lr 4.104317	time 1.1767 (1.9697)	loss 3.2307 (3.2197)	grad_norm 0.4328 (0.3792)	mem 39782MB
[2023-07-07 11:54:19 RepVGG-A0] (main.py 282): INFO Train: [122/300][60/78]	eta 0:00:34 lr 4.100195	time 1.2551 (1.9092)	loss 3.1905 (3.2226)	grad_norm 0.3409 (0.3807)	mem 39782MB
[2023-07-07 11:54:34 RepVGG-A0] (main.py 282): INFO Train: [122/300][70/78]	eta 0:00:14 lr 4.096072	time 1.2097 (1.8524)	loss 3.3211 (3.2174)	grad_norm 0.4102 (0.3791)	mem 39782MB
[2023-07-07 11:54:45 RepVGG-A0] (main.py 291): INFO EPOCH 122 training takes 0:02:21
[2023-07-07 11:55:06 RepVGG-A0] (main.py 282): INFO Train: [123/300][0/78]	eta 0:28:03 lr 4.092772	time 21.5847 (21.5847)	loss 3.2083 (3.2083)	grad_norm 0.4251 (0.4251)	mem 39782MB
[2023-07-07 11:55:21 RepVGG-A0] (main.py 282): INFO Train: [123/300][10/78]	eta 0:03:44 lr 4.088645	time 1.1930 (3.2995)	loss 3.1751 (3.2335)	grad_norm 0.3225 (0.4078)	mem 39782MB
[2023-07-07 11:55:36 RepVGG-A0] (main.py 282): INFO Train: [123/300][20/78]	eta 0:02:21 lr 4.084517	time 1.1729 (2.4428)	loss 3.1159 (3.2136)	grad_norm 0.3635 (0.3850)	mem 39782MB
[2023-07-07 11:55:51 RepVGG-A0] (main.py 282): INFO Train: [123/300][30/78]	eta 0:01:41 lr 4.080388	time 1.1264 (2.1225)	loss 3.7259 (3.2346)	grad_norm 0.7181 (0.4055)	mem 39782MB
[2023-07-07 11:56:09 RepVGG-A0] (main.py 282): INFO Train: [123/300][40/78]	eta 0:01:17 lr 4.076256	time 4.0643 (2.0466)	loss 5.6378 (3.8146)	grad_norm 0.5610 (0.5285)	mem 39782MB
[2023-07-07 11:56:24 RepVGG-A0] (main.py 282): INFO Train: [123/300][50/78]	eta 0:00:54 lr 4.072124	time 1.1719 (1.9340)	loss 4.4749 (4.0068)	grad_norm 0.3829 (0.4949)	mem 39782MB
[2023-07-07 11:56:38 RepVGG-A0] (main.py 282): INFO Train: [123/300][60/78]	eta 0:00:33 lr 4.067989	time 1.1777 (1.8519)	loss 4.0441 (4.0434)	grad_norm 0.2804 (0.4687)	mem 39782MB
[2023-07-07 11:56:53 RepVGG-A0] (main.py 282): INFO Train: [123/300][70/78]	eta 0:00:14 lr 4.063853	time 1.2055 (1.8019)	loss 3.7685 (4.0150)	grad_norm 0.2780 (0.4430)	mem 39782MB
[2023-07-07 11:57:04 RepVGG-A0] (main.py 291): INFO EPOCH 123 training takes 0:02:19
[2023-07-07 11:57:26 RepVGG-A0] (main.py 282): INFO Train: [124/300][0/78]	eta 0:27:25 lr 4.060543	time 21.0964 (21.0964)	loss 3.6585 (3.6585)	grad_norm 0.3113 (0.3113)	mem 39782MB
[2023-07-07 11:57:40 RepVGG-A0] (main.py 282): INFO Train: [124/300][10/78]	eta 0:03:38 lr 4.056405	time 1.1699 (3.2193)	loss 3.4499 (3.5863)	grad_norm 0.2768 (0.3000)	mem 39782MB
[2023-07-07 11:57:55 RepVGG-A0] (main.py 282): INFO Train: [124/300][20/78]	eta 0:02:19 lr 4.052264	time 1.1725 (2.3988)	loss 3.5731 (3.5551)	grad_norm 0.3314 (0.3120)	mem 39782MB
[2023-07-07 11:58:11 RepVGG-A0] (main.py 282): INFO Train: [124/300][30/78]	eta 0:01:43 lr 4.048123	time 1.2754 (2.1521)	loss 3.3974 (3.5291)	grad_norm 0.3085 (0.3089)	mem 39782MB
[2023-07-07 11:58:29 RepVGG-A0] (main.py 282): INFO Train: [124/300][40/78]	eta 0:01:18 lr 4.043979	time 2.6760 (2.0596)	loss 3.4561 (3.5141)	grad_norm 0.3648 (0.3243)	mem 39782MB
[2023-07-07 11:58:45 RepVGG-A0] (main.py 282): INFO Train: [124/300][50/78]	eta 0:00:54 lr 4.039835	time 1.1775 (1.9623)	loss 3.4287 (3.4977)	grad_norm 0.3472 (0.3260)	mem 39782MB
[2023-07-07 11:58:59 RepVGG-A0] (main.py 282): INFO Train: [124/300][60/78]	eta 0:00:33 lr 4.035688	time 1.4495 (1.8809)	loss 3.4688 (3.4849)	grad_norm 0.3672 (0.3340)	mem 39782MB
[2023-07-07 11:59:15 RepVGG-A0] (main.py 282): INFO Train: [124/300][70/78]	eta 0:00:14 lr 4.031540	time 1.1920 (1.8316)	loss 3.4307 (3.4679)	grad_norm 0.3971 (0.3335)	mem 39782MB
[2023-07-07 11:59:26 RepVGG-A0] (main.py 291): INFO EPOCH 124 training takes 0:02:21
[2023-07-07 11:59:46 RepVGG-A0] (main.py 282): INFO Train: [125/300][0/78]	eta 0:26:39 lr 4.028221	time 20.5050 (20.5050)	loss 3.4254 (3.4254)	grad_norm 0.4339 (0.4339)	mem 39782MB
[2023-07-07 12:00:00 RepVGG-A0] (main.py 282): INFO Train: [125/300][10/78]	eta 0:03:33 lr 4.024070	time 1.1714 (3.1418)	loss 3.3178 (3.3196)	grad_norm 0.4142 (0.3486)	mem 39782MB
[2023-07-07 12:00:15 RepVGG-A0] (main.py 282): INFO Train: [125/300][20/78]	eta 0:02:15 lr 4.019918	time 1.1720 (2.3436)	loss 3.2066 (3.3260)	grad_norm 0.3500 (0.3644)	mem 39782MB
[2023-07-07 12:00:30 RepVGG-A0] (main.py 282): INFO Train: [125/300][30/78]	eta 0:01:39 lr 4.015765	time 1.3363 (2.0828)	loss 3.3514 (3.3087)	grad_norm 0.3681 (0.3536)	mem 39782MB
[2023-07-07 12:00:49 RepVGG-A0] (main.py 282): INFO Train: [125/300][40/78]	eta 0:01:16 lr 4.011610	time 4.1526 (2.0190)	loss 3.2839 (3.3172)	grad_norm 0.3332 (0.3625)	mem 39782MB
[2023-07-07 12:01:03 RepVGG-A0] (main.py 282): INFO Train: [125/300][50/78]	eta 0:00:53 lr 4.007453	time 1.1745 (1.9167)	loss 3.2036 (3.3110)	grad_norm 0.3658 (0.3631)	mem 39782MB
[2023-07-07 12:01:18 RepVGG-A0] (main.py 282): INFO Train: [125/300][60/78]	eta 0:00:33 lr 4.003296	time 1.1743 (1.8431)	loss 3.4039 (3.3110)	grad_norm 0.4948 (0.3656)	mem 39782MB
[2023-07-07 12:01:34 RepVGG-A0] (main.py 282): INFO Train: [125/300][70/78]	eta 0:00:14 lr 3.999136	time 1.2354 (1.8046)	loss 3.3257 (3.3173)	grad_norm 0.3758 (0.3696)	mem 39782MB
[2023-07-07 12:01:46 RepVGG-A0] (main.py 291): INFO EPOCH 125 training takes 0:02:19
[2023-07-07 12:02:09 RepVGG-A0] (main.py 282): INFO Train: [126/300][0/78]	eta 0:29:49 lr 3.995808	time 22.9447 (22.9447)	loss 3.1842 (3.1842)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 12:02:23 RepVGG-A0] (main.py 282): INFO Train: [126/300][10/78]	eta 0:03:48 lr 3.991646	time 1.1720 (3.3530)	loss 3.2915 (3.2165)	grad_norm 0.4313 (0.3699)	mem 39782MB
[2023-07-07 12:02:36 RepVGG-A0] (main.py 282): INFO Train: [126/300][20/78]	eta 0:02:19 lr 3.987482	time 1.2349 (2.4099)	loss 4.1980 (3.4935)	grad_norm 0.7351 (0.5165)	mem 39782MB
[2023-07-07 12:02:51 RepVGG-A0] (main.py 282): INFO Train: [126/300][30/78]	eta 0:01:40 lr 3.983318	time 1.1771 (2.0986)	loss 3.4373 (3.5987)	grad_norm 0.2850 (0.4961)	mem 39782MB
[2023-07-07 12:03:10 RepVGG-A0] (main.py 282): INFO Train: [126/300][40/78]	eta 0:01:18 lr 3.979151	time 4.7410 (2.0540)	loss 3.3316 (3.5448)	grad_norm 0.2782 (0.4436)	mem 39782MB
[2023-07-07 12:03:24 RepVGG-A0] (main.py 282): INFO Train: [126/300][50/78]	eta 0:00:54 lr 3.974984	time 1.1731 (1.9334)	loss 3.2997 (3.4953)	grad_norm 0.3118 (0.4131)	mem 39782MB
[2023-07-07 12:03:40 RepVGG-A0] (main.py 282): INFO Train: [126/300][60/78]	eta 0:00:33 lr 3.970815	time 1.1803 (1.8725)	loss 3.1461 (3.4545)	grad_norm 0.2914 (0.3957)	mem 39782MB
[2023-07-07 12:03:55 RepVGG-A0] (main.py 282): INFO Train: [126/300][70/78]	eta 0:00:14 lr 3.966644	time 1.3349 (1.8238)	loss 3.2624 (3.4186)	grad_norm 0.3286 (0.3824)	mem 39782MB
[2023-07-07 12:04:07 RepVGG-A0] (main.py 291): INFO EPOCH 126 training takes 0:02:21
[2023-07-07 12:04:28 RepVGG-A0] (main.py 282): INFO Train: [127/300][0/78]	eta 0:26:40 lr 3.963307	time 20.5227 (20.5227)	loss 3.1686 (3.1686)	grad_norm 0.3726 (0.3726)	mem 39782MB
[2023-07-07 12:04:42 RepVGG-A0] (main.py 282): INFO Train: [127/300][10/78]	eta 0:03:37 lr 3.959134	time 1.3362 (3.2016)	loss 3.1637 (3.1916)	grad_norm 0.2905 (0.3446)	mem 39782MB
[2023-07-07 12:04:59 RepVGG-A0] (main.py 282): INFO Train: [127/300][20/78]	eta 0:02:24 lr 3.954960	time 1.2186 (2.4943)	loss 3.2927 (3.2016)	grad_norm 0.4340 (0.3657)	mem 39782MB
[2023-07-07 12:05:15 RepVGG-A0] (main.py 282): INFO Train: [127/300][30/78]	eta 0:01:44 lr 3.950784	time 1.3105 (2.1847)	loss 3.2520 (3.2138)	grad_norm 0.3447 (0.3619)	mem 39782MB
[2023-07-07 12:05:32 RepVGG-A0] (main.py 282): INFO Train: [127/300][40/78]	eta 0:01:18 lr 3.946607	time 1.1877 (2.0664)	loss 3.2599 (3.2051)	grad_norm 0.3421 (0.3549)	mem 39782MB
[2023-07-07 12:05:46 RepVGG-A0] (main.py 282): INFO Train: [127/300][50/78]	eta 0:00:54 lr 3.942429	time 1.1911 (1.9315)	loss 3.1916 (3.2073)	grad_norm 0.3641 (0.3589)	mem 39782MB
[2023-07-07 12:06:01 RepVGG-A0] (main.py 282): INFO Train: [127/300][60/78]	eta 0:00:33 lr 3.938249	time 1.1761 (1.8657)	loss 3.2166 (3.2146)	grad_norm 0.3602 (0.3625)	mem 39782MB
[2023-07-07 12:06:16 RepVGG-A0] (main.py 282): INFO Train: [127/300][70/78]	eta 0:00:14 lr 3.934069	time 1.6114 (1.8160)	loss 3.2527 (3.2135)	grad_norm 0.3669 (0.3619)	mem 39782MB
[2023-07-07 12:06:27 RepVGG-A0] (main.py 291): INFO EPOCH 127 training takes 0:02:19
[2023-07-07 12:06:47 RepVGG-A0] (main.py 282): INFO Train: [128/300][0/78]	eta 0:26:34 lr 3.930723	time 20.4443 (20.4443)	loss 3.1880 (3.1880)	grad_norm 0.4096 (0.4096)	mem 39782MB
[2023-07-07 12:07:02 RepVGG-A0] (main.py 282): INFO Train: [128/300][10/78]	eta 0:03:37 lr 3.926539	time 1.1732 (3.1958)	loss 3.3567 (3.1840)	grad_norm 0.5200 (0.3976)	mem 39782MB
[2023-07-07 12:07:17 RepVGG-A0] (main.py 282): INFO Train: [128/300][20/78]	eta 0:02:18 lr 3.922355	time 1.3494 (2.3872)	loss 3.2034 (3.2399)	grad_norm 0.3907 (0.4163)	mem 39782MB
[2023-07-07 12:07:32 RepVGG-A0] (main.py 282): INFO Train: [128/300][30/78]	eta 0:01:40 lr 3.918169	time 1.3442 (2.1035)	loss 3.1771 (3.2230)	grad_norm 0.3474 (0.3936)	mem 39782MB
[2023-07-07 12:07:49 RepVGG-A0] (main.py 282): INFO Train: [128/300][40/78]	eta 0:01:16 lr 3.913982	time 2.7195 (2.0088)	loss 3.1553 (3.2118)	grad_norm 0.3579 (0.3849)	mem 39782MB
[2023-07-07 12:08:04 RepVGG-A0] (main.py 282): INFO Train: [128/300][50/78]	eta 0:00:53 lr 3.909793	time 1.1716 (1.9087)	loss 3.3902 (3.2426)	grad_norm 0.5066 (0.4082)	mem 39782MB
[2023-07-07 12:08:20 RepVGG-A0] (main.py 282): INFO Train: [128/300][60/78]	eta 0:00:33 lr 3.905603	time 1.1278 (1.8496)	loss 3.2574 (3.2516)	grad_norm 0.3325 (0.4079)	mem 39782MB
[2023-07-07 12:08:35 RepVGG-A0] (main.py 282): INFO Train: [128/300][70/78]	eta 0:00:14 lr 3.901412	time 1.3808 (1.7988)	loss 3.1956 (3.2445)	grad_norm 0.3498 (0.3960)	mem 39782MB
[2023-07-07 12:08:46 RepVGG-A0] (main.py 291): INFO EPOCH 128 training takes 0:02:19
[2023-07-07 12:09:07 RepVGG-A0] (main.py 282): INFO Train: [129/300][0/78]	eta 0:26:48 lr 3.898058	time 20.6167 (20.6167)	loss 3.0784 (3.0784)	grad_norm 0.3332 (0.3332)	mem 39782MB
[2023-07-07 12:09:22 RepVGG-A0] (main.py 282): INFO Train: [129/300][10/78]	eta 0:03:43 lr 3.893865	time 1.1728 (3.2912)	loss 3.1011 (3.1304)	grad_norm 0.3821 (0.3543)	mem 39782MB
[2023-07-07 12:09:37 RepVGG-A0] (main.py 282): INFO Train: [129/300][20/78]	eta 0:02:20 lr 3.889670	time 1.3173 (2.4283)	loss 3.1406 (3.1373)	grad_norm 0.3358 (0.3566)	mem 39782MB
[2023-07-07 12:09:53 RepVGG-A0] (main.py 282): INFO Train: [129/300][30/78]	eta 0:01:43 lr 3.885475	time 1.1263 (2.1519)	loss 3.1890 (3.1406)	grad_norm 0.3979 (0.3596)	mem 39782MB
[2023-07-07 12:10:11 RepVGG-A0] (main.py 282): INFO Train: [129/300][40/78]	eta 0:01:18 lr 3.881277	time 4.1823 (2.0718)	loss 3.4060 (3.1972)	grad_norm 0.4657 (0.3996)	mem 39782MB
[2023-07-07 12:10:26 RepVGG-A0] (main.py 282): INFO Train: [129/300][50/78]	eta 0:00:55 lr 3.877079	time 1.2949 (1.9650)	loss 3.1715 (3.2085)	grad_norm 0.3066 (0.3906)	mem 39782MB
[2023-07-07 12:10:41 RepVGG-A0] (main.py 282): INFO Train: [129/300][60/78]	eta 0:00:33 lr 3.872880	time 1.1825 (1.8755)	loss 3.1791 (3.2071)	grad_norm 0.3338 (0.3834)	mem 39782MB
[2023-07-07 12:10:56 RepVGG-A0] (main.py 282): INFO Train: [129/300][70/78]	eta 0:00:14 lr 3.868679	time 1.2460 (1.8237)	loss 3.2812 (3.2034)	grad_norm 0.3892 (0.3804)	mem 39782MB
[2023-07-07 12:11:07 RepVGG-A0] (main.py 291): INFO EPOCH 129 training takes 0:02:20
[2023-07-07 12:11:28 RepVGG-A0] (main.py 282): INFO Train: [130/300][0/78]	eta 0:27:04 lr 3.865317	time 20.8298 (20.8298)	loss 3.1253 (3.1253)	grad_norm 0.3896 (0.3896)	mem 39782MB
[2023-07-07 12:11:43 RepVGG-A0] (main.py 282): INFO Train: [130/300][10/78]	eta 0:03:43 lr 3.861114	time 1.1900 (3.2871)	loss 3.2076 (3.1320)	grad_norm 0.4363 (0.3777)	mem 39782MB
[2023-07-07 12:11:58 RepVGG-A0] (main.py 282): INFO Train: [130/300][20/78]	eta 0:02:21 lr 3.856910	time 1.1753 (2.4355)	loss 3.2095 (3.1520)	grad_norm 0.3774 (0.3877)	mem 39782MB
[2023-07-07 12:12:14 RepVGG-A0] (main.py 282): INFO Train: [130/300][30/78]	eta 0:01:43 lr 3.852705	time 1.3917 (2.1570)	loss 3.2097 (3.1791)	grad_norm 0.3818 (0.4039)	mem 39782MB
[2023-07-07 12:12:31 RepVGG-A0] (main.py 282): INFO Train: [130/300][40/78]	eta 0:01:18 lr 3.848499	time 3.4113 (2.0618)	loss 3.0497 (3.1682)	grad_norm 0.3226 (0.3881)	mem 39782MB
[2023-07-07 12:12:46 RepVGG-A0] (main.py 282): INFO Train: [130/300][50/78]	eta 0:00:54 lr 3.844291	time 1.1733 (1.9471)	loss 3.2217 (3.1630)	grad_norm 0.3681 (0.3855)	mem 39782MB
[2023-07-07 12:13:00 RepVGG-A0] (main.py 282): INFO Train: [130/300][60/78]	eta 0:00:33 lr 3.840082	time 1.2108 (1.8556)	loss 3.1483 (3.1632)	grad_norm 0.4122 (0.3846)	mem 39782MB
[2023-07-07 12:13:16 RepVGG-A0] (main.py 282): INFO Train: [130/300][70/78]	eta 0:00:14 lr 3.835872	time 1.2116 (1.8105)	loss 3.2295 (3.1658)	grad_norm 0.4715 (0.3867)	mem 39782MB
[2023-07-07 12:13:27 RepVGG-A0] (main.py 291): INFO EPOCH 130 training takes 0:02:20
[2023-07-07 12:13:49 RepVGG-A0] (main.py 282): INFO Train: [131/300][0/78]	eta 0:28:32 lr 3.832503	time 21.9602 (21.9602)	loss 3.0846 (3.0846)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 12:14:04 RepVGG-A0] (main.py 282): INFO Train: [131/300][10/78]	eta 0:03:48 lr 3.828291	time 1.1718 (3.3552)	loss 3.0380 (3.1356)	grad_norm 0.3330 (0.3943)	mem 39782MB
[2023-07-07 12:14:18 RepVGG-A0] (main.py 282): INFO Train: [131/300][20/78]	eta 0:02:21 lr 3.824078	time 1.1722 (2.4363)	loss 3.0947 (3.1148)	grad_norm 0.3571 (0.3748)	mem 39782MB
[2023-07-07 12:14:34 RepVGG-A0] (main.py 282): INFO Train: [131/300][30/78]	eta 0:01:43 lr 3.819864	time 1.5822 (2.1637)	loss 3.1569 (3.1163)	grad_norm 0.4180 (0.3766)	mem 39782MB
[2023-07-07 12:14:52 RepVGG-A0] (main.py 282): INFO Train: [131/300][40/78]	eta 0:01:18 lr 3.815649	time 4.1113 (2.0754)	loss 3.1402 (3.1353)	grad_norm 0.4111 (0.3874)	mem 39782MB
[2023-07-07 12:15:07 RepVGG-A0] (main.py 282): INFO Train: [131/300][50/78]	eta 0:00:54 lr 3.811432	time 1.1753 (1.9530)	loss 3.1082 (3.1375)	grad_norm 0.3226 (0.3814)	mem 39782MB
[2023-07-07 12:15:22 RepVGG-A0] (main.py 282): INFO Train: [131/300][60/78]	eta 0:00:33 lr 3.807215	time 1.4013 (1.8810)	loss 3.1681 (3.1445)	grad_norm 0.4056 (0.3848)	mem 39782MB
[2023-07-07 12:15:36 RepVGG-A0] (main.py 282): INFO Train: [131/300][70/78]	eta 0:00:14 lr 3.802996	time 1.1257 (1.8166)	loss 3.1842 (3.1564)	grad_norm 0.3524 (0.3884)	mem 39782MB
[2023-07-07 12:15:48 RepVGG-A0] (main.py 291): INFO EPOCH 131 training takes 0:02:21
[2023-07-07 12:16:10 RepVGG-A0] (main.py 282): INFO Train: [132/300][0/78]	eta 0:27:44 lr 3.799620	time 21.3447 (21.3447)	loss 3.0818 (3.0818)	grad_norm 0.3986 (0.3986)	mem 39782MB
[2023-07-07 12:16:25 RepVGG-A0] (main.py 282): INFO Train: [132/300][10/78]	eta 0:03:48 lr 3.795400	time 1.1736 (3.3639)	loss 3.0938 (3.1026)	grad_norm 0.3565 (0.3877)	mem 39782MB
[2023-07-07 12:16:41 RepVGG-A0] (main.py 282): INFO Train: [132/300][20/78]	eta 0:02:24 lr 3.791178	time 1.1752 (2.4878)	loss 3.1312 (3.0894)	grad_norm 0.4164 (0.3764)	mem 39782MB
[2023-07-07 12:16:56 RepVGG-A0] (main.py 282): INFO Train: [132/300][30/78]	eta 0:01:45 lr 3.786955	time 1.3602 (2.1915)	loss 3.2371 (3.1279)	grad_norm 0.4345 (0.3963)	mem 39782MB
[2023-07-07 12:17:14 RepVGG-A0] (main.py 282): INFO Train: [132/300][40/78]	eta 0:01:19 lr 3.782731	time 4.0693 (2.0924)	loss 3.1445 (3.1295)	grad_norm 0.3607 (0.3917)	mem 39782MB
[2023-07-07 12:17:30 RepVGG-A0] (main.py 282): INFO Train: [132/300][50/78]	eta 0:00:55 lr 3.778506	time 1.1739 (1.9849)	loss 3.1267 (3.1304)	grad_norm 0.3569 (0.3917)	mem 39782MB
[2023-07-07 12:17:45 RepVGG-A0] (main.py 282): INFO Train: [132/300][60/78]	eta 0:00:34 lr 3.774280	time 1.5795 (1.9151)	loss 3.1923 (3.1304)	grad_norm 0.4383 (0.3900)	mem 39782MB
[2023-07-07 12:18:01 RepVGG-A0] (main.py 282): INFO Train: [132/300][70/78]	eta 0:00:14 lr 3.770053	time 1.1823 (1.8716)	loss 3.1065 (3.1311)	grad_norm 0.3495 (0.3890)	mem 39782MB
[2023-07-07 12:18:13 RepVGG-A0] (main.py 291): INFO EPOCH 132 training takes 0:02:24
[2023-07-07 12:18:35 RepVGG-A0] (main.py 282): INFO Train: [133/300][0/78]	eta 0:27:42 lr 3.766671	time 21.3109 (21.3109)	loss 3.1441 (3.1441)	grad_norm 0.4493 (0.4493)	mem 39782MB
[2023-07-07 12:18:50 RepVGG-A0] (main.py 282): INFO Train: [133/300][10/78]	eta 0:03:49 lr 3.762442	time 1.1889 (3.3710)	loss 3.1860 (3.1539)	grad_norm 0.3868 (0.4279)	mem 39782MB
[2023-07-07 12:19:04 RepVGG-A0] (main.py 282): INFO Train: [133/300][20/78]	eta 0:02:21 lr 3.758213	time 1.1793 (2.4364)	loss 3.0657 (3.1251)	grad_norm 0.3395 (0.3970)	mem 39782MB
[2023-07-07 12:19:20 RepVGG-A0] (main.py 282): INFO Train: [133/300][30/78]	eta 0:01:44 lr 3.753982	time 1.1266 (2.1681)	loss 3.2874 (3.1284)	grad_norm 0.5089 (0.3999)	mem 39782MB
[2023-07-07 12:19:38 RepVGG-A0] (main.py 282): INFO Train: [133/300][40/78]	eta 0:01:18 lr 3.749750	time 3.4142 (2.0784)	loss 3.2914 (3.1665)	grad_norm 0.4644 (0.4221)	mem 39782MB
[2023-07-07 12:19:53 RepVGG-A0] (main.py 282): INFO Train: [133/300][50/78]	eta 0:00:54 lr 3.745517	time 1.1745 (1.9618)	loss 3.1294 (3.1695)	grad_norm 0.3405 (0.4122)	mem 39782MB
[2023-07-07 12:20:09 RepVGG-A0] (main.py 282): INFO Train: [133/300][60/78]	eta 0:00:34 lr 3.741283	time 1.3816 (1.8912)	loss 3.1444 (3.1652)	grad_norm 0.3420 (0.4020)	mem 39782MB
[2023-07-07 12:20:24 RepVGG-A0] (main.py 282): INFO Train: [133/300][70/78]	eta 0:00:14 lr 3.737049	time 1.3156 (1.8391)	loss 3.1604 (3.1575)	grad_norm 0.3681 (0.3957)	mem 39782MB
[2023-07-07 12:20:35 RepVGG-A0] (main.py 291): INFO EPOCH 133 training takes 0:02:21
[2023-07-07 12:20:56 RepVGG-A0] (main.py 282): INFO Train: [134/300][0/78]	eta 0:27:50 lr 3.733660	time 21.4198 (21.4198)	loss 3.1304 (3.1304)	grad_norm 0.4067 (0.4067)	mem 39782MB
[2023-07-07 12:21:10 RepVGG-A0] (main.py 282): INFO Train: [134/300][10/78]	eta 0:03:33 lr 3.729423	time 1.1927 (3.1470)	loss 3.1437 (3.1064)	grad_norm 0.3856 (0.3913)	mem 39782MB
[2023-07-07 12:21:24 RepVGG-A0] (main.py 282): INFO Train: [134/300][20/78]	eta 0:02:15 lr 3.725186	time 1.1734 (2.3390)	loss 3.0609 (3.0904)	grad_norm 0.3655 (0.3833)	mem 39782MB
[2023-07-07 12:21:39 RepVGG-A0] (main.py 282): INFO Train: [134/300][30/78]	eta 0:01:38 lr 3.720948	time 1.1730 (2.0552)	loss 3.1155 (3.0866)	grad_norm 0.3957 (0.3810)	mem 39782MB
[2023-07-07 12:21:58 RepVGG-A0] (main.py 282): INFO Train: [134/300][40/78]	eta 0:01:16 lr 3.716708	time 3.9600 (2.0213)	loss 3.1727 (3.0948)	grad_norm 0.4246 (0.3872)	mem 39782MB
[2023-07-07 12:22:13 RepVGG-A0] (main.py 282): INFO Train: [134/300][50/78]	eta 0:00:53 lr 3.712468	time 1.1925 (1.9198)	loss 3.1115 (3.1051)	grad_norm 0.3637 (0.3909)	mem 39782MB
[2023-07-07 12:22:27 RepVGG-A0] (main.py 282): INFO Train: [134/300][60/78]	eta 0:00:33 lr 3.708227	time 1.1738 (1.8427)	loss 3.0965 (3.1041)	grad_norm 0.3580 (0.3857)	mem 39782MB
[2023-07-07 12:22:42 RepVGG-A0] (main.py 282): INFO Train: [134/300][70/78]	eta 0:00:14 lr 3.703985	time 1.2679 (1.7942)	loss 3.2060 (3.1095)	grad_norm 0.4400 (0.3887)	mem 39782MB
[2023-07-07 12:22:56 RepVGG-A0] (main.py 291): INFO EPOCH 134 training takes 0:02:20
[2023-07-07 12:23:17 RepVGG-A0] (main.py 282): INFO Train: [135/300][0/78]	eta 0:27:35 lr 3.700590	time 21.2206 (21.2206)	loss 3.1380 (3.1380)	grad_norm 0.3975 (0.3975)	mem 39782MB
[2023-07-07 12:23:31 RepVGG-A0] (main.py 282): INFO Train: [135/300][10/78]	eta 0:03:37 lr 3.696347	time 1.1715 (3.2015)	loss 3.0490 (3.0358)	grad_norm 0.3464 (0.3517)	mem 39782MB
[2023-07-07 12:23:46 RepVGG-A0] (main.py 282): INFO Train: [135/300][20/78]	eta 0:02:20 lr 3.692102	time 1.1728 (2.4204)	loss 3.2297 (3.1010)	grad_norm 0.5393 (0.4071)	mem 39782MB
[2023-07-07 12:24:02 RepVGG-A0] (main.py 282): INFO Train: [135/300][30/78]	eta 0:01:42 lr 3.687856	time 1.3224 (2.1284)	loss 3.0555 (3.1232)	grad_norm 0.3365 (0.4024)	mem 39782MB
[2023-07-07 12:24:20 RepVGG-A0] (main.py 282): INFO Train: [135/300][40/78]	eta 0:01:17 lr 3.683610	time 3.6069 (2.0503)	loss 3.0258 (3.1111)	grad_norm 0.3426 (0.3885)	mem 39782MB
[2023-07-07 12:24:35 RepVGG-A0] (main.py 282): INFO Train: [135/300][50/78]	eta 0:00:54 lr 3.679363	time 1.1774 (1.9421)	loss 3.1702 (3.1133)	grad_norm 0.3445 (0.3864)	mem 39782MB
[2023-07-07 12:24:50 RepVGG-A0] (main.py 282): INFO Train: [135/300][60/78]	eta 0:00:33 lr 3.675115	time 1.1733 (1.8669)	loss 3.1072 (3.1070)	grad_norm 0.3513 (0.3794)	mem 39782MB
[2023-07-07 12:25:04 RepVGG-A0] (main.py 282): INFO Train: [135/300][70/78]	eta 0:00:14 lr 3.670866	time 1.2648 (1.8133)	loss 3.2879 (3.1170)	grad_norm 0.4666 (0.3906)	mem 39782MB
[2023-07-07 12:25:16 RepVGG-A0] (main.py 291): INFO EPOCH 135 training takes 0:02:20
[2023-07-07 12:25:38 RepVGG-A0] (main.py 282): INFO Train: [136/300][0/78]	eta 0:28:28 lr 3.667466	time 21.8987 (21.8987)	loss 3.0547 (3.0547)	grad_norm 0.3493 (0.3493)	mem 39782MB
[2023-07-07 12:25:53 RepVGG-A0] (main.py 282): INFO Train: [136/300][10/78]	eta 0:03:47 lr 3.663215	time 1.2003 (3.3526)	loss 3.0711 (3.0758)	grad_norm 0.3979 (0.3630)	mem 39782MB
[2023-07-07 12:26:08 RepVGG-A0] (main.py 282): INFO Train: [136/300][20/78]	eta 0:02:22 lr 3.658964	time 1.4082 (2.4639)	loss 3.0253 (3.0757)	grad_norm 0.3678 (0.3712)	mem 39782MB
[2023-07-07 12:26:24 RepVGG-A0] (main.py 282): INFO Train: [136/300][30/78]	eta 0:01:44 lr 3.654712	time 1.5099 (2.1670)	loss 3.0703 (3.0839)	grad_norm 0.3802 (0.3806)	mem 39782MB
[2023-07-07 12:26:41 RepVGG-A0] (main.py 282): INFO Train: [136/300][40/78]	eta 0:01:18 lr 3.650459	time 3.2423 (2.0628)	loss 3.1937 (3.0862)	grad_norm 0.3895 (0.3786)	mem 39782MB
[2023-07-07 12:26:56 RepVGG-A0] (main.py 282): INFO Train: [136/300][50/78]	eta 0:00:54 lr 3.646205	time 1.1274 (1.9569)	loss 3.1941 (3.0936)	grad_norm 0.4674 (0.3877)	mem 39782MB
[2023-07-07 12:27:11 RepVGG-A0] (main.py 282): INFO Train: [136/300][60/78]	eta 0:00:33 lr 3.641950	time 1.2694 (1.8695)	loss 3.0889 (3.0996)	grad_norm 0.3659 (0.3899)	mem 39782MB
[2023-07-07 12:27:26 RepVGG-A0] (main.py 282): INFO Train: [136/300][70/78]	eta 0:00:14 lr 3.637695	time 1.2981 (1.8240)	loss 3.0726 (3.0930)	grad_norm 0.3520 (0.3849)	mem 39782MB
[2023-07-07 12:27:37 RepVGG-A0] (main.py 291): INFO EPOCH 136 training takes 0:02:20
[2023-07-07 12:27:59 RepVGG-A0] (main.py 282): INFO Train: [137/300][0/78]	eta 0:28:08 lr 3.634290	time 21.6507 (21.6507)	loss 3.0330 (3.0330)	grad_norm 0.3797 (0.3797)	mem 39782MB
[2023-07-07 12:28:14 RepVGG-A0] (main.py 282): INFO Train: [137/300][10/78]	eta 0:03:45 lr 3.630033	time 1.1736 (3.3114)	loss 3.1390 (3.1158)	grad_norm 0.4715 (0.4509)	mem 39782MB
[2023-07-07 12:28:28 RepVGG-A0] (main.py 282): INFO Train: [137/300][20/78]	eta 0:02:20 lr 3.625775	time 1.2778 (2.4218)	loss 3.1112 (3.1118)	grad_norm 0.4067 (0.4225)	mem 39782MB
[2023-07-07 12:28:45 RepVGG-A0] (main.py 282): INFO Train: [137/300][30/78]	eta 0:01:44 lr 3.621517	time 1.2942 (2.1855)	loss 3.1131 (3.0926)	grad_norm 0.3459 (0.3985)	mem 39782MB
[2023-07-07 12:29:02 RepVGG-A0] (main.py 282): INFO Train: [137/300][40/78]	eta 0:01:18 lr 3.617258	time 3.4861 (2.0594)	loss 3.0877 (3.0889)	grad_norm 0.3950 (0.3992)	mem 39782MB
[2023-07-07 12:29:16 RepVGG-A0] (main.py 282): INFO Train: [137/300][50/78]	eta 0:00:54 lr 3.612998	time 1.1742 (1.9425)	loss 3.1194 (3.0929)	grad_norm 0.4106 (0.4028)	mem 39782MB
[2023-07-07 12:29:32 RepVGG-A0] (main.py 282): INFO Train: [137/300][60/78]	eta 0:00:33 lr 3.608737	time 1.3973 (1.8736)	loss 3.0481 (3.0926)	grad_norm 0.3766 (0.3988)	mem 39782MB
[2023-07-07 12:29:48 RepVGG-A0] (main.py 282): INFO Train: [137/300][70/78]	eta 0:00:14 lr 3.604476	time 1.3777 (1.8396)	loss 3.0470 (3.0904)	grad_norm 0.3647 (0.3944)	mem 39782MB
[2023-07-07 12:29:59 RepVGG-A0] (main.py 291): INFO EPOCH 137 training takes 0:02:21
[2023-07-07 12:30:20 RepVGG-A0] (main.py 282): INFO Train: [138/300][0/78]	eta 0:27:47 lr 3.601066	time 21.3767 (21.3767)	loss 3.0243 (3.0243)	grad_norm 0.3662 (0.3662)	mem 39782MB
[2023-07-07 12:30:35 RepVGG-A0] (main.py 282): INFO Train: [138/300][10/78]	eta 0:03:44 lr 3.596804	time 1.1734 (3.3001)	loss 3.1568 (3.1145)	grad_norm 0.4469 (0.4457)	mem 39782MB
[2023-07-07 12:30:50 RepVGG-A0] (main.py 282): INFO Train: [138/300][20/78]	eta 0:02:21 lr 3.592540	time 1.1736 (2.4375)	loss 3.0712 (3.0911)	grad_norm 0.3703 (0.4149)	mem 39782MB
[2023-07-07 12:31:05 RepVGG-A0] (main.py 282): INFO Train: [138/300][30/78]	eta 0:01:42 lr 3.588276	time 1.3686 (2.1283)	loss 3.0230 (3.0800)	grad_norm 0.4117 (0.4038)	mem 39782MB
[2023-07-07 12:31:23 RepVGG-A0] (main.py 282): INFO Train: [138/300][40/78]	eta 0:01:17 lr 3.584011	time 4.1070 (2.0485)	loss 2.9753 (3.0707)	grad_norm 0.3636 (0.3978)	mem 39782MB
[2023-07-07 12:31:38 RepVGG-A0] (main.py 282): INFO Train: [138/300][50/78]	eta 0:00:54 lr 3.579746	time 1.1926 (1.9366)	loss 3.0532 (3.0736)	grad_norm 0.3665 (0.3944)	mem 39782MB
[2023-07-07 12:31:53 RepVGG-A0] (main.py 282): INFO Train: [138/300][60/78]	eta 0:00:33 lr 3.575480	time 1.2472 (1.8751)	loss 3.1835 (3.0767)	grad_norm 0.4636 (0.3988)	mem 39782MB
[2023-07-07 12:32:09 RepVGG-A0] (main.py 282): INFO Train: [138/300][70/78]	eta 0:00:14 lr 3.571213	time 1.4117 (1.8270)	loss 3.1047 (3.0949)	grad_norm 0.3824 (0.4076)	mem 39782MB
[2023-07-07 12:32:20 RepVGG-A0] (main.py 291): INFO EPOCH 138 training takes 0:02:21
[2023-07-07 12:32:41 RepVGG-A0] (main.py 282): INFO Train: [139/300][0/78]	eta 0:27:14 lr 3.567799	time 20.9511 (20.9511)	loss 3.0638 (3.0638)	grad_norm 0.3523 (0.3523)	mem 39782MB
[2023-07-07 12:32:56 RepVGG-A0] (main.py 282): INFO Train: [139/300][10/78]	eta 0:03:42 lr 3.563531	time 1.1926 (3.2765)	loss 3.0295 (3.0563)	grad_norm 0.3781 (0.3952)	mem 39782MB
[2023-07-07 12:33:12 RepVGG-A0] (main.py 282): INFO Train: [139/300][20/78]	eta 0:02:24 lr 3.559262	time 1.6893 (2.4883)	loss 3.1628 (3.0533)	grad_norm 0.4609 (0.3871)	mem 39782MB
[2023-07-07 12:33:25 RepVGG-A0] (main.py 282): INFO Train: [139/300][30/78]	eta 0:01:41 lr 3.554993	time 1.4334 (2.1072)	loss 3.0756 (3.0688)	grad_norm 0.3551 (0.3905)	mem 39782MB
[2023-07-07 12:33:43 RepVGG-A0] (main.py 282): INFO Train: [139/300][40/78]	eta 0:01:16 lr 3.550723	time 3.6506 (2.0248)	loss 3.1466 (3.0668)	grad_norm 0.4109 (0.3861)	mem 39782MB
[2023-07-07 12:33:59 RepVGG-A0] (main.py 282): INFO Train: [139/300][50/78]	eta 0:00:54 lr 3.546452	time 1.1728 (1.9398)	loss 2.9955 (3.0665)	grad_norm 0.3252 (0.3840)	mem 39782MB
[2023-07-07 12:34:14 RepVGG-A0] (main.py 282): INFO Train: [139/300][60/78]	eta 0:00:33 lr 3.542181	time 1.1832 (1.8653)	loss 3.1249 (3.0693)	grad_norm 0.4667 (0.3906)	mem 39782MB
[2023-07-07 12:34:29 RepVGG-A0] (main.py 282): INFO Train: [139/300][70/78]	eta 0:00:14 lr 3.537909	time 1.3262 (1.8177)	loss 3.0299 (3.0743)	grad_norm 0.3444 (0.3918)	mem 39782MB
[2023-07-07 12:34:41 RepVGG-A0] (main.py 291): INFO EPOCH 139 training takes 0:02:20
[2023-07-07 12:35:03 RepVGG-A0] (main.py 282): INFO Train: [140/300][0/78]	eta 0:28:57 lr 3.534491	time 22.2775 (22.2775)	loss 3.0723 (3.0723)	grad_norm 0.3325 (0.3325)	mem 39782MB
[2023-07-07 12:35:17 RepVGG-A0] (main.py 282): INFO Train: [140/300][10/78]	eta 0:03:45 lr 3.530218	time 1.1841 (3.3194)	loss 3.0736 (3.0220)	grad_norm 0.4228 (0.3946)	mem 39782MB
[2023-07-07 12:35:31 RepVGG-A0] (main.py 282): INFO Train: [140/300][20/78]	eta 0:02:17 lr 3.525945	time 1.1715 (2.3734)	loss 3.0695 (3.0324)	grad_norm 0.3781 (0.3896)	mem 39782MB
[2023-07-07 12:35:46 RepVGG-A0] (main.py 282): INFO Train: [140/300][30/78]	eta 0:01:40 lr 3.521670	time 1.3666 (2.1002)	loss 3.0330 (3.0318)	grad_norm 0.3498 (0.3859)	mem 39782MB
[2023-07-07 12:36:04 RepVGG-A0] (main.py 282): INFO Train: [140/300][40/78]	eta 0:01:16 lr 3.517396	time 3.8705 (2.0210)	loss 3.0445 (3.0536)	grad_norm 0.3589 (0.3966)	mem 39782MB
[2023-07-07 12:36:19 RepVGG-A0] (main.py 282): INFO Train: [140/300][50/78]	eta 0:00:53 lr 3.513120	time 1.1723 (1.9277)	loss 3.0433 (3.0511)	grad_norm 0.3936 (0.3909)	mem 39782MB
[2023-07-07 12:36:34 RepVGG-A0] (main.py 282): INFO Train: [140/300][60/78]	eta 0:00:33 lr 3.508845	time 1.1792 (1.8600)	loss 3.0152 (3.0543)	grad_norm 0.3913 (0.3921)	mem 39782MB
[2023-07-07 12:36:50 RepVGG-A0] (main.py 282): INFO Train: [140/300][70/78]	eta 0:00:14 lr 3.504568	time 1.4236 (1.8143)	loss 3.0474 (3.0571)	grad_norm 0.3965 (0.3920)	mem 39782MB
[2023-07-07 12:37:01 RepVGG-A0] (main.py 291): INFO EPOCH 140 training takes 0:02:20
[2023-07-07 12:37:18 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.327 (17.327)	Loss 3.0108 (3.0108)	Acc@1 38.049 (38.049)	Acc@5 64.020 (64.020)	Mem 39782MB
[2023-07-07 12:37:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 38.532 Acc@5 64.328
[2023-07-07 12:37:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 140: 38.532%
[2023-07-07 12:37:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 12:37:40 RepVGG-A0] (main.py 282): INFO Train: [141/300][0/78]	eta 0:26:22 lr 3.501147	time 20.2823 (20.2823)	loss 3.0218 (3.0218)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 12:37:55 RepVGG-A0] (main.py 282): INFO Train: [141/300][10/78]	eta 0:03:39 lr 3.496869	time 1.1949 (3.2267)	loss 3.0530 (3.0387)	grad_norm 0.3821 (0.3968)	mem 39782MB
[2023-07-07 12:38:10 RepVGG-A0] (main.py 282): INFO Train: [141/300][20/78]	eta 0:02:19 lr 3.492591	time 1.1753 (2.4092)	loss 3.0297 (3.0448)	grad_norm 0.3761 (0.3932)	mem 39782MB
[2023-07-07 12:38:25 RepVGG-A0] (main.py 282): INFO Train: [141/300][30/78]	eta 0:01:41 lr 3.488313	time 1.2987 (2.1062)	loss 3.0255 (3.0338)	grad_norm 0.3603 (0.3842)	mem 39782MB
[2023-07-07 12:38:43 RepVGG-A0] (main.py 282): INFO Train: [141/300][40/78]	eta 0:01:17 lr 3.484034	time 3.0559 (2.0317)	loss 3.1081 (3.0392)	grad_norm 0.4305 (0.3917)	mem 39782MB
[2023-07-07 12:38:59 RepVGG-A0] (main.py 282): INFO Train: [141/300][50/78]	eta 0:00:54 lr 3.479754	time 1.3001 (1.9362)	loss 3.0398 (3.0394)	grad_norm 0.3592 (0.3885)	mem 39782MB
[2023-07-07 12:39:13 RepVGG-A0] (main.py 282): INFO Train: [141/300][60/78]	eta 0:00:33 lr 3.475474	time 1.2082 (1.8578)	loss 3.0097 (3.0503)	grad_norm 0.3673 (0.3943)	mem 39782MB
[2023-07-07 12:39:29 RepVGG-A0] (main.py 282): INFO Train: [141/300][70/78]	eta 0:00:14 lr 3.471194	time 1.3180 (1.8117)	loss 3.1136 (3.0514)	grad_norm 0.4624 (0.3934)	mem 39782MB
[2023-07-07 12:39:40 RepVGG-A0] (main.py 291): INFO EPOCH 141 training takes 0:02:20
[2023-07-07 12:40:02 RepVGG-A0] (main.py 282): INFO Train: [142/300][0/78]	eta 0:27:45 lr 3.467769	time 21.3487 (21.3487)	loss 3.0707 (3.0707)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 12:40:16 RepVGG-A0] (main.py 282): INFO Train: [142/300][10/78]	eta 0:03:40 lr 3.463488	time 1.1737 (3.2416)	loss 3.0216 (3.0216)	grad_norm 0.3824 (0.3771)	mem 39782MB
[2023-07-07 12:40:32 RepVGG-A0] (main.py 282): INFO Train: [142/300][20/78]	eta 0:02:21 lr 3.459206	time 1.4691 (2.4454)	loss 3.0660 (3.0215)	grad_norm 0.4019 (0.3849)	mem 39782MB
[2023-07-07 12:40:46 RepVGG-A0] (main.py 282): INFO Train: [142/300][30/78]	eta 0:01:42 lr 3.454924	time 1.6071 (2.1298)	loss 3.0149 (3.0177)	grad_norm 0.4027 (0.3831)	mem 39782MB
[2023-07-07 12:41:04 RepVGG-A0] (main.py 282): INFO Train: [142/300][40/78]	eta 0:01:17 lr 3.450641	time 3.1633 (2.0361)	loss 3.2107 (3.0488)	grad_norm 0.4964 (0.4087)	mem 39782MB
[2023-07-07 12:41:18 RepVGG-A0] (main.py 282): INFO Train: [142/300][50/78]	eta 0:00:53 lr 3.446358	time 1.1265 (1.9189)	loss 3.0588 (3.0557)	grad_norm 0.3573 (0.4009)	mem 39782MB
[2023-07-07 12:41:34 RepVGG-A0] (main.py 282): INFO Train: [142/300][60/78]	eta 0:00:33 lr 3.442074	time 1.1804 (1.8567)	loss 3.0121 (3.0493)	grad_norm 0.3691 (0.3967)	mem 39782MB
[2023-07-07 12:41:49 RepVGG-A0] (main.py 282): INFO Train: [142/300][70/78]	eta 0:00:14 lr 3.437790	time 1.2607 (1.8111)	loss 3.0875 (3.0513)	grad_norm 0.4186 (0.3950)	mem 39782MB
[2023-07-07 12:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 142 training takes 0:02:19
[2023-07-07 12:42:20 RepVGG-A0] (main.py 282): INFO Train: [143/300][0/78]	eta 0:26:16 lr 3.434362	time 20.2160 (20.2160)	loss 2.9989 (2.9989)	grad_norm 0.3851 (0.3851)	mem 39782MB
[2023-07-07 12:42:39 RepVGG-A0] (main.py 282): INFO Train: [143/300][10/78]	eta 0:03:58 lr 3.430077	time 1.4306 (3.5116)	loss 2.9771 (2.9757)	grad_norm 0.4055 (0.3765)	mem 39782MB
[2023-07-07 12:42:52 RepVGG-A0] (main.py 282): INFO Train: [143/300][20/78]	eta 0:02:23 lr 3.425792	time 1.1816 (2.4694)	loss 3.0970 (3.0099)	grad_norm 0.4733 (0.3959)	mem 39782MB
[2023-07-07 12:43:06 RepVGG-A0] (main.py 282): INFO Train: [143/300][30/78]	eta 0:01:41 lr 3.421506	time 1.1737 (2.1136)	loss 2.9196 (3.0192)	grad_norm 0.3792 (0.3978)	mem 39782MB
[2023-07-07 12:43:25 RepVGG-A0] (main.py 282): INFO Train: [143/300][40/78]	eta 0:01:18 lr 3.417220	time 5.1888 (2.0604)	loss 3.0331 (3.0233)	grad_norm 0.4165 (0.3976)	mem 39782MB
[2023-07-07 12:43:40 RepVGG-A0] (main.py 282): INFO Train: [143/300][50/78]	eta 0:00:54 lr 3.412934	time 1.2419 (1.9585)	loss 3.1007 (3.0329)	grad_norm 0.3946 (0.3977)	mem 39782MB
[2023-07-07 12:43:55 RepVGG-A0] (main.py 282): INFO Train: [143/300][60/78]	eta 0:00:34 lr 3.408647	time 1.1763 (1.8896)	loss 3.1088 (3.0340)	grad_norm 0.4138 (0.3988)	mem 39782MB
[2023-07-07 12:44:10 RepVGG-A0] (main.py 282): INFO Train: [143/300][70/78]	eta 0:00:14 lr 3.404360	time 1.5436 (1.8278)	loss 3.1066 (3.0370)	grad_norm 0.4123 (0.3991)	mem 39782MB
[2023-07-07 12:44:22 RepVGG-A0] (main.py 291): INFO EPOCH 143 training takes 0:02:22
[2023-07-07 12:44:44 RepVGG-A0] (main.py 282): INFO Train: [144/300][0/78]	eta 0:27:54 lr 3.400930	time 21.4709 (21.4709)	loss 2.9717 (2.9717)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:44:58 RepVGG-A0] (main.py 282): INFO Train: [144/300][10/78]	eta 0:03:41 lr 3.396642	time 1.1715 (3.2544)	loss 3.0098 (2.9915)	grad_norm 0.4112 (0.4074)	mem 39782MB
[2023-07-07 12:45:12 RepVGG-A0] (main.py 282): INFO Train: [144/300][20/78]	eta 0:02:17 lr 3.392354	time 1.1738 (2.3625)	loss 3.0375 (3.0101)	grad_norm 0.3925 (0.4080)	mem 39782MB
[2023-07-07 12:45:27 RepVGG-A0] (main.py 282): INFO Train: [144/300][30/78]	eta 0:01:39 lr 3.388065	time 1.3646 (2.0736)	loss 3.0308 (3.0186)	grad_norm 0.3883 (0.4014)	mem 39782MB
[2023-07-07 12:45:45 RepVGG-A0] (main.py 282): INFO Train: [144/300][40/78]	eta 0:01:16 lr 3.383776	time 3.6954 (2.0256)	loss 3.0873 (3.0148)	grad_norm 0.4080 (0.3968)	mem 39782MB
[2023-07-07 12:46:01 RepVGG-A0] (main.py 282): INFO Train: [144/300][50/78]	eta 0:00:53 lr 3.379487	time 1.1727 (1.9266)	loss 3.0355 (3.0301)	grad_norm 0.3644 (0.4038)	mem 39782MB
[2023-07-07 12:46:16 RepVGG-A0] (main.py 282): INFO Train: [144/300][60/78]	eta 0:00:33 lr 3.375197	time 1.4649 (1.8628)	loss 3.0486 (3.0280)	grad_norm 0.3939 (0.4006)	mem 39782MB
[2023-07-07 12:46:31 RepVGG-A0] (main.py 282): INFO Train: [144/300][70/78]	eta 0:00:14 lr 3.370907	time 1.3937 (1.8120)	loss 3.0107 (3.0310)	grad_norm 0.4046 (0.4025)	mem 39782MB
[2023-07-07 12:46:43 RepVGG-A0] (main.py 291): INFO EPOCH 144 training takes 0:02:20
[2023-07-07 12:47:05 RepVGG-A0] (main.py 282): INFO Train: [145/300][0/78]	eta 0:28:33 lr 3.367475	time 21.9734 (21.9734)	loss 3.0455 (3.0455)	grad_norm 0.4466 (0.4466)	mem 39782MB
[2023-07-07 12:47:20 RepVGG-A0] (main.py 282): INFO Train: [145/300][10/78]	eta 0:03:47 lr 3.363185	time 1.1712 (3.3384)	loss 2.9792 (3.0178)	grad_norm 0.4192 (0.4218)	mem 39782MB
[2023-07-07 12:47:35 RepVGG-A0] (main.py 282): INFO Train: [145/300][20/78]	eta 0:02:22 lr 3.358894	time 1.1818 (2.4507)	loss 3.0738 (3.0365)	grad_norm 0.4341 (0.4198)	mem 39782MB
[2023-07-07 12:47:50 RepVGG-A0] (main.py 282): INFO Train: [145/300][30/78]	eta 0:01:42 lr 3.354603	time 1.4114 (2.1375)	loss 3.0086 (3.0315)	grad_norm 0.3616 (0.4094)	mem 39782MB
[2023-07-07 12:48:08 RepVGG-A0] (main.py 282): INFO Train: [145/300][40/78]	eta 0:01:18 lr 3.350311	time 4.0425 (2.0745)	loss 2.9025 (3.0243)	grad_norm 0.3599 (0.4018)	mem 39782MB
[2023-07-07 12:48:23 RepVGG-A0] (main.py 282): INFO Train: [145/300][50/78]	eta 0:00:54 lr 3.346020	time 1.1735 (1.9582)	loss 2.9741 (3.0316)	grad_norm 0.3457 (0.4026)	mem 39782MB
[2023-07-07 12:48:39 RepVGG-A0] (main.py 282): INFO Train: [145/300][60/78]	eta 0:00:34 lr 3.341728	time 1.4037 (1.8917)	loss 3.0978 (3.0295)	grad_norm 0.4584 (0.3997)	mem 39782MB
[2023-07-07 12:48:54 RepVGG-A0] (main.py 282): INFO Train: [145/300][70/78]	eta 0:00:14 lr 3.337436	time 1.4232 (1.8367)	loss 5.6483 (3.1131)	grad_norm 1.6408 (0.4593)	mem 39782MB
[2023-07-07 12:49:05 RepVGG-A0] (main.py 291): INFO EPOCH 145 training takes 0:02:21
[2023-07-07 12:49:27 RepVGG-A0] (main.py 282): INFO Train: [146/300][0/78]	eta 0:29:06 lr 3.334002	time 22.3967 (22.3967)	loss 5.7665 (5.7665)	grad_norm 0.4792 (0.4792)	mem 39782MB
[2023-07-07 12:49:41 RepVGG-A0] (main.py 282): INFO Train: [146/300][10/78]	eta 0:03:44 lr 3.329710	time 1.1729 (3.3029)	loss 4.7609 (5.2513)	grad_norm 0.3540 (0.4210)	mem 39782MB
[2023-07-07 12:49:56 RepVGG-A0] (main.py 282): INFO Train: [146/300][20/78]	eta 0:02:21 lr 3.325417	time 1.1748 (2.4435)	loss 4.2143 (4.9268)	grad_norm 0.3067 (0.4277)	mem 39782MB
[2023-07-07 12:50:11 RepVGG-A0] (main.py 282): INFO Train: [146/300][30/78]	eta 0:01:42 lr 3.321124	time 1.1526 (2.1384)	loss 4.0562 (4.6759)	grad_norm 0.3535 (0.3978)	mem 39782MB
[2023-07-07 12:50:28 RepVGG-A0] (main.py 282): INFO Train: [146/300][40/78]	eta 0:01:16 lr 3.316831	time 2.7509 (2.0224)	loss 3.7207 (4.4649)	grad_norm 0.3586 (0.3782)	mem 39782MB
[2023-07-07 12:50:44 RepVGG-A0] (main.py 282): INFO Train: [146/300][50/78]	eta 0:00:54 lr 3.312537	time 1.1759 (1.9434)	loss 3.6114 (4.3214)	grad_norm 0.3339 (0.3789)	mem 39782MB
[2023-07-07 12:50:59 RepVGG-A0] (main.py 282): INFO Train: [146/300][60/78]	eta 0:00:33 lr 3.308243	time 1.1947 (1.8680)	loss 3.5533 (4.1988)	grad_norm 0.3752 (0.3709)	mem 39782MB
[2023-07-07 12:51:14 RepVGG-A0] (main.py 282): INFO Train: [146/300][70/78]	eta 0:00:14 lr 3.303950	time 1.5012 (1.8193)	loss 3.5131 (4.1018)	grad_norm 0.4020 (0.3701)	mem 39782MB
[2023-07-07 12:51:26 RepVGG-A0] (main.py 291): INFO EPOCH 146 training takes 0:02:20
[2023-07-07 12:51:49 RepVGG-A0] (main.py 282): INFO Train: [147/300][0/78]	eta 0:29:45 lr 3.300514	time 22.8920 (22.8920)	loss 3.3671 (3.3671)	grad_norm 0.3848 (0.3848)	mem 39782MB
[2023-07-07 12:52:03 RepVGG-A0] (main.py 282): INFO Train: [147/300][10/78]	eta 0:03:49 lr 3.296220	time 1.1728 (3.3760)	loss 3.3342 (3.4077)	grad_norm 0.2838 (0.3664)	mem 39782MB
[2023-07-07 12:52:17 RepVGG-A0] (main.py 282): INFO Train: [147/300][20/78]	eta 0:02:22 lr 3.291926	time 1.1745 (2.4554)	loss 3.4900 (3.3737)	grad_norm 0.4730 (0.3555)	mem 39782MB
[2023-07-07 12:52:32 RepVGG-A0] (main.py 282): INFO Train: [147/300][30/78]	eta 0:01:43 lr 3.287631	time 1.5019 (2.1546)	loss 3.3816 (3.3689)	grad_norm 0.3753 (0.3671)	mem 39782MB
[2023-07-07 12:52:50 RepVGG-A0] (main.py 282): INFO Train: [147/300][40/78]	eta 0:01:18 lr 3.283337	time 3.4921 (2.0684)	loss 3.3098 (3.3533)	grad_norm 0.3578 (0.3627)	mem 39782MB
[2023-07-07 12:53:05 RepVGG-A0] (main.py 282): INFO Train: [147/300][50/78]	eta 0:00:54 lr 3.279042	time 1.1724 (1.9426)	loss 3.2364 (3.3405)	grad_norm 0.3598 (0.3630)	mem 39782MB
[2023-07-07 12:53:20 RepVGG-A0] (main.py 282): INFO Train: [147/300][60/78]	eta 0:00:33 lr 3.274747	time 1.3031 (1.8732)	loss 3.2093 (3.3296)	grad_norm 0.3440 (0.3625)	mem 39782MB
[2023-07-07 12:53:35 RepVGG-A0] (main.py 282): INFO Train: [147/300][70/78]	eta 0:00:14 lr 3.270452	time 1.1859 (1.8269)	loss 3.3577 (3.3262)	grad_norm 0.3847 (0.3696)	mem 39782MB
[2023-07-07 12:53:47 RepVGG-A0] (main.py 291): INFO EPOCH 147 training takes 0:02:21
[2023-07-07 12:54:10 RepVGG-A0] (main.py 282): INFO Train: [148/300][0/78]	eta 0:30:01 lr 3.267016	time 23.0904 (23.0904)	loss 3.2495 (3.2495)	grad_norm 0.3653 (0.3653)	mem 39782MB
[2023-07-07 12:54:24 RepVGG-A0] (main.py 282): INFO Train: [148/300][10/78]	eta 0:03:47 lr 3.262720	time 1.1721 (3.3456)	loss 3.1681 (3.2166)	grad_norm 0.3601 (0.3765)	mem 39782MB
[2023-07-07 12:54:37 RepVGG-A0] (main.py 282): INFO Train: [148/300][20/78]	eta 0:02:18 lr 3.258425	time 1.1731 (2.3891)	loss 3.2238 (3.2029)	grad_norm 0.4312 (0.3857)	mem 39782MB
[2023-07-07 12:54:53 RepVGG-A0] (main.py 282): INFO Train: [148/300][30/78]	eta 0:01:42 lr 3.254129	time 1.4511 (2.1319)	loss 3.1030 (3.1988)	grad_norm 0.3788 (0.3801)	mem 39782MB
[2023-07-07 12:55:11 RepVGG-A0] (main.py 282): INFO Train: [148/300][40/78]	eta 0:01:17 lr 3.249834	time 4.0085 (2.0518)	loss 3.2096 (3.2012)	grad_norm 0.3711 (0.3819)	mem 39782MB
[2023-07-07 12:55:26 RepVGG-A0] (main.py 282): INFO Train: [148/300][50/78]	eta 0:00:54 lr 3.245538	time 1.1736 (1.9438)	loss 3.2053 (3.1935)	grad_norm 0.4977 (0.3843)	mem 39782MB
[2023-07-07 12:55:40 RepVGG-A0] (main.py 282): INFO Train: [148/300][60/78]	eta 0:00:33 lr 3.241242	time 1.1760 (1.8616)	loss 3.1731 (3.2059)	grad_norm 0.3681 (0.3927)	mem 39782MB
[2023-07-07 12:55:55 RepVGG-A0] (main.py 282): INFO Train: [148/300][70/78]	eta 0:00:14 lr 3.236946	time 1.3290 (1.8129)	loss 3.1336 (3.2026)	grad_norm 0.3063 (0.3898)	mem 39782MB
[2023-07-07 12:56:07 RepVGG-A0] (main.py 291): INFO EPOCH 148 training takes 0:02:20
[2023-07-07 12:56:30 RepVGG-A0] (main.py 282): INFO Train: [149/300][0/78]	eta 0:29:11 lr 3.233510	time 22.4520 (22.4520)	loss 3.0972 (3.0972)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:56:45 RepVGG-A0] (main.py 282): INFO Train: [149/300][10/78]	eta 0:03:49 lr 3.229214	time 1.1708 (3.3746)	loss 3.1504 (3.1086)	grad_norm 0.4202 (0.3863)	mem 39782MB
[2023-07-07 12:57:00 RepVGG-A0] (main.py 282): INFO Train: [149/300][20/78]	eta 0:02:25 lr 3.224918	time 1.1768 (2.5170)	loss 3.1473 (3.1180)	grad_norm 0.3391 (0.3832)	mem 39782MB
[2023-07-07 12:57:16 RepVGG-A0] (main.py 282): INFO Train: [149/300][30/78]	eta 0:01:46 lr 3.220622	time 1.4934 (2.2177)	loss 3.1718 (3.1411)	grad_norm 0.3770 (0.3956)	mem 39782MB
[2023-07-07 12:57:33 RepVGG-A0] (main.py 282): INFO Train: [149/300][40/78]	eta 0:01:19 lr 3.216325	time 2.9388 (2.0979)	loss 3.1179 (3.1325)	grad_norm 0.4092 (0.3872)	mem 39782MB
[2023-07-07 12:57:49 RepVGG-A0] (main.py 282): INFO Train: [149/300][50/78]	eta 0:00:55 lr 3.212029	time 1.1723 (1.9851)	loss 3.1616 (3.1405)	grad_norm 0.4082 (0.3911)	mem 39782MB
[2023-07-07 12:58:04 RepVGG-A0] (main.py 282): INFO Train: [149/300][60/78]	eta 0:00:34 lr 3.207733	time 1.1858 (1.9073)	loss 3.0709 (3.1421)	grad_norm 0.3677 (0.3913)	mem 39782MB
[2023-07-07 12:58:19 RepVGG-A0] (main.py 282): INFO Train: [149/300][70/78]	eta 0:00:14 lr 3.203437	time 1.1738 (1.8536)	loss 3.2836 (3.1478)	grad_norm 0.5420 (0.3976)	mem 39782MB
[2023-07-07 12:58:30 RepVGG-A0] (main.py 291): INFO EPOCH 149 training takes 0:02:22
[2023-07-07 12:58:53 RepVGG-A0] (main.py 282): INFO Train: [150/300][0/78]	eta 0:28:40 lr 3.200000	time 22.0597 (22.0597)	loss 3.5018 (3.5018)	grad_norm 0.5789 (0.5789)	mem 39782MB
[2023-07-07 12:59:07 RepVGG-A0] (main.py 282): INFO Train: [150/300][10/78]	eta 0:03:43 lr 3.195704	time 1.1717 (3.2911)	loss 3.1036 (3.2359)	grad_norm 0.3354 (0.3925)	mem 39782MB
[2023-07-07 12:59:22 RepVGG-A0] (main.py 282): INFO Train: [150/300][20/78]	eta 0:02:21 lr 3.191408	time 1.1741 (2.4377)	loss 3.1007 (3.1793)	grad_norm 0.4256 (0.3746)	mem 39782MB
[2023-07-07 12:59:36 RepVGG-A0] (main.py 282): INFO Train: [150/300][30/78]	eta 0:01:41 lr 3.187111	time 1.2472 (2.1220)	loss 3.1311 (3.1558)	grad_norm 0.3508 (0.3665)	mem 39782MB
[2023-07-07 12:59:54 RepVGG-A0] (main.py 282): INFO Train: [150/300][40/78]	eta 0:01:17 lr 3.182815	time 3.6694 (2.0456)	loss 3.1492 (3.1414)	grad_norm 0.3752 (0.3712)	mem 39782MB
[2023-07-07 13:00:09 RepVGG-A0] (main.py 282): INFO Train: [150/300][50/78]	eta 0:00:54 lr 3.178519	time 1.1719 (1.9390)	loss 3.0454 (3.1294)	grad_norm 0.3473 (0.3678)	mem 39782MB
[2023-07-07 13:00:24 RepVGG-A0] (main.py 282): INFO Train: [150/300][60/78]	eta 0:00:33 lr 3.174223	time 1.1799 (1.8680)	loss 3.1152 (3.1193)	grad_norm 0.3779 (0.3675)	mem 39782MB
[2023-07-07 13:00:40 RepVGG-A0] (main.py 282): INFO Train: [150/300][70/78]	eta 0:00:14 lr 3.169927	time 1.2555 (1.8195)	loss 3.1451 (3.1185)	grad_norm 0.4487 (0.3727)	mem 39782MB
[2023-07-07 13:00:51 RepVGG-A0] (main.py 291): INFO EPOCH 150 training takes 0:02:20
[2023-07-07 13:01:12 RepVGG-A0] (main.py 282): INFO Train: [151/300][0/78]	eta 0:26:15 lr 3.166490	time 20.2027 (20.2027)	loss 3.0343 (3.0343)	grad_norm 0.3840 (0.3840)	mem 39782MB
[2023-07-07 13:01:28 RepVGG-A0] (main.py 282): INFO Train: [151/300][10/78]	eta 0:03:46 lr 3.162194	time 1.1702 (3.3297)	loss 3.1174 (3.0595)	grad_norm 0.3811 (0.3730)	mem 39782MB
[2023-07-07 13:01:42 RepVGG-A0] (main.py 282): INFO Train: [151/300][20/78]	eta 0:02:20 lr 3.157899	time 1.1282 (2.4288)	loss 3.0181 (3.0487)	grad_norm 0.3919 (0.3801)	mem 39782MB
[2023-07-07 13:01:57 RepVGG-A0] (main.py 282): INFO Train: [151/300][30/78]	eta 0:01:42 lr 3.153603	time 1.5017 (2.1272)	loss 3.0788 (3.0624)	grad_norm 0.3902 (0.3928)	mem 39782MB
[2023-07-07 13:02:14 RepVGG-A0] (main.py 282): INFO Train: [151/300][40/78]	eta 0:01:16 lr 3.149307	time 3.6465 (2.0206)	loss 3.1309 (3.0733)	grad_norm 0.4150 (0.3921)	mem 39782MB
[2023-07-07 13:02:29 RepVGG-A0] (main.py 282): INFO Train: [151/300][50/78]	eta 0:00:53 lr 3.145011	time 1.1722 (1.9147)	loss 3.0660 (3.0720)	grad_norm 0.4151 (0.3928)	mem 39782MB
[2023-07-07 13:02:45 RepVGG-A0] (main.py 282): INFO Train: [151/300][60/78]	eta 0:00:33 lr 3.140716	time 1.1788 (1.8565)	loss 3.0963 (3.0775)	grad_norm 0.3924 (0.3960)	mem 39782MB
[2023-07-07 13:02:59 RepVGG-A0] (main.py 282): INFO Train: [151/300][70/78]	eta 0:00:14 lr 3.136420	time 1.1815 (1.8008)	loss 3.0731 (3.0864)	grad_norm 0.3548 (0.4000)	mem 39782MB
[2023-07-07 13:03:11 RepVGG-A0] (main.py 291): INFO EPOCH 151 training takes 0:02:19
[2023-07-07 13:03:33 RepVGG-A0] (main.py 282): INFO Train: [152/300][0/78]	eta 0:28:19 lr 3.132984	time 21.7945 (21.7945)	loss 3.0628 (3.0628)	grad_norm 0.4497 (0.4497)	mem 39782MB
[2023-07-07 13:03:48 RepVGG-A0] (main.py 282): INFO Train: [152/300][10/78]	eta 0:03:44 lr 3.128689	time 1.1946 (3.3028)	loss 3.0712 (3.0487)	grad_norm 0.3745 (0.3943)	mem 39782MB
[2023-07-07 13:04:03 RepVGG-A0] (main.py 282): INFO Train: [152/300][20/78]	eta 0:02:22 lr 3.124394	time 1.1728 (2.4538)	loss 3.1095 (3.0434)	grad_norm 0.4298 (0.3839)	mem 39782MB
[2023-07-07 13:04:18 RepVGG-A0] (main.py 282): INFO Train: [152/300][30/78]	eta 0:01:43 lr 3.120099	time 1.3776 (2.1622)	loss 3.0304 (3.0643)	grad_norm 0.3830 (0.4053)	mem 39782MB
[2023-07-07 13:04:36 RepVGG-A0] (main.py 282): INFO Train: [152/300][40/78]	eta 0:01:18 lr 3.115804	time 3.7260 (2.0662)	loss 3.0186 (3.0634)	grad_norm 0.4093 (0.4006)	mem 39782MB
[2023-07-07 13:04:51 RepVGG-A0] (main.py 282): INFO Train: [152/300][50/78]	eta 0:00:54 lr 3.111510	time 1.1927 (1.9501)	loss 3.0122 (3.0581)	grad_norm 0.3895 (0.3977)	mem 39782MB
[2023-07-07 13:05:06 RepVGG-A0] (main.py 282): INFO Train: [152/300][60/78]	eta 0:00:33 lr 3.107215	time 1.1761 (1.8795)	loss 2.9823 (3.0564)	grad_norm 0.4042 (0.3981)	mem 39782MB
[2023-07-07 13:05:21 RepVGG-A0] (main.py 282): INFO Train: [152/300][70/78]	eta 0:00:14 lr 3.102921	time 1.1771 (1.8319)	loss 3.0363 (3.0570)	grad_norm 0.3651 (0.3966)	mem 39782MB
[2023-07-07 13:05:33 RepVGG-A0] (main.py 291): INFO EPOCH 152 training takes 0:02:21
[2023-07-07 13:05:56 RepVGG-A0] (main.py 282): INFO Train: [153/300][0/78]	eta 0:29:35 lr 3.099486	time 22.7596 (22.7596)	loss 2.9170 (2.9170)	grad_norm 0.3790 (0.3790)	mem 39782MB
[2023-07-07 13:06:10 RepVGG-A0] (main.py 282): INFO Train: [153/300][10/78]	eta 0:03:50 lr 3.095192	time 1.1724 (3.3848)	loss 3.0507 (3.0244)	grad_norm 0.4287 (0.4123)	mem 39782MB
[2023-07-07 13:06:25 RepVGG-A0] (main.py 282): INFO Train: [153/300][20/78]	eta 0:02:24 lr 3.090898	time 1.3315 (2.4873)	loss 3.0321 (3.0268)	grad_norm 0.4022 (0.4028)	mem 39782MB
[2023-07-07 13:06:40 RepVGG-A0] (main.py 282): INFO Train: [153/300][30/78]	eta 0:01:43 lr 3.086604	time 1.2422 (2.1589)	loss 3.0558 (3.0400)	grad_norm 0.3835 (0.4120)	mem 39782MB
[2023-07-07 13:06:59 RepVGG-A0] (main.py 282): INFO Train: [153/300][40/78]	eta 0:01:19 lr 3.082311	time 3.0869 (2.0813)	loss 3.0465 (3.0353)	grad_norm 0.3912 (0.4003)	mem 39782MB
[2023-07-07 13:07:13 RepVGG-A0] (main.py 282): INFO Train: [153/300][50/78]	eta 0:00:55 lr 3.078018	time 1.1913 (1.9644)	loss 3.1406 (3.0391)	grad_norm 0.4246 (0.4045)	mem 39782MB
[2023-07-07 13:07:29 RepVGG-A0] (main.py 282): INFO Train: [153/300][60/78]	eta 0:00:34 lr 3.073725	time 1.4265 (1.8947)	loss 3.0615 (3.0433)	grad_norm 0.4018 (0.4046)	mem 39782MB
[2023-07-07 13:07:45 RepVGG-A0] (main.py 282): INFO Train: [153/300][70/78]	eta 0:00:14 lr 3.069432	time 1.1723 (1.8514)	loss 3.0118 (3.0379)	grad_norm 0.3880 (0.4005)	mem 39782MB
[2023-07-07 13:07:55 RepVGG-A0] (main.py 291): INFO EPOCH 153 training takes 0:02:22
[2023-07-07 13:08:18 RepVGG-A0] (main.py 282): INFO Train: [154/300][0/78]	eta 0:29:04 lr 3.065998	time 22.3619 (22.3619)	loss 3.0118 (3.0118)	grad_norm 0.4179 (0.4179)	mem 39782MB
[2023-07-07 13:08:32 RepVGG-A0] (main.py 282): INFO Train: [154/300][10/78]	eta 0:03:48 lr 3.061706	time 1.1968 (3.3650)	loss 2.9706 (2.9748)	grad_norm 0.3944 (0.4052)	mem 39782MB
[2023-07-07 13:08:47 RepVGG-A0] (main.py 282): INFO Train: [154/300][20/78]	eta 0:02:23 lr 3.057414	time 1.1847 (2.4737)	loss 3.0143 (2.9829)	grad_norm 0.3801 (0.4055)	mem 39782MB
[2023-07-07 13:09:03 RepVGG-A0] (main.py 282): INFO Train: [154/300][30/78]	eta 0:01:44 lr 3.053122	time 1.5896 (2.1775)	loss 3.0734 (2.9931)	grad_norm 0.4335 (0.4096)	mem 39782MB
[2023-07-07 13:09:21 RepVGG-A0] (main.py 282): INFO Train: [154/300][40/78]	eta 0:01:18 lr 3.048830	time 2.5218 (2.0773)	loss 3.0232 (3.0058)	grad_norm 0.3554 (0.4097)	mem 39782MB
[2023-07-07 13:09:36 RepVGG-A0] (main.py 282): INFO Train: [154/300][50/78]	eta 0:00:55 lr 3.044539	time 1.5869 (1.9674)	loss 3.0569 (3.0121)	grad_norm 0.3664 (0.4070)	mem 39782MB
[2023-07-07 13:09:51 RepVGG-A0] (main.py 282): INFO Train: [154/300][60/78]	eta 0:00:34 lr 3.040248	time 1.2483 (1.8901)	loss 3.1205 (3.0189)	grad_norm 0.4155 (0.4075)	mem 39782MB
[2023-07-07 13:10:06 RepVGG-A0] (main.py 282): INFO Train: [154/300][70/78]	eta 0:00:14 lr 3.035957	time 1.3601 (1.8410)	loss 3.0393 (3.0192)	grad_norm 0.4036 (0.4070)	mem 39782MB
[2023-07-07 13:10:18 RepVGG-A0] (main.py 291): INFO EPOCH 154 training takes 0:02:22
[2023-07-07 13:10:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][0/78]	eta 0:28:06 lr 3.032525	time 21.6273 (21.6273)	loss 2.8880 (2.8880)	grad_norm 0.3518 (0.3518)	mem 39782MB
[2023-07-07 13:10:54 RepVGG-A0] (main.py 282): INFO Train: [155/300][10/78]	eta 0:03:45 lr 3.028235	time 1.1730 (3.3142)	loss 3.7754 (3.1576)	grad_norm 1.1281 (0.5835)	mem 39782MB
[2023-07-07 13:11:08 RepVGG-A0] (main.py 282): INFO Train: [155/300][20/78]	eta 0:02:17 lr 3.023945	time 1.1717 (2.3705)	loss 5.6369 (4.3484)	grad_norm 0.5419 (0.8188)	mem 39782MB
[2023-07-07 13:11:22 RepVGG-A0] (main.py 282): INFO Train: [155/300][30/78]	eta 0:01:39 lr 3.019655	time 1.2684 (2.0735)	loss 4.4875 (4.5436)	grad_norm 0.3827 (0.6999)	mem 39782MB
[2023-07-07 13:11:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][40/78]	eta 0:01:15 lr 3.015366	time 3.0114 (1.9974)	loss 4.0263 (4.4679)	grad_norm 0.3370 (0.6117)	mem 39782MB
[2023-07-07 13:11:56 RepVGG-A0] (main.py 282): INFO Train: [155/300][50/78]	eta 0:00:53 lr 3.011077	time 1.1773 (1.9159)	loss 3.9136 (4.3595)	grad_norm 0.4179 (0.5589)	mem 39782MB
[2023-07-07 13:12:11 RepVGG-A0] (main.py 282): INFO Train: [155/300][60/78]	eta 0:00:33 lr 3.006789	time 1.1798 (1.8464)	loss 3.6138 (4.2518)	grad_norm 0.2972 (0.5206)	mem 39782MB
[2023-07-07 13:12:26 RepVGG-A0] (main.py 282): INFO Train: [155/300][70/78]	eta 0:00:14 lr 3.002501	time 1.3029 (1.8069)	loss 3.4977 (4.1560)	grad_norm 0.3013 (0.4941)	mem 39782MB
[2023-07-07 13:12:38 RepVGG-A0] (main.py 291): INFO EPOCH 155 training takes 0:02:19
[2023-07-07 13:12:59 RepVGG-A0] (main.py 282): INFO Train: [156/300][0/78]	eta 0:27:22 lr 2.999070	time 21.0550 (21.0550)	loss 3.4227 (3.4227)	grad_norm 0.3452 (0.3452)	mem 39782MB
[2023-07-07 13:13:16 RepVGG-A0] (main.py 282): INFO Train: [156/300][10/78]	eta 0:03:54 lr 2.994783	time 1.3600 (3.4455)	loss 3.3542 (3.3851)	grad_norm 0.3327 (0.3296)	mem 39782MB
[2023-07-07 13:13:30 RepVGG-A0] (main.py 282): INFO Train: [156/300][20/78]	eta 0:02:24 lr 2.990496	time 1.3583 (2.4915)	loss 3.3024 (3.3668)	grad_norm 0.3448 (0.3362)	mem 39782MB
[2023-07-07 13:13:46 RepVGG-A0] (main.py 282): INFO Train: [156/300][30/78]	eta 0:01:44 lr 2.986209	time 1.4891 (2.1825)	loss 3.2590 (3.3529)	grad_norm 0.3727 (0.3414)	mem 39782MB
[2023-07-07 13:14:03 RepVGG-A0] (main.py 282): INFO Train: [156/300][40/78]	eta 0:01:18 lr 2.981922	time 3.3020 (2.0734)	loss 3.2732 (3.3414)	grad_norm 0.3332 (0.3497)	mem 39782MB
[2023-07-07 13:14:18 RepVGG-A0] (main.py 282): INFO Train: [156/300][50/78]	eta 0:00:55 lr 2.977636	time 1.1778 (1.9715)	loss 3.2100 (3.3198)	grad_norm 0.3488 (0.3481)	mem 39782MB
[2023-07-07 13:14:34 RepVGG-A0] (main.py 282): INFO Train: [156/300][60/78]	eta 0:00:34 lr 2.973351	time 1.1971 (1.9111)	loss 3.3390 (3.3101)	grad_norm 0.3679 (0.3528)	mem 39782MB
[2023-07-07 13:14:49 RepVGG-A0] (main.py 282): INFO Train: [156/300][70/78]	eta 0:00:14 lr 2.969066	time 1.3974 (1.8542)	loss 3.2005 (3.2941)	grad_norm 0.3609 (0.3550)	mem 39782MB
[2023-07-07 13:15:01 RepVGG-A0] (main.py 291): INFO EPOCH 156 training takes 0:02:23
[2023-07-07 13:15:23 RepVGG-A0] (main.py 282): INFO Train: [157/300][0/78]	eta 0:28:56 lr 2.965638	time 22.2661 (22.2661)	loss 3.1155 (3.1155)	grad_norm 0.3462 (0.3462)	mem 39782MB
[2023-07-07 13:15:38 RepVGG-A0] (main.py 282): INFO Train: [157/300][10/78]	eta 0:03:49 lr 2.961353	time 1.1726 (3.3731)	loss 3.1254 (3.1260)	grad_norm 0.3874 (0.3658)	mem 39782MB
[2023-07-07 13:15:52 RepVGG-A0] (main.py 282): INFO Train: [157/300][20/78]	eta 0:02:20 lr 2.957069	time 1.3722 (2.4149)	loss 3.1501 (3.1481)	grad_norm 0.3753 (0.3879)	mem 39782MB
[2023-07-07 13:16:08 RepVGG-A0] (main.py 282): INFO Train: [157/300][30/78]	eta 0:01:44 lr 2.952786	time 1.3036 (2.1687)	loss 3.1196 (3.1470)	grad_norm 0.3456 (0.3768)	mem 39782MB
[2023-07-07 13:16:26 RepVGG-A0] (main.py 282): INFO Train: [157/300][40/78]	eta 0:01:18 lr 2.948503	time 4.8368 (2.0733)	loss 3.1496 (3.1467)	grad_norm 0.3783 (0.3821)	mem 39782MB
[2023-07-07 13:16:41 RepVGG-A0] (main.py 282): INFO Train: [157/300][50/78]	eta 0:00:54 lr 2.944220	time 1.1772 (1.9636)	loss 3.1409 (3.1410)	grad_norm 0.4047 (0.3796)	mem 39782MB
[2023-07-07 13:16:57 RepVGG-A0] (main.py 282): INFO Train: [157/300][60/78]	eta 0:00:34 lr 2.939938	time 1.1763 (1.8918)	loss 3.1579 (3.1374)	grad_norm 0.4442 (0.3806)	mem 39782MB
[2023-07-07 13:17:10 RepVGG-A0] (main.py 282): INFO Train: [157/300][70/78]	eta 0:00:14 lr 2.935656	time 1.5309 (1.8198)	loss 3.0932 (3.1436)	grad_norm 0.3872 (0.3874)	mem 39782MB
[2023-07-07 13:17:23 RepVGG-A0] (main.py 291): INFO EPOCH 157 training takes 0:02:21
[2023-07-07 13:17:45 RepVGG-A0] (main.py 282): INFO Train: [158/300][0/78]	eta 0:28:49 lr 2.932231	time 22.1691 (22.1691)	loss 2.9990 (2.9990)	grad_norm 0.3878 (0.3878)	mem 39782MB
[2023-07-07 13:17:59 RepVGG-A0] (main.py 282): INFO Train: [158/300][10/78]	eta 0:03:46 lr 2.927950	time 1.1720 (3.3284)	loss 2.9804 (3.0261)	grad_norm 0.3798 (0.3710)	mem 39782MB
[2023-07-07 13:18:13 RepVGG-A0] (main.py 282): INFO Train: [158/300][20/78]	eta 0:02:19 lr 2.923670	time 1.1747 (2.4101)	loss 3.0389 (3.0432)	grad_norm 0.3635 (0.3752)	mem 39782MB
[2023-07-07 13:18:29 RepVGG-A0] (main.py 282): INFO Train: [158/300][30/78]	eta 0:01:42 lr 2.919390	time 1.1551 (2.1430)	loss 3.0076 (3.0507)	grad_norm 0.3642 (0.3777)	mem 39782MB
[2023-07-07 13:18:48 RepVGG-A0] (main.py 282): INFO Train: [158/300][40/78]	eta 0:01:19 lr 2.915110	time 4.4639 (2.0839)	loss 3.0841 (3.0583)	grad_norm 0.4779 (0.3854)	mem 39782MB
[2023-07-07 13:19:03 RepVGG-A0] (main.py 282): INFO Train: [158/300][50/78]	eta 0:00:55 lr 2.910831	time 1.1720 (1.9650)	loss 3.1124 (3.0739)	grad_norm 0.4053 (0.3954)	mem 39782MB
[2023-07-07 13:19:18 RepVGG-A0] (main.py 282): INFO Train: [158/300][60/78]	eta 0:00:33 lr 2.906553	time 1.1773 (1.8884)	loss 3.0980 (3.0793)	grad_norm 0.4078 (0.3960)	mem 39782MB
[2023-07-07 13:19:33 RepVGG-A0] (main.py 282): INFO Train: [158/300][70/78]	eta 0:00:14 lr 2.902275	time 1.2605 (1.8280)	loss 3.1144 (3.0821)	grad_norm 0.4382 (0.3976)	mem 39782MB
[2023-07-07 13:19:44 RepVGG-A0] (main.py 291): INFO EPOCH 158 training takes 0:02:21
[2023-07-07 13:20:07 RepVGG-A0] (main.py 282): INFO Train: [159/300][0/78]	eta 0:29:53 lr 2.898853	time 22.9895 (22.9895)	loss 3.0410 (3.0410)	grad_norm 0.3711 (0.3711)	mem 39782MB
[2023-07-07 13:20:21 RepVGG-A0] (main.py 282): INFO Train: [159/300][10/78]	eta 0:03:48 lr 2.894577	time 1.1713 (3.3594)	loss 3.0032 (3.0254)	grad_norm 0.3875 (0.3844)	mem 39782MB
[2023-07-07 13:20:35 RepVGG-A0] (main.py 282): INFO Train: [159/300][20/78]	eta 0:02:20 lr 2.890300	time 1.1981 (2.4300)	loss 3.2306 (3.0655)	grad_norm 0.5703 (0.4232)	mem 39782MB
[2023-07-07 13:20:49 RepVGG-A0] (main.py 282): INFO Train: [159/300][30/78]	eta 0:01:41 lr 2.886024	time 1.2388 (2.1124)	loss 3.0189 (3.0760)	grad_norm 0.3473 (0.4154)	mem 39782MB
[2023-07-07 13:21:08 RepVGG-A0] (main.py 282): INFO Train: [159/300][40/78]	eta 0:01:17 lr 2.881749	time 3.7008 (2.0447)	loss 3.1219 (3.0700)	grad_norm 0.4536 (0.4129)	mem 39782MB
[2023-07-07 13:21:23 RepVGG-A0] (main.py 282): INFO Train: [159/300][50/78]	eta 0:00:54 lr 2.877475	time 1.1726 (1.9438)	loss 2.9820 (3.0684)	grad_norm 0.3559 (0.4114)	mem 39782MB
[2023-07-07 13:21:39 RepVGG-A0] (main.py 282): INFO Train: [159/300][60/78]	eta 0:00:34 lr 2.873201	time 1.3114 (1.8901)	loss 2.9825 (3.0617)	grad_norm 0.3696 (0.4046)	mem 39782MB
[2023-07-07 13:21:54 RepVGG-A0] (main.py 282): INFO Train: [159/300][70/78]	eta 0:00:14 lr 2.868927	time 1.1863 (1.8334)	loss 3.0083 (3.0557)	grad_norm 0.3634 (0.4023)	mem 39782MB
[2023-07-07 13:22:06 RepVGG-A0] (main.py 291): INFO EPOCH 159 training takes 0:02:21
[2023-07-07 13:22:28 RepVGG-A0] (main.py 282): INFO Train: [160/300][0/78]	eta 0:29:23 lr 2.865509	time 22.6109 (22.6109)	loss 2.9146 (2.9146)	grad_norm 0.3670 (0.3670)	mem 39782MB
[2023-07-07 13:22:43 RepVGG-A0] (main.py 282): INFO Train: [160/300][10/78]	eta 0:03:50 lr 2.861237	time 1.1718 (3.3914)	loss 3.1240 (3.0544)	grad_norm 0.4970 (0.4653)	mem 39782MB
[2023-07-07 13:22:58 RepVGG-A0] (main.py 282): INFO Train: [160/300][20/78]	eta 0:02:24 lr 2.856965	time 1.1695 (2.4904)	loss 3.0268 (3.0357)	grad_norm 0.3629 (0.4239)	mem 39782MB
[2023-07-07 13:23:14 RepVGG-A0] (main.py 282): INFO Train: [160/300][30/78]	eta 0:01:45 lr 2.852694	time 1.3688 (2.1981)	loss 2.9566 (3.0204)	grad_norm 0.4084 (0.4091)	mem 39782MB
[2023-07-07 13:23:31 RepVGG-A0] (main.py 282): INFO Train: [160/300][40/78]	eta 0:01:18 lr 2.848423	time 3.1552 (2.0787)	loss 3.0406 (3.0183)	grad_norm 0.3805 (0.4102)	mem 39782MB
[2023-07-07 13:23:47 RepVGG-A0] (main.py 282): INFO Train: [160/300][50/78]	eta 0:00:55 lr 2.844153	time 1.1777 (1.9765)	loss 3.0785 (3.0214)	grad_norm 0.3968 (0.4078)	mem 39782MB
[2023-07-07 13:24:01 RepVGG-A0] (main.py 282): INFO Train: [160/300][60/78]	eta 0:00:33 lr 2.839884	time 1.1264 (1.8854)	loss 3.1012 (3.0280)	grad_norm 0.3754 (0.4087)	mem 39782MB
[2023-07-07 13:24:17 RepVGG-A0] (main.py 282): INFO Train: [160/300][70/78]	eta 0:00:14 lr 2.835616	time 1.4092 (1.8456)	loss 3.1261 (3.0426)	grad_norm 0.3880 (0.4187)	mem 39782MB
[2023-07-07 13:24:29 RepVGG-A0] (main.py 291): INFO EPOCH 160 training takes 0:02:22
[2023-07-07 13:24:47 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 18.187 (18.187)	Loss 2.4704 (2.4704)	Acc@1 47.650 (47.650)	Acc@5 72.766 (72.766)	Mem 39782MB
[2023-07-07 13:24:48 RepVGG-A0] (main.py 342): INFO  * Acc@1 48.562 Acc@5 72.958
[2023-07-07 13:24:48 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 160: 48.562%
[2023-07-07 13:24:48 RepVGG-A0] (main.py 172): INFO Max accuracy: 48.56%
[2023-07-07 13:25:09 RepVGG-A0] (main.py 282): INFO Train: [161/300][0/78]	eta 0:27:20 lr 2.832201	time 21.0333 (21.0333)	loss 2.9782 (2.9782)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 13:25:26 RepVGG-A0] (main.py 282): INFO Train: [161/300][10/78]	eta 0:03:52 lr 2.827934	time 1.1730 (3.4229)	loss 3.0168 (2.9997)	grad_norm 0.4074 (0.3967)	mem 39782MB
[2023-07-07 13:25:40 RepVGG-A0] (main.py 282): INFO Train: [161/300][20/78]	eta 0:02:24 lr 2.823667	time 1.3231 (2.4948)	loss 2.9970 (2.9999)	grad_norm 0.4197 (0.4031)	mem 39782MB
[2023-07-07 13:25:55 RepVGG-A0] (main.py 282): INFO Train: [161/300][30/78]	eta 0:01:44 lr 2.819401	time 1.4183 (2.1713)	loss 2.9835 (2.9898)	grad_norm 0.3911 (0.3961)	mem 39782MB
[2023-07-07 13:26:13 RepVGG-A0] (main.py 282): INFO Train: [161/300][40/78]	eta 0:01:18 lr 2.815136	time 3.6980 (2.0598)	loss 2.9756 (2.9904)	grad_norm 0.4257 (0.3975)	mem 39782MB
[2023-07-07 13:26:28 RepVGG-A0] (main.py 282): INFO Train: [161/300][50/78]	eta 0:00:54 lr 2.810871	time 1.2957 (1.9531)	loss 3.0241 (2.9975)	grad_norm 0.4067 (0.4060)	mem 39782MB
[2023-07-07 13:26:43 RepVGG-A0] (main.py 282): INFO Train: [161/300][60/78]	eta 0:00:33 lr 2.806607	time 1.1742 (1.8773)	loss 3.0447 (2.9986)	grad_norm 0.4276 (0.4064)	mem 39782MB
[2023-07-07 13:26:58 RepVGG-A0] (main.py 282): INFO Train: [161/300][70/78]	eta 0:00:14 lr 2.802344	time 1.2434 (1.8305)	loss 3.0561 (3.0039)	grad_norm 0.3827 (0.4061)	mem 39782MB
[2023-07-07 13:27:09 RepVGG-A0] (main.py 291): INFO EPOCH 161 training takes 0:02:21
[2023-07-07 13:27:29 RepVGG-A0] (main.py 282): INFO Train: [162/300][0/78]	eta 0:26:08 lr 2.798934	time 20.1064 (20.1064)	loss 3.0796 (3.0796)	grad_norm 0.4832 (0.4832)	mem 39782MB
[2023-07-07 13:27:45 RepVGG-A0] (main.py 282): INFO Train: [162/300][10/78]	eta 0:03:38 lr 2.794672	time 1.1711 (3.2160)	loss 3.0647 (2.9937)	grad_norm 0.4627 (0.4106)	mem 39782MB
[2023-07-07 13:28:00 RepVGG-A0] (main.py 282): INFO Train: [162/300][20/78]	eta 0:02:20 lr 2.790410	time 1.1397 (2.4270)	loss 3.0233 (2.9905)	grad_norm 0.4551 (0.4074)	mem 39782MB
[2023-07-07 13:28:14 RepVGG-A0] (main.py 282): INFO Train: [162/300][30/78]	eta 0:01:40 lr 2.786150	time 1.1998 (2.0964)	loss 2.9801 (2.9950)	grad_norm 0.3686 (0.4090)	mem 39782MB
[2023-07-07 13:28:33 RepVGG-A0] (main.py 282): INFO Train: [162/300][40/78]	eta 0:01:17 lr 2.781890	time 3.7884 (2.0346)	loss 3.0707 (2.9892)	grad_norm 0.5544 (0.4113)	mem 39782MB
[2023-07-07 13:28:48 RepVGG-A0] (main.py 282): INFO Train: [162/300][50/78]	eta 0:00:54 lr 2.777631	time 1.1730 (1.9360)	loss 6.3488 (3.2388)	grad_norm 1.1968 (0.5421)	mem 39782MB
[2023-07-07 13:29:04 RepVGG-A0] (main.py 282): INFO Train: [162/300][60/78]	eta 0:00:33 lr 2.773373	time 1.4953 (1.8749)	loss 5.0004 (3.5983)	grad_norm 0.6170 (0.5680)	mem 39782MB
[2023-07-07 13:29:19 RepVGG-A0] (main.py 282): INFO Train: [162/300][70/78]	eta 0:00:14 lr 2.769116	time 1.4128 (1.8262)	loss 4.1192 (3.7095)	grad_norm 0.4402 (0.5401)	mem 39782MB
[2023-07-07 13:29:31 RepVGG-A0] (main.py 291): INFO EPOCH 162 training takes 0:02:21
[2023-07-07 13:29:53 RepVGG-A0] (main.py 282): INFO Train: [163/300][0/78]	eta 0:29:06 lr 2.765710	time 22.3903 (22.3903)	loss 3.7692 (3.7692)	grad_norm 0.3159 (0.3159)	mem 39782MB
[2023-07-07 13:30:07 RepVGG-A0] (main.py 282): INFO Train: [163/300][10/78]	eta 0:03:41 lr 2.761454	time 1.1932 (3.2553)	loss 3.6377 (3.6882)	grad_norm 0.3559 (0.3428)	mem 39782MB
[2023-07-07 13:30:21 RepVGG-A0] (main.py 282): INFO Train: [163/300][20/78]	eta 0:02:17 lr 2.757199	time 1.1724 (2.3709)	loss 3.4817 (3.6065)	grad_norm 0.3433 (0.3434)	mem 39782MB
[2023-07-07 13:30:36 RepVGG-A0] (main.py 282): INFO Train: [163/300][30/78]	eta 0:01:40 lr 2.752944	time 1.1839 (2.0968)	loss 3.3519 (3.5428)	grad_norm 0.3365 (0.3408)	mem 39782MB
[2023-07-07 13:30:54 RepVGG-A0] (main.py 282): INFO Train: [163/300][40/78]	eta 0:01:16 lr 2.748691	time 3.5729 (2.0163)	loss 3.3447 (3.4991)	grad_norm 0.3382 (0.3436)	mem 39782MB
[2023-07-07 13:31:09 RepVGG-A0] (main.py 282): INFO Train: [163/300][50/78]	eta 0:00:53 lr 2.744438	time 1.1717 (1.9279)	loss 3.1837 (3.4627)	grad_norm 0.3159 (0.3447)	mem 39782MB
[2023-07-07 13:31:24 RepVGG-A0] (main.py 282): INFO Train: [163/300][60/78]	eta 0:00:33 lr 2.740186	time 1.3227 (1.8569)	loss 3.3318 (3.4299)	grad_norm 0.4374 (0.3462)	mem 39782MB
[2023-07-07 13:31:40 RepVGG-A0] (main.py 282): INFO Train: [163/300][70/78]	eta 0:00:14 lr 2.735935	time 1.4670 (1.8110)	loss 3.2141 (3.4025)	grad_norm 0.4030 (0.3485)	mem 39782MB
[2023-07-07 13:31:51 RepVGG-A0] (main.py 291): INFO EPOCH 163 training takes 0:02:20
[2023-07-07 13:32:12 RepVGG-A0] (main.py 282): INFO Train: [164/300][0/78]	eta 0:27:05 lr 2.732534	time 20.8348 (20.8348)	loss 3.1464 (3.1464)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 13:32:28 RepVGG-A0] (main.py 282): INFO Train: [164/300][10/78]	eta 0:03:44 lr 2.728285	time 1.1899 (3.3045)	loss 3.1124 (3.1159)	grad_norm 0.3385 (0.3550)	mem 39782MB
[2023-07-07 13:32:43 RepVGG-A0] (main.py 282): INFO Train: [164/300][20/78]	eta 0:02:22 lr 2.724036	time 1.1985 (2.4530)	loss 3.1970 (3.1257)	grad_norm 0.4180 (0.3588)	mem 39782MB
[2023-07-07 13:32:58 RepVGG-A0] (main.py 282): INFO Train: [164/300][30/78]	eta 0:01:43 lr 2.719788	time 1.1771 (2.1568)	loss 3.1484 (3.1317)	grad_norm 0.3496 (0.3657)	mem 39782MB
[2023-07-07 13:33:15 RepVGG-A0] (main.py 282): INFO Train: [164/300][40/78]	eta 0:01:17 lr 2.715541	time 2.7657 (2.0427)	loss 3.1270 (3.1303)	grad_norm 0.3559 (0.3653)	mem 39782MB
[2023-07-07 13:33:30 RepVGG-A0] (main.py 282): INFO Train: [164/300][50/78]	eta 0:00:53 lr 2.711294	time 1.1729 (1.9269)	loss 3.0987 (3.1302)	grad_norm 0.3679 (0.3675)	mem 39782MB
[2023-07-07 13:33:45 RepVGG-A0] (main.py 282): INFO Train: [164/300][60/78]	eta 0:00:33 lr 2.707049	time 1.2707 (1.8682)	loss 3.1022 (3.1309)	grad_norm 0.3913 (0.3753)	mem 39782MB
[2023-07-07 13:34:01 RepVGG-A0] (main.py 282): INFO Train: [164/300][70/78]	eta 0:00:14 lr 2.702805	time 1.1817 (1.8205)	loss 3.0607 (3.1247)	grad_norm 0.3562 (0.3726)	mem 39782MB
[2023-07-07 13:34:13 RepVGG-A0] (main.py 291): INFO EPOCH 164 training takes 0:02:21
[2023-07-07 13:34:34 RepVGG-A0] (main.py 282): INFO Train: [165/300][0/78]	eta 0:27:17 lr 2.699410	time 20.9875 (20.9875)	loss 3.0395 (3.0395)	grad_norm 0.4425 (0.4425)	mem 39782MB
[2023-07-07 13:34:48 RepVGG-A0] (main.py 282): INFO Train: [165/300][10/78]	eta 0:03:38 lr 2.695167	time 1.1725 (3.2140)	loss 2.9827 (3.0351)	grad_norm 0.3568 (0.3907)	mem 39782MB
[2023-07-07 13:35:02 RepVGG-A0] (main.py 282): INFO Train: [165/300][20/78]	eta 0:02:16 lr 2.690925	time 1.1735 (2.3594)	loss 3.1270 (3.0470)	grad_norm 0.4137 (0.3881)	mem 39782MB
[2023-07-07 13:35:18 RepVGG-A0] (main.py 282): INFO Train: [165/300][30/78]	eta 0:01:40 lr 2.686684	time 1.2066 (2.0996)	loss 2.9866 (3.0350)	grad_norm 0.3612 (0.3808)	mem 39782MB
[2023-07-07 13:35:37 RepVGG-A0] (main.py 282): INFO Train: [165/300][40/78]	eta 0:01:17 lr 2.682444	time 4.3174 (2.0472)	loss 3.2248 (3.0511)	grad_norm 0.5732 (0.3978)	mem 39782MB
[2023-07-07 13:35:51 RepVGG-A0] (main.py 282): INFO Train: [165/300][50/78]	eta 0:00:54 lr 2.678205	time 1.1976 (1.9295)	loss 3.0161 (3.0663)	grad_norm 0.3507 (0.4036)	mem 39782MB
[2023-07-07 13:36:06 RepVGG-A0] (main.py 282): INFO Train: [165/300][60/78]	eta 0:00:33 lr 2.673966	time 1.1264 (1.8653)	loss 3.0223 (3.0638)	grad_norm 0.3515 (0.3972)	mem 39782MB
[2023-07-07 13:36:22 RepVGG-A0] (main.py 282): INFO Train: [165/300][70/78]	eta 0:00:14 lr 2.669729	time 1.3333 (1.8193)	loss 3.0757 (3.0626)	grad_norm 0.3679 (0.3942)	mem 39782MB
[2023-07-07 13:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 165 training takes 0:02:21
[2023-07-07 13:36:55 RepVGG-A0] (main.py 282): INFO Train: [166/300][0/78]	eta 0:27:26 lr 2.666340	time 21.1099 (21.1099)	loss 2.9496 (2.9496)	grad_norm 0.3898 (0.3898)	mem 39782MB
[2023-07-07 13:37:11 RepVGG-A0] (main.py 282): INFO Train: [166/300][10/78]	eta 0:03:50 lr 2.662104	time 1.1933 (3.3843)	loss 2.9915 (3.0202)	grad_norm 0.3915 (0.4194)	mem 39782MB
[2023-07-07 13:37:26 RepVGG-A0] (main.py 282): INFO Train: [166/300][20/78]	eta 0:02:24 lr 2.657870	time 1.1745 (2.4836)	loss 2.9967 (3.0188)	grad_norm 0.4045 (0.4189)	mem 39782MB
[2023-07-07 13:37:41 RepVGG-A0] (main.py 282): INFO Train: [166/300][30/78]	eta 0:01:44 lr 2.653636	time 1.3348 (2.1725)	loss 3.0360 (3.0109)	grad_norm 0.4185 (0.4064)	mem 39782MB
[2023-07-07 13:37:59 RepVGG-A0] (main.py 282): INFO Train: [166/300][40/78]	eta 0:01:19 lr 2.649404	time 3.7557 (2.0828)	loss 2.9958 (3.0084)	grad_norm 0.3645 (0.4017)	mem 39782MB
[2023-07-07 13:38:14 RepVGG-A0] (main.py 282): INFO Train: [166/300][50/78]	eta 0:00:55 lr 2.645172	time 1.1960 (1.9716)	loss 3.0279 (3.0107)	grad_norm 0.3789 (0.4005)	mem 39782MB
[2023-07-07 13:38:30 RepVGG-A0] (main.py 282): INFO Train: [166/300][60/78]	eta 0:00:34 lr 2.640941	time 1.1263 (1.8992)	loss 3.0249 (3.0148)	grad_norm 0.4208 (0.4027)	mem 39782MB
[2023-07-07 13:38:45 RepVGG-A0] (main.py 282): INFO Train: [166/300][70/78]	eta 0:00:14 lr 2.636712	time 1.4646 (1.8459)	loss 2.9983 (3.0168)	grad_norm 0.4131 (0.4046)	mem 39782MB
[2023-07-07 13:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 166 training takes 0:02:21
[2023-07-07 13:39:17 RepVGG-A0] (main.py 282): INFO Train: [167/300][0/78]	eta 0:28:40 lr 2.633329	time 22.0565 (22.0565)	loss 3.0948 (3.0948)	grad_norm 0.4661 (0.4661)	mem 39782MB
[2023-07-07 13:39:32 RepVGG-A0] (main.py 282): INFO Train: [167/300][10/78]	eta 0:03:49 lr 2.629101	time 1.1717 (3.3690)	loss 2.9418 (2.9697)	grad_norm 0.4084 (0.4003)	mem 39782MB
[2023-07-07 13:39:47 RepVGG-A0] (main.py 282): INFO Train: [167/300][20/78]	eta 0:02:23 lr 2.624874	time 1.1830 (2.4740)	loss 3.0455 (2.9745)	grad_norm 0.4423 (0.4032)	mem 39782MB
[2023-07-07 13:40:01 RepVGG-A0] (main.py 282): INFO Train: [167/300][30/78]	eta 0:01:42 lr 2.620649	time 1.1779 (2.1256)	loss 2.9763 (2.9768)	grad_norm 0.3657 (0.4048)	mem 39782MB
[2023-07-07 13:40:20 RepVGG-A0] (main.py 282): INFO Train: [167/300][40/78]	eta 0:01:18 lr 2.616424	time 2.3777 (2.0699)	loss 2.9526 (2.9705)	grad_norm 0.3943 (0.3999)	mem 39782MB
[2023-07-07 13:40:35 RepVGG-A0] (main.py 282): INFO Train: [167/300][50/78]	eta 0:00:54 lr 2.612200	time 1.1762 (1.9527)	loss 2.9247 (2.9733)	grad_norm 0.3784 (0.4076)	mem 39782MB
[2023-07-07 13:40:51 RepVGG-A0] (main.py 282): INFO Train: [167/300][60/78]	eta 0:00:33 lr 2.607978	time 1.3477 (1.8862)	loss 3.0493 (2.9772)	grad_norm 0.4593 (0.4087)	mem 39782MB
[2023-07-07 13:41:06 RepVGG-A0] (main.py 282): INFO Train: [167/300][70/78]	eta 0:00:14 lr 2.603756	time 1.6326 (1.8401)	loss 3.0761 (2.9860)	grad_norm 0.4433 (0.4107)	mem 39782MB
[2023-07-07 13:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 167 training takes 0:02:21
[2023-07-07 13:41:38 RepVGG-A0] (main.py 282): INFO Train: [168/300][0/78]	eta 0:28:00 lr 2.600380	time 21.5427 (21.5427)	loss 2.9296 (2.9296)	grad_norm 0.3901 (0.3901)	mem 39782MB
[2023-07-07 13:41:53 RepVGG-A0] (main.py 282): INFO Train: [168/300][10/78]	eta 0:03:44 lr 2.596160	time 1.1717 (3.3071)	loss 3.0054 (2.9232)	grad_norm 0.4271 (0.3940)	mem 39782MB
[2023-07-07 13:42:08 RepVGG-A0] (main.py 282): INFO Train: [168/300][20/78]	eta 0:02:22 lr 2.591942	time 1.1799 (2.4523)	loss 2.9868 (2.9570)	grad_norm 0.4163 (0.4163)	mem 39782MB
[2023-07-07 13:42:24 RepVGG-A0] (main.py 282): INFO Train: [168/300][30/78]	eta 0:01:43 lr 2.587724	time 1.4749 (2.1552)	loss 2.9568 (2.9573)	grad_norm 0.4310 (0.4117)	mem 39782MB
[2023-07-07 13:42:41 RepVGG-A0] (main.py 282): INFO Train: [168/300][40/78]	eta 0:01:17 lr 2.583508	time 3.1516 (2.0501)	loss 2.9191 (2.9574)	grad_norm 0.3683 (0.4127)	mem 39782MB
[2023-07-07 13:42:56 RepVGG-A0] (main.py 282): INFO Train: [168/300][50/78]	eta 0:00:54 lr 2.579293	time 1.1733 (1.9446)	loss 3.0117 (2.9599)	grad_norm 0.4635 (0.4107)	mem 39782MB
[2023-07-07 13:43:11 RepVGG-A0] (main.py 282): INFO Train: [168/300][60/78]	eta 0:00:33 lr 2.575079	time 1.3584 (1.8810)	loss 3.0273 (2.9664)	grad_norm 0.4068 (0.4137)	mem 39782MB
[2023-07-07 13:43:27 RepVGG-A0] (main.py 282): INFO Train: [168/300][70/78]	eta 0:00:14 lr 2.570866	time 1.1759 (1.8369)	loss 3.0496 (2.9734)	grad_norm 0.4133 (0.4139)	mem 39782MB
[2023-07-07 13:43:39 RepVGG-A0] (main.py 291): INFO EPOCH 168 training takes 0:02:21
[2023-07-07 13:43:59 RepVGG-A0] (main.py 282): INFO Train: [169/300][0/78]	eta 0:26:57 lr 2.567497	time 20.7397 (20.7397)	loss 2.9033 (2.9033)	grad_norm 0.3882 (0.3882)	mem 39782MB
[2023-07-07 13:44:15 RepVGG-A0] (main.py 282): INFO Train: [169/300][10/78]	eta 0:03:47 lr 2.563286	time 1.1732 (3.3432)	loss 2.9967 (2.9459)	grad_norm 0.4695 (0.4336)	mem 39782MB
[2023-07-07 13:44:29 RepVGG-A0] (main.py 282): INFO Train: [169/300][20/78]	eta 0:02:18 lr 2.559076	time 1.1719 (2.3951)	loss 2.9727 (2.9565)	grad_norm 0.4118 (0.4210)	mem 39782MB
[2023-07-07 13:44:44 RepVGG-A0] (main.py 282): INFO Train: [169/300][30/78]	eta 0:01:41 lr 2.554867	time 1.1477 (2.1202)	loss 2.9740 (2.9619)	grad_norm 0.4428 (0.4221)	mem 39782MB
[2023-07-07 13:45:02 RepVGG-A0] (main.py 282): INFO Train: [169/300][40/78]	eta 0:01:17 lr 2.550660	time 3.9534 (2.0399)	loss 2.9103 (2.9505)	grad_norm 0.4374 (0.4156)	mem 39782MB
[2023-07-07 13:45:18 RepVGG-A0] (main.py 282): INFO Train: [169/300][50/78]	eta 0:00:54 lr 2.546454	time 1.2891 (1.9540)	loss 2.9513 (2.9554)	grad_norm 0.3932 (0.4165)	mem 39782MB
[2023-07-07 13:45:32 RepVGG-A0] (main.py 282): INFO Train: [169/300][60/78]	eta 0:00:33 lr 2.542249	time 1.1964 (1.8652)	loss 3.0121 (2.9581)	grad_norm 0.4186 (0.4186)	mem 39782MB
[2023-07-07 13:45:47 RepVGG-A0] (main.py 282): INFO Train: [169/300][70/78]	eta 0:00:14 lr 2.538045	time 1.3270 (1.8154)	loss 2.9507 (2.9576)	grad_norm 0.3849 (0.4143)	mem 39782MB
[2023-07-07 13:45:59 RepVGG-A0] (main.py 291): INFO EPOCH 169 training takes 0:02:20
[2023-07-07 13:46:20 RepVGG-A0] (main.py 282): INFO Train: [170/300][0/78]	eta 0:27:37 lr 2.534683	time 21.2562 (21.2562)	loss 2.9965 (2.9965)	grad_norm 0.4632 (0.4632)	mem 39782MB
[2023-07-07 13:46:35 RepVGG-A0] (main.py 282): INFO Train: [170/300][10/78]	eta 0:03:38 lr 2.530481	time 1.1730 (3.2185)	loss 3.0145 (2.9436)	grad_norm 0.4123 (0.4232)	mem 39782MB
[2023-07-07 13:46:49 RepVGG-A0] (main.py 282): INFO Train: [170/300][20/78]	eta 0:02:18 lr 2.526280	time 1.1750 (2.3862)	loss 2.9197 (2.9401)	grad_norm 0.3891 (0.4195)	mem 39782MB
[2023-07-07 13:47:05 RepVGG-A0] (main.py 282): INFO Train: [170/300][30/78]	eta 0:01:42 lr 2.522081	time 1.4033 (2.1304)	loss 3.0068 (2.9324)	grad_norm 0.3868 (0.4124)	mem 39782MB
[2023-07-07 13:47:24 RepVGG-A0] (main.py 282): INFO Train: [170/300][40/78]	eta 0:01:18 lr 2.517883	time 4.1086 (2.0557)	loss 3.0749 (2.9333)	grad_norm 0.4497 (0.4109)	mem 39782MB
[2023-07-07 13:47:38 RepVGG-A0] (main.py 282): INFO Train: [170/300][50/78]	eta 0:00:54 lr 2.513686	time 1.1896 (1.9306)	loss 3.0127 (2.9431)	grad_norm 0.4956 (0.4200)	mem 39782MB
[2023-07-07 13:47:52 RepVGG-A0] (main.py 282): INFO Train: [170/300][60/78]	eta 0:00:33 lr 2.509491	time 1.1870 (1.8540)	loss 2.9322 (2.9447)	grad_norm 0.3695 (0.4194)	mem 39782MB
[2023-07-07 13:48:07 RepVGG-A0] (main.py 282): INFO Train: [170/300][70/78]	eta 0:00:14 lr 2.505296	time 1.3368 (1.8044)	loss 3.0995 (2.9459)	grad_norm 0.4598 (0.4178)	mem 39782MB
[2023-07-07 13:48:19 RepVGG-A0] (main.py 291): INFO EPOCH 170 training takes 0:02:20
[2023-07-07 13:48:41 RepVGG-A0] (main.py 282): INFO Train: [171/300][0/78]	eta 0:28:37 lr 2.501942	time 22.0185 (22.0185)	loss 2.9522 (2.9522)	grad_norm 0.4047 (0.4047)	mem 39782MB
[2023-07-07 13:48:56 RepVGG-A0] (main.py 282): INFO Train: [171/300][10/78]	eta 0:03:45 lr 2.497750	time 1.1723 (3.3151)	loss 2.9441 (2.9138)	grad_norm 0.4071 (0.4257)	mem 39782MB
[2023-07-07 13:49:10 RepVGG-A0] (main.py 282): INFO Train: [171/300][20/78]	eta 0:02:19 lr 2.493559	time 1.1738 (2.4061)	loss 2.9581 (2.9152)	grad_norm 0.4124 (0.4168)	mem 39782MB
[2023-07-07 13:49:27 RepVGG-A0] (main.py 282): INFO Train: [171/300][30/78]	eta 0:01:44 lr 2.489369	time 1.5832 (2.1682)	loss 2.9168 (2.9223)	grad_norm 0.4142 (0.4192)	mem 39782MB
[2023-07-07 13:49:45 RepVGG-A0] (main.py 282): INFO Train: [171/300][40/78]	eta 0:01:19 lr 2.485181	time 3.5755 (2.0983)	loss 2.9606 (2.9352)	grad_norm 0.4302 (0.4287)	mem 39782MB
[2023-07-07 13:50:00 RepVGG-A0] (main.py 282): INFO Train: [171/300][50/78]	eta 0:00:55 lr 2.480994	time 1.1746 (1.9718)	loss 2.9288 (2.9306)	grad_norm 0.4170 (0.4232)	mem 39782MB
[2023-07-07 13:50:15 RepVGG-A0] (main.py 282): INFO Train: [171/300][60/78]	eta 0:00:34 lr 2.476808	time 1.2722 (1.9002)	loss 2.9556 (2.9317)	grad_norm 0.4056 (0.4211)	mem 39782MB
[2023-07-07 13:50:31 RepVGG-A0] (main.py 282): INFO Train: [171/300][70/78]	eta 0:00:14 lr 2.472624	time 1.3450 (1.8482)	loss 2.9567 (2.9348)	grad_norm 0.3904 (0.4189)	mem 39782MB
[2023-07-07 13:50:42 RepVGG-A0] (main.py 291): INFO EPOCH 171 training takes 0:02:22
[2023-07-07 13:51:02 RepVGG-A0] (main.py 282): INFO Train: [172/300][0/78]	eta 0:26:08 lr 2.469277	time 20.1146 (20.1146)	loss 2.9775 (2.9775)	grad_norm 0.4223 (0.4223)	mem 39782MB
[2023-07-07 13:51:18 RepVGG-A0] (main.py 282): INFO Train: [172/300][10/78]	eta 0:03:45 lr 2.465095	time 1.1898 (3.3228)	loss 2.8599 (2.8867)	grad_norm 0.3867 (0.4099)	mem 39782MB
[2023-07-07 13:51:32 RepVGG-A0] (main.py 282): INFO Train: [172/300][20/78]	eta 0:02:18 lr 2.460914	time 1.1739 (2.3959)	loss 2.8913 (2.9022)	grad_norm 0.4396 (0.4193)	mem 39782MB
[2023-07-07 13:51:47 RepVGG-A0] (main.py 282): INFO Train: [172/300][30/78]	eta 0:01:41 lr 2.456735	time 1.1745 (2.1175)	loss 2.9495 (2.9062)	grad_norm 0.4349 (0.4197)	mem 39782MB
[2023-07-07 13:52:04 RepVGG-A0] (main.py 282): INFO Train: [172/300][40/78]	eta 0:01:16 lr 2.452557	time 1.9839 (2.0009)	loss 2.9224 (2.9082)	grad_norm 0.4100 (0.4195)	mem 39782MB
[2023-07-07 13:52:19 RepVGG-A0] (main.py 282): INFO Train: [172/300][50/78]	eta 0:00:53 lr 2.448380	time 1.6068 (1.8994)	loss 2.9102 (2.9125)	grad_norm 0.4344 (0.4189)	mem 39782MB
[2023-07-07 13:52:35 RepVGG-A0] (main.py 282): INFO Train: [172/300][60/78]	eta 0:00:33 lr 2.444205	time 1.2294 (1.8545)	loss 2.9301 (2.9186)	grad_norm 0.3808 (0.4183)	mem 39782MB
[2023-07-07 13:52:50 RepVGG-A0] (main.py 282): INFO Train: [172/300][70/78]	eta 0:00:14 lr 2.440031	time 1.3023 (1.8090)	loss 3.0386 (2.9200)	grad_norm 0.5303 (0.4188)	mem 39782MB
[2023-07-07 13:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 172 training takes 0:02:19
[2023-07-07 13:53:23 RepVGG-A0] (main.py 282): INFO Train: [173/300][0/78]	eta 0:27:07 lr 2.436693	time 20.8615 (20.8615)	loss 3.0608 (3.0608)	grad_norm 0.5914 (0.5914)	mem 39782MB
[2023-07-07 13:53:37 RepVGG-A0] (main.py 282): INFO Train: [173/300][10/78]	eta 0:03:41 lr 2.432521	time 1.1730 (3.2556)	loss 2.9372 (3.0293)	grad_norm 0.3664 (0.4833)	mem 39782MB
[2023-07-07 13:53:52 RepVGG-A0] (main.py 282): INFO Train: [173/300][20/78]	eta 0:02:18 lr 2.428351	time 1.2072 (2.3952)	loss 2.8126 (2.9573)	grad_norm 0.3851 (0.4326)	mem 39782MB
[2023-07-07 13:54:07 RepVGG-A0] (main.py 282): INFO Train: [173/300][30/78]	eta 0:01:41 lr 2.424183	time 1.6680 (2.1205)	loss 2.8875 (2.9357)	grad_norm 0.3749 (0.4145)	mem 39782MB
[2023-07-07 13:54:24 RepVGG-A0] (main.py 282): INFO Train: [173/300][40/78]	eta 0:01:16 lr 2.420015	time 3.6383 (2.0199)	loss 2.8835 (2.9296)	grad_norm 0.3728 (0.4113)	mem 39782MB
[2023-07-07 13:54:41 RepVGG-A0] (main.py 282): INFO Train: [173/300][50/78]	eta 0:00:54 lr 2.415849	time 1.3010 (1.9395)	loss 2.9103 (2.9250)	grad_norm 0.3827 (0.4085)	mem 39782MB
[2023-07-07 13:54:56 RepVGG-A0] (main.py 282): INFO Train: [173/300][60/78]	eta 0:00:33 lr 2.411685	time 1.1719 (1.8671)	loss 2.9520 (2.9243)	grad_norm 0.4212 (0.4086)	mem 39782MB
[2023-07-07 13:55:11 RepVGG-A0] (main.py 282): INFO Train: [173/300][70/78]	eta 0:00:14 lr 2.407522	time 1.1741 (1.8173)	loss 2.8923 (2.9202)	grad_norm 0.3730 (0.4077)	mem 39782MB
[2023-07-07 13:55:22 RepVGG-A0] (main.py 291): INFO EPOCH 173 training takes 0:02:20
[2023-07-07 13:55:45 RepVGG-A0] (main.py 282): INFO Train: [174/300][0/78]	eta 0:28:53 lr 2.404192	time 22.2306 (22.2306)	loss 2.8484 (2.8484)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 13:55:59 RepVGG-A0] (main.py 282): INFO Train: [174/300][10/78]	eta 0:03:43 lr 2.400032	time 1.1722 (3.2938)	loss 2.7998 (2.8921)	grad_norm 0.3906 (0.4351)	mem 39782MB
[2023-07-07 13:56:13 RepVGG-A0] (main.py 282): INFO Train: [174/300][20/78]	eta 0:02:19 lr 2.395873	time 1.1915 (2.4091)	loss 2.8393 (2.8815)	grad_norm 0.4054 (0.4213)	mem 39782MB
[2023-07-07 13:56:28 RepVGG-A0] (main.py 282): INFO Train: [174/300][30/78]	eta 0:01:41 lr 2.391715	time 1.3479 (2.1192)	loss 2.9220 (2.8902)	grad_norm 0.4346 (0.4207)	mem 39782MB
[2023-07-07 13:56:46 RepVGG-A0] (main.py 282): INFO Train: [174/300][40/78]	eta 0:01:17 lr 2.387559	time 3.5879 (2.0412)	loss 2.8316 (2.8913)	grad_norm 0.4119 (0.4222)	mem 39782MB
[2023-07-07 13:57:01 RepVGG-A0] (main.py 282): INFO Train: [174/300][50/78]	eta 0:00:54 lr 2.383404	time 1.1888 (1.9407)	loss 2.9789 (2.8989)	grad_norm 0.3976 (0.4227)	mem 39782MB
[2023-07-07 13:57:17 RepVGG-A0] (main.py 282): INFO Train: [174/300][60/78]	eta 0:00:33 lr 2.379251	time 1.2053 (1.8762)	loss 2.8249 (2.9010)	grad_norm 0.3892 (0.4201)	mem 39782MB
[2023-07-07 13:57:32 RepVGG-A0] (main.py 282): INFO Train: [174/300][70/78]	eta 0:00:14 lr 2.375099	time 1.2466 (1.8277)	loss 2.9064 (2.9040)	grad_norm 0.4304 (0.4233)	mem 39782MB
[2023-07-07 13:57:44 RepVGG-A0] (main.py 291): INFO EPOCH 174 training takes 0:02:21
[2023-07-07 13:58:06 RepVGG-A0] (main.py 282): INFO Train: [175/300][0/78]	eta 0:28:51 lr 2.371779	time 22.1942 (22.1942)	loss 2.8887 (2.8887)	grad_norm 0.4550 (0.4550)	mem 39782MB
[2023-07-07 13:58:20 RepVGG-A0] (main.py 282): INFO Train: [175/300][10/78]	eta 0:03:45 lr 2.367630	time 1.1720 (3.3227)	loss 2.8109 (2.8592)	grad_norm 0.3782 (0.4255)	mem 39782MB
[2023-07-07 13:58:34 RepVGG-A0] (main.py 282): INFO Train: [175/300][20/78]	eta 0:02:18 lr 2.363482	time 1.1728 (2.3938)	loss 2.9065 (2.8624)	grad_norm 0.4397 (0.4166)	mem 39782MB
[2023-07-07 13:58:50 RepVGG-A0] (main.py 282): INFO Train: [175/300][30/78]	eta 0:01:42 lr 2.359336	time 1.5408 (2.1334)	loss 2.8227 (2.8741)	grad_norm 0.3908 (0.4234)	mem 39782MB
[2023-07-07 13:59:08 RepVGG-A0] (main.py 282): INFO Train: [175/300][40/78]	eta 0:01:18 lr 2.355192	time 3.6378 (2.0598)	loss 2.8759 (2.8795)	grad_norm 0.4323 (0.4225)	mem 39782MB
[2023-07-07 13:59:23 RepVGG-A0] (main.py 282): INFO Train: [175/300][50/78]	eta 0:00:54 lr 2.351049	time 1.1740 (1.9519)	loss 2.9453 (2.8952)	grad_norm 0.4569 (0.4365)	mem 39782MB
[2023-07-07 13:59:38 RepVGG-A0] (main.py 282): INFO Train: [175/300][60/78]	eta 0:00:33 lr 2.346907	time 1.4368 (1.8782)	loss 2.8750 (2.8965)	grad_norm 0.4288 (0.4316)	mem 39782MB
[2023-07-07 13:59:52 RepVGG-A0] (main.py 282): INFO Train: [175/300][70/78]	eta 0:00:14 lr 2.342767	time 1.4233 (1.8125)	loss 2.8719 (2.8972)	grad_norm 0.4479 (0.4276)	mem 39782MB
[2023-07-07 14:00:04 RepVGG-A0] (main.py 291): INFO EPOCH 175 training takes 0:02:20
[2023-07-07 14:00:26 RepVGG-A0] (main.py 282): INFO Train: [176/300][0/78]	eta 0:28:41 lr 2.339457	time 22.0697 (22.0697)	loss 2.9087 (2.9087)	grad_norm 0.4049 (0.4049)	mem 39782MB
[2023-07-07 14:00:40 RepVGG-A0] (main.py 282): INFO Train: [176/300][10/78]	eta 0:03:41 lr 2.335319	time 1.1727 (3.2547)	loss 2.8642 (2.8338)	grad_norm 0.4052 (0.4060)	mem 39782MB
[2023-07-07 14:00:54 RepVGG-A0] (main.py 282): INFO Train: [176/300][20/78]	eta 0:02:19 lr 2.331184	time 1.1913 (2.3969)	loss 2.8710 (2.8584)	grad_norm 0.3774 (0.4057)	mem 39782MB
[2023-07-07 14:01:11 RepVGG-A0] (main.py 282): INFO Train: [176/300][30/78]	eta 0:01:43 lr 2.327050	time 1.5090 (2.1489)	loss 2.8848 (2.8628)	grad_norm 0.4550 (0.4164)	mem 39782MB
[2023-07-07 14:01:28 RepVGG-A0] (main.py 282): INFO Train: [176/300][40/78]	eta 0:01:17 lr 2.322917	time 3.6419 (2.0458)	loss 2.9243 (2.8784)	grad_norm 0.4153 (0.4206)	mem 39782MB
[2023-07-07 14:01:44 RepVGG-A0] (main.py 282): INFO Train: [176/300][50/78]	eta 0:00:54 lr 2.318786	time 1.2354 (1.9488)	loss 2.8920 (2.8807)	grad_norm 0.4460 (0.4203)	mem 39782MB
[2023-07-07 14:01:59 RepVGG-A0] (main.py 282): INFO Train: [176/300][60/78]	eta 0:00:33 lr 2.314657	time 1.1819 (1.8803)	loss 2.9095 (2.8832)	grad_norm 0.4125 (0.4201)	mem 39782MB
[2023-07-07 14:02:14 RepVGG-A0] (main.py 282): INFO Train: [176/300][70/78]	eta 0:00:14 lr 2.310529	time 1.4510 (1.8280)	loss 2.8903 (2.8852)	grad_norm 0.4762 (0.4207)	mem 39782MB
[2023-07-07 14:02:25 RepVGG-A0] (main.py 291): INFO EPOCH 176 training takes 0:02:20
[2023-07-07 14:02:47 RepVGG-A0] (main.py 282): INFO Train: [177/300][0/78]	eta 0:28:21 lr 2.307228	time 21.8199 (21.8199)	loss 2.8113 (2.8113)	grad_norm 0.4294 (0.4294)	mem 39782MB
[2023-07-07 14:03:03 RepVGG-A0] (main.py 282): INFO Train: [177/300][10/78]	eta 0:03:52 lr 2.303104	time 1.1716 (3.4138)	loss 2.8988 (2.8655)	grad_norm 0.4109 (0.4347)	mem 39782MB
[2023-07-07 14:03:17 RepVGG-A0] (main.py 282): INFO Train: [177/300][20/78]	eta 0:02:24 lr 2.298980	time 1.1773 (2.4830)	loss 2.8378 (2.8599)	grad_norm 0.4054 (0.4214)	mem 39782MB
[2023-07-07 14:03:32 RepVGG-A0] (main.py 282): INFO Train: [177/300][30/78]	eta 0:01:43 lr 2.294859	time 1.2781 (2.1614)	loss 2.9347 (2.8572)	grad_norm 0.4534 (0.4241)	mem 39782MB
[2023-07-07 14:03:51 RepVGG-A0] (main.py 282): INFO Train: [177/300][40/78]	eta 0:01:19 lr 2.290739	time 3.6489 (2.0863)	loss 2.8586 (2.8643)	grad_norm 0.4210 (0.4281)	mem 39782MB
[2023-07-07 14:04:05 RepVGG-A0] (main.py 282): INFO Train: [177/300][50/78]	eta 0:00:55 lr 2.286621	time 1.1837 (1.9688)	loss 2.8936 (2.8665)	grad_norm 0.4044 (0.4290)	mem 39782MB
[2023-07-07 14:04:20 RepVGG-A0] (main.py 282): INFO Train: [177/300][60/78]	eta 0:00:33 lr 2.282504	time 1.1745 (1.8802)	loss 2.9734 (2.8650)	grad_norm 0.4053 (0.4258)	mem 39782MB
[2023-07-07 14:04:36 RepVGG-A0] (main.py 282): INFO Train: [177/300][70/78]	eta 0:00:14 lr 2.278389	time 1.4439 (1.8400)	loss 2.8956 (2.8655)	grad_norm 0.4117 (0.4240)	mem 39782MB
[2023-07-07 14:04:48 RepVGG-A0] (main.py 291): INFO EPOCH 177 training takes 0:02:22
[2023-07-07 14:05:08 RepVGG-A0] (main.py 282): INFO Train: [178/300][0/78]	eta 0:26:36 lr 2.275098	time 20.4630 (20.4630)	loss 2.9880 (2.9880)	grad_norm 0.5030 (0.5030)	mem 39782MB
[2023-07-07 14:05:23 RepVGG-A0] (main.py 282): INFO Train: [178/300][10/78]	eta 0:03:40 lr 2.270986	time 1.1730 (3.2376)	loss 2.8232 (2.9099)	grad_norm 0.4013 (0.4872)	mem 39782MB
[2023-07-07 14:05:39 RepVGG-A0] (main.py 282): INFO Train: [178/300][20/78]	eta 0:02:20 lr 2.266876	time 1.1736 (2.4206)	loss 2.8398 (2.8890)	grad_norm 0.4032 (0.4468)	mem 39782MB
[2023-07-07 14:05:54 RepVGG-A0] (main.py 282): INFO Train: [178/300][30/78]	eta 0:01:42 lr 2.262767	time 1.3382 (2.1372)	loss 2.9657 (2.8911)	grad_norm 0.5090 (0.4396)	mem 39782MB
[2023-07-07 14:06:12 RepVGG-A0] (main.py 282): INFO Train: [178/300][40/78]	eta 0:01:18 lr 2.258660	time 3.1697 (2.0583)	loss 2.8413 (2.8896)	grad_norm 0.3990 (0.4328)	mem 39782MB
[2023-07-07 14:06:27 RepVGG-A0] (main.py 282): INFO Train: [178/300][50/78]	eta 0:00:54 lr 2.254555	time 1.1711 (1.9435)	loss 2.8315 (2.8872)	grad_norm 0.4083 (0.4322)	mem 39782MB
[2023-07-07 14:06:42 RepVGG-A0] (main.py 282): INFO Train: [178/300][60/78]	eta 0:00:33 lr 2.250452	time 1.5254 (1.8783)	loss 2.8509 (2.8815)	grad_norm 0.4020 (0.4271)	mem 39782MB
[2023-07-07 14:06:57 RepVGG-A0] (main.py 282): INFO Train: [178/300][70/78]	eta 0:00:14 lr 2.246350	time 1.1711 (1.8227)	loss 2.9093 (2.8826)	grad_norm 0.4972 (0.4286)	mem 39782MB
[2023-07-07 14:07:09 RepVGG-A0] (main.py 291): INFO EPOCH 178 training takes 0:02:20
[2023-07-07 14:07:31 RepVGG-A0] (main.py 282): INFO Train: [179/300][0/78]	eta 0:29:38 lr 2.243069	time 22.8021 (22.8021)	loss 2.8079 (2.8079)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 14:07:45 RepVGG-A0] (main.py 282): INFO Train: [179/300][10/78]	eta 0:03:45 lr 2.238971	time 1.1720 (3.3189)	loss 2.8157 (2.8207)	grad_norm 0.4358 (0.4013)	mem 39782MB
[2023-07-07 14:08:00 RepVGG-A0] (main.py 282): INFO Train: [179/300][20/78]	eta 0:02:22 lr 2.234874	time 1.1739 (2.4618)	loss 2.8230 (2.8320)	grad_norm 0.4070 (0.4127)	mem 39782MB
[2023-07-07 14:08:15 RepVGG-A0] (main.py 282): INFO Train: [179/300][30/78]	eta 0:01:43 lr 2.230778	time 1.4124 (2.1549)	loss 2.8257 (2.8345)	grad_norm 0.3977 (0.4138)	mem 39782MB
[2023-07-07 14:08:33 RepVGG-A0] (main.py 282): INFO Train: [179/300][40/78]	eta 0:01:17 lr 2.226685	time 1.4425 (2.0484)	loss 2.9123 (2.8381)	grad_norm 0.4566 (0.4153)	mem 39782MB
[2023-07-07 14:08:48 RepVGG-A0] (main.py 282): INFO Train: [179/300][50/78]	eta 0:00:54 lr 2.222593	time 1.1743 (1.9512)	loss 2.9483 (2.8491)	grad_norm 0.4202 (0.4243)	mem 39782MB
[2023-07-07 14:09:03 RepVGG-A0] (main.py 282): INFO Train: [179/300][60/78]	eta 0:00:33 lr 2.218503	time 1.1930 (1.8791)	loss 2.8853 (2.8501)	grad_norm 0.4486 (0.4242)	mem 39782MB
[2023-07-07 14:09:18 RepVGG-A0] (main.py 282): INFO Train: [179/300][70/78]	eta 0:00:14 lr 2.214415	time 1.2412 (1.8253)	loss 2.8644 (2.8532)	grad_norm 0.4134 (0.4272)	mem 39782MB
[2023-07-07 14:09:30 RepVGG-A0] (main.py 291): INFO EPOCH 179 training takes 0:02:21
[2023-07-07 14:09:52 RepVGG-A0] (main.py 282): INFO Train: [180/300][0/78]	eta 0:28:50 lr 2.211146	time 22.1884 (22.1884)	loss 2.8422 (2.8422)	grad_norm 0.4234 (0.4234)	mem 39782MB
[2023-07-07 14:10:06 RepVGG-A0] (main.py 282): INFO Train: [180/300][10/78]	eta 0:03:42 lr 2.207061	time 1.1736 (3.2756)	loss 2.7868 (2.8231)	grad_norm 0.4227 (0.4185)	mem 39782MB
[2023-07-07 14:10:21 RepVGG-A0] (main.py 282): INFO Train: [180/300][20/78]	eta 0:02:21 lr 2.202977	time 1.1777 (2.4394)	loss 2.8208 (2.8238)	grad_norm 0.4307 (0.4238)	mem 39782MB
[2023-07-07 14:10:37 RepVGG-A0] (main.py 282): INFO Train: [180/300][30/78]	eta 0:01:44 lr 2.198896	time 1.3565 (2.1796)	loss 2.8289 (2.8434)	grad_norm 0.4013 (0.4360)	mem 39782MB
[2023-07-07 14:10:55 RepVGG-A0] (main.py 282): INFO Train: [180/300][40/78]	eta 0:01:18 lr 2.194816	time 3.4067 (2.0656)	loss 2.8884 (2.8480)	grad_norm 0.4398 (0.4329)	mem 39782MB
[2023-07-07 14:11:09 RepVGG-A0] (main.py 282): INFO Train: [180/300][50/78]	eta 0:00:54 lr 2.190738	time 1.1735 (1.9477)	loss 2.9307 (2.8461)	grad_norm 0.4570 (0.4285)	mem 39782MB
[2023-07-07 14:11:25 RepVGG-A0] (main.py 282): INFO Train: [180/300][60/78]	eta 0:00:33 lr 2.186662	time 1.4738 (1.8877)	loss 2.8781 (2.8522)	grad_norm 0.4141 (0.4297)	mem 39782MB
[2023-07-07 14:11:38 RepVGG-A0] (main.py 282): INFO Train: [180/300][70/78]	eta 0:00:14 lr 2.182588	time 1.1763 (1.8081)	loss 2.8952 (2.8541)	grad_norm 0.4716 (0.4313)	mem 39782MB
[2023-07-07 14:11:51 RepVGG-A0] (main.py 291): INFO EPOCH 180 training takes 0:02:20
[2023-07-07 14:12:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.604 (17.604)	Loss 2.2331 (2.2331)	Acc@1 51.160 (51.160)	Acc@5 75.751 (75.751)	Mem 39782MB
[2023-07-07 14:12:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 51.752 Acc@5 76.092
[2023-07-07 14:12:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 180: 51.752%
[2023-07-07 14:12:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 51.75%
[2023-07-07 14:12:30 RepVGG-A0] (main.py 282): INFO Train: [181/300][0/78]	eta 0:27:16 lr 2.179330	time 20.9845 (20.9845)	loss 2.7767 (2.7767)	grad_norm 0.4137 (0.4137)	mem 39782MB
[2023-07-07 14:12:47 RepVGG-A0] (main.py 282): INFO Train: [181/300][10/78]	eta 0:03:51 lr 2.175259	time 1.1713 (3.3977)	loss 2.8193 (2.8278)	grad_norm 0.3866 (0.4094)	mem 39782MB
[2023-07-07 14:13:01 RepVGG-A0] (main.py 282): INFO Train: [181/300][20/78]	eta 0:02:23 lr 2.171190	time 1.1961 (2.4691)	loss 2.9382 (2.8142)	grad_norm 0.4492 (0.4071)	mem 39782MB
[2023-07-07 14:13:16 RepVGG-A0] (main.py 282): INFO Train: [181/300][30/78]	eta 0:01:44 lr 2.167123	time 1.5199 (2.1695)	loss 2.8651 (2.8358)	grad_norm 0.4161 (0.4194)	mem 39782MB
[2023-07-07 14:13:34 RepVGG-A0] (main.py 282): INFO Train: [181/300][40/78]	eta 0:01:18 lr 2.163058	time 4.2177 (2.0648)	loss 2.8373 (2.8345)	grad_norm 0.4424 (0.4200)	mem 39782MB
[2023-07-07 14:13:49 RepVGG-A0] (main.py 282): INFO Train: [181/300][50/78]	eta 0:00:54 lr 2.158994	time 1.1742 (1.9546)	loss 2.8027 (2.8402)	grad_norm 0.4372 (0.4223)	mem 39782MB
[2023-07-07 14:14:03 RepVGG-A0] (main.py 282): INFO Train: [181/300][60/78]	eta 0:00:33 lr 2.154933	time 1.1736 (1.8727)	loss 2.9299 (2.8467)	grad_norm 0.4500 (0.4270)	mem 39782MB
[2023-07-07 14:14:19 RepVGG-A0] (main.py 282): INFO Train: [181/300][70/78]	eta 0:00:14 lr 2.150873	time 1.4370 (1.8334)	loss 2.8347 (2.8449)	grad_norm 0.4354 (0.4248)	mem 39782MB
[2023-07-07 14:14:30 RepVGG-A0] (main.py 291): INFO EPOCH 181 training takes 0:02:20
[2023-07-07 14:14:51 RepVGG-A0] (main.py 282): INFO Train: [182/300][0/78]	eta 0:27:04 lr 2.147627	time 20.8248 (20.8248)	loss 2.8491 (2.8491)	grad_norm 0.4604 (0.4604)	mem 39782MB
[2023-07-07 14:15:05 RepVGG-A0] (main.py 282): INFO Train: [182/300][10/78]	eta 0:03:36 lr 2.143570	time 1.1731 (3.1862)	loss 2.8147 (2.8099)	grad_norm 0.3832 (0.4279)	mem 39782MB
[2023-07-07 14:15:20 RepVGG-A0] (main.py 282): INFO Train: [182/300][20/78]	eta 0:02:17 lr 2.139516	time 1.1723 (2.3680)	loss 2.8838 (2.8243)	grad_norm 0.4696 (0.4289)	mem 39782MB
[2023-07-07 14:15:35 RepVGG-A0] (main.py 282): INFO Train: [182/300][30/78]	eta 0:01:40 lr 2.135464	time 1.2461 (2.0930)	loss 2.8056 (2.8495)	grad_norm 0.4038 (0.4527)	mem 39782MB
[2023-07-07 14:15:53 RepVGG-A0] (main.py 282): INFO Train: [182/300][40/78]	eta 0:01:17 lr 2.131413	time 3.9665 (2.0296)	loss 2.8580 (2.8449)	grad_norm 0.4073 (0.4402)	mem 39782MB
[2023-07-07 14:16:08 RepVGG-A0] (main.py 282): INFO Train: [182/300][50/78]	eta 0:00:54 lr 2.127364	time 1.1738 (1.9295)	loss 2.7543 (2.8434)	grad_norm 0.3986 (0.4338)	mem 39782MB
[2023-07-07 14:16:23 RepVGG-A0] (main.py 282): INFO Train: [182/300][60/78]	eta 0:00:33 lr 2.123318	time 1.1829 (1.8551)	loss 2.8187 (2.8441)	grad_norm 0.4175 (0.4315)	mem 39782MB
[2023-07-07 14:16:39 RepVGG-A0] (main.py 282): INFO Train: [182/300][70/78]	eta 0:00:14 lr 2.119273	time 1.1800 (1.8134)	loss 2.9271 (2.8491)	grad_norm 0.5108 (0.4387)	mem 39782MB
[2023-07-07 14:16:51 RepVGG-A0] (main.py 291): INFO EPOCH 182 training takes 0:02:20
[2023-07-07 14:17:12 RepVGG-A0] (main.py 282): INFO Train: [183/300][0/78]	eta 0:27:51 lr 2.116039	time 21.4321 (21.4321)	loss 2.7686 (2.7686)	grad_norm 0.4088 (0.4088)	mem 39782MB
[2023-07-07 14:17:27 RepVGG-A0] (main.py 282): INFO Train: [183/300][10/78]	eta 0:03:45 lr 2.111997	time 1.1727 (3.3219)	loss 2.8593 (2.8006)	grad_norm 0.4117 (0.4263)	mem 39782MB
[2023-07-07 14:17:41 RepVGG-A0] (main.py 282): INFO Train: [183/300][20/78]	eta 0:02:19 lr 2.107958	time 1.1751 (2.4116)	loss 2.8569 (2.8061)	grad_norm 0.4094 (0.4277)	mem 39782MB
[2023-07-07 14:17:58 RepVGG-A0] (main.py 282): INFO Train: [183/300][30/78]	eta 0:01:43 lr 2.103921	time 1.8339 (2.1611)	loss 2.8487 (2.8062)	grad_norm 0.4136 (0.4238)	mem 39782MB
[2023-07-07 14:18:15 RepVGG-A0] (main.py 282): INFO Train: [183/300][40/78]	eta 0:01:17 lr 2.099886	time 3.9434 (2.0442)	loss 2.8718 (2.8151)	grad_norm 0.4417 (0.4279)	mem 39782MB
[2023-07-07 14:18:30 RepVGG-A0] (main.py 282): INFO Train: [183/300][50/78]	eta 0:00:54 lr 2.095852	time 1.1746 (1.9378)	loss 2.7712 (2.8192)	grad_norm 0.4075 (0.4246)	mem 39782MB
[2023-07-07 14:18:44 RepVGG-A0] (main.py 282): INFO Train: [183/300][60/78]	eta 0:00:33 lr 2.091821	time 1.2910 (1.8616)	loss 2.7923 (2.8208)	grad_norm 0.3917 (0.4247)	mem 39782MB
[2023-07-07 14:19:00 RepVGG-A0] (main.py 282): INFO Train: [183/300][70/78]	eta 0:00:14 lr 2.087791	time 1.1449 (1.8167)	loss 2.8559 (2.8269)	grad_norm 0.4519 (0.4292)	mem 39782MB
[2023-07-07 14:19:11 RepVGG-A0] (main.py 291): INFO EPOCH 183 training takes 0:02:20
[2023-07-07 14:19:33 RepVGG-A0] (main.py 282): INFO Train: [184/300][0/78]	eta 0:28:38 lr 2.084569	time 22.0306 (22.0306)	loss 2.7898 (2.7898)	grad_norm 0.4164 (0.4164)	mem 39782MB
[2023-07-07 14:19:48 RepVGG-A0] (main.py 282): INFO Train: [184/300][10/78]	eta 0:03:51 lr 2.080544	time 1.1715 (3.4072)	loss 2.8414 (2.7878)	grad_norm 0.4092 (0.4290)	mem 39782MB
[2023-07-07 14:20:04 RepVGG-A0] (main.py 282): INFO Train: [184/300][20/78]	eta 0:02:25 lr 2.076520	time 1.1978 (2.5025)	loss 2.7574 (2.7945)	grad_norm 0.4272 (0.4374)	mem 39782MB
[2023-07-07 14:20:19 RepVGG-A0] (main.py 282): INFO Train: [184/300][30/78]	eta 0:01:44 lr 2.072498	time 1.4266 (2.1814)	loss 2.8257 (2.8009)	grad_norm 0.4715 (0.4347)	mem 39782MB
[2023-07-07 14:20:34 RepVGG-A0] (main.py 282): INFO Train: [184/300][40/78]	eta 0:01:16 lr 2.068479	time 2.0632 (2.0244)	loss 2.8374 (2.8081)	grad_norm 0.4266 (0.4359)	mem 39782MB
[2023-07-07 14:20:52 RepVGG-A0] (main.py 282): INFO Train: [184/300][50/78]	eta 0:00:55 lr 2.064461	time 1.3127 (1.9753)	loss 2.8440 (2.8120)	grad_norm 0.4441 (0.4355)	mem 39782MB
[2023-07-07 14:21:06 RepVGG-A0] (main.py 282): INFO Train: [184/300][60/78]	eta 0:00:34 lr 2.060445	time 1.2972 (1.8934)	loss 2.8007 (2.8156)	grad_norm 0.4380 (0.4349)	mem 39782MB
[2023-07-07 14:21:21 RepVGG-A0] (main.py 282): INFO Train: [184/300][70/78]	eta 0:00:14 lr 2.056432	time 1.2144 (1.8270)	loss 2.8519 (2.8179)	grad_norm 0.4162 (0.4350)	mem 39782MB
[2023-07-07 14:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 184 training takes 0:02:21
[2023-07-07 14:21:55 RepVGG-A0] (main.py 282): INFO Train: [185/300][0/78]	eta 0:29:15 lr 2.053223	time 22.5090 (22.5090)	loss 2.7067 (2.7067)	grad_norm 0.4285 (0.4285)	mem 39782MB
[2023-07-07 14:22:10 RepVGG-A0] (main.py 282): INFO Train: [185/300][10/78]	eta 0:03:50 lr 2.049213	time 1.1709 (3.3964)	loss 2.7804 (2.7743)	grad_norm 0.4397 (0.4510)	mem 39782MB
[2023-07-07 14:22:25 RepVGG-A0] (main.py 282): INFO Train: [185/300][20/78]	eta 0:02:24 lr 2.045205	time 1.1751 (2.4947)	loss 2.7970 (2.7938)	grad_norm 0.4867 (0.4514)	mem 39782MB
[2023-07-07 14:22:40 RepVGG-A0] (main.py 282): INFO Train: [185/300][30/78]	eta 0:01:43 lr 2.041199	time 1.3732 (2.1584)	loss 2.8718 (2.8032)	grad_norm 0.4233 (0.4425)	mem 39782MB
[2023-07-07 14:22:59 RepVGG-A0] (main.py 282): INFO Train: [185/300][40/78]	eta 0:01:19 lr 2.037196	time 4.5901 (2.0997)	loss 2.8243 (2.8071)	grad_norm 0.4123 (0.4435)	mem 39782MB
[2023-07-07 14:23:14 RepVGG-A0] (main.py 282): INFO Train: [185/300][50/78]	eta 0:00:55 lr 2.033194	time 1.1986 (1.9786)	loss 2.7733 (2.8037)	grad_norm 0.4245 (0.4378)	mem 39782MB
[2023-07-07 14:23:29 RepVGG-A0] (main.py 282): INFO Train: [185/300][60/78]	eta 0:00:34 lr 2.029195	time 1.1756 (1.9123)	loss 2.8580 (2.8050)	grad_norm 0.4865 (0.4370)	mem 39782MB
[2023-07-07 14:23:45 RepVGG-A0] (main.py 282): INFO Train: [185/300][70/78]	eta 0:00:14 lr 2.025198	time 1.4295 (1.8618)	loss 2.8548 (2.8180)	grad_norm 0.5153 (0.4496)	mem 39782MB
[2023-07-07 14:23:56 RepVGG-A0] (main.py 291): INFO EPOCH 185 training takes 0:02:23
[2023-07-07 14:24:16 RepVGG-A0] (main.py 282): INFO Train: [186/300][0/78]	eta 0:26:34 lr 2.022001	time 20.4406 (20.4406)	loss 2.7478 (2.7478)	grad_norm 0.3953 (0.3953)	mem 39782MB
[2023-07-07 14:24:32 RepVGG-A0] (main.py 282): INFO Train: [186/300][10/78]	eta 0:03:46 lr 2.018008	time 1.1726 (3.3308)	loss 2.7463 (2.7712)	grad_norm 0.4386 (0.4102)	mem 39782MB
[2023-07-07 14:24:47 RepVGG-A0] (main.py 282): INFO Train: [186/300][20/78]	eta 0:02:20 lr 2.014017	time 1.3572 (2.4205)	loss 2.8258 (2.7921)	grad_norm 0.4457 (0.4197)	mem 39782MB
[2023-07-07 14:25:01 RepVGG-A0] (main.py 282): INFO Train: [186/300][30/78]	eta 0:01:41 lr 2.010028	time 1.4581 (2.1145)	loss 2.8002 (2.7913)	grad_norm 0.4208 (0.4273)	mem 39782MB
[2023-07-07 14:25:19 RepVGG-A0] (main.py 282): INFO Train: [186/300][40/78]	eta 0:01:17 lr 2.006040	time 3.1822 (2.0397)	loss 2.8325 (2.8011)	grad_norm 0.3876 (0.4283)	mem 39782MB
[2023-07-07 14:25:35 RepVGG-A0] (main.py 282): INFO Train: [186/300][50/78]	eta 0:00:54 lr 2.002056	time 1.1716 (1.9457)	loss 2.7579 (2.8017)	grad_norm 0.4566 (0.4273)	mem 39782MB
[2023-07-07 14:25:50 RepVGG-A0] (main.py 282): INFO Train: [186/300][60/78]	eta 0:00:33 lr 1.998073	time 1.1777 (1.8701)	loss 2.8555 (2.8060)	grad_norm 0.4367 (0.4297)	mem 39782MB
[2023-07-07 14:26:05 RepVGG-A0] (main.py 282): INFO Train: [186/300][70/78]	eta 0:00:14 lr 1.994092	time 1.3114 (1.8155)	loss 2.7600 (2.8084)	grad_norm 0.4443 (0.4279)	mem 39782MB
[2023-07-07 14:26:16 RepVGG-A0] (main.py 291): INFO EPOCH 186 training takes 0:02:20
[2023-07-07 14:26:38 RepVGG-A0] (main.py 282): INFO Train: [187/300][0/78]	eta 0:28:26 lr 1.990909	time 21.8772 (21.8772)	loss 2.7561 (2.7561)	grad_norm 0.4073 (0.4073)	mem 39782MB
[2023-07-07 14:26:53 RepVGG-A0] (main.py 282): INFO Train: [187/300][10/78]	eta 0:03:46 lr 1.986933	time 1.1929 (3.3250)	loss 2.8602 (2.7969)	grad_norm 0.5060 (0.4395)	mem 39782MB
[2023-07-07 14:27:08 RepVGG-A0] (main.py 282): INFO Train: [187/300][20/78]	eta 0:02:23 lr 1.982958	time 1.1799 (2.4719)	loss 2.8469 (2.7946)	grad_norm 0.4179 (0.4472)	mem 39782MB
[2023-07-07 14:27:24 RepVGG-A0] (main.py 282): INFO Train: [187/300][30/78]	eta 0:01:44 lr 1.978986	time 1.4184 (2.1785)	loss 2.7916 (2.7959)	grad_norm 0.4245 (0.4434)	mem 39782MB
[2023-07-07 14:27:41 RepVGG-A0] (main.py 282): INFO Train: [187/300][40/78]	eta 0:01:18 lr 1.975016	time 1.6435 (2.0682)	loss 2.8653 (2.8013)	grad_norm 0.4820 (0.4404)	mem 39782MB
[2023-07-07 14:27:56 RepVGG-A0] (main.py 282): INFO Train: [187/300][50/78]	eta 0:00:54 lr 1.971048	time 1.1266 (1.9549)	loss 2.7956 (2.8019)	grad_norm 0.4164 (0.4371)	mem 39782MB
[2023-07-07 14:28:11 RepVGG-A0] (main.py 282): INFO Train: [187/300][60/78]	eta 0:00:33 lr 1.967083	time 1.2880 (1.8795)	loss 2.8092 (2.8033)	grad_norm 0.4245 (0.4376)	mem 39782MB
[2023-07-07 14:28:26 RepVGG-A0] (main.py 282): INFO Train: [187/300][70/78]	eta 0:00:14 lr 1.963119	time 1.4433 (1.8321)	loss 2.8000 (2.8055)	grad_norm 0.3970 (0.4364)	mem 39782MB
[2023-07-07 14:28:38 RepVGG-A0] (main.py 291): INFO EPOCH 187 training takes 0:02:21
[2023-07-07 14:28:59 RepVGG-A0] (main.py 282): INFO Train: [188/300][0/78]	eta 0:27:22 lr 1.959950	time 21.0590 (21.0590)	loss 2.7944 (2.7944)	grad_norm 0.4687 (0.4687)	mem 39782MB
[2023-07-07 14:29:14 RepVGG-A0] (main.py 282): INFO Train: [188/300][10/78]	eta 0:03:40 lr 1.955991	time 1.1912 (3.2417)	loss 2.7924 (2.7991)	grad_norm 0.5163 (0.4936)	mem 39782MB
[2023-07-07 14:29:28 RepVGG-A0] (main.py 282): INFO Train: [188/300][20/78]	eta 0:02:18 lr 1.952034	time 1.1722 (2.3872)	loss 2.7805 (2.7885)	grad_norm 0.4126 (0.4590)	mem 39782MB
[2023-07-07 14:29:44 RepVGG-A0] (main.py 282): INFO Train: [188/300][30/78]	eta 0:01:41 lr 1.948079	time 1.3224 (2.1177)	loss 2.7835 (2.7900)	grad_norm 0.4578 (0.4553)	mem 39782MB
[2023-07-07 14:30:01 RepVGG-A0] (main.py 282): INFO Train: [188/300][40/78]	eta 0:01:16 lr 1.944126	time 2.8125 (2.0166)	loss 2.8404 (2.7878)	grad_norm 0.4701 (0.4472)	mem 39782MB
[2023-07-07 14:30:16 RepVGG-A0] (main.py 282): INFO Train: [188/300][50/78]	eta 0:00:53 lr 1.940176	time 1.1912 (1.9215)	loss 2.8359 (2.7932)	grad_norm 0.4409 (0.4484)	mem 39782MB
[2023-07-07 14:30:31 RepVGG-A0] (main.py 282): INFO Train: [188/300][60/78]	eta 0:00:33 lr 1.936228	time 1.1783 (1.8534)	loss 2.7647 (2.7954)	grad_norm 0.4234 (0.4458)	mem 39782MB
[2023-07-07 14:30:46 RepVGG-A0] (main.py 282): INFO Train: [188/300][70/78]	eta 0:00:14 lr 1.932282	time 1.1707 (1.8046)	loss 2.7951 (2.7982)	grad_norm 0.4376 (0.4440)	mem 39782MB
[2023-07-07 14:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 188 training takes 0:02:19
[2023-07-07 14:31:19 RepVGG-A0] (main.py 282): INFO Train: [189/300][0/78]	eta 0:27:28 lr 1.929127	time 21.1397 (21.1397)	loss 2.7327 (2.7327)	grad_norm 0.4253 (0.4253)	mem 39782MB
[2023-07-07 14:31:34 RepVGG-A0] (main.py 282): INFO Train: [189/300][10/78]	eta 0:03:46 lr 1.925185	time 1.1924 (3.3260)	loss 2.7382 (2.7323)	grad_norm 0.4329 (0.4367)	mem 39782MB
[2023-07-07 14:31:48 RepVGG-A0] (main.py 282): INFO Train: [189/300][20/78]	eta 0:02:19 lr 1.921246	time 1.2052 (2.4106)	loss 2.8540 (2.7722)	grad_norm 0.5442 (0.4628)	mem 39782MB
[2023-07-07 14:32:04 RepVGG-A0] (main.py 282): INFO Train: [189/300][30/78]	eta 0:01:42 lr 1.917309	time 1.3410 (2.1387)	loss 2.8014 (2.7937)	grad_norm 0.4085 (0.4646)	mem 39782MB
[2023-07-07 14:32:21 RepVGG-A0] (main.py 282): INFO Train: [189/300][40/78]	eta 0:01:17 lr 1.913374	time 3.5602 (2.0396)	loss 2.8594 (2.7972)	grad_norm 0.4250 (0.4580)	mem 39782MB
[2023-07-07 14:32:37 RepVGG-A0] (main.py 282): INFO Train: [189/300][50/78]	eta 0:00:54 lr 1.909441	time 1.2175 (1.9413)	loss 2.8559 (2.8006)	grad_norm 0.5137 (0.4555)	mem 39782MB
[2023-07-07 14:32:52 RepVGG-A0] (main.py 282): INFO Train: [189/300][60/78]	eta 0:00:33 lr 1.905511	time 1.1920 (1.8660)	loss 2.8593 (2.8032)	grad_norm 0.4503 (0.4533)	mem 39782MB
[2023-07-07 14:33:07 RepVGG-A0] (main.py 282): INFO Train: [189/300][70/78]	eta 0:00:14 lr 1.901583	time 1.1252 (1.8240)	loss 2.7279 (2.8021)	grad_norm 0.3960 (0.4496)	mem 39782MB
[2023-07-07 14:33:19 RepVGG-A0] (main.py 291): INFO EPOCH 189 training takes 0:02:21
[2023-07-07 14:33:41 RepVGG-A0] (main.py 282): INFO Train: [190/300][0/78]	eta 0:28:48 lr 1.898443	time 22.1575 (22.1575)	loss 2.7222 (2.7222)	grad_norm 0.4072 (0.4072)	mem 39782MB
[2023-07-07 14:33:56 RepVGG-A0] (main.py 282): INFO Train: [190/300][10/78]	eta 0:03:46 lr 1.894519	time 1.1711 (3.3336)	loss 2.7438 (2.7324)	grad_norm 0.4427 (0.4193)	mem 39782MB
[2023-07-07 14:34:10 RepVGG-A0] (main.py 282): INFO Train: [190/300][20/78]	eta 0:02:19 lr 1.890598	time 1.1718 (2.4125)	loss 2.7016 (2.7471)	grad_norm 0.4369 (0.4279)	mem 39782MB
[2023-07-07 14:34:25 RepVGG-A0] (main.py 282): INFO Train: [190/300][30/78]	eta 0:01:41 lr 1.886679	time 1.2536 (2.1234)	loss 2.8229 (2.7536)	grad_norm 0.4388 (0.4329)	mem 39782MB
[2023-07-07 14:34:43 RepVGG-A0] (main.py 282): INFO Train: [190/300][40/78]	eta 0:01:17 lr 1.882763	time 2.8024 (2.0454)	loss 2.7999 (2.7624)	grad_norm 0.4305 (0.4336)	mem 39782MB
[2023-07-07 14:34:59 RepVGG-A0] (main.py 282): INFO Train: [190/300][50/78]	eta 0:00:54 lr 1.878848	time 1.1730 (1.9548)	loss 2.8816 (2.7645)	grad_norm 0.4950 (0.4375)	mem 39782MB
[2023-07-07 14:35:14 RepVGG-A0] (main.py 282): INFO Train: [190/300][60/78]	eta 0:00:33 lr 1.874937	time 1.3416 (1.8810)	loss 2.7913 (2.7692)	grad_norm 0.4458 (0.4381)	mem 39782MB
[2023-07-07 14:35:29 RepVGG-A0] (main.py 282): INFO Train: [190/300][70/78]	eta 0:00:14 lr 1.871027	time 1.1761 (1.8241)	loss 2.8242 (2.7710)	grad_norm 0.4468 (0.4383)	mem 39782MB
[2023-07-07 14:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 190 training takes 0:02:21
[2023-07-07 14:36:02 RepVGG-A0] (main.py 282): INFO Train: [191/300][0/78]	eta 0:28:02 lr 1.867901	time 21.5693 (21.5693)	loss 2.7942 (2.7942)	grad_norm 0.4486 (0.4486)	mem 39782MB
[2023-07-07 14:36:17 RepVGG-A0] (main.py 282): INFO Train: [191/300][10/78]	eta 0:03:48 lr 1.863996	time 1.1720 (3.3556)	loss 2.8316 (2.7522)	grad_norm 0.4554 (0.4545)	mem 39782MB
[2023-07-07 14:36:33 RepVGG-A0] (main.py 282): INFO Train: [191/300][20/78]	eta 0:02:23 lr 1.860094	time 1.1829 (2.4810)	loss 2.7236 (2.7482)	grad_norm 0.4229 (0.4408)	mem 39782MB
[2023-07-07 14:36:48 RepVGG-A0] (main.py 282): INFO Train: [191/300][30/78]	eta 0:01:45 lr 1.856194	time 1.3318 (2.1923)	loss 2.7948 (2.7565)	grad_norm 0.4214 (0.4470)	mem 39782MB
[2023-07-07 14:37:06 RepVGG-A0] (main.py 282): INFO Train: [191/300][40/78]	eta 0:01:19 lr 1.852296	time 3.1639 (2.0949)	loss 2.7572 (2.7593)	grad_norm 0.4349 (0.4468)	mem 39782MB
[2023-07-07 14:37:21 RepVGG-A0] (main.py 282): INFO Train: [191/300][50/78]	eta 0:00:55 lr 1.848400	time 1.1737 (1.9692)	loss 2.7399 (2.7641)	grad_norm 0.4610 (0.4467)	mem 39782MB
[2023-07-07 14:37:36 RepVGG-A0] (main.py 282): INFO Train: [191/300][60/78]	eta 0:00:34 lr 1.844507	time 1.2478 (1.9027)	loss 2.7640 (2.7711)	grad_norm 0.4316 (0.4449)	mem 39782MB
[2023-07-07 14:37:51 RepVGG-A0] (main.py 282): INFO Train: [191/300][70/78]	eta 0:00:14 lr 1.840617	time 1.3078 (1.8425)	loss 2.8077 (2.7704)	grad_norm 0.4229 (0.4425)	mem 39782MB
[2023-07-07 14:38:03 RepVGG-A0] (main.py 291): INFO EPOCH 191 training takes 0:02:22
[2023-07-07 14:38:25 RepVGG-A0] (main.py 282): INFO Train: [192/300][0/78]	eta 0:28:29 lr 1.837506	time 21.9131 (21.9131)	loss 2.7118 (2.7118)	grad_norm 0.4034 (0.4034)	mem 39782MB
[2023-07-07 14:38:39 RepVGG-A0] (main.py 282): INFO Train: [192/300][10/78]	eta 0:03:42 lr 1.833620	time 1.1721 (3.2746)	loss 2.7645 (2.7518)	grad_norm 0.5598 (0.4831)	mem 39782MB
[2023-07-07 14:38:53 RepVGG-A0] (main.py 282): INFO Train: [192/300][20/78]	eta 0:02:18 lr 1.829737	time 1.1717 (2.3826)	loss 2.7472 (2.7772)	grad_norm 0.4680 (0.4719)	mem 39782MB
[2023-07-07 14:39:08 RepVGG-A0] (main.py 282): INFO Train: [192/300][30/78]	eta 0:01:39 lr 1.825855	time 1.4093 (2.0825)	loss 2.7852 (2.7737)	grad_norm 0.4811 (0.4643)	mem 39782MB
[2023-07-07 14:39:27 RepVGG-A0] (main.py 282): INFO Train: [192/300][40/78]	eta 0:01:17 lr 1.821977	time 3.5820 (2.0375)	loss 2.8096 (2.7723)	grad_norm 0.4207 (0.4582)	mem 39782MB
[2023-07-07 14:39:42 RepVGG-A0] (main.py 282): INFO Train: [192/300][50/78]	eta 0:00:54 lr 1.818101	time 1.1723 (1.9354)	loss 2.7032 (2.7746)	grad_norm 0.4156 (0.4537)	mem 39782MB
[2023-07-07 14:39:57 RepVGG-A0] (main.py 282): INFO Train: [192/300][60/78]	eta 0:00:33 lr 1.814227	time 1.3101 (1.8676)	loss 2.7722 (2.7719)	grad_norm 0.4297 (0.4495)	mem 39782MB
[2023-07-07 14:40:12 RepVGG-A0] (main.py 282): INFO Train: [192/300][70/78]	eta 0:00:14 lr 1.810356	time 1.1739 (1.8145)	loss 2.6976 (2.7679)	grad_norm 0.4640 (0.4472)	mem 39782MB
[2023-07-07 14:40:23 RepVGG-A0] (main.py 291): INFO EPOCH 192 training takes 0:02:20
[2023-07-07 14:40:46 RepVGG-A0] (main.py 282): INFO Train: [193/300][0/78]	eta 0:29:15 lr 1.807260	time 22.5015 (22.5015)	loss 2.7380 (2.7380)	grad_norm 0.4036 (0.4036)	mem 39782MB
[2023-07-07 14:41:00 RepVGG-A0] (main.py 282): INFO Train: [193/300][10/78]	eta 0:03:48 lr 1.803394	time 1.1711 (3.3618)	loss 2.7789 (2.7403)	grad_norm 0.4517 (0.4502)	mem 39782MB
[2023-07-07 14:41:14 RepVGG-A0] (main.py 282): INFO Train: [193/300][20/78]	eta 0:02:20 lr 1.799530	time 1.1729 (2.4266)	loss 2.6996 (2.7403)	grad_norm 0.4116 (0.4525)	mem 39782MB
[2023-07-07 14:41:29 RepVGG-A0] (main.py 282): INFO Train: [193/300][30/78]	eta 0:01:41 lr 1.795668	time 1.3318 (2.1218)	loss 2.7769 (2.7395)	grad_norm 0.4694 (0.4457)	mem 39782MB
[2023-07-07 14:41:47 RepVGG-A0] (main.py 282): INFO Train: [193/300][40/78]	eta 0:01:17 lr 1.791809	time 3.7084 (2.0474)	loss 2.7990 (2.7470)	grad_norm 0.4968 (0.4518)	mem 39782MB
[2023-07-07 14:42:03 RepVGG-A0] (main.py 282): INFO Train: [193/300][50/78]	eta 0:00:54 lr 1.787952	time 1.1761 (1.9482)	loss 2.6977 (2.7523)	grad_norm 0.4137 (0.4515)	mem 39782MB
[2023-07-07 14:42:18 RepVGG-A0] (main.py 282): INFO Train: [193/300][60/78]	eta 0:00:33 lr 1.784098	time 1.2184 (1.8861)	loss 2.7691 (2.7500)	grad_norm 0.4364 (0.4494)	mem 39782MB
[2023-07-07 14:42:33 RepVGG-A0] (main.py 282): INFO Train: [193/300][70/78]	eta 0:00:14 lr 1.780247	time 1.1725 (1.8199)	loss 2.7792 (2.7549)	grad_norm 0.4380 (0.4486)	mem 39782MB
[2023-07-07 14:42:44 RepVGG-A0] (main.py 291): INFO EPOCH 193 training takes 0:02:20
[2023-07-07 14:43:04 RepVGG-A0] (main.py 282): INFO Train: [194/300][0/78]	eta 0:26:42 lr 1.777167	time 20.5414 (20.5414)	loss 2.7613 (2.7613)	grad_norm 0.4310 (0.4310)	mem 39782MB
[2023-07-07 14:43:20 RepVGG-A0] (main.py 282): INFO Train: [194/300][10/78]	eta 0:03:44 lr 1.773321	time 1.1721 (3.3051)	loss 2.7506 (2.7196)	grad_norm 0.4425 (0.4408)	mem 39782MB
[2023-07-07 14:43:35 RepVGG-A0] (main.py 282): INFO Train: [194/300][20/78]	eta 0:02:22 lr 1.769476	time 1.2361 (2.4527)	loss 2.7653 (2.7236)	grad_norm 0.4360 (0.4388)	mem 39782MB
[2023-07-07 14:43:51 RepVGG-A0] (main.py 282): INFO Train: [194/300][30/78]	eta 0:01:43 lr 1.765635	time 1.4245 (2.1578)	loss 2.6790 (2.7348)	grad_norm 0.4448 (0.4482)	mem 39782MB
[2023-07-07 14:44:10 RepVGG-A0] (main.py 282): INFO Train: [194/300][40/78]	eta 0:01:19 lr 1.761795	time 4.1277 (2.0970)	loss 2.7309 (2.7460)	grad_norm 0.4704 (0.4508)	mem 39782MB
[2023-07-07 14:44:24 RepVGG-A0] (main.py 282): INFO Train: [194/300][50/78]	eta 0:00:54 lr 1.757959	time 1.1913 (1.9598)	loss 2.7553 (2.7512)	grad_norm 0.4269 (0.4521)	mem 39782MB
[2023-07-07 14:44:40 RepVGG-A0] (main.py 282): INFO Train: [194/300][60/78]	eta 0:00:34 lr 1.754125	time 1.3974 (1.9114)	loss 2.8121 (2.7492)	grad_norm 0.4041 (0.4469)	mem 39782MB
[2023-07-07 14:44:55 RepVGG-A0] (main.py 282): INFO Train: [194/300][70/78]	eta 0:00:14 lr 1.750294	time 1.6165 (1.8441)	loss 2.7448 (2.7531)	grad_norm 0.4861 (0.4503)	mem 39782MB
[2023-07-07 14:45:06 RepVGG-A0] (main.py 291): INFO EPOCH 194 training takes 0:02:22
[2023-07-07 14:45:28 RepVGG-A0] (main.py 282): INFO Train: [195/300][0/78]	eta 0:28:37 lr 1.747230	time 22.0189 (22.0189)	loss 2.6869 (2.6869)	grad_norm 0.4089 (0.4089)	mem 39782MB
[2023-07-07 14:45:43 RepVGG-A0] (main.py 282): INFO Train: [195/300][10/78]	eta 0:03:45 lr 1.743404	time 1.1748 (3.3189)	loss 2.7071 (2.7108)	grad_norm 0.4321 (0.4382)	mem 39782MB
[2023-07-07 14:45:57 RepVGG-A0] (main.py 282): INFO Train: [195/300][20/78]	eta 0:02:20 lr 1.739580	time 1.1721 (2.4243)	loss 2.7121 (2.7192)	grad_norm 0.4999 (0.4435)	mem 39782MB
[2023-07-07 14:46:13 RepVGG-A0] (main.py 282): INFO Train: [195/300][30/78]	eta 0:01:42 lr 1.735758	time 1.2751 (2.1455)	loss 2.6444 (2.7263)	grad_norm 0.3932 (0.4407)	mem 39782MB
[2023-07-07 14:46:31 RepVGG-A0] (main.py 282): INFO Train: [195/300][40/78]	eta 0:01:18 lr 1.731940	time 3.8528 (2.0685)	loss 2.8700 (2.7304)	grad_norm 0.4674 (0.4386)	mem 39782MB
[2023-07-07 14:46:46 RepVGG-A0] (main.py 282): INFO Train: [195/300][50/78]	eta 0:00:54 lr 1.728124	time 1.1743 (1.9574)	loss 2.7710 (2.7364)	grad_norm 0.4913 (0.4462)	mem 39782MB
[2023-07-07 14:47:01 RepVGG-A0] (main.py 282): INFO Train: [195/300][60/78]	eta 0:00:33 lr 1.724310	time 1.2828 (1.8846)	loss 2.7376 (2.7363)	grad_norm 0.4378 (0.4458)	mem 39782MB
[2023-07-07 14:47:16 RepVGG-A0] (main.py 282): INFO Train: [195/300][70/78]	eta 0:00:14 lr 1.720499	time 1.2327 (1.8305)	loss 2.7615 (2.7406)	grad_norm 0.4418 (0.4459)	mem 39782MB
[2023-07-07 14:47:28 RepVGG-A0] (main.py 291): INFO EPOCH 195 training takes 0:02:21
[2023-07-07 14:47:49 RepVGG-A0] (main.py 282): INFO Train: [196/300][0/78]	eta 0:27:45 lr 1.717453	time 21.3574 (21.3574)	loss 2.6917 (2.6917)	grad_norm 0.4320 (0.4320)	mem 39782MB
[2023-07-07 14:48:04 RepVGG-A0] (main.py 282): INFO Train: [196/300][10/78]	eta 0:03:41 lr 1.713647	time 1.1719 (3.2620)	loss 2.7054 (2.7154)	grad_norm 0.4881 (0.4478)	mem 39782MB
[2023-07-07 14:48:18 RepVGG-A0] (main.py 282): INFO Train: [196/300][20/78]	eta 0:02:18 lr 1.709843	time 1.1735 (2.3827)	loss 2.7111 (2.7132)	grad_norm 0.4865 (0.4532)	mem 39782MB
[2023-07-07 14:48:34 RepVGG-A0] (main.py 282): INFO Train: [196/300][30/78]	eta 0:01:42 lr 1.706043	time 1.3127 (2.1361)	loss 2.7271 (2.7211)	grad_norm 0.4468 (0.4531)	mem 39782MB
[2023-07-07 14:48:52 RepVGG-A0] (main.py 282): INFO Train: [196/300][40/78]	eta 0:01:18 lr 1.702245	time 4.0271 (2.0533)	loss 2.7117 (2.7266)	grad_norm 0.4458 (0.4542)	mem 39782MB
[2023-07-07 14:49:07 RepVGG-A0] (main.py 282): INFO Train: [196/300][50/78]	eta 0:00:54 lr 1.698450	time 1.1723 (1.9412)	loss 2.8157 (2.7397)	grad_norm 0.4323 (0.4534)	mem 39782MB
[2023-07-07 14:49:22 RepVGG-A0] (main.py 282): INFO Train: [196/300][60/78]	eta 0:00:33 lr 1.694657	time 1.3288 (1.8707)	loss 2.7311 (2.7400)	grad_norm 0.4516 (0.4499)	mem 39782MB
[2023-07-07 14:49:38 RepVGG-A0] (main.py 282): INFO Train: [196/300][70/78]	eta 0:00:14 lr 1.690867	time 1.1690 (1.8346)	loss 2.8379 (2.7424)	grad_norm 0.4302 (0.4485)	mem 39782MB
[2023-07-07 14:49:49 RepVGG-A0] (main.py 291): INFO EPOCH 196 training takes 0:02:21
[2023-07-07 14:50:11 RepVGG-A0] (main.py 282): INFO Train: [197/300][0/78]	eta 0:28:33 lr 1.687838	time 21.9694 (21.9694)	loss 2.7939 (2.7939)	grad_norm 0.4770 (0.4770)	mem 39782MB
[2023-07-07 14:50:26 RepVGG-A0] (main.py 282): INFO Train: [197/300][10/78]	eta 0:03:48 lr 1.684053	time 1.1707 (3.3589)	loss 2.7629 (2.7070)	grad_norm 0.4498 (0.4401)	mem 39782MB
[2023-07-07 14:50:41 RepVGG-A0] (main.py 282): INFO Train: [197/300][20/78]	eta 0:02:23 lr 1.680271	time 1.2875 (2.4668)	loss 2.6745 (2.7110)	grad_norm 0.4524 (0.4523)	mem 39782MB
[2023-07-07 14:50:56 RepVGG-A0] (main.py 282): INFO Train: [197/300][30/78]	eta 0:01:43 lr 1.676491	time 1.2722 (2.1530)	loss 2.7396 (2.7198)	grad_norm 0.4815 (0.4515)	mem 39782MB
[2023-07-07 14:51:14 RepVGG-A0] (main.py 282): INFO Train: [197/300][40/78]	eta 0:01:18 lr 1.672714	time 4.1162 (2.0645)	loss 2.7603 (2.7295)	grad_norm 0.4727 (0.4603)	mem 39782MB
[2023-07-07 14:51:29 RepVGG-A0] (main.py 282): INFO Train: [197/300][50/78]	eta 0:00:54 lr 1.668941	time 1.3380 (1.9621)	loss 2.7617 (2.7303)	grad_norm 0.4550 (0.4557)	mem 39782MB
[2023-07-07 14:51:45 RepVGG-A0] (main.py 282): INFO Train: [197/300][60/78]	eta 0:00:34 lr 1.665169	time 1.3056 (1.8958)	loss 2.7337 (2.7363)	grad_norm 0.4759 (0.4596)	mem 39782MB
[2023-07-07 14:52:00 RepVGG-A0] (main.py 282): INFO Train: [197/300][70/78]	eta 0:00:14 lr 1.661401	time 1.1767 (1.8404)	loss 2.7629 (2.7391)	grad_norm 0.4191 (0.4553)	mem 39782MB
[2023-07-07 14:52:13 RepVGG-A0] (main.py 291): INFO EPOCH 197 training takes 0:02:23
[2023-07-07 14:52:34 RepVGG-A0] (main.py 282): INFO Train: [198/300][0/78]	eta 0:27:25 lr 1.658388	time 21.0998 (21.0998)	loss 2.7096 (2.7096)	grad_norm 0.4569 (0.4569)	mem 39782MB
[2023-07-07 14:52:50 RepVGG-A0] (main.py 282): INFO Train: [198/300][10/78]	eta 0:03:49 lr 1.654625	time 1.1732 (3.3813)	loss 2.7354 (2.7091)	grad_norm 0.4549 (0.4517)	mem 39782MB
[2023-07-07 14:53:04 RepVGG-A0] (main.py 282): INFO Train: [198/300][20/78]	eta 0:02:22 lr 1.650864	time 1.1732 (2.4618)	loss 2.7297 (2.7089)	grad_norm 0.4598 (0.4501)	mem 39782MB
[2023-07-07 14:53:19 RepVGG-A0] (main.py 282): INFO Train: [198/300][30/78]	eta 0:01:43 lr 1.647106	time 1.2552 (2.1498)	loss 2.7088 (2.7105)	grad_norm 0.4697 (0.4514)	mem 39782MB
[2023-07-07 14:53:39 RepVGG-A0] (main.py 282): INFO Train: [198/300][40/78]	eta 0:01:19 lr 1.643351	time 3.1974 (2.0940)	loss 2.7031 (2.7158)	grad_norm 0.4484 (0.4539)	mem 39782MB
[2023-07-07 14:53:53 RepVGG-A0] (main.py 282): INFO Train: [198/300][50/78]	eta 0:00:55 lr 1.639599	time 1.2779 (1.9742)	loss 2.7684 (2.7188)	grad_norm 0.4767 (0.4527)	mem 39782MB
[2023-07-07 14:54:08 RepVGG-A0] (main.py 282): INFO Train: [198/300][60/78]	eta 0:00:33 lr 1.635850	time 1.2152 (1.8833)	loss 2.7158 (2.7223)	grad_norm 0.4818 (0.4556)	mem 39782MB
[2023-07-07 14:54:23 RepVGG-A0] (main.py 282): INFO Train: [198/300][70/78]	eta 0:00:14 lr 1.632103	time 1.2890 (1.8416)	loss 2.8423 (2.7255)	grad_norm 0.4412 (0.4538)	mem 39782MB
[2023-07-07 14:54:35 RepVGG-A0] (main.py 291): INFO EPOCH 198 training takes 0:02:22
[2023-07-07 14:54:55 RepVGG-A0] (main.py 282): INFO Train: [199/300][0/78]	eta 0:25:46 lr 1.629108	time 19.8210 (19.8210)	loss 2.7051 (2.7051)	grad_norm 0.5080 (0.5080)	mem 39782MB
[2023-07-07 14:55:11 RepVGG-A0] (main.py 282): INFO Train: [199/300][10/78]	eta 0:03:40 lr 1.625367	time 1.1929 (3.2411)	loss 2.7005 (2.6806)	grad_norm 0.4871 (0.4536)	mem 39782MB
[2023-07-07 14:55:25 RepVGG-A0] (main.py 282): INFO Train: [199/300][20/78]	eta 0:02:17 lr 1.621628	time 1.1745 (2.3730)	loss 2.6853 (2.7036)	grad_norm 0.4320 (0.4726)	mem 39782MB
[2023-07-07 14:55:41 RepVGG-A0] (main.py 282): INFO Train: [199/300][30/78]	eta 0:01:40 lr 1.617892	time 1.3064 (2.1033)	loss 2.7218 (2.7039)	grad_norm 0.4160 (0.4564)	mem 39782MB
[2023-07-07 14:55:57 RepVGG-A0] (main.py 282): INFO Train: [199/300][40/78]	eta 0:01:15 lr 1.614159	time 2.3511 (1.9794)	loss 2.7171 (2.7095)	grad_norm 0.4930 (0.4578)	mem 39782MB
[2023-07-07 14:56:13 RepVGG-A0] (main.py 282): INFO Train: [199/300][50/78]	eta 0:00:53 lr 1.610429	time 1.3414 (1.9088)	loss 2.7459 (2.7119)	grad_norm 0.4328 (0.4530)	mem 39782MB
[2023-07-07 14:56:28 RepVGG-A0] (main.py 282): INFO Train: [199/300][60/78]	eta 0:00:33 lr 1.606702	time 1.2092 (1.8453)	loss 2.7044 (2.7161)	grad_norm 0.4593 (0.4521)	mem 39782MB
[2023-07-07 14:56:43 RepVGG-A0] (main.py 282): INFO Train: [199/300][70/78]	eta 0:00:14 lr 1.602977	time 1.1719 (1.7964)	loss 2.7396 (2.7176)	grad_norm 0.4478 (0.4521)	mem 39782MB
[2023-07-07 14:56:55 RepVGG-A0] (main.py 291): INFO EPOCH 199 training takes 0:02:19
[2023-07-07 14:57:17 RepVGG-A0] (main.py 282): INFO Train: [200/300][0/78]	eta 0:28:28 lr 1.600000	time 21.9001 (21.9001)	loss 2.6729 (2.6729)	grad_norm 0.4235 (0.4235)	mem 39782MB
[2023-07-07 14:57:32 RepVGG-A0] (main.py 282): INFO Train: [200/300][10/78]	eta 0:03:49 lr 1.596281	time 1.1722 (3.3681)	loss 2.7803 (2.7252)	grad_norm 0.4494 (0.4678)	mem 39782MB
[2023-07-07 14:57:46 RepVGG-A0] (main.py 282): INFO Train: [200/300][20/78]	eta 0:02:21 lr 1.592565	time 1.2779 (2.4446)	loss 2.6850 (2.7132)	grad_norm 0.4626 (0.4614)	mem 39782MB
[2023-07-07 14:58:02 RepVGG-A0] (main.py 282): INFO Train: [200/300][30/78]	eta 0:01:43 lr 1.588851	time 1.3454 (2.1628)	loss 2.6888 (2.7071)	grad_norm 0.4165 (0.4536)	mem 39782MB
[2023-07-07 14:58:19 RepVGG-A0] (main.py 282): INFO Train: [200/300][40/78]	eta 0:01:17 lr 1.585141	time 3.4777 (2.0466)	loss 2.7147 (2.7107)	grad_norm 0.4453 (0.4541)	mem 39782MB
[2023-07-07 14:58:35 RepVGG-A0] (main.py 282): INFO Train: [200/300][50/78]	eta 0:00:54 lr 1.581433	time 1.1924 (1.9629)	loss 2.6632 (2.7090)	grad_norm 0.4563 (0.4536)	mem 39782MB
[2023-07-07 14:58:50 RepVGG-A0] (main.py 282): INFO Train: [200/300][60/78]	eta 0:00:34 lr 1.577728	time 1.1634 (1.8918)	loss 2.7213 (2.7140)	grad_norm 0.4873 (0.4545)	mem 39782MB
[2023-07-07 14:59:06 RepVGG-A0] (main.py 282): INFO Train: [200/300][70/78]	eta 0:00:14 lr 1.574027	time 1.4598 (1.8458)	loss 2.6912 (2.7167)	grad_norm 0.4348 (0.4551)	mem 39782MB
[2023-07-07 14:59:17 RepVGG-A0] (main.py 291): INFO EPOCH 200 training takes 0:02:22
[2023-07-07 14:59:34 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.565 (17.565)	Loss 2.1103 (2.1103)	Acc@1 54.468 (54.468)	Acc@5 78.546 (78.546)	Mem 39782MB
[2023-07-07 14:59:35 RepVGG-A0] (main.py 342): INFO  * Acc@1 54.550 Acc@5 78.434
[2023-07-07 14:59:35 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 200: 54.550%
[2023-07-07 14:59:35 RepVGG-A0] (main.py 172): INFO Max accuracy: 54.55%
[2023-07-07 14:59:58 RepVGG-A0] (main.py 282): INFO Train: [201/300][0/78]	eta 0:29:11 lr 1.571067	time 22.4546 (22.4546)	loss 2.7303 (2.7303)	grad_norm 0.4643 (0.4643)	mem 39782MB
[2023-07-07 15:00:12 RepVGG-A0] (main.py 282): INFO Train: [201/300][10/78]	eta 0:03:48 lr 1.567371	time 1.1722 (3.3660)	loss 2.6831 (2.6801)	grad_norm 0.4720 (0.4569)	mem 39782MB
[2023-07-07 15:00:27 RepVGG-A0] (main.py 282): INFO Train: [201/300][20/78]	eta 0:02:21 lr 1.563678	time 1.1506 (2.4429)	loss 2.6666 (2.6908)	grad_norm 0.4784 (0.4527)	mem 39782MB
[2023-07-07 15:00:42 RepVGG-A0] (main.py 282): INFO Train: [201/300][30/78]	eta 0:01:42 lr 1.559987	time 1.3441 (2.1355)	loss 2.7135 (2.6978)	grad_norm 0.4531 (0.4595)	mem 39782MB
[2023-07-07 15:01:00 RepVGG-A0] (main.py 282): INFO Train: [201/300][40/78]	eta 0:01:18 lr 1.556299	time 4.4155 (2.0622)	loss 2.7060 (2.7021)	grad_norm 0.4294 (0.4565)	mem 39782MB
[2023-07-07 15:01:15 RepVGG-A0] (main.py 282): INFO Train: [201/300][50/78]	eta 0:00:54 lr 1.552615	time 1.1715 (1.9453)	loss 2.7473 (2.7054)	grad_norm 0.4932 (0.4562)	mem 39782MB
[2023-07-07 15:01:30 RepVGG-A0] (main.py 282): INFO Train: [201/300][60/78]	eta 0:00:33 lr 1.548933	time 1.3048 (1.8818)	loss 2.7218 (2.7155)	grad_norm 0.4492 (0.4645)	mem 39782MB
[2023-07-07 15:01:45 RepVGG-A0] (main.py 282): INFO Train: [201/300][70/78]	eta 0:00:14 lr 1.545254	time 1.1713 (1.8253)	loss 2.6404 (2.7167)	grad_norm 0.4466 (0.4634)	mem 39782MB
[2023-07-07 15:01:57 RepVGG-A0] (main.py 291): INFO EPOCH 201 training takes 0:02:21
[2023-07-07 15:02:19 RepVGG-A0] (main.py 282): INFO Train: [202/300][0/78]	eta 0:28:02 lr 1.542314	time 21.5702 (21.5702)	loss 2.6939 (2.6939)	grad_norm 0.4479 (0.4479)	mem 39782MB
[2023-07-07 15:02:33 RepVGG-A0] (main.py 282): INFO Train: [202/300][10/78]	eta 0:03:43 lr 1.538640	time 1.1700 (3.2901)	loss 2.7124 (2.6850)	grad_norm 0.4152 (0.4501)	mem 39782MB
[2023-07-07 15:02:48 RepVGG-A0] (main.py 282): INFO Train: [202/300][20/78]	eta 0:02:22 lr 1.534970	time 1.3004 (2.4537)	loss 2.7191 (2.6895)	grad_norm 0.4604 (0.4558)	mem 39782MB
[2023-07-07 15:03:03 RepVGG-A0] (main.py 282): INFO Train: [202/300][30/78]	eta 0:01:42 lr 1.531303	time 1.1821 (2.1341)	loss 2.7135 (2.6920)	grad_norm 0.4561 (0.4486)	mem 39782MB
[2023-07-07 15:03:22 RepVGG-A0] (main.py 282): INFO Train: [202/300][40/78]	eta 0:01:18 lr 1.527638	time 3.8714 (2.0692)	loss 2.6844 (2.6998)	grad_norm 0.5535 (0.4623)	mem 39782MB
[2023-07-07 15:03:36 RepVGG-A0] (main.py 282): INFO Train: [202/300][50/78]	eta 0:00:54 lr 1.523977	time 1.1761 (1.9480)	loss 2.6881 (2.7013)	grad_norm 0.4480 (0.4585)	mem 39782MB
[2023-07-07 15:03:52 RepVGG-A0] (main.py 282): INFO Train: [202/300][60/78]	eta 0:00:33 lr 1.520319	time 1.3701 (1.8845)	loss 2.7143 (2.7029)	grad_norm 0.4488 (0.4556)	mem 39782MB
[2023-07-07 15:04:06 RepVGG-A0] (main.py 282): INFO Train: [202/300][70/78]	eta 0:00:14 lr 1.516663	time 1.2559 (1.8216)	loss 2.6731 (2.7041)	grad_norm 0.4678 (0.4571)	mem 39782MB
[2023-07-07 15:04:18 RepVGG-A0] (main.py 291): INFO EPOCH 202 training takes 0:02:20
[2023-07-07 15:04:39 RepVGG-A0] (main.py 282): INFO Train: [203/300][0/78]	eta 0:27:32 lr 1.513741	time 21.1917 (21.1917)	loss 2.6902 (2.6902)	grad_norm 0.4610 (0.4610)	mem 39782MB
[2023-07-07 15:04:54 RepVGG-A0] (main.py 282): INFO Train: [203/300][10/78]	eta 0:03:42 lr 1.510092	time 1.1726 (3.2670)	loss 2.6010 (2.6673)	grad_norm 0.4398 (0.4600)	mem 39782MB
[2023-07-07 15:05:09 RepVGG-A0] (main.py 282): INFO Train: [203/300][20/78]	eta 0:02:22 lr 1.506445	time 1.4797 (2.4544)	loss 2.6808 (2.6767)	grad_norm 0.4564 (0.4558)	mem 39782MB
[2023-07-07 15:05:24 RepVGG-A0] (main.py 282): INFO Train: [203/300][30/78]	eta 0:01:42 lr 1.502801	time 1.3469 (2.1302)	loss 2.6891 (2.6798)	grad_norm 0.4566 (0.4520)	mem 39782MB
[2023-07-07 15:05:41 RepVGG-A0] (main.py 282): INFO Train: [203/300][40/78]	eta 0:01:17 lr 1.499161	time 2.0998 (2.0274)	loss 2.6895 (2.6859)	grad_norm 0.4678 (0.4598)	mem 39782MB
[2023-07-07 15:05:56 RepVGG-A0] (main.py 282): INFO Train: [203/300][50/78]	eta 0:00:54 lr 1.495523	time 1.1715 (1.9321)	loss 2.6444 (2.6884)	grad_norm 0.4720 (0.4575)	mem 39782MB
[2023-07-07 15:06:11 RepVGG-A0] (main.py 282): INFO Train: [203/300][60/78]	eta 0:00:33 lr 1.491889	time 1.2677 (1.8589)	loss 2.7444 (2.6909)	grad_norm 0.4767 (0.4594)	mem 39782MB
[2023-07-07 15:06:26 RepVGG-A0] (main.py 282): INFO Train: [203/300][70/78]	eta 0:00:14 lr 1.488257	time 1.3802 (1.8065)	loss 2.6948 (2.6910)	grad_norm 0.4470 (0.4568)	mem 39782MB
[2023-07-07 15:06:38 RepVGG-A0] (main.py 291): INFO EPOCH 203 training takes 0:02:20
[2023-07-07 15:06:58 RepVGG-A0] (main.py 282): INFO Train: [204/300][0/78]	eta 0:26:07 lr 1.485354	time 20.0980 (20.0980)	loss 2.6216 (2.6216)	grad_norm 0.4325 (0.4325)	mem 39782MB
[2023-07-07 15:07:13 RepVGG-A0] (main.py 282): INFO Train: [204/300][10/78]	eta 0:03:37 lr 1.481728	time 1.1722 (3.1939)	loss 2.7222 (2.6795)	grad_norm 0.4687 (0.4776)	mem 39782MB
[2023-07-07 15:07:29 RepVGG-A0] (main.py 282): INFO Train: [204/300][20/78]	eta 0:02:19 lr 1.478106	time 1.1761 (2.4126)	loss 2.6679 (2.6743)	grad_norm 0.4837 (0.4665)	mem 39782MB
[2023-07-07 15:07:45 RepVGG-A0] (main.py 282): INFO Train: [204/300][30/78]	eta 0:01:42 lr 1.474486	time 1.3491 (2.1421)	loss 2.6997 (2.6846)	grad_norm 0.4788 (0.4724)	mem 39782MB
[2023-07-07 15:08:02 RepVGG-A0] (main.py 282): INFO Train: [204/300][40/78]	eta 0:01:18 lr 1.470869	time 2.3424 (2.0549)	loss 2.6651 (2.6847)	grad_norm 0.4729 (0.4648)	mem 39782MB
[2023-07-07 15:08:17 RepVGG-A0] (main.py 282): INFO Train: [204/300][50/78]	eta 0:00:54 lr 1.467256	time 1.1739 (1.9404)	loss 2.6856 (2.6960)	grad_norm 0.4387 (0.4709)	mem 39782MB
[2023-07-07 15:08:33 RepVGG-A0] (main.py 282): INFO Train: [204/300][60/78]	eta 0:00:33 lr 1.463646	time 1.4898 (1.8801)	loss 2.6856 (2.6952)	grad_norm 0.4452 (0.4674)	mem 39782MB
[2023-07-07 15:08:47 RepVGG-A0] (main.py 282): INFO Train: [204/300][70/78]	eta 0:00:14 lr 1.460039	time 1.1927 (1.8145)	loss 2.7886 (2.6961)	grad_norm 0.5104 (0.4689)	mem 39782MB
[2023-07-07 15:08:59 RepVGG-A0] (main.py 291): INFO EPOCH 204 training takes 0:02:20
[2023-07-07 15:09:19 RepVGG-A0] (main.py 282): INFO Train: [205/300][0/78]	eta 0:25:23 lr 1.457155	time 19.5364 (19.5364)	loss 2.6544 (2.6544)	grad_norm 0.4268 (0.4268)	mem 39782MB
[2023-07-07 15:09:35 RepVGG-A0] (main.py 282): INFO Train: [205/300][10/78]	eta 0:03:41 lr 1.453554	time 1.1722 (3.2584)	loss 2.7123 (2.6673)	grad_norm 0.5214 (0.4603)	mem 39782MB
[2023-07-07 15:09:51 RepVGG-A0] (main.py 282): INFO Train: [205/300][20/78]	eta 0:02:23 lr 1.449955	time 1.2844 (2.4767)	loss 2.7212 (2.6744)	grad_norm 0.4474 (0.4633)	mem 39782MB
[2023-07-07 15:10:06 RepVGG-A0] (main.py 282): INFO Train: [205/300][30/78]	eta 0:01:43 lr 1.446360	time 1.2385 (2.1590)	loss 2.6908 (2.6755)	grad_norm 0.4202 (0.4566)	mem 39782MB
[2023-07-07 15:10:23 RepVGG-A0] (main.py 282): INFO Train: [205/300][40/78]	eta 0:01:17 lr 1.442768	time 2.1649 (2.0485)	loss 2.6661 (2.6831)	grad_norm 0.4638 (0.4551)	mem 39782MB
[2023-07-07 15:10:38 RepVGG-A0] (main.py 282): INFO Train: [205/300][50/78]	eta 0:00:54 lr 1.439179	time 1.1735 (1.9351)	loss 2.6901 (2.6842)	grad_norm 0.4931 (0.4569)	mem 39782MB
[2023-07-07 15:10:53 RepVGG-A0] (main.py 282): INFO Train: [205/300][60/78]	eta 0:00:33 lr 1.435593	time 1.1901 (1.8631)	loss 2.6265 (2.6824)	grad_norm 0.4572 (0.4584)	mem 39782MB
[2023-07-07 15:11:10 RepVGG-A0] (main.py 282): INFO Train: [205/300][70/78]	eta 0:00:14 lr 1.432011	time 1.4702 (1.8380)	loss 2.6398 (2.6834)	grad_norm 0.4536 (0.4589)	mem 39782MB
[2023-07-07 15:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 205 training takes 0:02:21
[2023-07-07 15:11:42 RepVGG-A0] (main.py 282): INFO Train: [206/300][0/78]	eta 0:28:27 lr 1.429147	time 21.8961 (21.8961)	loss 2.6018 (2.6018)	grad_norm 0.4490 (0.4490)	mem 39782MB
[2023-07-07 15:11:58 RepVGG-A0] (main.py 282): INFO Train: [206/300][10/78]	eta 0:03:50 lr 1.425570	time 1.2045 (3.3923)	loss 2.6485 (2.6429)	grad_norm 0.5078 (0.4835)	mem 39782MB
[2023-07-07 15:12:13 RepVGG-A0] (main.py 282): INFO Train: [206/300][20/78]	eta 0:02:24 lr 1.421997	time 1.2890 (2.4859)	loss 2.6471 (2.6569)	grad_norm 0.4207 (0.4753)	mem 39782MB
[2023-07-07 15:12:28 RepVGG-A0] (main.py 282): INFO Train: [206/300][30/78]	eta 0:01:44 lr 1.418426	time 1.2568 (2.1754)	loss 2.6662 (2.6553)	grad_norm 0.4883 (0.4718)	mem 39782MB
[2023-07-07 15:12:48 RepVGG-A0] (main.py 282): INFO Train: [206/300][40/78]	eta 0:01:20 lr 1.414859	time 2.8359 (2.1246)	loss 2.7408 (2.6617)	grad_norm 0.4709 (0.4731)	mem 39782MB
[2023-07-07 15:13:03 RepVGG-A0] (main.py 282): INFO Train: [206/300][50/78]	eta 0:00:56 lr 1.411295	time 1.1716 (2.0036)	loss 2.7175 (2.6668)	grad_norm 0.4930 (0.4689)	mem 39782MB
[2023-07-07 15:13:18 RepVGG-A0] (main.py 282): INFO Train: [206/300][60/78]	eta 0:00:34 lr 1.407734	time 1.1275 (1.9341)	loss 2.7345 (2.6689)	grad_norm 0.4478 (0.4682)	mem 39782MB
[2023-07-07 15:13:33 RepVGG-A0] (main.py 282): INFO Train: [206/300][70/78]	eta 0:00:14 lr 1.404177	time 1.3773 (1.8721)	loss 2.7061 (2.6722)	grad_norm 0.5127 (0.4701)	mem 39782MB
[2023-07-07 15:13:45 RepVGG-A0] (main.py 291): INFO EPOCH 206 training takes 0:02:24
[2023-07-07 15:14:07 RepVGG-A0] (main.py 282): INFO Train: [207/300][0/78]	eta 0:28:37 lr 1.401333	time 22.0201 (22.0201)	loss 2.5902 (2.5902)	grad_norm 0.4561 (0.4561)	mem 39782MB
[2023-07-07 15:14:22 RepVGG-A0] (main.py 282): INFO Train: [207/300][10/78]	eta 0:03:48 lr 1.397782	time 1.1971 (3.3564)	loss 2.6204 (2.6255)	grad_norm 0.4834 (0.4459)	mem 39782MB
[2023-07-07 15:14:36 RepVGG-A0] (main.py 282): INFO Train: [207/300][20/78]	eta 0:02:20 lr 1.394233	time 1.1750 (2.4307)	loss 2.6703 (2.6400)	grad_norm 0.4360 (0.4585)	mem 39782MB
[2023-07-07 15:14:51 RepVGG-A0] (main.py 282): INFO Train: [207/300][30/78]	eta 0:01:41 lr 1.390688	time 1.3341 (2.1244)	loss 2.6206 (2.6480)	grad_norm 0.4687 (0.4598)	mem 39782MB
[2023-07-07 15:15:10 RepVGG-A0] (main.py 282): INFO Train: [207/300][40/78]	eta 0:01:18 lr 1.387146	time 3.1608 (2.0607)	loss 2.7590 (2.6570)	grad_norm 0.4621 (0.4605)	mem 39782MB
[2023-07-07 15:15:25 RepVGG-A0] (main.py 282): INFO Train: [207/300][50/78]	eta 0:00:54 lr 1.383607	time 1.1714 (1.9551)	loss 2.7001 (2.6630)	grad_norm 0.4694 (0.4593)	mem 39782MB
[2023-07-07 15:15:39 RepVGG-A0] (main.py 282): INFO Train: [207/300][60/78]	eta 0:00:33 lr 1.380072	time 1.1781 (1.8730)	loss 2.6447 (2.6668)	grad_norm 0.4483 (0.4621)	mem 39782MB
[2023-07-07 15:15:55 RepVGG-A0] (main.py 282): INFO Train: [207/300][70/78]	eta 0:00:14 lr 1.376540	time 1.4367 (1.8257)	loss 2.6887 (2.6722)	grad_norm 0.5273 (0.4610)	mem 39782MB
[2023-07-07 15:16:06 RepVGG-A0] (main.py 291): INFO EPOCH 207 training takes 0:02:20
[2023-07-07 15:16:27 RepVGG-A0] (main.py 282): INFO Train: [208/300][0/78]	eta 0:27:28 lr 1.373717	time 21.1316 (21.1316)	loss 2.7189 (2.7189)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:16:42 RepVGG-A0] (main.py 282): INFO Train: [208/300][10/78]	eta 0:03:40 lr 1.370190	time 1.1729 (3.2402)	loss 2.5788 (2.6494)	grad_norm 0.4304 (0.4576)	mem 39782MB
[2023-07-07 15:16:56 RepVGG-A0] (main.py 282): INFO Train: [208/300][20/78]	eta 0:02:17 lr 1.366668	time 1.1717 (2.3769)	loss 2.6790 (2.6403)	grad_norm 0.5722 (0.4871)	mem 39782MB
[2023-07-07 15:17:10 RepVGG-A0] (main.py 282): INFO Train: [208/300][30/78]	eta 0:01:39 lr 1.363148	time 1.2169 (2.0701)	loss 2.6360 (2.6534)	grad_norm 0.4372 (0.4908)	mem 39782MB
[2023-07-07 15:17:30 RepVGG-A0] (main.py 282): INFO Train: [208/300][40/78]	eta 0:01:17 lr 1.359632	time 5.4407 (2.0444)	loss 2.6619 (2.6546)	grad_norm 0.4529 (0.4803)	mem 39782MB
[2023-07-07 15:17:45 RepVGG-A0] (main.py 282): INFO Train: [208/300][50/78]	eta 0:00:54 lr 1.356119	time 1.1738 (1.9392)	loss 2.6682 (2.6565)	grad_norm 0.4589 (0.4742)	mem 39782MB
[2023-07-07 15:18:00 RepVGG-A0] (main.py 282): INFO Train: [208/300][60/78]	eta 0:00:33 lr 1.352609	time 1.1776 (1.8710)	loss 2.7140 (2.6652)	grad_norm 0.5027 (0.4740)	mem 39782MB
[2023-07-07 15:18:15 RepVGG-A0] (main.py 282): INFO Train: [208/300][70/78]	eta 0:00:14 lr 1.349103	time 1.3052 (1.8156)	loss 2.6718 (2.6658)	grad_norm 0.4364 (0.4734)	mem 39782MB
[2023-07-07 15:18:27 RepVGG-A0] (main.py 291): INFO EPOCH 208 training takes 0:02:20
[2023-07-07 15:18:48 RepVGG-A0] (main.py 282): INFO Train: [209/300][0/78]	eta 0:27:53 lr 1.346300	time 21.4611 (21.4611)	loss 2.6057 (2.6057)	grad_norm 0.4722 (0.4722)	mem 39782MB
[2023-07-07 15:19:04 RepVGG-A0] (main.py 282): INFO Train: [209/300][10/78]	eta 0:03:49 lr 1.342800	time 1.1729 (3.3795)	loss 2.5861 (2.6153)	grad_norm 0.4505 (0.4658)	mem 39782MB
[2023-07-07 15:19:19 RepVGG-A0] (main.py 282): INFO Train: [209/300][20/78]	eta 0:02:24 lr 1.339303	time 1.4114 (2.4838)	loss 2.6517 (2.6253)	grad_norm 0.4839 (0.4602)	mem 39782MB
[2023-07-07 15:19:34 RepVGG-A0] (main.py 282): INFO Train: [209/300][30/78]	eta 0:01:44 lr 1.335809	time 1.1263 (2.1794)	loss 2.5577 (2.6325)	grad_norm 0.4522 (0.4636)	mem 39782MB
[2023-07-07 15:19:53 RepVGG-A0] (main.py 282): INFO Train: [209/300][40/78]	eta 0:01:19 lr 1.332319	time 4.2605 (2.0915)	loss 2.7131 (2.6376)	grad_norm 0.4650 (0.4680)	mem 39782MB
[2023-07-07 15:20:07 RepVGG-A0] (main.py 282): INFO Train: [209/300][50/78]	eta 0:00:54 lr 1.328832	time 1.1755 (1.9641)	loss 2.7158 (2.6428)	grad_norm 0.4505 (0.4659)	mem 39782MB
[2023-07-07 15:20:23 RepVGG-A0] (main.py 282): INFO Train: [209/300][60/78]	eta 0:00:34 lr 1.325349	time 1.2248 (1.8949)	loss 2.6604 (2.6492)	grad_norm 0.4856 (0.4687)	mem 39782MB
[2023-07-07 15:20:38 RepVGG-A0] (main.py 282): INFO Train: [209/300][70/78]	eta 0:00:14 lr 1.321869	time 1.2959 (1.8424)	loss 2.6882 (2.6533)	grad_norm 0.4369 (0.4675)	mem 39782MB
[2023-07-07 15:20:49 RepVGG-A0] (main.py 291): INFO EPOCH 209 training takes 0:02:22
[2023-07-07 15:21:10 RepVGG-A0] (main.py 282): INFO Train: [210/300][0/78]	eta 0:27:10 lr 1.319087	time 20.9090 (20.9090)	loss 2.5784 (2.5784)	grad_norm 0.4836 (0.4836)	mem 39782MB
[2023-07-07 15:21:24 RepVGG-A0] (main.py 282): INFO Train: [210/300][10/78]	eta 0:03:34 lr 1.315613	time 1.1722 (3.1566)	loss 2.6052 (2.6012)	grad_norm 0.4594 (0.4600)	mem 39782MB
[2023-07-07 15:21:38 RepVGG-A0] (main.py 282): INFO Train: [210/300][20/78]	eta 0:02:15 lr 1.312143	time 1.1730 (2.3373)	loss 2.6405 (2.6198)	grad_norm 0.4737 (0.4724)	mem 39782MB
[2023-07-07 15:21:54 RepVGG-A0] (main.py 282): INFO Train: [210/300][30/78]	eta 0:01:39 lr 1.308675	time 1.3585 (2.0823)	loss 2.7082 (2.6294)	grad_norm 0.4746 (0.4716)	mem 39782MB
[2023-07-07 15:22:11 RepVGG-A0] (main.py 282): INFO Train: [210/300][40/78]	eta 0:01:15 lr 1.305212	time 3.2474 (1.9940)	loss 2.6999 (2.6297)	grad_norm 0.4621 (0.4693)	mem 39782MB
[2023-07-07 15:22:27 RepVGG-A0] (main.py 282): INFO Train: [210/300][50/78]	eta 0:00:53 lr 1.301751	time 1.1986 (1.9080)	loss 2.6971 (2.6356)	grad_norm 0.4663 (0.4668)	mem 39782MB
[2023-07-07 15:22:42 RepVGG-A0] (main.py 282): INFO Train: [210/300][60/78]	eta 0:00:33 lr 1.298294	time 1.1751 (1.8502)	loss 2.6195 (2.6404)	grad_norm 0.4484 (0.4675)	mem 39782MB
[2023-07-07 15:22:57 RepVGG-A0] (main.py 282): INFO Train: [210/300][70/78]	eta 0:00:14 lr 1.294841	time 1.1738 (1.8013)	loss 2.6577 (2.6459)	grad_norm 0.5262 (0.4707)	mem 39782MB
[2023-07-07 15:23:10 RepVGG-A0] (main.py 291): INFO EPOCH 210 training takes 0:02:20
[2023-07-07 15:23:31 RepVGG-A0] (main.py 282): INFO Train: [211/300][0/78]	eta 0:27:47 lr 1.292080	time 21.3840 (21.3840)	loss 2.6007 (2.6007)	grad_norm 0.4356 (0.4356)	mem 39782MB
[2023-07-07 15:23:46 RepVGG-A0] (main.py 282): INFO Train: [211/300][10/78]	eta 0:03:42 lr 1.288633	time 1.1747 (3.2667)	loss 2.6270 (2.6256)	grad_norm 0.4630 (0.4541)	mem 39782MB
[2023-07-07 15:24:00 RepVGG-A0] (main.py 282): INFO Train: [211/300][20/78]	eta 0:02:18 lr 1.285189	time 1.1726 (2.3960)	loss 2.6423 (2.6260)	grad_norm 0.4485 (0.4595)	mem 39782MB
[2023-07-07 15:24:15 RepVGG-A0] (main.py 282): INFO Train: [211/300][30/78]	eta 0:01:41 lr 1.281749	time 1.3129 (2.1125)	loss 2.6620 (2.6226)	grad_norm 0.4985 (0.4621)	mem 39782MB
[2023-07-07 15:24:33 RepVGG-A0] (main.py 282): INFO Train: [211/300][40/78]	eta 0:01:17 lr 1.278312	time 4.3330 (2.0408)	loss 2.7068 (2.6295)	grad_norm 0.4584 (0.4635)	mem 39782MB
[2023-07-07 15:24:48 RepVGG-A0] (main.py 282): INFO Train: [211/300][50/78]	eta 0:00:53 lr 1.274878	time 1.2050 (1.9264)	loss 2.6755 (2.6359)	grad_norm 0.5000 (0.4648)	mem 39782MB
[2023-07-07 15:25:03 RepVGG-A0] (main.py 282): INFO Train: [211/300][60/78]	eta 0:00:33 lr 1.271448	time 1.4495 (1.8663)	loss 2.6334 (2.6437)	grad_norm 0.4516 (0.4671)	mem 39782MB
[2023-07-07 15:25:18 RepVGG-A0] (main.py 282): INFO Train: [211/300][70/78]	eta 0:00:14 lr 1.268022	time 1.2131 (1.8076)	loss 2.6969 (2.6457)	grad_norm 0.5160 (0.4688)	mem 39782MB
[2023-07-07 15:25:30 RepVGG-A0] (main.py 291): INFO EPOCH 211 training takes 0:02:20
[2023-07-07 15:25:52 RepVGG-A0] (main.py 282): INFO Train: [212/300][0/78]	eta 0:28:16 lr 1.265283	time 21.7541 (21.7541)	loss 2.5865 (2.5865)	grad_norm 0.4468 (0.4468)	mem 39782MB
[2023-07-07 15:26:06 RepVGG-A0] (main.py 282): INFO Train: [212/300][10/78]	eta 0:03:40 lr 1.261863	time 1.1726 (3.2489)	loss 2.6721 (2.6191)	grad_norm 0.4791 (0.4590)	mem 39782MB
[2023-07-07 15:26:21 RepVGG-A0] (main.py 282): INFO Train: [212/300][20/78]	eta 0:02:20 lr 1.258446	time 1.2845 (2.4154)	loss 2.6104 (2.6366)	grad_norm 0.4377 (0.4671)	mem 39782MB
[2023-07-07 15:26:36 RepVGG-A0] (main.py 282): INFO Train: [212/300][30/78]	eta 0:01:41 lr 1.255032	time 1.3598 (2.1187)	loss 2.5813 (2.6314)	grad_norm 0.4815 (0.4687)	mem 39782MB
[2023-07-07 15:26:54 RepVGG-A0] (main.py 282): INFO Train: [212/300][40/78]	eta 0:01:17 lr 1.251623	time 4.0887 (2.0510)	loss 2.6378 (2.6297)	grad_norm 0.4764 (0.4668)	mem 39782MB
[2023-07-07 15:27:09 RepVGG-A0] (main.py 282): INFO Train: [212/300][50/78]	eta 0:00:54 lr 1.248216	time 1.1715 (1.9366)	loss 2.6228 (2.6342)	grad_norm 0.4431 (0.4696)	mem 39782MB
[2023-07-07 15:27:25 RepVGG-A0] (main.py 282): INFO Train: [212/300][60/78]	eta 0:00:33 lr 1.244814	time 1.2912 (1.8796)	loss 2.6254 (2.6332)	grad_norm 0.4883 (0.4686)	mem 39782MB
[2023-07-07 15:27:39 RepVGG-A0] (main.py 282): INFO Train: [212/300][70/78]	eta 0:00:14 lr 1.241414	time 1.1746 (1.8083)	loss 2.6494 (2.6345)	grad_norm 0.4819 (0.4687)	mem 39782MB
[2023-07-07 15:27:52 RepVGG-A0] (main.py 291): INFO EPOCH 212 training takes 0:02:21
[2023-07-07 15:28:12 RepVGG-A0] (main.py 282): INFO Train: [213/300][0/78]	eta 0:26:53 lr 1.238697	time 20.6850 (20.6850)	loss 2.5721 (2.5721)	grad_norm 0.4698 (0.4698)	mem 39782MB
[2023-07-07 15:28:27 RepVGG-A0] (main.py 282): INFO Train: [213/300][10/78]	eta 0:03:36 lr 1.235305	time 1.1702 (3.1843)	loss 2.6089 (2.6100)	grad_norm 0.4888 (0.4668)	mem 39782MB
[2023-07-07 15:28:42 RepVGG-A0] (main.py 282): INFO Train: [213/300][20/78]	eta 0:02:17 lr 1.231915	time 1.1730 (2.3781)	loss 2.6533 (2.6128)	grad_norm 0.4763 (0.4782)	mem 39782MB
[2023-07-07 15:28:57 RepVGG-A0] (main.py 282): INFO Train: [213/300][30/78]	eta 0:01:40 lr 1.228529	time 1.5014 (2.1006)	loss 2.6084 (2.6123)	grad_norm 0.4601 (0.4699)	mem 39782MB
[2023-07-07 15:29:15 RepVGG-A0] (main.py 282): INFO Train: [213/300][40/78]	eta 0:01:16 lr 1.225147	time 4.1876 (2.0249)	loss 2.5905 (2.6165)	grad_norm 0.5136 (0.4774)	mem 39782MB
[2023-07-07 15:29:30 RepVGG-A0] (main.py 282): INFO Train: [213/300][50/78]	eta 0:00:53 lr 1.221768	time 1.1940 (1.9252)	loss 2.6375 (2.6187)	grad_norm 0.4761 (0.4741)	mem 39782MB
[2023-07-07 15:29:45 RepVGG-A0] (main.py 282): INFO Train: [213/300][60/78]	eta 0:00:33 lr 1.218393	time 1.1840 (1.8635)	loss 2.6561 (2.6206)	grad_norm 0.5029 (0.4761)	mem 39782MB
[2023-07-07 15:30:01 RepVGG-A0] (main.py 282): INFO Train: [213/300][70/78]	eta 0:00:14 lr 1.215022	time 1.2136 (1.8234)	loss 2.6502 (2.6237)	grad_norm 0.4545 (0.4756)	mem 39782MB
[2023-07-07 15:30:13 RepVGG-A0] (main.py 291): INFO EPOCH 213 training takes 0:02:21
[2023-07-07 15:30:33 RepVGG-A0] (main.py 282): INFO Train: [214/300][0/78]	eta 0:25:22 lr 1.212327	time 19.5137 (19.5137)	loss 2.6208 (2.6208)	grad_norm 0.4605 (0.4605)	mem 39782MB
[2023-07-07 15:30:49 RepVGG-A0] (main.py 282): INFO Train: [214/300][10/78]	eta 0:03:40 lr 1.208962	time 1.1710 (3.2424)	loss 2.6154 (2.5934)	grad_norm 0.4649 (0.4605)	mem 39782MB
[2023-07-07 15:31:05 RepVGG-A0] (main.py 282): INFO Train: [214/300][20/78]	eta 0:02:23 lr 1.205600	time 1.2970 (2.4810)	loss 2.5997 (2.5945)	grad_norm 0.5483 (0.4681)	mem 39782MB
[2023-07-07 15:31:19 RepVGG-A0] (main.py 282): INFO Train: [214/300][30/78]	eta 0:01:42 lr 1.202243	time 1.3723 (2.1401)	loss 2.6807 (2.6081)	grad_norm 0.4734 (0.4799)	mem 39782MB
[2023-07-07 15:31:37 RepVGG-A0] (main.py 282): INFO Train: [214/300][40/78]	eta 0:01:17 lr 1.198888	time 3.2307 (2.0508)	loss 2.5975 (2.6119)	grad_norm 0.4667 (0.4781)	mem 39782MB
[2023-07-07 15:31:52 RepVGG-A0] (main.py 282): INFO Train: [214/300][50/78]	eta 0:00:54 lr 1.195538	time 1.1948 (1.9391)	loss 2.6261 (2.6136)	grad_norm 0.4861 (0.4744)	mem 39782MB
[2023-07-07 15:32:07 RepVGG-A0] (main.py 282): INFO Train: [214/300][60/78]	eta 0:00:33 lr 1.192190	time 1.1812 (1.8678)	loss 2.6410 (2.6208)	grad_norm 0.4660 (0.4822)	mem 39782MB
[2023-07-07 15:32:23 RepVGG-A0] (main.py 282): INFO Train: [214/300][70/78]	eta 0:00:14 lr 1.188847	time 1.2788 (1.8306)	loss 2.6281 (2.6236)	grad_norm 0.4832 (0.4792)	mem 39782MB
[2023-07-07 15:32:33 RepVGG-A0] (main.py 291): INFO EPOCH 214 training takes 0:02:20
[2023-07-07 15:32:55 RepVGG-A0] (main.py 282): INFO Train: [215/300][0/78]	eta 0:27:44 lr 1.186175	time 21.3421 (21.3421)	loss 2.5964 (2.5964)	grad_norm 0.4838 (0.4838)	mem 39782MB
[2023-07-07 15:33:09 RepVGG-A0] (main.py 282): INFO Train: [215/300][10/78]	eta 0:03:40 lr 1.182838	time 1.1732 (3.2475)	loss 2.7091 (2.6030)	grad_norm 0.4760 (0.4567)	mem 39782MB
[2023-07-07 15:33:25 RepVGG-A0] (main.py 282): INFO Train: [215/300][20/78]	eta 0:02:23 lr 1.179504	time 1.1730 (2.4680)	loss 2.5508 (2.5949)	grad_norm 0.5156 (0.4638)	mem 39782MB
[2023-07-07 15:33:42 RepVGG-A0] (main.py 282): INFO Train: [215/300][30/78]	eta 0:01:45 lr 1.176175	time 1.5054 (2.1962)	loss 2.6220 (2.6076)	grad_norm 0.4806 (0.4775)	mem 39782MB
[2023-07-07 15:33:59 RepVGG-A0] (main.py 282): INFO Train: [215/300][40/78]	eta 0:01:19 lr 1.172849	time 3.6798 (2.0836)	loss 2.6781 (2.6088)	grad_norm 0.4640 (0.4733)	mem 39782MB
[2023-07-07 15:34:14 RepVGG-A0] (main.py 282): INFO Train: [215/300][50/78]	eta 0:00:55 lr 1.169526	time 1.1723 (1.9792)	loss 2.5897 (2.6093)	grad_norm 0.5113 (0.4762)	mem 39782MB
[2023-07-07 15:34:29 RepVGG-A0] (main.py 282): INFO Train: [215/300][60/78]	eta 0:00:34 lr 1.166208	time 1.1788 (1.8924)	loss 2.6467 (2.6142)	grad_norm 0.4671 (0.4752)	mem 39782MB
[2023-07-07 15:34:44 RepVGG-A0] (main.py 282): INFO Train: [215/300][70/78]	eta 0:00:14 lr 1.162893	time 1.1777 (1.8391)	loss 2.6721 (2.6153)	grad_norm 0.4564 (0.4789)	mem 39782MB
[2023-07-07 15:34:55 RepVGG-A0] (main.py 291): INFO EPOCH 215 training takes 0:02:22
[2023-07-07 15:35:17 RepVGG-A0] (main.py 282): INFO Train: [216/300][0/78]	eta 0:27:25 lr 1.160243	time 21.0987 (21.0987)	loss 2.6161 (2.6161)	grad_norm 0.5179 (0.5179)	mem 39782MB
[2023-07-07 15:35:33 RepVGG-A0] (main.py 282): INFO Train: [216/300][10/78]	eta 0:03:51 lr 1.156935	time 1.1718 (3.4036)	loss 2.5821 (2.5926)	grad_norm 0.4784 (0.4752)	mem 39782MB
[2023-07-07 15:35:47 RepVGG-A0] (main.py 282): INFO Train: [216/300][20/78]	eta 0:02:22 lr 1.153630	time 1.1745 (2.4597)	loss 2.6589 (2.5911)	grad_norm 0.4568 (0.4693)	mem 39782MB
[2023-07-07 15:36:03 RepVGG-A0] (main.py 282): INFO Train: [216/300][30/78]	eta 0:01:44 lr 1.150329	time 1.2131 (2.1755)	loss 2.5676 (2.5930)	grad_norm 0.5016 (0.4759)	mem 39782MB
[2023-07-07 15:36:21 RepVGG-A0] (main.py 282): INFO Train: [216/300][40/78]	eta 0:01:18 lr 1.147032	time 4.3344 (2.0743)	loss 2.6751 (2.5989)	grad_norm 0.4737 (0.4743)	mem 39782MB
[2023-07-07 15:36:36 RepVGG-A0] (main.py 282): INFO Train: [216/300][50/78]	eta 0:00:55 lr 1.143738	time 1.2263 (1.9672)	loss 2.6299 (2.6057)	grad_norm 0.5457 (0.4820)	mem 39782MB
[2023-07-07 15:36:51 RepVGG-A0] (main.py 282): INFO Train: [216/300][60/78]	eta 0:00:34 lr 1.140448	time 1.1973 (1.8918)	loss 2.5800 (2.6098)	grad_norm 0.4538 (0.4853)	mem 39782MB
[2023-07-07 15:37:06 RepVGG-A0] (main.py 282): INFO Train: [216/300][70/78]	eta 0:00:14 lr 1.137162	time 1.4525 (1.8436)	loss 2.6518 (2.6136)	grad_norm 0.4704 (0.4836)	mem 39782MB
[2023-07-07 15:37:17 RepVGG-A0] (main.py 291): INFO EPOCH 216 training takes 0:02:21
[2023-07-07 15:37:38 RepVGG-A0] (main.py 282): INFO Train: [217/300][0/78]	eta 0:28:17 lr 1.134535	time 21.7644 (21.7644)	loss 2.5682 (2.5682)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:37:52 RepVGG-A0] (main.py 282): INFO Train: [217/300][10/78]	eta 0:03:40 lr 1.131256	time 1.1709 (3.2387)	loss 2.5636 (2.5829)	grad_norm 0.4741 (0.4763)	mem 39782MB
[2023-07-07 15:38:07 RepVGG-A0] (main.py 282): INFO Train: [217/300][20/78]	eta 0:02:19 lr 1.127980	time 1.1736 (2.4051)	loss 2.6197 (2.5911)	grad_norm 0.4497 (0.4682)	mem 39782MB
[2023-07-07 15:38:22 RepVGG-A0] (main.py 282): INFO Train: [217/300][30/78]	eta 0:01:41 lr 1.124708	time 1.1932 (2.1112)	loss 2.5599 (2.5937)	grad_norm 0.4814 (0.4721)	mem 39782MB
[2023-07-07 15:38:40 RepVGG-A0] (main.py 282): INFO Train: [217/300][40/78]	eta 0:01:17 lr 1.121440	time 4.2438 (2.0397)	loss 2.5411 (2.5964)	grad_norm 0.4837 (0.4768)	mem 39782MB
[2023-07-07 15:38:55 RepVGG-A0] (main.py 282): INFO Train: [217/300][50/78]	eta 0:00:54 lr 1.118175	time 1.1728 (1.9323)	loss 2.6237 (2.5967)	grad_norm 0.4781 (0.4750)	mem 39782MB
[2023-07-07 15:39:10 RepVGG-A0] (main.py 282): INFO Train: [217/300][60/78]	eta 0:00:33 lr 1.114914	time 1.1262 (1.8562)	loss 2.6275 (2.5981)	grad_norm 0.5024 (0.4758)	mem 39782MB
[2023-07-07 15:39:26 RepVGG-A0] (main.py 282): INFO Train: [217/300][70/78]	eta 0:00:14 lr 1.111657	time 1.2920 (1.8180)	loss 2.6500 (2.5992)	grad_norm 0.4819 (0.4764)	mem 39782MB
[2023-07-07 15:39:37 RepVGG-A0] (main.py 291): INFO EPOCH 217 training takes 0:02:20
[2023-07-07 15:39:59 RepVGG-A0] (main.py 282): INFO Train: [218/300][0/78]	eta 0:28:40 lr 1.109054	time 22.0612 (22.0612)	loss 2.6092 (2.6092)	grad_norm 0.4891 (0.4891)	mem 39782MB
[2023-07-07 15:40:15 RepVGG-A0] (main.py 282): INFO Train: [218/300][10/78]	eta 0:03:53 lr 1.105804	time 1.1745 (3.4296)	loss 2.6197 (2.5753)	grad_norm 0.5280 (0.4843)	mem 39782MB
[2023-07-07 15:40:30 RepVGG-A0] (main.py 282): INFO Train: [218/300][20/78]	eta 0:02:25 lr 1.102557	time 1.1738 (2.5049)	loss 2.6281 (2.5798)	grad_norm 0.4757 (0.4871)	mem 39782MB
[2023-07-07 15:40:45 RepVGG-A0] (main.py 282): INFO Train: [218/300][30/78]	eta 0:01:45 lr 1.099314	time 1.6876 (2.1970)	loss 2.5861 (2.5865)	grad_norm 0.4633 (0.4888)	mem 39782MB
[2023-07-07 15:41:03 RepVGG-A0] (main.py 282): INFO Train: [218/300][40/78]	eta 0:01:19 lr 1.096075	time 3.8047 (2.0968)	loss 2.6581 (2.5917)	grad_norm 0.4775 (0.4850)	mem 39782MB
[2023-07-07 15:41:18 RepVGG-A0] (main.py 282): INFO Train: [218/300][50/78]	eta 0:00:55 lr 1.092840	time 1.1802 (1.9719)	loss 2.5226 (2.5906)	grad_norm 0.4559 (0.4835)	mem 39782MB
[2023-07-07 15:41:33 RepVGG-A0] (main.py 282): INFO Train: [218/300][60/78]	eta 0:00:34 lr 1.089609	time 1.2683 (1.9009)	loss 2.6063 (2.5877)	grad_norm 0.4809 (0.4809)	mem 39782MB
[2023-07-07 15:41:48 RepVGG-A0] (main.py 282): INFO Train: [218/300][70/78]	eta 0:00:14 lr 1.086381	time 1.2731 (1.8462)	loss 2.6660 (2.5924)	grad_norm 0.5080 (0.4838)	mem 39782MB
[2023-07-07 15:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 218 training takes 0:02:22
[2023-07-07 15:42:22 RepVGG-A0] (main.py 282): INFO Train: [219/300][0/78]	eta 0:28:00 lr 1.083802	time 21.5399 (21.5399)	loss 2.5562 (2.5562)	grad_norm 0.4598 (0.4598)	mem 39782MB
[2023-07-07 15:42:36 RepVGG-A0] (main.py 282): INFO Train: [219/300][10/78]	eta 0:03:44 lr 1.080581	time 1.1763 (3.2979)	loss 2.6055 (2.5702)	grad_norm 0.5098 (0.4698)	mem 39782MB
[2023-07-07 15:42:51 RepVGG-A0] (main.py 282): INFO Train: [219/300][20/78]	eta 0:02:20 lr 1.077364	time 1.2668 (2.4200)	loss 2.5878 (2.5761)	grad_norm 0.5126 (0.4855)	mem 39782MB
[2023-07-07 15:43:07 RepVGG-A0] (main.py 282): INFO Train: [219/300][30/78]	eta 0:01:43 lr 1.074151	time 1.5608 (2.1585)	loss 2.6277 (2.5809)	grad_norm 0.4718 (0.4858)	mem 39782MB
[2023-07-07 15:43:24 RepVGG-A0] (main.py 282): INFO Train: [219/300][40/78]	eta 0:01:18 lr 1.070942	time 2.3529 (2.0567)	loss 2.5930 (2.5841)	grad_norm 0.4710 (0.4841)	mem 39782MB
[2023-07-07 15:43:39 RepVGG-A0] (main.py 282): INFO Train: [219/300][50/78]	eta 0:00:54 lr 1.067737	time 1.1940 (1.9480)	loss 2.6299 (2.5880)	grad_norm 0.5241 (0.4860)	mem 39782MB
[2023-07-07 15:43:53 RepVGG-A0] (main.py 282): INFO Train: [219/300][60/78]	eta 0:00:33 lr 1.064535	time 1.1775 (1.8568)	loss 2.6126 (2.5921)	grad_norm 0.4939 (0.4877)	mem 39782MB
[2023-07-07 15:44:09 RepVGG-A0] (main.py 282): INFO Train: [219/300][70/78]	eta 0:00:14 lr 1.061337	time 1.2496 (1.8114)	loss 2.6267 (2.5929)	grad_norm 0.4977 (0.4861)	mem 39782MB
[2023-07-07 15:44:20 RepVGG-A0] (main.py 291): INFO EPOCH 219 training takes 0:02:20
[2023-07-07 15:44:41 RepVGG-A0] (main.py 282): INFO Train: [220/300][0/78]	eta 0:27:34 lr 1.058782	time 21.2159 (21.2159)	loss 2.5658 (2.5658)	grad_norm 0.4640 (0.4640)	mem 39782MB
[2023-07-07 15:44:56 RepVGG-A0] (main.py 282): INFO Train: [220/300][10/78]	eta 0:03:39 lr 1.055591	time 1.1710 (3.2325)	loss 2.5010 (2.5615)	grad_norm 0.4841 (0.4878)	mem 39782MB
[2023-07-07 15:45:10 RepVGG-A0] (main.py 282): INFO Train: [220/300][20/78]	eta 0:02:18 lr 1.052404	time 1.1740 (2.3902)	loss 2.6889 (2.5717)	grad_norm 0.4704 (0.5001)	mem 39782MB
[2023-07-07 15:45:26 RepVGG-A0] (main.py 282): INFO Train: [220/300][30/78]	eta 0:01:41 lr 1.049221	time 1.1697 (2.1241)	loss 2.6733 (2.5768)	grad_norm 0.4838 (0.4927)	mem 39782MB
[2023-07-07 15:45:44 RepVGG-A0] (main.py 282): INFO Train: [220/300][40/78]	eta 0:01:18 lr 1.046042	time 4.3581 (2.0527)	loss 2.6329 (2.5793)	grad_norm 0.4764 (0.4889)	mem 39782MB
[2023-07-07 15:45:59 RepVGG-A0] (main.py 282): INFO Train: [220/300][50/78]	eta 0:00:54 lr 1.042867	time 1.2999 (1.9468)	loss 2.5161 (2.5788)	grad_norm 0.4897 (0.4882)	mem 39782MB
[2023-07-07 15:46:14 RepVGG-A0] (main.py 282): INFO Train: [220/300][60/78]	eta 0:00:33 lr 1.039696	time 1.2615 (1.8725)	loss 2.5832 (2.5810)	grad_norm 0.4994 (0.4913)	mem 39782MB
[2023-07-07 15:46:30 RepVGG-A0] (main.py 282): INFO Train: [220/300][70/78]	eta 0:00:14 lr 1.036528	time 1.3708 (1.8268)	loss 2.5746 (2.5847)	grad_norm 0.4628 (0.4894)	mem 39782MB
[2023-07-07 15:46:41 RepVGG-A0] (main.py 291): INFO EPOCH 220 training takes 0:02:20
[2023-07-07 15:46:58 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.974 (16.974)	Loss 1.8846 (1.8846)	Acc@1 60.229 (60.229)	Acc@5 82.672 (82.672)	Mem 39782MB
[2023-07-07 15:46:59 RepVGG-A0] (main.py 342): INFO  * Acc@1 60.430 Acc@5 82.872
[2023-07-07 15:46:59 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 220: 60.430%
[2023-07-07 15:46:59 RepVGG-A0] (main.py 172): INFO Max accuracy: 60.43%
[2023-07-07 15:47:20 RepVGG-A0] (main.py 282): INFO Train: [221/300][0/78]	eta 0:26:33 lr 1.033997	time 20.4241 (20.4241)	loss 2.5588 (2.5588)	grad_norm 0.4686 (0.4686)	mem 39782MB
[2023-07-07 15:47:35 RepVGG-A0] (main.py 282): INFO Train: [221/300][10/78]	eta 0:03:40 lr 1.030836	time 1.1922 (3.2467)	loss 2.5436 (2.5682)	grad_norm 0.5104 (0.5007)	mem 39782MB
[2023-07-07 15:47:51 RepVGG-A0] (main.py 282): INFO Train: [221/300][20/78]	eta 0:02:21 lr 1.027680	time 1.1752 (2.4430)	loss 2.5222 (2.5570)	grad_norm 0.4605 (0.4899)	mem 39782MB
[2023-07-07 15:48:07 RepVGG-A0] (main.py 282): INFO Train: [221/300][30/78]	eta 0:01:45 lr 1.024527	time 2.1080 (2.1890)	loss 2.6220 (2.5597)	grad_norm 0.5106 (0.4890)	mem 39782MB
[2023-07-07 15:48:24 RepVGG-A0] (main.py 282): INFO Train: [221/300][40/78]	eta 0:01:18 lr 1.021379	time 3.6717 (2.0672)	loss 2.5109 (2.5649)	grad_norm 0.4713 (0.4880)	mem 39782MB
[2023-07-07 15:48:39 RepVGG-A0] (main.py 282): INFO Train: [221/300][50/78]	eta 0:00:54 lr 1.018234	time 1.3350 (1.9606)	loss 2.6121 (2.5697)	grad_norm 0.5240 (0.4871)	mem 39782MB
[2023-07-07 15:48:54 RepVGG-A0] (main.py 282): INFO Train: [221/300][60/78]	eta 0:00:33 lr 1.015093	time 1.1801 (1.8859)	loss 2.5237 (2.5691)	grad_norm 0.4760 (0.4858)	mem 39782MB
[2023-07-07 15:49:10 RepVGG-A0] (main.py 282): INFO Train: [221/300][70/78]	eta 0:00:14 lr 1.011956	time 1.3358 (1.8473)	loss 2.6531 (2.5752)	grad_norm 0.5042 (0.4868)	mem 39782MB
[2023-07-07 15:49:23 RepVGG-A0] (main.py 291): INFO EPOCH 221 training takes 0:02:23
[2023-07-07 15:49:45 RepVGG-A0] (main.py 282): INFO Train: [222/300][0/78]	eta 0:29:39 lr 1.009449	time 22.8204 (22.8204)	loss 2.4767 (2.4767)	grad_norm 0.4914 (0.4914)	mem 39782MB
[2023-07-07 15:50:00 RepVGG-A0] (main.py 282): INFO Train: [222/300][10/78]	eta 0:03:52 lr 1.006319	time 1.1721 (3.4200)	loss 2.5664 (2.5394)	grad_norm 0.4525 (0.4776)	mem 39782MB
[2023-07-07 15:50:14 RepVGG-A0] (main.py 282): INFO Train: [222/300][20/78]	eta 0:02:21 lr 1.003194	time 1.1720 (2.4433)	loss 2.5296 (2.5434)	grad_norm 0.4798 (0.4826)	mem 39782MB
[2023-07-07 15:50:28 RepVGG-A0] (main.py 282): INFO Train: [222/300][30/78]	eta 0:01:41 lr 1.000072	time 1.2506 (2.1234)	loss 2.4989 (2.5522)	grad_norm 0.4730 (0.4815)	mem 39782MB
[2023-07-07 15:50:46 RepVGG-A0] (main.py 282): INFO Train: [222/300][40/78]	eta 0:01:17 lr 0.996954	time 3.1611 (2.0335)	loss 2.5676 (2.5575)	grad_norm 0.5011 (0.4845)	mem 39782MB
[2023-07-07 15:51:01 RepVGG-A0] (main.py 282): INFO Train: [222/300][50/78]	eta 0:00:54 lr 0.993840	time 1.4802 (1.9375)	loss 2.5700 (2.5624)	grad_norm 0.4818 (0.4836)	mem 39782MB
[2023-07-07 15:51:17 RepVGG-A0] (main.py 282): INFO Train: [222/300][60/78]	eta 0:00:33 lr 0.990730	time 1.1753 (1.8807)	loss 2.5671 (2.5674)	grad_norm 0.4855 (0.4862)	mem 39782MB
[2023-07-07 15:51:32 RepVGG-A0] (main.py 282): INFO Train: [222/300][70/78]	eta 0:00:14 lr 0.987624	time 1.3428 (1.8243)	loss 2.5413 (2.5691)	grad_norm 0.4788 (0.4853)	mem 39782MB
[2023-07-07 15:51:44 RepVGG-A0] (main.py 291): INFO EPOCH 222 training takes 0:02:21
[2023-07-07 15:52:07 RepVGG-A0] (main.py 282): INFO Train: [223/300][0/78]	eta 0:29:36 lr 0.985142	time 22.7776 (22.7776)	loss 2.5364 (2.5364)	grad_norm 0.4824 (0.4824)	mem 39782MB
[2023-07-07 15:52:22 RepVGG-A0] (main.py 282): INFO Train: [223/300][10/78]	eta 0:03:53 lr 0.982043	time 1.1946 (3.4345)	loss 2.4939 (2.5443)	grad_norm 0.5013 (0.4981)	mem 39782MB
[2023-07-07 15:52:35 RepVGG-A0] (main.py 282): INFO Train: [223/300][20/78]	eta 0:02:22 lr 0.978948	time 1.1730 (2.4517)	loss 2.5438 (2.5527)	grad_norm 0.4780 (0.5029)	mem 39782MB
[2023-07-07 15:52:53 RepVGG-A0] (main.py 282): INFO Train: [223/300][30/78]	eta 0:01:46 lr 0.975857	time 1.7560 (2.2145)	loss 2.5784 (2.5500)	grad_norm 0.4752 (0.4952)	mem 39782MB
[2023-07-07 15:53:09 RepVGG-A0] (main.py 282): INFO Train: [223/300][40/78]	eta 0:01:19 lr 0.972771	time 2.8176 (2.0795)	loss 2.5279 (2.5532)	grad_norm 0.4764 (0.4953)	mem 39782MB
[2023-07-07 15:53:24 RepVGG-A0] (main.py 282): INFO Train: [223/300][50/78]	eta 0:00:55 lr 0.969688	time 1.1728 (1.9645)	loss 2.5330 (2.5597)	grad_norm 0.4945 (0.4948)	mem 39782MB
[2023-07-07 15:53:39 RepVGG-A0] (main.py 282): INFO Train: [223/300][60/78]	eta 0:00:34 lr 0.966609	time 1.2876 (1.8902)	loss 2.5767 (2.5644)	grad_norm 0.4734 (0.4932)	mem 39782MB
[2023-07-07 15:53:55 RepVGG-A0] (main.py 282): INFO Train: [223/300][70/78]	eta 0:00:14 lr 0.963534	time 1.3966 (1.8418)	loss 2.5437 (2.5671)	grad_norm 0.4944 (0.4923)	mem 39782MB
[2023-07-07 15:54:06 RepVGG-A0] (main.py 291): INFO EPOCH 223 training takes 0:02:22
[2023-07-07 15:54:27 RepVGG-A0] (main.py 282): INFO Train: [224/300][0/78]	eta 0:27:07 lr 0.961077	time 20.8593 (20.8593)	loss 2.4499 (2.4499)	grad_norm 0.4953 (0.4953)	mem 39782MB
[2023-07-07 15:54:41 RepVGG-A0] (main.py 282): INFO Train: [224/300][10/78]	eta 0:03:37 lr 0.958010	time 1.1706 (3.1952)	loss 2.4934 (2.5189)	grad_norm 0.4578 (0.5028)	mem 39782MB
[2023-07-07 15:54:57 RepVGG-A0] (main.py 282): INFO Train: [224/300][20/78]	eta 0:02:20 lr 0.954946	time 1.2287 (2.4267)	loss 2.6025 (2.5385)	grad_norm 0.4992 (0.5000)	mem 39782MB
[2023-07-07 15:55:12 RepVGG-A0] (main.py 282): INFO Train: [224/300][30/78]	eta 0:01:42 lr 0.951887	time 1.4248 (2.1271)	loss 2.6016 (2.5430)	grad_norm 0.4729 (0.4954)	mem 39782MB
[2023-07-07 15:55:31 RepVGG-A0] (main.py 282): INFO Train: [224/300][40/78]	eta 0:01:18 lr 0.948832	time 3.5368 (2.0713)	loss 2.4720 (2.5462)	grad_norm 0.5102 (0.4970)	mem 39782MB
[2023-07-07 15:55:46 RepVGG-A0] (main.py 282): INFO Train: [224/300][50/78]	eta 0:00:54 lr 0.945780	time 1.2082 (1.9575)	loss 2.5732 (2.5476)	grad_norm 0.4963 (0.4969)	mem 39782MB
[2023-07-07 15:56:01 RepVGG-A0] (main.py 282): INFO Train: [224/300][60/78]	eta 0:00:33 lr 0.942733	time 1.5764 (1.8829)	loss 2.5535 (2.5489)	grad_norm 0.4766 (0.4956)	mem 39782MB
[2023-07-07 15:56:16 RepVGG-A0] (main.py 282): INFO Train: [224/300][70/78]	eta 0:00:14 lr 0.939690	time 1.3263 (1.8317)	loss 2.5569 (2.5497)	grad_norm 0.4975 (0.4972)	mem 39782MB
[2023-07-07 15:56:28 RepVGG-A0] (main.py 291): INFO EPOCH 224 training takes 0:02:21
[2023-07-07 15:56:50 RepVGG-A0] (main.py 282): INFO Train: [225/300][0/78]	eta 0:28:29 lr 0.937258	time 21.9216 (21.9216)	loss 2.5183 (2.5183)	grad_norm 0.5075 (0.5075)	mem 39782MB
[2023-07-07 15:57:04 RepVGG-A0] (main.py 282): INFO Train: [225/300][10/78]	eta 0:03:43 lr 0.934222	time 1.1714 (3.2891)	loss 2.5198 (2.5466)	grad_norm 0.4895 (0.4909)	mem 39782MB
[2023-07-07 15:57:18 RepVGG-A0] (main.py 282): INFO Train: [225/300][20/78]	eta 0:02:19 lr 0.931191	time 1.1722 (2.4039)	loss 2.5250 (2.5402)	grad_norm 0.4810 (0.4851)	mem 39782MB
[2023-07-07 15:57:34 RepVGG-A0] (main.py 282): INFO Train: [225/300][30/78]	eta 0:01:42 lr 0.928163	time 1.4736 (2.1380)	loss 2.5909 (2.5405)	grad_norm 0.4985 (0.4874)	mem 39782MB
[2023-07-07 15:57:51 RepVGG-A0] (main.py 282): INFO Train: [225/300][40/78]	eta 0:01:16 lr 0.925140	time 3.4198 (2.0223)	loss 2.5487 (2.5453)	grad_norm 0.5378 (0.4909)	mem 39782MB
[2023-07-07 15:58:07 RepVGG-A0] (main.py 282): INFO Train: [225/300][50/78]	eta 0:00:54 lr 0.922120	time 1.2170 (1.9399)	loss 2.5338 (2.5475)	grad_norm 0.4918 (0.4955)	mem 39782MB
[2023-07-07 15:58:23 RepVGG-A0] (main.py 282): INFO Train: [225/300][60/78]	eta 0:00:33 lr 0.919105	time 1.3439 (1.8822)	loss 2.5262 (2.5499)	grad_norm 0.4952 (0.4940)	mem 39782MB
[2023-07-07 15:58:38 RepVGG-A0] (main.py 282): INFO Train: [225/300][70/78]	eta 0:00:14 lr 0.916093	time 1.2381 (1.8294)	loss 2.5326 (2.5543)	grad_norm 0.5021 (0.4925)	mem 39782MB
[2023-07-07 15:58:50 RepVGG-A0] (main.py 291): INFO EPOCH 225 training takes 0:02:21
[2023-07-07 15:59:10 RepVGG-A0] (main.py 282): INFO Train: [226/300][0/78]	eta 0:26:49 lr 0.913687	time 20.6376 (20.6376)	loss 2.5618 (2.5618)	grad_norm 0.4776 (0.4776)	mem 39782MB
[2023-07-07 15:59:27 RepVGG-A0] (main.py 282): INFO Train: [226/300][10/78]	eta 0:03:49 lr 0.910684	time 1.1704 (3.3761)	loss 2.5597 (2.5150)	grad_norm 0.4954 (0.4838)	mem 39782MB
[2023-07-07 15:59:42 RepVGG-A0] (main.py 282): INFO Train: [226/300][20/78]	eta 0:02:24 lr 0.907684	time 1.1877 (2.4880)	loss 2.5146 (2.5232)	grad_norm 0.4981 (0.4960)	mem 39782MB
[2023-07-07 15:59:57 RepVGG-A0] (main.py 282): INFO Train: [226/300][30/78]	eta 0:01:43 lr 0.904688	time 1.5765 (2.1661)	loss 2.4667 (2.5252)	grad_norm 0.4910 (0.4935)	mem 39782MB
[2023-07-07 16:00:14 RepVGG-A0] (main.py 282): INFO Train: [226/300][40/78]	eta 0:01:18 lr 0.901697	time 2.6911 (2.0586)	loss 2.5561 (2.5317)	grad_norm 0.5053 (0.4947)	mem 39782MB
[2023-07-07 16:00:29 RepVGG-A0] (main.py 282): INFO Train: [226/300][50/78]	eta 0:00:54 lr 0.898710	time 1.1957 (1.9508)	loss 2.5707 (2.5352)	grad_norm 0.5148 (0.4937)	mem 39782MB
[2023-07-07 16:00:45 RepVGG-A0] (main.py 282): INFO Train: [226/300][60/78]	eta 0:00:33 lr 0.895726	time 1.2623 (1.8856)	loss 2.6280 (2.5428)	grad_norm 0.5291 (0.4971)	mem 39782MB
[2023-07-07 16:00:59 RepVGG-A0] (main.py 282): INFO Train: [226/300][70/78]	eta 0:00:14 lr 0.892747	time 1.4579 (1.8251)	loss 2.5338 (2.5451)	grad_norm 0.5015 (0.4992)	mem 39782MB
[2023-07-07 16:01:11 RepVGG-A0] (main.py 291): INFO EPOCH 226 training takes 0:02:21
[2023-07-07 16:01:33 RepVGG-A0] (main.py 282): INFO Train: [227/300][0/78]	eta 0:28:22 lr 0.890367	time 21.8297 (21.8297)	loss 2.4759 (2.4759)	grad_norm 0.4839 (0.4839)	mem 39782MB
[2023-07-07 16:01:47 RepVGG-A0] (main.py 282): INFO Train: [227/300][10/78]	eta 0:03:43 lr 0.887396	time 1.1659 (3.2814)	loss 2.4933 (2.5254)	grad_norm 0.5000 (0.4859)	mem 39782MB
[2023-07-07 16:02:02 RepVGG-A0] (main.py 282): INFO Train: [227/300][20/78]	eta 0:02:21 lr 0.884428	time 1.2434 (2.4337)	loss 2.5057 (2.5324)	grad_norm 0.5048 (0.4904)	mem 39782MB
[2023-07-07 16:02:18 RepVGG-A0] (main.py 282): INFO Train: [227/300][30/78]	eta 0:01:43 lr 0.881465	time 1.6611 (2.1631)	loss 2.5571 (2.5296)	grad_norm 0.5313 (0.4920)	mem 39782MB
[2023-07-07 16:02:35 RepVGG-A0] (main.py 282): INFO Train: [227/300][40/78]	eta 0:01:17 lr 0.878506	time 3.7950 (2.0395)	loss 2.4970 (2.5304)	grad_norm 0.4835 (0.4962)	mem 39782MB
[2023-07-07 16:02:51 RepVGG-A0] (main.py 282): INFO Train: [227/300][50/78]	eta 0:00:54 lr 0.875552	time 1.1736 (1.9579)	loss 2.5664 (2.5349)	grad_norm 0.5101 (0.4968)	mem 39782MB
[2023-07-07 16:03:06 RepVGG-A0] (main.py 282): INFO Train: [227/300][60/78]	eta 0:00:33 lr 0.872601	time 1.3471 (1.8851)	loss 2.5632 (2.5396)	grad_norm 0.5010 (0.4974)	mem 39782MB
[2023-07-07 16:03:21 RepVGG-A0] (main.py 282): INFO Train: [227/300][70/78]	eta 0:00:14 lr 0.869654	time 1.2881 (1.8328)	loss 2.4779 (2.5397)	grad_norm 0.4780 (0.4987)	mem 39782MB
[2023-07-07 16:03:31 RepVGG-A0] (main.py 291): INFO EPOCH 227 training takes 0:02:20
[2023-07-07 16:03:52 RepVGG-A0] (main.py 282): INFO Train: [228/300][0/78]	eta 0:26:23 lr 0.867300	time 20.2971 (20.2971)	loss 2.4502 (2.4502)	grad_norm 0.4888 (0.4888)	mem 39782MB
[2023-07-07 16:04:06 RepVGG-A0] (main.py 282): INFO Train: [228/300][10/78]	eta 0:03:36 lr 0.864362	time 1.1903 (3.1798)	loss 2.5075 (2.5003)	grad_norm 0.5211 (0.5037)	mem 39782MB
[2023-07-07 16:04:21 RepVGG-A0] (main.py 282): INFO Train: [228/300][20/78]	eta 0:02:18 lr 0.861427	time 1.1722 (2.3824)	loss 2.5125 (2.5115)	grad_norm 0.4989 (0.4966)	mem 39782MB
[2023-07-07 16:04:38 RepVGG-A0] (main.py 282): INFO Train: [228/300][30/78]	eta 0:01:42 lr 0.858496	time 1.6317 (2.1424)	loss 2.4864 (2.5088)	grad_norm 0.4733 (0.4940)	mem 39782MB
[2023-07-07 16:04:55 RepVGG-A0] (main.py 282): INFO Train: [228/300][40/78]	eta 0:01:17 lr 0.855570	time 2.9806 (2.0355)	loss 2.5997 (2.5172)	grad_norm 0.5176 (0.4957)	mem 39782MB
[2023-07-07 16:05:10 RepVGG-A0] (main.py 282): INFO Train: [228/300][50/78]	eta 0:00:53 lr 0.852648	time 1.1881 (1.9267)	loss 2.5345 (2.5206)	grad_norm 0.4996 (0.5002)	mem 39782MB
[2023-07-07 16:05:25 RepVGG-A0] (main.py 282): INFO Train: [228/300][60/78]	eta 0:00:33 lr 0.849731	time 1.3648 (1.8597)	loss 2.5103 (2.5233)	grad_norm 0.4959 (0.4983)	mem 39782MB
[2023-07-07 16:05:40 RepVGG-A0] (main.py 282): INFO Train: [228/300][70/78]	eta 0:00:14 lr 0.846817	time 1.1985 (1.8091)	loss 2.5382 (2.5255)	grad_norm 0.5037 (0.4973)	mem 39782MB
[2023-07-07 16:05:51 RepVGG-A0] (main.py 291): INFO EPOCH 228 training takes 0:02:19
[2023-07-07 16:06:13 RepVGG-A0] (main.py 282): INFO Train: [229/300][0/78]	eta 0:28:39 lr 0.844489	time 22.0492 (22.0492)	loss 2.4984 (2.4984)	grad_norm 0.4955 (0.4955)	mem 39782MB
[2023-07-07 16:06:28 RepVGG-A0] (main.py 282): INFO Train: [229/300][10/78]	eta 0:03:45 lr 0.841583	time 1.1739 (3.3235)	loss 2.4672 (2.5150)	grad_norm 0.4885 (0.4975)	mem 39782MB
[2023-07-07 16:06:42 RepVGG-A0] (main.py 282): INFO Train: [229/300][20/78]	eta 0:02:21 lr 0.838682	time 1.2613 (2.4320)	loss 2.5536 (2.5161)	grad_norm 0.5325 (0.5072)	mem 39782MB
[2023-07-07 16:06:58 RepVGG-A0] (main.py 282): INFO Train: [229/300][30/78]	eta 0:01:42 lr 0.835784	time 1.4414 (2.1408)	loss 2.4742 (2.5116)	grad_norm 0.4963 (0.5021)	mem 39782MB
[2023-07-07 16:07:16 RepVGG-A0] (main.py 282): INFO Train: [229/300][40/78]	eta 0:01:18 lr 0.832891	time 2.7771 (2.0664)	loss 2.4912 (2.5130)	grad_norm 0.5258 (0.5019)	mem 39782MB
[2023-07-07 16:07:31 RepVGG-A0] (main.py 282): INFO Train: [229/300][50/78]	eta 0:00:54 lr 0.830003	time 1.1745 (1.9574)	loss 2.4746 (2.5137)	grad_norm 0.5343 (0.5030)	mem 39782MB
[2023-07-07 16:07:46 RepVGG-A0] (main.py 282): INFO Train: [229/300][60/78]	eta 0:00:33 lr 0.827118	time 1.1783 (1.8829)	loss 2.5505 (2.5176)	grad_norm 0.4989 (0.5037)	mem 39782MB
[2023-07-07 16:08:02 RepVGG-A0] (main.py 282): INFO Train: [229/300][70/78]	eta 0:00:14 lr 0.824238	time 1.5274 (1.8353)	loss 2.5625 (2.5211)	grad_norm 0.5166 (0.5035)	mem 39782MB
[2023-07-07 16:08:13 RepVGG-A0] (main.py 291): INFO EPOCH 229 training takes 0:02:21
[2023-07-07 16:08:34 RepVGG-A0] (main.py 282): INFO Train: [230/300][0/78]	eta 0:28:16 lr 0.821937	time 21.7495 (21.7495)	loss 2.5485 (2.5485)	grad_norm 0.4908 (0.4908)	mem 39782MB
[2023-07-07 16:08:49 RepVGG-A0] (main.py 282): INFO Train: [230/300][10/78]	eta 0:03:46 lr 0.819064	time 1.1697 (3.3371)	loss 2.5280 (2.5075)	grad_norm 0.5070 (0.4987)	mem 39782MB
[2023-07-07 16:09:05 RepVGG-A0] (main.py 282): INFO Train: [230/300][20/78]	eta 0:02:25 lr 0.816196	time 1.2205 (2.5006)	loss 2.5121 (2.5134)	grad_norm 0.4918 (0.5001)	mem 39782MB
[2023-07-07 16:09:19 RepVGG-A0] (main.py 282): INFO Train: [230/300][30/78]	eta 0:01:42 lr 0.813332	time 1.3893 (2.1363)	loss 2.4802 (2.5124)	grad_norm 0.4943 (0.5026)	mem 39782MB
[2023-07-07 16:09:36 RepVGG-A0] (main.py 282): INFO Train: [230/300][40/78]	eta 0:01:17 lr 0.810472	time 2.8909 (2.0393)	loss 2.4835 (2.5151)	grad_norm 0.4874 (0.5005)	mem 39782MB
[2023-07-07 16:09:52 RepVGG-A0] (main.py 282): INFO Train: [230/300][50/78]	eta 0:00:54 lr 0.807617	time 1.1724 (1.9518)	loss 2.5004 (2.5210)	grad_norm 0.5224 (0.5003)	mem 39782MB
[2023-07-07 16:10:07 RepVGG-A0] (main.py 282): INFO Train: [230/300][60/78]	eta 0:00:33 lr 0.804766	time 1.3699 (1.8783)	loss 2.5322 (2.5219)	grad_norm 0.5131 (0.5037)	mem 39782MB
[2023-07-07 16:10:22 RepVGG-A0] (main.py 282): INFO Train: [230/300][70/78]	eta 0:00:14 lr 0.801919	time 1.1387 (1.8267)	loss 2.5709 (2.5234)	grad_norm 0.4890 (0.5033)	mem 39782MB
[2023-07-07 16:10:34 RepVGG-A0] (main.py 291): INFO EPOCH 230 training takes 0:02:20
[2023-07-07 16:10:55 RepVGG-A0] (main.py 282): INFO Train: [231/300][0/78]	eta 0:28:28 lr 0.799645	time 21.9032 (21.9032)	loss 2.4209 (2.4209)	grad_norm 0.4890 (0.4890)	mem 39782MB
[2023-07-07 16:11:09 RepVGG-A0] (main.py 282): INFO Train: [231/300][10/78]	eta 0:03:41 lr 0.796806	time 1.1711 (3.2604)	loss 2.5193 (2.4848)	grad_norm 0.5044 (0.4964)	mem 39782MB
[2023-07-07 16:11:25 RepVGG-A0] (main.py 282): INFO Train: [231/300][20/78]	eta 0:02:20 lr 0.793971	time 1.1781 (2.4277)	loss 2.5004 (2.4866)	grad_norm 0.5226 (0.5073)	mem 39782MB
[2023-07-07 16:11:40 RepVGG-A0] (main.py 282): INFO Train: [231/300][30/78]	eta 0:01:43 lr 0.791141	time 1.2427 (2.1513)	loss 2.4578 (2.4907)	grad_norm 0.4892 (0.5057)	mem 39782MB
[2023-07-07 16:11:58 RepVGG-A0] (main.py 282): INFO Train: [231/300][40/78]	eta 0:01:18 lr 0.788315	time 3.4230 (2.0702)	loss 2.5014 (2.4966)	grad_norm 0.4973 (0.5028)	mem 39782MB
[2023-07-07 16:12:13 RepVGG-A0] (main.py 282): INFO Train: [231/300][50/78]	eta 0:00:54 lr 0.785493	time 1.1800 (1.9583)	loss 2.5280 (2.5007)	grad_norm 0.5195 (0.5043)	mem 39782MB
[2023-07-07 16:12:28 RepVGG-A0] (main.py 282): INFO Train: [231/300][60/78]	eta 0:00:33 lr 0.782676	time 1.1284 (1.8775)	loss 2.5637 (2.5062)	grad_norm 0.5058 (0.5039)	mem 39782MB
[2023-07-07 16:12:44 RepVGG-A0] (main.py 282): INFO Train: [231/300][70/78]	eta 0:00:14 lr 0.779863	time 1.1245 (1.8341)	loss 2.4943 (2.5055)	grad_norm 0.4934 (0.5065)	mem 39782MB
[2023-07-07 16:12:55 RepVGG-A0] (main.py 291): INFO EPOCH 231 training takes 0:02:21
[2023-07-07 16:13:17 RepVGG-A0] (main.py 282): INFO Train: [232/300][0/78]	eta 0:28:08 lr 0.777616	time 21.6458 (21.6458)	loss 2.5542 (2.5542)	grad_norm 0.5016 (0.5016)	mem 39782MB
[2023-07-07 16:13:31 RepVGG-A0] (main.py 282): INFO Train: [232/300][10/78]	eta 0:03:45 lr 0.774811	time 1.1709 (3.3108)	loss 2.5870 (2.4953)	grad_norm 0.5215 (0.5087)	mem 39782MB
[2023-07-07 16:13:46 RepVGG-A0] (main.py 282): INFO Train: [232/300][20/78]	eta 0:02:21 lr 0.772010	time 1.1772 (2.4418)	loss 2.5277 (2.4951)	grad_norm 0.5125 (0.5089)	mem 39782MB
[2023-07-07 16:14:00 RepVGG-A0] (main.py 282): INFO Train: [232/300][30/78]	eta 0:01:40 lr 0.769214	time 1.3475 (2.0986)	loss 2.4497 (2.4944)	grad_norm 0.5037 (0.5062)	mem 39782MB
[2023-07-07 16:14:20 RepVGG-A0] (main.py 282): INFO Train: [232/300][40/78]	eta 0:01:18 lr 0.766422	time 4.2605 (2.0649)	loss 2.5569 (2.5003)	grad_norm 0.5148 (0.5051)	mem 39782MB
[2023-07-07 16:14:35 RepVGG-A0] (main.py 282): INFO Train: [232/300][50/78]	eta 0:00:54 lr 0.763634	time 1.2503 (1.9547)	loss 2.5239 (2.5045)	grad_norm 0.4926 (0.5051)	mem 39782MB
[2023-07-07 16:14:51 RepVGG-A0] (main.py 282): INFO Train: [232/300][60/78]	eta 0:00:34 lr 0.760851	time 1.4590 (1.8966)	loss 2.5363 (2.5064)	grad_norm 0.5255 (0.5054)	mem 39782MB
[2023-07-07 16:15:04 RepVGG-A0] (main.py 282): INFO Train: [232/300][70/78]	eta 0:00:14 lr 0.758073	time 1.2672 (1.8140)	loss 2.4875 (2.5077)	grad_norm 0.5199 (0.5059)	mem 39782MB
[2023-07-07 16:15:16 RepVGG-A0] (main.py 291): INFO EPOCH 232 training takes 0:02:21
[2023-07-07 16:15:38 RepVGG-A0] (main.py 282): INFO Train: [233/300][0/78]	eta 0:28:11 lr 0.755853	time 21.6852 (21.6852)	loss 2.4172 (2.4172)	grad_norm 0.4861 (0.4861)	mem 39782MB
[2023-07-07 16:15:52 RepVGG-A0] (main.py 282): INFO Train: [233/300][10/78]	eta 0:03:43 lr 0.753082	time 1.1724 (3.2820)	loss 2.5254 (2.4816)	grad_norm 0.5264 (0.5047)	mem 39782MB
[2023-07-07 16:16:07 RepVGG-A0] (main.py 282): INFO Train: [233/300][20/78]	eta 0:02:19 lr 0.750316	time 1.1768 (2.4091)	loss 2.4805 (2.4892)	grad_norm 0.5059 (0.5057)	mem 39782MB
[2023-07-07 16:16:23 RepVGG-A0] (main.py 282): INFO Train: [233/300][30/78]	eta 0:01:43 lr 0.747554	time 1.2526 (2.1506)	loss 2.4577 (2.4881)	grad_norm 0.5195 (0.5117)	mem 39782MB
[2023-07-07 16:16:40 RepVGG-A0] (main.py 282): INFO Train: [233/300][40/78]	eta 0:01:17 lr 0.744796	time 3.4723 (2.0369)	loss 2.5155 (2.4891)	grad_norm 0.4857 (0.5098)	mem 39782MB
[2023-07-07 16:16:55 RepVGG-A0] (main.py 282): INFO Train: [233/300][50/78]	eta 0:00:53 lr 0.742043	time 1.1738 (1.9266)	loss 2.4920 (2.4922)	grad_norm 0.5036 (0.5124)	mem 39782MB
[2023-07-07 16:17:10 RepVGG-A0] (main.py 282): INFO Train: [233/300][60/78]	eta 0:00:33 lr 0.739294	time 1.3934 (1.8628)	loss 2.4680 (2.4912)	grad_norm 0.4957 (0.5112)	mem 39782MB
[2023-07-07 16:17:25 RepVGG-A0] (main.py 282): INFO Train: [233/300][70/78]	eta 0:00:14 lr 0.736550	time 1.1446 (1.8102)	loss 2.4791 (2.4923)	grad_norm 0.5257 (0.5134)	mem 39782MB
[2023-07-07 16:17:37 RepVGG-A0] (main.py 291): INFO EPOCH 233 training takes 0:02:20
[2023-07-07 16:18:00 RepVGG-A0] (main.py 282): INFO Train: [234/300][0/78]	eta 0:29:11 lr 0.734358	time 22.4589 (22.4589)	loss 2.4527 (2.4527)	grad_norm 0.5111 (0.5111)	mem 39782MB
[2023-07-07 16:18:14 RepVGG-A0] (main.py 282): INFO Train: [234/300][10/78]	eta 0:03:48 lr 0.731621	time 1.1709 (3.3664)	loss 2.4144 (2.4804)	grad_norm 0.5129 (0.5066)	mem 39782MB
[2023-07-07 16:18:29 RepVGG-A0] (main.py 282): INFO Train: [234/300][20/78]	eta 0:02:23 lr 0.728890	time 1.3436 (2.4702)	loss 2.4147 (2.4742)	grad_norm 0.5179 (0.5055)	mem 39782MB
[2023-07-07 16:18:44 RepVGG-A0] (main.py 282): INFO Train: [234/300][30/78]	eta 0:01:42 lr 0.726162	time 1.2138 (2.1428)	loss 2.5031 (2.4826)	grad_norm 0.5414 (0.5103)	mem 39782MB
[2023-07-07 16:19:02 RepVGG-A0] (main.py 282): INFO Train: [234/300][40/78]	eta 0:01:18 lr 0.723439	time 3.9376 (2.0671)	loss 2.4892 (2.4868)	grad_norm 0.5134 (0.5097)	mem 39782MB
[2023-07-07 16:19:18 RepVGG-A0] (main.py 282): INFO Train: [234/300][50/78]	eta 0:00:55 lr 0.720721	time 1.1731 (1.9768)	loss 2.5875 (2.4906)	grad_norm 0.4892 (0.5068)	mem 39782MB
[2023-07-07 16:19:32 RepVGG-A0] (main.py 282): INFO Train: [234/300][60/78]	eta 0:00:33 lr 0.718007	time 1.1876 (1.8782)	loss 2.5070 (2.4923)	grad_norm 0.5074 (0.5100)	mem 39782MB
[2023-07-07 16:19:48 RepVGG-A0] (main.py 282): INFO Train: [234/300][70/78]	eta 0:00:14 lr 0.715297	time 1.4799 (1.8485)	loss 2.5733 (2.4958)	grad_norm 0.5236 (0.5097)	mem 39782MB
[2023-07-07 16:19:59 RepVGG-A0] (main.py 291): INFO EPOCH 234 training takes 0:02:22
[2023-07-07 16:20:21 RepVGG-A0] (main.py 282): INFO Train: [235/300][0/78]	eta 0:27:51 lr 0.713133	time 21.4238 (21.4238)	loss 2.4317 (2.4317)	grad_norm 0.5096 (0.5096)	mem 39782MB
[2023-07-07 16:20:35 RepVGG-A0] (main.py 282): INFO Train: [235/300][10/78]	eta 0:03:44 lr 0.710431	time 1.1739 (3.2951)	loss 2.4592 (2.4680)	grad_norm 0.5333 (0.5153)	mem 39782MB
[2023-07-07 16:20:51 RepVGG-A0] (main.py 282): INFO Train: [235/300][20/78]	eta 0:02:21 lr 0.707735	time 1.1775 (2.4480)	loss 2.4987 (2.4728)	grad_norm 0.5101 (0.5163)	mem 39782MB
[2023-07-07 16:21:06 RepVGG-A0] (main.py 282): INFO Train: [235/300][30/78]	eta 0:01:43 lr 0.705042	time 1.2191 (2.1664)	loss 2.4826 (2.4724)	grad_norm 0.4835 (0.5139)	mem 39782MB
[2023-07-07 16:21:24 RepVGG-A0] (main.py 282): INFO Train: [235/300][40/78]	eta 0:01:18 lr 0.702354	time 3.6373 (2.0763)	loss 2.4523 (2.4801)	grad_norm 0.5222 (0.5125)	mem 39782MB
[2023-07-07 16:21:39 RepVGG-A0] (main.py 282): INFO Train: [235/300][50/78]	eta 0:00:54 lr 0.699671	time 1.1738 (1.9623)	loss 2.4679 (2.4877)	grad_norm 0.5040 (0.5119)	mem 39782MB
[2023-07-07 16:21:54 RepVGG-A0] (main.py 282): INFO Train: [235/300][60/78]	eta 0:00:34 lr 0.696992	time 1.1265 (1.8896)	loss 2.5058 (2.4891)	grad_norm 0.5282 (0.5113)	mem 39782MB
[2023-07-07 16:22:10 RepVGG-A0] (main.py 282): INFO Train: [235/300][70/78]	eta 0:00:14 lr 0.694317	time 1.3049 (1.8413)	loss 2.4630 (2.4910)	grad_norm 0.5023 (0.5132)	mem 39782MB
[2023-07-07 16:22:21 RepVGG-A0] (main.py 291): INFO EPOCH 235 training takes 0:02:22
[2023-07-07 16:22:43 RepVGG-A0] (main.py 282): INFO Train: [236/300][0/78]	eta 0:28:14 lr 0.692181	time 21.7298 (21.7298)	loss 2.4975 (2.4975)	grad_norm 0.5067 (0.5067)	mem 39782MB
[2023-07-07 16:22:58 RepVGG-A0] (main.py 282): INFO Train: [236/300][10/78]	eta 0:03:45 lr 0.689515	time 1.1733 (3.3132)	loss 2.4823 (2.4664)	grad_norm 0.5149 (0.5207)	mem 39782MB
[2023-07-07 16:23:12 RepVGG-A0] (main.py 282): INFO Train: [236/300][20/78]	eta 0:02:20 lr 0.686853	time 1.1729 (2.4152)	loss 2.4287 (2.4688)	grad_norm 0.5042 (0.5174)	mem 39782MB
[2023-07-07 16:23:28 RepVGG-A0] (main.py 282): INFO Train: [236/300][30/78]	eta 0:01:43 lr 0.684196	time 1.6139 (2.1495)	loss 2.4607 (2.4743)	grad_norm 0.5256 (0.5191)	mem 39782MB
[2023-07-07 16:23:45 RepVGG-A0] (main.py 282): INFO Train: [236/300][40/78]	eta 0:01:17 lr 0.681543	time 3.2436 (2.0506)	loss 2.4974 (2.4785)	grad_norm 0.5654 (0.5184)	mem 39782MB
[2023-07-07 16:24:00 RepVGG-A0] (main.py 282): INFO Train: [236/300][50/78]	eta 0:00:54 lr 0.678895	time 1.1730 (1.9397)	loss 2.4728 (2.4767)	grad_norm 0.5100 (0.5184)	mem 39782MB
[2023-07-07 16:24:15 RepVGG-A0] (main.py 282): INFO Train: [236/300][60/78]	eta 0:00:33 lr 0.676251	time 1.1850 (1.8692)	loss 2.4839 (2.4812)	grad_norm 0.5365 (0.5205)	mem 39782MB
[2023-07-07 16:24:31 RepVGG-A0] (main.py 282): INFO Train: [236/300][70/78]	eta 0:00:14 lr 0.673612	time 1.2044 (1.8263)	loss 2.4588 (2.4827)	grad_norm 0.5180 (0.5196)	mem 39782MB
[2023-07-07 16:24:43 RepVGG-A0] (main.py 291): INFO EPOCH 236 training takes 0:02:21
[2023-07-07 16:25:04 RepVGG-A0] (main.py 282): INFO Train: [237/300][0/78]	eta 0:27:51 lr 0.671504	time 21.4312 (21.4312)	loss 2.4771 (2.4771)	grad_norm 0.5018 (0.5018)	mem 39782MB
[2023-07-07 16:25:21 RepVGG-A0] (main.py 282): INFO Train: [237/300][10/78]	eta 0:03:52 lr 0.668873	time 1.1707 (3.4144)	loss 2.3437 (2.4395)	grad_norm 0.5053 (0.5123)	mem 39782MB
[2023-07-07 16:25:35 RepVGG-A0] (main.py 282): INFO Train: [237/300][20/78]	eta 0:02:24 lr 0.666247	time 1.2069 (2.4915)	loss 2.3733 (2.4476)	grad_norm 0.4952 (0.5129)	mem 39782MB
[2023-07-07 16:25:51 RepVGG-A0] (main.py 282): INFO Train: [237/300][30/78]	eta 0:01:44 lr 0.663625	time 1.1256 (2.1795)	loss 2.4338 (2.4559)	grad_norm 0.5083 (0.5118)	mem 39782MB
[2023-07-07 16:26:09 RepVGG-A0] (main.py 282): INFO Train: [237/300][40/78]	eta 0:01:19 lr 0.661008	time 3.0883 (2.0937)	loss 2.4806 (2.4617)	grad_norm 0.5057 (0.5110)	mem 39782MB
[2023-07-07 16:26:24 RepVGG-A0] (main.py 282): INFO Train: [237/300][50/78]	eta 0:00:55 lr 0.658395	time 1.1752 (1.9778)	loss 2.4637 (2.4657)	grad_norm 0.5189 (0.5121)	mem 39782MB
[2023-07-07 16:26:39 RepVGG-A0] (main.py 282): INFO Train: [237/300][60/78]	eta 0:00:34 lr 0.655787	time 1.4227 (1.9088)	loss 2.5209 (2.4685)	grad_norm 0.5117 (0.5155)	mem 39782MB
[2023-07-07 16:26:54 RepVGG-A0] (main.py 282): INFO Train: [237/300][70/78]	eta 0:00:14 lr 0.653184	time 1.2004 (1.8443)	loss 2.4842 (2.4698)	grad_norm 0.4989 (0.5149)	mem 39782MB
[2023-07-07 16:27:06 RepVGG-A0] (main.py 291): INFO EPOCH 237 training takes 0:02:23
[2023-07-07 16:27:27 RepVGG-A0] (main.py 282): INFO Train: [238/300][0/78]	eta 0:26:58 lr 0.651104	time 20.7438 (20.7438)	loss 2.4234 (2.4234)	grad_norm 0.5201 (0.5201)	mem 39782MB
[2023-07-07 16:27:43 RepVGG-A0] (main.py 282): INFO Train: [238/300][10/78]	eta 0:03:48 lr 0.648509	time 1.1717 (3.3633)	loss 2.4582 (2.4519)	grad_norm 0.5409 (0.5316)	mem 39782MB
[2023-07-07 16:27:58 RepVGG-A0] (main.py 282): INFO Train: [238/300][20/78]	eta 0:02:21 lr 0.645919	time 1.2393 (2.4349)	loss 2.4770 (2.4466)	grad_norm 0.5059 (0.5210)	mem 39782MB
[2023-07-07 16:28:12 RepVGG-A0] (main.py 282): INFO Train: [238/300][30/78]	eta 0:01:42 lr 0.643333	time 1.1764 (2.1251)	loss 2.4632 (2.4551)	grad_norm 0.5094 (0.5194)	mem 39782MB
[2023-07-07 16:28:30 RepVGG-A0] (main.py 282): INFO Train: [238/300][40/78]	eta 0:01:17 lr 0.640751	time 2.4174 (2.0341)	loss 2.4767 (2.4573)	grad_norm 0.5411 (0.5217)	mem 39782MB
[2023-07-07 16:28:46 RepVGG-A0] (main.py 282): INFO Train: [238/300][50/78]	eta 0:00:54 lr 0.638174	time 1.1828 (1.9452)	loss 2.3983 (2.4578)	grad_norm 0.5207 (0.5190)	mem 39782MB
[2023-07-07 16:29:01 RepVGG-A0] (main.py 282): INFO Train: [238/300][60/78]	eta 0:00:33 lr 0.635602	time 1.1732 (1.8776)	loss 2.4168 (2.4589)	grad_norm 0.5533 (0.5213)	mem 39782MB
[2023-07-07 16:29:17 RepVGG-A0] (main.py 282): INFO Train: [238/300][70/78]	eta 0:00:14 lr 0.633035	time 1.3639 (1.8421)	loss 2.4864 (2.4648)	grad_norm 0.5158 (0.5216)	mem 39782MB
[2023-07-07 16:29:30 RepVGG-A0] (main.py 291): INFO EPOCH 238 training takes 0:02:24
[2023-07-07 16:29:50 RepVGG-A0] (main.py 282): INFO Train: [239/300][0/78]	eta 0:25:39 lr 0.630984	time 19.7346 (19.7346)	loss 2.4283 (2.4283)	grad_norm 0.5044 (0.5044)	mem 39782MB
[2023-07-07 16:30:08 RepVGG-A0] (main.py 282): INFO Train: [239/300][10/78]	eta 0:03:50 lr 0.628425	time 1.1719 (3.3831)	loss 2.4487 (2.4480)	grad_norm 0.5167 (0.5076)	mem 39782MB
[2023-07-07 16:30:22 RepVGG-A0] (main.py 282): INFO Train: [239/300][20/78]	eta 0:02:22 lr 0.625870	time 1.1725 (2.4569)	loss 2.4156 (2.4430)	grad_norm 0.5082 (0.5065)	mem 39782MB
[2023-07-07 16:30:37 RepVGG-A0] (main.py 282): INFO Train: [239/300][30/78]	eta 0:01:42 lr 0.623320	time 1.2715 (2.1443)	loss 2.4329 (2.4443)	grad_norm 0.5131 (0.5116)	mem 39782MB
[2023-07-07 16:30:53 RepVGG-A0] (main.py 282): INFO Train: [239/300][40/78]	eta 0:01:16 lr 0.620775	time 2.0226 (2.0013)	loss 2.4328 (2.4479)	grad_norm 0.5239 (0.5122)	mem 39782MB
[2023-07-07 16:31:09 RepVGG-A0] (main.py 282): INFO Train: [239/300][50/78]	eta 0:00:53 lr 0.618235	time 1.1277 (1.9270)	loss 2.4825 (2.4531)	grad_norm 0.5131 (0.5181)	mem 39782MB
[2023-07-07 16:31:24 RepVGG-A0] (main.py 282): INFO Train: [239/300][60/78]	eta 0:00:33 lr 0.615699	time 1.1744 (1.8619)	loss 2.4639 (2.4549)	grad_norm 0.5130 (0.5182)	mem 39782MB
[2023-07-07 16:31:39 RepVGG-A0] (main.py 282): INFO Train: [239/300][70/78]	eta 0:00:14 lr 0.613167	time 1.2008 (1.8132)	loss 2.4910 (2.4570)	grad_norm 0.5155 (0.5188)	mem 39782MB
[2023-07-07 16:31:52 RepVGG-A0] (main.py 291): INFO EPOCH 239 training takes 0:02:21
[2023-07-07 16:32:13 RepVGG-A0] (main.py 282): INFO Train: [240/300][0/78]	eta 0:27:41 lr 0.611146	time 21.3037 (21.3037)	loss 2.3998 (2.3998)	grad_norm 0.5347 (0.5347)	mem 39782MB
[2023-07-07 16:32:27 RepVGG-A0] (main.py 282): INFO Train: [240/300][10/78]	eta 0:03:39 lr 0.608623	time 1.1914 (3.2287)	loss 2.4796 (2.4320)	grad_norm 0.5065 (0.5107)	mem 39782MB
[2023-07-07 16:32:42 RepVGG-A0] (main.py 282): INFO Train: [240/300][20/78]	eta 0:02:17 lr 0.606104	time 1.1930 (2.3680)	loss 2.4648 (2.4309)	grad_norm 0.5195 (0.5150)	mem 39782MB
[2023-07-07 16:32:57 RepVGG-A0] (main.py 282): INFO Train: [240/300][30/78]	eta 0:01:40 lr 0.603591	time 1.1756 (2.0860)	loss 2.5095 (2.4403)	grad_norm 0.5357 (0.5225)	mem 39782MB
[2023-07-07 16:33:15 RepVGG-A0] (main.py 282): INFO Train: [240/300][40/78]	eta 0:01:16 lr 0.601082	time 3.7978 (2.0198)	loss 2.4214 (2.4378)	grad_norm 0.5102 (0.5195)	mem 39782MB
[2023-07-07 16:33:30 RepVGG-A0] (main.py 282): INFO Train: [240/300][50/78]	eta 0:00:53 lr 0.598578	time 1.1716 (1.9230)	loss 2.4790 (2.4411)	grad_norm 0.5417 (0.5226)	mem 39782MB
[2023-07-07 16:33:45 RepVGG-A0] (main.py 282): INFO Train: [240/300][60/78]	eta 0:00:33 lr 0.596078	time 1.1687 (1.8556)	loss 2.4378 (2.4459)	grad_norm 0.5251 (0.5232)	mem 39782MB
[2023-07-07 16:34:01 RepVGG-A0] (main.py 282): INFO Train: [240/300][70/78]	eta 0:00:14 lr 0.593584	time 1.5254 (1.8119)	loss 2.4820 (2.4484)	grad_norm 0.5203 (0.5220)	mem 39782MB
[2023-07-07 16:34:12 RepVGG-A0] (main.py 291): INFO EPOCH 240 training takes 0:02:20
[2023-07-07 16:34:29 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.486 (17.486)	Loss 1.6567 (1.6567)	Acc@1 63.867 (63.867)	Acc@5 85.229 (85.229)	Mem 39782MB
[2023-07-07 16:34:31 RepVGG-A0] (main.py 342): INFO  * Acc@1 63.708 Acc@5 85.256
[2023-07-07 16:34:31 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 240: 63.708%
[2023-07-07 16:34:31 RepVGG-A0] (main.py 172): INFO Max accuracy: 63.71%
[2023-07-07 16:34:53 RepVGG-A0] (main.py 282): INFO Train: [241/300][0/78]	eta 0:28:55 lr 0.591591	time 22.2552 (22.2552)	loss 2.4005 (2.4005)	grad_norm 0.5200 (0.5200)	mem 39782MB
[2023-07-07 16:35:09 RepVGG-A0] (main.py 282): INFO Train: [241/300][10/78]	eta 0:03:55 lr 0.589105	time 1.1940 (3.4563)	loss 2.4257 (2.4024)	grad_norm 0.5386 (0.5268)	mem 39782MB
[2023-07-07 16:35:23 RepVGG-A0] (main.py 282): INFO Train: [241/300][20/78]	eta 0:02:23 lr 0.586623	time 1.2892 (2.4809)	loss 2.3533 (2.4089)	grad_norm 0.5181 (0.5230)	mem 39782MB
[2023-07-07 16:35:38 RepVGG-A0] (main.py 282): INFO Train: [241/300][30/78]	eta 0:01:44 lr 0.584146	time 1.1257 (2.1745)	loss 2.4918 (2.4235)	grad_norm 0.5373 (0.5264)	mem 39782MB
[2023-07-07 16:35:56 RepVGG-A0] (main.py 282): INFO Train: [241/300][40/78]	eta 0:01:18 lr 0.581674	time 3.0716 (2.0754)	loss 2.4747 (2.4318)	grad_norm 0.5300 (0.5295)	mem 39782MB
[2023-07-07 16:36:11 RepVGG-A0] (main.py 282): INFO Train: [241/300][50/78]	eta 0:00:54 lr 0.579206	time 1.1802 (1.9621)	loss 2.5360 (2.4365)	grad_norm 0.5122 (0.5267)	mem 39782MB
[2023-07-07 16:36:26 RepVGG-A0] (main.py 282): INFO Train: [241/300][60/78]	eta 0:00:34 lr 0.576744	time 1.3070 (1.8915)	loss 2.4511 (2.4414)	grad_norm 0.5366 (0.5284)	mem 39782MB
[2023-07-07 16:36:41 RepVGG-A0] (main.py 282): INFO Train: [241/300][70/78]	eta 0:00:14 lr 0.574286	time 1.2558 (1.8376)	loss 2.4865 (2.4435)	grad_norm 0.5246 (0.5284)	mem 39782MB
[2023-07-07 16:36:53 RepVGG-A0] (main.py 291): INFO EPOCH 241 training takes 0:02:22
[2023-07-07 16:37:15 RepVGG-A0] (main.py 282): INFO Train: [242/300][0/78]	eta 0:29:07 lr 0.572323	time 22.4039 (22.4039)	loss 2.4519 (2.4519)	grad_norm 0.4983 (0.4983)	mem 39782MB
[2023-07-07 16:37:30 RepVGG-A0] (main.py 282): INFO Train: [242/300][10/78]	eta 0:03:49 lr 0.569873	time 1.1715 (3.3713)	loss 2.4120 (2.4233)	grad_norm 0.5256 (0.5114)	mem 39782MB
[2023-07-07 16:37:45 RepVGG-A0] (main.py 282): INFO Train: [242/300][20/78]	eta 0:02:25 lr 0.567428	time 1.1816 (2.5014)	loss 2.4146 (2.4243)	grad_norm 0.5348 (0.5161)	mem 39782MB
[2023-07-07 16:38:00 RepVGG-A0] (main.py 282): INFO Train: [242/300][30/78]	eta 0:01:43 lr 0.564988	time 1.1863 (2.1610)	loss 2.4566 (2.4263)	grad_norm 0.5473 (0.5234)	mem 39782MB
[2023-07-07 16:38:17 RepVGG-A0] (main.py 282): INFO Train: [242/300][40/78]	eta 0:01:18 lr 0.562553	time 2.9792 (2.0645)	loss 2.4797 (2.4293)	grad_norm 0.5147 (0.5238)	mem 39782MB
[2023-07-07 16:38:33 RepVGG-A0] (main.py 282): INFO Train: [242/300][50/78]	eta 0:00:54 lr 0.560122	time 1.2645 (1.9559)	loss 2.4854 (2.4332)	grad_norm 0.5428 (0.5256)	mem 39782MB
[2023-07-07 16:38:47 RepVGG-A0] (main.py 282): INFO Train: [242/300][60/78]	eta 0:00:33 lr 0.557697	time 1.1726 (1.8791)	loss 2.4613 (2.4344)	grad_norm 0.5336 (0.5258)	mem 39782MB
[2023-07-07 16:39:03 RepVGG-A0] (main.py 282): INFO Train: [242/300][70/78]	eta 0:00:14 lr 0.555276	time 1.3418 (1.8278)	loss 2.4229 (2.4399)	grad_norm 0.5259 (0.5274)	mem 39782MB
[2023-07-07 16:39:15 RepVGG-A0] (main.py 291): INFO EPOCH 242 training takes 0:02:21
[2023-07-07 16:39:37 RepVGG-A0] (main.py 282): INFO Train: [243/300][0/78]	eta 0:28:57 lr 0.553342	time 22.2764 (22.2764)	loss 2.4427 (2.4427)	grad_norm 0.5264 (0.5264)	mem 39782MB
[2023-07-07 16:39:51 RepVGG-A0] (main.py 282): INFO Train: [243/300][10/78]	eta 0:03:45 lr 0.550930	time 1.1732 (3.3218)	loss 2.4160 (2.4150)	grad_norm 0.5474 (0.5210)	mem 39782MB
[2023-07-07 16:40:06 RepVGG-A0] (main.py 282): INFO Train: [243/300][20/78]	eta 0:02:21 lr 0.548522	time 1.1726 (2.4448)	loss 2.3541 (2.4081)	grad_norm 0.5586 (0.5246)	mem 39782MB
[2023-07-07 16:40:21 RepVGG-A0] (main.py 282): INFO Train: [243/300][30/78]	eta 0:01:43 lr 0.546119	time 1.4689 (2.1490)	loss 2.4715 (2.4105)	grad_norm 0.5263 (0.5280)	mem 39782MB
[2023-07-07 16:40:39 RepVGG-A0] (main.py 282): INFO Train: [243/300][40/78]	eta 0:01:18 lr 0.543721	time 4.4359 (2.0694)	loss 2.4742 (2.4184)	grad_norm 0.5355 (0.5277)	mem 39782MB
[2023-07-07 16:40:54 RepVGG-A0] (main.py 282): INFO Train: [243/300][50/78]	eta 0:00:54 lr 0.541328	time 1.1928 (1.9484)	loss 2.4476 (2.4241)	grad_norm 0.5468 (0.5269)	mem 39782MB
[2023-07-07 16:41:09 RepVGG-A0] (main.py 282): INFO Train: [243/300][60/78]	eta 0:00:33 lr 0.538939	time 1.1919 (1.8797)	loss 2.4481 (2.4251)	grad_norm 0.5250 (0.5287)	mem 39782MB
[2023-07-07 16:41:25 RepVGG-A0] (main.py 282): INFO Train: [243/300][70/78]	eta 0:00:14 lr 0.536556	time 1.2325 (1.8339)	loss 2.4034 (2.4258)	grad_norm 0.5215 (0.5294)	mem 39782MB
[2023-07-07 16:41:36 RepVGG-A0] (main.py 291): INFO EPOCH 243 training takes 0:02:21
[2023-07-07 16:41:58 RepVGG-A0] (main.py 282): INFO Train: [244/300][0/78]	eta 0:28:07 lr 0.534652	time 21.6404 (21.6404)	loss 2.3915 (2.3915)	grad_norm 0.5363 (0.5363)	mem 39782MB
[2023-07-07 16:42:12 RepVGG-A0] (main.py 282): INFO Train: [244/300][10/78]	eta 0:03:42 lr 0.532277	time 1.1726 (3.2662)	loss 2.3414 (2.4038)	grad_norm 0.5216 (0.5318)	mem 39782MB
[2023-07-07 16:42:27 RepVGG-A0] (main.py 282): INFO Train: [244/300][20/78]	eta 0:02:20 lr 0.529907	time 1.2227 (2.4216)	loss 2.4112 (2.4110)	grad_norm 0.5616 (0.5337)	mem 39782MB
[2023-07-07 16:42:43 RepVGG-A0] (main.py 282): INFO Train: [244/300][30/78]	eta 0:01:43 lr 0.527541	time 1.3501 (2.1459)	loss 2.4186 (2.4176)	grad_norm 0.5230 (0.5312)	mem 39782MB
[2023-07-07 16:43:01 RepVGG-A0] (main.py 282): INFO Train: [244/300][40/78]	eta 0:01:18 lr 0.525181	time 3.5481 (2.0583)	loss 2.4478 (2.4213)	grad_norm 0.5274 (0.5338)	mem 39782MB
[2023-07-07 16:43:17 RepVGG-A0] (main.py 282): INFO Train: [244/300][50/78]	eta 0:00:55 lr 0.522825	time 1.3605 (1.9682)	loss 2.3986 (2.4223)	grad_norm 0.5291 (0.5338)	mem 39782MB
[2023-07-07 16:43:32 RepVGG-A0] (main.py 282): INFO Train: [244/300][60/78]	eta 0:00:34 lr 0.520474	time 1.4274 (1.9011)	loss 2.4361 (2.4235)	grad_norm 0.5210 (0.5318)	mem 39782MB
[2023-07-07 16:43:47 RepVGG-A0] (main.py 282): INFO Train: [244/300][70/78]	eta 0:00:14 lr 0.518128	time 1.2067 (1.8436)	loss 2.4249 (2.4236)	grad_norm 0.5280 (0.5313)	mem 39782MB
[2023-07-07 16:43:58 RepVGG-A0] (main.py 291): INFO EPOCH 244 training takes 0:02:22
[2023-07-07 16:44:20 RepVGG-A0] (main.py 282): INFO Train: [245/300][0/78]	eta 0:27:49 lr 0.516254	time 21.4031 (21.4031)	loss 2.4388 (2.4388)	grad_norm 0.5272 (0.5272)	mem 39782MB
[2023-07-07 16:44:35 RepVGG-A0] (main.py 282): INFO Train: [245/300][10/78]	eta 0:03:46 lr 0.513917	time 1.1721 (3.3371)	loss 2.3795 (2.3985)	grad_norm 0.5456 (0.5333)	mem 39782MB
[2023-07-07 16:44:49 RepVGG-A0] (main.py 282): INFO Train: [245/300][20/78]	eta 0:02:20 lr 0.511584	time 1.1740 (2.4240)	loss 2.4072 (2.4039)	grad_norm 0.5279 (0.5315)	mem 39782MB
[2023-07-07 16:45:05 RepVGG-A0] (main.py 282): INFO Train: [245/300][30/78]	eta 0:01:43 lr 0.509256	time 1.6806 (2.1653)	loss 2.3973 (2.4105)	grad_norm 0.5196 (0.5296)	mem 39782MB
[2023-07-07 16:45:24 RepVGG-A0] (main.py 282): INFO Train: [245/300][40/78]	eta 0:01:19 lr 0.506933	time 4.9744 (2.0878)	loss 2.4749 (2.4108)	grad_norm 0.5629 (0.5344)	mem 39782MB
[2023-07-07 16:45:38 RepVGG-A0] (main.py 282): INFO Train: [245/300][50/78]	eta 0:00:54 lr 0.504615	time 1.1849 (1.9570)	loss 2.4428 (2.4150)	grad_norm 0.5365 (0.5367)	mem 39782MB
[2023-07-07 16:45:54 RepVGG-A0] (main.py 282): INFO Train: [245/300][60/78]	eta 0:00:34 lr 0.502302	time 1.3722 (1.8906)	loss 2.4226 (2.4132)	grad_norm 0.5408 (0.5354)	mem 39782MB
[2023-07-07 16:46:09 RepVGG-A0] (main.py 282): INFO Train: [245/300][70/78]	eta 0:00:14 lr 0.499994	time 1.2392 (1.8435)	loss 2.4587 (2.4169)	grad_norm 0.5221 (0.5342)	mem 39782MB
[2023-07-07 16:46:20 RepVGG-A0] (main.py 291): INFO EPOCH 245 training takes 0:02:21
[2023-07-07 16:46:40 RepVGG-A0] (main.py 282): INFO Train: [246/300][0/78]	eta 0:27:00 lr 0.498151	time 20.7733 (20.7733)	loss 2.4790 (2.4790)	grad_norm 0.5154 (0.5154)	mem 39782MB
[2023-07-07 16:46:56 RepVGG-A0] (main.py 282): INFO Train: [246/300][10/78]	eta 0:03:41 lr 0.495851	time 1.1744 (3.2637)	loss 2.4056 (2.3934)	grad_norm 0.5220 (0.5350)	mem 39782MB
[2023-07-07 16:47:10 RepVGG-A0] (main.py 282): INFO Train: [246/300][20/78]	eta 0:02:19 lr 0.493556	time 1.1737 (2.4027)	loss 2.4416 (2.3873)	grad_norm 0.5343 (0.5351)	mem 39782MB
[2023-07-07 16:47:25 RepVGG-A0] (main.py 282): INFO Train: [246/300][30/78]	eta 0:01:41 lr 0.491267	time 1.5489 (2.1105)	loss 2.4345 (2.3930)	grad_norm 0.5511 (0.5362)	mem 39782MB
[2023-07-07 16:47:44 RepVGG-A0] (main.py 282): INFO Train: [246/300][40/78]	eta 0:01:17 lr 0.488982	time 4.0918 (2.0492)	loss 2.4421 (2.4016)	grad_norm 0.5395 (0.5391)	mem 39782MB
[2023-07-07 16:47:59 RepVGG-A0] (main.py 282): INFO Train: [246/300][50/78]	eta 0:00:54 lr 0.486702	time 1.2817 (1.9462)	loss 2.4066 (2.4049)	grad_norm 0.5357 (0.5385)	mem 39782MB
[2023-07-07 16:48:14 RepVGG-A0] (main.py 282): INFO Train: [246/300][60/78]	eta 0:00:33 lr 0.484426	time 1.3706 (1.8744)	loss 2.3972 (2.4064)	grad_norm 0.5322 (0.5378)	mem 39782MB
[2023-07-07 16:48:30 RepVGG-A0] (main.py 282): INFO Train: [246/300][70/78]	eta 0:00:14 lr 0.482156	time 1.2737 (1.8324)	loss 2.3844 (2.4094)	grad_norm 0.5437 (0.5383)	mem 39782MB
[2023-07-07 16:48:42 RepVGG-A0] (main.py 291): INFO EPOCH 246 training takes 0:02:22
[2023-07-07 16:49:04 RepVGG-A0] (main.py 282): INFO Train: [247/300][0/78]	eta 0:27:59 lr 0.480343	time 21.5325 (21.5325)	loss 2.3523 (2.3523)	grad_norm 0.5318 (0.5318)	mem 39782MB
[2023-07-07 16:49:19 RepVGG-A0] (main.py 282): INFO Train: [247/300][10/78]	eta 0:03:45 lr 0.478082	time 1.1734 (3.3223)	loss 2.4017 (2.3853)	grad_norm 0.5305 (0.5308)	mem 39782MB
[2023-07-07 16:49:33 RepVGG-A0] (main.py 282): INFO Train: [247/300][20/78]	eta 0:02:20 lr 0.475825	time 1.1841 (2.4271)	loss 2.3689 (2.3909)	grad_norm 0.5342 (0.5354)	mem 39782MB
[2023-07-07 16:49:49 RepVGG-A0] (main.py 282): INFO Train: [247/300][30/78]	eta 0:01:42 lr 0.473574	time 1.4971 (2.1442)	loss 2.3807 (2.3959)	grad_norm 0.5426 (0.5353)	mem 39782MB
[2023-07-07 16:50:06 RepVGG-A0] (main.py 282): INFO Train: [247/300][40/78]	eta 0:01:17 lr 0.471327	time 3.2129 (2.0428)	loss 2.3888 (2.3987)	grad_norm 0.5285 (0.5371)	mem 39782MB
[2023-07-07 16:50:21 RepVGG-A0] (main.py 282): INFO Train: [247/300][50/78]	eta 0:00:54 lr 0.469085	time 1.2955 (1.9353)	loss 2.3988 (2.4023)	grad_norm 0.5415 (0.5373)	mem 39782MB
[2023-07-07 16:50:36 RepVGG-A0] (main.py 282): INFO Train: [247/300][60/78]	eta 0:00:33 lr 0.466848	time 1.2425 (1.8735)	loss 2.4516 (2.4058)	grad_norm 0.5326 (0.5376)	mem 39782MB
[2023-07-07 16:50:52 RepVGG-A0] (main.py 282): INFO Train: [247/300][70/78]	eta 0:00:14 lr 0.464616	time 1.2651 (1.8226)	loss 2.3726 (2.4065)	grad_norm 0.5408 (0.5387)	mem 39782MB
[2023-07-07 16:51:03 RepVGG-A0] (main.py 291): INFO EPOCH 247 training takes 0:02:21
[2023-07-07 16:51:25 RepVGG-A0] (main.py 282): INFO Train: [248/300][0/78]	eta 0:28:23 lr 0.462834	time 21.8418 (21.8418)	loss 2.3790 (2.3790)	grad_norm 0.5286 (0.5286)	mem 39782MB
[2023-07-07 16:51:40 RepVGG-A0] (main.py 282): INFO Train: [248/300][10/78]	eta 0:03:49 lr 0.460611	time 1.1650 (3.3703)	loss 2.3868 (2.3808)	grad_norm 0.5408 (0.5415)	mem 39782MB
[2023-07-07 16:51:56 RepVGG-A0] (main.py 282): INFO Train: [248/300][20/78]	eta 0:02:24 lr 0.458393	time 1.5471 (2.4965)	loss 2.3319 (2.3874)	grad_norm 0.5374 (0.5391)	mem 39782MB
[2023-07-07 16:52:10 RepVGG-A0] (main.py 282): INFO Train: [248/300][30/78]	eta 0:01:43 lr 0.456180	time 1.3324 (2.1546)	loss 2.3670 (2.3892)	grad_norm 0.5345 (0.5420)	mem 39782MB
[2023-07-07 16:52:28 RepVGG-A0] (main.py 282): INFO Train: [248/300][40/78]	eta 0:01:18 lr 0.453972	time 3.8442 (2.0698)	loss 2.3321 (2.3909)	grad_norm 0.5308 (0.5417)	mem 39782MB
[2023-07-07 16:52:44 RepVGG-A0] (main.py 282): INFO Train: [248/300][50/78]	eta 0:00:54 lr 0.451768	time 1.1718 (1.9631)	loss 2.3754 (2.3940)	grad_norm 0.5242 (0.5407)	mem 39782MB
[2023-07-07 16:52:59 RepVGG-A0] (main.py 282): INFO Train: [248/300][60/78]	eta 0:00:34 lr 0.449570	time 1.1286 (1.8964)	loss 2.4368 (2.3969)	grad_norm 0.5247 (0.5394)	mem 39782MB
[2023-07-07 16:53:14 RepVGG-A0] (main.py 282): INFO Train: [248/300][70/78]	eta 0:00:14 lr 0.447377	time 1.2252 (1.8351)	loss 2.5123 (2.4016)	grad_norm 0.5516 (0.5400)	mem 39782MB
[2023-07-07 16:53:25 RepVGG-A0] (main.py 291): INFO EPOCH 248 training takes 0:02:22
[2023-07-07 16:53:47 RepVGG-A0] (main.py 282): INFO Train: [249/300][0/78]	eta 0:28:13 lr 0.445626	time 21.7126 (21.7126)	loss 2.4150 (2.4150)	grad_norm 0.5415 (0.5415)	mem 39782MB
[2023-07-07 16:54:03 RepVGG-A0] (main.py 282): INFO Train: [249/300][10/78]	eta 0:03:52 lr 0.443441	time 1.1706 (3.4226)	loss 2.4222 (2.3796)	grad_norm 0.5613 (0.5463)	mem 39782MB
[2023-07-07 16:54:19 RepVGG-A0] (main.py 282): INFO Train: [249/300][20/78]	eta 0:02:26 lr 0.441262	time 1.2993 (2.5267)	loss 2.3456 (2.3806)	grad_norm 0.5299 (0.5436)	mem 39782MB
[2023-07-07 16:54:33 RepVGG-A0] (main.py 282): INFO Train: [249/300][30/78]	eta 0:01:44 lr 0.439087	time 1.2440 (2.1719)	loss 2.4502 (2.3831)	grad_norm 0.5466 (0.5423)	mem 39782MB
[2023-07-07 16:54:52 RepVGG-A0] (main.py 282): INFO Train: [249/300][40/78]	eta 0:01:20 lr 0.436918	time 3.5687 (2.1082)	loss 2.4188 (2.3856)	grad_norm 0.5560 (0.5440)	mem 39782MB
[2023-07-07 16:55:07 RepVGG-A0] (main.py 282): INFO Train: [249/300][50/78]	eta 0:00:55 lr 0.434753	time 1.1744 (1.9889)	loss 2.3088 (2.3834)	grad_norm 0.5436 (0.5435)	mem 39782MB
[2023-07-07 16:55:23 RepVGG-A0] (main.py 282): INFO Train: [249/300][60/78]	eta 0:00:34 lr 0.432593	time 1.4400 (1.9237)	loss 2.4015 (2.3857)	grad_norm 0.5453 (0.5442)	mem 39782MB
[2023-07-07 16:55:37 RepVGG-A0] (main.py 282): INFO Train: [249/300][70/78]	eta 0:00:14 lr 0.430439	time 1.4852 (1.8598)	loss 2.4249 (2.3866)	grad_norm 0.5415 (0.5455)	mem 39782MB
[2023-07-07 16:55:49 RepVGG-A0] (main.py 291): INFO EPOCH 249 training takes 0:02:23
[2023-07-07 16:56:12 RepVGG-A0] (main.py 282): INFO Train: [250/300][0/78]	eta 0:29:08 lr 0.428719	time 22.4105 (22.4105)	loss 2.3442 (2.3442)	grad_norm 0.5473 (0.5473)	mem 39782MB
[2023-07-07 16:56:25 RepVGG-A0] (main.py 282): INFO Train: [250/300][10/78]	eta 0:03:43 lr 0.426573	time 1.1721 (3.2860)	loss 2.3994 (2.3839)	grad_norm 0.5381 (0.5453)	mem 39782MB
[2023-07-07 16:56:41 RepVGG-A0] (main.py 282): INFO Train: [250/300][20/78]	eta 0:02:24 lr 0.424433	time 1.3253 (2.4899)	loss 2.3639 (2.3831)	grad_norm 0.5433 (0.5451)	mem 39782MB
[2023-07-07 16:56:56 RepVGG-A0] (main.py 282): INFO Train: [250/300][30/78]	eta 0:01:43 lr 0.422297	time 1.7873 (2.1565)	loss 2.3426 (2.3805)	grad_norm 0.5434 (0.5436)	mem 39782MB
[2023-07-07 16:57:13 RepVGG-A0] (main.py 282): INFO Train: [250/300][40/78]	eta 0:01:17 lr 0.420166	time 3.6509 (2.0516)	loss 2.4034 (2.3807)	grad_norm 0.5405 (0.5441)	mem 39782MB
[2023-07-07 16:57:28 RepVGG-A0] (main.py 282): INFO Train: [250/300][50/78]	eta 0:00:54 lr 0.418041	time 1.2917 (1.9441)	loss 2.4287 (2.3803)	grad_norm 0.5372 (0.5442)	mem 39782MB
[2023-07-07 16:57:44 RepVGG-A0] (main.py 282): INFO Train: [250/300][60/78]	eta 0:00:33 lr 0.415920	time 1.1734 (1.8751)	loss 2.4361 (2.3845)	grad_norm 0.5433 (0.5445)	mem 39782MB
[2023-07-07 16:57:58 RepVGG-A0] (main.py 282): INFO Train: [250/300][70/78]	eta 0:00:14 lr 0.413805	time 1.3094 (1.8212)	loss 2.4155 (2.3883)	grad_norm 0.5415 (0.5441)	mem 39782MB
[2023-07-07 16:58:10 RepVGG-A0] (main.py 291): INFO EPOCH 250 training takes 0:02:21
[2023-07-07 16:58:33 RepVGG-A0] (main.py 282): INFO Train: [251/300][0/78]	eta 0:29:22 lr 0.412116	time 22.5945 (22.5945)	loss 2.3861 (2.3861)	grad_norm 0.5354 (0.5354)	mem 39782MB
[2023-07-07 16:58:47 RepVGG-A0] (main.py 282): INFO Train: [251/300][10/78]	eta 0:03:47 lr 0.410009	time 1.1721 (3.3422)	loss 2.3758 (2.3736)	grad_norm 0.5519 (0.5437)	mem 39782MB
[2023-07-07 16:59:03 RepVGG-A0] (main.py 282): INFO Train: [251/300][20/78]	eta 0:02:25 lr 0.407908	time 1.1961 (2.5051)	loss 2.3882 (2.3747)	grad_norm 0.5602 (0.5462)	mem 39782MB
[2023-07-07 16:59:17 RepVGG-A0] (main.py 282): INFO Train: [251/300][30/78]	eta 0:01:44 lr 0.405811	time 1.3665 (2.1686)	loss 2.4107 (2.3764)	grad_norm 0.5405 (0.5464)	mem 39782MB
[2023-07-07 16:59:35 RepVGG-A0] (main.py 282): INFO Train: [251/300][40/78]	eta 0:01:18 lr 0.403720	time 3.7385 (2.0578)	loss 2.3655 (2.3735)	grad_norm 0.5541 (0.5469)	mem 39782MB
[2023-07-07 16:59:50 RepVGG-A0] (main.py 282): INFO Train: [251/300][50/78]	eta 0:00:54 lr 0.401634	time 1.2713 (1.9572)	loss 2.3602 (2.3741)	grad_norm 0.5494 (0.5473)	mem 39782MB
[2023-07-07 17:00:06 RepVGG-A0] (main.py 282): INFO Train: [251/300][60/78]	eta 0:00:34 lr 0.399552	time 1.1947 (1.8898)	loss 2.4123 (2.3763)	grad_norm 0.5450 (0.5477)	mem 39782MB
[2023-07-07 17:00:20 RepVGG-A0] (main.py 282): INFO Train: [251/300][70/78]	eta 0:00:14 lr 0.397476	time 1.2458 (1.8303)	loss 2.4120 (2.3782)	grad_norm 0.5406 (0.5481)	mem 39782MB
[2023-07-07 17:00:32 RepVGG-A0] (main.py 291): INFO EPOCH 251 training takes 0:02:21
[2023-07-07 17:00:54 RepVGG-A0] (main.py 282): INFO Train: [252/300][0/78]	eta 0:28:30 lr 0.395819	time 21.9293 (21.9293)	loss 2.3777 (2.3777)	grad_norm 0.5385 (0.5385)	mem 39782MB
[2023-07-07 17:01:10 RepVGG-A0] (main.py 282): INFO Train: [252/300][10/78]	eta 0:03:54 lr 0.393751	time 1.1740 (3.4557)	loss 2.3265 (2.3539)	grad_norm 0.5492 (0.5555)	mem 39782MB
[2023-07-07 17:01:25 RepVGG-A0] (main.py 282): INFO Train: [252/300][20/78]	eta 0:02:27 lr 0.391689	time 1.1809 (2.5391)	loss 2.4229 (2.3617)	grad_norm 0.5463 (0.5476)	mem 39782MB
[2023-07-07 17:01:41 RepVGG-A0] (main.py 282): INFO Train: [252/300][30/78]	eta 0:01:47 lr 0.389632	time 1.7494 (2.2330)	loss 2.3683 (2.3663)	grad_norm 0.5640 (0.5487)	mem 39782MB
[2023-07-07 17:01:58 RepVGG-A0] (main.py 282): INFO Train: [252/300][40/78]	eta 0:01:19 lr 0.387580	time 2.3929 (2.1000)	loss 2.4311 (2.3751)	grad_norm 0.5449 (0.5482)	mem 39782MB
[2023-07-07 17:02:14 RepVGG-A0] (main.py 282): INFO Train: [252/300][50/78]	eta 0:00:55 lr 0.385533	time 1.1926 (1.9902)	loss 2.3856 (2.3747)	grad_norm 0.5438 (0.5501)	mem 39782MB
[2023-07-07 17:02:29 RepVGG-A0] (main.py 282): INFO Train: [252/300][60/78]	eta 0:00:34 lr 0.383491	time 1.6860 (1.9193)	loss 2.3644 (2.3737)	grad_norm 0.5508 (0.5500)	mem 39782MB
[2023-07-07 17:02:44 RepVGG-A0] (main.py 282): INFO Train: [252/300][70/78]	eta 0:00:14 lr 0.381455	time 1.4151 (1.8610)	loss 2.3474 (2.3746)	grad_norm 0.5554 (0.5510)	mem 39782MB
[2023-07-07 17:02:56 RepVGG-A0] (main.py 291): INFO EPOCH 252 training takes 0:02:23
[2023-07-07 17:03:18 RepVGG-A0] (main.py 282): INFO Train: [253/300][0/78]	eta 0:28:53 lr 0.379829	time 22.2278 (22.2278)	loss 2.3723 (2.3723)	grad_norm 0.5560 (0.5560)	mem 39782MB
[2023-07-07 17:03:33 RepVGG-A0] (main.py 282): INFO Train: [253/300][10/78]	eta 0:03:51 lr 0.377801	time 1.1917 (3.4065)	loss 2.3511 (2.3509)	grad_norm 0.5352 (0.5418)	mem 39782MB
[2023-07-07 17:03:48 RepVGG-A0] (main.py 282): INFO Train: [253/300][20/78]	eta 0:02:23 lr 0.375779	time 1.1489 (2.4803)	loss 2.3198 (2.3533)	grad_norm 0.5387 (0.5432)	mem 39782MB
[2023-07-07 17:04:03 RepVGG-A0] (main.py 282): INFO Train: [253/300][30/78]	eta 0:01:44 lr 0.373761	time 1.3437 (2.1852)	loss 2.4184 (2.3626)	grad_norm 0.5472 (0.5463)	mem 39782MB
[2023-07-07 17:04:22 RepVGG-A0] (main.py 282): INFO Train: [253/300][40/78]	eta 0:01:20 lr 0.371749	time 2.8540 (2.1073)	loss 2.4002 (2.3660)	grad_norm 0.5497 (0.5491)	mem 39782MB
[2023-07-07 17:04:36 RepVGG-A0] (main.py 282): INFO Train: [253/300][50/78]	eta 0:00:55 lr 0.369742	time 1.1742 (1.9725)	loss 2.3885 (2.3684)	grad_norm 0.5633 (0.5515)	mem 39782MB
[2023-07-07 17:04:52 RepVGG-A0] (main.py 282): INFO Train: [253/300][60/78]	eta 0:00:34 lr 0.367740	time 1.5019 (1.9126)	loss 2.3663 (2.3677)	grad_norm 0.5622 (0.5516)	mem 39782MB
[2023-07-07 17:05:07 RepVGG-A0] (main.py 282): INFO Train: [253/300][70/78]	eta 0:00:14 lr 0.365743	time 1.2334 (1.8484)	loss 2.4111 (2.3696)	grad_norm 0.5523 (0.5535)	mem 39782MB
[2023-07-07 17:05:19 RepVGG-A0] (main.py 291): INFO EPOCH 253 training takes 0:02:23
[2023-07-07 17:05:40 RepVGG-A0] (main.py 282): INFO Train: [254/300][0/78]	eta 0:27:31 lr 0.364149	time 21.1756 (21.1756)	loss 2.3757 (2.3757)	grad_norm 0.5703 (0.5703)	mem 39782MB
[2023-07-07 17:05:55 RepVGG-A0] (main.py 282): INFO Train: [254/300][10/78]	eta 0:03:46 lr 0.362161	time 1.1727 (3.3311)	loss 2.3156 (2.3538)	grad_norm 0.5651 (0.5628)	mem 39782MB
[2023-07-07 17:06:11 RepVGG-A0] (main.py 282): INFO Train: [254/300][20/78]	eta 0:02:22 lr 0.360178	time 1.3007 (2.4634)	loss 2.3935 (2.3521)	grad_norm 0.5542 (0.5571)	mem 39782MB
[2023-07-07 17:06:26 RepVGG-A0] (main.py 282): INFO Train: [254/300][30/78]	eta 0:01:44 lr 0.358200	time 1.5554 (2.1752)	loss 2.3446 (2.3514)	grad_norm 0.5460 (0.5571)	mem 39782MB
[2023-07-07 17:06:44 RepVGG-A0] (main.py 282): INFO Train: [254/300][40/78]	eta 0:01:19 lr 0.356228	time 3.0492 (2.0795)	loss 2.3479 (2.3490)	grad_norm 0.5505 (0.5565)	mem 39782MB
[2023-07-07 17:06:58 RepVGG-A0] (main.py 282): INFO Train: [254/300][50/78]	eta 0:00:54 lr 0.354260	time 1.2007 (1.9499)	loss 2.4057 (2.3541)	grad_norm 0.5571 (0.5577)	mem 39782MB
[2023-07-07 17:07:13 RepVGG-A0] (main.py 282): INFO Train: [254/300][60/78]	eta 0:00:33 lr 0.352298	time 1.3056 (1.8757)	loss 2.3599 (2.3563)	grad_norm 0.5771 (0.5577)	mem 39782MB
[2023-07-07 17:07:28 RepVGG-A0] (main.py 282): INFO Train: [254/300][70/78]	eta 0:00:14 lr 0.350341	time 1.1767 (1.8207)	loss 2.3823 (2.3582)	grad_norm 0.5646 (0.5588)	mem 39782MB
[2023-07-07 17:07:40 RepVGG-A0] (main.py 291): INFO EPOCH 254 training takes 0:02:21
[2023-07-07 17:08:02 RepVGG-A0] (main.py 282): INFO Train: [255/300][0/78]	eta 0:28:17 lr 0.348779	time 21.7680 (21.7680)	loss 2.3233 (2.3233)	grad_norm 0.5669 (0.5669)	mem 39782MB
[2023-07-07 17:08:16 RepVGG-A0] (main.py 282): INFO Train: [255/300][10/78]	eta 0:03:40 lr 0.346831	time 1.1715 (3.2465)	loss 2.3069 (2.3313)	grad_norm 0.5479 (0.5538)	mem 39782MB
[2023-07-07 17:08:30 RepVGG-A0] (main.py 282): INFO Train: [255/300][20/78]	eta 0:02:18 lr 0.344889	time 1.1912 (2.3947)	loss 2.3770 (2.3483)	grad_norm 0.5469 (0.5539)	mem 39782MB
[2023-07-07 17:08:46 RepVGG-A0] (main.py 282): INFO Train: [255/300][30/78]	eta 0:01:42 lr 0.342951	time 1.2514 (2.1446)	loss 2.3348 (2.3533)	grad_norm 0.5710 (0.5572)	mem 39782MB
[2023-07-07 17:09:05 RepVGG-A0] (main.py 282): INFO Train: [255/300][40/78]	eta 0:01:19 lr 0.341019	time 3.2852 (2.0850)	loss 2.3574 (2.3555)	grad_norm 0.5662 (0.5588)	mem 39782MB
[2023-07-07 17:09:20 RepVGG-A0] (main.py 282): INFO Train: [255/300][50/78]	eta 0:00:55 lr 0.339091	time 1.3038 (1.9706)	loss 2.3498 (2.3585)	grad_norm 0.5755 (0.5597)	mem 39782MB
[2023-07-07 17:09:35 RepVGG-A0] (main.py 282): INFO Train: [255/300][60/78]	eta 0:00:34 lr 0.337169	time 1.2180 (1.8940)	loss 2.3585 (2.3616)	grad_norm 0.5575 (0.5600)	mem 39782MB
[2023-07-07 17:09:51 RepVGG-A0] (main.py 282): INFO Train: [255/300][70/78]	eta 0:00:14 lr 0.335252	time 1.2420 (1.8438)	loss 2.3333 (2.3619)	grad_norm 0.5533 (0.5602)	mem 39782MB
[2023-07-07 17:10:01 RepVGG-A0] (main.py 291): INFO EPOCH 255 training takes 0:02:21
[2023-07-07 17:10:23 RepVGG-A0] (main.py 282): INFO Train: [256/300][0/78]	eta 0:28:14 lr 0.333722	time 21.7253 (21.7253)	loss 2.3349 (2.3349)	grad_norm 0.5691 (0.5691)	mem 39782MB
[2023-07-07 17:10:38 RepVGG-A0] (main.py 282): INFO Train: [256/300][10/78]	eta 0:03:44 lr 0.331815	time 1.1728 (3.3014)	loss 2.3534 (2.3246)	grad_norm 0.5738 (0.5588)	mem 39782MB
[2023-07-07 17:10:53 RepVGG-A0] (main.py 282): INFO Train: [256/300][20/78]	eta 0:02:22 lr 0.329912	time 1.2182 (2.4587)	loss 2.3430 (2.3284)	grad_norm 0.5591 (0.5602)	mem 39782MB
[2023-07-07 17:11:08 RepVGG-A0] (main.py 282): INFO Train: [256/300][30/78]	eta 0:01:43 lr 0.328015	time 1.4995 (2.1553)	loss 2.3226 (2.3365)	grad_norm 0.5674 (0.5626)	mem 39782MB
[2023-07-07 17:11:26 RepVGG-A0] (main.py 282): INFO Train: [256/300][40/78]	eta 0:01:18 lr 0.326123	time 2.8723 (2.0594)	loss 2.3791 (2.3399)	grad_norm 0.5526 (0.5633)	mem 39782MB
[2023-07-07 17:11:41 RepVGG-A0] (main.py 282): INFO Train: [256/300][50/78]	eta 0:00:54 lr 0.324236	time 1.1734 (1.9472)	loss 2.3294 (2.3392)	grad_norm 0.5577 (0.5630)	mem 39782MB
[2023-07-07 17:11:56 RepVGG-A0] (main.py 282): INFO Train: [256/300][60/78]	eta 0:00:33 lr 0.322354	time 1.2428 (1.8816)	loss 2.3616 (2.3398)	grad_norm 0.5718 (0.5624)	mem 39782MB
[2023-07-07 17:12:12 RepVGG-A0] (main.py 282): INFO Train: [256/300][70/78]	eta 0:00:14 lr 0.320477	time 1.3093 (1.8344)	loss 2.3399 (2.3407)	grad_norm 0.5744 (0.5625)	mem 39782MB
[2023-07-07 17:12:23 RepVGG-A0] (main.py 291): INFO EPOCH 256 training takes 0:02:21
[2023-07-07 17:12:44 RepVGG-A0] (main.py 282): INFO Train: [257/300][0/78]	eta 0:27:52 lr 0.318980	time 21.4430 (21.4430)	loss 2.2683 (2.2683)	grad_norm 0.5496 (0.5496)	mem 39782MB
[2023-07-07 17:13:00 RepVGG-A0] (main.py 282): INFO Train: [257/300][10/78]	eta 0:03:52 lr 0.317113	time 1.1717 (3.4261)	loss 2.3028 (2.3157)	grad_norm 0.5543 (0.5601)	mem 39782MB
[2023-07-07 17:13:15 RepVGG-A0] (main.py 282): INFO Train: [257/300][20/78]	eta 0:02:25 lr 0.315251	time 1.3532 (2.5063)	loss 2.3138 (2.3247)	grad_norm 0.5422 (0.5634)	mem 39782MB
[2023-07-07 17:13:30 RepVGG-A0] (main.py 282): INFO Train: [257/300][30/78]	eta 0:01:44 lr 0.313394	time 1.3216 (2.1842)	loss 2.3366 (2.3292)	grad_norm 0.5773 (0.5651)	mem 39782MB
[2023-07-07 17:13:49 RepVGG-A0] (main.py 282): INFO Train: [257/300][40/78]	eta 0:01:19 lr 0.311542	time 2.6074 (2.0976)	loss 2.3576 (2.3294)	grad_norm 0.5564 (0.5640)	mem 39782MB
[2023-07-07 17:14:04 RepVGG-A0] (main.py 282): INFO Train: [257/300][50/78]	eta 0:00:55 lr 0.309696	time 1.1743 (1.9973)	loss 2.3449 (2.3314)	grad_norm 0.5823 (0.5645)	mem 39782MB
[2023-07-07 17:14:20 RepVGG-A0] (main.py 282): INFO Train: [257/300][60/78]	eta 0:00:34 lr 0.307854	time 1.4378 (1.9223)	loss 2.3398 (2.3354)	grad_norm 0.5753 (0.5650)	mem 39782MB
[2023-07-07 17:14:35 RepVGG-A0] (main.py 282): INFO Train: [257/300][70/78]	eta 0:00:14 lr 0.306018	time 1.5016 (1.8674)	loss 2.3414 (2.3375)	grad_norm 0.5710 (0.5652)	mem 39782MB
[2023-07-07 17:14:46 RepVGG-A0] (main.py 291): INFO EPOCH 257 training takes 0:02:23
[2023-07-07 17:15:07 RepVGG-A0] (main.py 282): INFO Train: [258/300][0/78]	eta 0:28:14 lr 0.304553	time 21.7244 (21.7244)	loss 2.2936 (2.2936)	grad_norm 0.5610 (0.5610)	mem 39782MB
[2023-07-07 17:15:23 RepVGG-A0] (main.py 282): INFO Train: [258/300][10/78]	eta 0:03:47 lr 0.302727	time 1.1708 (3.3500)	loss 2.3437 (2.3155)	grad_norm 0.5682 (0.5617)	mem 39782MB
[2023-07-07 17:15:38 RepVGG-A0] (main.py 282): INFO Train: [258/300][20/78]	eta 0:02:23 lr 0.300905	time 1.3113 (2.4774)	loss 2.3251 (2.3251)	grad_norm 0.5610 (0.5649)	mem 39782MB
[2023-07-07 17:15:53 RepVGG-A0] (main.py 282): INFO Train: [258/300][30/78]	eta 0:01:44 lr 0.299089	time 1.2362 (2.1734)	loss 2.3319 (2.3214)	grad_norm 0.5888 (0.5667)	mem 39782MB
[2023-07-07 17:16:11 RepVGG-A0] (main.py 282): INFO Train: [258/300][40/78]	eta 0:01:19 lr 0.297278	time 3.6718 (2.0853)	loss 2.3235 (2.3221)	grad_norm 0.5585 (0.5660)	mem 39782MB
[2023-07-07 17:16:26 RepVGG-A0] (main.py 282): INFO Train: [258/300][50/78]	eta 0:00:55 lr 0.295473	time 1.1739 (1.9653)	loss 2.4038 (2.3284)	grad_norm 0.5721 (0.5666)	mem 39782MB
[2023-07-07 17:16:41 RepVGG-A0] (main.py 282): INFO Train: [258/300][60/78]	eta 0:00:34 lr 0.293672	time 1.3458 (1.8903)	loss 2.3393 (2.3289)	grad_norm 0.5658 (0.5671)	mem 39782MB
[2023-07-07 17:16:56 RepVGG-A0] (main.py 282): INFO Train: [258/300][70/78]	eta 0:00:14 lr 0.291877	time 1.1260 (1.8366)	loss 2.2892 (2.3296)	grad_norm 0.5701 (0.5676)	mem 39782MB
[2023-07-07 17:17:08 RepVGG-A0] (main.py 291): INFO EPOCH 258 training takes 0:02:22
[2023-07-07 17:17:30 RepVGG-A0] (main.py 282): INFO Train: [259/300][0/78]	eta 0:28:34 lr 0.290444	time 21.9770 (21.9770)	loss 2.3136 (2.3136)	grad_norm 0.5662 (0.5662)	mem 39782MB
[2023-07-07 17:17:45 RepVGG-A0] (main.py 282): INFO Train: [259/300][10/78]	eta 0:03:47 lr 0.288659	time 1.1704 (3.3443)	loss 2.3191 (2.3185)	grad_norm 0.5638 (0.5631)	mem 39782MB
[2023-07-07 17:18:00 RepVGG-A0] (main.py 282): INFO Train: [259/300][20/78]	eta 0:02:24 lr 0.286878	time 1.2296 (2.4917)	loss 2.3006 (2.3266)	grad_norm 0.5729 (0.5700)	mem 39782MB
[2023-07-07 17:18:14 RepVGG-A0] (main.py 282): INFO Train: [259/300][30/78]	eta 0:01:41 lr 0.285103	time 1.2080 (2.1244)	loss 2.3420 (2.3291)	grad_norm 0.5809 (0.5702)	mem 39782MB
[2023-07-07 17:18:32 RepVGG-A0] (main.py 282): INFO Train: [259/300][40/78]	eta 0:01:18 lr 0.283333	time 3.8033 (2.0653)	loss 2.3120 (2.3280)	grad_norm 0.5714 (0.5703)	mem 39782MB
[2023-07-07 17:18:47 RepVGG-A0] (main.py 282): INFO Train: [259/300][50/78]	eta 0:00:54 lr 0.281568	time 1.1714 (1.9403)	loss 2.3453 (2.3304)	grad_norm 0.5831 (0.5699)	mem 39782MB
[2023-07-07 17:19:02 RepVGG-A0] (main.py 282): INFO Train: [259/300][60/78]	eta 0:00:33 lr 0.279808	time 1.4597 (1.8777)	loss 2.3391 (2.3308)	grad_norm 0.5977 (0.5710)	mem 39782MB
[2023-07-07 17:19:17 RepVGG-A0] (main.py 282): INFO Train: [259/300][70/78]	eta 0:00:14 lr 0.278054	time 1.3281 (1.8234)	loss 2.3225 (2.3315)	grad_norm 0.5771 (0.5717)	mem 39782MB
[2023-07-07 17:19:30 RepVGG-A0] (main.py 291): INFO EPOCH 259 training takes 0:02:21
[2023-07-07 17:19:50 RepVGG-A0] (main.py 282): INFO Train: [260/300][0/78]	eta 0:27:12 lr 0.276655	time 20.9339 (20.9339)	loss 2.2867 (2.2867)	grad_norm 0.5650 (0.5650)	mem 39782MB
[2023-07-07 17:20:06 RepVGG-A0] (main.py 282): INFO Train: [260/300][10/78]	eta 0:03:43 lr 0.274910	time 1.1711 (3.2842)	loss 2.3376 (2.3160)	grad_norm 0.5658 (0.5689)	mem 39782MB
[2023-07-07 17:20:20 RepVGG-A0] (main.py 282): INFO Train: [260/300][20/78]	eta 0:02:19 lr 0.273170	time 1.3339 (2.4073)	loss 2.3980 (2.3228)	grad_norm 0.5763 (0.5697)	mem 39782MB
[2023-07-07 17:20:35 RepVGG-A0] (main.py 282): INFO Train: [260/300][30/78]	eta 0:01:40 lr 0.271436	time 1.2020 (2.1018)	loss 2.3404 (2.3217)	grad_norm 0.5676 (0.5700)	mem 39782MB
[2023-07-07 17:20:53 RepVGG-A0] (main.py 282): INFO Train: [260/300][40/78]	eta 0:01:17 lr 0.269707	time 3.6008 (2.0321)	loss 2.2854 (2.3211)	grad_norm 0.5700 (0.5724)	mem 39782MB
[2023-07-07 17:21:08 RepVGG-A0] (main.py 282): INFO Train: [260/300][50/78]	eta 0:00:54 lr 0.267983	time 1.3092 (1.9362)	loss 2.3047 (2.3218)	grad_norm 0.5723 (0.5737)	mem 39782MB
[2023-07-07 17:21:23 RepVGG-A0] (main.py 282): INFO Train: [260/300][60/78]	eta 0:00:33 lr 0.266265	time 1.2090 (1.8625)	loss 2.3491 (2.3238)	grad_norm 0.5727 (0.5749)	mem 39782MB
[2023-07-07 17:21:38 RepVGG-A0] (main.py 282): INFO Train: [260/300][70/78]	eta 0:00:14 lr 0.264552	time 1.1861 (1.8138)	loss 2.3272 (2.3253)	grad_norm 0.5777 (0.5755)	mem 39782MB
[2023-07-07 17:21:51 RepVGG-A0] (main.py 291): INFO EPOCH 260 training takes 0:02:20
[2023-07-07 17:22:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.969 (16.969)	Loss 1.4969 (1.4969)	Acc@1 67.114 (67.114)	Acc@5 87.482 (87.482)	Mem 39782MB
[2023-07-07 17:22:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 67.272 Acc@5 87.486
[2023-07-07 17:22:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 260: 67.272%
[2023-07-07 17:22:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 67.27%
[2023-07-07 17:22:30 RepVGG-A0] (main.py 282): INFO Train: [261/300][0/78]	eta 0:27:45 lr 0.263185	time 21.3504 (21.3504)	loss 2.2747 (2.2747)	grad_norm 0.5742 (0.5742)	mem 39782MB
[2023-07-07 17:22:46 RepVGG-A0] (main.py 282): INFO Train: [261/300][10/78]	eta 0:03:47 lr 0.261482	time 1.1710 (3.3518)	loss 2.2773 (2.3029)	grad_norm 0.5759 (0.5737)	mem 39782MB
[2023-07-07 17:23:00 RepVGG-A0] (main.py 282): INFO Train: [261/300][20/78]	eta 0:02:21 lr 0.259783	time 1.1751 (2.4406)	loss 2.4047 (2.3104)	grad_norm 0.5811 (0.5762)	mem 39782MB
[2023-07-07 17:23:15 RepVGG-A0] (main.py 282): INFO Train: [261/300][30/78]	eta 0:01:42 lr 0.258090	time 1.5628 (2.1262)	loss 2.3146 (2.3121)	grad_norm 0.5711 (0.5770)	mem 39782MB
[2023-07-07 17:23:32 RepVGG-A0] (main.py 282): INFO Train: [261/300][40/78]	eta 0:01:17 lr 0.256403	time 1.8621 (2.0308)	loss 2.3486 (2.3133)	grad_norm 0.5813 (0.5768)	mem 39782MB
[2023-07-07 17:23:48 RepVGG-A0] (main.py 282): INFO Train: [261/300][50/78]	eta 0:00:54 lr 0.254720	time 1.1721 (1.9463)	loss 2.2891 (2.3133)	grad_norm 0.5722 (0.5772)	mem 39782MB
[2023-07-07 17:24:03 RepVGG-A0] (main.py 282): INFO Train: [261/300][60/78]	eta 0:00:33 lr 0.253043	time 1.1908 (1.8655)	loss 2.3832 (2.3153)	grad_norm 0.5751 (0.5766)	mem 39782MB
[2023-07-07 17:24:18 RepVGG-A0] (main.py 282): INFO Train: [261/300][70/78]	eta 0:00:14 lr 0.251371	time 1.3467 (1.8223)	loss 2.3137 (2.3185)	grad_norm 0.5704 (0.5782)	mem 39782MB
[2023-07-07 17:24:30 RepVGG-A0] (main.py 291): INFO EPOCH 261 training takes 0:02:21
[2023-07-07 17:24:52 RepVGG-A0] (main.py 282): INFO Train: [262/300][0/78]	eta 0:28:20 lr 0.250038	time 21.8053 (21.8053)	loss 2.2726 (2.2726)	grad_norm 0.5803 (0.5803)	mem 39782MB
[2023-07-07 17:25:07 RepVGG-A0] (main.py 282): INFO Train: [262/300][10/78]	eta 0:03:45 lr 0.248376	time 1.1905 (3.3093)	loss 2.2831 (2.2852)	grad_norm 0.5728 (0.5734)	mem 39782MB
[2023-07-07 17:25:22 RepVGG-A0] (main.py 282): INFO Train: [262/300][20/78]	eta 0:02:21 lr 0.246719	time 1.1739 (2.4459)	loss 2.2744 (2.2891)	grad_norm 0.5873 (0.5748)	mem 39782MB
[2023-07-07 17:25:38 RepVGG-A0] (main.py 282): INFO Train: [262/300][30/78]	eta 0:01:44 lr 0.245067	time 1.4675 (2.1795)	loss 2.2525 (2.2927)	grad_norm 0.5979 (0.5759)	mem 39782MB
[2023-07-07 17:25:56 RepVGG-A0] (main.py 282): INFO Train: [262/300][40/78]	eta 0:01:19 lr 0.243421	time 3.6384 (2.0792)	loss 2.3057 (2.2970)	grad_norm 0.5793 (0.5774)	mem 39782MB
[2023-07-07 17:26:10 RepVGG-A0] (main.py 282): INFO Train: [262/300][50/78]	eta 0:00:54 lr 0.241780	time 1.1726 (1.9625)	loss 2.3100 (2.2989)	grad_norm 0.5810 (0.5782)	mem 39782MB
[2023-07-07 17:26:26 RepVGG-A0] (main.py 282): INFO Train: [262/300][60/78]	eta 0:00:33 lr 0.240145	time 1.3072 (1.8877)	loss 2.3108 (2.3027)	grad_norm 0.5828 (0.5782)	mem 39782MB
[2023-07-07 17:26:41 RepVGG-A0] (main.py 282): INFO Train: [262/300][70/78]	eta 0:00:14 lr 0.238514	time 1.5170 (1.8356)	loss 2.3256 (2.3049)	grad_norm 0.5824 (0.5790)	mem 39782MB
[2023-07-07 17:26:52 RepVGG-A0] (main.py 291): INFO EPOCH 262 training takes 0:02:22
[2023-07-07 17:27:13 RepVGG-A0] (main.py 282): INFO Train: [263/300][0/78]	eta 0:27:15 lr 0.237214	time 20.9727 (20.9727)	loss 2.3149 (2.3149)	grad_norm 0.6101 (0.6101)	mem 39782MB
[2023-07-07 17:27:28 RepVGG-A0] (main.py 282): INFO Train: [263/300][10/78]	eta 0:03:39 lr 0.235594	time 1.1731 (3.2230)	loss 2.3239 (2.3153)	grad_norm 0.5813 (0.6169)	mem 39782MB
[2023-07-07 17:27:43 RepVGG-A0] (main.py 282): INFO Train: [263/300][20/78]	eta 0:02:20 lr 0.233978	time 1.2832 (2.4255)	loss 2.3591 (2.2973)	grad_norm 0.5791 (0.5982)	mem 39782MB
[2023-07-07 17:28:05 RepVGG-A0] (main.py 282): INFO Train: [263/300][30/78]	eta 0:01:51 lr 0.232368	time 1.1715 (2.3283)	loss 2.2939 (2.2977)	grad_norm 0.5789 (0.5924)	mem 39782MB
[2023-07-07 17:28:21 RepVGG-A0] (main.py 282): INFO Train: [263/300][40/78]	eta 0:01:21 lr 0.230764	time 1.1766 (2.1518)	loss 2.3414 (2.3026)	grad_norm 0.5843 (0.5906)	mem 39782MB
[2023-07-07 17:28:36 RepVGG-A0] (main.py 282): INFO Train: [263/300][50/78]	eta 0:00:57 lr 0.229165	time 1.1781 (2.0361)	loss 2.3287 (2.3029)	grad_norm 0.5638 (0.5889)	mem 39782MB
[2023-07-07 17:28:51 RepVGG-A0] (main.py 282): INFO Train: [263/300][60/78]	eta 0:00:35 lr 0.227571	time 1.2576 (1.9449)	loss 2.3157 (2.3058)	grad_norm 0.5914 (0.5885)	mem 39782MB
[2023-07-07 17:29:06 RepVGG-A0] (main.py 282): INFO Train: [263/300][70/78]	eta 0:00:15 lr 0.225982	time 1.2252 (1.8802)	loss 2.3096 (2.3054)	grad_norm 0.5738 (0.5882)	mem 39782MB
[2023-07-07 17:29:17 RepVGG-A0] (main.py 291): INFO EPOCH 263 training takes 0:02:24
[2023-07-07 17:29:37 RepVGG-A0] (main.py 282): INFO Train: [264/300][0/78]	eta 0:26:54 lr 0.224715	time 20.6934 (20.6934)	loss 2.2419 (2.2419)	grad_norm 0.5828 (0.5828)	mem 39782MB
[2023-07-07 17:29:53 RepVGG-A0] (main.py 282): INFO Train: [264/300][10/78]	eta 0:03:41 lr 0.223136	time 1.1719 (3.2610)	loss 2.3332 (2.2719)	grad_norm 0.5700 (0.5851)	mem 39782MB
[2023-07-07 17:30:07 RepVGG-A0] (main.py 282): INFO Train: [264/300][20/78]	eta 0:02:19 lr 0.221563	time 1.1728 (2.4061)	loss 2.3093 (2.2748)	grad_norm 0.5929 (0.5869)	mem 39782MB
[2023-07-07 17:30:23 RepVGG-A0] (main.py 282): INFO Train: [264/300][30/78]	eta 0:01:41 lr 0.219995	time 1.1817 (2.1214)	loss 2.2894 (2.2859)	grad_norm 0.6009 (0.5866)	mem 39782MB
[2023-07-07 17:30:40 RepVGG-A0] (main.py 282): INFO Train: [264/300][40/78]	eta 0:01:17 lr 0.218432	time 3.3827 (2.0298)	loss 2.3022 (2.2916)	grad_norm 0.5828 (0.5865)	mem 39782MB
[2023-07-07 17:30:55 RepVGG-A0] (main.py 282): INFO Train: [264/300][50/78]	eta 0:00:54 lr 0.216875	time 1.1728 (1.9344)	loss 2.2808 (2.2959)	grad_norm 0.5860 (0.5859)	mem 39782MB
[2023-07-07 17:31:11 RepVGG-A0] (main.py 282): INFO Train: [264/300][60/78]	eta 0:00:33 lr 0.215323	time 1.2292 (1.8753)	loss 2.3526 (2.2963)	grad_norm 0.5947 (0.5869)	mem 39782MB
[2023-07-07 17:31:26 RepVGG-A0] (main.py 282): INFO Train: [264/300][70/78]	eta 0:00:14 lr 0.213776	time 1.2226 (1.8142)	loss 2.3309 (2.2974)	grad_norm 0.5859 (0.5867)	mem 39782MB
[2023-07-07 17:31:38 RepVGG-A0] (main.py 291): INFO EPOCH 264 training takes 0:02:20
[2023-07-07 17:32:00 RepVGG-A0] (main.py 282): INFO Train: [265/300][0/78]	eta 0:28:40 lr 0.212543	time 22.0569 (22.0569)	loss 2.2719 (2.2719)	grad_norm 0.5911 (0.5911)	mem 39782MB
[2023-07-07 17:32:15 RepVGG-A0] (main.py 282): INFO Train: [265/300][10/78]	eta 0:03:49 lr 0.211006	time 1.1914 (3.3770)	loss 2.2448 (2.2779)	grad_norm 0.5899 (0.5860)	mem 39782MB
[2023-07-07 17:32:29 RepVGG-A0] (main.py 282): INFO Train: [265/300][20/78]	eta 0:02:23 lr 0.209474	time 1.2090 (2.4743)	loss 2.2812 (2.2705)	grad_norm 0.5889 (0.5902)	mem 39782MB
[2023-07-07 17:32:44 RepVGG-A0] (main.py 282): INFO Train: [265/300][30/78]	eta 0:01:43 lr 0.207948	time 1.2392 (2.1552)	loss 2.3235 (2.2789)	grad_norm 0.5842 (0.5901)	mem 39782MB
[2023-07-07 17:33:02 RepVGG-A0] (main.py 282): INFO Train: [265/300][40/78]	eta 0:01:18 lr 0.206427	time 3.7167 (2.0672)	loss 2.3237 (2.2813)	grad_norm 0.6056 (0.5899)	mem 39782MB
[2023-07-07 17:33:17 RepVGG-A0] (main.py 282): INFO Train: [265/300][50/78]	eta 0:00:54 lr 0.204912	time 1.1725 (1.9513)	loss 2.2711 (2.2848)	grad_norm 0.5949 (0.5911)	mem 39782MB
[2023-07-07 17:33:33 RepVGG-A0] (main.py 282): INFO Train: [265/300][60/78]	eta 0:00:33 lr 0.203402	time 1.3606 (1.8863)	loss 2.3388 (2.2898)	grad_norm 0.5862 (0.5911)	mem 39782MB
[2023-07-07 17:33:48 RepVGG-A0] (main.py 282): INFO Train: [265/300][70/78]	eta 0:00:14 lr 0.201897	time 1.3213 (1.8428)	loss 2.3571 (2.2906)	grad_norm 0.5918 (0.5905)	mem 39782MB
[2023-07-07 17:33:59 RepVGG-A0] (main.py 291): INFO EPOCH 265 training takes 0:02:21
[2023-07-07 17:34:21 RepVGG-A0] (main.py 282): INFO Train: [266/300][0/78]	eta 0:28:14 lr 0.200698	time 21.7306 (21.7306)	loss 2.2613 (2.2613)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 17:34:36 RepVGG-A0] (main.py 282): INFO Train: [266/300][10/78]	eta 0:03:47 lr 0.199203	time 1.1731 (3.3439)	loss 2.2636 (2.2757)	grad_norm 0.5801 (0.5881)	mem 39782MB
[2023-07-07 17:34:51 RepVGG-A0] (main.py 282): INFO Train: [266/300][20/78]	eta 0:02:22 lr 0.197713	time 1.2882 (2.4642)	loss 2.2644 (2.2694)	grad_norm 0.5976 (0.5885)	mem 39782MB
[2023-07-07 17:35:06 RepVGG-A0] (main.py 282): INFO Train: [266/300][30/78]	eta 0:01:43 lr 0.196229	time 1.3007 (2.1639)	loss 2.2774 (2.2723)	grad_norm 0.5975 (0.5891)	mem 39782MB
[2023-07-07 17:35:23 RepVGG-A0] (main.py 282): INFO Train: [266/300][40/78]	eta 0:01:17 lr 0.194751	time 2.6806 (2.0461)	loss 2.2485 (2.2754)	grad_norm 0.5995 (0.5908)	mem 39782MB
[2023-07-07 17:35:39 RepVGG-A0] (main.py 282): INFO Train: [266/300][50/78]	eta 0:00:54 lr 0.193278	time 1.1727 (1.9510)	loss 2.3164 (2.2779)	grad_norm 0.5956 (0.5913)	mem 39782MB
[2023-07-07 17:35:54 RepVGG-A0] (main.py 282): INFO Train: [266/300][60/78]	eta 0:00:33 lr 0.191810	time 1.2013 (1.8726)	loss 2.2993 (2.2795)	grad_norm 0.5952 (0.5922)	mem 39782MB
[2023-07-07 17:36:09 RepVGG-A0] (main.py 282): INFO Train: [266/300][70/78]	eta 0:00:14 lr 0.190348	time 1.4107 (1.8203)	loss 2.2851 (2.2804)	grad_norm 0.6125 (0.5929)	mem 39782MB
[2023-07-07 17:36:21 RepVGG-A0] (main.py 291): INFO EPOCH 266 training takes 0:02:21
[2023-07-07 17:36:41 RepVGG-A0] (main.py 282): INFO Train: [267/300][0/78]	eta 0:26:00 lr 0.189182	time 20.0112 (20.0112)	loss 2.3107 (2.3107)	grad_norm 0.5900 (0.5900)	mem 39782MB
[2023-07-07 17:36:56 RepVGG-A0] (main.py 282): INFO Train: [267/300][10/78]	eta 0:03:34 lr 0.187729	time 1.1894 (3.1546)	loss 2.3200 (2.2745)	grad_norm 0.5996 (0.5898)	mem 39782MB
[2023-07-07 17:37:12 RepVGG-A0] (main.py 282): INFO Train: [267/300][20/78]	eta 0:02:21 lr 0.186282	time 1.3277 (2.4343)	loss 2.3304 (2.2785)	grad_norm 0.6010 (0.5914)	mem 39782MB
[2023-07-07 17:37:27 RepVGG-A0] (main.py 282): INFO Train: [267/300][30/78]	eta 0:01:41 lr 0.184840	time 1.3389 (2.1233)	loss 2.2817 (2.2766)	grad_norm 0.5988 (0.5931)	mem 39782MB
[2023-07-07 17:37:43 RepVGG-A0] (main.py 282): INFO Train: [267/300][40/78]	eta 0:01:16 lr 0.183404	time 3.6385 (2.0064)	loss 2.3306 (2.2750)	grad_norm 0.5921 (0.5955)	mem 39782MB
[2023-07-07 17:37:58 RepVGG-A0] (main.py 282): INFO Train: [267/300][50/78]	eta 0:00:53 lr 0.181973	time 1.1665 (1.9044)	loss 2.2663 (2.2729)	grad_norm 0.6023 (0.5957)	mem 39782MB
[2023-07-07 17:38:13 RepVGG-A0] (main.py 282): INFO Train: [267/300][60/78]	eta 0:00:33 lr 0.180548	time 1.1733 (1.8374)	loss 2.2436 (2.2732)	grad_norm 0.6014 (0.5958)	mem 39782MB
[2023-07-07 17:38:28 RepVGG-A0] (main.py 282): INFO Train: [267/300][70/78]	eta 0:00:14 lr 0.179128	time 1.3610 (1.7903)	loss 2.2789 (2.2720)	grad_norm 0.6048 (0.5967)	mem 39782MB
[2023-07-07 17:38:40 RepVGG-A0] (main.py 291): INFO EPOCH 267 training takes 0:02:18
[2023-07-07 17:39:00 RepVGG-A0] (main.py 282): INFO Train: [268/300][0/78]	eta 0:26:57 lr 0.177996	time 20.7332 (20.7332)	loss 2.2414 (2.2414)	grad_norm 0.5898 (0.5898)	mem 39782MB
[2023-07-07 17:39:16 RepVGG-A0] (main.py 282): INFO Train: [268/300][10/78]	eta 0:03:41 lr 0.176585	time 1.1719 (3.2643)	loss 2.2757 (2.2532)	grad_norm 0.5931 (0.5918)	mem 39782MB
[2023-07-07 17:39:31 RepVGG-A0] (main.py 282): INFO Train: [268/300][20/78]	eta 0:02:22 lr 0.175181	time 1.4991 (2.4619)	loss 2.3496 (2.2609)	grad_norm 0.5965 (0.5918)	mem 39782MB
[2023-07-07 17:39:46 RepVGG-A0] (main.py 282): INFO Train: [268/300][30/78]	eta 0:01:42 lr 0.173782	time 1.3608 (2.1336)	loss 2.2054 (2.2590)	grad_norm 0.5863 (0.5934)	mem 39782MB
[2023-07-07 17:40:03 RepVGG-A0] (main.py 282): INFO Train: [268/300][40/78]	eta 0:01:17 lr 0.172388	time 3.2250 (2.0409)	loss 2.2528 (2.2580)	grad_norm 0.5968 (0.5946)	mem 39782MB
[2023-07-07 17:40:19 RepVGG-A0] (main.py 282): INFO Train: [268/300][50/78]	eta 0:00:54 lr 0.170999	time 1.1722 (1.9438)	loss 2.1858 (2.2572)	grad_norm 0.5996 (0.5957)	mem 39782MB
[2023-07-07 17:40:34 RepVGG-A0] (main.py 282): INFO Train: [268/300][60/78]	eta 0:00:33 lr 0.169617	time 1.1678 (1.8738)	loss 2.2468 (2.2642)	grad_norm 0.5948 (0.5972)	mem 39782MB
[2023-07-07 17:40:49 RepVGG-A0] (main.py 282): INFO Train: [268/300][70/78]	eta 0:00:14 lr 0.168239	time 1.2743 (1.8167)	loss 2.3010 (2.2655)	grad_norm 0.6081 (0.5977)	mem 39782MB
[2023-07-07 17:41:00 RepVGG-A0] (main.py 291): INFO EPOCH 268 training takes 0:02:20
[2023-07-07 17:41:21 RepVGG-A0] (main.py 282): INFO Train: [269/300][0/78]	eta 0:27:23 lr 0.167141	time 21.0716 (21.0716)	loss 2.3250 (2.3250)	grad_norm 0.5896 (0.5896)	mem 39782MB
[2023-07-07 17:41:36 RepVGG-A0] (main.py 282): INFO Train: [269/300][10/78]	eta 0:03:43 lr 0.165774	time 1.1748 (3.2858)	loss 2.2518 (2.2470)	grad_norm 0.6026 (0.5946)	mem 39782MB
[2023-07-07 17:41:51 RepVGG-A0] (main.py 282): INFO Train: [269/300][20/78]	eta 0:02:21 lr 0.164411	time 1.2062 (2.4404)	loss 2.2299 (2.2451)	grad_norm 0.6027 (0.5969)	mem 39782MB
[2023-07-07 17:42:07 RepVGG-A0] (main.py 282): INFO Train: [269/300][30/78]	eta 0:01:42 lr 0.163055	time 1.2723 (2.1436)	loss 2.2278 (2.2492)	grad_norm 0.5956 (0.5978)	mem 39782MB
[2023-07-07 17:42:26 RepVGG-A0] (main.py 282): INFO Train: [269/300][40/78]	eta 0:01:19 lr 0.161704	time 3.7314 (2.0801)	loss 2.2675 (2.2563)	grad_norm 0.6046 (0.5996)	mem 39782MB
[2023-07-07 17:42:40 RepVGG-A0] (main.py 282): INFO Train: [269/300][50/78]	eta 0:00:54 lr 0.160358	time 1.1771 (1.9593)	loss 2.2372 (2.2602)	grad_norm 0.5963 (0.6004)	mem 39782MB
[2023-07-07 17:42:55 RepVGG-A0] (main.py 282): INFO Train: [269/300][60/78]	eta 0:00:33 lr 0.159018	time 1.1760 (1.8869)	loss 2.2472 (2.2584)	grad_norm 0.6096 (0.6003)	mem 39782MB
[2023-07-07 17:43:10 RepVGG-A0] (main.py 282): INFO Train: [269/300][70/78]	eta 0:00:14 lr 0.157683	time 1.3702 (1.8305)	loss 2.2467 (2.2583)	grad_norm 0.5994 (0.6009)	mem 39782MB
[2023-07-07 17:43:21 RepVGG-A0] (main.py 291): INFO EPOCH 269 training takes 0:02:20
[2023-07-07 17:43:43 RepVGG-A0] (main.py 282): INFO Train: [270/300][0/78]	eta 0:28:48 lr 0.156619	time 22.1654 (22.1654)	loss 2.2078 (2.2078)	grad_norm 0.6002 (0.6002)	mem 39782MB
[2023-07-07 17:43:58 RepVGG-A0] (main.py 282): INFO Train: [270/300][10/78]	eta 0:03:50 lr 0.155294	time 1.1733 (3.3834)	loss 2.2031 (2.2350)	grad_norm 0.5950 (0.6043)	mem 39782MB
[2023-07-07 17:44:14 RepVGG-A0] (main.py 282): INFO Train: [270/300][20/78]	eta 0:02:24 lr 0.153975	time 1.1617 (2.4893)	loss 2.2311 (2.2388)	grad_norm 0.5992 (0.6035)	mem 39782MB
[2023-07-07 17:44:29 RepVGG-A0] (main.py 282): INFO Train: [270/300][30/78]	eta 0:01:44 lr 0.152661	time 1.5634 (2.1766)	loss 2.2300 (2.2444)	grad_norm 0.6050 (0.6041)	mem 39782MB
[2023-07-07 17:44:46 RepVGG-A0] (main.py 282): INFO Train: [270/300][40/78]	eta 0:01:18 lr 0.151353	time 3.2316 (2.0651)	loss 2.2250 (2.2469)	grad_norm 0.6112 (0.6051)	mem 39782MB
[2023-07-07 17:45:01 RepVGG-A0] (main.py 282): INFO Train: [270/300][50/78]	eta 0:00:54 lr 0.150050	time 1.3933 (1.9578)	loss 2.3152 (2.2499)	grad_norm 0.6031 (0.6053)	mem 39782MB
[2023-07-07 17:45:16 RepVGG-A0] (main.py 282): INFO Train: [270/300][60/78]	eta 0:00:33 lr 0.148752	time 1.1276 (1.8790)	loss 2.2162 (2.2518)	grad_norm 0.6040 (0.6058)	mem 39782MB
[2023-07-07 17:45:31 RepVGG-A0] (main.py 282): INFO Train: [270/300][70/78]	eta 0:00:14 lr 0.147460	time 1.2462 (1.8269)	loss 2.2615 (2.2536)	grad_norm 0.6121 (0.6065)	mem 39782MB
[2023-07-07 17:45:42 RepVGG-A0] (main.py 291): INFO EPOCH 270 training takes 0:02:21
[2023-07-07 17:46:02 RepVGG-A0] (main.py 282): INFO Train: [271/300][0/78]	eta 0:25:35 lr 0.146431	time 19.6884 (19.6884)	loss 2.2531 (2.2531)	grad_norm 0.6115 (0.6115)	mem 39782MB
[2023-07-07 17:46:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][10/78]	eta 0:03:49 lr 0.145149	time 1.1713 (3.3788)	loss 2.2013 (2.2322)	grad_norm 0.5993 (0.6003)	mem 39782MB
[2023-07-07 17:46:33 RepVGG-A0] (main.py 282): INFO Train: [271/300][20/78]	eta 0:02:20 lr 0.143872	time 1.2178 (2.4199)	loss 2.2210 (2.2448)	grad_norm 0.5962 (0.6028)	mem 39782MB
[2023-07-07 17:46:48 RepVGG-A0] (main.py 282): INFO Train: [271/300][30/78]	eta 0:01:41 lr 0.142602	time 1.1916 (2.1046)	loss 2.2658 (2.2425)	grad_norm 0.6090 (0.6048)	mem 39782MB
[2023-07-07 17:47:05 RepVGG-A0] (main.py 282): INFO Train: [271/300][40/78]	eta 0:01:16 lr 0.141336	time 3.3189 (2.0126)	loss 2.2855 (2.2451)	grad_norm 0.6036 (0.6051)	mem 39782MB
[2023-07-07 17:47:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][50/78]	eta 0:00:53 lr 0.140076	time 1.1811 (1.9123)	loss 2.2724 (2.2468)	grad_norm 0.6162 (0.6058)	mem 39782MB
[2023-07-07 17:47:36 RepVGG-A0] (main.py 282): INFO Train: [271/300][60/78]	eta 0:00:33 lr 0.138822	time 1.2513 (1.8530)	loss 2.2657 (2.2495)	grad_norm 0.6106 (0.6069)	mem 39782MB
[2023-07-07 17:47:50 RepVGG-A0] (main.py 282): INFO Train: [271/300][70/78]	eta 0:00:14 lr 0.137573	time 1.3906 (1.7998)	loss 2.2509 (2.2502)	grad_norm 0.6113 (0.6073)	mem 39782MB
[2023-07-07 17:48:02 RepVGG-A0] (main.py 291): INFO EPOCH 271 training takes 0:02:19
[2023-07-07 17:48:24 RepVGG-A0] (main.py 282): INFO Train: [272/300][0/78]	eta 0:28:38 lr 0.136578	time 22.0304 (22.0304)	loss 2.2343 (2.2343)	grad_norm 0.6081 (0.6081)	mem 39782MB
[2023-07-07 17:48:39 RepVGG-A0] (main.py 282): INFO Train: [272/300][10/78]	eta 0:03:46 lr 0.135339	time 1.1724 (3.3308)	loss 2.2699 (2.2480)	grad_norm 0.6057 (0.6103)	mem 39782MB
[2023-07-07 17:48:53 RepVGG-A0] (main.py 282): INFO Train: [272/300][20/78]	eta 0:02:21 lr 0.134105	time 1.1809 (2.4392)	loss 2.2579 (2.2489)	grad_norm 0.6070 (0.6112)	mem 39782MB
[2023-07-07 17:49:08 RepVGG-A0] (main.py 282): INFO Train: [272/300][30/78]	eta 0:01:41 lr 0.132877	time 1.1710 (2.1196)	loss 2.2055 (2.2411)	grad_norm 0.6172 (0.6116)	mem 39782MB
[2023-07-07 17:49:25 RepVGG-A0] (main.py 282): INFO Train: [272/300][40/78]	eta 0:01:17 lr 0.131655	time 3.9518 (2.0287)	loss 2.3054 (2.2398)	grad_norm 0.6209 (0.6121)	mem 39782MB
[2023-07-07 17:49:41 RepVGG-A0] (main.py 282): INFO Train: [272/300][50/78]	eta 0:00:54 lr 0.130438	time 1.1863 (1.9334)	loss 2.2604 (2.2364)	grad_norm 0.6034 (0.6133)	mem 39782MB
[2023-07-07 17:49:56 RepVGG-A0] (main.py 282): INFO Train: [272/300][60/78]	eta 0:00:33 lr 0.129227	time 1.1752 (1.8667)	loss 2.2357 (2.2388)	grad_norm 0.6289 (0.6136)	mem 39782MB
[2023-07-07 17:50:12 RepVGG-A0] (main.py 282): INFO Train: [272/300][70/78]	eta 0:00:14 lr 0.128021	time 1.2820 (1.8236)	loss 2.2828 (2.2422)	grad_norm 0.6133 (0.6140)	mem 39782MB
[2023-07-07 17:50:24 RepVGG-A0] (main.py 291): INFO EPOCH 272 training takes 0:02:21
[2023-07-07 17:50:45 RepVGG-A0] (main.py 282): INFO Train: [273/300][0/78]	eta 0:27:07 lr 0.127060	time 20.8621 (20.8621)	loss 2.2637 (2.2637)	grad_norm 0.6025 (0.6025)	mem 39782MB
[2023-07-07 17:51:01 RepVGG-A0] (main.py 282): INFO Train: [273/300][10/78]	eta 0:03:51 lr 0.125864	time 1.1720 (3.4054)	loss 2.2499 (2.2318)	grad_norm 0.6136 (0.6100)	mem 39782MB
[2023-07-07 17:51:17 RepVGG-A0] (main.py 282): INFO Train: [273/300][20/78]	eta 0:02:27 lr 0.124674	time 1.2912 (2.5408)	loss 2.2971 (2.2368)	grad_norm 0.6155 (0.6130)	mem 39782MB
[2023-07-07 17:51:32 RepVGG-A0] (main.py 282): INFO Train: [273/300][30/78]	eta 0:01:46 lr 0.123489	time 1.4676 (2.2149)	loss 2.2823 (2.2367)	grad_norm 0.6181 (0.6123)	mem 39782MB
[2023-07-07 17:51:50 RepVGG-A0] (main.py 282): INFO Train: [273/300][40/78]	eta 0:01:19 lr 0.122310	time 2.3245 (2.1036)	loss 2.2270 (2.2360)	grad_norm 0.6127 (0.6129)	mem 39782MB
[2023-07-07 17:52:06 RepVGG-A0] (main.py 282): INFO Train: [273/300][50/78]	eta 0:00:55 lr 0.121136	time 1.3667 (1.9965)	loss 2.2097 (2.2356)	grad_norm 0.6200 (0.6141)	mem 39782MB
[2023-07-07 17:52:20 RepVGG-A0] (main.py 282): INFO Train: [273/300][60/78]	eta 0:00:34 lr 0.119968	time 1.1746 (1.9065)	loss 2.2255 (2.2386)	grad_norm 0.6246 (0.6147)	mem 39782MB
[2023-07-07 17:52:36 RepVGG-A0] (main.py 282): INFO Train: [273/300][70/78]	eta 0:00:14 lr 0.118806	time 1.8446 (1.8554)	loss 2.2659 (2.2403)	grad_norm 0.6233 (0.6163)	mem 39782MB
[2023-07-07 17:52:46 RepVGG-A0] (main.py 291): INFO EPOCH 273 training takes 0:02:22
[2023-07-07 17:53:07 RepVGG-A0] (main.py 282): INFO Train: [274/300][0/78]	eta 0:26:31 lr 0.117880	time 20.4046 (20.4046)	loss 2.1993 (2.1993)	grad_norm 0.6061 (0.6061)	mem 39782MB
[2023-07-07 17:53:22 RepVGG-A0] (main.py 282): INFO Train: [274/300][10/78]	eta 0:03:39 lr 0.116727	time 1.1909 (3.2262)	loss 2.2192 (2.2313)	grad_norm 0.6169 (0.6088)	mem 39782MB
[2023-07-07 17:53:37 RepVGG-A0] (main.py 282): INFO Train: [274/300][20/78]	eta 0:02:20 lr 0.115580	time 1.1902 (2.4169)	loss 2.2107 (2.2278)	grad_norm 0.6198 (0.6120)	mem 39782MB
[2023-07-07 17:53:52 RepVGG-A0] (main.py 282): INFO Train: [274/300][30/78]	eta 0:01:41 lr 0.114439	time 1.4346 (2.1213)	loss 2.1396 (2.2309)	grad_norm 0.6142 (0.6141)	mem 39782MB
[2023-07-07 17:54:11 RepVGG-A0] (main.py 282): INFO Train: [274/300][40/78]	eta 0:01:18 lr 0.113303	time 3.6596 (2.0562)	loss 2.1928 (2.2320)	grad_norm 0.6123 (0.6146)	mem 39782MB
[2023-07-07 17:54:26 RepVGG-A0] (main.py 282): INFO Train: [274/300][50/78]	eta 0:00:54 lr 0.112173	time 1.2026 (1.9452)	loss 2.2482 (2.2323)	grad_norm 0.6258 (0.6161)	mem 39782MB
[2023-07-07 17:54:40 RepVGG-A0] (main.py 282): INFO Train: [274/300][60/78]	eta 0:00:33 lr 0.111048	time 1.1990 (1.8659)	loss 2.2395 (2.2350)	grad_norm 0.6216 (0.6162)	mem 39782MB
[2023-07-07 17:54:55 RepVGG-A0] (main.py 282): INFO Train: [274/300][70/78]	eta 0:00:14 lr 0.109929	time 1.2989 (1.8123)	loss 2.2307 (2.2354)	grad_norm 0.6171 (0.6171)	mem 39782MB
[2023-07-07 17:55:07 RepVGG-A0] (main.py 291): INFO EPOCH 274 training takes 0:02:20
[2023-07-07 17:55:28 RepVGG-A0] (main.py 282): INFO Train: [275/300][0/78]	eta 0:26:58 lr 0.109037	time 20.7462 (20.7462)	loss 2.2151 (2.2151)	grad_norm 0.6124 (0.6124)	mem 39782MB
[2023-07-07 17:55:43 RepVGG-A0] (main.py 282): INFO Train: [275/300][10/78]	eta 0:03:40 lr 0.107928	time 1.1709 (3.2437)	loss 2.2074 (2.2067)	grad_norm 0.6142 (0.6143)	mem 39782MB
[2023-07-07 17:55:57 RepVGG-A0] (main.py 282): INFO Train: [275/300][20/78]	eta 0:02:18 lr 0.106825	time 1.1720 (2.3934)	loss 2.2211 (2.2011)	grad_norm 0.6073 (0.6151)	mem 39782MB
[2023-07-07 17:56:13 RepVGG-A0] (main.py 282): INFO Train: [275/300][30/78]	eta 0:01:41 lr 0.105727	time 1.3248 (2.1213)	loss 2.2313 (2.2076)	grad_norm 0.6171 (0.6158)	mem 39782MB
[2023-07-07 17:56:30 RepVGG-A0] (main.py 282): INFO Train: [275/300][40/78]	eta 0:01:17 lr 0.104634	time 3.6763 (2.0278)	loss 2.2503 (2.2124)	grad_norm 0.6200 (0.6171)	mem 39782MB
[2023-07-07 17:56:45 RepVGG-A0] (main.py 282): INFO Train: [275/300][50/78]	eta 0:00:53 lr 0.103547	time 1.1723 (1.9177)	loss 2.2404 (2.2178)	grad_norm 0.6284 (0.6182)	mem 39782MB
[2023-07-07 17:57:00 RepVGG-A0] (main.py 282): INFO Train: [275/300][60/78]	eta 0:00:33 lr 0.102466	time 1.3293 (1.8543)	loss 2.2215 (2.2213)	grad_norm 0.6174 (0.6187)	mem 39782MB
[2023-07-07 17:57:15 RepVGG-A0] (main.py 282): INFO Train: [275/300][70/78]	eta 0:00:14 lr 0.101390	time 1.1720 (1.8036)	loss 2.2882 (2.2241)	grad_norm 0.6305 (0.6191)	mem 39782MB
[2023-07-07 17:57:26 RepVGG-A0] (main.py 291): INFO EPOCH 275 training takes 0:02:19
[2023-07-07 17:57:49 RepVGG-A0] (main.py 282): INFO Train: [276/300][0/78]	eta 0:29:17 lr 0.100534	time 22.5304 (22.5304)	loss 2.2336 (2.2336)	grad_norm 0.6158 (0.6158)	mem 39782MB
[2023-07-07 17:58:03 RepVGG-A0] (main.py 282): INFO Train: [276/300][10/78]	eta 0:03:43 lr 0.099468	time 1.1920 (3.2799)	loss 2.2639 (2.2293)	grad_norm 0.6254 (0.6183)	mem 39782MB
[2023-07-07 17:58:17 RepVGG-A0] (main.py 282): INFO Train: [276/300][20/78]	eta 0:02:18 lr 0.098408	time 1.2376 (2.3947)	loss 2.1878 (2.2296)	grad_norm 0.6192 (0.6210)	mem 39782MB
[2023-07-07 17:58:33 RepVGG-A0] (main.py 282): INFO Train: [276/300][30/78]	eta 0:01:43 lr 0.097354	time 1.1450 (2.1493)	loss 2.1930 (2.2272)	grad_norm 0.6238 (0.6215)	mem 39782MB
[2023-07-07 17:58:50 RepVGG-A0] (main.py 282): INFO Train: [276/300][40/78]	eta 0:01:17 lr 0.096305	time 3.4814 (2.0489)	loss 2.3157 (2.2325)	grad_norm 0.6140 (0.6213)	mem 39782MB
[2023-07-07 17:59:06 RepVGG-A0] (main.py 282): INFO Train: [276/300][50/78]	eta 0:00:54 lr 0.095262	time 1.1735 (1.9430)	loss 2.2179 (2.2322)	grad_norm 0.6189 (0.6214)	mem 39782MB
[2023-07-07 17:59:22 RepVGG-A0] (main.py 282): INFO Train: [276/300][60/78]	eta 0:00:34 lr 0.094224	time 1.2042 (1.8932)	loss 2.2260 (2.2298)	grad_norm 0.6191 (0.6219)	mem 39782MB
[2023-07-07 17:59:37 RepVGG-A0] (main.py 282): INFO Train: [276/300][70/78]	eta 0:00:14 lr 0.093192	time 1.2103 (1.8327)	loss 2.2053 (2.2296)	grad_norm 0.6211 (0.6219)	mem 39782MB
[2023-07-07 17:59:49 RepVGG-A0] (main.py 291): INFO EPOCH 276 training takes 0:02:22
[2023-07-07 18:00:11 RepVGG-A0] (main.py 282): INFO Train: [277/300][0/78]	eta 0:28:00 lr 0.092370	time 21.5431 (21.5431)	loss 2.1962 (2.1962)	grad_norm 0.6191 (0.6191)	mem 39782MB
[2023-07-07 18:00:25 RepVGG-A0] (main.py 282): INFO Train: [277/300][10/78]	eta 0:03:44 lr 0.091348	time 1.1725 (3.2956)	loss 2.1712 (2.2014)	grad_norm 0.6192 (0.6209)	mem 39782MB
[2023-07-07 18:00:41 RepVGG-A0] (main.py 282): INFO Train: [277/300][20/78]	eta 0:02:23 lr 0.090332	time 1.3308 (2.4759)	loss 2.2361 (2.2043)	grad_norm 0.6143 (0.6234)	mem 39782MB
[2023-07-07 18:00:56 RepVGG-A0] (main.py 282): INFO Train: [277/300][30/78]	eta 0:01:43 lr 0.089321	time 1.1278 (2.1520)	loss 2.2234 (2.2110)	grad_norm 0.6254 (0.6242)	mem 39782MB
[2023-07-07 18:01:13 RepVGG-A0] (main.py 282): INFO Train: [277/300][40/78]	eta 0:01:18 lr 0.088316	time 2.3349 (2.0535)	loss 2.2567 (2.2130)	grad_norm 0.6309 (0.6240)	mem 39782MB
[2023-07-07 18:01:29 RepVGG-A0] (main.py 282): INFO Train: [277/300][50/78]	eta 0:00:54 lr 0.087316	time 1.1708 (1.9596)	loss 2.1777 (2.2183)	grad_norm 0.6257 (0.6247)	mem 39782MB
[2023-07-07 18:01:44 RepVGG-A0] (main.py 282): INFO Train: [277/300][60/78]	eta 0:00:33 lr 0.086322	time 1.2025 (1.8868)	loss 2.2746 (2.2182)	grad_norm 0.6303 (0.6249)	mem 39782MB
[2023-07-07 18:01:59 RepVGG-A0] (main.py 282): INFO Train: [277/300][70/78]	eta 0:00:14 lr 0.085334	time 1.1743 (1.8294)	loss 2.1963 (2.2191)	grad_norm 0.6297 (0.6249)	mem 39782MB
[2023-07-07 18:02:11 RepVGG-A0] (main.py 291): INFO EPOCH 277 training takes 0:02:21
[2023-07-07 18:02:31 RepVGG-A0] (main.py 282): INFO Train: [278/300][0/78]	eta 0:26:22 lr 0.084548	time 20.2843 (20.2843)	loss 2.1673 (2.1673)	grad_norm 0.6245 (0.6245)	mem 39782MB
[2023-07-07 18:02:47 RepVGG-A0] (main.py 282): INFO Train: [278/300][10/78]	eta 0:03:41 lr 0.083569	time 1.1728 (3.2597)	loss 2.1832 (2.1995)	grad_norm 0.6288 (0.6279)	mem 39782MB
[2023-07-07 18:03:01 RepVGG-A0] (main.py 282): INFO Train: [278/300][20/78]	eta 0:02:18 lr 0.082597	time 1.2335 (2.3898)	loss 2.2022 (2.1994)	grad_norm 0.6294 (0.6258)	mem 39782MB
[2023-07-07 18:03:17 RepVGG-A0] (main.py 282): INFO Train: [278/300][30/78]	eta 0:01:42 lr 0.081630	time 1.5435 (2.1391)	loss 2.2031 (2.2026)	grad_norm 0.6267 (0.6270)	mem 39782MB
[2023-07-07 18:03:34 RepVGG-A0] (main.py 282): INFO Train: [278/300][40/78]	eta 0:01:16 lr 0.080668	time 3.7118 (2.0234)	loss 2.1800 (2.2020)	grad_norm 0.6280 (0.6274)	mem 39782MB
[2023-07-07 18:03:49 RepVGG-A0] (main.py 282): INFO Train: [278/300][50/78]	eta 0:00:53 lr 0.079713	time 1.1733 (1.9209)	loss 2.2271 (2.2024)	grad_norm 0.6328 (0.6273)	mem 39782MB
[2023-07-07 18:04:05 RepVGG-A0] (main.py 282): INFO Train: [278/300][60/78]	eta 0:00:33 lr 0.078762	time 1.2628 (1.8762)	loss 2.1629 (2.2014)	grad_norm 0.6323 (0.6273)	mem 39782MB
[2023-07-07 18:04:20 RepVGG-A0] (main.py 282): INFO Train: [278/300][70/78]	eta 0:00:14 lr 0.077818	time 1.2688 (1.8192)	loss 2.2411 (2.2040)	grad_norm 0.6310 (0.6271)	mem 39782MB
[2023-07-07 18:04:32 RepVGG-A0] (main.py 291): INFO EPOCH 278 training takes 0:02:21
[2023-07-07 18:04:54 RepVGG-A0] (main.py 282): INFO Train: [279/300][0/78]	eta 0:29:02 lr 0.077066	time 22.3370 (22.3370)	loss 2.1646 (2.1646)	grad_norm 0.6333 (0.6333)	mem 39782MB
[2023-07-07 18:05:08 RepVGG-A0] (main.py 282): INFO Train: [279/300][10/78]	eta 0:03:44 lr 0.076132	time 1.1816 (3.3061)	loss 2.1987 (2.1961)	grad_norm 0.6290 (0.6256)	mem 39782MB
[2023-07-07 18:05:22 RepVGG-A0] (main.py 282): INFO Train: [279/300][20/78]	eta 0:02:18 lr 0.075203	time 1.1711 (2.3935)	loss 2.2097 (2.1916)	grad_norm 0.6231 (0.6288)	mem 39782MB
[2023-07-07 18:05:38 RepVGG-A0] (main.py 282): INFO Train: [279/300][30/78]	eta 0:01:41 lr 0.074280	time 1.2647 (2.1214)	loss 2.1857 (2.2015)	grad_norm 0.6293 (0.6302)	mem 39782MB
[2023-07-07 18:05:56 RepVGG-A0] (main.py 282): INFO Train: [279/300][40/78]	eta 0:01:17 lr 0.073363	time 3.3881 (2.0413)	loss 2.2218 (2.2028)	grad_norm 0.6336 (0.6288)	mem 39782MB
[2023-07-07 18:06:11 RepVGG-A0] (main.py 282): INFO Train: [279/300][50/78]	eta 0:00:54 lr 0.072451	time 1.1723 (1.9330)	loss 2.1873 (2.2019)	grad_norm 0.6366 (0.6295)	mem 39782MB
[2023-07-07 18:06:26 RepVGG-A0] (main.py 282): INFO Train: [279/300][60/78]	eta 0:00:33 lr 0.071545	time 1.1802 (1.8615)	loss 2.2035 (2.2042)	grad_norm 0.6231 (0.6301)	mem 39782MB
[2023-07-07 18:06:41 RepVGG-A0] (main.py 282): INFO Train: [279/300][70/78]	eta 0:00:14 lr 0.070644	time 1.3018 (1.8112)	loss 2.2109 (2.2048)	grad_norm 0.6338 (0.6305)	mem 39782MB
[2023-07-07 18:06:52 RepVGG-A0] (main.py 291): INFO EPOCH 279 training takes 0:02:20
[2023-07-07 18:07:14 RepVGG-A0] (main.py 282): INFO Train: [280/300][0/78]	eta 0:28:30 lr 0.069928	time 21.9307 (21.9307)	loss 2.2051 (2.2051)	grad_norm 0.6307 (0.6307)	mem 39782MB
[2023-07-07 18:07:29 RepVGG-A0] (main.py 282): INFO Train: [280/300][10/78]	eta 0:03:46 lr 0.069037	time 1.1901 (3.3292)	loss 2.2145 (2.1913)	grad_norm 0.6386 (0.6312)	mem 39782MB
[2023-07-07 18:07:44 RepVGG-A0] (main.py 282): INFO Train: [280/300][20/78]	eta 0:02:22 lr 0.068153	time 1.3231 (2.4503)	loss 2.2024 (2.1914)	grad_norm 0.6311 (0.6313)	mem 39782MB
[2023-07-07 18:07:58 RepVGG-A0] (main.py 282): INFO Train: [280/300][30/78]	eta 0:01:41 lr 0.067273	time 1.1897 (2.1203)	loss 2.1580 (2.1872)	grad_norm 0.6304 (0.6313)	mem 39782MB
[2023-07-07 18:08:17 RepVGG-A0] (main.py 282): INFO Train: [280/300][40/78]	eta 0:01:19 lr 0.066400	time 5.0632 (2.0805)	loss 2.2191 (2.1886)	grad_norm 0.6321 (0.6312)	mem 39782MB
[2023-07-07 18:08:32 RepVGG-A0] (main.py 282): INFO Train: [280/300][50/78]	eta 0:00:54 lr 0.065532	time 1.1906 (1.9614)	loss 2.1663 (2.1904)	grad_norm 0.6427 (0.6314)	mem 39782MB
[2023-07-07 18:08:47 RepVGG-A0] (main.py 282): INFO Train: [280/300][60/78]	eta 0:00:33 lr 0.064670	time 1.1722 (1.8867)	loss 2.2189 (2.1898)	grad_norm 0.6401 (0.6316)	mem 39782MB
[2023-07-07 18:09:03 RepVGG-A0] (main.py 282): INFO Train: [280/300][70/78]	eta 0:00:14 lr 0.063813	time 1.1798 (1.8363)	loss 2.1993 (2.1905)	grad_norm 0.6405 (0.6322)	mem 39782MB
[2023-07-07 18:09:14 RepVGG-A0] (main.py 291): INFO EPOCH 280 training takes 0:02:22
[2023-07-07 18:09:32 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.586 (17.586)	Loss 1.3635 (1.3635)	Acc@1 69.037 (69.037)	Acc@5 88.812 (88.812)	Mem 39782MB
[2023-07-07 18:09:33 RepVGG-A0] (main.py 342): INFO  * Acc@1 69.638 Acc@5 88.854
[2023-07-07 18:09:33 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 280: 69.638%
[2023-07-07 18:09:33 RepVGG-A0] (main.py 172): INFO Max accuracy: 69.64%
[2023-07-07 18:09:52 RepVGG-A0] (main.py 282): INFO Train: [281/300][0/78]	eta 0:24:42 lr 0.063132	time 19.0093 (19.0093)	loss 2.1249 (2.1249)	grad_norm 0.6216 (0.6216)	mem 39782MB
[2023-07-07 18:10:08 RepVGG-A0] (main.py 282): INFO Train: [281/300][10/78]	eta 0:03:36 lr 0.062286	time 1.1715 (3.1869)	loss 2.1375 (2.1799)	grad_norm 0.6274 (0.6287)	mem 39782MB
[2023-07-07 18:10:24 RepVGG-A0] (main.py 282): INFO Train: [281/300][20/78]	eta 0:02:20 lr 0.061445	time 1.1927 (2.4219)	loss 2.1397 (2.1794)	grad_norm 0.6191 (0.6288)	mem 39782MB
[2023-07-07 18:10:39 RepVGG-A0] (main.py 282): INFO Train: [281/300][30/78]	eta 0:01:42 lr 0.060610	time 1.3031 (2.1302)	loss 2.1783 (2.1798)	grad_norm 0.6321 (0.6304)	mem 39782MB
[2023-07-07 18:10:58 RepVGG-A0] (main.py 282): INFO Train: [281/300][40/78]	eta 0:01:18 lr 0.059781	time 2.8845 (2.0572)	loss 2.1954 (2.1794)	grad_norm 0.6289 (0.6306)	mem 39782MB
[2023-07-07 18:11:12 RepVGG-A0] (main.py 282): INFO Train: [281/300][50/78]	eta 0:00:54 lr 0.058957	time 1.1723 (1.9376)	loss 2.1918 (2.1848)	grad_norm 0.6314 (0.6313)	mem 39782MB
[2023-07-07 18:11:28 RepVGG-A0] (main.py 282): INFO Train: [281/300][60/78]	eta 0:00:33 lr 0.058139	time 1.2337 (1.8747)	loss 2.1849 (2.1860)	grad_norm 0.6353 (0.6314)	mem 39782MB
[2023-07-07 18:11:43 RepVGG-A0] (main.py 282): INFO Train: [281/300][70/78]	eta 0:00:14 lr 0.057327	time 1.1726 (1.8291)	loss 2.1931 (2.1869)	grad_norm 0.6258 (0.6322)	mem 39782MB
[2023-07-07 18:11:54 RepVGG-A0] (main.py 291): INFO EPOCH 281 training takes 0:02:21
[2023-07-07 18:12:15 RepVGG-A0] (main.py 282): INFO Train: [282/300][0/78]	eta 0:27:30 lr 0.056681	time 21.1626 (21.1626)	loss 2.1909 (2.1909)	grad_norm 0.6240 (0.6240)	mem 39782MB
[2023-07-07 18:12:32 RepVGG-A0] (main.py 282): INFO Train: [282/300][10/78]	eta 0:03:51 lr 0.055879	time 1.1715 (3.4022)	loss 2.1842 (2.1842)	grad_norm 0.6307 (0.6304)	mem 39782MB
[2023-07-07 18:12:46 RepVGG-A0] (main.py 282): INFO Train: [282/300][20/78]	eta 0:02:24 lr 0.055082	time 1.3576 (2.4840)	loss 2.1670 (2.1797)	grad_norm 0.6330 (0.6300)	mem 39782MB
[2023-07-07 18:13:02 RepVGG-A0] (main.py 282): INFO Train: [282/300][30/78]	eta 0:01:44 lr 0.054291	time 1.5441 (2.1782)	loss 2.1487 (2.1760)	grad_norm 0.6427 (0.6300)	mem 39782MB
[2023-07-07 18:13:20 RepVGG-A0] (main.py 282): INFO Train: [282/300][40/78]	eta 0:01:19 lr 0.053506	time 4.4595 (2.0928)	loss 2.1989 (2.1763)	grad_norm 0.6304 (0.6312)	mem 39782MB
[2023-07-07 18:13:34 RepVGG-A0] (main.py 282): INFO Train: [282/300][50/78]	eta 0:00:54 lr 0.052727	time 1.1737 (1.9639)	loss 2.1497 (2.1786)	grad_norm 0.6291 (0.6317)	mem 39782MB
[2023-07-07 18:13:50 RepVGG-A0] (main.py 282): INFO Train: [282/300][60/78]	eta 0:00:34 lr 0.051953	time 1.4504 (1.8984)	loss 2.2462 (2.1818)	grad_norm 0.6489 (0.6326)	mem 39782MB
[2023-07-07 18:14:05 RepVGG-A0] (main.py 282): INFO Train: [282/300][70/78]	eta 0:00:14 lr 0.051185	time 1.3548 (1.8413)	loss 2.1935 (2.1813)	grad_norm 0.6391 (0.6338)	mem 39782MB
[2023-07-07 18:14:16 RepVGG-A0] (main.py 291): INFO EPOCH 282 training takes 0:02:21
[2023-07-07 18:14:35 RepVGG-A0] (main.py 282): INFO Train: [283/300][0/78]	eta 0:23:56 lr 0.050574	time 18.4139 (18.4139)	loss 2.2045 (2.2045)	grad_norm 0.6352 (0.6352)	mem 39782MB
[2023-07-07 18:14:52 RepVGG-A0] (main.py 282): INFO Train: [283/300][10/78]	eta 0:03:42 lr 0.049816	time 1.1719 (3.2765)	loss 2.2320 (2.1902)	grad_norm 0.6357 (0.6315)	mem 39782MB
[2023-07-07 18:15:07 RepVGG-A0] (main.py 282): INFO Train: [283/300][20/78]	eta 0:02:19 lr 0.049064	time 1.1754 (2.4137)	loss 2.1720 (2.1820)	grad_norm 0.6375 (0.6325)	mem 39782MB
[2023-07-07 18:15:21 RepVGG-A0] (main.py 282): INFO Train: [283/300][30/78]	eta 0:01:40 lr 0.048317	time 1.3624 (2.1021)	loss 2.2175 (2.1839)	grad_norm 0.6477 (0.6340)	mem 39782MB
[2023-07-07 18:15:40 RepVGG-A0] (main.py 282): INFO Train: [283/300][40/78]	eta 0:01:17 lr 0.047576	time 4.7302 (2.0435)	loss 2.2180 (2.1856)	grad_norm 0.6324 (0.6340)	mem 39782MB
[2023-07-07 18:15:54 RepVGG-A0] (main.py 282): INFO Train: [283/300][50/78]	eta 0:00:53 lr 0.046841	time 1.1736 (1.9233)	loss 2.2212 (2.1899)	grad_norm 0.6307 (0.6344)	mem 39782MB
[2023-07-07 18:16:09 RepVGG-A0] (main.py 282): INFO Train: [283/300][60/78]	eta 0:00:33 lr 0.046112	time 1.1728 (1.8536)	loss 2.1818 (2.1877)	grad_norm 0.6432 (0.6346)	mem 39782MB
[2023-07-07 18:16:25 RepVGG-A0] (main.py 282): INFO Train: [283/300][70/78]	eta 0:00:14 lr 0.045388	time 1.1281 (1.8152)	loss 2.2326 (2.1909)	grad_norm 0.6443 (0.6353)	mem 39782MB
[2023-07-07 18:16:37 RepVGG-A0] (main.py 291): INFO EPOCH 283 training takes 0:02:20
[2023-07-07 18:16:59 RepVGG-A0] (main.py 282): INFO Train: [284/300][0/78]	eta 0:28:37 lr 0.044813	time 22.0170 (22.0170)	loss 2.1338 (2.1338)	grad_norm 0.6296 (0.6296)	mem 39782MB
[2023-07-07 18:17:13 RepVGG-A0] (main.py 282): INFO Train: [284/300][10/78]	eta 0:03:43 lr 0.044099	time 1.1937 (3.2844)	loss 2.1694 (2.1780)	grad_norm 0.6321 (0.6322)	mem 39782MB
[2023-07-07 18:17:28 RepVGG-A0] (main.py 282): INFO Train: [284/300][20/78]	eta 0:02:20 lr 0.043391	time 1.1786 (2.4287)	loss 2.1721 (2.1751)	grad_norm 0.6344 (0.6327)	mem 39782MB
[2023-07-07 18:17:42 RepVGG-A0] (main.py 282): INFO Train: [284/300][30/78]	eta 0:01:41 lr 0.042689	time 1.4633 (2.1221)	loss 2.1682 (2.1699)	grad_norm 0.6331 (0.6334)	mem 39782MB
[2023-07-07 18:18:01 RepVGG-A0] (main.py 282): INFO Train: [284/300][40/78]	eta 0:01:18 lr 0.041992	time 4.2904 (2.0536)	loss 2.1918 (2.1705)	grad_norm 0.6395 (0.6343)	mem 39782MB
[2023-07-07 18:18:16 RepVGG-A0] (main.py 282): INFO Train: [284/300][50/78]	eta 0:00:54 lr 0.041301	time 1.1741 (1.9584)	loss 2.2244 (2.1740)	grad_norm 0.6439 (0.6352)	mem 39782MB
[2023-07-07 18:18:31 RepVGG-A0] (main.py 282): INFO Train: [284/300][60/78]	eta 0:00:33 lr 0.040616	time 1.1959 (1.8692)	loss 2.2144 (2.1752)	grad_norm 0.6367 (0.6358)	mem 39782MB
[2023-07-07 18:18:45 RepVGG-A0] (main.py 282): INFO Train: [284/300][70/78]	eta 0:00:14 lr 0.039937	time 1.2083 (1.8097)	loss 2.1202 (2.1746)	grad_norm 0.6448 (0.6363)	mem 39782MB
[2023-07-07 18:18:57 RepVGG-A0] (main.py 291): INFO EPOCH 284 training takes 0:02:20
[2023-07-07 18:19:19 RepVGG-A0] (main.py 282): INFO Train: [285/300][0/78]	eta 0:28:20 lr 0.039397	time 21.8049 (21.8049)	loss 2.1800 (2.1800)	grad_norm 0.6319 (0.6319)	mem 39782MB
[2023-07-07 18:19:33 RepVGG-A0] (main.py 282): INFO Train: [285/300][10/78]	eta 0:03:41 lr 0.038728	time 1.1718 (3.2566)	loss 2.2759 (2.1805)	grad_norm 0.6371 (0.6377)	mem 39782MB
[2023-07-07 18:19:48 RepVGG-A0] (main.py 282): INFO Train: [285/300][20/78]	eta 0:02:20 lr 0.038065	time 1.1749 (2.4218)	loss 2.1389 (2.1747)	grad_norm 0.6384 (0.6370)	mem 39782MB
[2023-07-07 18:20:04 RepVGG-A0] (main.py 282): INFO Train: [285/300][30/78]	eta 0:01:42 lr 0.037407	time 1.6081 (2.1440)	loss 2.1621 (2.1726)	grad_norm 0.6332 (0.6374)	mem 39782MB
[2023-07-07 18:20:22 RepVGG-A0] (main.py 282): INFO Train: [285/300][40/78]	eta 0:01:18 lr 0.036755	time 2.9923 (2.0590)	loss 2.1389 (2.1702)	grad_norm 0.6368 (0.6371)	mem 39782MB
[2023-07-07 18:20:38 RepVGG-A0] (main.py 282): INFO Train: [285/300][50/78]	eta 0:00:55 lr 0.036108	time 1.3290 (1.9659)	loss 2.1459 (2.1716)	grad_norm 0.6503 (0.6375)	mem 39782MB
[2023-07-07 18:20:52 RepVGG-A0] (main.py 282): INFO Train: [285/300][60/78]	eta 0:00:33 lr 0.035467	time 1.3686 (1.8816)	loss 2.1839 (2.1756)	grad_norm 0.6346 (0.6379)	mem 39782MB
[2023-07-07 18:21:07 RepVGG-A0] (main.py 282): INFO Train: [285/300][70/78]	eta 0:00:14 lr 0.034832	time 1.2059 (1.8331)	loss 2.1472 (2.1753)	grad_norm 0.6494 (0.6384)	mem 39782MB
[2023-07-07 18:21:19 RepVGG-A0] (main.py 291): INFO EPOCH 285 training takes 0:02:21
[2023-07-07 18:21:40 RepVGG-A0] (main.py 282): INFO Train: [286/300][0/78]	eta 0:28:10 lr 0.034329	time 21.6714 (21.6714)	loss 2.1152 (2.1152)	grad_norm 0.6346 (0.6346)	mem 39782MB
[2023-07-07 18:21:55 RepVGG-A0] (main.py 282): INFO Train: [286/300][10/78]	eta 0:03:46 lr 0.033704	time 1.1732 (3.3265)	loss 2.1868 (2.1593)	grad_norm 0.6388 (0.6375)	mem 39782MB
[2023-07-07 18:22:11 RepVGG-A0] (main.py 282): INFO Train: [286/300][20/78]	eta 0:02:23 lr 0.033085	time 1.2462 (2.4784)	loss 2.2406 (2.1626)	grad_norm 0.6456 (0.6377)	mem 39782MB
[2023-07-07 18:22:26 RepVGG-A0] (main.py 282): INFO Train: [286/300][30/78]	eta 0:01:44 lr 0.032471	time 1.2335 (2.1811)	loss 2.1717 (2.1616)	grad_norm 0.6315 (0.6382)	mem 39782MB
[2023-07-07 18:22:43 RepVGG-A0] (main.py 282): INFO Train: [286/300][40/78]	eta 0:01:18 lr 0.031864	time 2.8413 (2.0649)	loss 2.1476 (2.1606)	grad_norm 0.6351 (0.6383)	mem 39782MB
[2023-07-07 18:22:58 RepVGG-A0] (main.py 282): INFO Train: [286/300][50/78]	eta 0:00:54 lr 0.031262	time 1.1726 (1.9549)	loss 2.1143 (2.1640)	grad_norm 0.6456 (0.6389)	mem 39782MB
[2023-07-07 18:23:14 RepVGG-A0] (main.py 282): INFO Train: [286/300][60/78]	eta 0:00:33 lr 0.030666	time 1.1782 (1.8859)	loss 2.1874 (2.1675)	grad_norm 0.6461 (0.6393)	mem 39782MB
[2023-07-07 18:23:29 RepVGG-A0] (main.py 282): INFO Train: [286/300][70/78]	eta 0:00:14 lr 0.030075	time 1.3028 (1.8376)	loss 2.1530 (2.1693)	grad_norm 0.6385 (0.6391)	mem 39782MB
[2023-07-07 18:23:41 RepVGG-A0] (main.py 291): INFO EPOCH 286 training takes 0:02:22
[2023-07-07 18:24:02 RepVGG-A0] (main.py 282): INFO Train: [287/300][0/78]	eta 0:27:42 lr 0.029607	time 21.3163 (21.3163)	loss 2.1808 (2.1808)	grad_norm 0.6271 (0.6271)	mem 39782MB
[2023-07-07 18:24:16 RepVGG-A0] (main.py 282): INFO Train: [287/300][10/78]	eta 0:03:35 lr 0.029027	time 1.1745 (3.1702)	loss 2.2075 (2.1652)	grad_norm 0.6414 (0.6348)	mem 39782MB
[2023-07-07 18:24:30 RepVGG-A0] (main.py 282): INFO Train: [287/300][20/78]	eta 0:02:16 lr 0.028452	time 1.1738 (2.3545)	loss 2.1786 (2.1657)	grad_norm 0.6405 (0.6372)	mem 39782MB
[2023-07-07 18:24:48 RepVGG-A0] (main.py 282): INFO Train: [287/300][30/78]	eta 0:01:43 lr 0.027883	time 1.8488 (2.1504)	loss 2.1598 (2.1660)	grad_norm 0.6416 (0.6386)	mem 39782MB
[2023-07-07 18:25:04 RepVGG-A0] (main.py 282): INFO Train: [287/300][40/78]	eta 0:01:17 lr 0.027320	time 4.1823 (2.0287)	loss 2.1742 (2.1646)	grad_norm 0.6366 (0.6384)	mem 39782MB
[2023-07-07 18:25:19 RepVGG-A0] (main.py 282): INFO Train: [287/300][50/78]	eta 0:00:53 lr 0.026763	time 1.1732 (1.9243)	loss 2.1594 (2.1643)	grad_norm 0.6437 (0.6379)	mem 39782MB
[2023-07-07 18:25:34 RepVGG-A0] (main.py 282): INFO Train: [287/300][60/78]	eta 0:00:33 lr 0.026211	time 1.1783 (1.8550)	loss 2.1587 (2.1646)	grad_norm 0.6364 (0.6377)	mem 39782MB
[2023-07-07 18:25:49 RepVGG-A0] (main.py 282): INFO Train: [287/300][70/78]	eta 0:00:14 lr 0.025666	time 1.2332 (1.8100)	loss 2.1838 (2.1652)	grad_norm 0.6396 (0.6378)	mem 39782MB
[2023-07-07 18:26:02 RepVGG-A0] (main.py 291): INFO EPOCH 287 training takes 0:02:20
[2023-07-07 18:26:23 RepVGG-A0] (main.py 282): INFO Train: [288/300][0/78]	eta 0:28:06 lr 0.025233	time 21.6257 (21.6257)	loss 2.1705 (2.1705)	grad_norm 0.6299 (0.6299)	mem 39782MB
[2023-07-07 18:26:39 RepVGG-A0] (main.py 282): INFO Train: [288/300][10/78]	eta 0:03:49 lr 0.024697	time 1.1836 (3.3703)	loss 2.1605 (2.1656)	grad_norm 0.6283 (0.6344)	mem 39782MB
[2023-07-07 18:26:53 RepVGG-A0] (main.py 282): INFO Train: [288/300][20/78]	eta 0:02:22 lr 0.024167	time 1.1786 (2.4521)	loss 2.1682 (2.1519)	grad_norm 0.6313 (0.6354)	mem 39782MB
[2023-07-07 18:27:09 RepVGG-A0] (main.py 282): INFO Train: [288/300][30/78]	eta 0:01:43 lr 0.023643	time 1.4983 (2.1535)	loss 2.1898 (2.1613)	grad_norm 0.6364 (0.6366)	mem 39782MB
[2023-07-07 18:27:26 RepVGG-A0] (main.py 282): INFO Train: [288/300][40/78]	eta 0:01:18 lr 0.023125	time 3.7315 (2.0571)	loss 2.1525 (2.1611)	grad_norm 0.6396 (0.6369)	mem 39782MB
[2023-07-07 18:27:41 RepVGG-A0] (main.py 282): INFO Train: [288/300][50/78]	eta 0:00:54 lr 0.022612	time 1.1720 (1.9555)	loss 2.1405 (2.1593)	grad_norm 0.6432 (0.6380)	mem 39782MB
[2023-07-07 18:27:57 RepVGG-A0] (main.py 282): INFO Train: [288/300][60/78]	eta 0:00:33 lr 0.022105	time 1.2887 (1.8885)	loss 2.1998 (2.1587)	grad_norm 0.6505 (0.6383)	mem 39782MB
[2023-07-07 18:28:13 RepVGG-A0] (main.py 282): INFO Train: [288/300][70/78]	eta 0:00:14 lr 0.021604	time 1.3252 (1.8454)	loss 2.1477 (2.1568)	grad_norm 0.6443 (0.6382)	mem 39782MB
[2023-07-07 18:28:23 RepVGG-A0] (main.py 291): INFO EPOCH 288 training takes 0:02:21
[2023-07-07 18:28:45 RepVGG-A0] (main.py 282): INFO Train: [289/300][0/78]	eta 0:28:21 lr 0.021207	time 21.8190 (21.8190)	loss 2.1557 (2.1557)	grad_norm 0.6301 (0.6301)	mem 39782MB
[2023-07-07 18:28:59 RepVGG-A0] (main.py 282): INFO Train: [289/300][10/78]	eta 0:03:43 lr 0.020716	time 1.1734 (3.2818)	loss 2.1529 (2.1525)	grad_norm 0.6348 (0.6334)	mem 39782MB
[2023-07-07 18:29:14 RepVGG-A0] (main.py 282): INFO Train: [289/300][20/78]	eta 0:02:18 lr 0.020231	time 1.1714 (2.3933)	loss 2.1119 (2.1507)	grad_norm 0.6334 (0.6342)	mem 39782MB
[2023-07-07 18:29:29 RepVGG-A0] (main.py 282): INFO Train: [289/300][30/78]	eta 0:01:41 lr 0.019752	time 1.5769 (2.1227)	loss 2.1687 (2.1557)	grad_norm 0.6473 (0.6355)	mem 39782MB
[2023-07-07 18:29:47 RepVGG-A0] (main.py 282): INFO Train: [289/300][40/78]	eta 0:01:17 lr 0.019278	time 3.2525 (2.0313)	loss 2.1424 (2.1568)	grad_norm 0.6360 (0.6361)	mem 39782MB
[2023-07-07 18:30:02 RepVGG-A0] (main.py 282): INFO Train: [289/300][50/78]	eta 0:00:54 lr 0.018810	time 1.1728 (1.9329)	loss 2.0894 (2.1555)	grad_norm 0.6379 (0.6367)	mem 39782MB
[2023-07-07 18:30:17 RepVGG-A0] (main.py 282): INFO Train: [289/300][60/78]	eta 0:00:33 lr 0.018348	time 1.2597 (1.8640)	loss 2.1691 (2.1535)	grad_norm 0.6434 (0.6373)	mem 39782MB
[2023-07-07 18:30:32 RepVGG-A0] (main.py 282): INFO Train: [289/300][70/78]	eta 0:00:14 lr 0.017891	time 1.4822 (1.8117)	loss 2.1843 (2.1547)	grad_norm 0.6380 (0.6376)	mem 39782MB
[2023-07-07 18:30:44 RepVGG-A0] (main.py 291): INFO EPOCH 289 training takes 0:02:20
[2023-07-07 18:31:05 RepVGG-A0] (main.py 282): INFO Train: [290/300][0/78]	eta 0:27:57 lr 0.017530	time 21.5116 (21.5116)	loss 2.1790 (2.1790)	grad_norm 0.6331 (0.6331)	mem 39782MB
[2023-07-07 18:31:20 RepVGG-A0] (main.py 282): INFO Train: [290/300][10/78]	eta 0:03:45 lr 0.017084	time 1.1713 (3.3234)	loss 2.1517 (2.1553)	grad_norm 0.6345 (0.6371)	mem 39782MB
[2023-07-07 18:31:36 RepVGG-A0] (main.py 282): INFO Train: [290/300][20/78]	eta 0:02:23 lr 0.016643	time 1.1747 (2.4766)	loss 2.1661 (2.1508)	grad_norm 0.6403 (0.6375)	mem 39782MB
[2023-07-07 18:31:51 RepVGG-A0] (main.py 282): INFO Train: [290/300][30/78]	eta 0:01:43 lr 0.016209	time 1.3837 (2.1611)	loss 2.1510 (2.1480)	grad_norm 0.6392 (0.6381)	mem 39782MB
[2023-07-07 18:32:09 RepVGG-A0] (main.py 282): INFO Train: [290/300][40/78]	eta 0:01:19 lr 0.015780	time 4.0303 (2.0829)	loss 2.1386 (2.1489)	grad_norm 0.6362 (0.6382)	mem 39782MB
[2023-07-07 18:32:24 RepVGG-A0] (main.py 282): INFO Train: [290/300][50/78]	eta 0:00:55 lr 0.015356	time 1.1813 (1.9674)	loss 2.1955 (2.1501)	grad_norm 0.6442 (0.6385)	mem 39782MB
[2023-07-07 18:32:39 RepVGG-A0] (main.py 282): INFO Train: [290/300][60/78]	eta 0:00:33 lr 0.014939	time 1.3577 (1.8880)	loss 2.1566 (2.1532)	grad_norm 0.6374 (0.6388)	mem 39782MB
[2023-07-07 18:32:55 RepVGG-A0] (main.py 282): INFO Train: [290/300][70/78]	eta 0:00:14 lr 0.014527	time 1.5086 (1.8411)	loss 2.1709 (2.1538)	grad_norm 0.6340 (0.6390)	mem 39782MB
[2023-07-07 18:33:06 RepVGG-A0] (main.py 291): INFO EPOCH 290 training takes 0:02:21
[2023-07-07 18:33:23 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.672 (17.672)	Loss 1.3477 (1.3477)	Acc@1 70.551 (70.551)	Acc@5 89.075 (89.075)	Mem 39782MB
[2023-07-07 18:33:24 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.714 Acc@5 89.520
[2023-07-07 18:33:24 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 290: 70.714%
[2023-07-07 18:33:24 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:33:46 RepVGG-A0] (main.py 282): INFO Train: [291/300][0/78]	eta 0:27:49 lr 0.014202	time 21.3986 (21.3986)	loss 2.1625 (2.1625)	grad_norm 0.6434 (0.6434)	mem 39782MB
[2023-07-07 18:34:01 RepVGG-A0] (main.py 282): INFO Train: [291/300][10/78]	eta 0:03:48 lr 0.013800	time 1.1915 (3.3615)	loss 2.1176 (2.1632)	grad_norm 0.6438 (0.6372)	mem 39782MB
[2023-07-07 18:34:15 RepVGG-A0] (main.py 282): INFO Train: [291/300][20/78]	eta 0:02:20 lr 0.013405	time 1.1728 (2.4181)	loss 2.1442 (2.1552)	grad_norm 0.6340 (0.6360)	mem 39782MB
[2023-07-07 18:34:30 RepVGG-A0] (main.py 282): INFO Train: [291/300][30/78]	eta 0:01:41 lr 0.013015	time 1.3644 (2.1069)	loss 2.0930 (2.1516)	grad_norm 0.6422 (0.6367)	mem 39782MB
[2023-07-07 18:34:48 RepVGG-A0] (main.py 282): INFO Train: [291/300][40/78]	eta 0:01:17 lr 0.012630	time 3.4853 (2.0346)	loss 2.1814 (2.1511)	grad_norm 0.6372 (0.6366)	mem 39782MB
[2023-07-07 18:35:03 RepVGG-A0] (main.py 282): INFO Train: [291/300][50/78]	eta 0:00:53 lr 0.012252	time 1.3553 (1.9227)	loss 2.1307 (2.1510)	grad_norm 0.6398 (0.6368)	mem 39782MB
[2023-07-07 18:35:17 RepVGG-A0] (main.py 282): INFO Train: [291/300][60/78]	eta 0:00:33 lr 0.011879	time 1.1748 (1.8416)	loss 2.1150 (2.1502)	grad_norm 0.6288 (0.6369)	mem 39782MB
[2023-07-07 18:35:31 RepVGG-A0] (main.py 282): INFO Train: [291/300][70/78]	eta 0:00:14 lr 0.011512	time 1.1923 (1.7882)	loss 2.2132 (2.1519)	grad_norm 0.6503 (0.6372)	mem 39782MB
[2023-07-07 18:35:44 RepVGG-A0] (main.py 291): INFO EPOCH 291 training takes 0:02:19
[2023-07-07 18:36:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.309 (17.309)	Loss 1.3313 (1.3313)	Acc@1 70.636 (70.636)	Acc@5 89.459 (89.459)	Mem 39782MB
[2023-07-07 18:36:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.680 Acc@5 89.592
[2023-07-07 18:36:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 291: 70.680%
[2023-07-07 18:36:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:36:25 RepVGG-A0] (main.py 282): INFO Train: [292/300][0/78]	eta 0:29:00 lr 0.011223	time 22.3078 (22.3078)	loss 2.2109 (2.2109)	grad_norm 0.6248 (0.6248)	mem 39782MB
[2023-07-07 18:36:39 RepVGG-A0] (main.py 282): INFO Train: [292/300][10/78]	eta 0:03:47 lr 0.010866	time 1.1990 (3.3447)	loss 2.1417 (2.1538)	grad_norm 0.6354 (0.6333)	mem 39782MB
[2023-07-07 18:36:52 RepVGG-A0] (main.py 282): INFO Train: [292/300][20/78]	eta 0:02:17 lr 0.010515	time 1.1724 (2.3676)	loss 2.1454 (2.1472)	grad_norm 0.6346 (0.6351)	mem 39782MB
[2023-07-07 18:37:09 RepVGG-A0] (main.py 282): INFO Train: [292/300][30/78]	eta 0:01:43 lr 0.010170	time 1.5363 (2.1464)	loss 2.1848 (2.1453)	grad_norm 0.6324 (0.6356)	mem 39782MB
[2023-07-07 18:37:24 RepVGG-A0] (main.py 282): INFO Train: [292/300][40/78]	eta 0:01:16 lr 0.009831	time 1.7464 (2.0032)	loss 2.1735 (2.1428)	grad_norm 0.6360 (0.6356)	mem 39782MB
[2023-07-07 18:37:42 RepVGG-A0] (main.py 282): INFO Train: [292/300][50/78]	eta 0:00:54 lr 0.009497	time 1.1746 (1.9506)	loss 2.1195 (2.1421)	grad_norm 0.6320 (0.6359)	mem 39782MB
[2023-07-07 18:37:57 RepVGG-A0] (main.py 282): INFO Train: [292/300][60/78]	eta 0:00:33 lr 0.009169	time 1.3279 (1.8790)	loss 2.1177 (2.1422)	grad_norm 0.6324 (0.6360)	mem 39782MB
[2023-07-07 18:38:12 RepVGG-A0] (main.py 282): INFO Train: [292/300][70/78]	eta 0:00:14 lr 0.008847	time 1.3450 (1.8277)	loss 2.1815 (2.1438)	grad_norm 0.6374 (0.6361)	mem 39782MB
[2023-07-07 18:38:24 RepVGG-A0] (main.py 291): INFO EPOCH 292 training takes 0:02:21
[2023-07-07 18:38:41 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.235 (17.235)	Loss 1.3228 (1.3228)	Acc@1 70.398 (70.398)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:38:42 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.696 Acc@5 89.542
[2023-07-07 18:38:42 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 292: 70.696%
[2023-07-07 18:38:42 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:39:04 RepVGG-A0] (main.py 282): INFO Train: [293/300][0/78]	eta 0:28:23 lr 0.008594	time 21.8402 (21.8402)	loss 2.1703 (2.1703)	grad_norm 0.6353 (0.6353)	mem 39782MB
[2023-07-07 18:39:19 RepVGG-A0] (main.py 282): INFO Train: [293/300][10/78]	eta 0:03:46 lr 0.008282	time 1.1720 (3.3327)	loss 2.1715 (2.1429)	grad_norm 0.6343 (0.6344)	mem 39782MB
[2023-07-07 18:39:34 RepVGG-A0] (main.py 282): INFO Train: [293/300][20/78]	eta 0:02:22 lr 0.007976	time 1.2619 (2.4578)	loss 2.1063 (2.1498)	grad_norm 0.6426 (0.6347)	mem 39782MB
[2023-07-07 18:39:48 RepVGG-A0] (main.py 282): INFO Train: [293/300][30/78]	eta 0:01:42 lr 0.007676	time 1.4422 (2.1309)	loss 2.0874 (2.1508)	grad_norm 0.6335 (0.6353)	mem 39782MB
[2023-07-07 18:40:06 RepVGG-A0] (main.py 282): INFO Train: [293/300][40/78]	eta 0:01:17 lr 0.007381	time 3.1001 (2.0441)	loss 2.1119 (2.1492)	grad_norm 0.6293 (0.6353)	mem 39782MB
[2023-07-07 18:40:21 RepVGG-A0] (main.py 282): INFO Train: [293/300][50/78]	eta 0:00:54 lr 0.007092	time 1.1728 (1.9329)	loss 2.1611 (2.1452)	grad_norm 0.6350 (0.6354)	mem 39782MB
[2023-07-07 18:40:36 RepVGG-A0] (main.py 282): INFO Train: [293/300][60/78]	eta 0:00:33 lr 0.006809	time 1.3345 (1.8746)	loss 2.1983 (2.1459)	grad_norm 0.6328 (0.6346)	mem 39782MB
[2023-07-07 18:40:51 RepVGG-A0] (main.py 282): INFO Train: [293/300][70/78]	eta 0:00:14 lr 0.006532	time 1.4237 (1.8195)	loss 2.1809 (2.1461)	grad_norm 0.6330 (0.6345)	mem 39782MB
[2023-07-07 18:41:04 RepVGG-A0] (main.py 291): INFO EPOCH 293 training takes 0:02:21
[2023-07-07 18:41:21 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.218 (17.218)	Loss 1.3155 (1.3155)	Acc@1 70.862 (70.862)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:41:22 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.908 Acc@5 89.588
[2023-07-07 18:41:22 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 293: 70.908%
[2023-07-07 18:41:22 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:41:45 RepVGG-A0] (main.py 282): INFO Train: [294/300][0/78]	eta 0:29:27 lr 0.006314	time 22.6542 (22.6542)	loss 2.1443 (2.1443)	grad_norm 0.6317 (0.6317)	mem 39782MB
[2023-07-07 18:41:59 RepVGG-A0] (main.py 282): INFO Train: [294/300][10/78]	eta 0:03:49 lr 0.006048	time 1.1704 (3.3746)	loss 2.1460 (2.1467)	grad_norm 0.6324 (0.6331)	mem 39782MB
[2023-07-07 18:42:13 RepVGG-A0] (main.py 282): INFO Train: [294/300][20/78]	eta 0:02:21 lr 0.005786	time 1.1758 (2.4357)	loss 2.1052 (2.1484)	grad_norm 0.6389 (0.6340)	mem 39782MB
[2023-07-07 18:42:29 RepVGG-A0] (main.py 282): INFO Train: [294/300][30/78]	eta 0:01:42 lr 0.005531	time 1.1930 (2.1451)	loss 2.0908 (2.1444)	grad_norm 0.6441 (0.6348)	mem 39782MB
[2023-07-07 18:42:47 RepVGG-A0] (main.py 282): INFO Train: [294/300][40/78]	eta 0:01:18 lr 0.005281	time 3.4973 (2.0666)	loss 2.1597 (2.1442)	grad_norm 0.6303 (0.6342)	mem 39782MB
[2023-07-07 18:43:01 RepVGG-A0] (main.py 282): INFO Train: [294/300][50/78]	eta 0:00:54 lr 0.005038	time 1.1722 (1.9489)	loss 2.1006 (2.1430)	grad_norm 0.6358 (0.6345)	mem 39782MB
[2023-07-07 18:43:16 RepVGG-A0] (main.py 282): INFO Train: [294/300][60/78]	eta 0:00:33 lr 0.004800	time 1.3461 (1.8747)	loss 2.1091 (2.1395)	grad_norm 0.6295 (0.6341)	mem 39782MB
[2023-07-07 18:43:32 RepVGG-A0] (main.py 282): INFO Train: [294/300][70/78]	eta 0:00:14 lr 0.004567	time 1.2912 (1.8276)	loss 2.1842 (2.1419)	grad_norm 0.6185 (0.6338)	mem 39782MB
[2023-07-07 18:43:43 RepVGG-A0] (main.py 291): INFO EPOCH 294 training takes 0:02:20
[2023-07-07 18:44:00 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.491 (17.491)	Loss 1.3250 (1.3250)	Acc@1 70.532 (70.532)	Acc@5 89.752 (89.752)	Mem 39782MB
[2023-07-07 18:44:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.842 Acc@5 89.598
[2023-07-07 18:44:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 294: 70.842%
[2023-07-07 18:44:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:44:23 RepVGG-A0] (main.py 282): INFO Train: [295/300][0/78]	eta 0:27:18 lr 0.004385	time 21.0054 (21.0054)	loss 2.1566 (2.1566)	grad_norm 0.6282 (0.6282)	mem 39782MB
[2023-07-07 18:44:38 RepVGG-A0] (main.py 282): INFO Train: [295/300][10/78]	eta 0:03:42 lr 0.004164	time 1.1702 (3.2750)	loss 2.1127 (2.1486)	grad_norm 0.6271 (0.6331)	mem 39782MB
[2023-07-07 18:44:52 RepVGG-A0] (main.py 282): INFO Train: [295/300][20/78]	eta 0:02:18 lr 0.003947	time 1.1727 (2.3952)	loss 2.1745 (2.1421)	grad_norm 0.6318 (0.6325)	mem 39782MB
[2023-07-07 18:45:07 RepVGG-A0] (main.py 282): INFO Train: [295/300][30/78]	eta 0:01:41 lr 0.003737	time 1.3600 (2.1117)	loss 2.1387 (2.1448)	grad_norm 0.6297 (0.6330)	mem 39782MB
[2023-07-07 18:45:25 RepVGG-A0] (main.py 282): INFO Train: [295/300][40/78]	eta 0:01:17 lr 0.003532	time 3.4536 (2.0293)	loss 2.1688 (2.1439)	grad_norm 0.6445 (0.6335)	mem 39782MB
[2023-07-07 18:45:40 RepVGG-A0] (main.py 282): INFO Train: [295/300][50/78]	eta 0:00:54 lr 0.003333	time 1.1737 (1.9339)	loss 2.1465 (2.1440)	grad_norm 0.6327 (0.6334)	mem 39782MB
[2023-07-07 18:45:55 RepVGG-A0] (main.py 282): INFO Train: [295/300][60/78]	eta 0:00:33 lr 0.003140	time 1.3638 (1.8629)	loss 2.1165 (2.1438)	grad_norm 0.6386 (0.6334)	mem 39782MB
[2023-07-07 18:46:10 RepVGG-A0] (main.py 282): INFO Train: [295/300][70/78]	eta 0:00:14 lr 0.002953	time 1.2524 (1.8037)	loss 2.1356 (2.1416)	grad_norm 0.6326 (0.6333)	mem 39782MB
[2023-07-07 18:46:22 RepVGG-A0] (main.py 291): INFO EPOCH 295 training takes 0:02:20
[2023-07-07 18:46:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.288 (17.288)	Loss 1.3213 (1.3213)	Acc@1 70.807 (70.807)	Acc@5 89.526 (89.526)	Mem 39782MB
[2023-07-07 18:46:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.834 Acc@5 89.672
[2023-07-07 18:46:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 295: 70.834%
[2023-07-07 18:46:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:47:03 RepVGG-A0] (main.py 282): INFO Train: [296/300][0/78]	eta 0:29:13 lr 0.002807	time 22.4829 (22.4829)	loss 2.1471 (2.1471)	grad_norm 0.6409 (0.6409)	mem 39782MB
[2023-07-07 18:47:18 RepVGG-A0] (main.py 282): INFO Train: [296/300][10/78]	eta 0:03:49 lr 0.002630	time 1.1725 (3.3711)	loss 2.0875 (2.1389)	grad_norm 0.6360 (0.6313)	mem 39782MB
[2023-07-07 18:47:32 RepVGG-A0] (main.py 282): INFO Train: [296/300][20/78]	eta 0:02:21 lr 0.002459	time 1.1959 (2.4457)	loss 2.0730 (2.1374)	grad_norm 0.6263 (0.6316)	mem 39782MB
[2023-07-07 18:47:48 RepVGG-A0] (main.py 282): INFO Train: [296/300][30/78]	eta 0:01:45 lr 0.002293	time 2.0574 (2.1903)	loss 2.1409 (2.1407)	grad_norm 0.6213 (0.6309)	mem 39782MB
[2023-07-07 18:48:05 RepVGG-A0] (main.py 282): INFO Train: [296/300][40/78]	eta 0:01:17 lr 0.002133	time 3.9235 (2.0515)	loss 2.1188 (2.1444)	grad_norm 0.6220 (0.6305)	mem 39782MB
[2023-07-07 18:48:20 RepVGG-A0] (main.py 282): INFO Train: [296/300][50/78]	eta 0:00:54 lr 0.001979	time 1.1722 (1.9433)	loss 2.0935 (2.1410)	grad_norm 0.6307 (0.6305)	mem 39782MB
[2023-07-07 18:48:35 RepVGG-A0] (main.py 282): INFO Train: [296/300][60/78]	eta 0:00:33 lr 0.001831	time 1.1751 (1.8786)	loss 2.1568 (2.1414)	grad_norm 0.6358 (0.6309)	mem 39782MB
[2023-07-07 18:48:51 RepVGG-A0] (main.py 282): INFO Train: [296/300][70/78]	eta 0:00:14 lr 0.001689	time 1.4335 (1.8388)	loss 2.1075 (2.1424)	grad_norm 0.6276 (0.6312)	mem 39782MB
[2023-07-07 18:49:02 RepVGG-A0] (main.py 291): INFO EPOCH 296 training takes 0:02:21
[2023-07-07 18:49:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.533 (17.533)	Loss 1.3167 (1.3167)	Acc@1 70.837 (70.837)	Acc@5 89.807 (89.807)	Mem 39782MB
[2023-07-07 18:49:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.906 Acc@5 89.658
[2023-07-07 18:49:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 296: 70.906%
[2023-07-07 18:49:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:49:41 RepVGG-A0] (main.py 282): INFO Train: [297/300][0/78]	eta 0:27:02 lr 0.001579	time 20.7951 (20.7951)	loss 2.1271 (2.1271)	grad_norm 0.6238 (0.6238)	mem 39782MB
[2023-07-07 18:49:57 RepVGG-A0] (main.py 282): INFO Train: [297/300][10/78]	eta 0:03:42 lr 0.001447	time 1.1720 (3.2774)	loss 2.1714 (2.1438)	grad_norm 0.6274 (0.6294)	mem 39782MB
[2023-07-07 18:50:12 RepVGG-A0] (main.py 282): INFO Train: [297/300][20/78]	eta 0:02:21 lr 0.001321	time 1.1750 (2.4323)	loss 2.1060 (2.1323)	grad_norm 0.6337 (0.6296)	mem 39782MB
[2023-07-07 18:50:27 RepVGG-A0] (main.py 282): INFO Train: [297/300][30/78]	eta 0:01:43 lr 0.001200	time 1.6573 (2.1511)	loss 2.1894 (2.1362)	grad_norm 0.6343 (0.6302)	mem 39782MB
[2023-07-07 18:50:44 RepVGG-A0] (main.py 282): INFO Train: [297/300][40/78]	eta 0:01:17 lr 0.001085	time 3.6901 (2.0395)	loss 2.1301 (2.1355)	grad_norm 0.6336 (0.6305)	mem 39782MB
[2023-07-07 18:51:00 RepVGG-A0] (main.py 282): INFO Train: [297/300][50/78]	eta 0:00:54 lr 0.000976	time 1.1894 (1.9430)	loss 2.1048 (2.1328)	grad_norm 0.6287 (0.6300)	mem 39782MB
[2023-07-07 18:51:15 RepVGG-A0] (main.py 282): INFO Train: [297/300][60/78]	eta 0:00:33 lr 0.000873	time 1.3400 (1.8706)	loss 2.1576 (2.1366)	grad_norm 0.6384 (0.6298)	mem 39782MB
[2023-07-07 18:51:31 RepVGG-A0] (main.py 282): INFO Train: [297/300][70/78]	eta 0:00:14 lr 0.000776	time 1.2782 (1.8389)	loss 2.1322 (2.1369)	grad_norm 0.6278 (0.6301)	mem 39782MB
[2023-07-07 18:51:42 RepVGG-A0] (main.py 291): INFO EPOCH 297 training takes 0:02:21
[2023-07-07 18:51:59 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.018 (17.018)	Loss 1.3204 (1.3204)	Acc@1 70.703 (70.703)	Acc@5 89.709 (89.709)	Mem 39782MB
[2023-07-07 18:52:01 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.910 Acc@5 89.666
[2023-07-07 18:52:01 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 297: 70.910%
[2023-07-07 18:52:01 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:52:24 RepVGG-A0] (main.py 282): INFO Train: [298/300][0/78]	eta 0:29:17 lr 0.000702	time 22.5313 (22.5313)	loss 2.1328 (2.1328)	grad_norm 0.6243 (0.6243)	mem 39782MB
[2023-07-07 18:52:37 RepVGG-A0] (main.py 282): INFO Train: [298/300][10/78]	eta 0:03:44 lr 0.000615	time 1.1743 (3.2962)	loss 2.1502 (2.1344)	grad_norm 0.6289 (0.6289)	mem 39782MB
[2023-07-07 18:52:52 RepVGG-A0] (main.py 282): INFO Train: [298/300][20/78]	eta 0:02:20 lr 0.000533	time 1.1720 (2.4157)	loss 2.1920 (2.1318)	grad_norm 0.6324 (0.6287)	mem 39782MB
[2023-07-07 18:53:07 RepVGG-A0] (main.py 282): INFO Train: [298/300][30/78]	eta 0:01:42 lr 0.000458	time 1.1897 (2.1341)	loss 2.1623 (2.1424)	grad_norm 0.6304 (0.6298)	mem 39782MB
[2023-07-07 18:53:26 RepVGG-A0] (main.py 282): INFO Train: [298/300][40/78]	eta 0:01:18 lr 0.000388	time 3.6657 (2.0756)	loss 2.0950 (2.1417)	grad_norm 0.6381 (0.6295)	mem 39782MB
[2023-07-07 18:53:41 RepVGG-A0] (main.py 282): INFO Train: [298/300][50/78]	eta 0:00:55 lr 0.000324	time 1.1805 (1.9649)	loss 2.1428 (2.1413)	grad_norm 0.6352 (0.6292)	mem 39782MB
[2023-07-07 18:53:56 RepVGG-A0] (main.py 282): INFO Train: [298/300][60/78]	eta 0:00:33 lr 0.000266	time 1.2007 (1.8833)	loss 2.1701 (2.1400)	grad_norm 0.6251 (0.6291)	mem 39782MB
[2023-07-07 18:54:11 RepVGG-A0] (main.py 282): INFO Train: [298/300][70/78]	eta 0:00:14 lr 0.000213	time 1.4457 (1.8322)	loss 2.1642 (2.1399)	grad_norm 0.6323 (0.6295)	mem 39782MB
[2023-07-07 18:54:23 RepVGG-A0] (main.py 291): INFO EPOCH 298 training takes 0:02:21
[2023-07-07 18:54:40 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.097 (17.097)	Loss 1.3234 (1.3234)	Acc@1 70.844 (70.844)	Acc@5 89.368 (89.368)	Mem 39782MB
[2023-07-07 18:54:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.926 Acc@5 89.596
[2023-07-07 18:54:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 298: 70.926%
[2023-07-07 18:54:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:55:02 RepVGG-A0] (main.py 282): INFO Train: [299/300][0/78]	eta 0:26:46 lr 0.000175	time 20.5938 (20.5938)	loss 2.1527 (2.1527)	grad_norm 0.6278 (0.6278)	mem 39782MB
[2023-07-07 18:55:18 RepVGG-A0] (main.py 282): INFO Train: [299/300][10/78]	eta 0:03:45 lr 0.000133	time 1.1722 (3.3196)	loss 2.1628 (2.1463)	grad_norm 0.6257 (0.6300)	mem 39782MB
[2023-07-07 18:55:33 RepVGG-A0] (main.py 282): INFO Train: [299/300][20/78]	eta 0:02:22 lr 0.000097	time 1.3943 (2.4599)	loss 2.0947 (2.1315)	grad_norm 0.6276 (0.6300)	mem 39782MB
[2023-07-07 18:55:48 RepVGG-A0] (main.py 282): INFO Train: [299/300][30/78]	eta 0:01:43 lr 0.000066	time 1.4190 (2.1565)	loss 2.1045 (2.1273)	grad_norm 0.6263 (0.6297)	mem 39782MB
[2023-07-07 18:56:06 RepVGG-A0] (main.py 282): INFO Train: [299/300][40/78]	eta 0:01:18 lr 0.000042	time 3.3016 (2.0577)	loss 2.1526 (2.1308)	grad_norm 0.6283 (0.6291)	mem 39782MB
[2023-07-07 18:56:21 RepVGG-A0] (main.py 282): INFO Train: [299/300][50/78]	eta 0:00:54 lr 0.000023	time 1.1733 (1.9426)	loss 2.1368 (2.1302)	grad_norm 0.6304 (0.6295)	mem 39782MB
[2023-07-07 18:56:35 RepVGG-A0] (main.py 282): INFO Train: [299/300][60/78]	eta 0:00:33 lr 0.000009	time 1.1723 (1.8613)	loss 2.2172 (2.1323)	grad_norm 0.6289 (0.6294)	mem 39782MB
[2023-07-07 18:56:50 RepVGG-A0] (main.py 282): INFO Train: [299/300][70/78]	eta 0:00:14 lr 0.000002	time 1.1265 (1.8173)	loss 2.1205 (2.1310)	grad_norm 0.6317 (0.6294)	mem 39782MB
[2023-07-07 18:57:02 RepVGG-A0] (main.py 291): INFO EPOCH 299 training takes 0:02:20
[2023-07-07 18:57:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.002 (17.002)	Loss 1.3233 (1.3233)	Acc@1 70.471 (70.471)	Acc@5 89.478 (89.478)	Mem 39782MB
[2023-07-07 18:57:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.892 Acc@5 89.628
[2023-07-07 18:57:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 299: 70.892%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 194): INFO Training time 11:54:08
