[2023-07-07 06:57:03 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 3
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 06:57:06 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 06:57:06 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 06:57:07 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 06:57:07 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 06:58:00 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 1:08:55 lr 0.000000	time 53.0143 (53.0143)	loss 6.9399 (6.9399)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 06:58:12 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:06:42 lr 0.164103	time 1.2068 (5.9152)	loss 6.8712 (6.9115)	grad_norm 0.3863 (0.4375)	mem 39782MB
[2023-07-07 06:58:25 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:36 lr 0.328205	time 1.2957 (3.7283)	loss 6.8298 (6.8847)	grad_norm 0.6087 (0.4656)	mem 39782MB
[2023-07-07 06:58:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:22 lr 0.492308	time 1.4229 (2.9770)	loss 6.6976 (6.8453)	grad_norm 0.3451 (0.4584)	mem 39782MB
[2023-07-07 06:58:52 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:37 lr 0.656410	time 1.1887 (2.5761)	loss 6.6137 (6.8029)	grad_norm 0.2875 (0.4779)	mem 39782MB
[2023-07-07 06:59:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:06 lr 0.820513	time 1.9151 (2.3583)	loss 6.5510 (6.7571)	grad_norm 0.4756 (0.4584)	mem 39782MB
[2023-07-07 06:59:24 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:40 lr 0.984615	time 2.0284 (2.2532)	loss 6.4946 (6.7191)	grad_norm 0.2836 (0.4587)	mem 39782MB
[2023-07-07 06:59:40 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:17 lr 1.148718	time 1.6023 (2.1536)	loss 6.4255 (6.6875)	grad_norm 0.2158 (0.4426)	mem 39782MB
[2023-07-07 06:59:50 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:43
[2023-07-07 07:01:01 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 4096
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 4096
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 3
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 12.8
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:01:05 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:01:05 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:01:05 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:01:05 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:09 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 3
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:03:12 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:03:12 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:03:12 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:03:12 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:55 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 0:56:13 lr 0.000000	time 43.2495 (43.2495)	loss 6.9399 (6.9399)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 07:04:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:05:41 lr 0.164103	time 1.1698 (5.0183)	loss 6.8695 (6.9111)	grad_norm 0.3837 (0.4372)	mem 39782MB
[2023-07-07 07:04:20 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:06 lr 0.328205	time 1.1728 (3.2159)	loss 6.8228 (6.8803)	grad_norm 0.6673 (0.4541)	mem 39782MB
[2023-07-07 07:04:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:04 lr 0.492308	time 1.1726 (2.5842)	loss 6.7223 (6.8489)	grad_norm 0.3204 (0.5029)	mem 39782MB
[2023-07-07 07:04:45 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:26 lr 0.656410	time 1.1720 (2.2744)	loss 6.6045 (6.8026)	grad_norm 0.2427 (0.4866)	mem 39782MB
[2023-07-07 07:05:02 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:00 lr 0.820513	time 2.4283 (2.1500)	loss 6.5360 (6.7606)	grad_norm 0.2072 (0.4704)	mem 39782MB
[2023-07-07 07:05:17 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:36 lr 0.984615	time 1.6836 (2.0477)	loss 6.4152 (6.7146)	grad_norm 0.3638 (0.4523)	mem 39782MB
[2023-07-07 07:05:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:15 lr 1.148718	time 1.1739 (1.9721)	loss 6.3630 (6.6722)	grad_norm 0.2930 (0.4425)	mem 39782MB
[2023-07-07 07:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:32
[2023-07-07 07:06:02 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.500 (17.500)	Loss 8.4176 (8.4176)	Acc@1 0.433 (0.433)	Acc@5 1.807 (1.807)	Mem 39782MB
[2023-07-07 07:06:04 RepVGG-A0] (main.py 342): INFO  * Acc@1 0.438 Acc@5 1.750
[2023-07-07 07:06:04 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 0: 0.438%
[2023-07-07 07:06:04 RepVGG-A0] (main.py 172): INFO Max accuracy: 0.44%
[2023-07-07 07:06:25 RepVGG-A0] (main.py 282): INFO Train: [1/300][0/78]	eta 0:27:47 lr 1.280000	time 21.3819 (21.3819)	loss 6.4427 (6.4427)	grad_norm 0.3022 (0.3022)	mem 39782MB
[2023-07-07 07:06:39 RepVGG-A0] (main.py 282): INFO Train: [1/300][10/78]	eta 0:03:37 lr 1.444103	time 1.1725 (3.1918)	loss 6.2870 (6.3514)	grad_norm 0.2858 (0.3078)	mem 39782MB
[2023-07-07 07:06:53 RepVGG-A0] (main.py 282): INFO Train: [1/300][20/78]	eta 0:02:15 lr 1.608205	time 1.1890 (2.3430)	loss 6.2489 (6.3142)	grad_norm 0.3848 (0.3558)	mem 39782MB
[2023-07-07 07:07:09 RepVGG-A0] (main.py 282): INFO Train: [1/300][30/78]	eta 0:01:39 lr 1.772308	time 1.2811 (2.0828)	loss 6.2200 (6.2828)	grad_norm 0.3921 (0.3527)	mem 39782MB
[2023-07-07 07:07:28 RepVGG-A0] (main.py 282): INFO Train: [1/300][40/78]	eta 0:01:18 lr 1.936410	time 4.3356 (2.0536)	loss 6.1365 (6.2512)	grad_norm 0.3742 (0.3538)	mem 39782MB
[2023-07-07 07:07:44 RepVGG-A0] (main.py 282): INFO Train: [1/300][50/78]	eta 0:00:54 lr 2.100513	time 1.1723 (1.9522)	loss 6.1474 (6.2247)	grad_norm 0.5806 (0.3590)	mem 39782MB
[2023-07-07 07:07:59 RepVGG-A0] (main.py 282): INFO Train: [1/300][60/78]	eta 0:00:33 lr 2.264615	time 1.3220 (1.8788)	loss 6.0542 (6.1976)	grad_norm 0.4412 (0.3583)	mem 39782MB
[2023-07-07 07:08:14 RepVGG-A0] (main.py 282): INFO Train: [1/300][70/78]	eta 0:00:14 lr 2.428718	time 1.3952 (1.8340)	loss 5.9838 (6.1671)	grad_norm 0.4348 (0.3595)	mem 39782MB
[2023-07-07 07:08:25 RepVGG-A0] (main.py 291): INFO EPOCH 1 training takes 0:02:21
[2023-07-07 07:08:47 RepVGG-A0] (main.py 282): INFO Train: [2/300][0/78]	eta 0:28:19 lr 2.560000	time 21.7828 (21.7828)	loss 5.8201 (5.8201)	grad_norm 0.3089 (0.3089)	mem 39782MB
[2023-07-07 07:09:01 RepVGG-A0] (main.py 282): INFO Train: [2/300][10/78]	eta 0:03:40 lr 2.724103	time 1.1895 (3.2466)	loss 5.8307 (5.8809)	grad_norm 0.3208 (0.3754)	mem 39782MB
[2023-07-07 07:09:16 RepVGG-A0] (main.py 282): INFO Train: [2/300][20/78]	eta 0:02:19 lr 2.888205	time 1.2256 (2.4113)	loss 5.8840 (5.8615)	grad_norm 0.5859 (0.3874)	mem 39782MB
[2023-07-07 07:09:31 RepVGG-A0] (main.py 282): INFO Train: [2/300][30/78]	eta 0:01:41 lr 3.052308	time 1.3622 (2.1192)	loss 5.8135 (5.8768)	grad_norm 0.3534 (0.3930)	mem 39782MB
[2023-07-07 07:09:49 RepVGG-A0] (main.py 282): INFO Train: [2/300][40/78]	eta 0:01:17 lr 3.216410	time 3.6722 (2.0323)	loss 5.6593 (5.8531)	grad_norm 0.2448 (0.3795)	mem 39782MB
[2023-07-07 07:10:04 RepVGG-A0] (main.py 282): INFO Train: [2/300][50/78]	eta 0:00:54 lr 3.380513	time 1.3520 (1.9345)	loss 5.6386 (5.8240)	grad_norm 0.2856 (0.3737)	mem 39782MB
[2023-07-07 07:10:20 RepVGG-A0] (main.py 282): INFO Train: [2/300][60/78]	eta 0:00:33 lr 3.544615	time 1.3071 (1.8780)	loss 5.5992 (5.7890)	grad_norm 0.3870 (0.3667)	mem 39782MB
[2023-07-07 07:10:35 RepVGG-A0] (main.py 282): INFO Train: [2/300][70/78]	eta 0:00:14 lr 3.708718	time 1.3864 (1.8238)	loss 5.4483 (5.7644)	grad_norm 0.2952 (0.3666)	mem 39782MB
[2023-07-07 07:10:47 RepVGG-A0] (main.py 291): INFO EPOCH 2 training takes 0:02:21
[2023-07-07 07:11:07 RepVGG-A0] (main.py 282): INFO Train: [3/300][0/78]	eta 0:26:33 lr 3.840000	time 20.4272 (20.4272)	loss 5.5222 (5.5222)	grad_norm 0.4211 (0.4211)	mem 39782MB
[2023-07-07 07:11:22 RepVGG-A0] (main.py 282): INFO Train: [3/300][10/78]	eta 0:03:35 lr 4.004103	time 1.1895 (3.1753)	loss 5.6613 (5.7014)	grad_norm 0.3348 (0.4536)	mem 39782MB
[2023-07-07 07:11:37 RepVGG-A0] (main.py 282): INFO Train: [3/300][20/78]	eta 0:02:18 lr 4.168205	time 1.1747 (2.3834)	loss 5.4817 (5.6404)	grad_norm 0.2892 (0.3932)	mem 39782MB
[2023-07-07 07:11:52 RepVGG-A0] (main.py 282): INFO Train: [3/300][30/78]	eta 0:01:40 lr 4.332308	time 1.5285 (2.1038)	loss 5.5189 (5.5689)	grad_norm 0.4183 (0.3690)	mem 39782MB
[2023-07-07 07:12:09 RepVGG-A0] (main.py 282): INFO Train: [3/300][40/78]	eta 0:01:16 lr 4.496410	time 3.6454 (2.0094)	loss 5.4271 (5.5186)	grad_norm 0.4425 (0.3594)	mem 39782MB
[2023-07-07 07:12:24 RepVGG-A0] (main.py 282): INFO Train: [3/300][50/78]	eta 0:00:53 lr 4.660513	time 1.1734 (1.8992)	loss 5.3781 (5.5100)	grad_norm 0.3540 (0.3620)	mem 39782MB
[2023-07-07 07:12:39 RepVGG-A0] (main.py 282): INFO Train: [3/300][60/78]	eta 0:00:33 lr 4.824615	time 1.1747 (1.8374)	loss 5.2551 (5.4712)	grad_norm 0.3398 (0.3547)	mem 39782MB
[2023-07-07 07:12:54 RepVGG-A0] (main.py 282): INFO Train: [3/300][70/78]	eta 0:00:14 lr 4.988718	time 1.6819 (1.7873)	loss 5.1440 (5.4333)	grad_norm 0.3245 (0.3490)	mem 39782MB
[2023-07-07 07:13:05 RepVGG-A0] (main.py 291): INFO EPOCH 3 training takes 0:02:18
[2023-07-07 07:13:26 RepVGG-A0] (main.py 282): INFO Train: [4/300][0/78]	eta 0:27:04 lr 5.120000	time 20.8235 (20.8235)	loss 5.1175 (5.1175)	grad_norm 0.3194 (0.3194)	mem 39782MB
[2023-07-07 07:13:40 RepVGG-A0] (main.py 282): INFO Train: [4/300][10/78]	eta 0:03:38 lr 5.284103	time 1.1912 (3.2112)	loss 5.2364 (5.2467)	grad_norm 0.3480 (0.3871)	mem 39782MB
[2023-07-07 07:13:55 RepVGG-A0] (main.py 282): INFO Train: [4/300][20/78]	eta 0:02:17 lr 5.448205	time 1.1722 (2.3742)	loss 5.0399 (5.1934)	grad_norm 0.3079 (0.3590)	mem 39782MB
[2023-07-07 07:14:10 RepVGG-A0] (main.py 282): INFO Train: [4/300][30/78]	eta 0:01:40 lr 5.612308	time 1.2713 (2.0910)	loss 5.1497 (5.1488)	grad_norm 0.4055 (0.3539)	mem 39782MB
[2023-07-07 07:14:28 RepVGG-A0] (main.py 282): INFO Train: [4/300][40/78]	eta 0:01:16 lr 5.776410	time 4.9597 (2.0258)	loss 5.1456 (5.1844)	grad_norm 0.2796 (0.3646)	mem 39782MB
[2023-07-07 07:14:44 RepVGG-A0] (main.py 282): INFO Train: [4/300][50/78]	eta 0:00:54 lr 5.940513	time 1.3379 (1.9298)	loss 5.0654 (5.1847)	grad_norm 0.2789 (0.3640)	mem 39782MB
[2023-07-07 07:14:59 RepVGG-A0] (main.py 282): INFO Train: [4/300][60/78]	eta 0:00:33 lr 6.104615	time 1.1734 (1.8588)	loss 5.0640 (5.1560)	grad_norm 0.4101 (0.3544)	mem 39782MB
[2023-07-07 07:15:14 RepVGG-A0] (main.py 282): INFO Train: [4/300][70/78]	eta 0:00:14 lr 6.268718	time 1.3737 (1.8149)	loss 4.9618 (5.1278)	grad_norm 0.3424 (0.3485)	mem 39782MB
[2023-07-07 07:15:26 RepVGG-A0] (main.py 291): INFO EPOCH 4 training takes 0:02:20
[2023-07-07 07:15:47 RepVGG-A0] (main.py 282): INFO Train: [5/300][0/78]	eta 0:27:49 lr 6.395615	time 21.4001 (21.4001)	loss 5.0424 (5.0424)	grad_norm 0.3501 (0.3501)	mem 39782MB
[2023-07-07 07:16:03 RepVGG-A0] (main.py 282): INFO Train: [5/300][10/78]	eta 0:03:48 lr 6.395387	time 1.1734 (3.3605)	loss 4.8161 (4.9068)	grad_norm 0.3121 (0.3207)	mem 39782MB
[2023-07-07 07:16:17 RepVGG-A0] (main.py 282): INFO Train: [5/300][20/78]	eta 0:02:20 lr 6.395153	time 1.2870 (2.4274)	loss 4.7295 (4.8603)	grad_norm 0.3066 (0.3194)	mem 39782MB
[2023-07-07 07:16:33 RepVGG-A0] (main.py 282): INFO Train: [5/300][30/78]	eta 0:01:43 lr 6.394914	time 1.2219 (2.1606)	loss 4.7563 (4.8408)	grad_norm 0.3153 (0.3274)	mem 39782MB
[2023-07-07 07:16:50 RepVGG-A0] (main.py 282): INFO Train: [5/300][40/78]	eta 0:01:18 lr 6.394669	time 3.6890 (2.0562)	loss 4.8380 (4.8257)	grad_norm 0.4065 (0.3341)	mem 39782MB
[2023-07-07 07:17:05 RepVGG-A0] (main.py 282): INFO Train: [5/300][50/78]	eta 0:00:54 lr 6.394418	time 1.1707 (1.9395)	loss 4.7270 (4.8161)	grad_norm 0.3186 (0.3363)	mem 39782MB
[2023-07-07 07:17:20 RepVGG-A0] (main.py 282): INFO Train: [5/300][60/78]	eta 0:00:33 lr 6.394162	time 1.3842 (1.8674)	loss 4.6687 (4.8049)	grad_norm 0.2947 (0.3370)	mem 39782MB
[2023-07-07 07:17:35 RepVGG-A0] (main.py 282): INFO Train: [5/300][70/78]	eta 0:00:14 lr 6.393899	time 1.3456 (1.8185)	loss 4.7200 (4.7864)	grad_norm 0.3928 (0.3394)	mem 39782MB
[2023-07-07 07:17:47 RepVGG-A0] (main.py 291): INFO EPOCH 5 training takes 0:02:21
[2023-07-07 07:18:09 RepVGG-A0] (main.py 282): INFO Train: [6/300][0/78]	eta 0:28:29 lr 6.393686	time 21.9145 (21.9145)	loss 4.5865 (4.5865)	grad_norm 0.3199 (0.3199)	mem 39782MB
[2023-07-07 07:18:24 RepVGG-A0] (main.py 282): INFO Train: [6/300][10/78]	eta 0:03:47 lr 6.393413	time 1.1723 (3.3472)	loss 4.6178 (4.5796)	grad_norm 0.3654 (0.3503)	mem 39782MB
[2023-07-07 07:18:38 RepVGG-A0] (main.py 282): INFO Train: [6/300][20/78]	eta 0:02:21 lr 6.393134	time 1.1967 (2.4433)	loss 4.6425 (4.5554)	grad_norm 0.4356 (0.3452)	mem 39782MB
[2023-07-07 07:18:53 RepVGG-A0] (main.py 282): INFO Train: [6/300][30/78]	eta 0:01:41 lr 6.392850	time 1.3744 (2.1215)	loss 4.8274 (4.6762)	grad_norm 0.3324 (0.3829)	mem 39782MB
[2023-07-07 07:19:11 RepVGG-A0] (main.py 282): INFO Train: [6/300][40/78]	eta 0:01:17 lr 6.392560	time 3.1447 (2.0436)	loss 4.6004 (4.6550)	grad_norm 0.3424 (0.3618)	mem 39782MB
[2023-07-07 07:19:27 RepVGG-A0] (main.py 282): INFO Train: [6/300][50/78]	eta 0:00:54 lr 6.392265	time 1.1723 (1.9522)	loss 4.3360 (4.6220)	grad_norm 0.2716 (0.3537)	mem 39782MB
[2023-07-07 07:19:42 RepVGG-A0] (main.py 282): INFO Train: [6/300][60/78]	eta 0:00:33 lr 6.391963	time 1.1942 (1.8816)	loss 4.6219 (4.5957)	grad_norm 0.4000 (0.3523)	mem 39782MB
[2023-07-07 07:19:57 RepVGG-A0] (main.py 282): INFO Train: [6/300][70/78]	eta 0:00:14 lr 6.391656	time 1.2226 (1.8299)	loss 4.3994 (4.5747)	grad_norm 0.3288 (0.3490)	mem 39782MB
[2023-07-07 07:20:09 RepVGG-A0] (main.py 291): INFO EPOCH 6 training takes 0:02:22
[2023-07-07 07:20:31 RepVGG-A0] (main.py 282): INFO Train: [7/300][0/78]	eta 0:27:45 lr 6.391406	time 21.3517 (21.3517)	loss 4.9094 (4.9094)	grad_norm 0.6078 (0.6078)	mem 39782MB
[2023-07-07 07:20:45 RepVGG-A0] (main.py 282): INFO Train: [7/300][10/78]	eta 0:03:38 lr 6.391089	time 1.1712 (3.2184)	loss 5.0064 (5.2065)	grad_norm 0.3224 (0.5314)	mem 39782MB
[2023-07-07 07:20:59 RepVGG-A0] (main.py 282): INFO Train: [7/300][20/78]	eta 0:02:17 lr 6.390766	time 1.1718 (2.3771)	loss 4.5063 (4.9948)	grad_norm 0.2351 (0.4205)	mem 39782MB
[2023-07-07 07:21:15 RepVGG-A0] (main.py 282): INFO Train: [7/300][30/78]	eta 0:01:41 lr 6.390437	time 1.5859 (2.1145)	loss 4.3297 (4.8615)	grad_norm 0.2142 (0.3827)	mem 39782MB
[2023-07-07 07:21:34 RepVGG-A0] (main.py 282): INFO Train: [7/300][40/78]	eta 0:01:18 lr 6.390102	time 3.9618 (2.0555)	loss 4.3717 (4.7430)	grad_norm 0.3031 (0.3593)	mem 39782MB
[2023-07-07 07:21:50 RepVGG-A0] (main.py 282): INFO Train: [7/300][50/78]	eta 0:00:55 lr 6.389761	time 1.2680 (1.9692)	loss 4.4473 (4.6657)	grad_norm 0.3885 (0.3520)	mem 39782MB
[2023-07-07 07:22:05 RepVGG-A0] (main.py 282): INFO Train: [7/300][60/78]	eta 0:00:34 lr 6.389415	time 1.5198 (1.8991)	loss 4.2037 (4.6117)	grad_norm 0.2802 (0.3473)	mem 39782MB
[2023-07-07 07:22:20 RepVGG-A0] (main.py 282): INFO Train: [7/300][70/78]	eta 0:00:14 lr 6.389063	time 1.1747 (1.8371)	loss 4.4650 (4.5804)	grad_norm 0.3772 (0.3502)	mem 39782MB
[2023-07-07 07:22:31 RepVGG-A0] (main.py 291): INFO EPOCH 7 training takes 0:02:21
[2023-07-07 07:22:53 RepVGG-A0] (main.py 282): INFO Train: [8/300][0/78]	eta 0:28:10 lr 6.388777	time 21.6757 (21.6757)	loss 4.2105 (4.2105)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 07:23:06 RepVGG-A0] (main.py 282): INFO Train: [8/300][10/78]	eta 0:03:36 lr 6.388415	time 1.1714 (3.1829)	loss 4.1416 (4.2118)	grad_norm 0.3247 (0.3365)	mem 39782MB
[2023-07-07 07:23:20 RepVGG-A0] (main.py 282): INFO Train: [8/300][20/78]	eta 0:02:15 lr 6.388047	time 1.1895 (2.3436)	loss 4.3174 (4.2531)	grad_norm 0.3676 (0.3602)	mem 39782MB
[2023-07-07 07:23:35 RepVGG-A0] (main.py 282): INFO Train: [8/300][30/78]	eta 0:01:39 lr 6.387673	time 1.3642 (2.0775)	loss 4.2835 (4.2612)	grad_norm 0.3572 (0.3583)	mem 39782MB
[2023-07-07 07:23:54 RepVGG-A0] (main.py 282): INFO Train: [8/300][40/78]	eta 0:01:16 lr 6.387293	time 4.0665 (2.0153)	loss 4.1164 (4.2471)	grad_norm 0.3285 (0.3522)	mem 39782MB
[2023-07-07 07:24:09 RepVGG-A0] (main.py 282): INFO Train: [8/300][50/78]	eta 0:00:53 lr 6.386908	time 1.1721 (1.9166)	loss 4.1728 (4.2449)	grad_norm 0.3480 (0.3560)	mem 39782MB
[2023-07-07 07:24:23 RepVGG-A0] (main.py 282): INFO Train: [8/300][60/78]	eta 0:00:33 lr 6.386517	time 1.2015 (1.8410)	loss 4.0175 (4.2299)	grad_norm 0.3056 (0.3526)	mem 39782MB
[2023-07-07 07:24:39 RepVGG-A0] (main.py 282): INFO Train: [8/300][70/78]	eta 0:00:14 lr 6.386120	time 1.1738 (1.8039)	loss 4.5976 (4.2511)	grad_norm 0.5369 (0.3675)	mem 39782MB
[2023-07-07 07:24:51 RepVGG-A0] (main.py 291): INFO EPOCH 8 training takes 0:02:20
[2023-07-07 07:25:13 RepVGG-A0] (main.py 282): INFO Train: [9/300][0/78]	eta 0:28:42 lr 6.385798	time 22.0823 (22.0823)	loss 4.5473 (4.5473)	grad_norm 0.3629 (0.3629)	mem 39782MB
[2023-07-07 07:25:27 RepVGG-A0] (main.py 282): INFO Train: [9/300][10/78]	eta 0:03:41 lr 6.385391	time 1.1728 (3.2502)	loss 4.1219 (4.2980)	grad_norm 0.2382 (0.2936)	mem 39782MB
[2023-07-07 07:25:43 RepVGG-A0] (main.py 282): INFO Train: [9/300][20/78]	eta 0:02:22 lr 6.384978	time 1.3330 (2.4556)	loss 4.1156 (4.2293)	grad_norm 0.3011 (0.2995)	mem 39782MB
[2023-07-07 07:25:57 RepVGG-A0] (main.py 282): INFO Train: [9/300][30/78]	eta 0:01:42 lr 6.384560	time 1.2953 (2.1282)	loss 3.9849 (4.1861)	grad_norm 0.2605 (0.3031)	mem 39782MB
[2023-07-07 07:26:14 RepVGG-A0] (main.py 282): INFO Train: [9/300][40/78]	eta 0:01:16 lr 6.384135	time 2.5130 (2.0185)	loss 4.0042 (4.1559)	grad_norm 0.3226 (0.3117)	mem 39782MB
[2023-07-07 07:26:30 RepVGG-A0] (main.py 282): INFO Train: [9/300][50/78]	eta 0:00:54 lr 6.383705	time 1.1736 (1.9368)	loss 4.4179 (4.1696)	grad_norm 0.4367 (0.3327)	mem 39782MB
[2023-07-07 07:26:45 RepVGG-A0] (main.py 282): INFO Train: [9/300][60/78]	eta 0:00:33 lr 6.383269	time 1.1766 (1.8662)	loss 3.9630 (4.1516)	grad_norm 0.3265 (0.3286)	mem 39782MB
[2023-07-07 07:27:00 RepVGG-A0] (main.py 282): INFO Train: [9/300][70/78]	eta 0:00:14 lr 6.382827	time 1.3988 (1.8121)	loss 4.0524 (4.1332)	grad_norm 0.3517 (0.3280)	mem 39782MB
[2023-07-07 07:27:11 RepVGG-A0] (main.py 291): INFO EPOCH 9 training takes 0:02:19
[2023-07-07 07:27:32 RepVGG-A0] (main.py 282): INFO Train: [10/300][0/78]	eta 0:27:11 lr 6.382470	time 20.9152 (20.9152)	loss 4.3315 (4.3315)	grad_norm 0.4651 (0.4651)	mem 39782MB
[2023-07-07 07:27:47 RepVGG-A0] (main.py 282): INFO Train: [10/300][10/78]	eta 0:03:40 lr 6.382018	time 1.1717 (3.2450)	loss 4.0418 (4.1143)	grad_norm 0.3140 (0.3522)	mem 39782MB
[2023-07-07 07:28:02 RepVGG-A0] (main.py 282): INFO Train: [10/300][20/78]	eta 0:02:20 lr 6.381560	time 1.2090 (2.4155)	loss 4.1158 (4.0623)	grad_norm 0.3932 (0.3513)	mem 39782MB
[2023-07-07 07:28:16 RepVGG-A0] (main.py 282): INFO Train: [10/300][30/78]	eta 0:01:41 lr 6.381097	time 1.4520 (2.1121)	loss 4.1394 (4.0307)	grad_norm 0.4598 (0.3468)	mem 39782MB
[2023-07-07 07:28:34 RepVGG-A0] (main.py 282): INFO Train: [10/300][40/78]	eta 0:01:17 lr 6.380628	time 3.9255 (2.0355)	loss 4.0421 (4.0439)	grad_norm 0.3532 (0.3555)	mem 39782MB
[2023-07-07 07:28:50 RepVGG-A0] (main.py 282): INFO Train: [10/300][50/78]	eta 0:00:54 lr 6.380153	time 1.1742 (1.9416)	loss 3.9422 (4.0328)	grad_norm 0.3167 (0.3534)	mem 39782MB
[2023-07-07 07:29:05 RepVGG-A0] (main.py 282): INFO Train: [10/300][60/78]	eta 0:00:33 lr 6.379672	time 1.1842 (1.8761)	loss 3.9715 (4.0236)	grad_norm 0.3627 (0.3533)	mem 39782MB
[2023-07-07 07:29:21 RepVGG-A0] (main.py 282): INFO Train: [10/300][70/78]	eta 0:00:14 lr 6.379186	time 1.3863 (1.8349)	loss 3.9064 (4.0124)	grad_norm 0.3247 (0.3522)	mem 39782MB
[2023-07-07 07:29:33 RepVGG-A0] (main.py 291): INFO EPOCH 10 training takes 0:02:21
[2023-07-07 07:29:55 RepVGG-A0] (main.py 282): INFO Train: [11/300][0/78]	eta 0:28:44 lr 6.378793	time 22.1044 (22.1044)	loss 4.2912 (4.2912)	grad_norm 0.4965 (0.4965)	mem 39782MB
[2023-07-07 07:30:09 RepVGG-A0] (main.py 282): INFO Train: [11/300][10/78]	eta 0:03:45 lr 6.378296	time 1.1903 (3.3182)	loss 4.5630 (4.6020)	grad_norm 0.4137 (0.5417)	mem 39782MB
[2023-07-07 07:30:23 RepVGG-A0] (main.py 282): INFO Train: [11/300][20/78]	eta 0:02:19 lr 6.377794	time 1.1759 (2.4105)	loss 3.9908 (4.4131)	grad_norm 0.2363 (0.4263)	mem 39782MB
[2023-07-07 07:30:39 RepVGG-A0] (main.py 282): INFO Train: [11/300][30/78]	eta 0:01:42 lr 6.377286	time 1.3717 (2.1452)	loss 3.9930 (4.2800)	grad_norm 0.2683 (0.3847)	mem 39782MB
[2023-07-07 07:30:57 RepVGG-A0] (main.py 282): INFO Train: [11/300][40/78]	eta 0:01:18 lr 6.376772	time 3.5335 (2.0596)	loss 3.9551 (4.1847)	grad_norm 0.3163 (0.3636)	mem 39782MB
[2023-07-07 07:31:12 RepVGG-A0] (main.py 282): INFO Train: [11/300][50/78]	eta 0:00:54 lr 6.376252	time 1.1720 (1.9441)	loss 3.9423 (4.1265)	grad_norm 0.3426 (0.3517)	mem 39782MB
[2023-07-07 07:31:28 RepVGG-A0] (main.py 282): INFO Train: [11/300][60/78]	eta 0:00:33 lr 6.375727	time 1.2859 (1.8827)	loss 3.9116 (4.1046)	grad_norm 0.3005 (0.3552)	mem 39782MB
[2023-07-07 07:31:42 RepVGG-A0] (main.py 282): INFO Train: [11/300][70/78]	eta 0:00:14 lr 6.375196	time 1.3165 (1.8246)	loss 4.3357 (4.0884)	grad_norm 0.5178 (0.3610)	mem 39782MB
[2023-07-07 07:31:54 RepVGG-A0] (main.py 291): INFO EPOCH 11 training takes 0:02:21
[2023-07-07 07:32:16 RepVGG-A0] (main.py 282): INFO Train: [12/300][0/78]	eta 0:28:04 lr 6.374767	time 21.5907 (21.5907)	loss 3.9181 (3.9181)	grad_norm 0.3421 (0.3421)	mem 39782MB
[2023-07-07 07:32:30 RepVGG-A0] (main.py 282): INFO Train: [12/300][10/78]	eta 0:03:42 lr 6.374226	time 1.1722 (3.2759)	loss 3.8831 (3.8601)	grad_norm 0.3571 (0.3158)	mem 39782MB
[2023-07-07 07:32:45 RepVGG-A0] (main.py 282): INFO Train: [12/300][20/78]	eta 0:02:20 lr 6.373679	time 1.2078 (2.4227)	loss 3.8371 (3.8411)	grad_norm 0.3231 (0.3243)	mem 39782MB
[2023-07-07 07:33:00 RepVGG-A0] (main.py 282): INFO Train: [12/300][30/78]	eta 0:01:42 lr 6.373126	time 1.2423 (2.1399)	loss 4.1692 (3.8651)	grad_norm 0.4718 (0.3424)	mem 39782MB
[2023-07-07 07:33:18 RepVGG-A0] (main.py 282): INFO Train: [12/300][40/78]	eta 0:01:17 lr 6.372567	time 2.8709 (2.0350)	loss 3.7586 (3.8766)	grad_norm 0.2953 (0.3434)	mem 39782MB
[2023-07-07 07:33:33 RepVGG-A0] (main.py 282): INFO Train: [12/300][50/78]	eta 0:00:54 lr 6.372003	time 1.1739 (1.9354)	loss 3.9121 (3.8716)	grad_norm 0.3674 (0.3439)	mem 39782MB
[2023-07-07 07:33:49 RepVGG-A0] (main.py 282): INFO Train: [12/300][60/78]	eta 0:00:33 lr 6.371433	time 1.2478 (1.8816)	loss 3.9143 (3.8703)	grad_norm 0.3711 (0.3458)	mem 39782MB
[2023-07-07 07:34:03 RepVGG-A0] (main.py 282): INFO Train: [12/300][70/78]	eta 0:00:14 lr 6.370858	time 1.3250 (1.8187)	loss 4.1998 (3.8774)	grad_norm 0.5503 (0.3526)	mem 39782MB
[2023-07-07 07:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 12 training takes 0:02:20
[2023-07-07 07:34:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][0/78]	eta 0:28:26 lr 6.370393	time 21.8781 (21.8781)	loss 4.5616 (4.5616)	grad_norm 0.5121 (0.5121)	mem 39782MB
[2023-07-07 07:34:50 RepVGG-A0] (main.py 282): INFO Train: [13/300][10/78]	eta 0:03:42 lr 6.369807	time 1.1706 (3.2708)	loss 4.0002 (4.2381)	grad_norm 0.3029 (0.3710)	mem 39782MB
[2023-07-07 07:35:05 RepVGG-A0] (main.py 282): INFO Train: [13/300][20/78]	eta 0:02:18 lr 6.369216	time 1.1731 (2.3956)	loss 3.8351 (4.0637)	grad_norm 0.2852 (0.3273)	mem 39782MB
[2023-07-07 07:35:20 RepVGG-A0] (main.py 282): INFO Train: [13/300][30/78]	eta 0:01:40 lr 6.368618	time 1.4255 (2.1032)	loss 3.7687 (3.9886)	grad_norm 0.3547 (0.3255)	mem 39782MB
[2023-07-07 07:35:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][40/78]	eta 0:01:15 lr 6.368015	time 2.8679 (1.9956)	loss 3.8209 (3.9403)	grad_norm 0.3138 (0.3253)	mem 39782MB
[2023-07-07 07:35:52 RepVGG-A0] (main.py 282): INFO Train: [13/300][50/78]	eta 0:00:53 lr 6.367406	time 1.3422 (1.9135)	loss 4.0853 (3.9270)	grad_norm 0.4586 (0.3365)	mem 39782MB
[2023-07-07 07:36:07 RepVGG-A0] (main.py 282): INFO Train: [13/300][60/78]	eta 0:00:33 lr 6.366792	time 1.1731 (1.8427)	loss 3.7339 (3.9093)	grad_norm 0.3021 (0.3360)	mem 39782MB
[2023-07-07 07:36:22 RepVGG-A0] (main.py 282): INFO Train: [13/300][70/78]	eta 0:00:14 lr 6.366172	time 1.5847 (1.8048)	loss 3.7660 (3.8878)	grad_norm 0.3652 (0.3343)	mem 39782MB
[2023-07-07 07:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 13 training takes 0:02:19
[2023-07-07 07:36:55 RepVGG-A0] (main.py 282): INFO Train: [14/300][0/78]	eta 0:27:02 lr 6.365671	time 20.7962 (20.7962)	loss 3.9315 (3.9315)	grad_norm 0.3951 (0.3951)	mem 39782MB
[2023-07-07 07:37:10 RepVGG-A0] (main.py 282): INFO Train: [14/300][10/78]	eta 0:03:42 lr 6.365041	time 1.1731 (3.2746)	loss 3.7196 (3.8111)	grad_norm 0.3136 (0.3536)	mem 39782MB
[2023-07-07 07:37:25 RepVGG-A0] (main.py 282): INFO Train: [14/300][20/78]	eta 0:02:20 lr 6.364405	time 1.1729 (2.4233)	loss 3.7754 (3.7790)	grad_norm 0.3702 (0.3490)	mem 39782MB
[2023-07-07 07:37:40 RepVGG-A0] (main.py 282): INFO Train: [14/300][30/78]	eta 0:01:42 lr 6.363763	time 1.2027 (2.1261)	loss 3.8550 (3.7927)	grad_norm 0.3959 (0.3608)	mem 39782MB
[2023-07-07 07:37:59 RepVGG-A0] (main.py 282): INFO Train: [14/300][40/78]	eta 0:01:18 lr 6.363115	time 4.3126 (2.0610)	loss 3.7596 (3.7953)	grad_norm 0.3423 (0.3600)	mem 39782MB
[2023-07-07 07:38:14 RepVGG-A0] (main.py 282): INFO Train: [14/300][50/78]	eta 0:00:54 lr 6.362462	time 1.2455 (1.9519)	loss 3.8074 (3.7882)	grad_norm 0.3715 (0.3569)	mem 39782MB
[2023-07-07 07:38:29 RepVGG-A0] (main.py 282): INFO Train: [14/300][60/78]	eta 0:00:33 lr 6.361803	time 1.1812 (1.8778)	loss 4.3682 (3.8520)	grad_norm 0.5011 (0.3816)	mem 39782MB
[2023-07-07 07:38:44 RepVGG-A0] (main.py 282): INFO Train: [14/300][70/78]	eta 0:00:14 lr 6.361139	time 1.4323 (1.8297)	loss 3.8065 (3.8839)	grad_norm 0.2397 (0.3792)	mem 39782MB
[2023-07-07 07:38:56 RepVGG-A0] (main.py 291): INFO EPOCH 14 training takes 0:02:21
[2023-07-07 07:39:16 RepVGG-A0] (main.py 282): INFO Train: [15/300][0/78]	eta 0:25:53 lr 6.360603	time 19.9125 (19.9125)	loss 3.7038 (3.7038)	grad_norm 0.2818 (0.2818)	mem 39782MB
[2023-07-07 07:39:32 RepVGG-A0] (main.py 282): INFO Train: [15/300][10/78]	eta 0:03:45 lr 6.359928	time 1.1745 (3.3168)	loss 3.6269 (3.7331)	grad_norm 0.2760 (0.3218)	mem 39782MB
[2023-07-07 07:39:46 RepVGG-A0] (main.py 282): INFO Train: [15/300][20/78]	eta 0:02:20 lr 6.359247	time 1.3140 (2.4228)	loss 3.7487 (3.7117)	grad_norm 0.3307 (0.3248)	mem 39782MB
[2023-07-07 07:40:01 RepVGG-A0] (main.py 282): INFO Train: [15/300][30/78]	eta 0:01:41 lr 6.358561	time 1.1910 (2.1224)	loss 3.7674 (3.6927)	grad_norm 0.3374 (0.3216)	mem 39782MB
[2023-07-07 07:40:20 RepVGG-A0] (main.py 282): INFO Train: [15/300][40/78]	eta 0:01:17 lr 6.357869	time 3.6502 (2.0483)	loss 3.7280 (3.7015)	grad_norm 0.3651 (0.3323)	mem 39782MB
[2023-07-07 07:40:35 RepVGG-A0] (main.py 282): INFO Train: [15/300][50/78]	eta 0:00:54 lr 6.357171	time 1.1734 (1.9402)	loss 4.2722 (3.7444)	grad_norm 0.6949 (0.3576)	mem 39782MB
[2023-07-07 07:40:50 RepVGG-A0] (main.py 282): INFO Train: [15/300][60/78]	eta 0:00:33 lr 6.356468	time 1.3043 (1.8700)	loss 5.2670 (4.0202)	grad_norm 0.4850 (0.4067)	mem 39782MB
[2023-07-07 07:41:05 RepVGG-A0] (main.py 282): INFO Train: [15/300][70/78]	eta 0:00:14 lr 6.355759	time 1.2068 (1.8168)	loss 4.4144 (4.1228)	grad_norm 0.2292 (0.3932)	mem 39782MB
[2023-07-07 07:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 15 training takes 0:02:21
[2023-07-07 07:41:37 RepVGG-A0] (main.py 282): INFO Train: [16/300][0/78]	eta 0:26:21 lr 6.355187	time 20.2721 (20.2721)	loss 4.2752 (4.2752)	grad_norm 0.2985 (0.2985)	mem 39782MB
[2023-07-07 07:41:53 RepVGG-A0] (main.py 282): INFO Train: [16/300][10/78]	eta 0:03:43 lr 6.354468	time 1.1708 (3.2825)	loss 3.9071 (4.0688)	grad_norm 0.2392 (0.2544)	mem 39782MB
[2023-07-07 07:42:07 RepVGG-A0] (main.py 282): INFO Train: [16/300][20/78]	eta 0:02:19 lr 6.353743	time 1.1722 (2.4010)	loss 3.9288 (4.0137)	grad_norm 0.3623 (0.2789)	mem 39782MB
[2023-07-07 07:42:23 RepVGG-A0] (main.py 282): INFO Train: [16/300][30/78]	eta 0:01:42 lr 6.353012	time 1.6038 (2.1300)	loss 3.8132 (3.9806)	grad_norm 0.2343 (0.2871)	mem 39782MB
[2023-07-07 07:42:40 RepVGG-A0] (main.py 282): INFO Train: [16/300][40/78]	eta 0:01:17 lr 6.352276	time 3.5622 (2.0372)	loss 4.0529 (3.9542)	grad_norm 0.4042 (0.2984)	mem 39782MB
[2023-07-07 07:42:55 RepVGG-A0] (main.py 282): INFO Train: [16/300][50/78]	eta 0:00:54 lr 6.351534	time 1.1722 (1.9318)	loss 3.8401 (3.9274)	grad_norm 0.3138 (0.2998)	mem 39782MB
[2023-07-07 07:43:11 RepVGG-A0] (main.py 282): INFO Train: [16/300][60/78]	eta 0:00:33 lr 6.350786	time 1.2720 (1.8749)	loss 4.0029 (3.9156)	grad_norm 0.4180 (0.3114)	mem 39782MB
[2023-07-07 07:43:26 RepVGG-A0] (main.py 282): INFO Train: [16/300][70/78]	eta 0:00:14 lr 6.350033	time 1.1766 (1.8207)	loss 3.7638 (3.9047)	grad_norm 0.3425 (0.3142)	mem 39782MB
[2023-07-07 07:43:38 RepVGG-A0] (main.py 291): INFO EPOCH 16 training takes 0:02:20
[2023-07-07 07:43:58 RepVGG-A0] (main.py 282): INFO Train: [17/300][0/78]	eta 0:26:54 lr 6.349426	time 20.6997 (20.6997)	loss 3.6306 (3.6306)	grad_norm 0.3172 (0.3172)	mem 39782MB
[2023-07-07 07:44:14 RepVGG-A0] (main.py 282): INFO Train: [17/300][10/78]	eta 0:03:43 lr 6.348662	time 1.1709 (3.2849)	loss 3.7250 (3.7121)	grad_norm 0.3768 (0.3612)	mem 39782MB
[2023-07-07 07:44:29 RepVGG-A0] (main.py 282): INFO Train: [17/300][20/78]	eta 0:02:21 lr 6.347893	time 1.1772 (2.4356)	loss 3.6829 (3.7222)	grad_norm 0.3442 (0.3521)	mem 39782MB
[2023-07-07 07:44:44 RepVGG-A0] (main.py 282): INFO Train: [17/300][30/78]	eta 0:01:42 lr 6.347118	time 1.1257 (2.1393)	loss 3.7612 (3.7273)	grad_norm 0.3819 (0.3557)	mem 39782MB
[2023-07-07 07:45:02 RepVGG-A0] (main.py 282): INFO Train: [17/300][40/78]	eta 0:01:18 lr 6.346337	time 3.9559 (2.0573)	loss 3.6107 (3.7237)	grad_norm 0.3219 (0.3521)	mem 39782MB
[2023-07-07 07:45:18 RepVGG-A0] (main.py 282): INFO Train: [17/300][50/78]	eta 0:00:54 lr 6.345551	time 1.2799 (1.9627)	loss 3.9002 (3.7368)	grad_norm 0.4348 (0.3601)	mem 39782MB
[2023-07-07 07:45:32 RepVGG-A0] (main.py 282): INFO Train: [17/300][60/78]	eta 0:00:33 lr 6.344759	time 1.1852 (1.8782)	loss 3.6846 (3.7495)	grad_norm 0.2790 (0.3611)	mem 39782MB
[2023-07-07 07:45:47 RepVGG-A0] (main.py 282): INFO Train: [17/300][70/78]	eta 0:00:14 lr 6.343961	time 1.1684 (1.8252)	loss 3.6803 (3.7408)	grad_norm 0.3194 (0.3548)	mem 39782MB
[2023-07-07 07:46:00 RepVGG-A0] (main.py 291): INFO EPOCH 17 training takes 0:02:22
[2023-07-07 07:46:22 RepVGG-A0] (main.py 282): INFO Train: [18/300][0/78]	eta 0:27:28 lr 6.343319	time 21.1338 (21.1338)	loss 6.3002 (6.3002)	grad_norm 1.0156 (1.0156)	mem 39782MB
[2023-07-07 07:46:36 RepVGG-A0] (main.py 282): INFO Train: [18/300][10/78]	eta 0:03:41 lr 6.342511	time 1.1915 (3.2642)	loss 5.4564 (5.8249)	grad_norm 0.4270 (0.5488)	mem 39782MB
[2023-07-07 07:46:51 RepVGG-A0] (main.py 282): INFO Train: [18/300][20/78]	eta 0:02:18 lr 6.341698	time 1.1734 (2.3954)	loss 4.7645 (5.4208)	grad_norm 0.3467 (0.4279)	mem 39782MB
[2023-07-07 07:47:06 RepVGG-A0] (main.py 282): INFO Train: [18/300][30/78]	eta 0:01:40 lr 6.340879	time 1.1273 (2.1022)	loss 4.3970 (5.1629)	grad_norm 0.2444 (0.3872)	mem 39782MB
[2023-07-07 07:47:24 RepVGG-A0] (main.py 282): INFO Train: [18/300][40/78]	eta 0:01:17 lr 6.340054	time 4.1909 (2.0445)	loss 4.3150 (4.9483)	grad_norm 0.3201 (0.3564)	mem 39782MB
[2023-07-07 07:47:39 RepVGG-A0] (main.py 282): INFO Train: [18/300][50/78]	eta 0:00:54 lr 6.339223	time 1.1719 (1.9417)	loss 4.0917 (4.7992)	grad_norm 0.2617 (0.3466)	mem 39782MB
[2023-07-07 07:47:55 RepVGG-A0] (main.py 282): INFO Train: [18/300][60/78]	eta 0:00:33 lr 6.338387	time 1.2978 (1.8791)	loss 4.1137 (4.6775)	grad_norm 0.3505 (0.3408)	mem 39782MB
[2023-07-07 07:48:11 RepVGG-A0] (main.py 282): INFO Train: [18/300][70/78]	eta 0:00:14 lr 6.337545	time 1.4937 (1.8391)	loss 4.0678 (4.5825)	grad_norm 0.3598 (0.3366)	mem 39782MB
[2023-07-07 07:48:22 RepVGG-A0] (main.py 291): INFO EPOCH 18 training takes 0:02:21
[2023-07-07 07:48:43 RepVGG-A0] (main.py 282): INFO Train: [19/300][0/78]	eta 0:27:28 lr 6.336868	time 21.1379 (21.1379)	loss 3.8354 (3.8354)	grad_norm 0.3231 (0.3231)	mem 39782MB
[2023-07-07 07:48:57 RepVGG-A0] (main.py 282): INFO Train: [19/300][10/78]	eta 0:03:36 lr 6.336016	time 1.1709 (3.1851)	loss 3.9307 (3.9039)	grad_norm 0.3505 (0.3401)	mem 39782MB
[2023-07-07 07:49:12 RepVGG-A0] (main.py 282): INFO Train: [19/300][20/78]	eta 0:02:18 lr 6.335158	time 1.2063 (2.3952)	loss 3.9978 (3.9145)	grad_norm 0.3872 (0.3436)	mem 39782MB
[2023-07-07 07:49:27 RepVGG-A0] (main.py 282): INFO Train: [19/300][30/78]	eta 0:01:39 lr 6.334295	time 1.1265 (2.0825)	loss 3.7529 (3.9069)	grad_norm 0.3336 (0.3445)	mem 39782MB
[2023-07-07 07:49:44 RepVGG-A0] (main.py 282): INFO Train: [19/300][40/78]	eta 0:01:16 lr 6.333426	time 4.0422 (2.0013)	loss 3.9696 (3.8844)	grad_norm 0.4114 (0.3415)	mem 39782MB
[2023-07-07 07:50:00 RepVGG-A0] (main.py 282): INFO Train: [19/300][50/78]	eta 0:00:53 lr 6.332551	time 1.1734 (1.9089)	loss 3.7907 (3.8747)	grad_norm 0.3259 (0.3416)	mem 39782MB
[2023-07-07 07:50:15 RepVGG-A0] (main.py 282): INFO Train: [19/300][60/78]	eta 0:00:33 lr 6.331671	time 1.2536 (1.8423)	loss 3.8421 (3.8632)	grad_norm 0.3858 (0.3434)	mem 39782MB
[2023-07-07 07:50:30 RepVGG-A0] (main.py 282): INFO Train: [19/300][70/78]	eta 0:00:14 lr 6.330785	time 1.1754 (1.8000)	loss 4.0089 (3.8625)	grad_norm 0.4791 (0.3495)	mem 39782MB
[2023-07-07 07:50:41 RepVGG-A0] (main.py 291): INFO EPOCH 19 training takes 0:02:19
[2023-07-07 07:51:03 RepVGG-A0] (main.py 282): INFO Train: [20/300][0/78]	eta 0:28:14 lr 6.330072	time 21.7208 (21.7208)	loss 3.7479 (3.7479)	grad_norm 0.2921 (0.2921)	mem 39782MB
[2023-07-07 07:51:17 RepVGG-A0] (main.py 282): INFO Train: [20/300][10/78]	eta 0:03:42 lr 6.329176	time 1.1775 (3.2769)	loss 4.1518 (3.8327)	grad_norm 0.4776 (0.3881)	mem 39782MB
[2023-07-07 07:51:33 RepVGG-A0] (main.py 282): INFO Train: [20/300][20/78]	eta 0:02:22 lr 6.328275	time 1.1759 (2.4587)	loss 3.7529 (3.8447)	grad_norm 0.3171 (0.3670)	mem 39782MB
[2023-07-07 07:51:49 RepVGG-A0] (main.py 282): INFO Train: [20/300][30/78]	eta 0:01:44 lr 6.327367	time 1.6727 (2.1742)	loss 3.8033 (3.8618)	grad_norm 0.3293 (0.3753)	mem 39782MB
[2023-07-07 07:52:06 RepVGG-A0] (main.py 282): INFO Train: [20/300][40/78]	eta 0:01:18 lr 6.326454	time 3.9685 (2.0678)	loss 3.7375 (3.8344)	grad_norm 0.3773 (0.3609)	mem 39782MB
[2023-07-07 07:52:21 RepVGG-A0] (main.py 282): INFO Train: [20/300][50/78]	eta 0:00:54 lr 6.325536	time 1.1930 (1.9521)	loss 3.5751 (3.8057)	grad_norm 0.2934 (0.3514)	mem 39782MB
[2023-07-07 07:52:36 RepVGG-A0] (main.py 282): INFO Train: [20/300][60/78]	eta 0:00:33 lr 6.324611	time 1.4753 (1.8844)	loss 3.9349 (3.8045)	grad_norm 0.4276 (0.3578)	mem 39782MB
[2023-07-07 07:52:51 RepVGG-A0] (main.py 282): INFO Train: [20/300][70/78]	eta 0:00:14 lr 6.323682	time 1.1258 (1.8275)	loss 3.7016 (3.8068)	grad_norm 0.3177 (0.3581)	mem 39782MB
[2023-07-07 07:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 20 training takes 0:02:20
[2023-07-07 07:53:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.626 (17.626)	Loss 3.2837 (3.2837)	Acc@1 32.971 (32.971)	Acc@5 57.623 (57.623)	Mem 39782MB
[2023-07-07 07:53:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 32.742 Acc@5 57.506
[2023-07-07 07:53:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 20: 32.742%
[2023-07-07 07:53:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 07:53:42 RepVGG-A0] (main.py 282): INFO Train: [21/300][0/78]	eta 0:27:33 lr 6.322934	time 21.2020 (21.2020)	loss 3.6087 (3.6087)	grad_norm 0.3284 (0.3284)	mem 39782MB
[2023-07-07 07:53:57 RepVGG-A0] (main.py 282): INFO Train: [21/300][10/78]	eta 0:03:45 lr 6.321994	time 1.1737 (3.3109)	loss 3.9081 (3.7041)	grad_norm 0.4108 (0.3748)	mem 39782MB
[2023-07-07 07:54:12 RepVGG-A0] (main.py 282): INFO Train: [21/300][20/78]	eta 0:02:21 lr 6.321048	time 1.1916 (2.4330)	loss 3.8289 (3.7301)	grad_norm 0.3869 (0.3783)	mem 39782MB
[2023-07-07 07:54:27 RepVGG-A0] (main.py 282): INFO Train: [21/300][30/78]	eta 0:01:42 lr 6.320097	time 1.1272 (2.1389)	loss 3.6300 (3.7250)	grad_norm 0.3176 (0.3678)	mem 39782MB
[2023-07-07 07:54:44 RepVGG-A0] (main.py 282): INFO Train: [21/300][40/78]	eta 0:01:17 lr 6.319140	time 3.0256 (2.0432)	loss 3.7609 (3.7068)	grad_norm 0.4025 (0.3611)	mem 39782MB
[2023-07-07 07:54:59 RepVGG-A0] (main.py 282): INFO Train: [21/300][50/78]	eta 0:00:54 lr 6.318177	time 1.1727 (1.9407)	loss 3.6540 (3.7038)	grad_norm 0.3152 (0.3574)	mem 39782MB
[2023-07-07 07:55:15 RepVGG-A0] (main.py 282): INFO Train: [21/300][60/78]	eta 0:00:33 lr 6.317209	time 1.1862 (1.8721)	loss 3.6826 (3.7009)	grad_norm 0.3534 (0.3590)	mem 39782MB
[2023-07-07 07:55:30 RepVGG-A0] (main.py 282): INFO Train: [21/300][70/78]	eta 0:00:14 lr 6.316236	time 1.4062 (1.8231)	loss 3.7938 (3.7071)	grad_norm 0.4265 (0.3649)	mem 39782MB
[2023-07-07 07:55:42 RepVGG-A0] (main.py 291): INFO EPOCH 21 training takes 0:02:21
[2023-07-07 07:56:03 RepVGG-A0] (main.py 282): INFO Train: [22/300][0/78]	eta 0:27:58 lr 6.315452	time 21.5168 (21.5168)	loss 4.4788 (4.4788)	grad_norm 0.5225 (0.5225)	mem 39782MB
[2023-07-07 07:56:18 RepVGG-A0] (main.py 282): INFO Train: [22/300][10/78]	eta 0:03:43 lr 6.314469	time 1.1965 (3.2810)	loss 3.8314 (4.1125)	grad_norm 0.3035 (0.3728)	mem 39782MB
[2023-07-07 07:56:32 RepVGG-A0] (main.py 282): INFO Train: [22/300][20/78]	eta 0:02:19 lr 6.313479	time 1.1747 (2.4019)	loss 3.6260 (3.9265)	grad_norm 0.2631 (0.3263)	mem 39782MB
[2023-07-07 07:56:48 RepVGG-A0] (main.py 282): INFO Train: [22/300][30/78]	eta 0:01:43 lr 6.312484	time 1.2020 (2.1487)	loss 3.6527 (3.8256)	grad_norm 0.3040 (0.3154)	mem 39782MB
[2023-07-07 07:57:06 RepVGG-A0] (main.py 282): INFO Train: [22/300][40/78]	eta 0:01:17 lr 6.311483	time 3.7677 (2.0502)	loss 3.6175 (3.7774)	grad_norm 0.3168 (0.3164)	mem 39782MB
[2023-07-07 07:57:20 RepVGG-A0] (main.py 282): INFO Train: [22/300][50/78]	eta 0:00:54 lr 6.310477	time 1.3185 (1.9376)	loss 3.7253 (3.7592)	grad_norm 0.3499 (0.3246)	mem 39782MB
[2023-07-07 07:57:35 RepVGG-A0] (main.py 282): INFO Train: [22/300][60/78]	eta 0:00:33 lr 6.309465	time 1.1522 (1.8630)	loss 3.6267 (3.7363)	grad_norm 0.3477 (0.3247)	mem 39782MB
[2023-07-07 07:57:50 RepVGG-A0] (main.py 282): INFO Train: [22/300][70/78]	eta 0:00:14 lr 6.308448	time 1.1699 (1.8151)	loss 3.6759 (3.7253)	grad_norm 0.3597 (0.3286)	mem 39782MB
[2023-07-07 07:58:03 RepVGG-A0] (main.py 291): INFO EPOCH 22 training takes 0:02:21
[2023-07-07 07:58:24 RepVGG-A0] (main.py 282): INFO Train: [23/300][0/78]	eta 0:27:24 lr 6.307630	time 21.0810 (21.0810)	loss 3.5150 (3.5150)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 07:58:39 RepVGG-A0] (main.py 282): INFO Train: [23/300][10/78]	eta 0:03:41 lr 6.306602	time 1.1718 (3.2533)	loss 3.5688 (3.6209)	grad_norm 0.3604 (0.3686)	mem 39782MB
[2023-07-07 07:58:54 RepVGG-A0] (main.py 282): INFO Train: [23/300][20/78]	eta 0:02:22 lr 6.305569	time 1.3803 (2.4501)	loss 3.5684 (3.6089)	grad_norm 0.3414 (0.3583)	mem 39782MB
[2023-07-07 07:59:09 RepVGG-A0] (main.py 282): INFO Train: [23/300][30/78]	eta 0:01:42 lr 6.304530	time 1.2736 (2.1369)	loss 3.5149 (3.6097)	grad_norm 0.3500 (0.3585)	mem 39782MB
[2023-07-07 07:59:27 RepVGG-A0] (main.py 282): INFO Train: [23/300][40/78]	eta 0:01:18 lr 6.303486	time 3.0461 (2.0540)	loss 3.6036 (3.6093)	grad_norm 0.3400 (0.3606)	mem 39782MB
[2023-07-07 07:59:42 RepVGG-A0] (main.py 282): INFO Train: [23/300][50/78]	eta 0:00:54 lr 6.302436	time 1.1947 (1.9453)	loss 3.6110 (3.6045)	grad_norm 0.3568 (0.3566)	mem 39782MB
[2023-07-07 07:59:57 RepVGG-A0] (main.py 282): INFO Train: [23/300][60/78]	eta 0:00:33 lr 6.301380	time 1.2039 (1.8781)	loss 3.7174 (3.6123)	grad_norm 0.3734 (0.3597)	mem 39782MB
[2023-07-07 08:00:13 RepVGG-A0] (main.py 282): INFO Train: [23/300][70/78]	eta 0:00:14 lr 6.300319	time 1.6855 (1.8324)	loss 3.6981 (3.6093)	grad_norm 0.3992 (0.3592)	mem 39782MB
[2023-07-07 08:00:24 RepVGG-A0] (main.py 291): INFO EPOCH 23 training takes 0:02:20
[2023-07-07 08:00:46 RepVGG-A0] (main.py 282): INFO Train: [24/300][0/78]	eta 0:28:26 lr 6.299466	time 21.8786 (21.8786)	loss 3.5790 (3.5790)	grad_norm 0.3645 (0.3645)	mem 39782MB
[2023-07-07 08:00:59 RepVGG-A0] (main.py 282): INFO Train: [24/300][10/78]	eta 0:03:40 lr 6.298395	time 1.1722 (3.2402)	loss 3.4900 (3.5220)	grad_norm 0.3359 (0.3254)	mem 39782MB
[2023-07-07 08:01:14 RepVGG-A0] (main.py 282): INFO Train: [24/300][20/78]	eta 0:02:18 lr 6.297318	time 1.1720 (2.3925)	loss 4.4562 (3.6584)	grad_norm 0.7927 (0.4109)	mem 39782MB
[2023-07-07 08:01:29 RepVGG-A0] (main.py 282): INFO Train: [24/300][30/78]	eta 0:01:41 lr 6.296236	time 1.5026 (2.1112)	loss 5.6288 (4.3546)	grad_norm 0.3807 (0.4860)	mem 39782MB
[2023-07-07 08:01:47 RepVGG-A0] (main.py 282): INFO Train: [24/300][40/78]	eta 0:01:16 lr 6.295148	time 3.2334 (2.0256)	loss 4.7693 (4.5630)	grad_norm 0.2415 (0.4467)	mem 39782MB
[2023-07-07 08:02:02 RepVGG-A0] (main.py 282): INFO Train: [24/300][50/78]	eta 0:00:53 lr 6.294054	time 1.1893 (1.9178)	loss 4.3824 (4.5739)	grad_norm 0.2658 (0.4163)	mem 39782MB
[2023-07-07 08:02:17 RepVGG-A0] (main.py 282): INFO Train: [24/300][60/78]	eta 0:00:33 lr 6.292955	time 1.1799 (1.8498)	loss 4.2792 (4.5385)	grad_norm 0.3431 (0.3977)	mem 39782MB
[2023-07-07 08:02:32 RepVGG-A0] (main.py 282): INFO Train: [24/300][70/78]	eta 0:00:14 lr 6.291850	time 1.1703 (1.8007)	loss 4.2536 (4.4847)	grad_norm 0.4236 (0.3862)	mem 39782MB
[2023-07-07 08:02:44 RepVGG-A0] (main.py 291): INFO EPOCH 24 training takes 0:02:19
[2023-07-07 08:03:04 RepVGG-A0] (main.py 282): INFO Train: [25/300][0/78]	eta 0:26:27 lr 6.290963	time 20.3563 (20.3563)	loss 4.0296 (4.0296)	grad_norm 0.2841 (0.2841)	mem 39782MB
[2023-07-07 08:03:21 RepVGG-A0] (main.py 282): INFO Train: [25/300][10/78]	eta 0:03:49 lr 6.289848	time 1.1717 (3.3709)	loss 3.9761 (3.9732)	grad_norm 0.3544 (0.3094)	mem 39782MB
[2023-07-07 08:03:35 RepVGG-A0] (main.py 282): INFO Train: [25/300][20/78]	eta 0:02:21 lr 6.288728	time 1.1851 (2.4370)	loss 3.8577 (3.9414)	grad_norm 0.2953 (0.3101)	mem 39782MB
[2023-07-07 08:03:50 RepVGG-A0] (main.py 282): INFO Train: [25/300][30/78]	eta 0:01:42 lr 6.287602	time 1.5717 (2.1407)	loss 3.8545 (3.9082)	grad_norm 0.3473 (0.3172)	mem 39782MB
[2023-07-07 08:04:07 RepVGG-A0] (main.py 282): INFO Train: [25/300][40/78]	eta 0:01:17 lr 6.286470	time 4.0545 (2.0386)	loss 3.9223 (3.9112)	grad_norm 0.3601 (0.3316)	mem 39782MB
[2023-07-07 08:04:23 RepVGG-A0] (main.py 282): INFO Train: [25/300][50/78]	eta 0:00:54 lr 6.285333	time 1.2764 (1.9408)	loss 3.8391 (3.8919)	grad_norm 0.3959 (0.3312)	mem 39782MB
[2023-07-07 08:04:38 RepVGG-A0] (main.py 282): INFO Train: [25/300][60/78]	eta 0:00:33 lr 6.284191	time 1.1721 (1.8731)	loss 3.7237 (3.8759)	grad_norm 0.3242 (0.3322)	mem 39782MB
[2023-07-07 08:04:54 RepVGG-A0] (main.py 282): INFO Train: [25/300][70/78]	eta 0:00:14 lr 6.283043	time 1.2761 (1.8299)	loss 4.0373 (3.8636)	grad_norm 0.4574 (0.3368)	mem 39782MB
[2023-07-07 08:05:06 RepVGG-A0] (main.py 291): INFO EPOCH 25 training takes 0:02:21
[2023-07-07 08:05:27 RepVGG-A0] (main.py 282): INFO Train: [26/300][0/78]	eta 0:27:33 lr 6.282120	time 21.1935 (21.1935)	loss 3.6592 (3.6592)	grad_norm 0.3104 (0.3104)	mem 39782MB
[2023-07-07 08:05:42 RepVGG-A0] (main.py 282): INFO Train: [26/300][10/78]	eta 0:03:44 lr 6.280962	time 1.1720 (3.3039)	loss 4.3273 (3.8098)	grad_norm 0.7122 (0.4144)	mem 39782MB
[2023-07-07 08:05:56 RepVGG-A0] (main.py 282): INFO Train: [26/300][20/78]	eta 0:02:19 lr 6.279798	time 1.2864 (2.4018)	loss 4.7328 (4.3956)	grad_norm 0.3648 (0.5107)	mem 39782MB
[2023-07-07 08:06:11 RepVGG-A0] (main.py 282): INFO Train: [26/300][30/78]	eta 0:01:41 lr 6.278629	time 1.2046 (2.1179)	loss 4.2740 (4.3839)	grad_norm 0.3739 (0.4444)	mem 39782MB
[2023-07-07 08:06:30 RepVGG-A0] (main.py 282): INFO Train: [26/300][40/78]	eta 0:01:18 lr 6.277454	time 4.0975 (2.0540)	loss 3.9055 (4.3127)	grad_norm 0.2316 (0.4091)	mem 39782MB
[2023-07-07 08:06:45 RepVGG-A0] (main.py 282): INFO Train: [26/300][50/78]	eta 0:00:54 lr 6.276274	time 1.1745 (1.9412)	loss 3.7646 (4.2289)	grad_norm 0.2624 (0.3826)	mem 39782MB
[2023-07-07 08:07:00 RepVGG-A0] (main.py 282): INFO Train: [26/300][60/78]	eta 0:00:33 lr 6.275088	time 1.1811 (1.8741)	loss 3.7667 (4.1516)	grad_norm 0.3173 (0.3659)	mem 39782MB
[2023-07-07 08:07:14 RepVGG-A0] (main.py 282): INFO Train: [26/300][70/78]	eta 0:00:14 lr 6.273897	time 1.1714 (1.8128)	loss 3.6978 (4.0913)	grad_norm 0.3091 (0.3571)	mem 39782MB
[2023-07-07 08:07:26 RepVGG-A0] (main.py 291): INFO EPOCH 26 training takes 0:02:20
[2023-07-07 08:07:48 RepVGG-A0] (main.py 282): INFO Train: [27/300][0/78]	eta 0:27:54 lr 6.272940	time 21.4731 (21.4731)	loss 3.6591 (3.6591)	grad_norm 0.3342 (0.3342)	mem 39782MB
[2023-07-07 08:08:03 RepVGG-A0] (main.py 282): INFO Train: [27/300][10/78]	eta 0:03:44 lr 6.271738	time 1.1698 (3.2981)	loss 3.8514 (3.7267)	grad_norm 0.3630 (0.3613)	mem 39782MB
[2023-07-07 08:08:17 RepVGG-A0] (main.py 282): INFO Train: [27/300][20/78]	eta 0:02:20 lr 6.270532	time 1.1769 (2.4306)	loss 3.7827 (3.7287)	grad_norm 0.3418 (0.3543)	mem 39782MB
[2023-07-07 08:08:32 RepVGG-A0] (main.py 282): INFO Train: [27/300][30/78]	eta 0:01:42 lr 6.269319	time 1.4501 (2.1270)	loss 3.6638 (3.7062)	grad_norm 0.3159 (0.3384)	mem 39782MB
[2023-07-07 08:08:50 RepVGG-A0] (main.py 282): INFO Train: [27/300][40/78]	eta 0:01:17 lr 6.268101	time 3.0176 (2.0464)	loss 4.0496 (3.7199)	grad_norm 0.5404 (0.3534)	mem 39782MB
[2023-07-07 08:09:05 RepVGG-A0] (main.py 282): INFO Train: [27/300][50/78]	eta 0:00:54 lr 6.266878	time 1.1718 (1.9343)	loss 3.9691 (3.8198)	grad_norm 0.3163 (0.3780)	mem 39782MB
[2023-07-07 08:09:20 RepVGG-A0] (main.py 282): INFO Train: [27/300][60/78]	eta 0:00:33 lr 6.265649	time 1.1767 (1.8615)	loss 3.7310 (3.8125)	grad_norm 0.2731 (0.3623)	mem 39782MB
[2023-07-07 08:09:35 RepVGG-A0] (main.py 282): INFO Train: [27/300][70/78]	eta 0:00:14 lr 6.264414	time 1.1717 (1.8128)	loss 3.7350 (3.7920)	grad_norm 0.3163 (0.3513)	mem 39782MB
[2023-07-07 08:09:47 RepVGG-A0] (main.py 291): INFO EPOCH 27 training takes 0:02:20
[2023-07-07 08:10:09 RepVGG-A0] (main.py 282): INFO Train: [28/300][0/78]	eta 0:28:17 lr 6.263422	time 21.7568 (21.7568)	loss 3.6492 (3.6492)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 08:10:24 RepVGG-A0] (main.py 282): INFO Train: [28/300][10/78]	eta 0:03:48 lr 6.262178	time 1.1716 (3.3632)	loss 3.5335 (3.5566)	grad_norm 0.3147 (0.2939)	mem 39782MB
[2023-07-07 08:10:38 RepVGG-A0] (main.py 282): INFO Train: [28/300][20/78]	eta 0:02:21 lr 6.260928	time 1.1752 (2.4378)	loss 3.5702 (3.5753)	grad_norm 0.3378 (0.3093)	mem 39782MB
[2023-07-07 08:10:53 RepVGG-A0] (main.py 282): INFO Train: [28/300][30/78]	eta 0:01:41 lr 6.259672	time 1.1679 (2.1217)	loss 3.7941 (3.6151)	grad_norm 0.3801 (0.3378)	mem 39782MB
[2023-07-07 08:11:11 RepVGG-A0] (main.py 282): INFO Train: [28/300][40/78]	eta 0:01:17 lr 6.258411	time 3.0754 (2.0439)	loss 3.5739 (3.6218)	grad_norm 0.3011 (0.3368)	mem 39782MB
[2023-07-07 08:11:26 RepVGG-A0] (main.py 282): INFO Train: [28/300][50/78]	eta 0:00:54 lr 6.257145	time 1.1711 (1.9394)	loss 3.6794 (3.6222)	grad_norm 0.3926 (0.3398)	mem 39782MB
[2023-07-07 08:11:41 RepVGG-A0] (main.py 282): INFO Train: [28/300][60/78]	eta 0:00:33 lr 6.255873	time 1.2762 (1.8638)	loss 3.5973 (3.6328)	grad_norm 0.3168 (0.3440)	mem 39782MB
[2023-07-07 08:11:56 RepVGG-A0] (main.py 282): INFO Train: [28/300][70/78]	eta 0:00:14 lr 6.254595	time 1.1962 (1.8182)	loss 3.6057 (3.6256)	grad_norm 0.3334 (0.3408)	mem 39782MB
[2023-07-07 08:12:09 RepVGG-A0] (main.py 291): INFO EPOCH 28 training takes 0:02:21
[2023-07-07 08:12:31 RepVGG-A0] (main.py 282): INFO Train: [29/300][0/78]	eta 0:28:40 lr 6.253569	time 22.0603 (22.0603)	loss 3.6606 (3.6606)	grad_norm 0.3577 (0.3577)	mem 39782MB
[2023-07-07 08:12:45 RepVGG-A0] (main.py 282): INFO Train: [29/300][10/78]	eta 0:03:45 lr 6.252282	time 1.1715 (3.3178)	loss 6.1339 (4.6550)	grad_norm 0.7011 (0.6846)	mem 39782MB
[2023-07-07 08:13:00 RepVGG-A0] (main.py 282): INFO Train: [29/300][20/78]	eta 0:02:20 lr 6.250989	time 1.4187 (2.4285)	loss 4.9898 (5.0697)	grad_norm 0.3091 (0.5526)	mem 39782MB
[2023-07-07 08:13:15 RepVGG-A0] (main.py 282): INFO Train: [29/300][30/78]	eta 0:01:41 lr 6.249690	time 1.2505 (2.1177)	loss 4.5239 (4.9469)	grad_norm 0.3007 (0.4655)	mem 39782MB
[2023-07-07 08:13:33 RepVGG-A0] (main.py 282): INFO Train: [29/300][40/78]	eta 0:01:18 lr 6.248386	time 4.6230 (2.0555)	loss 4.1756 (4.7941)	grad_norm 0.2924 (0.4179)	mem 39782MB
[2023-07-07 08:13:48 RepVGG-A0] (main.py 282): INFO Train: [29/300][50/78]	eta 0:00:54 lr 6.247077	time 1.1745 (1.9463)	loss 4.1115 (4.6626)	grad_norm 0.3205 (0.3931)	mem 39782MB
[2023-07-07 08:14:04 RepVGG-A0] (main.py 282): INFO Train: [29/300][60/78]	eta 0:00:33 lr 6.245762	time 1.2821 (1.8841)	loss 3.9576 (4.5596)	grad_norm 0.3041 (0.3779)	mem 39782MB
[2023-07-07 08:14:18 RepVGG-A0] (main.py 282): INFO Train: [29/300][70/78]	eta 0:00:14 lr 6.244441	time 1.2729 (1.8195)	loss 3.9350 (4.4766)	grad_norm 0.2823 (0.3697)	mem 39782MB
[2023-07-07 08:14:31 RepVGG-A0] (main.py 291): INFO EPOCH 29 training takes 0:02:21
[2023-07-07 08:14:51 RepVGG-A0] (main.py 282): INFO Train: [30/300][0/78]	eta 0:27:09 lr 6.243381	time 20.8964 (20.8964)	loss 3.8879 (3.8879)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 08:15:06 RepVGG-A0] (main.py 282): INFO Train: [30/300][10/78]	eta 0:03:38 lr 6.242051	time 1.1705 (3.2176)	loss 3.8635 (3.8374)	grad_norm 0.3725 (0.3390)	mem 39782MB
[2023-07-07 08:15:20 RepVGG-A0] (main.py 282): INFO Train: [30/300][20/78]	eta 0:02:17 lr 6.240715	time 1.1912 (2.3774)	loss 3.7835 (3.8324)	grad_norm 0.3284 (0.3372)	mem 39782MB
[2023-07-07 08:15:35 RepVGG-A0] (main.py 282): INFO Train: [30/300][30/78]	eta 0:01:39 lr 6.239373	time 1.3242 (2.0716)	loss 3.7569 (3.8149)	grad_norm 0.3047 (0.3383)	mem 39782MB
[2023-07-07 08:15:53 RepVGG-A0] (main.py 282): INFO Train: [30/300][40/78]	eta 0:01:16 lr 6.238027	time 5.3745 (2.0212)	loss 3.8945 (3.8062)	grad_norm 0.3972 (0.3407)	mem 39782MB
[2023-07-07 08:16:08 RepVGG-A0] (main.py 282): INFO Train: [30/300][50/78]	eta 0:00:53 lr 6.236674	time 1.1723 (1.9158)	loss 3.7392 (3.7952)	grad_norm 0.3080 (0.3382)	mem 39782MB
[2023-07-07 08:16:24 RepVGG-A0] (main.py 282): INFO Train: [30/300][60/78]	eta 0:00:33 lr 6.235317	time 1.1804 (1.8630)	loss 3.7141 (3.7939)	grad_norm 0.3292 (0.3433)	mem 39782MB
[2023-07-07 08:16:38 RepVGG-A0] (main.py 282): INFO Train: [30/300][70/78]	eta 0:00:14 lr 6.233953	time 1.3702 (1.8013)	loss 4.0435 (3.7859)	grad_norm 0.4951 (0.3462)	mem 39782MB
[2023-07-07 08:16:50 RepVGG-A0] (main.py 291): INFO EPOCH 30 training takes 0:02:19
[2023-07-07 08:17:12 RepVGG-A0] (main.py 282): INFO Train: [31/300][0/78]	eta 0:28:26 lr 6.232859	time 21.8841 (21.8841)	loss 5.3415 (5.3415)	grad_norm 0.5897 (0.5897)	mem 39782MB
[2023-07-07 08:17:27 RepVGG-A0] (main.py 282): INFO Train: [31/300][10/78]	eta 0:03:50 lr 6.231486	time 1.1728 (3.3842)	loss 4.2598 (4.6422)	grad_norm 0.2788 (0.3600)	mem 39782MB
[2023-07-07 08:17:42 RepVGG-A0] (main.py 282): INFO Train: [31/300][20/78]	eta 0:02:23 lr 6.230107	time 1.3029 (2.4667)	loss 4.0993 (4.3954)	grad_norm 0.3201 (0.3397)	mem 39782MB
[2023-07-07 08:17:57 RepVGG-A0] (main.py 282): INFO Train: [31/300][30/78]	eta 0:01:44 lr 6.228723	time 1.2290 (2.1710)	loss 3.8273 (4.2133)	grad_norm 0.2599 (0.3074)	mem 39782MB
[2023-07-07 08:18:15 RepVGG-A0] (main.py 282): INFO Train: [31/300][40/78]	eta 0:01:18 lr 6.227334	time 3.1912 (2.0729)	loss 3.7464 (4.1024)	grad_norm 0.3200 (0.2997)	mem 39782MB
[2023-07-07 08:18:30 RepVGG-A0] (main.py 282): INFO Train: [31/300][50/78]	eta 0:00:54 lr 6.225939	time 1.1708 (1.9590)	loss 3.7269 (4.0375)	grad_norm 0.3230 (0.3059)	mem 39782MB
[2023-07-07 08:18:45 RepVGG-A0] (main.py 282): INFO Train: [31/300][60/78]	eta 0:00:33 lr 6.224539	time 1.2796 (1.8845)	loss 3.8077 (3.9856)	grad_norm 0.3415 (0.3073)	mem 39782MB
[2023-07-07 08:19:00 RepVGG-A0] (main.py 282): INFO Train: [31/300][70/78]	eta 0:00:14 lr 6.223133	time 1.2245 (1.8345)	loss 3.6423 (3.9404)	grad_norm 0.3307 (0.3094)	mem 39782MB
[2023-07-07 08:19:12 RepVGG-A0] (main.py 291): INFO EPOCH 31 training takes 0:02:21
[2023-07-07 08:19:32 RepVGG-A0] (main.py 282): INFO Train: [32/300][0/78]	eta 0:26:39 lr 6.222004	time 20.5040 (20.5040)	loss 3.5864 (3.5864)	grad_norm 0.3058 (0.3058)	mem 39782MB
[2023-07-07 08:19:46 RepVGG-A0] (main.py 282): INFO Train: [32/300][10/78]	eta 0:03:32 lr 6.220589	time 1.1719 (3.1274)	loss 3.7947 (3.7188)	grad_norm 0.3673 (0.3759)	mem 39782MB
[2023-07-07 08:20:02 RepVGG-A0] (main.py 282): INFO Train: [32/300][20/78]	eta 0:02:18 lr 6.219168	time 1.2992 (2.3879)	loss 3.5454 (3.6881)	grad_norm 0.2875 (0.3475)	mem 39782MB
[2023-07-07 08:20:17 RepVGG-A0] (main.py 282): INFO Train: [32/300][30/78]	eta 0:01:41 lr 6.217741	time 1.1877 (2.1135)	loss 3.5797 (3.6663)	grad_norm 0.3112 (0.3431)	mem 39782MB
[2023-07-07 08:20:35 RepVGG-A0] (main.py 282): INFO Train: [32/300][40/78]	eta 0:01:17 lr 6.216309	time 4.7973 (2.0399)	loss 3.7025 (3.6623)	grad_norm 0.4289 (0.3510)	mem 39782MB
[2023-07-07 08:20:50 RepVGG-A0] (main.py 282): INFO Train: [32/300][50/78]	eta 0:00:54 lr 6.214872	time 1.1743 (1.9333)	loss 3.7118 (3.6652)	grad_norm 0.4604 (0.3518)	mem 39782MB
[2023-07-07 08:21:05 RepVGG-A0] (main.py 282): INFO Train: [32/300][60/78]	eta 0:00:33 lr 6.213429	time 1.3372 (1.8640)	loss 3.6311 (3.6786)	grad_norm 0.3088 (0.3563)	mem 39782MB
[2023-07-07 08:21:20 RepVGG-A0] (main.py 282): INFO Train: [32/300][70/78]	eta 0:00:14 lr 6.211981	time 1.3075 (1.8122)	loss 3.6079 (3.6613)	grad_norm 0.3149 (0.3469)	mem 39782MB
[2023-07-07 08:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 32 training takes 0:02:20
[2023-07-07 08:21:54 RepVGG-A0] (main.py 282): INFO Train: [33/300][0/78]	eta 0:27:56 lr 6.210818	time 21.4981 (21.4981)	loss 4.0035 (4.0035)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 08:22:09 RepVGG-A0] (main.py 282): INFO Train: [33/300][10/78]	eta 0:03:45 lr 6.209360	time 1.1728 (3.3118)	loss 5.5112 (4.9015)	grad_norm 0.5298 (0.7022)	mem 39782MB
[2023-07-07 08:22:24 RepVGG-A0] (main.py 282): INFO Train: [33/300][20/78]	eta 0:02:21 lr 6.207897	time 1.1784 (2.4409)	loss 4.4151 (4.8414)	grad_norm 0.2923 (0.5366)	mem 39782MB
[2023-07-07 08:22:39 RepVGG-A0] (main.py 282): INFO Train: [33/300][30/78]	eta 0:01:43 lr 6.206428	time 1.1840 (2.1512)	loss 3.9524 (4.6188)	grad_norm 0.2446 (0.4461)	mem 39782MB
[2023-07-07 08:22:57 RepVGG-A0] (main.py 282): INFO Train: [33/300][40/78]	eta 0:01:18 lr 6.204954	time 3.6854 (2.0630)	loss 4.0446 (4.4578)	grad_norm 0.3565 (0.4098)	mem 39782MB
[2023-07-07 08:23:12 RepVGG-A0] (main.py 282): INFO Train: [33/300][50/78]	eta 0:00:54 lr 6.203474	time 1.2400 (1.9546)	loss 3.7482 (4.3308)	grad_norm 0.2677 (0.3821)	mem 39782MB
[2023-07-07 08:23:27 RepVGG-A0] (main.py 282): INFO Train: [33/300][60/78]	eta 0:00:33 lr 6.201989	time 1.2992 (1.8780)	loss 3.6950 (4.2342)	grad_norm 0.3083 (0.3665)	mem 39782MB
[2023-07-07 08:23:42 RepVGG-A0] (main.py 282): INFO Train: [33/300][70/78]	eta 0:00:14 lr 6.200499	time 1.1252 (1.8297)	loss 3.6633 (4.1624)	grad_norm 0.3201 (0.3605)	mem 39782MB
[2023-07-07 08:23:54 RepVGG-A0] (main.py 291): INFO EPOCH 33 training takes 0:02:21
[2023-07-07 08:24:16 RepVGG-A0] (main.py 282): INFO Train: [34/300][0/78]	eta 0:29:19 lr 6.199302	time 22.5558 (22.5558)	loss 3.5657 (3.5657)	grad_norm 0.2979 (0.2979)	mem 39782MB
[2023-07-07 08:24:31 RepVGG-A0] (main.py 282): INFO Train: [34/300][10/78]	eta 0:03:49 lr 6.197802	time 1.1738 (3.3766)	loss 3.6331 (3.6385)	grad_norm 0.3314 (0.3289)	mem 39782MB
[2023-07-07 08:24:46 RepVGG-A0] (main.py 282): INFO Train: [34/300][20/78]	eta 0:02:23 lr 6.196296	time 1.2818 (2.4665)	loss 3.8492 (3.7128)	grad_norm 0.4196 (0.3657)	mem 39782MB
[2023-07-07 08:25:00 RepVGG-A0] (main.py 282): INFO Train: [34/300][30/78]	eta 0:01:43 lr 6.194785	time 1.1508 (2.1472)	loss 3.6298 (3.6928)	grad_norm 0.3606 (0.3504)	mem 39782MB
[2023-07-07 08:25:17 RepVGG-A0] (main.py 282): INFO Train: [34/300][40/78]	eta 0:01:17 lr 6.193269	time 3.4224 (2.0363)	loss 3.7635 (3.6861)	grad_norm 0.3824 (0.3458)	mem 39782MB
[2023-07-07 08:25:32 RepVGG-A0] (main.py 282): INFO Train: [34/300][50/78]	eta 0:00:54 lr 6.191747	time 1.1740 (1.9325)	loss 3.7060 (3.6750)	grad_norm 0.3597 (0.3452)	mem 39782MB
[2023-07-07 08:25:47 RepVGG-A0] (main.py 282): INFO Train: [34/300][60/78]	eta 0:00:33 lr 6.190220	time 1.3186 (1.8589)	loss 3.5983 (3.6670)	grad_norm 0.3250 (0.3445)	mem 39782MB
[2023-07-07 08:26:02 RepVGG-A0] (main.py 282): INFO Train: [34/300][70/78]	eta 0:00:14 lr 6.188687	time 1.1725 (1.8012)	loss 3.7800 (3.6615)	grad_norm 0.4421 (0.3453)	mem 39782MB
[2023-07-07 08:26:14 RepVGG-A0] (main.py 291): INFO EPOCH 34 training takes 0:02:20
[2023-07-07 08:26:35 RepVGG-A0] (main.py 282): INFO Train: [35/300][0/78]	eta 0:27:20 lr 6.187457	time 21.0299 (21.0299)	loss 3.5313 (3.5313)	grad_norm 0.3010 (0.3010)	mem 39782MB
[2023-07-07 08:26:51 RepVGG-A0] (main.py 282): INFO Train: [35/300][10/78]	eta 0:03:46 lr 6.185915	time 1.1719 (3.3346)	loss 3.6888 (3.5663)	grad_norm 0.4171 (0.3401)	mem 39782MB
[2023-07-07 08:27:05 RepVGG-A0] (main.py 282): INFO Train: [35/300][20/78]	eta 0:02:22 lr 6.184367	time 1.1928 (2.4495)	loss 3.6866 (3.6085)	grad_norm 0.3161 (0.3442)	mem 39782MB
[2023-07-07 08:27:20 RepVGG-A0] (main.py 282): INFO Train: [35/300][30/78]	eta 0:01:42 lr 6.182814	time 1.4446 (2.1392)	loss 3.5808 (3.5854)	grad_norm 0.3487 (0.3416)	mem 39782MB
[2023-07-07 08:27:39 RepVGG-A0] (main.py 282): INFO Train: [35/300][40/78]	eta 0:01:18 lr 6.181256	time 3.2791 (2.0606)	loss 3.5662 (3.5826)	grad_norm 0.3401 (0.3428)	mem 39782MB
[2023-07-07 08:27:53 RepVGG-A0] (main.py 282): INFO Train: [35/300][50/78]	eta 0:00:54 lr 6.179692	time 1.1834 (1.9497)	loss 3.4729 (3.5871)	grad_norm 0.2910 (0.3484)	mem 39782MB
[2023-07-07 08:28:10 RepVGG-A0] (main.py 282): INFO Train: [35/300][60/78]	eta 0:00:34 lr 6.178123	time 1.1717 (1.8993)	loss 3.6924 (3.5840)	grad_norm 0.4451 (0.3473)	mem 39782MB
[2023-07-07 08:28:24 RepVGG-A0] (main.py 282): INFO Train: [35/300][70/78]	eta 0:00:14 lr 6.176548	time 1.3243 (1.8235)	loss 5.9550 (3.8011)	grad_norm 0.6339 (0.4042)	mem 39782MB
[2023-07-07 08:28:36 RepVGG-A0] (main.py 291): INFO EPOCH 35 training takes 0:02:22
[2023-07-07 08:28:57 RepVGG-A0] (main.py 282): INFO Train: [36/300][0/78]	eta 0:27:35 lr 6.175285	time 21.2247 (21.2247)	loss 5.1155 (5.1155)	grad_norm 0.3020 (0.3020)	mem 39782MB
[2023-07-07 08:29:13 RepVGG-A0] (main.py 282): INFO Train: [36/300][10/78]	eta 0:03:49 lr 6.173701	time 1.1725 (3.3763)	loss 4.4627 (4.8242)	grad_norm 0.2546 (0.2981)	mem 39782MB
[2023-07-07 08:29:29 RepVGG-A0] (main.py 282): INFO Train: [36/300][20/78]	eta 0:02:25 lr 6.172111	time 1.1801 (2.5089)	loss 4.1515 (4.6023)	grad_norm 0.2571 (0.2900)	mem 39782MB
[2023-07-07 08:29:45 RepVGG-A0] (main.py 282): INFO Train: [36/300][30/78]	eta 0:01:45 lr 6.170516	time 1.3837 (2.2064)	loss 4.0561 (4.4780)	grad_norm 0.2667 (0.2970)	mem 39782MB
[2023-07-07 08:30:02 RepVGG-A0] (main.py 282): INFO Train: [36/300][40/78]	eta 0:01:19 lr 6.168916	time 3.0802 (2.0957)	loss 3.8535 (4.3575)	grad_norm 0.2985 (0.2937)	mem 39782MB
[2023-07-07 08:30:17 RepVGG-A0] (main.py 282): INFO Train: [36/300][50/78]	eta 0:00:55 lr 6.167310	time 1.1721 (1.9852)	loss 3.8398 (4.2677)	grad_norm 0.2791 (0.2976)	mem 39782MB
[2023-07-07 08:30:32 RepVGG-A0] (main.py 282): INFO Train: [36/300][60/78]	eta 0:00:34 lr 6.165699	time 1.1737 (1.8954)	loss 3.8277 (4.2021)	grad_norm 0.2899 (0.3001)	mem 39782MB
[2023-07-07 08:30:48 RepVGG-A0] (main.py 282): INFO Train: [36/300][70/78]	eta 0:00:14 lr 6.164083	time 1.7123 (1.8514)	loss 3.9071 (4.1546)	grad_norm 0.3755 (0.3072)	mem 39782MB
[2023-07-07 08:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 36 training takes 0:02:21
[2023-07-07 08:31:20 RepVGG-A0] (main.py 282): INFO Train: [37/300][0/78]	eta 0:27:45 lr 6.162786	time 21.3528 (21.3528)	loss 3.6772 (3.6772)	grad_norm 0.2641 (0.2641)	mem 39782MB
[2023-07-07 08:31:35 RepVGG-A0] (main.py 282): INFO Train: [37/300][10/78]	eta 0:03:49 lr 6.161160	time 1.1706 (3.3807)	loss 4.1548 (3.8525)	grad_norm 0.5285 (0.3896)	mem 39782MB
[2023-07-07 08:31:51 RepVGG-A0] (main.py 282): INFO Train: [37/300][20/78]	eta 0:02:24 lr 6.159529	time 1.2690 (2.4935)	loss 3.7108 (3.8546)	grad_norm 0.2866 (0.3609)	mem 39782MB
[2023-07-07 08:32:05 RepVGG-A0] (main.py 282): INFO Train: [37/300][30/78]	eta 0:01:44 lr 6.157892	time 1.2194 (2.1676)	loss 3.7011 (3.8084)	grad_norm 0.3098 (0.3445)	mem 39782MB
[2023-07-07 08:32:24 RepVGG-A0] (main.py 282): INFO Train: [37/300][40/78]	eta 0:01:19 lr 6.156250	time 3.6690 (2.0807)	loss 3.9676 (3.7974)	grad_norm 0.4558 (0.3483)	mem 39782MB
[2023-07-07 08:32:38 RepVGG-A0] (main.py 282): INFO Train: [37/300][50/78]	eta 0:00:54 lr 6.154603	time 1.1706 (1.9639)	loss 3.6538 (3.7789)	grad_norm 0.3601 (0.3421)	mem 39782MB
[2023-07-07 08:32:54 RepVGG-A0] (main.py 282): INFO Train: [37/300][60/78]	eta 0:00:34 lr 6.152950	time 1.1752 (1.8951)	loss 3.6295 (3.7718)	grad_norm 0.2920 (0.3431)	mem 39782MB
[2023-07-07 08:33:10 RepVGG-A0] (main.py 282): INFO Train: [37/300][70/78]	eta 0:00:14 lr 6.151292	time 1.6658 (1.8505)	loss 3.6344 (3.7494)	grad_norm 0.3624 (0.3397)	mem 39782MB
[2023-07-07 08:33:21 RepVGG-A0] (main.py 291): INFO EPOCH 37 training takes 0:02:22
[2023-07-07 08:33:41 RepVGG-A0] (main.py 282): INFO Train: [38/300][0/78]	eta 0:26:24 lr 6.149962	time 20.3168 (20.3168)	loss 4.0222 (4.0222)	grad_norm 0.4791 (0.4791)	mem 39782MB
[2023-07-07 08:33:55 RepVGG-A0] (main.py 282): INFO Train: [38/300][10/78]	eta 0:03:34 lr 6.148295	time 1.1951 (3.1573)	loss 3.6831 (3.8233)	grad_norm 0.3382 (0.3775)	mem 39782MB
[2023-07-07 08:34:11 RepVGG-A0] (main.py 282): INFO Train: [38/300][20/78]	eta 0:02:17 lr 6.146622	time 1.1702 (2.3789)	loss 3.6942 (3.8136)	grad_norm 0.3023 (0.3812)	mem 39782MB
[2023-07-07 08:34:27 RepVGG-A0] (main.py 282): INFO Train: [38/300][30/78]	eta 0:01:42 lr 6.144944	time 1.4607 (2.1325)	loss 3.5726 (3.7373)	grad_norm 0.3173 (0.3514)	mem 39782MB
[2023-07-07 08:34:44 RepVGG-A0] (main.py 282): INFO Train: [38/300][40/78]	eta 0:01:17 lr 6.143260	time 2.7887 (2.0447)	loss 3.7291 (3.7082)	grad_norm 0.4193 (0.3488)	mem 39782MB
[2023-07-07 08:35:00 RepVGG-A0] (main.py 282): INFO Train: [38/300][50/78]	eta 0:00:54 lr 6.141571	time 1.1734 (1.9408)	loss 3.5761 (3.7148)	grad_norm 0.2784 (0.3514)	mem 39782MB
[2023-07-07 08:35:14 RepVGG-A0] (main.py 282): INFO Train: [38/300][60/78]	eta 0:00:33 lr 6.139877	time 1.1284 (1.8582)	loss 3.7057 (3.6936)	grad_norm 0.4043 (0.3475)	mem 39782MB
[2023-07-07 08:35:29 RepVGG-A0] (main.py 282): INFO Train: [38/300][70/78]	eta 0:00:14 lr 6.138178	time 1.3005 (1.8027)	loss 3.5566 (3.6795)	grad_norm 0.3260 (0.3473)	mem 39782MB
[2023-07-07 08:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 38 training takes 0:02:19
[2023-07-07 08:36:00 RepVGG-A0] (main.py 282): INFO Train: [39/300][0/78]	eta 0:25:36 lr 6.136815	time 19.6997 (19.6997)	loss 3.4686 (3.4686)	grad_norm 0.3211 (0.3211)	mem 39782MB
[2023-07-07 08:36:16 RepVGG-A0] (main.py 282): INFO Train: [39/300][10/78]	eta 0:03:43 lr 6.135106	time 1.1714 (3.2803)	loss 3.9338 (3.6957)	grad_norm 0.5231 (0.4356)	mem 39782MB
[2023-07-07 08:36:32 RepVGG-A0] (main.py 282): INFO Train: [39/300][20/78]	eta 0:02:22 lr 6.133392	time 1.3738 (2.4529)	loss 3.6016 (3.7339)	grad_norm 0.2831 (0.4031)	mem 39782MB
[2023-07-07 08:36:47 RepVGG-A0] (main.py 282): INFO Train: [39/300][30/78]	eta 0:01:43 lr 6.131672	time 1.2305 (2.1520)	loss 3.5850 (3.6828)	grad_norm 0.3069 (0.3710)	mem 39782MB
[2023-07-07 08:37:05 RepVGG-A0] (main.py 282): INFO Train: [39/300][40/78]	eta 0:01:18 lr 6.129948	time 3.5968 (2.0651)	loss 3.7153 (3.6629)	grad_norm 0.3971 (0.3680)	mem 39782MB
[2023-07-07 08:37:20 RepVGG-A0] (main.py 282): INFO Train: [39/300][50/78]	eta 0:00:54 lr 6.128218	time 1.2059 (1.9588)	loss 3.4960 (3.6383)	grad_norm 0.3044 (0.3579)	mem 39782MB
[2023-07-07 08:37:36 RepVGG-A0] (main.py 282): INFO Train: [39/300][60/78]	eta 0:00:33 lr 6.126482	time 1.4470 (1.8888)	loss 3.6600 (3.6251)	grad_norm 0.4063 (0.3590)	mem 39782MB
[2023-07-07 08:37:50 RepVGG-A0] (main.py 282): INFO Train: [39/300][70/78]	eta 0:00:14 lr 6.124742	time 1.2405 (1.8273)	loss 5.9339 (3.7917)	grad_norm 0.7251 (0.4069)	mem 39782MB
[2023-07-07 08:38:02 RepVGG-A0] (main.py 291): INFO EPOCH 39 training takes 0:02:21
[2023-07-07 08:38:24 RepVGG-A0] (main.py 282): INFO Train: [40/300][0/78]	eta 0:28:12 lr 6.123345	time 21.7013 (21.7013)	loss 4.9651 (4.9651)	grad_norm 0.3385 (0.3385)	mem 39782MB
[2023-07-07 08:38:38 RepVGG-A0] (main.py 282): INFO Train: [40/300][10/78]	eta 0:03:44 lr 6.121595	time 1.1909 (3.2954)	loss 4.3794 (4.7393)	grad_norm 0.2171 (0.3292)	mem 39782MB
[2023-07-07 08:38:54 RepVGG-A0] (main.py 282): INFO Train: [40/300][20/78]	eta 0:02:22 lr 6.119840	time 1.2019 (2.4644)	loss 4.1435 (4.4812)	grad_norm 0.2960 (0.2941)	mem 39782MB
[2023-07-07 08:39:09 RepVGG-A0] (main.py 282): INFO Train: [40/300][30/78]	eta 0:01:43 lr 6.118080	time 1.2306 (2.1506)	loss 4.0575 (4.3404)	grad_norm 0.3498 (0.2936)	mem 39782MB
[2023-07-07 08:39:26 RepVGG-A0] (main.py 282): INFO Train: [40/300][40/78]	eta 0:01:18 lr 6.116314	time 4.4591 (2.0584)	loss 3.8298 (4.2346)	grad_norm 0.2709 (0.2886)	mem 39782MB
[2023-07-07 08:39:42 RepVGG-A0] (main.py 282): INFO Train: [40/300][50/78]	eta 0:00:54 lr 6.114543	time 1.1722 (1.9533)	loss 3.9065 (4.1605)	grad_norm 0.3507 (0.2931)	mem 39782MB
[2023-07-07 08:39:56 RepVGG-A0] (main.py 282): INFO Train: [40/300][60/78]	eta 0:00:33 lr 6.112766	time 1.2663 (1.8616)	loss 3.7789 (4.1080)	grad_norm 0.2797 (0.2978)	mem 39782MB
[2023-07-07 08:40:11 RepVGG-A0] (main.py 282): INFO Train: [40/300][70/78]	eta 0:00:14 lr 6.110985	time 1.1768 (1.8151)	loss 4.0070 (4.0639)	grad_norm 0.4053 (0.3037)	mem 39782MB
[2023-07-07 08:40:23 RepVGG-A0] (main.py 291): INFO EPOCH 40 training takes 0:02:20
[2023-07-07 08:40:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.987 (16.987)	Loss 3.4978 (3.4978)	Acc@1 30.176 (30.176)	Acc@5 54.333 (54.333)	Mem 39782MB
[2023-07-07 08:40:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 30.152 Acc@5 53.964
[2023-07-07 08:40:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 40: 30.152%
[2023-07-07 08:40:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 08:41:03 RepVGG-A0] (main.py 282): INFO Train: [41/300][0/78]	eta 0:28:11 lr 6.109556	time 21.6809 (21.6809)	loss 3.7263 (3.7263)	grad_norm 0.2828 (0.2828)	mem 39782MB
[2023-07-07 08:41:17 RepVGG-A0] (main.py 282): INFO Train: [41/300][10/78]	eta 0:03:43 lr 6.107765	time 1.1716 (3.2849)	loss 3.7377 (3.6945)	grad_norm 0.3373 (0.3208)	mem 39782MB
[2023-07-07 08:41:33 RepVGG-A0] (main.py 282): INFO Train: [41/300][20/78]	eta 0:02:23 lr 6.105968	time 1.1795 (2.4682)	loss 3.6207 (3.6804)	grad_norm 0.3243 (0.3212)	mem 39782MB
[2023-07-07 08:41:47 RepVGG-A0] (main.py 282): INFO Train: [41/300][30/78]	eta 0:01:42 lr 6.104167	time 1.3771 (2.1331)	loss 3.6981 (3.6996)	grad_norm 0.3527 (0.3398)	mem 39782MB
[2023-07-07 08:42:06 RepVGG-A0] (main.py 282): INFO Train: [41/300][40/78]	eta 0:01:18 lr 6.102360	time 4.5629 (2.0702)	loss 4.8030 (3.7959)	grad_norm 0.7509 (0.3882)	mem 39782MB
[2023-07-07 08:42:21 RepVGG-A0] (main.py 282): INFO Train: [41/300][50/78]	eta 0:00:54 lr 6.100548	time 1.1843 (1.9565)	loss 4.1469 (3.9449)	grad_norm 0.2980 (0.4007)	mem 39782MB
[2023-07-07 08:42:36 RepVGG-A0] (main.py 282): INFO Train: [41/300][60/78]	eta 0:00:33 lr 6.098731	time 1.4309 (1.8818)	loss 3.7557 (3.9418)	grad_norm 0.2564 (0.3769)	mem 39782MB
[2023-07-07 08:42:51 RepVGG-A0] (main.py 282): INFO Train: [41/300][70/78]	eta 0:00:14 lr 6.096908	time 1.1804 (1.8243)	loss 3.8276 (3.9255)	grad_norm 0.2968 (0.3665)	mem 39782MB
[2023-07-07 08:43:03 RepVGG-A0] (main.py 291): INFO EPOCH 41 training takes 0:02:21
[2023-07-07 08:43:23 RepVGG-A0] (main.py 282): INFO Train: [42/300][0/78]	eta 0:26:33 lr 6.095447	time 20.4317 (20.4317)	loss 3.5222 (3.5222)	grad_norm 0.2683 (0.2683)	mem 39782MB
[2023-07-07 08:43:39 RepVGG-A0] (main.py 282): INFO Train: [42/300][10/78]	eta 0:03:45 lr 6.093615	time 1.1708 (3.3109)	loss 3.5938 (3.6165)	grad_norm 0.3046 (0.3101)	mem 39782MB
[2023-07-07 08:43:54 RepVGG-A0] (main.py 282): INFO Train: [42/300][20/78]	eta 0:02:22 lr 6.091778	time 1.1811 (2.4532)	loss 3.6672 (3.6256)	grad_norm 0.3314 (0.3194)	mem 39782MB
[2023-07-07 08:44:10 RepVGG-A0] (main.py 282): INFO Train: [42/300][30/78]	eta 0:01:44 lr 6.089935	time 1.8420 (2.1671)	loss 3.6901 (3.6224)	grad_norm 0.3844 (0.3224)	mem 39782MB
[2023-07-07 08:44:27 RepVGG-A0] (main.py 282): INFO Train: [42/300][40/78]	eta 0:01:18 lr 6.088088	time 2.3505 (2.0633)	loss 3.6496 (3.6360)	grad_norm 0.3619 (0.3305)	mem 39782MB
[2023-07-07 08:44:43 RepVGG-A0] (main.py 282): INFO Train: [42/300][50/78]	eta 0:00:54 lr 6.086235	time 1.1754 (1.9584)	loss 3.6278 (3.6323)	grad_norm 0.3298 (0.3319)	mem 39782MB
[2023-07-07 08:44:58 RepVGG-A0] (main.py 282): INFO Train: [42/300][60/78]	eta 0:00:34 lr 6.084377	time 1.3556 (1.8956)	loss 3.5925 (3.6206)	grad_norm 0.3289 (0.3301)	mem 39782MB
[2023-07-07 08:45:13 RepVGG-A0] (main.py 282): INFO Train: [42/300][70/78]	eta 0:00:14 lr 6.082514	time 1.7445 (1.8377)	loss 5.4179 (3.7451)	grad_norm 0.6171 (0.3765)	mem 39782MB
[2023-07-07 08:45:25 RepVGG-A0] (main.py 291): INFO EPOCH 42 training takes 0:02:22
[2023-07-07 08:45:48 RepVGG-A0] (main.py 282): INFO Train: [43/300][0/78]	eta 0:30:03 lr 6.081020	time 23.1193 (23.1193)	loss 4.3454 (4.3454)	grad_norm 0.2995 (0.2995)	mem 39782MB
[2023-07-07 08:46:03 RepVGG-A0] (main.py 282): INFO Train: [43/300][10/78]	eta 0:03:55 lr 6.079148	time 1.1725 (3.4577)	loss 4.0929 (4.1962)	grad_norm 0.3257 (0.2908)	mem 39782MB
[2023-07-07 08:46:19 RepVGG-A0] (main.py 282): INFO Train: [43/300][20/78]	eta 0:02:30 lr 6.077270	time 1.1724 (2.5906)	loss 3.6846 (4.0496)	grad_norm 0.2543 (0.2742)	mem 39782MB
[2023-07-07 08:46:34 RepVGG-A0] (main.py 282): INFO Train: [43/300][30/78]	eta 0:01:46 lr 6.075387	time 1.1999 (2.2159)	loss 3.7557 (3.9763)	grad_norm 0.2847 (0.2890)	mem 39782MB
[2023-07-07 08:46:52 RepVGG-A0] (main.py 282): INFO Train: [43/300][40/78]	eta 0:01:20 lr 6.073499	time 4.2383 (2.1312)	loss 3.6860 (3.9003)	grad_norm 0.2838 (0.2848)	mem 39782MB
[2023-07-07 08:47:07 RepVGG-A0] (main.py 282): INFO Train: [43/300][50/78]	eta 0:00:55 lr 6.071606	time 1.1739 (1.9989)	loss 3.6744 (3.8530)	grad_norm 0.3253 (0.2884)	mem 39782MB
[2023-07-07 08:47:24 RepVGG-A0] (main.py 282): INFO Train: [43/300][60/78]	eta 0:00:35 lr 6.069708	time 1.3979 (1.9448)	loss 3.6649 (3.8222)	grad_norm 0.3038 (0.2949)	mem 39782MB
[2023-07-07 08:47:40 RepVGG-A0] (main.py 282): INFO Train: [43/300][70/78]	eta 0:00:15 lr 6.067804	time 1.3231 (1.8977)	loss 3.6247 (3.7949)	grad_norm 0.3611 (0.2987)	mem 39782MB
[2023-07-07 08:47:50 RepVGG-A0] (main.py 291): INFO EPOCH 43 training takes 0:02:24
[2023-07-07 08:48:14 RepVGG-A0] (main.py 282): INFO Train: [44/300][0/78]	eta 0:30:58 lr 6.066278	time 23.8290 (23.8290)	loss 3.5554 (3.5554)	grad_norm 0.2954 (0.2954)	mem 39782MB
[2023-07-07 08:48:29 RepVGG-A0] (main.py 282): INFO Train: [44/300][10/78]	eta 0:03:59 lr 6.064365	time 1.1992 (3.5238)	loss 3.7406 (3.6528)	grad_norm 0.4345 (0.3724)	mem 39782MB
[2023-07-07 08:48:42 RepVGG-A0] (main.py 282): INFO Train: [44/300][20/78]	eta 0:02:25 lr 6.062447	time 1.1732 (2.5089)	loss 3.5715 (3.6418)	grad_norm 0.2973 (0.3572)	mem 39782MB
[2023-07-07 08:48:59 RepVGG-A0] (main.py 282): INFO Train: [44/300][30/78]	eta 0:01:47 lr 6.060524	time 1.5014 (2.2337)	loss 3.6161 (3.6200)	grad_norm 0.3415 (0.3459)	mem 39782MB
[2023-07-07 08:49:17 RepVGG-A0] (main.py 282): INFO Train: [44/300][40/78]	eta 0:01:20 lr 6.058595	time 2.9496 (2.1244)	loss 3.5963 (3.6172)	grad_norm 0.3129 (0.3475)	mem 39782MB
[2023-07-07 08:49:32 RepVGG-A0] (main.py 282): INFO Train: [44/300][50/78]	eta 0:00:56 lr 6.056662	time 1.2784 (2.0126)	loss 3.5601 (3.5977)	grad_norm 0.3771 (0.3424)	mem 39782MB
[2023-07-07 08:49:47 RepVGG-A0] (main.py 282): INFO Train: [44/300][60/78]	eta 0:00:34 lr 6.054723	time 1.2797 (1.9274)	loss 6.1850 (3.8401)	grad_norm 0.5306 (0.4077)	mem 39782MB
[2023-07-07 08:50:02 RepVGG-A0] (main.py 282): INFO Train: [44/300][70/78]	eta 0:00:14 lr 6.052780	time 1.4137 (1.8628)	loss 5.0356 (4.0716)	grad_norm 0.2979 (0.4005)	mem 39782MB
[2023-07-07 08:50:14 RepVGG-A0] (main.py 291): INFO EPOCH 44 training takes 0:02:24
[2023-07-07 08:50:35 RepVGG-A0] (main.py 282): INFO Train: [45/300][0/78]	eta 0:26:37 lr 6.051221	time 20.4771 (20.4771)	loss 4.8765 (4.8765)	grad_norm 0.4593 (0.4593)	mem 39782MB
[2023-07-07 08:50:49 RepVGG-A0] (main.py 282): INFO Train: [45/300][10/78]	eta 0:03:37 lr 6.049268	time 1.1711 (3.2014)	loss 4.2030 (4.4704)	grad_norm 0.2622 (0.2962)	mem 39782MB
[2023-07-07 08:51:03 RepVGG-A0] (main.py 282): INFO Train: [45/300][20/78]	eta 0:02:16 lr 6.047310	time 1.1895 (2.3457)	loss 4.1864 (4.3427)	grad_norm 0.3535 (0.3022)	mem 39782MB
[2023-07-07 08:51:18 RepVGG-A0] (main.py 282): INFO Train: [45/300][30/78]	eta 0:01:39 lr 6.045346	time 1.3576 (2.0739)	loss 3.9650 (4.2339)	grad_norm 0.3194 (0.2951)	mem 39782MB
[2023-07-07 08:51:37 RepVGG-A0] (main.py 282): INFO Train: [45/300][40/78]	eta 0:01:16 lr 6.043378	time 4.4185 (2.0144)	loss 3.9083 (4.1640)	grad_norm 0.2758 (0.3002)	mem 39782MB
[2023-07-07 08:51:51 RepVGG-A0] (main.py 282): INFO Train: [45/300][50/78]	eta 0:00:53 lr 6.041405	time 1.1754 (1.9068)	loss 3.9110 (4.1102)	grad_norm 0.3430 (0.3055)	mem 39782MB
[2023-07-07 08:52:07 RepVGG-A0] (main.py 282): INFO Train: [45/300][60/78]	eta 0:00:33 lr 6.039426	time 1.2626 (1.8486)	loss 4.3197 (4.0821)	grad_norm 0.6054 (0.3205)	mem 39782MB
[2023-07-07 08:52:22 RepVGG-A0] (main.py 282): INFO Train: [45/300][70/78]	eta 0:00:14 lr 6.037442	time 1.2338 (1.8023)	loss 4.0018 (4.1148)	grad_norm 0.2760 (0.3360)	mem 39782MB
[2023-07-07 08:52:34 RepVGG-A0] (main.py 291): INFO EPOCH 45 training takes 0:02:19
[2023-07-07 08:52:55 RepVGG-A0] (main.py 282): INFO Train: [46/300][0/78]	eta 0:26:50 lr 6.035851	time 20.6510 (20.6510)	loss 3.7537 (3.7537)	grad_norm 0.2596 (0.2596)	mem 39782MB
[2023-07-07 08:53:10 RepVGG-A0] (main.py 282): INFO Train: [46/300][10/78]	eta 0:03:44 lr 6.033858	time 1.1729 (3.3087)	loss 3.7718 (3.7424)	grad_norm 0.3166 (0.2873)	mem 39782MB
[2023-07-07 08:53:26 RepVGG-A0] (main.py 282): INFO Train: [46/300][20/78]	eta 0:02:22 lr 6.031860	time 1.2247 (2.4581)	loss 3.6503 (3.7359)	grad_norm 0.2918 (0.3043)	mem 39782MB
[2023-07-07 08:53:42 RepVGG-A0] (main.py 282): INFO Train: [46/300][30/78]	eta 0:01:44 lr 6.029857	time 1.3382 (2.1858)	loss 3.7720 (3.7312)	grad_norm 0.3898 (0.3162)	mem 39782MB
[2023-07-07 08:54:00 RepVGG-A0] (main.py 282): INFO Train: [46/300][40/78]	eta 0:01:19 lr 6.027849	time 3.7371 (2.0856)	loss 3.7361 (3.7266)	grad_norm 0.3323 (0.3213)	mem 39782MB
[2023-07-07 08:54:14 RepVGG-A0] (main.py 282): INFO Train: [46/300][50/78]	eta 0:00:55 lr 6.025836	time 1.1515 (1.9644)	loss 3.6802 (3.7180)	grad_norm 0.3697 (0.3247)	mem 39782MB
[2023-07-07 08:54:29 RepVGG-A0] (main.py 282): INFO Train: [46/300][60/78]	eta 0:00:33 lr 6.023817	time 1.1280 (1.8803)	loss 3.7390 (3.7359)	grad_norm 0.3131 (0.3347)	mem 39782MB
[2023-07-07 08:54:45 RepVGG-A0] (main.py 282): INFO Train: [46/300][70/78]	eta 0:00:14 lr 6.021794	time 1.3337 (1.8412)	loss 3.9143 (3.7346)	grad_norm 0.4250 (0.3374)	mem 39782MB
[2023-07-07 08:54:56 RepVGG-A0] (main.py 291): INFO EPOCH 46 training takes 0:02:22
[2023-07-07 08:55:19 RepVGG-A0] (main.py 282): INFO Train: [47/300][0/78]	eta 0:28:53 lr 6.020171	time 22.2202 (22.2202)	loss 3.5599 (3.5599)	grad_norm 0.2796 (0.2796)	mem 39782MB
[2023-07-07 08:55:32 RepVGG-A0] (main.py 282): INFO Train: [47/300][10/78]	eta 0:03:39 lr 6.018138	time 1.1870 (3.2343)	loss 3.5607 (3.6071)	grad_norm 0.3517 (0.3406)	mem 39782MB
[2023-07-07 08:55:48 RepVGG-A0] (main.py 282): INFO Train: [47/300][20/78]	eta 0:02:22 lr 6.016101	time 1.1819 (2.4519)	loss 3.6714 (3.6204)	grad_norm 0.3655 (0.3468)	mem 39782MB
[2023-07-07 08:56:02 RepVGG-A0] (main.py 282): INFO Train: [47/300][30/78]	eta 0:01:41 lr 6.014058	time 1.3506 (2.1181)	loss 3.9948 (3.6435)	grad_norm 0.5037 (0.3573)	mem 39782MB
[2023-07-07 08:56:20 RepVGG-A0] (main.py 282): INFO Train: [47/300][40/78]	eta 0:01:17 lr 6.012010	time 3.8286 (2.0360)	loss 3.7238 (3.7296)	grad_norm 0.2925 (0.3810)	mem 39782MB
[2023-07-07 08:56:34 RepVGG-A0] (main.py 282): INFO Train: [47/300][50/78]	eta 0:00:53 lr 6.009957	time 1.1719 (1.9177)	loss 3.6638 (3.7079)	grad_norm 0.4113 (0.3637)	mem 39782MB
[2023-07-07 08:56:49 RepVGG-A0] (main.py 282): INFO Train: [47/300][60/78]	eta 0:00:33 lr 6.007899	time 1.1739 (1.8517)	loss 3.5057 (3.6979)	grad_norm 0.2575 (0.3587)	mem 39782MB
[2023-07-07 08:57:04 RepVGG-A0] (main.py 282): INFO Train: [47/300][70/78]	eta 0:00:14 lr 6.005836	time 1.3444 (1.8024)	loss 3.5947 (3.6817)	grad_norm 0.3760 (0.3543)	mem 39782MB
[2023-07-07 08:57:16 RepVGG-A0] (main.py 291): INFO EPOCH 47 training takes 0:02:20
[2023-07-07 08:57:37 RepVGG-A0] (main.py 282): INFO Train: [48/300][0/78]	eta 0:27:19 lr 6.004181	time 21.0165 (21.0165)	loss 3.4253 (3.4253)	grad_norm 0.3321 (0.3321)	mem 39782MB
[2023-07-07 08:57:52 RepVGG-A0] (main.py 282): INFO Train: [48/300][10/78]	eta 0:03:41 lr 6.002109	time 1.1718 (3.2521)	loss 3.6022 (3.5743)	grad_norm 0.3679 (0.3627)	mem 39782MB
[2023-07-07 08:58:07 RepVGG-A0] (main.py 282): INFO Train: [48/300][20/78]	eta 0:02:20 lr 6.000032	time 1.1747 (2.4229)	loss 3.4561 (3.5528)	grad_norm 0.3330 (0.3525)	mem 39782MB
[2023-07-07 08:58:23 RepVGG-A0] (main.py 282): INFO Train: [48/300][30/78]	eta 0:01:42 lr 5.997950	time 1.5951 (2.1308)	loss 3.5567 (3.5422)	grad_norm 0.3271 (0.3473)	mem 39782MB
[2023-07-07 08:58:41 RepVGG-A0] (main.py 282): INFO Train: [48/300][40/78]	eta 0:01:18 lr 5.995862	time 4.1600 (2.0700)	loss 6.1157 (3.6798)	grad_norm 1.0851 (0.4075)	mem 39782MB
[2023-07-07 08:58:55 RepVGG-A0] (main.py 282): INFO Train: [48/300][50/78]	eta 0:00:54 lr 5.993770	time 1.1721 (1.9382)	loss 5.3418 (4.1292)	grad_norm 0.3712 (0.4201)	mem 39782MB
[2023-07-07 08:59:11 RepVGG-A0] (main.py 282): INFO Train: [48/300][60/78]	eta 0:00:33 lr 5.991672	time 1.6034 (1.8801)	loss 4.6652 (4.2735)	grad_norm 0.2745 (0.4012)	mem 39782MB
[2023-07-07 08:59:26 RepVGG-A0] (main.py 282): INFO Train: [48/300][70/78]	eta 0:00:14 lr 5.989570	time 1.2262 (1.8225)	loss 4.3700 (4.3041)	grad_norm 0.2977 (0.3865)	mem 39782MB
[2023-07-07 08:59:37 RepVGG-A0] (main.py 291): INFO EPOCH 48 training takes 0:02:20
[2023-07-07 08:59:58 RepVGG-A0] (main.py 282): INFO Train: [49/300][0/78]	eta 0:27:25 lr 5.987884	time 21.0955 (21.0955)	loss 4.1039 (4.1039)	grad_norm 0.3038 (0.3038)	mem 39782MB
[2023-07-07 09:00:13 RepVGG-A0] (main.py 282): INFO Train: [49/300][10/78]	eta 0:03:41 lr 5.985773	time 1.1727 (3.2589)	loss 4.1297 (4.0756)	grad_norm 0.4388 (0.3053)	mem 39782MB
[2023-07-07 09:00:28 RepVGG-A0] (main.py 282): INFO Train: [49/300][20/78]	eta 0:02:21 lr 5.983656	time 1.2046 (2.4369)	loss 3.9236 (4.0961)	grad_norm 0.2403 (0.3206)	mem 39782MB
[2023-07-07 09:00:44 RepVGG-A0] (main.py 282): INFO Train: [49/300][30/78]	eta 0:01:43 lr 5.981535	time 1.1266 (2.1554)	loss 3.8361 (4.0219)	grad_norm 0.3422 (0.3050)	mem 39782MB
[2023-07-07 09:01:02 RepVGG-A0] (main.py 282): INFO Train: [49/300][40/78]	eta 0:01:19 lr 5.979408	time 2.7604 (2.0793)	loss 3.9196 (3.9747)	grad_norm 0.3663 (0.3073)	mem 39782MB
[2023-07-07 09:01:17 RepVGG-A0] (main.py 282): INFO Train: [49/300][50/78]	eta 0:00:54 lr 5.977276	time 1.2179 (1.9611)	loss 3.7544 (3.9398)	grad_norm 0.2899 (0.3088)	mem 39782MB
[2023-07-07 09:01:33 RepVGG-A0] (main.py 282): INFO Train: [49/300][60/78]	eta 0:00:34 lr 5.975140	time 1.2876 (1.8918)	loss 3.9424 (3.9166)	grad_norm 0.4693 (0.3180)	mem 39782MB
[2023-07-07 09:01:47 RepVGG-A0] (main.py 282): INFO Train: [49/300][70/78]	eta 0:00:14 lr 5.972998	time 1.1804 (1.8230)	loss 3.9759 (3.9560)	grad_norm 0.3394 (0.3382)	mem 39782MB
[2023-07-07 09:01:59 RepVGG-A0] (main.py 291): INFO EPOCH 49 training takes 0:02:21
[2023-07-07 09:02:20 RepVGG-A0] (main.py 282): INFO Train: [50/300][0/78]	eta 0:26:58 lr 5.971281	time 20.7527 (20.7527)	loss 3.8060 (3.8060)	grad_norm 0.2950 (0.2950)	mem 39782MB
[2023-07-07 09:02:35 RepVGG-A0] (main.py 282): INFO Train: [50/300][10/78]	eta 0:03:42 lr 5.969131	time 1.1920 (3.2758)	loss 3.6553 (3.7272)	grad_norm 0.2737 (0.2964)	mem 39782MB
[2023-07-07 09:02:50 RepVGG-A0] (main.py 282): INFO Train: [50/300][20/78]	eta 0:02:21 lr 5.966975	time 1.1941 (2.4356)	loss 3.8057 (3.7145)	grad_norm 0.3660 (0.3141)	mem 39782MB
[2023-07-07 09:03:06 RepVGG-A0] (main.py 282): INFO Train: [50/300][30/78]	eta 0:01:44 lr 5.964815	time 1.6417 (2.1679)	loss 3.7379 (3.7133)	grad_norm 0.3405 (0.3242)	mem 39782MB
[2023-07-07 09:03:23 RepVGG-A0] (main.py 282): INFO Train: [50/300][40/78]	eta 0:01:18 lr 5.962649	time 2.6989 (2.0547)	loss 3.6407 (3.6904)	grad_norm 0.3403 (0.3205)	mem 39782MB
[2023-07-07 09:03:37 RepVGG-A0] (main.py 282): INFO Train: [50/300][50/78]	eta 0:00:53 lr 5.960478	time 1.1916 (1.9223)	loss 3.7893 (3.7257)	grad_norm 0.3356 (0.3412)	mem 39782MB
[2023-07-07 09:03:53 RepVGG-A0] (main.py 282): INFO Train: [50/300][60/78]	eta 0:00:33 lr 5.958303	time 1.1977 (1.8680)	loss 3.6935 (3.7141)	grad_norm 0.3280 (0.3350)	mem 39782MB
[2023-07-07 09:04:07 RepVGG-A0] (main.py 282): INFO Train: [50/300][70/78]	eta 0:00:14 lr 5.956122	time 1.2141 (1.8058)	loss 3.6001 (3.7035)	grad_norm 0.3263 (0.3350)	mem 39782MB
[2023-07-07 09:04:19 RepVGG-A0] (main.py 291): INFO EPOCH 50 training takes 0:02:20
[2023-07-07 09:04:40 RepVGG-A0] (main.py 282): INFO Train: [51/300][0/78]	eta 0:26:52 lr 5.954374	time 20.6696 (20.6696)	loss 3.6716 (3.6716)	grad_norm 0.3777 (0.3777)	mem 39782MB
[2023-07-07 09:04:54 RepVGG-A0] (main.py 282): INFO Train: [51/300][10/78]	eta 0:03:37 lr 5.952185	time 1.1714 (3.1916)	loss 3.5887 (3.6586)	grad_norm 0.3116 (0.3741)	mem 39782MB
[2023-07-07 09:05:09 RepVGG-A0] (main.py 282): INFO Train: [51/300][20/78]	eta 0:02:18 lr 5.949991	time 1.1757 (2.3951)	loss 3.5670 (3.6214)	grad_norm 0.3179 (0.3613)	mem 39782MB
[2023-07-07 09:05:25 RepVGG-A0] (main.py 282): INFO Train: [51/300][30/78]	eta 0:01:41 lr 5.947791	time 1.1941 (2.1155)	loss 3.6370 (3.6136)	grad_norm 0.3729 (0.3550)	mem 39782MB
[2023-07-07 09:05:43 RepVGG-A0] (main.py 282): INFO Train: [51/300][40/78]	eta 0:01:17 lr 5.945587	time 3.6734 (2.0394)	loss 3.5714 (3.6114)	grad_norm 0.3457 (0.3568)	mem 39782MB
[2023-07-07 09:05:57 RepVGG-A0] (main.py 282): INFO Train: [51/300][50/78]	eta 0:00:53 lr 5.943378	time 1.1708 (1.9283)	loss 3.5439 (3.6129)	grad_norm 0.3412 (0.3562)	mem 39782MB
[2023-07-07 09:06:13 RepVGG-A0] (main.py 282): INFO Train: [51/300][60/78]	eta 0:00:33 lr 5.941164	time 1.4291 (1.8615)	loss 6.0899 (3.8037)	grad_norm 0.5566 (0.4047)	mem 39782MB
[2023-07-07 09:06:27 RepVGG-A0] (main.py 282): INFO Train: [51/300][70/78]	eta 0:00:14 lr 5.938944	time 1.2586 (1.8030)	loss 5.2519 (4.0758)	grad_norm 0.2728 (0.4118)	mem 39782MB
[2023-07-07 09:06:39 RepVGG-A0] (main.py 291): INFO EPOCH 51 training takes 0:02:19
[2023-07-07 09:07:00 RepVGG-A0] (main.py 282): INFO Train: [52/300][0/78]	eta 0:27:28 lr 5.937166	time 21.1382 (21.1382)	loss 4.7857 (4.7857)	grad_norm 0.3029 (0.3029)	mem 39782MB
[2023-07-07 09:07:15 RepVGG-A0] (main.py 282): INFO Train: [52/300][10/78]	eta 0:03:42 lr 5.934938	time 1.1718 (3.2706)	loss 4.4127 (4.5291)	grad_norm 0.3327 (0.2876)	mem 39782MB
[2023-07-07 09:07:29 RepVGG-A0] (main.py 282): INFO Train: [52/300][20/78]	eta 0:02:18 lr 5.932705	time 1.1743 (2.3930)	loss 4.1279 (4.3886)	grad_norm 0.3075 (0.2900)	mem 39782MB
[2023-07-07 09:07:45 RepVGG-A0] (main.py 282): INFO Train: [52/300][30/78]	eta 0:01:41 lr 5.930467	time 1.4538 (2.1203)	loss 4.0108 (4.2999)	grad_norm 0.2978 (0.2967)	mem 39782MB
[2023-07-07 09:08:03 RepVGG-A0] (main.py 282): INFO Train: [52/300][40/78]	eta 0:01:17 lr 5.928224	time 3.6355 (2.0462)	loss 3.9464 (4.2226)	grad_norm 0.2919 (0.2976)	mem 39782MB
[2023-07-07 09:08:18 RepVGG-A0] (main.py 282): INFO Train: [52/300][50/78]	eta 0:00:54 lr 5.925976	time 1.1745 (1.9446)	loss 3.8674 (4.1588)	grad_norm 0.3220 (0.2993)	mem 39782MB
[2023-07-07 09:08:33 RepVGG-A0] (main.py 282): INFO Train: [52/300][60/78]	eta 0:00:33 lr 5.923724	time 1.2101 (1.8766)	loss 3.8927 (4.1209)	grad_norm 0.3542 (0.3089)	mem 39782MB
[2023-07-07 09:08:48 RepVGG-A0] (main.py 282): INFO Train: [52/300][70/78]	eta 0:00:14 lr 5.921466	time 1.1630 (1.8169)	loss 4.5521 (4.0925)	grad_norm 0.7432 (0.3164)	mem 39782MB
[2023-07-07 09:09:01 RepVGG-A0] (main.py 291): INFO EPOCH 52 training takes 0:02:21
[2023-07-07 09:09:21 RepVGG-A0] (main.py 282): INFO Train: [53/300][0/78]	eta 0:26:01 lr 5.919657	time 20.0190 (20.0190)	loss 5.1346 (5.1346)	grad_norm 0.4777 (0.4777)	mem 39782MB
[2023-07-07 09:09:36 RepVGG-A0] (main.py 282): INFO Train: [53/300][10/78]	eta 0:03:39 lr 5.917390	time 1.1709 (3.2336)	loss 4.2928 (4.4920)	grad_norm 0.3043 (0.3298)	mem 39782MB
[2023-07-07 09:09:50 RepVGG-A0] (main.py 282): INFO Train: [53/300][20/78]	eta 0:02:17 lr 5.915119	time 1.1737 (2.3667)	loss 3.9010 (4.2845)	grad_norm 0.2308 (0.3019)	mem 39782MB
[2023-07-07 09:10:06 RepVGG-A0] (main.py 282): INFO Train: [53/300][30/78]	eta 0:01:40 lr 5.912843	time 1.2211 (2.0928)	loss 3.9337 (4.1643)	grad_norm 0.3032 (0.2942)	mem 39782MB
[2023-07-07 09:10:24 RepVGG-A0] (main.py 282): INFO Train: [53/300][40/78]	eta 0:01:16 lr 5.910562	time 3.7811 (2.0220)	loss 3.7941 (4.0726)	grad_norm 0.2973 (0.2907)	mem 39782MB
[2023-07-07 09:10:39 RepVGG-A0] (main.py 282): INFO Train: [53/300][50/78]	eta 0:00:53 lr 5.908276	time 1.1761 (1.9232)	loss 3.7345 (4.0165)	grad_norm 0.3332 (0.2959)	mem 39782MB
[2023-07-07 09:10:54 RepVGG-A0] (main.py 282): INFO Train: [53/300][60/78]	eta 0:00:33 lr 5.905985	time 1.1281 (1.8510)	loss 3.8174 (3.9887)	grad_norm 0.2992 (0.3058)	mem 39782MB
[2023-07-07 09:11:08 RepVGG-A0] (main.py 282): INFO Train: [53/300][70/78]	eta 0:00:14 lr 5.903689	time 1.2124 (1.7974)	loss 3.7304 (3.9487)	grad_norm 0.3184 (0.3045)	mem 39782MB
[2023-07-07 09:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 53 training takes 0:02:19
[2023-07-07 09:11:41 RepVGG-A0] (main.py 282): INFO Train: [54/300][0/78]	eta 0:27:00 lr 5.901849	time 20.7768 (20.7768)	loss 3.7699 (3.7699)	grad_norm 0.4143 (0.4143)	mem 39782MB
[2023-07-07 09:11:57 RepVGG-A0] (main.py 282): INFO Train: [54/300][10/78]	eta 0:03:47 lr 5.899545	time 1.1719 (3.3461)	loss 3.7300 (3.9403)	grad_norm 0.2811 (0.4191)	mem 39782MB
[2023-07-07 09:12:12 RepVGG-A0] (main.py 282): INFO Train: [54/300][20/78]	eta 0:02:23 lr 5.897236	time 1.1859 (2.4666)	loss 3.6550 (3.8238)	grad_norm 0.3360 (0.3612)	mem 39782MB
[2023-07-07 09:12:28 RepVGG-A0] (main.py 282): INFO Train: [54/300][30/78]	eta 0:01:44 lr 5.894921	time 1.6246 (2.1841)	loss 3.8349 (3.7932)	grad_norm 0.3742 (0.3560)	mem 39782MB
[2023-07-07 09:12:45 RepVGG-A0] (main.py 282): INFO Train: [54/300][40/78]	eta 0:01:19 lr 5.892602	time 2.9223 (2.0806)	loss 3.5795 (3.7600)	grad_norm 0.3055 (0.3458)	mem 39782MB
[2023-07-07 09:13:00 RepVGG-A0] (main.py 282): INFO Train: [54/300][50/78]	eta 0:00:54 lr 5.890278	time 1.1729 (1.9633)	loss 3.7256 (3.7442)	grad_norm 0.3613 (0.3470)	mem 39782MB
[2023-07-07 09:13:16 RepVGG-A0] (main.py 282): INFO Train: [54/300][60/78]	eta 0:00:34 lr 5.887950	time 1.3272 (1.8972)	loss 4.1643 (3.7405)	grad_norm 0.5986 (0.3528)	mem 39782MB
[2023-07-07 09:13:31 RepVGG-A0] (main.py 282): INFO Train: [54/300][70/78]	eta 0:00:14 lr 5.885616	time 1.3131 (1.8412)	loss 3.8400 (3.7893)	grad_norm 0.2966 (0.3676)	mem 39782MB
[2023-07-07 09:13:42 RepVGG-A0] (main.py 291): INFO EPOCH 54 training takes 0:02:22
[2023-07-07 09:14:04 RepVGG-A0] (main.py 282): INFO Train: [55/300][0/78]	eta 0:28:58 lr 5.883746	time 22.2923 (22.2923)	loss 3.6304 (3.6304)	grad_norm 0.3142 (0.3142)	mem 39782MB
[2023-07-07 09:14:18 RepVGG-A0] (main.py 282): INFO Train: [55/300][10/78]	eta 0:03:44 lr 5.881404	time 1.1706 (3.2988)	loss 3.5409 (3.6480)	grad_norm 0.2664 (0.3141)	mem 39782MB
[2023-07-07 09:14:32 RepVGG-A0] (main.py 282): INFO Train: [55/300][20/78]	eta 0:02:18 lr 5.879056	time 1.1917 (2.3931)	loss 3.6787 (3.6230)	grad_norm 0.3742 (0.3193)	mem 39782MB
[2023-07-07 09:14:48 RepVGG-A0] (main.py 282): INFO Train: [55/300][30/78]	eta 0:01:41 lr 5.876704	time 1.7391 (2.1240)	loss 3.6280 (3.6206)	grad_norm 0.3462 (0.3244)	mem 39782MB
[2023-07-07 09:15:05 RepVGG-A0] (main.py 282): INFO Train: [55/300][40/78]	eta 0:01:16 lr 5.874348	time 3.7325 (2.0181)	loss 3.6573 (3.6075)	grad_norm 0.4316 (0.3270)	mem 39782MB
[2023-07-07 09:15:22 RepVGG-A0] (main.py 282): INFO Train: [55/300][50/78]	eta 0:00:54 lr 5.871986	time 1.1727 (1.9528)	loss 3.5729 (3.6269)	grad_norm 0.3439 (0.3371)	mem 39782MB
[2023-07-07 09:15:37 RepVGG-A0] (main.py 282): INFO Train: [55/300][60/78]	eta 0:00:33 lr 5.869620	time 1.4294 (1.8858)	loss 3.6092 (3.6283)	grad_norm 0.3490 (0.3377)	mem 39782MB
[2023-07-07 09:15:52 RepVGG-A0] (main.py 282): INFO Train: [55/300][70/78]	eta 0:00:14 lr 5.867248	time 1.2641 (1.8278)	loss 4.1530 (3.6753)	grad_norm 0.5416 (0.3622)	mem 39782MB
[2023-07-07 09:16:03 RepVGG-A0] (main.py 291): INFO EPOCH 55 training takes 0:02:20
[2023-07-07 09:16:24 RepVGG-A0] (main.py 282): INFO Train: [56/300][0/78]	eta 0:27:29 lr 5.865348	time 21.1487 (21.1487)	loss 3.5846 (3.5846)	grad_norm 0.2869 (0.2869)	mem 39782MB
[2023-07-07 09:16:40 RepVGG-A0] (main.py 282): INFO Train: [56/300][10/78]	eta 0:03:48 lr 5.862968	time 1.1701 (3.3556)	loss 3.5791 (3.5781)	grad_norm 0.2982 (0.2909)	mem 39782MB
[2023-07-07 09:16:54 RepVGG-A0] (main.py 282): INFO Train: [56/300][20/78]	eta 0:02:21 lr 5.860583	time 1.3317 (2.4395)	loss 3.6159 (3.5649)	grad_norm 0.3235 (0.3030)	mem 39782MB
[2023-07-07 09:17:10 RepVGG-A0] (main.py 282): INFO Train: [56/300][30/78]	eta 0:01:43 lr 5.858194	time 1.4941 (2.1561)	loss 3.5195 (3.5467)	grad_norm 0.3312 (0.3073)	mem 39782MB
[2023-07-07 09:17:27 RepVGG-A0] (main.py 282): INFO Train: [56/300][40/78]	eta 0:01:18 lr 5.855800	time 2.6557 (2.0537)	loss 3.5612 (3.5466)	grad_norm 0.3846 (0.3146)	mem 39782MB
[2023-07-07 09:17:43 RepVGG-A0] (main.py 282): INFO Train: [56/300][50/78]	eta 0:00:54 lr 5.853401	time 1.1730 (1.9540)	loss 4.3487 (3.6264)	grad_norm 0.6707 (0.3569)	mem 39782MB
[2023-07-07 09:17:59 RepVGG-A0] (main.py 282): INFO Train: [56/300][60/78]	eta 0:00:34 lr 5.850997	time 1.1355 (1.8976)	loss 3.8029 (3.7182)	grad_norm 0.2702 (0.3711)	mem 39782MB
[2023-07-07 09:18:14 RepVGG-A0] (main.py 282): INFO Train: [56/300][70/78]	eta 0:00:14 lr 5.848588	time 1.2279 (1.8395)	loss 3.6624 (3.7124)	grad_norm 0.3020 (0.3574)	mem 39782MB
[2023-07-07 09:18:25 RepVGG-A0] (main.py 291): INFO EPOCH 56 training takes 0:02:21
[2023-07-07 09:18:46 RepVGG-A0] (main.py 282): INFO Train: [57/300][0/78]	eta 0:27:54 lr 5.846658	time 21.4629 (21.4629)	loss 3.4980 (3.4980)	grad_norm 0.2411 (0.2411)	mem 39782MB
[2023-07-07 09:19:00 RepVGG-A0] (main.py 282): INFO Train: [57/300][10/78]	eta 0:03:36 lr 5.844241	time 1.1728 (3.1871)	loss 3.4670 (3.4902)	grad_norm 0.3036 (0.2740)	mem 39782MB
[2023-07-07 09:19:15 RepVGG-A0] (main.py 282): INFO Train: [57/300][20/78]	eta 0:02:18 lr 5.841819	time 1.1939 (2.3896)	loss 3.5482 (3.5117)	grad_norm 0.3639 (0.3037)	mem 39782MB
[2023-07-07 09:19:31 RepVGG-A0] (main.py 282): INFO Train: [57/300][30/78]	eta 0:01:42 lr 5.839392	time 1.3771 (2.1358)	loss 3.5322 (3.5274)	grad_norm 0.3151 (0.3156)	mem 39782MB
[2023-07-07 09:19:48 RepVGG-A0] (main.py 282): INFO Train: [57/300][40/78]	eta 0:01:17 lr 5.836960	time 2.1370 (2.0352)	loss 3.4881 (3.5194)	grad_norm 0.3532 (0.3159)	mem 39782MB
[2023-07-07 09:20:03 RepVGG-A0] (main.py 282): INFO Train: [57/300][50/78]	eta 0:00:54 lr 5.834524	time 1.1725 (1.9336)	loss 3.5028 (3.5252)	grad_norm 0.3171 (0.3222)	mem 39782MB
[2023-07-07 09:20:19 RepVGG-A0] (main.py 282): INFO Train: [57/300][60/78]	eta 0:00:33 lr 5.832083	time 1.2716 (1.8689)	loss 3.6522 (3.5375)	grad_norm 0.4287 (0.3322)	mem 39782MB
[2023-07-07 09:20:35 RepVGG-A0] (main.py 282): INFO Train: [57/300][70/78]	eta 0:00:14 lr 5.829637	time 1.4229 (1.8334)	loss 3.6036 (3.5509)	grad_norm 0.3394 (0.3365)	mem 39782MB
[2023-07-07 09:20:46 RepVGG-A0] (main.py 291): INFO EPOCH 57 training takes 0:02:21
[2023-07-07 09:21:07 RepVGG-A0] (main.py 282): INFO Train: [58/300][0/78]	eta 0:28:11 lr 5.827677	time 21.6800 (21.6800)	loss 3.4424 (3.4424)	grad_norm 0.3257 (0.3257)	mem 39782MB
[2023-07-07 09:21:22 RepVGG-A0] (main.py 282): INFO Train: [58/300][10/78]	eta 0:03:42 lr 5.825223	time 1.2016 (3.2673)	loss 3.5607 (3.4882)	grad_norm 0.4379 (0.3458)	mem 39782MB
[2023-07-07 09:21:37 RepVGG-A0] (main.py 282): INFO Train: [58/300][20/78]	eta 0:02:21 lr 5.822764	time 1.1731 (2.4390)	loss 5.8195 (3.9999)	grad_norm 0.8552 (0.5332)	mem 39782MB
[2023-07-07 09:21:51 RepVGG-A0] (main.py 282): INFO Train: [58/300][30/78]	eta 0:01:41 lr 5.820300	time 1.2993 (2.1178)	loss 4.4050 (4.2738)	grad_norm 0.2507 (0.4912)	mem 39782MB
[2023-07-07 09:22:09 RepVGG-A0] (main.py 282): INFO Train: [58/300][40/78]	eta 0:01:17 lr 5.817832	time 3.7054 (2.0426)	loss 3.8571 (4.2306)	grad_norm 0.2199 (0.4393)	mem 39782MB
[2023-07-07 09:22:24 RepVGG-A0] (main.py 282): INFO Train: [58/300][50/78]	eta 0:00:54 lr 5.815359	time 1.1734 (1.9359)	loss 3.7917 (4.1563)	grad_norm 0.2943 (0.4105)	mem 39782MB
[2023-07-07 09:22:40 RepVGG-A0] (main.py 282): INFO Train: [58/300][60/78]	eta 0:00:33 lr 5.812881	time 1.1673 (1.8786)	loss 3.6655 (4.0821)	grad_norm 0.2548 (0.3863)	mem 39782MB
[2023-07-07 09:22:56 RepVGG-A0] (main.py 282): INFO Train: [58/300][70/78]	eta 0:00:14 lr 5.810398	time 1.3280 (1.8305)	loss 3.5985 (4.0199)	grad_norm 0.2529 (0.3735)	mem 39782MB
[2023-07-07 09:23:07 RepVGG-A0] (main.py 291): INFO EPOCH 58 training takes 0:02:21
[2023-07-07 09:23:27 RepVGG-A0] (main.py 282): INFO Train: [59/300][0/78]	eta 0:26:33 lr 5.808409	time 20.4293 (20.4293)	loss 3.6507 (3.6507)	grad_norm 0.4193 (0.4193)	mem 39782MB
[2023-07-07 09:23:43 RepVGG-A0] (main.py 282): INFO Train: [59/300][10/78]	eta 0:03:40 lr 5.805918	time 1.1911 (3.2419)	loss 3.4334 (3.5727)	grad_norm 0.2791 (0.3217)	mem 39782MB
[2023-07-07 09:23:58 RepVGG-A0] (main.py 282): INFO Train: [59/300][20/78]	eta 0:02:21 lr 5.803422	time 1.1738 (2.4344)	loss 3.6360 (3.5773)	grad_norm 0.3507 (0.3272)	mem 39782MB
[2023-07-07 09:24:14 RepVGG-A0] (main.py 282): INFO Train: [59/300][30/78]	eta 0:01:43 lr 5.800922	time 1.1938 (2.1647)	loss 3.4646 (3.5936)	grad_norm 0.2843 (0.3336)	mem 39782MB
[2023-07-07 09:24:32 RepVGG-A0] (main.py 282): INFO Train: [59/300][40/78]	eta 0:01:19 lr 5.798417	time 2.9821 (2.0872)	loss 3.5150 (3.5808)	grad_norm 0.3075 (0.3316)	mem 39782MB
[2023-07-07 09:24:47 RepVGG-A0] (main.py 282): INFO Train: [59/300][50/78]	eta 0:00:55 lr 5.795907	time 1.1754 (1.9711)	loss 3.5609 (3.5732)	grad_norm 0.3520 (0.3340)	mem 39782MB
[2023-07-07 09:25:03 RepVGG-A0] (main.py 282): INFO Train: [59/300][60/78]	eta 0:00:34 lr 5.793392	time 1.4573 (1.8972)	loss 3.5953 (3.5744)	grad_norm 0.3667 (0.3382)	mem 39782MB
[2023-07-07 09:25:18 RepVGG-A0] (main.py 282): INFO Train: [59/300][70/78]	eta 0:00:14 lr 5.790873	time 1.2605 (1.8525)	loss 3.4953 (3.5706)	grad_norm 0.2880 (0.3382)	mem 39782MB
[2023-07-07 09:25:29 RepVGG-A0] (main.py 291): INFO EPOCH 59 training takes 0:02:22
[2023-07-07 09:25:51 RepVGG-A0] (main.py 282): INFO Train: [60/300][0/78]	eta 0:28:32 lr 5.788854	time 21.9562 (21.9562)	loss 3.5356 (3.5356)	grad_norm 0.3800 (0.3800)	mem 39782MB
[2023-07-07 09:26:05 RepVGG-A0] (main.py 282): INFO Train: [60/300][10/78]	eta 0:03:41 lr 5.786327	time 1.1732 (3.2596)	loss 3.8869 (3.7798)	grad_norm 0.4371 (0.4711)	mem 39782MB
[2023-07-07 09:26:20 RepVGG-A0] (main.py 282): INFO Train: [60/300][20/78]	eta 0:02:19 lr 5.783795	time 1.1735 (2.4100)	loss 3.5643 (3.6797)	grad_norm 0.3213 (0.3947)	mem 39782MB
[2023-07-07 09:26:35 RepVGG-A0] (main.py 282): INFO Train: [60/300][30/78]	eta 0:01:41 lr 5.781258	time 1.2619 (2.1154)	loss 3.4080 (3.6097)	grad_norm 0.2783 (0.3676)	mem 39782MB
[2023-07-07 09:26:54 RepVGG-A0] (main.py 282): INFO Train: [60/300][40/78]	eta 0:01:18 lr 5.778716	time 4.6595 (2.0585)	loss 3.5537 (3.5806)	grad_norm 0.3812 (0.3604)	mem 39782MB
[2023-07-07 09:27:09 RepVGG-A0] (main.py 282): INFO Train: [60/300][50/78]	eta 0:00:54 lr 5.776170	time 1.3136 (1.9495)	loss 3.4902 (3.5913)	grad_norm 0.3176 (0.3683)	mem 39782MB
[2023-07-07 09:27:23 RepVGG-A0] (main.py 282): INFO Train: [60/300][60/78]	eta 0:00:33 lr 5.773619	time 1.1753 (1.8630)	loss 3.4743 (3.5688)	grad_norm 0.3014 (0.3571)	mem 39782MB
[2023-07-07 09:27:38 RepVGG-A0] (main.py 282): INFO Train: [60/300][70/78]	eta 0:00:14 lr 5.771064	time 1.3722 (1.8171)	loss 4.7063 (3.6170)	grad_norm 0.9074 (0.3854)	mem 39782MB
[2023-07-07 09:27:50 RepVGG-A0] (main.py 291): INFO EPOCH 60 training takes 0:02:21
[2023-07-07 09:28:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.500 (17.500)	Loss 9.5352 (9.5352)	Acc@1 1.117 (1.117)	Acc@5 4.065 (4.065)	Mem 39782MB
[2023-07-07 09:28:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 1.154 Acc@5 3.944
[2023-07-07 09:28:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 60: 1.154%
[2023-07-07 09:28:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 09:28:31 RepVGG-A0] (main.py 282): INFO Train: [61/300][0/78]	eta 0:28:33 lr 5.769016	time 21.9719 (21.9719)	loss 4.4236 (4.4236)	grad_norm 0.3837 (0.3837)	mem 39782MB
[2023-07-07 09:28:48 RepVGG-A0] (main.py 282): INFO Train: [61/300][10/78]	eta 0:04:00 lr 5.766452	time 1.1780 (3.5346)	loss 3.8207 (4.0776)	grad_norm 0.2932 (0.3212)	mem 39782MB
[2023-07-07 09:29:02 RepVGG-A0] (main.py 282): INFO Train: [61/300][20/78]	eta 0:02:26 lr 5.763884	time 1.1737 (2.5238)	loss 3.5860 (3.9069)	grad_norm 0.2410 (0.3010)	mem 39782MB
[2023-07-07 09:29:17 RepVGG-A0] (main.py 282): INFO Train: [61/300][30/78]	eta 0:01:44 lr 5.761311	time 1.4142 (2.1846)	loss 3.5581 (3.7947)	grad_norm 0.2852 (0.2923)	mem 39782MB
[2023-07-07 09:29:34 RepVGG-A0] (main.py 282): INFO Train: [61/300][40/78]	eta 0:01:18 lr 5.758733	time 3.3766 (2.0767)	loss 3.5419 (3.7292)	grad_norm 0.3038 (0.2913)	mem 39782MB
[2023-07-07 09:29:49 RepVGG-A0] (main.py 282): INFO Train: [61/300][50/78]	eta 0:00:54 lr 5.756151	time 1.2182 (1.9581)	loss 3.4635 (3.6802)	grad_norm 0.3334 (0.2957)	mem 39782MB
[2023-07-07 09:30:04 RepVGG-A0] (main.py 282): INFO Train: [61/300][60/78]	eta 0:00:34 lr 5.753564	time 1.2125 (1.8926)	loss 3.4387 (3.6468)	grad_norm 0.2989 (0.2962)	mem 39782MB
[2023-07-07 09:30:20 RepVGG-A0] (main.py 282): INFO Train: [61/300][70/78]	eta 0:00:14 lr 5.750972	time 1.2129 (1.8454)	loss 3.6214 (3.6325)	grad_norm 0.4232 (0.3059)	mem 39782MB
[2023-07-07 09:30:31 RepVGG-A0] (main.py 291): INFO EPOCH 61 training takes 0:02:22
[2023-07-07 09:30:52 RepVGG-A0] (main.py 282): INFO Train: [62/300][0/78]	eta 0:26:49 lr 5.748896	time 20.6387 (20.6387)	loss 3.5264 (3.5264)	grad_norm 0.3303 (0.3303)	mem 39782MB
[2023-07-07 09:31:06 RepVGG-A0] (main.py 282): INFO Train: [62/300][10/78]	eta 0:03:31 lr 5.746296	time 1.1726 (3.1133)	loss 3.3294 (3.4250)	grad_norm 0.3172 (0.3186)	mem 39782MB
[2023-07-07 09:31:21 RepVGG-A0] (main.py 282): INFO Train: [62/300][20/78]	eta 0:02:17 lr 5.743692	time 1.2823 (2.3721)	loss 3.4591 (3.4381)	grad_norm 0.3536 (0.3274)	mem 39782MB
[2023-07-07 09:31:37 RepVGG-A0] (main.py 282): INFO Train: [62/300][30/78]	eta 0:01:41 lr 5.741083	time 1.3928 (2.1187)	loss 3.5675 (3.4740)	grad_norm 0.4112 (0.3466)	mem 39782MB
[2023-07-07 09:31:55 RepVGG-A0] (main.py 282): INFO Train: [62/300][40/78]	eta 0:01:17 lr 5.738469	time 4.0569 (2.0274)	loss 3.7097 (3.5625)	grad_norm 0.3568 (0.3771)	mem 39782MB
[2023-07-07 09:32:10 RepVGG-A0] (main.py 282): INFO Train: [62/300][50/78]	eta 0:00:53 lr 5.735851	time 1.1715 (1.9274)	loss 3.4341 (3.5539)	grad_norm 0.2826 (0.3600)	mem 39782MB
[2023-07-07 09:32:25 RepVGG-A0] (main.py 282): INFO Train: [62/300][60/78]	eta 0:00:33 lr 5.733228	time 1.3086 (1.8583)	loss 3.4511 (3.5398)	grad_norm 0.3257 (0.3530)	mem 39782MB
[2023-07-07 09:32:40 RepVGG-A0] (main.py 282): INFO Train: [62/300][70/78]	eta 0:00:14 lr 5.730601	time 1.4727 (1.8095)	loss 3.5545 (3.5334)	grad_norm 0.3370 (0.3522)	mem 39782MB
[2023-07-07 09:32:52 RepVGG-A0] (main.py 291): INFO EPOCH 62 training takes 0:02:20
[2023-07-07 09:33:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][0/78]	eta 0:28:36 lr 5.728496	time 22.0026 (22.0026)	loss 3.4198 (3.4198)	grad_norm 0.3240 (0.3240)	mem 39782MB
[2023-07-07 09:33:28 RepVGG-A0] (main.py 282): INFO Train: [63/300][10/78]	eta 0:03:42 lr 5.725861	time 1.1725 (3.2673)	loss 3.5364 (3.4182)	grad_norm 0.4217 (0.3436)	mem 39782MB
[2023-07-07 09:33:42 RepVGG-A0] (main.py 282): INFO Train: [63/300][20/78]	eta 0:02:18 lr 5.723221	time 1.2884 (2.3839)	loss 5.1960 (3.9103)	grad_norm 0.7453 (0.5193)	mem 39782MB
[2023-07-07 09:33:57 RepVGG-A0] (main.py 282): INFO Train: [63/300][30/78]	eta 0:01:40 lr 5.720576	time 1.4758 (2.0969)	loss 4.2028 (4.1500)	grad_norm 0.2767 (0.4875)	mem 39782MB
[2023-07-07 09:34:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][40/78]	eta 0:01:16 lr 5.717927	time 2.7101 (2.0008)	loss 3.9095 (4.1119)	grad_norm 0.2881 (0.4358)	mem 39782MB
[2023-07-07 09:34:29 RepVGG-A0] (main.py 282): INFO Train: [63/300][50/78]	eta 0:00:53 lr 5.715273	time 1.3426 (1.9190)	loss 3.7434 (4.0389)	grad_norm 0.3010 (0.4041)	mem 39782MB
[2023-07-07 09:34:45 RepVGG-A0] (main.py 282): INFO Train: [63/300][60/78]	eta 0:00:33 lr 5.712615	time 1.1737 (1.8550)	loss 3.5611 (3.9704)	grad_norm 0.2600 (0.3830)	mem 39782MB
[2023-07-07 09:35:00 RepVGG-A0] (main.py 282): INFO Train: [63/300][70/78]	eta 0:00:14 lr 5.709952	time 1.3304 (1.8129)	loss 3.5408 (3.9084)	grad_norm 0.3287 (0.3677)	mem 39782MB
[2023-07-07 09:35:12 RepVGG-A0] (main.py 291): INFO EPOCH 63 training takes 0:02:20
[2023-07-07 09:35:33 RepVGG-A0] (main.py 282): INFO Train: [64/300][0/78]	eta 0:27:52 lr 5.707819	time 21.4381 (21.4381)	loss 3.3971 (3.3971)	grad_norm 0.3458 (0.3458)	mem 39782MB
[2023-07-07 09:35:49 RepVGG-A0] (main.py 282): INFO Train: [64/300][10/78]	eta 0:03:49 lr 5.705148	time 1.1707 (3.3798)	loss 3.4389 (3.4838)	grad_norm 0.2726 (0.3107)	mem 39782MB
[2023-07-07 09:36:04 RepVGG-A0] (main.py 282): INFO Train: [64/300][20/78]	eta 0:02:25 lr 5.702473	time 1.1967 (2.5120)	loss 3.6100 (3.4923)	grad_norm 0.4396 (0.3233)	mem 39782MB
[2023-07-07 09:36:20 RepVGG-A0] (main.py 282): INFO Train: [64/300][30/78]	eta 0:01:45 lr 5.699793	time 1.5733 (2.1955)	loss 3.4328 (3.5162)	grad_norm 0.2986 (0.3359)	mem 39782MB
[2023-07-07 09:36:38 RepVGG-A0] (main.py 282): INFO Train: [64/300][40/78]	eta 0:01:19 lr 5.697109	time 2.1966 (2.0990)	loss 3.5562 (3.5099)	grad_norm 0.3475 (0.3318)	mem 39782MB
[2023-07-07 09:36:53 RepVGG-A0] (main.py 282): INFO Train: [64/300][50/78]	eta 0:00:55 lr 5.694420	time 1.1760 (1.9852)	loss 3.5499 (3.4956)	grad_norm 0.3971 (0.3264)	mem 39782MB
[2023-07-07 09:37:07 RepVGG-A0] (main.py 282): INFO Train: [64/300][60/78]	eta 0:00:34 lr 5.691726	time 1.1751 (1.8923)	loss 3.6001 (3.5246)	grad_norm 0.3464 (0.3421)	mem 39782MB
[2023-07-07 09:37:22 RepVGG-A0] (main.py 282): INFO Train: [64/300][70/78]	eta 0:00:14 lr 5.689029	time 1.2917 (1.8354)	loss 3.5047 (3.5176)	grad_norm 0.3460 (0.3384)	mem 39782MB
[2023-07-07 09:37:34 RepVGG-A0] (main.py 291): INFO EPOCH 64 training takes 0:02:22
[2023-07-07 09:37:55 RepVGG-A0] (main.py 282): INFO Train: [65/300][0/78]	eta 0:27:25 lr 5.686867	time 21.0959 (21.0959)	loss 3.3750 (3.3750)	grad_norm 0.3390 (0.3390)	mem 39782MB
[2023-07-07 09:38:09 RepVGG-A0] (main.py 282): INFO Train: [65/300][10/78]	eta 0:03:38 lr 5.684161	time 1.1743 (3.2189)	loss 3.3615 (3.4488)	grad_norm 0.3396 (0.3593)	mem 39782MB
[2023-07-07 09:38:25 RepVGG-A0] (main.py 282): INFO Train: [65/300][20/78]	eta 0:02:21 lr 5.681451	time 1.1855 (2.4468)	loss 3.4913 (3.4282)	grad_norm 0.3700 (0.3420)	mem 39782MB
[2023-07-07 09:38:41 RepVGG-A0] (main.py 282): INFO Train: [65/300][30/78]	eta 0:01:43 lr 5.678736	time 1.7314 (2.1549)	loss 3.4643 (3.4409)	grad_norm 0.3616 (0.3542)	mem 39782MB
[2023-07-07 09:38:58 RepVGG-A0] (main.py 282): INFO Train: [65/300][40/78]	eta 0:01:17 lr 5.676017	time 3.4897 (2.0503)	loss 3.4580 (3.4425)	grad_norm 0.4233 (0.3501)	mem 39782MB
[2023-07-07 09:39:13 RepVGG-A0] (main.py 282): INFO Train: [65/300][50/78]	eta 0:00:54 lr 5.673293	time 1.1743 (1.9456)	loss 4.8227 (3.6155)	grad_norm 0.6230 (0.4151)	mem 39782MB
[2023-07-07 09:39:28 RepVGG-A0] (main.py 282): INFO Train: [65/300][60/78]	eta 0:00:33 lr 5.670564	time 1.2093 (1.8706)	loss 4.2846 (3.7895)	grad_norm 0.3560 (0.4301)	mem 39782MB
[2023-07-07 09:39:43 RepVGG-A0] (main.py 282): INFO Train: [65/300][70/78]	eta 0:00:14 lr 5.667832	time 1.2435 (1.8158)	loss 3.8134 (3.8101)	grad_norm 0.3073 (0.4077)	mem 39782MB
[2023-07-07 09:39:55 RepVGG-A0] (main.py 291): INFO EPOCH 65 training takes 0:02:21
[2023-07-07 09:40:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][0/78]	eta 0:27:02 lr 5.665642	time 20.7954 (20.7954)	loss 3.6035 (3.6035)	grad_norm 0.2577 (0.2577)	mem 39782MB
[2023-07-07 09:40:30 RepVGG-A0] (main.py 282): INFO Train: [66/300][10/78]	eta 0:03:33 lr 5.662902	time 1.1918 (3.1363)	loss 3.5343 (3.5817)	grad_norm 0.2528 (0.2668)	mem 39782MB
[2023-07-07 09:40:44 RepVGG-A0] (main.py 282): INFO Train: [66/300][20/78]	eta 0:02:14 lr 5.660156	time 1.1919 (2.3192)	loss 3.5056 (3.5385)	grad_norm 0.2966 (0.2720)	mem 39782MB
[2023-07-07 09:40:59 RepVGG-A0] (main.py 282): INFO Train: [66/300][30/78]	eta 0:01:38 lr 5.657407	time 1.1761 (2.0424)	loss 3.4981 (3.5215)	grad_norm 0.3068 (0.2793)	mem 39782MB
[2023-07-07 09:41:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][40/78]	eta 0:01:14 lr 5.654653	time 3.5759 (1.9697)	loss 3.4165 (3.5112)	grad_norm 0.2734 (0.2895)	mem 39782MB
[2023-07-07 09:41:32 RepVGG-A0] (main.py 282): INFO Train: [66/300][50/78]	eta 0:00:52 lr 5.651894	time 2.1476 (1.8913)	loss 3.5757 (3.5014)	grad_norm 0.3489 (0.2950)	mem 39782MB
[2023-07-07 09:41:47 RepVGG-A0] (main.py 282): INFO Train: [66/300][60/78]	eta 0:00:32 lr 5.649132	time 1.1756 (1.8265)	loss 5.2293 (3.6660)	grad_norm 0.5786 (0.3609)	mem 39782MB
[2023-07-07 09:42:03 RepVGG-A0] (main.py 282): INFO Train: [66/300][70/78]	eta 0:00:14 lr 5.646364	time 1.3804 (1.7916)	loss 4.4569 (3.8270)	grad_norm 0.3216 (0.3730)	mem 39782MB
[2023-07-07 09:42:14 RepVGG-A0] (main.py 291): INFO EPOCH 66 training takes 0:02:19
[2023-07-07 09:42:36 RepVGG-A0] (main.py 282): INFO Train: [67/300][0/78]	eta 0:27:53 lr 5.644147	time 21.4536 (21.4536)	loss 3.8975 (3.8975)	grad_norm 0.2578 (0.2578)	mem 39782MB
[2023-07-07 09:42:50 RepVGG-A0] (main.py 282): INFO Train: [67/300][10/78]	eta 0:03:41 lr 5.641372	time 1.1936 (3.2558)	loss 3.8836 (3.8753)	grad_norm 0.2625 (0.2836)	mem 39782MB
[2023-07-07 09:43:04 RepVGG-A0] (main.py 282): INFO Train: [67/300][20/78]	eta 0:02:16 lr 5.638592	time 1.1719 (2.3620)	loss 3.6424 (3.7848)	grad_norm 0.2765 (0.2761)	mem 39782MB
[2023-07-07 09:43:19 RepVGG-A0] (main.py 282): INFO Train: [67/300][30/78]	eta 0:01:40 lr 5.635808	time 1.3788 (2.0841)	loss 3.6318 (3.7340)	grad_norm 0.2977 (0.2811)	mem 39782MB
[2023-07-07 09:43:37 RepVGG-A0] (main.py 282): INFO Train: [67/300][40/78]	eta 0:01:16 lr 5.633020	time 3.5791 (2.0159)	loss 3.5384 (3.7075)	grad_norm 0.2655 (0.2931)	mem 39782MB
[2023-07-07 09:43:53 RepVGG-A0] (main.py 282): INFO Train: [67/300][50/78]	eta 0:00:54 lr 5.630227	time 1.1734 (1.9294)	loss 3.5614 (3.6794)	grad_norm 0.3324 (0.2952)	mem 39782MB
[2023-07-07 09:44:07 RepVGG-A0] (main.py 282): INFO Train: [67/300][60/78]	eta 0:00:33 lr 5.627430	time 1.3105 (1.8516)	loss 3.6825 (3.6584)	grad_norm 0.3992 (0.3004)	mem 39782MB
[2023-07-07 09:44:23 RepVGG-A0] (main.py 282): INFO Train: [67/300][70/78]	eta 0:00:14 lr 5.624629	time 1.3107 (1.8076)	loss 3.5247 (3.6481)	grad_norm 0.3790 (0.3068)	mem 39782MB
[2023-07-07 09:44:35 RepVGG-A0] (main.py 291): INFO EPOCH 67 training takes 0:02:20
[2023-07-07 09:44:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][0/78]	eta 0:28:00 lr 5.622384	time 21.5495 (21.5495)	loss 3.4875 (3.4875)	grad_norm 0.2924 (0.2924)	mem 39782MB
[2023-07-07 09:45:10 RepVGG-A0] (main.py 282): INFO Train: [68/300][10/78]	eta 0:03:37 lr 5.619575	time 1.1719 (3.1960)	loss 3.4614 (3.4908)	grad_norm 0.3247 (0.3421)	mem 39782MB
[2023-07-07 09:45:25 RepVGG-A0] (main.py 282): INFO Train: [68/300][20/78]	eta 0:02:19 lr 5.616761	time 1.2852 (2.4029)	loss 3.4936 (3.4839)	grad_norm 0.3365 (0.3351)	mem 39782MB
[2023-07-07 09:45:40 RepVGG-A0] (main.py 282): INFO Train: [68/300][30/78]	eta 0:01:41 lr 5.613943	time 1.4627 (2.1176)	loss 3.4866 (3.4924)	grad_norm 0.3669 (0.3429)	mem 39782MB
[2023-07-07 09:45:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][40/78]	eta 0:01:15 lr 5.611120	time 2.0410 (1.9919)	loss 3.5078 (3.4997)	grad_norm 0.3171 (0.3462)	mem 39782MB
[2023-07-07 09:46:14 RepVGG-A0] (main.py 282): INFO Train: [68/300][50/78]	eta 0:00:54 lr 5.608294	time 1.3789 (1.9400)	loss 3.5740 (3.5027)	grad_norm 0.3760 (0.3501)	mem 39782MB
[2023-07-07 09:46:29 RepVGG-A0] (main.py 282): INFO Train: [68/300][60/78]	eta 0:00:33 lr 5.605462	time 1.3286 (1.8667)	loss 3.5770 (3.5113)	grad_norm 0.3654 (0.3540)	mem 39782MB
[2023-07-07 09:46:44 RepVGG-A0] (main.py 282): INFO Train: [68/300][70/78]	eta 0:00:14 lr 5.602627	time 1.1788 (1.8202)	loss 3.4575 (3.5028)	grad_norm 0.3921 (0.3495)	mem 39782MB
[2023-07-07 09:46:56 RepVGG-A0] (main.py 291): INFO EPOCH 68 training takes 0:02:20
[2023-07-07 09:47:17 RepVGG-A0] (main.py 282): INFO Train: [69/300][0/78]	eta 0:28:17 lr 5.600355	time 21.7582 (21.7582)	loss 3.5560 (3.5560)	grad_norm 0.4097 (0.4097)	mem 39782MB
[2023-07-07 09:47:32 RepVGG-A0] (main.py 282): INFO Train: [69/300][10/78]	eta 0:03:45 lr 5.597512	time 1.1707 (3.3135)	loss 3.4138 (3.5564)	grad_norm 0.3140 (0.3957)	mem 39782MB
[2023-07-07 09:47:46 RepVGG-A0] (main.py 282): INFO Train: [69/300][20/78]	eta 0:02:20 lr 5.594665	time 1.2126 (2.4140)	loss 3.4610 (3.5105)	grad_norm 0.3201 (0.3725)	mem 39782MB
[2023-07-07 09:48:02 RepVGG-A0] (main.py 282): INFO Train: [69/300][30/78]	eta 0:01:42 lr 5.591813	time 1.3211 (2.1335)	loss 3.4568 (3.4803)	grad_norm 0.3596 (0.3596)	mem 39782MB
[2023-07-07 09:48:20 RepVGG-A0] (main.py 282): INFO Train: [69/300][40/78]	eta 0:01:17 lr 5.588956	time 3.9401 (2.0514)	loss 3.5976 (3.4792)	grad_norm 0.4635 (0.3623)	mem 39782MB
[2023-07-07 09:48:35 RepVGG-A0] (main.py 282): INFO Train: [69/300][50/78]	eta 0:00:54 lr 5.586096	time 1.1719 (1.9514)	loss 6.1664 (3.7867)	grad_norm 0.6966 (0.4551)	mem 39782MB
[2023-07-07 09:48:50 RepVGG-A0] (main.py 282): INFO Train: [69/300][60/78]	eta 0:00:33 lr 5.583231	time 1.2221 (1.8730)	loss 4.9918 (4.0734)	grad_norm 0.3042 (0.4439)	mem 39782MB
[2023-07-07 09:49:05 RepVGG-A0] (main.py 282): INFO Train: [69/300][70/78]	eta 0:00:14 lr 5.580362	time 1.1943 (1.8227)	loss 4.5291 (4.1603)	grad_norm 0.3020 (0.4236)	mem 39782MB
[2023-07-07 09:49:17 RepVGG-A0] (main.py 291): INFO EPOCH 69 training takes 0:02:21
[2023-07-07 09:49:39 RepVGG-A0] (main.py 282): INFO Train: [70/300][0/78]	eta 0:28:41 lr 5.578063	time 22.0675 (22.0675)	loss 4.1313 (4.1313)	grad_norm 0.2419 (0.2419)	mem 39782MB
[2023-07-07 09:49:53 RepVGG-A0] (main.py 282): INFO Train: [70/300][10/78]	eta 0:03:42 lr 5.575187	time 1.1718 (3.2671)	loss 4.0037 (4.0930)	grad_norm 0.3224 (0.2928)	mem 39782MB
[2023-07-07 09:50:09 RepVGG-A0] (main.py 282): INFO Train: [70/300][20/78]	eta 0:02:22 lr 5.572305	time 1.3422 (2.4634)	loss 3.8894 (4.0106)	grad_norm 0.2858 (0.2949)	mem 39782MB
[2023-07-07 09:50:24 RepVGG-A0] (main.py 282): INFO Train: [70/300][30/78]	eta 0:01:44 lr 5.569420	time 1.3426 (2.1768)	loss 3.7478 (3.9495)	grad_norm 0.2641 (0.2913)	mem 39782MB
[2023-07-07 09:50:41 RepVGG-A0] (main.py 282): INFO Train: [70/300][40/78]	eta 0:01:18 lr 5.566530	time 3.2967 (2.0615)	loss 3.8513 (3.9153)	grad_norm 0.3403 (0.3055)	mem 39782MB
[2023-07-07 09:50:56 RepVGG-A0] (main.py 282): INFO Train: [70/300][50/78]	eta 0:00:54 lr 5.563636	time 1.1741 (1.9418)	loss 3.6048 (3.8698)	grad_norm 0.2810 (0.3034)	mem 39782MB
[2023-07-07 09:51:11 RepVGG-A0] (main.py 282): INFO Train: [70/300][60/78]	eta 0:00:33 lr 5.560738	time 1.2393 (1.8721)	loss 3.8482 (3.8460)	grad_norm 0.4148 (0.3113)	mem 39782MB
[2023-07-07 09:51:25 RepVGG-A0] (main.py 282): INFO Train: [70/300][70/78]	eta 0:00:14 lr 5.557836	time 1.3045 (1.8018)	loss 3.5706 (3.8310)	grad_norm 0.2909 (0.3134)	mem 39782MB
[2023-07-07 09:51:36 RepVGG-A0] (main.py 291): INFO EPOCH 70 training takes 0:02:19
[2023-07-07 09:51:58 RepVGG-A0] (main.py 282): INFO Train: [71/300][0/78]	eta 0:28:20 lr 5.555511	time 21.8060 (21.8060)	loss 3.4765 (3.4765)	grad_norm 0.2949 (0.2949)	mem 39782MB
[2023-07-07 09:52:12 RepVGG-A0] (main.py 282): INFO Train: [71/300][10/78]	eta 0:03:42 lr 5.552601	time 1.1725 (3.2664)	loss 3.5728 (3.6559)	grad_norm 0.2917 (0.3733)	mem 39782MB
[2023-07-07 09:52:26 RepVGG-A0] (main.py 282): INFO Train: [71/300][20/78]	eta 0:02:17 lr 5.549686	time 1.1720 (2.3627)	loss 3.4861 (3.6084)	grad_norm 0.2888 (0.3414)	mem 39782MB
[2023-07-07 09:52:42 RepVGG-A0] (main.py 282): INFO Train: [71/300][30/78]	eta 0:01:41 lr 5.546768	time 1.4221 (2.1098)	loss 3.6122 (3.6002)	grad_norm 0.3619 (0.3468)	mem 39782MB
[2023-07-07 09:53:00 RepVGG-A0] (main.py 282): INFO Train: [71/300][40/78]	eta 0:01:17 lr 5.543845	time 4.2997 (2.0358)	loss 3.5454 (3.5857)	grad_norm 0.3471 (0.3410)	mem 39782MB
[2023-07-07 09:53:15 RepVGG-A0] (main.py 282): INFO Train: [71/300][50/78]	eta 0:00:53 lr 5.540918	time 1.1723 (1.9241)	loss 3.7688 (3.6524)	grad_norm 0.3041 (0.3686)	mem 39782MB
[2023-07-07 09:53:29 RepVGG-A0] (main.py 282): INFO Train: [71/300][60/78]	eta 0:00:33 lr 5.537986	time 1.1267 (1.8527)	loss 3.7406 (3.6477)	grad_norm 0.3630 (0.3598)	mem 39782MB
[2023-07-07 09:53:45 RepVGG-A0] (main.py 282): INFO Train: [71/300][70/78]	eta 0:00:14 lr 5.535051	time 1.2885 (1.8039)	loss 3.5506 (3.6326)	grad_norm 0.3185 (0.3501)	mem 39782MB
[2023-07-07 09:53:56 RepVGG-A0] (main.py 291): INFO EPOCH 71 training takes 0:02:20
[2023-07-07 09:54:18 RepVGG-A0] (main.py 282): INFO Train: [72/300][0/78]	eta 0:28:06 lr 5.532700	time 21.6256 (21.6256)	loss 3.5130 (3.5130)	grad_norm 0.2911 (0.2911)	mem 39782MB
[2023-07-07 09:54:32 RepVGG-A0] (main.py 282): INFO Train: [72/300][10/78]	eta 0:03:42 lr 5.529757	time 1.1724 (3.2699)	loss 3.4709 (3.4381)	grad_norm 0.3112 (0.3135)	mem 39782MB
[2023-07-07 09:54:48 RepVGG-A0] (main.py 282): INFO Train: [72/300][20/78]	eta 0:02:22 lr 5.526809	time 1.2342 (2.4523)	loss 3.6535 (3.5166)	grad_norm 0.3500 (0.3556)	mem 39782MB
[2023-07-07 09:55:04 RepVGG-A0] (main.py 282): INFO Train: [72/300][30/78]	eta 0:01:44 lr 5.523858	time 1.7228 (2.1730)	loss 3.4072 (3.5036)	grad_norm 0.3324 (0.3452)	mem 39782MB
[2023-07-07 09:55:21 RepVGG-A0] (main.py 282): INFO Train: [72/300][40/78]	eta 0:01:18 lr 5.520902	time 4.1351 (2.0564)	loss 3.5466 (3.5053)	grad_norm 0.3531 (0.3500)	mem 39782MB
[2023-07-07 09:55:36 RepVGG-A0] (main.py 282): INFO Train: [72/300][50/78]	eta 0:00:54 lr 5.517942	time 1.1718 (1.9459)	loss 3.4456 (3.4965)	grad_norm 0.3320 (0.3453)	mem 39782MB
[2023-07-07 09:55:50 RepVGG-A0] (main.py 282): INFO Train: [72/300][60/78]	eta 0:00:33 lr 5.514978	time 1.3346 (1.8674)	loss 3.5965 (3.4981)	grad_norm 0.4239 (0.3478)	mem 39782MB
[2023-07-07 09:56:06 RepVGG-A0] (main.py 282): INFO Train: [72/300][70/78]	eta 0:00:14 lr 5.512010	time 1.2436 (1.8218)	loss 5.4827 (3.6411)	grad_norm 0.8740 (0.4036)	mem 39782MB
[2023-07-07 09:56:18 RepVGG-A0] (main.py 291): INFO EPOCH 72 training takes 0:02:21
[2023-07-07 09:56:39 RepVGG-A0] (main.py 282): INFO Train: [73/300][0/78]	eta 0:28:13 lr 5.509633	time 21.7126 (21.7126)	loss 4.8151 (4.8151)	grad_norm 0.3197 (0.3197)	mem 39782MB
[2023-07-07 09:56:54 RepVGG-A0] (main.py 282): INFO Train: [73/300][10/78]	eta 0:03:44 lr 5.506657	time 1.1902 (3.3085)	loss 4.0722 (4.3813)	grad_norm 0.2373 (0.2861)	mem 39782MB
[2023-07-07 09:57:09 RepVGG-A0] (main.py 282): INFO Train: [73/300][20/78]	eta 0:02:21 lr 5.503677	time 1.3901 (2.4402)	loss 3.9463 (4.2411)	grad_norm 0.2448 (0.3022)	mem 39782MB
[2023-07-07 09:57:24 RepVGG-A0] (main.py 282): INFO Train: [73/300][30/78]	eta 0:01:42 lr 5.500693	time 1.2441 (2.1312)	loss 3.7072 (4.0931)	grad_norm 0.2543 (0.2828)	mem 39782MB
[2023-07-07 09:57:42 RepVGG-A0] (main.py 282): INFO Train: [73/300][40/78]	eta 0:01:18 lr 5.497705	time 3.5303 (2.0551)	loss 3.5064 (3.9942)	grad_norm 0.2672 (0.2799)	mem 39782MB
[2023-07-07 09:57:57 RepVGG-A0] (main.py 282): INFO Train: [73/300][50/78]	eta 0:00:54 lr 5.494713	time 1.1721 (1.9432)	loss 3.6333 (3.9214)	grad_norm 0.3221 (0.2826)	mem 39782MB
[2023-07-07 09:58:12 RepVGG-A0] (main.py 282): INFO Train: [73/300][60/78]	eta 0:00:33 lr 5.491716	time 1.3584 (1.8675)	loss 3.5891 (3.8684)	grad_norm 0.2941 (0.2880)	mem 39782MB
[2023-07-07 09:58:26 RepVGG-A0] (main.py 282): INFO Train: [73/300][70/78]	eta 0:00:14 lr 5.488716	time 1.1701 (1.8096)	loss 3.6735 (3.8258)	grad_norm 0.3572 (0.2900)	mem 39782MB
[2023-07-07 09:58:38 RepVGG-A0] (main.py 291): INFO EPOCH 73 training takes 0:02:20
[2023-07-07 09:59:00 RepVGG-A0] (main.py 282): INFO Train: [74/300][0/78]	eta 0:27:57 lr 5.486313	time 21.5055 (21.5055)	loss 3.5503 (3.5503)	grad_norm 0.3862 (0.3862)	mem 39782MB
[2023-07-07 09:59:15 RepVGG-A0] (main.py 282): INFO Train: [74/300][10/78]	eta 0:03:48 lr 5.483305	time 1.1716 (3.3604)	loss 3.4061 (3.5569)	grad_norm 0.2935 (0.3335)	mem 39782MB
[2023-07-07 09:59:30 RepVGG-A0] (main.py 282): INFO Train: [74/300][20/78]	eta 0:02:22 lr 5.480293	time 1.1754 (2.4606)	loss 3.6581 (3.5483)	grad_norm 0.3946 (0.3368)	mem 39782MB
[2023-07-07 09:59:46 RepVGG-A0] (main.py 282): INFO Train: [74/300][30/78]	eta 0:01:44 lr 5.477276	time 1.2343 (2.1751)	loss 3.4510 (3.5450)	grad_norm 0.2881 (0.3353)	mem 39782MB
[2023-07-07 10:00:04 RepVGG-A0] (main.py 282): INFO Train: [74/300][40/78]	eta 0:01:19 lr 5.474256	time 4.0086 (2.0888)	loss 3.4865 (3.5351)	grad_norm 0.3264 (0.3352)	mem 39782MB
[2023-07-07 10:00:18 RepVGG-A0] (main.py 282): INFO Train: [74/300][50/78]	eta 0:00:54 lr 5.471232	time 1.1726 (1.9605)	loss 3.5772 (3.5327)	grad_norm 0.3907 (0.3412)	mem 39782MB
[2023-07-07 10:00:34 RepVGG-A0] (main.py 282): INFO Train: [74/300][60/78]	eta 0:00:33 lr 5.468203	time 1.3040 (1.8884)	loss 3.5042 (3.5300)	grad_norm 0.3227 (0.3421)	mem 39782MB
[2023-07-07 10:00:50 RepVGG-A0] (main.py 282): INFO Train: [74/300][70/78]	eta 0:00:14 lr 5.465171	time 1.3097 (1.8517)	loss 3.7183 (3.5297)	grad_norm 0.4644 (0.3466)	mem 39782MB
[2023-07-07 10:01:01 RepVGG-A0] (main.py 291): INFO EPOCH 74 training takes 0:02:22
[2023-07-07 10:01:22 RepVGG-A0] (main.py 282): INFO Train: [75/300][0/78]	eta 0:26:52 lr 5.462742	time 20.6678 (20.6678)	loss 3.4608 (3.4608)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 10:01:36 RepVGG-A0] (main.py 282): INFO Train: [75/300][10/78]	eta 0:03:38 lr 5.459702	time 1.1724 (3.2123)	loss 3.5256 (3.4836)	grad_norm 0.3977 (0.3616)	mem 39782MB
[2023-07-07 10:01:51 RepVGG-A0] (main.py 282): INFO Train: [75/300][20/78]	eta 0:02:17 lr 5.456658	time 1.1706 (2.3759)	loss 3.3967 (3.4519)	grad_norm 0.3402 (0.3409)	mem 39782MB
[2023-07-07 10:02:07 RepVGG-A0] (main.py 282): INFO Train: [75/300][30/78]	eta 0:01:41 lr 5.453610	time 1.3381 (2.1115)	loss 3.6680 (3.4965)	grad_norm 0.4109 (0.3673)	mem 39782MB
[2023-07-07 10:02:24 RepVGG-A0] (main.py 282): INFO Train: [75/300][40/78]	eta 0:01:16 lr 5.450558	time 2.7848 (2.0138)	loss 3.4180 (3.4885)	grad_norm 0.2769 (0.3562)	mem 39782MB
[2023-07-07 10:02:41 RepVGG-A0] (main.py 282): INFO Train: [75/300][50/78]	eta 0:00:54 lr 5.447501	time 1.2428 (1.9631)	loss 3.3899 (3.4863)	grad_norm 0.3503 (0.3551)	mem 39782MB
[2023-07-07 10:02:57 RepVGG-A0] (main.py 282): INFO Train: [75/300][60/78]	eta 0:00:34 lr 5.444441	time 1.2527 (1.8946)	loss 3.4042 (3.4736)	grad_norm 0.3656 (0.3504)	mem 39782MB
[2023-07-07 10:03:12 RepVGG-A0] (main.py 282): INFO Train: [75/300][70/78]	eta 0:00:14 lr 5.441377	time 1.1715 (1.8435)	loss 3.5113 (3.5019)	grad_norm 0.3341 (0.3662)	mem 39782MB
[2023-07-07 10:03:23 RepVGG-A0] (main.py 291): INFO EPOCH 75 training takes 0:02:21
[2023-07-07 10:03:44 RepVGG-A0] (main.py 282): INFO Train: [76/300][0/78]	eta 0:27:43 lr 5.438923	time 21.3255 (21.3255)	loss 3.3819 (3.3819)	grad_norm 0.2974 (0.2974)	mem 39782MB
[2023-07-07 10:04:01 RepVGG-A0] (main.py 282): INFO Train: [76/300][10/78]	eta 0:03:52 lr 5.435851	time 1.1976 (3.4207)	loss 3.4003 (3.4034)	grad_norm 0.3213 (0.3309)	mem 39782MB
[2023-07-07 10:04:15 RepVGG-A0] (main.py 282): INFO Train: [76/300][20/78]	eta 0:02:22 lr 5.432776	time 1.3135 (2.4553)	loss 3.3433 (3.3827)	grad_norm 0.3448 (0.3281)	mem 39782MB
[2023-07-07 10:04:30 RepVGG-A0] (main.py 282): INFO Train: [76/300][30/78]	eta 0:01:43 lr 5.429696	time 1.5004 (2.1519)	loss 3.4970 (3.4208)	grad_norm 0.4127 (0.3527)	mem 39782MB
[2023-07-07 10:04:47 RepVGG-A0] (main.py 282): INFO Train: [76/300][40/78]	eta 0:01:18 lr 5.426612	time 3.6100 (2.0594)	loss 3.3794 (3.4310)	grad_norm 0.3175 (0.3496)	mem 39782MB
[2023-07-07 10:05:02 RepVGG-A0] (main.py 282): INFO Train: [76/300][50/78]	eta 0:00:54 lr 5.423525	time 1.3603 (1.9475)	loss 3.4002 (3.4285)	grad_norm 0.3627 (0.3508)	mem 39782MB
[2023-07-07 10:05:18 RepVGG-A0] (main.py 282): INFO Train: [76/300][60/78]	eta 0:00:33 lr 5.420433	time 1.1851 (1.8801)	loss 3.4506 (3.4246)	grad_norm 0.3779 (0.3503)	mem 39782MB
[2023-07-07 10:05:32 RepVGG-A0] (main.py 282): INFO Train: [76/300][70/78]	eta 0:00:14 lr 5.417338	time 1.1804 (1.8177)	loss 5.4164 (3.5065)	grad_norm 1.0900 (0.3931)	mem 39782MB
[2023-07-07 10:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 76 training takes 0:02:20
[2023-07-07 10:06:06 RepVGG-A0] (main.py 282): INFO Train: [77/300][0/78]	eta 0:28:56 lr 5.414858	time 22.2657 (22.2657)	loss 5.2520 (5.2520)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 10:06:20 RepVGG-A0] (main.py 282): INFO Train: [77/300][10/78]	eta 0:03:41 lr 5.411755	time 1.1718 (3.2572)	loss 4.4956 (4.8316)	grad_norm 0.3152 (0.3642)	mem 39782MB
[2023-07-07 10:06:34 RepVGG-A0] (main.py 282): INFO Train: [77/300][20/78]	eta 0:02:18 lr 5.408649	time 1.1915 (2.3810)	loss 4.0897 (4.5344)	grad_norm 0.2650 (0.3186)	mem 39782MB
[2023-07-07 10:06:50 RepVGG-A0] (main.py 282): INFO Train: [77/300][30/78]	eta 0:01:42 lr 5.405538	time 1.2479 (2.1251)	loss 3.9717 (4.3444)	grad_norm 0.3430 (0.3121)	mem 39782MB
[2023-07-07 10:07:08 RepVGG-A0] (main.py 282): INFO Train: [77/300][40/78]	eta 0:01:18 lr 5.402423	time 4.3112 (2.0601)	loss 3.7447 (4.2052)	grad_norm 0.3259 (0.3036)	mem 39782MB
[2023-07-07 10:07:23 RepVGG-A0] (main.py 282): INFO Train: [77/300][50/78]	eta 0:00:54 lr 5.399304	time 1.1732 (1.9346)	loss 3.7280 (4.1149)	grad_norm 0.3076 (0.3064)	mem 39782MB
[2023-07-07 10:07:39 RepVGG-A0] (main.py 282): INFO Train: [77/300][60/78]	eta 0:00:33 lr 5.396182	time 1.1969 (1.8797)	loss 3.6382 (4.0353)	grad_norm 0.3446 (0.3027)	mem 39782MB
[2023-07-07 10:07:54 RepVGG-A0] (main.py 282): INFO Train: [77/300][70/78]	eta 0:00:14 lr 5.393055	time 1.3748 (1.8307)	loss 3.6134 (3.9869)	grad_norm 0.2742 (0.3071)	mem 39782MB
[2023-07-07 10:08:06 RepVGG-A0] (main.py 291): INFO EPOCH 77 training takes 0:02:21
[2023-07-07 10:08:27 RepVGG-A0] (main.py 282): INFO Train: [78/300][0/78]	eta 0:28:18 lr 5.390551	time 21.7812 (21.7812)	loss 3.5423 (3.5423)	grad_norm 0.3382 (0.3382)	mem 39782MB
[2023-07-07 10:08:42 RepVGG-A0] (main.py 282): INFO Train: [78/300][10/78]	eta 0:03:43 lr 5.387417	time 1.1709 (3.2892)	loss 3.4561 (3.5360)	grad_norm 0.2988 (0.3343)	mem 39782MB
[2023-07-07 10:08:57 RepVGG-A0] (main.py 282): INFO Train: [78/300][20/78]	eta 0:02:21 lr 5.384279	time 1.2008 (2.4418)	loss 3.6154 (3.5525)	grad_norm 0.3817 (0.3522)	mem 39782MB
[2023-07-07 10:09:11 RepVGG-A0] (main.py 282): INFO Train: [78/300][30/78]	eta 0:01:41 lr 5.381138	time 1.1913 (2.1165)	loss 3.5064 (3.5403)	grad_norm 0.3380 (0.3396)	mem 39782MB
[2023-07-07 10:09:30 RepVGG-A0] (main.py 282): INFO Train: [78/300][40/78]	eta 0:01:18 lr 5.377992	time 3.3206 (2.0601)	loss 3.4875 (3.5317)	grad_norm 0.3562 (0.3401)	mem 39782MB
[2023-07-07 10:09:46 RepVGG-A0] (main.py 282): INFO Train: [78/300][50/78]	eta 0:00:54 lr 5.374843	time 1.1732 (1.9610)	loss 3.5874 (3.5356)	grad_norm 0.3894 (0.3455)	mem 39782MB
[2023-07-07 10:10:01 RepVGG-A0] (main.py 282): INFO Train: [78/300][60/78]	eta 0:00:33 lr 5.371689	time 1.4102 (1.8858)	loss 3.5717 (3.5314)	grad_norm 0.3290 (0.3454)	mem 39782MB
[2023-07-07 10:10:15 RepVGG-A0] (main.py 282): INFO Train: [78/300][70/78]	eta 0:00:14 lr 5.368532	time 1.1261 (1.8257)	loss 3.7802 (3.5256)	grad_norm 0.5386 (0.3483)	mem 39782MB
[2023-07-07 10:10:27 RepVGG-A0] (main.py 291): INFO EPOCH 78 training takes 0:02:21
[2023-07-07 10:10:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][0/78]	eta 0:28:38 lr 5.366003	time 22.0310 (22.0310)	loss 3.6995 (3.6995)	grad_norm 0.3883 (0.3883)	mem 39782MB
[2023-07-07 10:11:03 RepVGG-A0] (main.py 282): INFO Train: [79/300][10/78]	eta 0:03:42 lr 5.362839	time 1.1703 (3.2752)	loss 3.4591 (3.5795)	grad_norm 0.2665 (0.3224)	mem 39782MB
[2023-07-07 10:11:17 RepVGG-A0] (main.py 282): INFO Train: [79/300][20/78]	eta 0:02:16 lr 5.359670	time 1.1900 (2.3594)	loss 3.4233 (3.4954)	grad_norm 0.3262 (0.3080)	mem 39782MB
[2023-07-07 10:11:32 RepVGG-A0] (main.py 282): INFO Train: [79/300][30/78]	eta 0:01:40 lr 5.356498	time 1.5094 (2.1030)	loss 3.5701 (3.4867)	grad_norm 0.3432 (0.3223)	mem 39782MB
[2023-07-07 10:11:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][40/78]	eta 0:01:16 lr 5.353322	time 1.9137 (2.0005)	loss 3.3348 (3.4777)	grad_norm 0.3033 (0.3284)	mem 39782MB
[2023-07-07 10:12:05 RepVGG-A0] (main.py 282): INFO Train: [79/300][50/78]	eta 0:00:53 lr 5.350142	time 1.3035 (1.9214)	loss 3.5594 (3.4719)	grad_norm 0.3717 (0.3329)	mem 39782MB
[2023-07-07 10:12:21 RepVGG-A0] (main.py 282): INFO Train: [79/300][60/78]	eta 0:00:33 lr 5.346959	time 1.2245 (1.8655)	loss 3.4616 (3.4646)	grad_norm 0.3667 (0.3314)	mem 39782MB
[2023-07-07 10:12:36 RepVGG-A0] (main.py 282): INFO Train: [79/300][70/78]	eta 0:00:14 lr 5.343771	time 1.3375 (1.8196)	loss 4.1238 (3.5049)	grad_norm 0.7083 (0.3583)	mem 39782MB
[2023-07-07 10:12:47 RepVGG-A0] (main.py 291): INFO EPOCH 79 training takes 0:02:20
[2023-07-07 10:13:07 RepVGG-A0] (main.py 282): INFO Train: [80/300][0/78]	eta 0:25:56 lr 5.341218	time 19.9586 (19.9586)	loss 3.7852 (3.7852)	grad_norm 0.3243 (0.3243)	mem 39782MB
[2023-07-07 10:13:22 RepVGG-A0] (main.py 282): INFO Train: [80/300][10/78]	eta 0:03:36 lr 5.338023	time 1.1898 (3.1799)	loss 3.5526 (3.5864)	grad_norm 0.2977 (0.2853)	mem 39782MB
[2023-07-07 10:13:38 RepVGG-A0] (main.py 282): INFO Train: [80/300][20/78]	eta 0:02:19 lr 5.334825	time 1.1281 (2.4009)	loss 3.5424 (3.5291)	grad_norm 0.3072 (0.2960)	mem 39782MB
[2023-07-07 10:13:53 RepVGG-A0] (main.py 282): INFO Train: [80/300][30/78]	eta 0:01:42 lr 5.331623	time 1.3881 (2.1258)	loss 3.3263 (3.4871)	grad_norm 0.2722 (0.2921)	mem 39782MB
[2023-07-07 10:14:11 RepVGG-A0] (main.py 282): INFO Train: [80/300][40/78]	eta 0:01:17 lr 5.328416	time 4.3317 (2.0493)	loss 3.4424 (3.4556)	grad_norm 0.3658 (0.2937)	mem 39782MB
[2023-07-07 10:14:27 RepVGG-A0] (main.py 282): INFO Train: [80/300][50/78]	eta 0:00:54 lr 5.325206	time 1.1731 (1.9423)	loss 3.4763 (3.4612)	grad_norm 0.3275 (0.3082)	mem 39782MB
[2023-07-07 10:14:41 RepVGG-A0] (main.py 282): INFO Train: [80/300][60/78]	eta 0:00:33 lr 5.321993	time 1.1261 (1.8663)	loss 3.5386 (3.4498)	grad_norm 0.4813 (0.3119)	mem 39782MB
[2023-07-07 10:14:56 RepVGG-A0] (main.py 282): INFO Train: [80/300][70/78]	eta 0:00:14 lr 5.318775	time 1.3842 (1.8151)	loss 4.7350 (3.6103)	grad_norm 0.5154 (0.3707)	mem 39782MB
[2023-07-07 10:15:08 RepVGG-A0] (main.py 291): INFO EPOCH 80 training takes 0:02:20
[2023-07-07 10:15:25 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.024 (17.024)	Loss 5.1657 (5.1657)	Acc@1 11.731 (11.731)	Acc@5 27.191 (27.191)	Mem 39782MB
[2023-07-07 10:15:26 RepVGG-A0] (main.py 342): INFO  * Acc@1 11.640 Acc@5 26.608
[2023-07-07 10:15:26 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 80: 11.640%
[2023-07-07 10:15:26 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 10:15:46 RepVGG-A0] (main.py 282): INFO Train: [81/300][0/78]	eta 0:25:22 lr 5.316198	time 19.5132 (19.5132)	loss 3.8880 (3.8880)	grad_norm 0.2790 (0.2790)	mem 39782MB
[2023-07-07 10:16:01 RepVGG-A0] (main.py 282): INFO Train: [81/300][10/78]	eta 0:03:37 lr 5.312973	time 1.1699 (3.1935)	loss 3.5950 (3.7177)	grad_norm 0.2627 (0.2694)	mem 39782MB
[2023-07-07 10:16:16 RepVGG-A0] (main.py 282): INFO Train: [81/300][20/78]	eta 0:02:16 lr 5.309745	time 1.1907 (2.3559)	loss 3.5184 (3.6532)	grad_norm 0.2382 (0.2740)	mem 39782MB
[2023-07-07 10:16:31 RepVGG-A0] (main.py 282): INFO Train: [81/300][30/78]	eta 0:01:40 lr 5.306513	time 1.2242 (2.0854)	loss 3.4464 (3.5990)	grad_norm 0.2845 (0.2751)	mem 39782MB
[2023-07-07 10:16:49 RepVGG-A0] (main.py 282): INFO Train: [81/300][40/78]	eta 0:01:16 lr 5.303277	time 2.5281 (2.0195)	loss 3.4021 (3.5563)	grad_norm 0.2972 (0.2759)	mem 39782MB
[2023-07-07 10:17:06 RepVGG-A0] (main.py 282): INFO Train: [81/300][50/78]	eta 0:00:54 lr 5.300037	time 2.6889 (1.9512)	loss 3.5159 (3.5328)	grad_norm 0.3083 (0.2858)	mem 39782MB
[2023-07-07 10:17:21 RepVGG-A0] (main.py 282): INFO Train: [81/300][60/78]	eta 0:00:33 lr 5.296794	time 1.1975 (1.8736)	loss 3.3551 (3.5056)	grad_norm 0.3078 (0.2882)	mem 39782MB
[2023-07-07 10:17:36 RepVGG-A0] (main.py 282): INFO Train: [81/300][70/78]	eta 0:00:14 lr 5.293546	time 1.1730 (1.8222)	loss 3.3051 (3.4895)	grad_norm 0.3443 (0.2952)	mem 39782MB
[2023-07-07 10:17:48 RepVGG-A0] (main.py 291): INFO EPOCH 81 training takes 0:02:21
[2023-07-07 10:18:08 RepVGG-A0] (main.py 282): INFO Train: [82/300][0/78]	eta 0:26:49 lr 5.290946	time 20.6282 (20.6282)	loss 3.3754 (3.3754)	grad_norm 0.3601 (0.3601)	mem 39782MB
[2023-07-07 10:18:23 RepVGG-A0] (main.py 282): INFO Train: [82/300][10/78]	eta 0:03:37 lr 5.287692	time 1.1722 (3.1952)	loss 3.3866 (3.3755)	grad_norm 0.2981 (0.3495)	mem 39782MB
[2023-07-07 10:18:38 RepVGG-A0] (main.py 282): INFO Train: [82/300][20/78]	eta 0:02:19 lr 5.284434	time 1.1731 (2.4018)	loss 3.4421 (3.3805)	grad_norm 0.3628 (0.3463)	mem 39782MB
[2023-07-07 10:18:52 RepVGG-A0] (main.py 282): INFO Train: [82/300][30/78]	eta 0:01:39 lr 5.281172	time 1.1938 (2.0800)	loss 3.3400 (3.3671)	grad_norm 0.3732 (0.3417)	mem 39782MB
[2023-07-07 10:19:11 RepVGG-A0] (main.py 282): INFO Train: [82/300][40/78]	eta 0:01:16 lr 5.277907	time 3.9558 (2.0247)	loss 4.5916 (3.4763)	grad_norm 0.8830 (0.4006)	mem 39782MB
[2023-07-07 10:19:26 RepVGG-A0] (main.py 282): INFO Train: [82/300][50/78]	eta 0:00:53 lr 5.274638	time 1.1725 (1.9234)	loss 3.8459 (3.6328)	grad_norm 0.3246 (0.4212)	mem 39782MB
[2023-07-07 10:19:42 RepVGG-A0] (main.py 282): INFO Train: [82/300][60/78]	eta 0:00:33 lr 5.271365	time 1.3686 (1.8658)	loss 3.5571 (3.6355)	grad_norm 0.2857 (0.3992)	mem 39782MB
[2023-07-07 10:19:55 RepVGG-A0] (main.py 282): INFO Train: [82/300][70/78]	eta 0:00:14 lr 5.268089	time 1.1730 (1.7965)	loss 3.3697 (3.6147)	grad_norm 0.2560 (0.3825)	mem 39782MB
[2023-07-07 10:20:08 RepVGG-A0] (main.py 291): INFO EPOCH 82 training takes 0:02:19
[2023-07-07 10:20:29 RepVGG-A0] (main.py 282): INFO Train: [83/300][0/78]	eta 0:28:02 lr 5.265465	time 21.5713 (21.5713)	loss 3.3658 (3.3658)	grad_norm 0.3216 (0.3216)	mem 39782MB
[2023-07-07 10:20:44 RepVGG-A0] (main.py 282): INFO Train: [83/300][10/78]	eta 0:03:42 lr 5.262181	time 1.1724 (3.2754)	loss 3.3504 (3.3326)	grad_norm 0.3384 (0.3006)	mem 39782MB
[2023-07-07 10:20:58 RepVGG-A0] (main.py 282): INFO Train: [83/300][20/78]	eta 0:02:18 lr 5.258894	time 1.1731 (2.3946)	loss 3.4647 (3.3745)	grad_norm 0.3841 (0.3199)	mem 39782MB
[2023-07-07 10:21:14 RepVGG-A0] (main.py 282): INFO Train: [83/300][30/78]	eta 0:01:42 lr 5.255604	time 1.3987 (2.1331)	loss 3.3244 (3.3828)	grad_norm 0.3160 (0.3292)	mem 39782MB
[2023-07-07 10:21:32 RepVGG-A0] (main.py 282): INFO Train: [83/300][40/78]	eta 0:01:18 lr 5.252309	time 4.2796 (2.0629)	loss 3.4129 (3.3706)	grad_norm 0.3920 (0.3250)	mem 39782MB
[2023-07-07 10:21:46 RepVGG-A0] (main.py 282): INFO Train: [83/300][50/78]	eta 0:00:54 lr 5.249011	time 1.1908 (1.9291)	loss 3.4039 (3.3711)	grad_norm 0.3291 (0.3297)	mem 39782MB
[2023-07-07 10:22:02 RepVGG-A0] (main.py 282): INFO Train: [83/300][60/78]	eta 0:00:33 lr 5.245709	time 1.3594 (1.8684)	loss 3.4216 (3.3761)	grad_norm 0.3200 (0.3347)	mem 39782MB
[2023-07-07 10:22:16 RepVGG-A0] (main.py 282): INFO Train: [83/300][70/78]	eta 0:00:14 lr 5.242404	time 1.1269 (1.8114)	loss 3.3710 (3.3733)	grad_norm 0.3974 (0.3345)	mem 39782MB
[2023-07-07 10:22:28 RepVGG-A0] (main.py 291): INFO EPOCH 83 training takes 0:02:19
[2023-07-07 10:22:49 RepVGG-A0] (main.py 282): INFO Train: [84/300][0/78]	eta 0:27:45 lr 5.239757	time 21.3565 (21.3565)	loss 3.5957 (3.5957)	grad_norm 0.5047 (0.5047)	mem 39782MB
[2023-07-07 10:23:03 RepVGG-A0] (main.py 282): INFO Train: [84/300][10/78]	eta 0:03:38 lr 5.236445	time 1.1725 (3.2187)	loss 3.2780 (3.4075)	grad_norm 0.2995 (0.3506)	mem 39782MB
[2023-07-07 10:23:18 RepVGG-A0] (main.py 282): INFO Train: [84/300][20/78]	eta 0:02:19 lr 5.233129	time 1.1718 (2.4083)	loss 3.3710 (3.3863)	grad_norm 0.3304 (0.3447)	mem 39782MB
[2023-07-07 10:23:33 RepVGG-A0] (main.py 282): INFO Train: [84/300][30/78]	eta 0:01:41 lr 5.229809	time 1.4382 (2.1197)	loss 3.4786 (3.3850)	grad_norm 0.4088 (0.3489)	mem 39782MB
[2023-07-07 10:23:51 RepVGG-A0] (main.py 282): INFO Train: [84/300][40/78]	eta 0:01:17 lr 5.226486	time 4.5280 (2.0433)	loss 3.3769 (3.3767)	grad_norm 0.3027 (0.3448)	mem 39782MB
[2023-07-07 10:24:06 RepVGG-A0] (main.py 282): INFO Train: [84/300][50/78]	eta 0:00:53 lr 5.223160	time 1.1720 (1.9276)	loss 3.4411 (3.3762)	grad_norm 0.3730 (0.3488)	mem 39782MB
[2023-07-07 10:24:21 RepVGG-A0] (main.py 282): INFO Train: [84/300][60/78]	eta 0:00:33 lr 5.219829	time 1.1856 (1.8593)	loss 3.4467 (3.3764)	grad_norm 0.4371 (0.3504)	mem 39782MB
[2023-07-07 10:24:36 RepVGG-A0] (main.py 282): INFO Train: [84/300][70/78]	eta 0:00:14 lr 5.216495	time 1.4540 (1.8108)	loss 3.2891 (3.3807)	grad_norm 0.2982 (0.3514)	mem 39782MB
[2023-07-07 10:24:47 RepVGG-A0] (main.py 291): INFO EPOCH 84 training takes 0:02:19
[2023-07-07 10:25:09 RepVGG-A0] (main.py 282): INFO Train: [85/300][0/78]	eta 0:27:57 lr 5.213825	time 21.5046 (21.5046)	loss 3.3822 (3.3822)	grad_norm 0.4159 (0.4159)	mem 39782MB
[2023-07-07 10:25:22 RepVGG-A0] (main.py 282): INFO Train: [85/300][10/78]	eta 0:03:36 lr 5.210485	time 1.1883 (3.1880)	loss 3.8943 (3.6093)	grad_norm 0.5796 (0.5154)	mem 39782MB
[2023-07-07 10:25:37 RepVGG-A0] (main.py 282): INFO Train: [85/300][20/78]	eta 0:02:17 lr 5.207140	time 1.1720 (2.3774)	loss 3.3227 (3.5845)	grad_norm 0.2774 (0.4386)	mem 39782MB
[2023-07-07 10:25:52 RepVGG-A0] (main.py 282): INFO Train: [85/300][30/78]	eta 0:01:40 lr 5.203793	time 1.3689 (2.0880)	loss 3.2904 (3.5030)	grad_norm 0.3069 (0.3939)	mem 39782MB
[2023-07-07 10:26:10 RepVGG-A0] (main.py 282): INFO Train: [85/300][40/78]	eta 0:01:16 lr 5.200441	time 3.6025 (2.0251)	loss 3.3110 (3.4527)	grad_norm 0.3181 (0.3711)	mem 39782MB
[2023-07-07 10:26:25 RepVGG-A0] (main.py 282): INFO Train: [85/300][50/78]	eta 0:00:53 lr 5.197086	time 1.1734 (1.9266)	loss 3.3139 (3.4265)	grad_norm 0.3898 (0.3666)	mem 39782MB
[2023-07-07 10:26:41 RepVGG-A0] (main.py 282): INFO Train: [85/300][60/78]	eta 0:00:33 lr 5.193728	time 1.1810 (1.8615)	loss 3.3461 (3.4121)	grad_norm 0.3192 (0.3636)	mem 39782MB
[2023-07-07 10:26:56 RepVGG-A0] (main.py 282): INFO Train: [85/300][70/78]	eta 0:00:14 lr 5.190365	time 1.1728 (1.8163)	loss 3.2958 (3.3967)	grad_norm 0.3511 (0.3602)	mem 39782MB
[2023-07-07 10:27:07 RepVGG-A0] (main.py 291): INFO EPOCH 85 training takes 0:02:20
[2023-07-07 10:27:28 RepVGG-A0] (main.py 282): INFO Train: [86/300][0/78]	eta 0:27:16 lr 5.187673	time 20.9776 (20.9776)	loss 3.6790 (3.6790)	grad_norm 0.5963 (0.5963)	mem 39782MB
[2023-07-07 10:27:44 RepVGG-A0] (main.py 282): INFO Train: [86/300][10/78]	eta 0:03:45 lr 5.184304	time 1.1719 (3.3184)	loss 5.2562 (4.4873)	grad_norm 0.7889 (0.7841)	mem 39782MB
[2023-07-07 10:27:59 RepVGG-A0] (main.py 282): INFO Train: [86/300][20/78]	eta 0:02:21 lr 5.180932	time 1.3194 (2.4430)	loss 4.0756 (4.5502)	grad_norm 0.2884 (0.6187)	mem 39782MB
[2023-07-07 10:28:14 RepVGG-A0] (main.py 282): INFO Train: [86/300][30/78]	eta 0:01:42 lr 5.177556	time 1.3948 (2.1336)	loss 3.9241 (4.3439)	grad_norm 0.3546 (0.5155)	mem 39782MB
[2023-07-07 10:28:33 RepVGG-A0] (main.py 282): INFO Train: [86/300][40/78]	eta 0:01:18 lr 5.174177	time 4.3430 (2.0780)	loss 3.5348 (4.1696)	grad_norm 0.2587 (0.4501)	mem 39782MB
[2023-07-07 10:28:48 RepVGG-A0] (main.py 282): INFO Train: [86/300][50/78]	eta 0:00:54 lr 5.170794	time 1.3005 (1.9632)	loss 3.4713 (4.0396)	grad_norm 0.2524 (0.4154)	mem 39782MB
[2023-07-07 10:29:03 RepVGG-A0] (main.py 282): INFO Train: [86/300][60/78]	eta 0:00:34 lr 5.167407	time 1.3670 (1.8914)	loss 3.4456 (3.9445)	grad_norm 0.2897 (0.3935)	mem 39782MB
[2023-07-07 10:29:17 RepVGG-A0] (main.py 282): INFO Train: [86/300][70/78]	eta 0:00:14 lr 5.164017	time 1.1248 (1.8205)	loss 3.4555 (3.8729)	grad_norm 0.3005 (0.3827)	mem 39782MB
[2023-07-07 10:29:29 RepVGG-A0] (main.py 291): INFO EPOCH 86 training takes 0:02:21
[2023-07-07 10:29:50 RepVGG-A0] (main.py 282): INFO Train: [87/300][0/78]	eta 0:28:09 lr 5.161303	time 21.6640 (21.6640)	loss 3.3687 (3.3687)	grad_norm 0.3264 (0.3264)	mem 39782MB
[2023-07-07 10:30:06 RepVGG-A0] (main.py 282): INFO Train: [87/300][10/78]	eta 0:03:49 lr 5.157906	time 1.1896 (3.3777)	loss 3.3053 (3.3664)	grad_norm 0.3041 (0.3253)	mem 39782MB
[2023-07-07 10:30:21 RepVGG-A0] (main.py 282): INFO Train: [87/300][20/78]	eta 0:02:23 lr 5.154506	time 1.2142 (2.4768)	loss 3.5213 (3.3727)	grad_norm 0.4556 (0.3385)	mem 39782MB
[2023-07-07 10:30:36 RepVGG-A0] (main.py 282): INFO Train: [87/300][30/78]	eta 0:01:43 lr 5.151103	time 1.4071 (2.1624)	loss 3.2976 (3.3616)	grad_norm 0.3088 (0.3321)	mem 39782MB
[2023-07-07 10:30:54 RepVGG-A0] (main.py 282): INFO Train: [87/300][40/78]	eta 0:01:18 lr 5.147696	time 4.0763 (2.0768)	loss 3.4645 (3.3602)	grad_norm 0.3761 (0.3334)	mem 39782MB
[2023-07-07 10:31:08 RepVGG-A0] (main.py 282): INFO Train: [87/300][50/78]	eta 0:00:54 lr 5.144285	time 1.1902 (1.9593)	loss 3.2802 (3.3559)	grad_norm 0.2973 (0.3326)	mem 39782MB
[2023-07-07 10:31:23 RepVGG-A0] (main.py 282): INFO Train: [87/300][60/78]	eta 0:00:33 lr 5.140871	time 1.1745 (1.8815)	loss 3.3747 (3.3651)	grad_norm 0.3193 (0.3411)	mem 39782MB
[2023-07-07 10:31:39 RepVGG-A0] (main.py 282): INFO Train: [87/300][70/78]	eta 0:00:14 lr 5.137454	time 1.2920 (1.8363)	loss 3.4161 (3.3638)	grad_norm 0.3821 (0.3391)	mem 39782MB
[2023-07-07 10:31:50 RepVGG-A0] (main.py 291): INFO EPOCH 87 training takes 0:02:21
[2023-07-07 10:32:13 RepVGG-A0] (main.py 282): INFO Train: [88/300][0/78]	eta 0:28:54 lr 5.134717	time 22.2390 (22.2390)	loss 3.3336 (3.3336)	grad_norm 0.3599 (0.3599)	mem 39782MB
[2023-07-07 10:32:28 RepVGG-A0] (main.py 282): INFO Train: [88/300][10/78]	eta 0:03:54 lr 5.131293	time 1.1901 (3.4485)	loss 3.3149 (3.3688)	grad_norm 0.3363 (0.3783)	mem 39782MB
[2023-07-07 10:32:43 RepVGG-A0] (main.py 282): INFO Train: [88/300][20/78]	eta 0:02:26 lr 5.127866	time 1.3793 (2.5221)	loss 3.2455 (3.3337)	grad_norm 0.3279 (0.3545)	mem 39782MB
[2023-07-07 10:32:58 RepVGG-A0] (main.py 282): INFO Train: [88/300][30/78]	eta 0:01:44 lr 5.124435	time 1.3850 (2.1810)	loss 3.3170 (3.3329)	grad_norm 0.3467 (0.3561)	mem 39782MB
[2023-07-07 10:33:16 RepVGG-A0] (main.py 282): INFO Train: [88/300][40/78]	eta 0:01:19 lr 5.121001	time 4.8543 (2.0961)	loss 3.4191 (3.3354)	grad_norm 0.4504 (0.3562)	mem 39782MB
[2023-07-07 10:33:30 RepVGG-A0] (main.py 282): INFO Train: [88/300][50/78]	eta 0:00:55 lr 5.117563	time 1.2417 (1.9647)	loss 5.6511 (3.6106)	grad_norm 0.5972 (0.4390)	mem 39782MB
[2023-07-07 10:33:46 RepVGG-A0] (main.py 282): INFO Train: [88/300][60/78]	eta 0:00:34 lr 5.114122	time 1.2864 (1.8970)	loss 4.5167 (3.8398)	grad_norm 0.2926 (0.4385)	mem 39782MB
[2023-07-07 10:34:01 RepVGG-A0] (main.py 282): INFO Train: [88/300][70/78]	eta 0:00:14 lr 5.110678	time 1.2928 (1.8393)	loss 4.1257 (3.8965)	grad_norm 0.2949 (0.4208)	mem 39782MB
[2023-07-07 10:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 88 training takes 0:02:23
[2023-07-07 10:34:36 RepVGG-A0] (main.py 282): INFO Train: [89/300][0/78]	eta 0:28:42 lr 5.107920	time 22.0772 (22.0772)	loss 3.7678 (3.7678)	grad_norm 0.2494 (0.2494)	mem 39782MB
[2023-07-07 10:34:51 RepVGG-A0] (main.py 282): INFO Train: [89/300][10/78]	eta 0:03:48 lr 5.104469	time 1.4110 (3.3592)	loss 3.6878 (3.7243)	grad_norm 0.2979 (0.2737)	mem 39782MB
[2023-07-07 10:35:05 RepVGG-A0] (main.py 282): INFO Train: [89/300][20/78]	eta 0:02:22 lr 5.101015	time 1.3325 (2.4524)	loss 3.5399 (3.6497)	grad_norm 0.3213 (0.2793)	mem 39782MB
[2023-07-07 10:35:20 RepVGG-A0] (main.py 282): INFO Train: [89/300][30/78]	eta 0:01:42 lr 5.097557	time 1.6058 (2.1281)	loss 3.5737 (3.6178)	grad_norm 0.3384 (0.2874)	mem 39782MB
[2023-07-07 10:35:37 RepVGG-A0] (main.py 282): INFO Train: [89/300][40/78]	eta 0:01:17 lr 5.094096	time 3.2331 (2.0441)	loss 3.4558 (3.5871)	grad_norm 0.2683 (0.2941)	mem 39782MB
[2023-07-07 10:35:52 RepVGG-A0] (main.py 282): INFO Train: [89/300][50/78]	eta 0:00:54 lr 5.090631	time 1.1921 (1.9348)	loss 3.4289 (3.5591)	grad_norm 0.3317 (0.2978)	mem 39782MB
[2023-07-07 10:36:08 RepVGG-A0] (main.py 282): INFO Train: [89/300][60/78]	eta 0:00:33 lr 5.087164	time 1.5257 (1.8732)	loss 3.4313 (3.5404)	grad_norm 0.3111 (0.3032)	mem 39782MB
[2023-07-07 10:36:23 RepVGG-A0] (main.py 282): INFO Train: [89/300][70/78]	eta 0:00:14 lr 5.083692	time 1.2858 (1.8215)	loss 3.5090 (3.5232)	grad_norm 0.3837 (0.3085)	mem 39782MB
[2023-07-07 10:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 89 training takes 0:02:20
[2023-07-07 10:36:55 RepVGG-A0] (main.py 282): INFO Train: [90/300][0/78]	eta 0:27:56 lr 5.080913	time 21.4958 (21.4958)	loss 3.2503 (3.2503)	grad_norm 0.2854 (0.2854)	mem 39782MB
[2023-07-07 10:37:11 RepVGG-A0] (main.py 282): INFO Train: [90/300][10/78]	eta 0:03:49 lr 5.077435	time 1.1720 (3.3696)	loss 3.6319 (3.4852)	grad_norm 0.4454 (0.4168)	mem 39782MB
[2023-07-07 10:37:25 RepVGG-A0] (main.py 282): INFO Train: [90/300][20/78]	eta 0:02:21 lr 5.073955	time 1.3371 (2.4386)	loss 3.3582 (3.4778)	grad_norm 0.2934 (0.3839)	mem 39782MB
[2023-07-07 10:37:40 RepVGG-A0] (main.py 282): INFO Train: [90/300][30/78]	eta 0:01:42 lr 5.070470	time 1.2239 (2.1398)	loss 3.4053 (3.4526)	grad_norm 0.3416 (0.3664)	mem 39782MB
[2023-07-07 10:37:58 RepVGG-A0] (main.py 282): INFO Train: [90/300][40/78]	eta 0:01:18 lr 5.066983	time 3.7088 (2.0601)	loss 3.3238 (3.4250)	grad_norm 0.2938 (0.3541)	mem 39782MB
[2023-07-07 10:38:14 RepVGG-A0] (main.py 282): INFO Train: [90/300][50/78]	eta 0:00:54 lr 5.063492	time 1.2108 (1.9557)	loss 3.5892 (3.4216)	grad_norm 0.4873 (0.3578)	mem 39782MB
[2023-07-07 10:38:28 RepVGG-A0] (main.py 282): INFO Train: [90/300][60/78]	eta 0:00:33 lr 5.059998	time 1.1261 (1.8719)	loss 5.2380 (3.6044)	grad_norm 0.6534 (0.4244)	mem 39782MB
[2023-07-07 10:38:43 RepVGG-A0] (main.py 282): INFO Train: [90/300][70/78]	eta 0:00:14 lr 5.056500	time 1.2892 (1.8227)	loss 4.1054 (3.7249)	grad_norm 0.2893 (0.4222)	mem 39782MB
[2023-07-07 10:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 90 training takes 0:02:20
[2023-07-07 10:39:17 RepVGG-A0] (main.py 282): INFO Train: [91/300][0/78]	eta 0:28:44 lr 5.053700	time 22.1093 (22.1093)	loss 3.7256 (3.7256)	grad_norm 0.2900 (0.2900)	mem 39782MB
[2023-07-07 10:39:31 RepVGG-A0] (main.py 282): INFO Train: [91/300][10/78]	eta 0:03:42 lr 5.050196	time 1.1738 (3.2774)	loss 3.5483 (3.6350)	grad_norm 0.3048 (0.2744)	mem 39782MB
[2023-07-07 10:39:46 RepVGG-A0] (main.py 282): INFO Train: [91/300][20/78]	eta 0:02:20 lr 5.046689	time 1.1277 (2.4218)	loss 3.5047 (3.5847)	grad_norm 0.2436 (0.2787)	mem 39782MB
[2023-07-07 10:40:02 RepVGG-A0] (main.py 282): INFO Train: [91/300][30/78]	eta 0:01:44 lr 5.043179	time 1.3632 (2.1712)	loss 3.3720 (3.5332)	grad_norm 0.2710 (0.2819)	mem 39782MB
[2023-07-07 10:40:18 RepVGG-A0] (main.py 282): INFO Train: [91/300][40/78]	eta 0:01:17 lr 5.039665	time 2.7309 (2.0293)	loss 3.4086 (3.5106)	grad_norm 0.2918 (0.2888)	mem 39782MB
[2023-07-07 10:40:33 RepVGG-A0] (main.py 282): INFO Train: [91/300][50/78]	eta 0:00:53 lr 5.036148	time 1.1728 (1.9249)	loss 3.4007 (3.4855)	grad_norm 0.3607 (0.2909)	mem 39782MB
[2023-07-07 10:40:48 RepVGG-A0] (main.py 282): INFO Train: [91/300][60/78]	eta 0:00:33 lr 5.032628	time 1.1997 (1.8509)	loss 3.4407 (3.4738)	grad_norm 0.3677 (0.3011)	mem 39782MB
[2023-07-07 10:41:03 RepVGG-A0] (main.py 282): INFO Train: [91/300][70/78]	eta 0:00:14 lr 5.029105	time 1.2134 (1.8083)	loss 3.2081 (3.4559)	grad_norm 0.3018 (0.3001)	mem 39782MB
[2023-07-07 10:41:15 RepVGG-A0] (main.py 291): INFO EPOCH 91 training takes 0:02:20
[2023-07-07 10:41:36 RepVGG-A0] (main.py 282): INFO Train: [92/300][0/78]	eta 0:27:27 lr 5.026283	time 21.1197 (21.1197)	loss 3.5231 (3.5231)	grad_norm 0.4467 (0.4467)	mem 39782MB
[2023-07-07 10:41:51 RepVGG-A0] (main.py 282): INFO Train: [92/300][10/78]	eta 0:03:42 lr 5.022754	time 1.1719 (3.2712)	loss 3.2820 (3.4024)	grad_norm 0.3085 (0.3474)	mem 39782MB
[2023-07-07 10:42:05 RepVGG-A0] (main.py 282): INFO Train: [92/300][20/78]	eta 0:02:18 lr 5.019221	time 1.1722 (2.3897)	loss 3.3876 (3.3729)	grad_norm 0.3563 (0.3408)	mem 39782MB
[2023-07-07 10:42:20 RepVGG-A0] (main.py 282): INFO Train: [92/300][30/78]	eta 0:01:41 lr 5.015685	time 1.2195 (2.1051)	loss 3.4192 (3.3728)	grad_norm 0.3890 (0.3458)	mem 39782MB
[2023-07-07 10:42:38 RepVGG-A0] (main.py 282): INFO Train: [92/300][40/78]	eta 0:01:16 lr 5.012146	time 4.2063 (2.0256)	loss 3.3056 (3.3776)	grad_norm 0.3086 (0.3479)	mem 39782MB
[2023-07-07 10:42:53 RepVGG-A0] (main.py 282): INFO Train: [92/300][50/78]	eta 0:00:53 lr 5.008603	time 1.1738 (1.9239)	loss 3.3883 (3.3655)	grad_norm 0.3969 (0.3440)	mem 39782MB
[2023-07-07 10:43:08 RepVGG-A0] (main.py 282): INFO Train: [92/300][60/78]	eta 0:00:33 lr 5.005057	time 1.1638 (1.8587)	loss 3.3318 (3.3788)	grad_norm 0.3106 (0.3543)	mem 39782MB
[2023-07-07 10:43:23 RepVGG-A0] (main.py 282): INFO Train: [92/300][70/78]	eta 0:00:14 lr 5.001508	time 1.2453 (1.8089)	loss 3.3567 (3.3732)	grad_norm 0.3792 (0.3507)	mem 39782MB
[2023-07-07 10:43:35 RepVGG-A0] (main.py 291): INFO EPOCH 92 training takes 0:02:20
[2023-07-07 10:43:57 RepVGG-A0] (main.py 282): INFO Train: [93/300][0/78]	eta 0:28:44 lr 4.998667	time 22.1047 (22.1047)	loss 3.5409 (3.5409)	grad_norm 0.4690 (0.4690)	mem 39782MB
[2023-07-07 10:44:12 RepVGG-A0] (main.py 282): INFO Train: [93/300][10/78]	eta 0:03:47 lr 4.995112	time 1.1737 (3.3445)	loss 3.3899 (3.3815)	grad_norm 0.3758 (0.3627)	mem 39782MB
[2023-07-07 10:44:26 RepVGG-A0] (main.py 282): INFO Train: [93/300][20/78]	eta 0:02:19 lr 4.991554	time 1.1724 (2.3981)	loss 3.3120 (3.3402)	grad_norm 0.3243 (0.3417)	mem 39782MB
[2023-07-07 10:44:41 RepVGG-A0] (main.py 282): INFO Train: [93/300][30/78]	eta 0:01:42 lr 4.987992	time 1.4220 (2.1352)	loss 3.4213 (3.3459)	grad_norm 0.3700 (0.3540)	mem 39782MB
[2023-07-07 10:44:59 RepVGG-A0] (main.py 282): INFO Train: [93/300][40/78]	eta 0:01:17 lr 4.984428	time 3.1882 (2.0401)	loss 3.2213 (3.3333)	grad_norm 0.3630 (0.3527)	mem 39782MB
[2023-07-07 10:45:14 RepVGG-A0] (main.py 282): INFO Train: [93/300][50/78]	eta 0:00:54 lr 4.980860	time 1.2291 (1.9357)	loss 3.3154 (3.3241)	grad_norm 0.3187 (0.3509)	mem 39782MB
[2023-07-07 10:45:29 RepVGG-A0] (main.py 282): INFO Train: [93/300][60/78]	eta 0:00:33 lr 4.977289	time 1.2386 (1.8646)	loss 3.7980 (3.3595)	grad_norm 0.5721 (0.3726)	mem 39782MB
[2023-07-07 10:45:44 RepVGG-A0] (main.py 282): INFO Train: [93/300][70/78]	eta 0:00:14 lr 4.973715	time 1.3718 (1.8145)	loss 3.3738 (3.3935)	grad_norm 0.2790 (0.3798)	mem 39782MB
[2023-07-07 10:45:56 RepVGG-A0] (main.py 291): INFO EPOCH 93 training takes 0:02:20
[2023-07-07 10:46:16 RepVGG-A0] (main.py 282): INFO Train: [94/300][0/78]	eta 0:26:19 lr 4.970853	time 20.2537 (20.2537)	loss 3.2431 (3.2431)	grad_norm 0.2970 (0.2970)	mem 39782MB
[2023-07-07 10:46:33 RepVGG-A0] (main.py 282): INFO Train: [94/300][10/78]	eta 0:03:48 lr 4.967273	time 1.1714 (3.3642)	loss 3.2747 (3.2514)	grad_norm 0.3257 (0.3105)	mem 39782MB
[2023-07-07 10:46:49 RepVGG-A0] (main.py 282): INFO Train: [94/300][20/78]	eta 0:02:25 lr 4.963690	time 1.1782 (2.5163)	loss 3.2414 (3.2583)	grad_norm 0.3192 (0.3282)	mem 39782MB
[2023-07-07 10:47:05 RepVGG-A0] (main.py 282): INFO Train: [94/300][30/78]	eta 0:01:47 lr 4.960103	time 1.7807 (2.2405)	loss 3.3383 (3.2541)	grad_norm 0.3676 (0.3276)	mem 39782MB
[2023-07-07 10:47:21 RepVGG-A0] (main.py 282): INFO Train: [94/300][40/78]	eta 0:01:19 lr 4.956514	time 1.5691 (2.0793)	loss 3.3895 (3.3013)	grad_norm 0.3815 (0.3565)	mem 39782MB
[2023-07-07 10:47:36 RepVGG-A0] (main.py 282): INFO Train: [94/300][50/78]	eta 0:00:55 lr 4.952921	time 1.1936 (1.9668)	loss 3.3227 (3.3018)	grad_norm 0.3048 (0.3481)	mem 39782MB
[2023-07-07 10:47:51 RepVGG-A0] (main.py 282): INFO Train: [94/300][60/78]	eta 0:00:33 lr 4.949325	time 1.1868 (1.8868)	loss 3.3119 (3.3003)	grad_norm 0.3780 (0.3469)	mem 39782MB
[2023-07-07 10:48:06 RepVGG-A0] (main.py 282): INFO Train: [94/300][70/78]	eta 0:00:14 lr 4.945726	time 1.4559 (1.8281)	loss 3.2682 (3.2979)	grad_norm 0.3318 (0.3462)	mem 39782MB
[2023-07-07 10:48:18 RepVGG-A0] (main.py 291): INFO EPOCH 94 training takes 0:02:22
[2023-07-07 10:48:40 RepVGG-A0] (main.py 282): INFO Train: [95/300][0/78]	eta 0:28:39 lr 4.942845	time 22.0418 (22.0418)	loss 3.4446 (3.4446)	grad_norm 0.4473 (0.4473)	mem 39782MB
[2023-07-07 10:48:54 RepVGG-A0] (main.py 282): INFO Train: [95/300][10/78]	eta 0:03:44 lr 4.939240	time 1.1723 (3.3023)	loss 3.2675 (3.3630)	grad_norm 0.3206 (0.3940)	mem 39782MB
[2023-07-07 10:49:10 RepVGG-A0] (main.py 282): INFO Train: [95/300][20/78]	eta 0:02:23 lr 4.935632	time 1.4984 (2.4820)	loss 3.1793 (3.2976)	grad_norm 0.3305 (0.3543)	mem 39782MB
[2023-07-07 10:49:25 RepVGG-A0] (main.py 282): INFO Train: [95/300][30/78]	eta 0:01:44 lr 4.932022	time 1.4717 (2.1702)	loss 3.3906 (3.2974)	grad_norm 0.4079 (0.3655)	mem 39782MB
[2023-07-07 10:49:42 RepVGG-A0] (main.py 282): INFO Train: [95/300][40/78]	eta 0:01:17 lr 4.928407	time 2.7058 (2.0461)	loss 3.2714 (3.2940)	grad_norm 0.3472 (0.3665)	mem 39782MB
[2023-07-07 10:49:57 RepVGG-A0] (main.py 282): INFO Train: [95/300][50/78]	eta 0:00:54 lr 4.924790	time 1.1719 (1.9467)	loss 3.3272 (3.2861)	grad_norm 0.4050 (0.3629)	mem 39782MB
[2023-07-07 10:50:12 RepVGG-A0] (main.py 282): INFO Train: [95/300][60/78]	eta 0:00:33 lr 4.921170	time 1.3039 (1.8655)	loss 3.2669 (3.3003)	grad_norm 0.2904 (0.3676)	mem 39782MB
[2023-07-07 10:50:26 RepVGG-A0] (main.py 282): INFO Train: [95/300][70/78]	eta 0:00:14 lr 4.917547	time 1.1261 (1.8120)	loss 3.2747 (3.2988)	grad_norm 0.3459 (0.3644)	mem 39782MB
[2023-07-07 10:50:38 RepVGG-A0] (main.py 291): INFO EPOCH 95 training takes 0:02:20
[2023-07-07 10:50:59 RepVGG-A0] (main.py 282): INFO Train: [96/300][0/78]	eta 0:27:10 lr 4.914646	time 20.9077 (20.9077)	loss 3.4089 (3.4089)	grad_norm 0.4653 (0.4653)	mem 39782MB
[2023-07-07 10:51:14 RepVGG-A0] (main.py 282): INFO Train: [96/300][10/78]	eta 0:03:40 lr 4.911017	time 1.1922 (3.2455)	loss 6.3244 (4.4464)	grad_norm 0.8510 (0.8143)	mem 39782MB
[2023-07-07 10:51:29 RepVGG-A0] (main.py 282): INFO Train: [96/300][20/78]	eta 0:02:19 lr 4.907385	time 1.1718 (2.4011)	loss 5.1919 (5.1077)	grad_norm 0.2901 (0.6619)	mem 39782MB
[2023-07-07 10:51:43 RepVGG-A0] (main.py 282): INFO Train: [96/300][30/78]	eta 0:01:40 lr 4.903750	time 1.1837 (2.0928)	loss 4.4773 (5.0064)	grad_norm 0.2770 (0.5503)	mem 39782MB
[2023-07-07 10:52:02 RepVGG-A0] (main.py 282): INFO Train: [96/300][40/78]	eta 0:01:17 lr 4.900111	time 4.2891 (2.0285)	loss 4.1070 (4.8457)	grad_norm 0.2482 (0.4951)	mem 39782MB
[2023-07-07 10:52:16 RepVGG-A0] (main.py 282): INFO Train: [96/300][50/78]	eta 0:00:53 lr 4.896470	time 1.1733 (1.9159)	loss 3.8735 (4.6801)	grad_norm 0.2669 (0.4522)	mem 39782MB
[2023-07-07 10:52:31 RepVGG-A0] (main.py 282): INFO Train: [96/300][60/78]	eta 0:00:33 lr 4.892826	time 1.2331 (1.8459)	loss 3.8059 (4.5419)	grad_norm 0.3133 (0.4259)	mem 39782MB
[2023-07-07 10:52:47 RepVGG-A0] (main.py 282): INFO Train: [96/300][70/78]	eta 0:00:14 lr 4.889179	time 1.2860 (1.8051)	loss 3.7827 (4.4286)	grad_norm 0.3464 (0.4095)	mem 39782MB
[2023-07-07 10:52:58 RepVGG-A0] (main.py 291): INFO EPOCH 96 training takes 0:02:19
[2023-07-07 10:53:20 RepVGG-A0] (main.py 282): INFO Train: [97/300][0/78]	eta 0:28:39 lr 4.886259	time 22.0475 (22.0475)	loss 3.5318 (3.5318)	grad_norm 0.2730 (0.2730)	mem 39782MB
[2023-07-07 10:53:35 RepVGG-A0] (main.py 282): INFO Train: [97/300][10/78]	eta 0:03:44 lr 4.882606	time 1.1891 (3.2994)	loss 3.5389 (3.5621)	grad_norm 0.3142 (0.3169)	mem 39782MB
[2023-07-07 10:53:49 RepVGG-A0] (main.py 282): INFO Train: [97/300][20/78]	eta 0:02:19 lr 4.878950	time 1.2574 (2.4010)	loss 3.5256 (3.5567)	grad_norm 0.3494 (0.3215)	mem 39782MB
[2023-07-07 10:54:05 RepVGG-A0] (main.py 282): INFO Train: [97/300][30/78]	eta 0:01:42 lr 4.875291	time 1.2341 (2.1412)	loss 3.5557 (3.5539)	grad_norm 0.3804 (0.3323)	mem 39782MB
[2023-07-07 10:54:23 RepVGG-A0] (main.py 282): INFO Train: [97/300][40/78]	eta 0:01:17 lr 4.871629	time 3.3855 (2.0517)	loss 3.5154 (3.5360)	grad_norm 0.3200 (0.3301)	mem 39782MB
[2023-07-07 10:54:37 RepVGG-A0] (main.py 282): INFO Train: [97/300][50/78]	eta 0:00:54 lr 4.867964	time 1.1769 (1.9356)	loss 3.4520 (3.5338)	grad_norm 0.3250 (0.3386)	mem 39782MB
[2023-07-07 10:54:52 RepVGG-A0] (main.py 282): INFO Train: [97/300][60/78]	eta 0:00:33 lr 4.864296	time 1.1806 (1.8683)	loss 3.4965 (3.5266)	grad_norm 0.3264 (0.3380)	mem 39782MB
[2023-07-07 10:55:07 RepVGG-A0] (main.py 282): INFO Train: [97/300][70/78]	eta 0:00:14 lr 4.860625	time 1.1960 (1.8142)	loss 3.5698 (3.5202)	grad_norm 0.3968 (0.3426)	mem 39782MB
[2023-07-07 10:55:19 RepVGG-A0] (main.py 291): INFO EPOCH 97 training takes 0:02:20
[2023-07-07 10:55:40 RepVGG-A0] (main.py 282): INFO Train: [98/300][0/78]	eta 0:27:51 lr 4.857686	time 21.4352 (21.4352)	loss 3.4387 (3.4387)	grad_norm 0.3202 (0.3202)	mem 39782MB
[2023-07-07 10:55:54 RepVGG-A0] (main.py 282): INFO Train: [98/300][10/78]	eta 0:03:39 lr 4.854010	time 1.1926 (3.2287)	loss 3.4252 (3.5020)	grad_norm 0.3928 (0.4157)	mem 39782MB
[2023-07-07 10:56:09 RepVGG-A0] (main.py 282): INFO Train: [98/300][20/78]	eta 0:02:20 lr 4.850331	time 1.3282 (2.4238)	loss 3.3317 (3.4642)	grad_norm 0.3147 (0.3766)	mem 39782MB
[2023-07-07 10:56:24 RepVGG-A0] (main.py 282): INFO Train: [98/300][30/78]	eta 0:01:41 lr 4.846649	time 1.4321 (2.1178)	loss 3.3547 (3.4258)	grad_norm 0.3499 (0.3597)	mem 39782MB
[2023-07-07 10:56:42 RepVGG-A0] (main.py 282): INFO Train: [98/300][40/78]	eta 0:01:17 lr 4.842963	time 3.7185 (2.0460)	loss 3.4167 (3.4130)	grad_norm 0.4264 (0.3585)	mem 39782MB
[2023-07-07 10:56:57 RepVGG-A0] (main.py 282): INFO Train: [98/300][50/78]	eta 0:00:54 lr 4.839275	time 1.1723 (1.9389)	loss 3.4882 (3.4371)	grad_norm 0.3982 (0.3720)	mem 39782MB
[2023-07-07 10:57:12 RepVGG-A0] (main.py 282): INFO Train: [98/300][60/78]	eta 0:00:33 lr 4.835584	time 1.1274 (1.8673)	loss 3.3605 (3.4264)	grad_norm 0.3177 (0.3655)	mem 39782MB
[2023-07-07 10:57:28 RepVGG-A0] (main.py 282): INFO Train: [98/300][70/78]	eta 0:00:14 lr 4.831890	time 1.3526 (1.8185)	loss 3.3290 (3.4105)	grad_norm 0.3478 (0.3604)	mem 39782MB
[2023-07-07 10:57:40 RepVGG-A0] (main.py 291): INFO EPOCH 98 training takes 0:02:21
[2023-07-07 10:58:02 RepVGG-A0] (main.py 282): INFO Train: [99/300][0/78]	eta 0:28:06 lr 4.828933	time 21.6163 (21.6163)	loss 3.2472 (3.2472)	grad_norm 0.4066 (0.4066)	mem 39782MB
[2023-07-07 10:58:16 RepVGG-A0] (main.py 282): INFO Train: [99/300][10/78]	eta 0:03:40 lr 4.825233	time 1.1713 (3.2423)	loss 3.4577 (3.4255)	grad_norm 0.3805 (0.4299)	mem 39782MB
[2023-07-07 10:58:29 RepVGG-A0] (main.py 282): INFO Train: [99/300][20/78]	eta 0:02:15 lr 4.821531	time 1.1721 (2.3402)	loss 3.2560 (3.3762)	grad_norm 0.3074 (0.3755)	mem 39782MB
[2023-07-07 10:58:44 RepVGG-A0] (main.py 282): INFO Train: [99/300][30/78]	eta 0:01:38 lr 4.817826	time 1.2996 (2.0622)	loss 3.3374 (3.3620)	grad_norm 0.3995 (0.3717)	mem 39782MB
[2023-07-07 10:59:03 RepVGG-A0] (main.py 282): INFO Train: [99/300][40/78]	eta 0:01:16 lr 4.814117	time 4.1038 (2.0126)	loss 3.8714 (3.4178)	grad_norm 0.5800 (0.4067)	mem 39782MB
[2023-07-07 10:59:17 RepVGG-A0] (main.py 282): INFO Train: [99/300][50/78]	eta 0:00:53 lr 4.810406	time 1.2285 (1.9032)	loss 3.4526 (3.4359)	grad_norm 0.3095 (0.3978)	mem 39782MB
[2023-07-07 10:59:33 RepVGG-A0] (main.py 282): INFO Train: [99/300][60/78]	eta 0:00:33 lr 4.806692	time 1.1883 (1.8414)	loss 3.2589 (3.4192)	grad_norm 0.3078 (0.3838)	mem 39782MB
[2023-07-07 10:59:48 RepVGG-A0] (main.py 282): INFO Train: [99/300][70/78]	eta 0:00:14 lr 4.802976	time 1.2299 (1.7949)	loss 3.2997 (3.4081)	grad_norm 0.3218 (0.3770)	mem 39782MB
[2023-07-07 10:59:59 RepVGG-A0] (main.py 291): INFO EPOCH 99 training takes 0:02:18
[2023-07-07 11:00:20 RepVGG-A0] (main.py 282): INFO Train: [100/300][0/78]	eta 0:27:03 lr 4.800000	time 20.8167 (20.8167)	loss 3.2634 (3.2634)	grad_norm 0.3370 (0.3370)	mem 39782MB
[2023-07-07 11:00:33 RepVGG-A0] (main.py 282): INFO Train: [100/300][10/78]	eta 0:03:33 lr 4.796278	time 1.1733 (3.1330)	loss 3.2838 (3.2841)	grad_norm 0.3589 (0.3672)	mem 39782MB
[2023-07-07 11:00:48 RepVGG-A0] (main.py 282): INFO Train: [100/300][20/78]	eta 0:02:15 lr 4.792553	time 1.1713 (2.3345)	loss 3.3358 (3.2842)	grad_norm 0.3386 (0.3572)	mem 39782MB
[2023-07-07 11:01:03 RepVGG-A0] (main.py 282): INFO Train: [100/300][30/78]	eta 0:01:39 lr 4.788825	time 1.1269 (2.0797)	loss 3.2914 (3.2899)	grad_norm 0.3677 (0.3633)	mem 39782MB
[2023-07-07 11:01:21 RepVGG-A0] (main.py 282): INFO Train: [100/300][40/78]	eta 0:01:16 lr 4.785095	time 3.3967 (2.0031)	loss 3.2619 (3.2906)	grad_norm 0.3622 (0.3610)	mem 39782MB
[2023-07-07 11:01:36 RepVGG-A0] (main.py 282): INFO Train: [100/300][50/78]	eta 0:00:53 lr 4.781361	time 1.2912 (1.9046)	loss 3.4163 (3.2961)	grad_norm 0.3899 (0.3616)	mem 39782MB
[2023-07-07 11:01:51 RepVGG-A0] (main.py 282): INFO Train: [100/300][60/78]	eta 0:00:33 lr 4.777625	time 1.1929 (1.8358)	loss 3.2822 (3.2991)	grad_norm 0.3464 (0.3632)	mem 39782MB
[2023-07-07 11:02:06 RepVGG-A0] (main.py 282): INFO Train: [100/300][70/78]	eta 0:00:14 lr 4.773885	time 1.2148 (1.7930)	loss 3.3884 (3.3016)	grad_norm 0.4160 (0.3661)	mem 39782MB
[2023-07-07 11:02:18 RepVGG-A0] (main.py 291): INFO EPOCH 100 training takes 0:02:19
[2023-07-07 11:02:36 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.376 (17.376)	Loss 2.8196 (2.8196)	Acc@1 40.741 (40.741)	Acc@5 66.449 (66.449)	Mem 39782MB
[2023-07-07 11:02:37 RepVGG-A0] (main.py 342): INFO  * Acc@1 40.988 Acc@5 66.530
[2023-07-07 11:02:37 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 100: 40.988%
[2023-07-07 11:02:37 RepVGG-A0] (main.py 172): INFO Max accuracy: 40.99%
[2023-07-07 11:02:58 RepVGG-A0] (main.py 282): INFO Train: [101/300][0/78]	eta 0:27:24 lr 4.770892	time 21.0805 (21.0805)	loss 3.2596 (3.2596)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 11:03:15 RepVGG-A0] (main.py 282): INFO Train: [101/300][10/78]	eta 0:03:57 lr 4.767148	time 1.1756 (3.4948)	loss 3.2774 (3.2533)	grad_norm 0.3965 (0.3596)	mem 39782MB
[2023-07-07 11:03:29 RepVGG-A0] (main.py 282): INFO Train: [101/300][20/78]	eta 0:02:24 lr 4.763401	time 1.2280 (2.4902)	loss 3.2498 (3.2635)	grad_norm 0.3963 (0.3756)	mem 39782MB
[2023-07-07 11:03:45 RepVGG-A0] (main.py 282): INFO Train: [101/300][30/78]	eta 0:01:44 lr 4.759651	time 1.5059 (2.1875)	loss 3.2646 (3.2704)	grad_norm 0.3679 (0.3772)	mem 39782MB
[2023-07-07 11:04:03 RepVGG-A0] (main.py 282): INFO Train: [101/300][40/78]	eta 0:01:19 lr 4.755898	time 4.5346 (2.1031)	loss 3.2280 (3.2596)	grad_norm 0.3157 (0.3655)	mem 39782MB
[2023-07-07 11:04:17 RepVGG-A0] (main.py 282): INFO Train: [101/300][50/78]	eta 0:00:55 lr 4.752142	time 1.3048 (1.9697)	loss 6.5167 (3.4981)	grad_norm 0.9319 (0.4543)	mem 39782MB
[2023-07-07 11:04:33 RepVGG-A0] (main.py 282): INFO Train: [101/300][60/78]	eta 0:00:34 lr 4.748384	time 1.1945 (1.8958)	loss 5.4765 (3.9057)	grad_norm 0.3905 (0.4563)	mem 39782MB
[2023-07-07 11:04:48 RepVGG-A0] (main.py 282): INFO Train: [101/300][70/78]	eta 0:00:14 lr 4.744623	time 1.3900 (1.8463)	loss 4.7816 (4.0771)	grad_norm 0.2919 (0.4443)	mem 39782MB
[2023-07-07 11:04:59 RepVGG-A0] (main.py 291): INFO EPOCH 101 training takes 0:02:21
[2023-07-07 11:05:20 RepVGG-A0] (main.py 282): INFO Train: [102/300][0/78]	eta 0:27:33 lr 4.741612	time 21.2006 (21.2006)	loss 4.3430 (4.3430)	grad_norm 0.2890 (0.2890)	mem 39782MB
[2023-07-07 11:05:34 RepVGG-A0] (main.py 282): INFO Train: [102/300][10/78]	eta 0:03:41 lr 4.737846	time 1.1715 (3.2528)	loss 4.2372 (4.2952)	grad_norm 0.3381 (0.3161)	mem 39782MB
[2023-07-07 11:05:49 RepVGG-A0] (main.py 282): INFO Train: [102/300][20/78]	eta 0:02:18 lr 4.734077	time 1.1728 (2.3913)	loss 3.9514 (4.1841)	grad_norm 0.3016 (0.3182)	mem 39782MB
[2023-07-07 11:06:04 RepVGG-A0] (main.py 282): INFO Train: [102/300][30/78]	eta 0:01:41 lr 4.730305	time 1.3720 (2.1195)	loss 3.8966 (4.1036)	grad_norm 0.4031 (0.3212)	mem 39782MB
[2023-07-07 11:06:23 RepVGG-A0] (main.py 282): INFO Train: [102/300][40/78]	eta 0:01:18 lr 4.726530	time 3.7439 (2.0598)	loss 3.8209 (4.0407)	grad_norm 0.3427 (0.3224)	mem 39782MB
[2023-07-07 11:06:38 RepVGG-A0] (main.py 282): INFO Train: [102/300][50/78]	eta 0:00:54 lr 4.722753	time 1.1729 (1.9431)	loss 3.8295 (3.9795)	grad_norm 0.3630 (0.3240)	mem 39782MB
[2023-07-07 11:06:53 RepVGG-A0] (main.py 282): INFO Train: [102/300][60/78]	eta 0:00:33 lr 4.718973	time 1.1784 (1.8705)	loss 3.6890 (3.9316)	grad_norm 0.3410 (0.3284)	mem 39782MB
[2023-07-07 11:07:07 RepVGG-A0] (main.py 282): INFO Train: [102/300][70/78]	eta 0:00:14 lr 4.715191	time 1.3881 (1.8138)	loss 3.5379 (3.8865)	grad_norm 0.3241 (0.3260)	mem 39782MB
[2023-07-07 11:07:19 RepVGG-A0] (main.py 291): INFO EPOCH 102 training takes 0:02:20
[2023-07-07 11:07:42 RepVGG-A0] (main.py 282): INFO Train: [103/300][0/78]	eta 0:30:10 lr 4.712162	time 23.2079 (23.2079)	loss 3.6299 (3.6299)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 11:07:58 RepVGG-A0] (main.py 282): INFO Train: [103/300][10/78]	eta 0:04:04 lr 4.708375	time 1.3123 (3.5912)	loss 3.5451 (3.5533)	grad_norm 0.3307 (0.3436)	mem 39782MB
[2023-07-07 11:08:12 RepVGG-A0] (main.py 282): INFO Train: [103/300][20/78]	eta 0:02:28 lr 4.704585	time 1.1676 (2.5558)	loss 3.5534 (3.5243)	grad_norm 0.4160 (0.3458)	mem 39782MB
[2023-07-07 11:08:28 RepVGG-A0] (main.py 282): INFO Train: [103/300][30/78]	eta 0:01:47 lr 4.700791	time 1.4010 (2.2484)	loss 3.4514 (3.5148)	grad_norm 0.3507 (0.3477)	mem 39782MB
[2023-07-07 11:08:46 RepVGG-A0] (main.py 282): INFO Train: [103/300][40/78]	eta 0:01:20 lr 4.696996	time 4.2457 (2.1256)	loss 3.6343 (3.5158)	grad_norm 0.4226 (0.3557)	mem 39782MB
[2023-07-07 11:09:02 RepVGG-A0] (main.py 282): INFO Train: [103/300][50/78]	eta 0:00:56 lr 4.693197	time 1.3056 (2.0176)	loss 3.5024 (3.5068)	grad_norm 0.3632 (0.3557)	mem 39782MB
[2023-07-07 11:09:17 RepVGG-A0] (main.py 282): INFO Train: [103/300][60/78]	eta 0:00:34 lr 4.689396	time 1.2681 (1.9333)	loss 3.3367 (3.4973)	grad_norm 0.3377 (0.3563)	mem 39782MB
[2023-07-07 11:09:31 RepVGG-A0] (main.py 282): INFO Train: [103/300][70/78]	eta 0:00:14 lr 4.685592	time 1.3413 (1.8714)	loss 3.9476 (3.5209)	grad_norm 0.6074 (0.3754)	mem 39782MB
[2023-07-07 11:09:43 RepVGG-A0] (main.py 291): INFO EPOCH 103 training takes 0:02:24
[2023-07-07 11:10:05 RepVGG-A0] (main.py 282): INFO Train: [104/300][0/78]	eta 0:28:35 lr 4.682547	time 21.9951 (21.9951)	loss 3.4811 (3.4811)	grad_norm 0.3481 (0.3481)	mem 39782MB
[2023-07-07 11:10:21 RepVGG-A0] (main.py 282): INFO Train: [104/300][10/78]	eta 0:03:51 lr 4.678739	time 1.1727 (3.3977)	loss 3.3415 (3.4116)	grad_norm 0.2905 (0.3089)	mem 39782MB
[2023-07-07 11:10:36 RepVGG-A0] (main.py 282): INFO Train: [104/300][20/78]	eta 0:02:25 lr 4.674927	time 1.2059 (2.5083)	loss 3.3652 (3.4064)	grad_norm 0.3190 (0.3227)	mem 39782MB
[2023-07-07 11:10:52 RepVGG-A0] (main.py 282): INFO Train: [104/300][30/78]	eta 0:01:45 lr 4.671113	time 1.5515 (2.1978)	loss 3.4541 (3.3997)	grad_norm 0.4319 (0.3306)	mem 39782MB
[2023-07-07 11:11:09 RepVGG-A0] (main.py 282): INFO Train: [104/300][40/78]	eta 0:01:19 lr 4.667297	time 3.5071 (2.0790)	loss 3.4345 (3.3955)	grad_norm 0.3650 (0.3313)	mem 39782MB
[2023-07-07 11:11:23 RepVGG-A0] (main.py 282): INFO Train: [104/300][50/78]	eta 0:00:54 lr 4.663478	time 1.1739 (1.9605)	loss 3.3844 (3.3937)	grad_norm 0.3621 (0.3355)	mem 39782MB
[2023-07-07 11:11:39 RepVGG-A0] (main.py 282): INFO Train: [104/300][60/78]	eta 0:00:34 lr 4.659656	time 1.2305 (1.8979)	loss 3.4577 (3.3894)	grad_norm 0.4318 (0.3407)	mem 39782MB
[2023-07-07 11:11:54 RepVGG-A0] (main.py 282): INFO Train: [104/300][70/78]	eta 0:00:14 lr 4.655831	time 1.1734 (1.8403)	loss 5.5360 (3.5226)	grad_norm 0.8881 (0.3996)	mem 39782MB
[2023-07-07 11:12:06 RepVGG-A0] (main.py 291): INFO EPOCH 104 training takes 0:02:22
[2023-07-07 11:12:26 RepVGG-A0] (main.py 282): INFO Train: [105/300][0/78]	eta 0:26:11 lr 4.652770	time 20.1439 (20.1439)	loss 4.1351 (4.1351)	grad_norm 0.3295 (0.3295)	mem 39782MB
[2023-07-07 11:12:41 RepVGG-A0] (main.py 282): INFO Train: [105/300][10/78]	eta 0:03:35 lr 4.648940	time 1.1723 (3.1705)	loss 3.7367 (3.8893)	grad_norm 0.2783 (0.2920)	mem 39782MB
[2023-07-07 11:12:55 RepVGG-A0] (main.py 282): INFO Train: [105/300][20/78]	eta 0:02:15 lr 4.645108	time 1.1717 (2.3434)	loss 3.5938 (3.7575)	grad_norm 0.2957 (0.2914)	mem 39782MB
[2023-07-07 11:13:10 RepVGG-A0] (main.py 282): INFO Train: [105/300][30/78]	eta 0:01:38 lr 4.641274	time 1.3702 (2.0585)	loss 3.5027 (3.6761)	grad_norm 0.3138 (0.2870)	mem 39782MB
[2023-07-07 11:13:28 RepVGG-A0] (main.py 282): INFO Train: [105/300][40/78]	eta 0:01:16 lr 4.637437	time 4.0334 (2.0009)	loss 3.3484 (3.6097)	grad_norm 0.3247 (0.2892)	mem 39782MB
[2023-07-07 11:13:43 RepVGG-A0] (main.py 282): INFO Train: [105/300][50/78]	eta 0:00:53 lr 4.633597	time 1.1724 (1.9114)	loss 3.4232 (3.5705)	grad_norm 0.3176 (0.2935)	mem 39782MB
[2023-07-07 11:13:58 RepVGG-A0] (main.py 282): INFO Train: [105/300][60/78]	eta 0:00:33 lr 4.629755	time 1.1755 (1.8396)	loss 3.3283 (3.5371)	grad_norm 0.3564 (0.2974)	mem 39782MB
[2023-07-07 11:14:13 RepVGG-A0] (main.py 282): INFO Train: [105/300][70/78]	eta 0:00:14 lr 4.625910	time 1.2469 (1.7870)	loss 3.4030 (3.5103)	grad_norm 0.3480 (0.3017)	mem 39782MB
[2023-07-07 11:14:25 RepVGG-A0] (main.py 291): INFO EPOCH 105 training takes 0:02:19
[2023-07-07 11:14:46 RepVGG-A0] (main.py 282): INFO Train: [106/300][0/78]	eta 0:27:37 lr 4.622833	time 21.2478 (21.2478)	loss 3.4326 (3.4326)	grad_norm 0.4038 (0.4038)	mem 39782MB
[2023-07-07 11:15:01 RepVGG-A0] (main.py 282): INFO Train: [106/300][10/78]	eta 0:03:43 lr 4.618983	time 1.1726 (3.2906)	loss 3.3170 (3.3585)	grad_norm 0.3277 (0.3555)	mem 39782MB
[2023-07-07 11:15:15 RepVGG-A0] (main.py 282): INFO Train: [106/300][20/78]	eta 0:02:19 lr 4.615131	time 1.1728 (2.3977)	loss 3.3694 (3.3410)	grad_norm 0.3653 (0.3493)	mem 39782MB
[2023-07-07 11:15:31 RepVGG-A0] (main.py 282): INFO Train: [106/300][30/78]	eta 0:01:43 lr 4.611277	time 1.6438 (2.1485)	loss 3.3581 (3.3364)	grad_norm 0.3596 (0.3467)	mem 39782MB
[2023-07-07 11:15:49 RepVGG-A0] (main.py 282): INFO Train: [106/300][40/78]	eta 0:01:17 lr 4.607420	time 4.2326 (2.0492)	loss 3.3143 (3.3330)	grad_norm 0.3452 (0.3519)	mem 39782MB
[2023-07-07 11:16:04 RepVGG-A0] (main.py 282): INFO Train: [106/300][50/78]	eta 0:00:54 lr 4.603560	time 1.1719 (1.9454)	loss 3.3190 (3.3366)	grad_norm 0.3828 (0.3579)	mem 39782MB
[2023-07-07 11:16:19 RepVGG-A0] (main.py 282): INFO Train: [106/300][60/78]	eta 0:00:33 lr 4.599698	time 1.2926 (1.8792)	loss 3.3043 (3.3387)	grad_norm 0.3683 (0.3593)	mem 39782MB
[2023-07-07 11:16:34 RepVGG-A0] (main.py 282): INFO Train: [106/300][70/78]	eta 0:00:14 lr 4.595833	time 1.1726 (1.8223)	loss 3.3364 (3.3351)	grad_norm 0.3370 (0.3559)	mem 39782MB
[2023-07-07 11:16:47 RepVGG-A0] (main.py 291): INFO EPOCH 106 training takes 0:02:21
[2023-07-07 11:17:10 RepVGG-A0] (main.py 282): INFO Train: [107/300][0/78]	eta 0:29:42 lr 4.592740	time 22.8533 (22.8533)	loss 3.4778 (3.4778)	grad_norm 0.5276 (0.5276)	mem 39782MB
[2023-07-07 11:17:25 RepVGG-A0] (main.py 282): INFO Train: [107/300][10/78]	eta 0:03:55 lr 4.588870	time 1.1770 (3.4614)	loss 3.3323 (3.4059)	grad_norm 0.3273 (0.4080)	mem 39782MB
[2023-07-07 11:17:39 RepVGG-A0] (main.py 282): INFO Train: [107/300][20/78]	eta 0:02:24 lr 4.584999	time 1.1745 (2.4932)	loss 3.3835 (3.3530)	grad_norm 0.3680 (0.3765)	mem 39782MB
[2023-07-07 11:17:54 RepVGG-A0] (main.py 282): INFO Train: [107/300][30/78]	eta 0:01:44 lr 4.581124	time 1.2146 (2.1849)	loss 3.2152 (3.3276)	grad_norm 0.2996 (0.3620)	mem 39782MB
[2023-07-07 11:18:13 RepVGG-A0] (main.py 282): INFO Train: [107/300][40/78]	eta 0:01:19 lr 4.577248	time 3.2779 (2.0997)	loss 3.4789 (3.3382)	grad_norm 0.4557 (0.3777)	mem 39782MB
[2023-07-07 11:18:28 RepVGG-A0] (main.py 282): INFO Train: [107/300][50/78]	eta 0:00:55 lr 4.573369	time 1.3520 (1.9947)	loss 3.3151 (3.3530)	grad_norm 0.3145 (0.3829)	mem 39782MB
[2023-07-07 11:18:43 RepVGG-A0] (main.py 282): INFO Train: [107/300][60/78]	eta 0:00:34 lr 4.569487	time 1.2168 (1.9048)	loss 3.2581 (3.3362)	grad_norm 0.3167 (0.3693)	mem 39782MB
[2023-07-07 11:18:58 RepVGG-A0] (main.py 282): INFO Train: [107/300][70/78]	eta 0:00:14 lr 4.565603	time 1.1961 (1.8509)	loss 3.2459 (3.3290)	grad_norm 0.3865 (0.3690)	mem 39782MB
[2023-07-07 11:19:10 RepVGG-A0] (main.py 291): INFO EPOCH 107 training takes 0:02:23
[2023-07-07 11:19:32 RepVGG-A0] (main.py 282): INFO Train: [108/300][0/78]	eta 0:28:12 lr 4.562494	time 21.6954 (21.6954)	loss 3.2646 (3.2646)	grad_norm 0.3557 (0.3557)	mem 39782MB
[2023-07-07 11:19:46 RepVGG-A0] (main.py 282): INFO Train: [108/300][10/78]	eta 0:03:44 lr 4.558605	time 1.1719 (3.3028)	loss 3.2981 (3.2870)	grad_norm 0.3630 (0.3826)	mem 39782MB
[2023-07-07 11:20:01 RepVGG-A0] (main.py 282): INFO Train: [108/300][20/78]	eta 0:02:21 lr 4.554714	time 1.1769 (2.4365)	loss 3.2132 (3.2740)	grad_norm 0.3497 (0.3675)	mem 39782MB
[2023-07-07 11:20:17 RepVGG-A0] (main.py 282): INFO Train: [108/300][30/78]	eta 0:01:43 lr 4.550821	time 1.1997 (2.1576)	loss 3.6350 (3.3048)	grad_norm 0.6360 (0.3946)	mem 39782MB
[2023-07-07 11:20:34 RepVGG-A0] (main.py 282): INFO Train: [108/300][40/78]	eta 0:01:17 lr 4.546925	time 3.3652 (2.0516)	loss 6.1650 (3.7409)	grad_norm 0.7834 (0.5315)	mem 39782MB
[2023-07-07 11:20:49 RepVGG-A0] (main.py 282): INFO Train: [108/300][50/78]	eta 0:00:54 lr 4.543027	time 1.1880 (1.9313)	loss 4.7326 (4.0328)	grad_norm 0.3638 (0.5098)	mem 39782MB
[2023-07-07 11:21:03 RepVGG-A0] (main.py 282): INFO Train: [108/300][60/78]	eta 0:00:33 lr 4.539126	time 1.2007 (1.8560)	loss 4.1866 (4.0889)	grad_norm 0.3112 (0.4736)	mem 39782MB
[2023-07-07 11:21:19 RepVGG-A0] (main.py 282): INFO Train: [108/300][70/78]	eta 0:00:14 lr 4.535223	time 1.1735 (1.8108)	loss 4.0249 (4.0854)	grad_norm 0.3120 (0.4521)	mem 39782MB
[2023-07-07 11:21:31 RepVGG-A0] (main.py 291): INFO EPOCH 108 training takes 0:02:20
[2023-07-07 11:21:52 RepVGG-A0] (main.py 282): INFO Train: [109/300][0/78]	eta 0:27:21 lr 4.532099	time 21.0387 (21.0387)	loss 3.7358 (3.7358)	grad_norm 0.3026 (0.3026)	mem 39782MB
[2023-07-07 11:22:07 RepVGG-A0] (main.py 282): INFO Train: [109/300][10/78]	eta 0:03:43 lr 4.528191	time 1.1909 (3.2852)	loss 3.6645 (3.6883)	grad_norm 0.2990 (0.2913)	mem 39782MB
[2023-07-07 11:22:22 RepVGG-A0] (main.py 282): INFO Train: [109/300][20/78]	eta 0:02:20 lr 4.524281	time 1.1730 (2.4274)	loss 3.7118 (3.6463)	grad_norm 0.3674 (0.3030)	mem 39782MB
[2023-07-07 11:22:37 RepVGG-A0] (main.py 282): INFO Train: [109/300][30/78]	eta 0:01:42 lr 4.520369	time 1.1271 (2.1434)	loss 3.5475 (3.6399)	grad_norm 0.3363 (0.3214)	mem 39782MB
[2023-07-07 11:22:55 RepVGG-A0] (main.py 282): INFO Train: [109/300][40/78]	eta 0:01:18 lr 4.516454	time 2.5600 (2.0552)	loss 3.4666 (3.6092)	grad_norm 0.2979 (0.3182)	mem 39782MB
[2023-07-07 11:23:10 RepVGG-A0] (main.py 282): INFO Train: [109/300][50/78]	eta 0:00:54 lr 4.512537	time 1.2390 (1.9407)	loss 3.4693 (3.5753)	grad_norm 0.3396 (0.3165)	mem 39782MB
[2023-07-07 11:23:25 RepVGG-A0] (main.py 282): INFO Train: [109/300][60/78]	eta 0:00:33 lr 4.508618	time 1.1733 (1.8720)	loss 3.3883 (3.5632)	grad_norm 0.3085 (0.3234)	mem 39782MB
[2023-07-07 11:23:39 RepVGG-A0] (main.py 282): INFO Train: [109/300][70/78]	eta 0:00:14 lr 4.504696	time 1.1866 (1.8108)	loss 3.3968 (3.5493)	grad_norm 0.3000 (0.3251)	mem 39782MB
[2023-07-07 11:23:52 RepVGG-A0] (main.py 291): INFO EPOCH 109 training takes 0:02:20
[2023-07-07 11:24:11 RepVGG-A0] (main.py 282): INFO Train: [110/300][0/78]	eta 0:25:45 lr 4.501557	time 19.8136 (19.8136)	loss 3.3802 (3.3802)	grad_norm 0.3769 (0.3769)	mem 39782MB
[2023-07-07 11:24:28 RepVGG-A0] (main.py 282): INFO Train: [110/300][10/78]	eta 0:03:44 lr 4.497631	time 1.1714 (3.2982)	loss 3.4437 (3.4330)	grad_norm 0.3576 (0.3923)	mem 39782MB
[2023-07-07 11:24:43 RepVGG-A0] (main.py 282): INFO Train: [110/300][20/78]	eta 0:02:22 lr 4.493703	time 1.1762 (2.4603)	loss 3.4229 (3.3955)	grad_norm 0.3262 (0.3626)	mem 39782MB
[2023-07-07 11:24:58 RepVGG-A0] (main.py 282): INFO Train: [110/300][30/78]	eta 0:01:42 lr 4.489772	time 1.1972 (2.1423)	loss 3.4581 (3.3918)	grad_norm 0.3733 (0.3650)	mem 39782MB
[2023-07-07 11:25:16 RepVGG-A0] (main.py 282): INFO Train: [110/300][40/78]	eta 0:01:18 lr 4.485839	time 3.0021 (2.0713)	loss 3.3017 (3.3870)	grad_norm 0.3394 (0.3637)	mem 39782MB
[2023-07-07 11:25:30 RepVGG-A0] (main.py 282): INFO Train: [110/300][50/78]	eta 0:00:54 lr 4.481904	time 1.1917 (1.9331)	loss 3.3156 (3.3848)	grad_norm 0.3152 (0.3632)	mem 39782MB
[2023-07-07 11:25:45 RepVGG-A0] (main.py 282): INFO Train: [110/300][60/78]	eta 0:00:33 lr 4.477967	time 1.1725 (1.8565)	loss 3.4173 (3.3789)	grad_norm 0.4600 (0.3634)	mem 39782MB
[2023-07-07 11:26:01 RepVGG-A0] (main.py 282): INFO Train: [110/300][70/78]	eta 0:00:14 lr 4.474027	time 1.7178 (1.8166)	loss 5.5825 (3.5722)	grad_norm 0.7272 (0.4327)	mem 39782MB
[2023-07-07 11:26:11 RepVGG-A0] (main.py 291): INFO EPOCH 110 training takes 0:02:19
[2023-07-07 11:26:32 RepVGG-A0] (main.py 282): INFO Train: [111/300][0/78]	eta 0:28:10 lr 4.470873	time 21.6672 (21.6672)	loss 4.4756 (4.4756)	grad_norm 0.3477 (0.3477)	mem 39782MB
[2023-07-07 11:26:47 RepVGG-A0] (main.py 282): INFO Train: [111/300][10/78]	eta 0:03:41 lr 4.466929	time 1.1717 (3.2607)	loss 3.9868 (4.2475)	grad_norm 0.2552 (0.3349)	mem 39782MB
[2023-07-07 11:27:01 RepVGG-A0] (main.py 282): INFO Train: [111/300][20/78]	eta 0:02:18 lr 4.462983	time 1.1731 (2.3940)	loss 3.8666 (4.0613)	grad_norm 0.3483 (0.3131)	mem 39782MB
[2023-07-07 11:27:17 RepVGG-A0] (main.py 282): INFO Train: [111/300][30/78]	eta 0:01:42 lr 4.459034	time 1.3198 (2.1367)	loss 3.6167 (3.9422)	grad_norm 0.3363 (0.3081)	mem 39782MB
[2023-07-07 11:27:35 RepVGG-A0] (main.py 282): INFO Train: [111/300][40/78]	eta 0:01:17 lr 4.455084	time 4.4396 (2.0474)	loss 3.6053 (3.8608)	grad_norm 0.2866 (0.3069)	mem 39782MB
[2023-07-07 11:27:49 RepVGG-A0] (main.py 282): INFO Train: [111/300][50/78]	eta 0:00:54 lr 4.451130	time 1.3039 (1.9348)	loss 3.6332 (3.7913)	grad_norm 0.4533 (0.3089)	mem 39782MB
[2023-07-07 11:28:05 RepVGG-A0] (main.py 282): INFO Train: [111/300][60/78]	eta 0:00:33 lr 4.447175	time 1.2687 (1.8701)	loss 3.4723 (3.7466)	grad_norm 0.2819 (0.3109)	mem 39782MB
[2023-07-07 11:28:20 RepVGG-A0] (main.py 282): INFO Train: [111/300][70/78]	eta 0:00:14 lr 4.443218	time 1.1263 (1.8173)	loss 3.4680 (3.7037)	grad_norm 0.3564 (0.3111)	mem 39782MB
[2023-07-07 11:28:31 RepVGG-A0] (main.py 291): INFO EPOCH 111 training takes 0:02:20
[2023-07-07 11:28:52 RepVGG-A0] (main.py 282): INFO Train: [112/300][0/78]	eta 0:26:41 lr 4.440050	time 20.5270 (20.5270)	loss 3.3192 (3.3192)	grad_norm 0.2872 (0.2872)	mem 39782MB
[2023-07-07 11:29:08 RepVGG-A0] (main.py 282): INFO Train: [112/300][10/78]	eta 0:03:44 lr 4.436088	time 1.1718 (3.3041)	loss 3.3353 (3.3539)	grad_norm 0.2874 (0.3194)	mem 39782MB
[2023-07-07 11:29:23 RepVGG-A0] (main.py 282): INFO Train: [112/300][20/78]	eta 0:02:22 lr 4.432124	time 1.2092 (2.4651)	loss 3.5323 (3.4235)	grad_norm 0.4420 (0.3740)	mem 39782MB
[2023-07-07 11:29:39 RepVGG-A0] (main.py 282): INFO Train: [112/300][30/78]	eta 0:01:44 lr 4.428158	time 1.3698 (2.1716)	loss 3.4405 (3.4245)	grad_norm 0.3504 (0.3588)	mem 39782MB
[2023-07-07 11:29:57 RepVGG-A0] (main.py 282): INFO Train: [112/300][40/78]	eta 0:01:19 lr 4.424190	time 4.6892 (2.0806)	loss 3.4045 (3.4147)	grad_norm 0.3638 (0.3531)	mem 39782MB
[2023-07-07 11:30:11 RepVGG-A0] (main.py 282): INFO Train: [112/300][50/78]	eta 0:00:54 lr 4.420220	time 1.1737 (1.9443)	loss 3.3381 (3.4069)	grad_norm 0.3132 (0.3519)	mem 39782MB
[2023-07-07 11:30:26 RepVGG-A0] (main.py 282): INFO Train: [112/300][60/78]	eta 0:00:33 lr 4.416247	time 1.2097 (1.8744)	loss 3.4050 (3.4044)	grad_norm 0.4104 (0.3566)	mem 39782MB
[2023-07-07 11:30:41 RepVGG-A0] (main.py 282): INFO Train: [112/300][70/78]	eta 0:00:14 lr 4.412272	time 1.3419 (1.8292)	loss 3.2966 (3.3943)	grad_norm 0.3236 (0.3543)	mem 39782MB
[2023-07-07 11:30:53 RepVGG-A0] (main.py 291): INFO EPOCH 112 training takes 0:02:21
[2023-07-07 11:31:15 RepVGG-A0] (main.py 282): INFO Train: [113/300][0/78]	eta 0:29:24 lr 4.409091	time 22.6155 (22.6155)	loss 3.2776 (3.2776)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:31:29 RepVGG-A0] (main.py 282): INFO Train: [113/300][10/78]	eta 0:03:45 lr 4.405112	time 1.1722 (3.3224)	loss 3.4378 (3.3414)	grad_norm 0.4377 (0.3845)	mem 39782MB
[2023-07-07 11:31:44 RepVGG-A0] (main.py 282): INFO Train: [113/300][20/78]	eta 0:02:21 lr 4.401131	time 1.1744 (2.4328)	loss 3.2887 (3.3469)	grad_norm 0.3471 (0.3794)	mem 39782MB
[2023-07-07 11:31:58 RepVGG-A0] (main.py 282): INFO Train: [113/300][30/78]	eta 0:01:41 lr 4.397148	time 1.2959 (2.1170)	loss 3.3468 (3.3427)	grad_norm 0.3474 (0.3720)	mem 39782MB
[2023-07-07 11:32:17 RepVGG-A0] (main.py 282): INFO Train: [113/300][40/78]	eta 0:01:17 lr 4.393162	time 3.4036 (2.0438)	loss 3.3424 (3.3438)	grad_norm 0.3684 (0.3746)	mem 39782MB
[2023-07-07 11:32:32 RepVGG-A0] (main.py 282): INFO Train: [113/300][50/78]	eta 0:00:54 lr 4.389175	time 1.2577 (1.9433)	loss 3.3047 (3.3375)	grad_norm 0.3695 (0.3714)	mem 39782MB
[2023-07-07 11:32:47 RepVGG-A0] (main.py 282): INFO Train: [113/300][60/78]	eta 0:00:33 lr 4.385185	time 1.1780 (1.8667)	loss 3.4196 (3.3403)	grad_norm 0.4120 (0.3745)	mem 39782MB
[2023-07-07 11:33:02 RepVGG-A0] (main.py 282): INFO Train: [113/300][70/78]	eta 0:00:14 lr 4.381193	time 1.2781 (1.8179)	loss 3.3480 (3.3417)	grad_norm 0.3438 (0.3746)	mem 39782MB
[2023-07-07 11:33:13 RepVGG-A0] (main.py 291): INFO EPOCH 113 training takes 0:02:20
[2023-07-07 11:33:34 RepVGG-A0] (main.py 282): INFO Train: [114/300][0/78]	eta 0:27:35 lr 4.377999	time 21.2258 (21.2258)	loss 3.3301 (3.3301)	grad_norm 0.4531 (0.4531)	mem 39782MB
[2023-07-07 11:33:49 RepVGG-A0] (main.py 282): INFO Train: [114/300][10/78]	eta 0:03:43 lr 4.374003	time 1.1711 (3.2818)	loss 3.3734 (3.3374)	grad_norm 0.4236 (0.4216)	mem 39782MB
[2023-07-07 11:34:05 RepVGG-A0] (main.py 282): INFO Train: [114/300][20/78]	eta 0:02:23 lr 4.370005	time 1.3663 (2.4685)	loss 3.2347 (3.3080)	grad_norm 0.3482 (0.3937)	mem 39782MB
[2023-07-07 11:34:20 RepVGG-A0] (main.py 282): INFO Train: [114/300][30/78]	eta 0:01:42 lr 4.366006	time 1.4769 (2.1399)	loss 3.1995 (3.2821)	grad_norm 0.3508 (0.3768)	mem 39782MB
[2023-07-07 11:34:37 RepVGG-A0] (main.py 282): INFO Train: [114/300][40/78]	eta 0:01:17 lr 4.362004	time 3.1190 (2.0374)	loss 3.4040 (3.2865)	grad_norm 0.5292 (0.3844)	mem 39782MB
[2023-07-07 11:34:52 RepVGG-A0] (main.py 282): INFO Train: [114/300][50/78]	eta 0:00:53 lr 4.358000	time 1.1724 (1.9282)	loss 5.7523 (3.7033)	grad_norm 0.5064 (0.4853)	mem 39782MB
[2023-07-07 11:35:07 RepVGG-A0] (main.py 282): INFO Train: [114/300][60/78]	eta 0:00:33 lr 4.353994	time 1.1883 (1.8650)	loss 4.5502 (3.9080)	grad_norm 0.3221 (0.4664)	mem 39782MB
[2023-07-07 11:35:22 RepVGG-A0] (main.py 282): INFO Train: [114/300][70/78]	eta 0:00:14 lr 4.349985	time 1.6380 (1.8131)	loss 4.1083 (3.9614)	grad_norm 0.2630 (0.4472)	mem 39782MB
[2023-07-07 11:35:33 RepVGG-A0] (main.py 291): INFO EPOCH 114 training takes 0:02:20
[2023-07-07 11:35:55 RepVGG-A0] (main.py 282): INFO Train: [115/300][0/78]	eta 0:28:19 lr 4.346777	time 21.7936 (21.7936)	loss 3.8131 (3.8131)	grad_norm 0.3248 (0.3248)	mem 39782MB
[2023-07-07 11:36:11 RepVGG-A0] (main.py 282): INFO Train: [115/300][10/78]	eta 0:03:53 lr 4.342766	time 1.1706 (3.4312)	loss 3.6369 (3.7685)	grad_norm 0.3051 (0.3070)	mem 39782MB
[2023-07-07 11:36:25 RepVGG-A0] (main.py 282): INFO Train: [115/300][20/78]	eta 0:02:23 lr 4.338752	time 1.1872 (2.4733)	loss 3.5454 (3.7178)	grad_norm 0.2789 (0.3140)	mem 39782MB
[2023-07-07 11:36:42 RepVGG-A0] (main.py 282): INFO Train: [115/300][30/78]	eta 0:01:46 lr 4.334736	time 1.2381 (2.2201)	loss 3.4452 (3.6560)	grad_norm 0.3284 (0.3023)	mem 39782MB
[2023-07-07 11:36:58 RepVGG-A0] (main.py 282): INFO Train: [115/300][40/78]	eta 0:01:18 lr 4.330718	time 4.0570 (2.0743)	loss 3.5547 (3.6433)	grad_norm 0.3425 (0.3178)	mem 39782MB
[2023-07-07 11:37:13 RepVGG-A0] (main.py 282): INFO Train: [115/300][50/78]	eta 0:00:54 lr 4.326698	time 1.1724 (1.9574)	loss 3.5098 (3.6100)	grad_norm 0.3487 (0.3182)	mem 39782MB
[2023-07-07 11:37:28 RepVGG-A0] (main.py 282): INFO Train: [115/300][60/78]	eta 0:00:33 lr 4.322675	time 1.1839 (1.8759)	loss 3.5431 (3.5843)	grad_norm 0.3808 (0.3186)	mem 39782MB
[2023-07-07 11:37:43 RepVGG-A0] (main.py 282): INFO Train: [115/300][70/78]	eta 0:00:14 lr 4.318651	time 1.1731 (1.8295)	loss 3.4566 (3.5723)	grad_norm 0.3352 (0.3265)	mem 39782MB
[2023-07-07 11:37:55 RepVGG-A0] (main.py 291): INFO EPOCH 115 training takes 0:02:21
[2023-07-07 11:38:18 RepVGG-A0] (main.py 282): INFO Train: [116/300][0/78]	eta 0:29:28 lr 4.315431	time 22.6780 (22.6780)	loss 3.4536 (3.4536)	grad_norm 0.3650 (0.3650)	mem 39782MB
[2023-07-07 11:38:32 RepVGG-A0] (main.py 282): INFO Train: [116/300][10/78]	eta 0:03:49 lr 4.311403	time 1.1746 (3.3769)	loss 3.3250 (3.3842)	grad_norm 0.3171 (0.3505)	mem 39782MB
[2023-07-07 11:38:47 RepVGG-A0] (main.py 282): INFO Train: [116/300][20/78]	eta 0:02:23 lr 4.307373	time 1.2178 (2.4828)	loss 3.3511 (3.3679)	grad_norm 0.3678 (0.3540)	mem 39782MB
[2023-07-07 11:39:03 RepVGG-A0] (main.py 282): INFO Train: [116/300][30/78]	eta 0:01:44 lr 4.303341	time 1.4353 (2.1788)	loss 3.4644 (3.3602)	grad_norm 0.4433 (0.3512)	mem 39782MB
[2023-07-07 11:39:20 RepVGG-A0] (main.py 282): INFO Train: [116/300][40/78]	eta 0:01:19 lr 4.299308	time 3.9595 (2.0825)	loss 3.4445 (3.3767)	grad_norm 0.3991 (0.3630)	mem 39782MB
[2023-07-07 11:39:35 RepVGG-A0] (main.py 282): INFO Train: [116/300][50/78]	eta 0:00:54 lr 4.295272	time 1.1732 (1.9598)	loss 3.4552 (3.3802)	grad_norm 0.4535 (0.3668)	mem 39782MB
[2023-07-07 11:39:50 RepVGG-A0] (main.py 282): INFO Train: [116/300][60/78]	eta 0:00:34 lr 4.291234	time 1.2905 (1.8915)	loss 3.3303 (3.3799)	grad_norm 0.3718 (0.3664)	mem 39782MB
[2023-07-07 11:40:06 RepVGG-A0] (main.py 282): INFO Train: [116/300][70/78]	eta 0:00:14 lr 4.287194	time 1.5471 (1.8440)	loss 3.3269 (3.3725)	grad_norm 0.3259 (0.3620)	mem 39782MB
[2023-07-07 11:40:17 RepVGG-A0] (main.py 291): INFO EPOCH 116 training takes 0:02:22
[2023-07-07 11:40:39 RepVGG-A0] (main.py 282): INFO Train: [117/300][0/78]	eta 0:28:10 lr 4.283961	time 21.6727 (21.6727)	loss 3.2728 (3.2728)	grad_norm 0.3688 (0.3688)	mem 39782MB
[2023-07-07 11:40:53 RepVGG-A0] (main.py 282): INFO Train: [117/300][10/78]	eta 0:03:41 lr 4.279918	time 1.1722 (3.2565)	loss 3.4885 (3.2992)	grad_norm 0.5023 (0.3819)	mem 39782MB
[2023-07-07 11:41:08 RepVGG-A0] (main.py 282): INFO Train: [117/300][20/78]	eta 0:02:19 lr 4.275873	time 1.1739 (2.4024)	loss 3.8532 (3.5341)	grad_norm 0.5983 (0.4939)	mem 39782MB
[2023-07-07 11:41:23 RepVGG-A0] (main.py 282): INFO Train: [117/300][30/78]	eta 0:01:41 lr 4.271826	time 1.4148 (2.1121)	loss 3.4434 (3.5439)	grad_norm 0.2836 (0.4522)	mem 39782MB
[2023-07-07 11:41:42 RepVGG-A0] (main.py 282): INFO Train: [117/300][40/78]	eta 0:01:18 lr 4.267777	time 4.6575 (2.0676)	loss 3.2860 (3.4877)	grad_norm 0.3041 (0.4120)	mem 39782MB
[2023-07-07 11:41:56 RepVGG-A0] (main.py 282): INFO Train: [117/300][50/78]	eta 0:00:54 lr 4.263726	time 1.1759 (1.9389)	loss 3.3712 (3.4521)	grad_norm 0.3454 (0.3936)	mem 39782MB
[2023-07-07 11:42:12 RepVGG-A0] (main.py 282): INFO Train: [117/300][60/78]	eta 0:00:33 lr 4.259673	time 1.1269 (1.8798)	loss 3.2703 (3.4253)	grad_norm 0.3274 (0.3820)	mem 39782MB
[2023-07-07 11:42:27 RepVGG-A0] (main.py 282): INFO Train: [117/300][70/78]	eta 0:00:14 lr 4.255618	time 1.2863 (1.8240)	loss 3.2268 (3.4020)	grad_norm 0.3250 (0.3736)	mem 39782MB
[2023-07-07 11:42:38 RepVGG-A0] (main.py 291): INFO EPOCH 117 training takes 0:02:21
[2023-07-07 11:43:00 RepVGG-A0] (main.py 282): INFO Train: [118/300][0/78]	eta 0:28:09 lr 4.252373	time 21.6586 (21.6586)	loss 3.3343 (3.3343)	grad_norm 0.4037 (0.4037)	mem 39782MB
[2023-07-07 11:43:14 RepVGG-A0] (main.py 282): INFO Train: [118/300][10/78]	eta 0:03:40 lr 4.248315	time 1.1734 (3.2372)	loss 3.1534 (3.2672)	grad_norm 0.3842 (0.3773)	mem 39782MB
[2023-07-07 11:43:29 RepVGG-A0] (main.py 282): INFO Train: [118/300][20/78]	eta 0:02:20 lr 4.244255	time 1.1732 (2.4255)	loss 3.3012 (3.2649)	grad_norm 0.4043 (0.3773)	mem 39782MB
[2023-07-07 11:43:44 RepVGG-A0] (main.py 282): INFO Train: [118/300][30/78]	eta 0:01:42 lr 4.240193	time 1.3591 (2.1284)	loss 3.3084 (3.2699)	grad_norm 0.3339 (0.3742)	mem 39782MB
[2023-07-07 11:44:02 RepVGG-A0] (main.py 282): INFO Train: [118/300][40/78]	eta 0:01:17 lr 4.236129	time 3.8868 (2.0403)	loss 3.4148 (3.2757)	grad_norm 0.4177 (0.3778)	mem 39782MB
[2023-07-07 11:44:17 RepVGG-A0] (main.py 282): INFO Train: [118/300][50/78]	eta 0:00:54 lr 4.232064	time 1.1707 (1.9412)	loss 3.3072 (3.2801)	grad_norm 0.4319 (0.3776)	mem 39782MB
[2023-07-07 11:44:32 RepVGG-A0] (main.py 282): INFO Train: [118/300][60/78]	eta 0:00:33 lr 4.227996	time 1.1715 (1.8706)	loss 3.2791 (3.2853)	grad_norm 0.3622 (0.3796)	mem 39782MB
[2023-07-07 11:44:48 RepVGG-A0] (main.py 282): INFO Train: [118/300][70/78]	eta 0:00:14 lr 4.223927	time 1.1718 (1.8208)	loss 3.2672 (3.2812)	grad_norm 0.3388 (0.3744)	mem 39782MB
[2023-07-07 11:45:00 RepVGG-A0] (main.py 291): INFO EPOCH 118 training takes 0:02:21
[2023-07-07 11:45:21 RepVGG-A0] (main.py 282): INFO Train: [119/300][0/78]	eta 0:27:44 lr 4.220670	time 21.3450 (21.3450)	loss 3.2693 (3.2693)	grad_norm 0.4124 (0.4124)	mem 39782MB
[2023-07-07 11:45:36 RepVGG-A0] (main.py 282): INFO Train: [119/300][10/78]	eta 0:03:45 lr 4.216597	time 1.1964 (3.3208)	loss 3.4139 (3.3209)	grad_norm 0.4046 (0.4327)	mem 39782MB
[2023-07-07 11:45:52 RepVGG-A0] (main.py 282): INFO Train: [119/300][20/78]	eta 0:02:24 lr 4.212523	time 1.2391 (2.4969)	loss 3.2896 (3.2929)	grad_norm 0.3663 (0.3993)	mem 39782MB
[2023-07-07 11:46:07 RepVGG-A0] (main.py 282): INFO Train: [119/300][30/78]	eta 0:01:43 lr 4.208446	time 1.1718 (2.1604)	loss 3.2285 (3.2698)	grad_norm 0.3449 (0.3821)	mem 39782MB
[2023-07-07 11:46:25 RepVGG-A0] (main.py 282): INFO Train: [119/300][40/78]	eta 0:01:19 lr 4.204368	time 3.9191 (2.0834)	loss 3.8621 (3.3165)	grad_norm 0.7106 (0.4147)	mem 39782MB
[2023-07-07 11:46:40 RepVGG-A0] (main.py 282): INFO Train: [119/300][50/78]	eta 0:00:55 lr 4.200288	time 1.1760 (1.9675)	loss 4.5037 (3.5673)	grad_norm 0.5672 (0.4931)	mem 39782MB
[2023-07-07 11:46:55 RepVGG-A0] (main.py 282): INFO Train: [119/300][60/78]	eta 0:00:33 lr 4.196206	time 1.1818 (1.8833)	loss 3.6674 (3.6237)	grad_norm 0.2740 (0.4655)	mem 39782MB
[2023-07-07 11:47:10 RepVGG-A0] (main.py 282): INFO Train: [119/300][70/78]	eta 0:00:14 lr 4.192123	time 1.3236 (1.8335)	loss 3.5051 (3.6190)	grad_norm 0.2807 (0.4434)	mem 39782MB
[2023-07-07 11:47:23 RepVGG-A0] (main.py 291): INFO EPOCH 119 training takes 0:02:22
[2023-07-07 11:47:44 RepVGG-A0] (main.py 282): INFO Train: [120/300][0/78]	eta 0:27:28 lr 4.188854	time 21.1329 (21.1329)	loss 3.3093 (3.3093)	grad_norm 0.2635 (0.2635)	mem 39782MB
[2023-07-07 11:48:00 RepVGG-A0] (main.py 282): INFO Train: [120/300][10/78]	eta 0:03:47 lr 4.184768	time 1.1891 (3.3511)	loss 3.2621 (3.3229)	grad_norm 0.2956 (0.2783)	mem 39782MB
[2023-07-07 11:48:14 RepVGG-A0] (main.py 282): INFO Train: [120/300][20/78]	eta 0:02:20 lr 4.180679	time 1.1992 (2.4202)	loss 3.2833 (3.2994)	grad_norm 0.3431 (0.2922)	mem 39782MB
[2023-07-07 11:48:28 RepVGG-A0] (main.py 282): INFO Train: [120/300][30/78]	eta 0:01:41 lr 4.176589	time 1.3321 (2.1184)	loss 3.2243 (3.2786)	grad_norm 0.2969 (0.2938)	mem 39782MB
[2023-07-07 11:48:46 RepVGG-A0] (main.py 282): INFO Train: [120/300][40/78]	eta 0:01:17 lr 4.172497	time 3.8121 (2.0353)	loss 3.2074 (3.2713)	grad_norm 0.3494 (0.3035)	mem 39782MB
[2023-07-07 11:49:02 RepVGG-A0] (main.py 282): INFO Train: [120/300][50/78]	eta 0:00:54 lr 4.168403	time 1.1889 (1.9388)	loss 3.3108 (3.2659)	grad_norm 0.3221 (0.3095)	mem 39782MB
[2023-07-07 11:49:17 RepVGG-A0] (main.py 282): INFO Train: [120/300][60/78]	eta 0:00:33 lr 4.164307	time 1.4061 (1.8645)	loss 3.3238 (3.2640)	grad_norm 0.3574 (0.3145)	mem 39782MB
[2023-07-07 11:49:31 RepVGG-A0] (main.py 282): INFO Train: [120/300][70/78]	eta 0:00:14 lr 4.160210	time 1.2764 (1.8058)	loss 3.1911 (3.2688)	grad_norm 0.3350 (0.3239)	mem 39782MB
[2023-07-07 11:49:43 RepVGG-A0] (main.py 291): INFO EPOCH 120 training takes 0:02:19
[2023-07-07 11:50:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.860 (17.860)	Loss 2.7981 (2.7981)	Acc@1 41.357 (41.357)	Acc@5 67.542 (67.542)	Mem 39782MB
[2023-07-07 11:50:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 41.654 Acc@5 67.390
[2023-07-07 11:50:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 120: 41.654%
[2023-07-07 11:50:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 11:50:24 RepVGG-A0] (main.py 282): INFO Train: [121/300][0/78]	eta 0:28:47 lr 4.156931	time 22.1479 (22.1479)	loss 3.2337 (3.2337)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:50:39 RepVGG-A0] (main.py 282): INFO Train: [121/300][10/78]	eta 0:03:49 lr 4.152830	time 1.1734 (3.3778)	loss 3.1420 (3.1943)	grad_norm 0.3425 (0.3579)	mem 39782MB
[2023-07-07 11:50:55 RepVGG-A0] (main.py 282): INFO Train: [121/300][20/78]	eta 0:02:25 lr 4.148728	time 1.4009 (2.5148)	loss 3.3909 (3.2238)	grad_norm 0.4370 (0.3791)	mem 39782MB
[2023-07-07 11:51:10 RepVGG-A0] (main.py 282): INFO Train: [121/300][30/78]	eta 0:01:45 lr 4.144624	time 1.1271 (2.1891)	loss 3.1782 (3.2168)	grad_norm 0.3754 (0.3653)	mem 39782MB
[2023-07-07 11:51:28 RepVGG-A0] (main.py 282): INFO Train: [121/300][40/78]	eta 0:01:19 lr 4.140518	time 2.7940 (2.1029)	loss 3.2065 (3.2178)	grad_norm 0.3326 (0.3670)	mem 39782MB
[2023-07-07 11:51:43 RepVGG-A0] (main.py 282): INFO Train: [121/300][50/78]	eta 0:00:55 lr 4.136411	time 1.2890 (1.9876)	loss 3.1934 (3.2144)	grad_norm 0.3987 (0.3655)	mem 39782MB
[2023-07-07 11:51:58 RepVGG-A0] (main.py 282): INFO Train: [121/300][60/78]	eta 0:00:34 lr 4.132302	time 1.1740 (1.9017)	loss 3.1963 (3.2236)	grad_norm 0.3280 (0.3717)	mem 39782MB
[2023-07-07 11:52:12 RepVGG-A0] (main.py 282): INFO Train: [121/300][70/78]	eta 0:00:14 lr 4.128191	time 1.4291 (1.8308)	loss 3.3180 (3.2251)	grad_norm 0.4218 (0.3689)	mem 39782MB
[2023-07-07 11:52:23 RepVGG-A0] (main.py 291): INFO EPOCH 121 training takes 0:02:21
[2023-07-07 11:52:43 RepVGG-A0] (main.py 282): INFO Train: [122/300][0/78]	eta 0:26:36 lr 4.124902	time 20.4664 (20.4664)	loss 3.1908 (3.1908)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 11:52:59 RepVGG-A0] (main.py 282): INFO Train: [122/300][10/78]	eta 0:03:40 lr 4.120788	time 1.1701 (3.2420)	loss 3.2377 (3.2528)	grad_norm 0.3633 (0.4267)	mem 39782MB
[2023-07-07 11:53:15 RepVGG-A0] (main.py 282): INFO Train: [122/300][20/78]	eta 0:02:22 lr 4.116673	time 1.1812 (2.4540)	loss 3.1272 (3.2247)	grad_norm 0.3262 (0.3902)	mem 39782MB
[2023-07-07 11:53:29 RepVGG-A0] (main.py 282): INFO Train: [122/300][30/78]	eta 0:01:42 lr 4.112556	time 1.2266 (2.1331)	loss 3.2934 (3.2117)	grad_norm 0.4414 (0.3851)	mem 39782MB
[2023-07-07 11:53:49 RepVGG-A0] (main.py 282): INFO Train: [122/300][40/78]	eta 0:01:19 lr 4.108437	time 5.1661 (2.0888)	loss 3.1689 (3.2093)	grad_norm 0.3652 (0.3833)	mem 39782MB
[2023-07-07 11:54:03 RepVGG-A0] (main.py 282): INFO Train: [122/300][50/78]	eta 0:00:55 lr 4.104317	time 1.1763 (1.9693)	loss 3.2992 (3.2066)	grad_norm 0.4328 (0.3792)	mem 39782MB
[2023-07-07 11:54:19 RepVGG-A0] (main.py 282): INFO Train: [122/300][60/78]	eta 0:00:34 lr 4.100195	time 1.2581 (1.9088)	loss 3.1741 (3.2137)	grad_norm 0.3409 (0.3807)	mem 39782MB
[2023-07-07 11:54:34 RepVGG-A0] (main.py 282): INFO Train: [122/300][70/78]	eta 0:00:14 lr 4.096072	time 1.2100 (1.8521)	loss 3.2612 (3.2116)	grad_norm 0.4102 (0.3791)	mem 39782MB
[2023-07-07 11:54:45 RepVGG-A0] (main.py 291): INFO EPOCH 122 training takes 0:02:21
[2023-07-07 11:55:07 RepVGG-A0] (main.py 282): INFO Train: [123/300][0/78]	eta 0:28:10 lr 4.092772	time 21.6698 (21.6698)	loss 3.2054 (3.2054)	grad_norm 0.4251 (0.4251)	mem 39782MB
[2023-07-07 11:55:21 RepVGG-A0] (main.py 282): INFO Train: [123/300][10/78]	eta 0:03:44 lr 4.088645	time 1.1931 (3.3022)	loss 3.1693 (3.2390)	grad_norm 0.3225 (0.4078)	mem 39782MB
[2023-07-07 11:55:36 RepVGG-A0] (main.py 282): INFO Train: [123/300][20/78]	eta 0:02:21 lr 4.084517	time 1.1734 (2.4442)	loss 3.1405 (3.2066)	grad_norm 0.3635 (0.3850)	mem 39782MB
[2023-07-07 11:55:51 RepVGG-A0] (main.py 282): INFO Train: [123/300][30/78]	eta 0:01:41 lr 4.080388	time 1.2709 (2.1235)	loss 3.6260 (3.2292)	grad_norm 0.7181 (0.4055)	mem 39782MB
[2023-07-07 11:56:09 RepVGG-A0] (main.py 282): INFO Train: [123/300][40/78]	eta 0:01:17 lr 4.076256	time 3.9100 (2.0473)	loss 5.6277 (3.8140)	grad_norm 0.5610 (0.5285)	mem 39782MB
[2023-07-07 11:56:24 RepVGG-A0] (main.py 282): INFO Train: [123/300][50/78]	eta 0:00:54 lr 4.072124	time 1.1718 (1.9346)	loss 4.5859 (4.0088)	grad_norm 0.3829 (0.4949)	mem 39782MB
[2023-07-07 11:56:38 RepVGG-A0] (main.py 282): INFO Train: [123/300][60/78]	eta 0:00:33 lr 4.067989	time 1.1776 (1.8524)	loss 3.9588 (4.0424)	grad_norm 0.2804 (0.4687)	mem 39782MB
[2023-07-07 11:56:53 RepVGG-A0] (main.py 282): INFO Train: [123/300][70/78]	eta 0:00:14 lr 4.063853	time 1.1269 (1.8024)	loss 3.6976 (4.0183)	grad_norm 0.2780 (0.4430)	mem 39782MB
[2023-07-07 11:57:05 RepVGG-A0] (main.py 291): INFO EPOCH 123 training takes 0:02:19
[2023-07-07 11:57:26 RepVGG-A0] (main.py 282): INFO Train: [124/300][0/78]	eta 0:27:22 lr 4.060543	time 21.0589 (21.0589)	loss 3.6935 (3.6935)	grad_norm 0.3113 (0.3113)	mem 39782MB
[2023-07-07 11:57:40 RepVGG-A0] (main.py 282): INFO Train: [124/300][10/78]	eta 0:03:38 lr 4.056405	time 1.1692 (3.2157)	loss 3.4659 (3.5812)	grad_norm 0.2768 (0.3000)	mem 39782MB
[2023-07-07 11:57:55 RepVGG-A0] (main.py 282): INFO Train: [124/300][20/78]	eta 0:02:19 lr 4.052264	time 1.1726 (2.3970)	loss 3.5152 (3.5503)	grad_norm 0.3314 (0.3120)	mem 39782MB
[2023-07-07 11:58:11 RepVGG-A0] (main.py 282): INFO Train: [124/300][30/78]	eta 0:01:43 lr 4.048123	time 1.1616 (2.1508)	loss 3.5365 (3.5183)	grad_norm 0.3085 (0.3089)	mem 39782MB
[2023-07-07 11:58:29 RepVGG-A0] (main.py 282): INFO Train: [124/300][40/78]	eta 0:01:18 lr 4.043979	time 2.6761 (2.0586)	loss 3.4505 (3.5077)	grad_norm 0.3648 (0.3243)	mem 39782MB
[2023-07-07 11:58:45 RepVGG-A0] (main.py 282): INFO Train: [124/300][50/78]	eta 0:00:54 lr 4.039835	time 1.1630 (1.9616)	loss 3.4718 (3.4897)	grad_norm 0.3472 (0.3260)	mem 39782MB
[2023-07-07 11:58:59 RepVGG-A0] (main.py 282): INFO Train: [124/300][60/78]	eta 0:00:33 lr 4.035688	time 1.4487 (1.8803)	loss 3.4362 (3.4803)	grad_norm 0.3672 (0.3340)	mem 39782MB
[2023-07-07 11:59:15 RepVGG-A0] (main.py 282): INFO Train: [124/300][70/78]	eta 0:00:14 lr 4.031540	time 1.2827 (1.8323)	loss 3.3710 (3.4641)	grad_norm 0.3971 (0.3335)	mem 39782MB
[2023-07-07 11:59:26 RepVGG-A0] (main.py 291): INFO EPOCH 124 training takes 0:02:21
[2023-07-07 11:59:46 RepVGG-A0] (main.py 282): INFO Train: [125/300][0/78]	eta 0:26:33 lr 4.028221	time 20.4325 (20.4325)	loss 3.4341 (3.4341)	grad_norm 0.4339 (0.4339)	mem 39782MB
[2023-07-07 12:00:00 RepVGG-A0] (main.py 282): INFO Train: [125/300][10/78]	eta 0:03:33 lr 4.024070	time 1.1724 (3.1439)	loss 3.3956 (3.3057)	grad_norm 0.4142 (0.3486)	mem 39782MB
[2023-07-07 12:00:15 RepVGG-A0] (main.py 282): INFO Train: [125/300][20/78]	eta 0:02:15 lr 4.019918	time 1.1720 (2.3447)	loss 3.3254 (3.3301)	grad_norm 0.3500 (0.3644)	mem 39782MB
[2023-07-07 12:00:30 RepVGG-A0] (main.py 282): INFO Train: [125/300][30/78]	eta 0:01:40 lr 4.015765	time 1.3351 (2.0836)	loss 3.3072 (3.3083)	grad_norm 0.3681 (0.3536)	mem 39782MB
[2023-07-07 12:00:49 RepVGG-A0] (main.py 282): INFO Train: [125/300][40/78]	eta 0:01:16 lr 4.011610	time 4.2022 (2.0208)	loss 3.2339 (3.3168)	grad_norm 0.3332 (0.3625)	mem 39782MB
[2023-07-07 12:01:03 RepVGG-A0] (main.py 282): INFO Train: [125/300][50/78]	eta 0:00:53 lr 4.007453	time 1.1745 (1.9172)	loss 3.2418 (3.3136)	grad_norm 0.3658 (0.3631)	mem 39782MB
[2023-07-07 12:01:18 RepVGG-A0] (main.py 282): INFO Train: [125/300][60/78]	eta 0:00:33 lr 4.003296	time 1.1726 (1.8435)	loss 3.3556 (3.3135)	grad_norm 0.4948 (0.3656)	mem 39782MB
[2023-07-07 12:01:34 RepVGG-A0] (main.py 282): INFO Train: [125/300][70/78]	eta 0:00:14 lr 3.999136	time 1.2357 (1.8049)	loss 3.2656 (3.3177)	grad_norm 0.3758 (0.3696)	mem 39782MB
[2023-07-07 12:01:46 RepVGG-A0] (main.py 291): INFO EPOCH 125 training takes 0:02:19
[2023-07-07 12:02:09 RepVGG-A0] (main.py 282): INFO Train: [126/300][0/78]	eta 0:29:49 lr 3.995808	time 22.9435 (22.9435)	loss 3.2943 (3.2943)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 12:02:23 RepVGG-A0] (main.py 282): INFO Train: [126/300][10/78]	eta 0:03:47 lr 3.991646	time 1.1720 (3.3529)	loss 3.2742 (3.2450)	grad_norm 0.4313 (0.3699)	mem 39782MB
[2023-07-07 12:02:36 RepVGG-A0] (main.py 282): INFO Train: [126/300][20/78]	eta 0:02:19 lr 3.987482	time 1.2348 (2.4099)	loss 4.2546 (3.5045)	grad_norm 0.7351 (0.5165)	mem 39782MB
[2023-07-07 12:02:51 RepVGG-A0] (main.py 282): INFO Train: [126/300][30/78]	eta 0:01:40 lr 3.983318	time 1.1772 (2.0985)	loss 3.5395 (3.6063)	grad_norm 0.2850 (0.4961)	mem 39782MB
[2023-07-07 12:03:10 RepVGG-A0] (main.py 282): INFO Train: [126/300][40/78]	eta 0:01:17 lr 3.979151	time 4.5605 (2.0496)	loss 3.3783 (3.5514)	grad_norm 0.2782 (0.4436)	mem 39782MB
[2023-07-07 12:03:24 RepVGG-A0] (main.py 282): INFO Train: [126/300][50/78]	eta 0:00:54 lr 3.974984	time 1.1734 (1.9334)	loss 3.2635 (3.4985)	grad_norm 0.3118 (0.4131)	mem 39782MB
[2023-07-07 12:03:40 RepVGG-A0] (main.py 282): INFO Train: [126/300][60/78]	eta 0:00:33 lr 3.970815	time 1.3570 (1.8725)	loss 3.1984 (3.4602)	grad_norm 0.2914 (0.3957)	mem 39782MB
[2023-07-07 12:03:55 RepVGG-A0] (main.py 282): INFO Train: [126/300][70/78]	eta 0:00:14 lr 3.966644	time 1.3349 (1.8238)	loss 3.2464 (3.4262)	grad_norm 0.3286 (0.3824)	mem 39782MB
[2023-07-07 12:04:07 RepVGG-A0] (main.py 291): INFO EPOCH 126 training takes 0:02:21
[2023-07-07 12:04:27 RepVGG-A0] (main.py 282): INFO Train: [127/300][0/78]	eta 0:26:31 lr 3.963307	time 20.3981 (20.3981)	loss 3.1847 (3.1847)	grad_norm 0.3726 (0.3726)	mem 39782MB
[2023-07-07 12:04:42 RepVGG-A0] (main.py 282): INFO Train: [127/300][10/78]	eta 0:03:38 lr 3.959134	time 1.3356 (3.2074)	loss 3.1260 (3.1931)	grad_norm 0.2905 (0.3446)	mem 39782MB
[2023-07-07 12:05:00 RepVGG-A0] (main.py 282): INFO Train: [127/300][20/78]	eta 0:02:25 lr 3.954960	time 1.5542 (2.5025)	loss 3.3116 (3.1985)	grad_norm 0.4340 (0.3657)	mem 39782MB
[2023-07-07 12:05:15 RepVGG-A0] (main.py 282): INFO Train: [127/300][30/78]	eta 0:01:45 lr 3.950784	time 1.4025 (2.1897)	loss 3.1989 (3.1981)	grad_norm 0.3447 (0.3619)	mem 39782MB
[2023-07-07 12:05:32 RepVGG-A0] (main.py 282): INFO Train: [127/300][40/78]	eta 0:01:18 lr 3.946607	time 1.6189 (2.0680)	loss 3.1902 (3.1873)	grad_norm 0.3421 (0.3549)	mem 39782MB
[2023-07-07 12:05:46 RepVGG-A0] (main.py 282): INFO Train: [127/300][50/78]	eta 0:00:54 lr 3.942429	time 1.1908 (1.9327)	loss 3.1890 (3.1891)	grad_norm 0.3641 (0.3589)	mem 39782MB
[2023-07-07 12:06:01 RepVGG-A0] (main.py 282): INFO Train: [127/300][60/78]	eta 0:00:33 lr 3.938249	time 1.1357 (1.8668)	loss 3.2034 (3.1967)	grad_norm 0.3602 (0.3625)	mem 39782MB
[2023-07-07 12:06:16 RepVGG-A0] (main.py 282): INFO Train: [127/300][70/78]	eta 0:00:14 lr 3.934069	time 1.4491 (1.8146)	loss 3.1976 (3.1970)	grad_norm 0.3669 (0.3619)	mem 39782MB
[2023-07-07 12:06:27 RepVGG-A0] (main.py 291): INFO EPOCH 127 training takes 0:02:20
[2023-07-07 12:06:47 RepVGG-A0] (main.py 282): INFO Train: [128/300][0/78]	eta 0:26:33 lr 3.930723	time 20.4281 (20.4281)	loss 3.2059 (3.2059)	grad_norm 0.4096 (0.4096)	mem 39782MB
[2023-07-07 12:07:02 RepVGG-A0] (main.py 282): INFO Train: [128/300][10/78]	eta 0:03:37 lr 3.926539	time 1.1730 (3.1948)	loss 3.2739 (3.1914)	grad_norm 0.5200 (0.3976)	mem 39782MB
[2023-07-07 12:07:17 RepVGG-A0] (main.py 282): INFO Train: [128/300][20/78]	eta 0:02:17 lr 3.922355	time 1.1741 (2.3783)	loss 3.2561 (3.2357)	grad_norm 0.3907 (0.4163)	mem 39782MB
[2023-07-07 12:07:32 RepVGG-A0] (main.py 282): INFO Train: [128/300][30/78]	eta 0:01:40 lr 3.918169	time 1.3271 (2.1026)	loss 3.1355 (3.2169)	grad_norm 0.3474 (0.3936)	mem 39782MB
[2023-07-07 12:07:49 RepVGG-A0] (main.py 282): INFO Train: [128/300][40/78]	eta 0:01:16 lr 3.913982	time 2.0816 (2.0086)	loss 3.2014 (3.2063)	grad_norm 0.3579 (0.3849)	mem 39782MB
[2023-07-07 12:08:04 RepVGG-A0] (main.py 282): INFO Train: [128/300][50/78]	eta 0:00:53 lr 3.909793	time 1.1725 (1.9085)	loss 3.4012 (3.2399)	grad_norm 0.5066 (0.4082)	mem 39782MB
[2023-07-07 12:08:20 RepVGG-A0] (main.py 282): INFO Train: [128/300][60/78]	eta 0:00:33 lr 3.905603	time 1.3607 (1.8502)	loss 3.2449 (3.2514)	grad_norm 0.3325 (0.4079)	mem 39782MB
[2023-07-07 12:08:35 RepVGG-A0] (main.py 282): INFO Train: [128/300][70/78]	eta 0:00:14 lr 3.901412	time 1.1346 (1.7978)	loss 3.1983 (3.2438)	grad_norm 0.3498 (0.3960)	mem 39782MB
[2023-07-07 12:08:46 RepVGG-A0] (main.py 291): INFO EPOCH 128 training takes 0:02:19
[2023-07-07 12:09:07 RepVGG-A0] (main.py 282): INFO Train: [129/300][0/78]	eta 0:26:47 lr 3.898058	time 20.6117 (20.6117)	loss 3.0350 (3.0350)	grad_norm 0.3332 (0.3332)	mem 39782MB
[2023-07-07 12:09:22 RepVGG-A0] (main.py 282): INFO Train: [129/300][10/78]	eta 0:03:43 lr 3.893865	time 1.1724 (3.2907)	loss 3.1609 (3.1175)	grad_norm 0.3821 (0.3543)	mem 39782MB
[2023-07-07 12:09:37 RepVGG-A0] (main.py 282): INFO Train: [129/300][20/78]	eta 0:02:21 lr 3.889670	time 1.4376 (2.4338)	loss 3.1134 (3.1240)	grad_norm 0.3358 (0.3566)	mem 39782MB
[2023-07-07 12:09:53 RepVGG-A0] (main.py 282): INFO Train: [129/300][30/78]	eta 0:01:43 lr 3.885475	time 1.4402 (2.1517)	loss 3.1567 (3.1344)	grad_norm 0.3979 (0.3596)	mem 39782MB
[2023-07-07 12:10:11 RepVGG-A0] (main.py 282): INFO Train: [129/300][40/78]	eta 0:01:18 lr 3.881277	time 4.1830 (2.0717)	loss 3.3612 (3.1920)	grad_norm 0.4657 (0.3996)	mem 39782MB
[2023-07-07 12:10:26 RepVGG-A0] (main.py 282): INFO Train: [129/300][50/78]	eta 0:00:55 lr 3.877079	time 1.1269 (1.9649)	loss 3.2223 (3.2007)	grad_norm 0.3066 (0.3906)	mem 39782MB
[2023-07-07 12:10:41 RepVGG-A0] (main.py 282): INFO Train: [129/300][60/78]	eta 0:00:33 lr 3.872880	time 1.3855 (1.8788)	loss 3.1846 (3.1952)	grad_norm 0.3338 (0.3834)	mem 39782MB
[2023-07-07 12:10:56 RepVGG-A0] (main.py 282): INFO Train: [129/300][70/78]	eta 0:00:14 lr 3.868679	time 1.3841 (1.8236)	loss 3.1399 (3.1899)	grad_norm 0.3892 (0.3804)	mem 39782MB
[2023-07-07 12:11:07 RepVGG-A0] (main.py 291): INFO EPOCH 129 training takes 0:02:20
[2023-07-07 12:11:28 RepVGG-A0] (main.py 282): INFO Train: [130/300][0/78]	eta 0:26:55 lr 3.865317	time 20.7128 (20.7128)	loss 3.1521 (3.1521)	grad_norm 0.3896 (0.3896)	mem 39782MB
[2023-07-07 12:11:43 RepVGG-A0] (main.py 282): INFO Train: [130/300][10/78]	eta 0:03:42 lr 3.861114	time 1.1902 (3.2764)	loss 3.2285 (3.1163)	grad_norm 0.4363 (0.3777)	mem 39782MB
[2023-07-07 12:11:58 RepVGG-A0] (main.py 282): INFO Train: [130/300][20/78]	eta 0:02:20 lr 3.856910	time 1.1762 (2.4300)	loss 3.1819 (3.1424)	grad_norm 0.3774 (0.3877)	mem 39782MB
[2023-07-07 12:12:14 RepVGG-A0] (main.py 282): INFO Train: [130/300][30/78]	eta 0:01:43 lr 3.852705	time 1.3923 (2.1532)	loss 3.1469 (3.1717)	grad_norm 0.3818 (0.4039)	mem 39782MB
[2023-07-07 12:12:31 RepVGG-A0] (main.py 282): INFO Train: [130/300][40/78]	eta 0:01:18 lr 3.848499	time 3.7138 (2.0589)	loss 3.0704 (3.1678)	grad_norm 0.3226 (0.3881)	mem 39782MB
[2023-07-07 12:12:46 RepVGG-A0] (main.py 282): INFO Train: [130/300][50/78]	eta 0:00:54 lr 3.844291	time 1.1735 (1.9448)	loss 3.1709 (3.1665)	grad_norm 0.3681 (0.3855)	mem 39782MB
[2023-07-07 12:13:00 RepVGG-A0] (main.py 282): INFO Train: [130/300][60/78]	eta 0:00:33 lr 3.840082	time 1.2111 (1.8536)	loss 3.1793 (3.1661)	grad_norm 0.4122 (0.3846)	mem 39782MB
[2023-07-07 12:13:16 RepVGG-A0] (main.py 282): INFO Train: [130/300][70/78]	eta 0:00:14 lr 3.835872	time 1.2114 (1.8089)	loss 3.2448 (3.1684)	grad_norm 0.4715 (0.3867)	mem 39782MB
[2023-07-07 12:13:27 RepVGG-A0] (main.py 291): INFO EPOCH 130 training takes 0:02:20
[2023-07-07 12:13:49 RepVGG-A0] (main.py 282): INFO Train: [131/300][0/78]	eta 0:28:28 lr 3.832503	time 21.9012 (21.9012)	loss 3.1630 (3.1630)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 12:14:04 RepVGG-A0] (main.py 282): INFO Train: [131/300][10/78]	eta 0:03:48 lr 3.828291	time 1.1724 (3.3549)	loss 3.1485 (3.1750)	grad_norm 0.3330 (0.3943)	mem 39782MB
[2023-07-07 12:14:18 RepVGG-A0] (main.py 282): INFO Train: [131/300][20/78]	eta 0:02:21 lr 3.824078	time 1.1723 (2.4361)	loss 3.0294 (3.1365)	grad_norm 0.3571 (0.3748)	mem 39782MB
[2023-07-07 12:14:34 RepVGG-A0] (main.py 282): INFO Train: [131/300][30/78]	eta 0:01:43 lr 3.819864	time 1.4022 (2.1577)	loss 3.2001 (3.1343)	grad_norm 0.4180 (0.3766)	mem 39782MB
[2023-07-07 12:14:52 RepVGG-A0] (main.py 282): INFO Train: [131/300][40/78]	eta 0:01:18 lr 3.815649	time 4.1113 (2.0753)	loss 3.1045 (3.1489)	grad_norm 0.4111 (0.3874)	mem 39782MB
[2023-07-07 12:15:07 RepVGG-A0] (main.py 282): INFO Train: [131/300][50/78]	eta 0:00:54 lr 3.811432	time 1.1730 (1.9529)	loss 3.0317 (3.1478)	grad_norm 0.3226 (0.3814)	mem 39782MB
[2023-07-07 12:15:22 RepVGG-A0] (main.py 282): INFO Train: [131/300][60/78]	eta 0:00:33 lr 3.807215	time 1.1278 (1.8809)	loss 3.1445 (3.1498)	grad_norm 0.4056 (0.3848)	mem 39782MB
[2023-07-07 12:15:36 RepVGG-A0] (main.py 282): INFO Train: [131/300][70/78]	eta 0:00:14 lr 3.802996	time 1.3419 (1.8166)	loss 3.1334 (3.1547)	grad_norm 0.3524 (0.3884)	mem 39782MB
[2023-07-07 12:15:48 RepVGG-A0] (main.py 291): INFO EPOCH 131 training takes 0:02:21
[2023-07-07 12:16:10 RepVGG-A0] (main.py 282): INFO Train: [132/300][0/78]	eta 0:28:11 lr 3.799620	time 21.6820 (21.6820)	loss 3.1193 (3.1193)	grad_norm 0.3986 (0.3986)	mem 39782MB
[2023-07-07 12:16:25 RepVGG-A0] (main.py 282): INFO Train: [132/300][10/78]	eta 0:03:48 lr 3.795400	time 1.1733 (3.3636)	loss 3.1210 (3.1102)	grad_norm 0.3565 (0.3877)	mem 39782MB
[2023-07-07 12:16:41 RepVGG-A0] (main.py 282): INFO Train: [132/300][20/78]	eta 0:02:24 lr 3.791178	time 1.2770 (2.4925)	loss 3.1515 (3.0971)	grad_norm 0.4164 (0.3764)	mem 39782MB
[2023-07-07 12:16:57 RepVGG-A0] (main.py 282): INFO Train: [132/300][30/78]	eta 0:01:45 lr 3.786955	time 1.7311 (2.2010)	loss 3.2308 (3.1214)	grad_norm 0.4345 (0.3963)	mem 39782MB
[2023-07-07 12:17:14 RepVGG-A0] (main.py 282): INFO Train: [132/300][40/78]	eta 0:01:19 lr 3.782731	time 4.0696 (2.0923)	loss 3.0752 (3.1217)	grad_norm 0.3607 (0.3917)	mem 39782MB
[2023-07-07 12:17:30 RepVGG-A0] (main.py 282): INFO Train: [132/300][50/78]	eta 0:00:55 lr 3.778506	time 1.1742 (1.9848)	loss 3.0646 (3.1293)	grad_norm 0.3569 (0.3917)	mem 39782MB
[2023-07-07 12:17:45 RepVGG-A0] (main.py 282): INFO Train: [132/300][60/78]	eta 0:00:34 lr 3.774280	time 1.3342 (1.9125)	loss 3.2626 (3.1310)	grad_norm 0.4383 (0.3900)	mem 39782MB
[2023-07-07 12:18:01 RepVGG-A0] (main.py 282): INFO Train: [132/300][70/78]	eta 0:00:14 lr 3.770053	time 1.1819 (1.8715)	loss 3.1228 (3.1319)	grad_norm 0.3495 (0.3890)	mem 39782MB
[2023-07-07 12:18:13 RepVGG-A0] (main.py 291): INFO EPOCH 132 training takes 0:02:24
[2023-07-07 12:18:35 RepVGG-A0] (main.py 282): INFO Train: [133/300][0/78]	eta 0:27:43 lr 3.766671	time 21.3275 (21.3275)	loss 3.1590 (3.1590)	grad_norm 0.4493 (0.4493)	mem 39782MB
[2023-07-07 12:18:50 RepVGG-A0] (main.py 282): INFO Train: [133/300][10/78]	eta 0:03:49 lr 3.762442	time 1.1893 (3.3725)	loss 3.1637 (3.1661)	grad_norm 0.3868 (0.4279)	mem 39782MB
[2023-07-07 12:19:04 RepVGG-A0] (main.py 282): INFO Train: [133/300][20/78]	eta 0:02:21 lr 3.758213	time 1.1794 (2.4372)	loss 3.0952 (3.1354)	grad_norm 0.3395 (0.3970)	mem 39782MB
[2023-07-07 12:19:20 RepVGG-A0] (main.py 282): INFO Train: [133/300][30/78]	eta 0:01:44 lr 3.753982	time 1.3321 (2.1686)	loss 3.2723 (3.1400)	grad_norm 0.5089 (0.3999)	mem 39782MB
[2023-07-07 12:19:38 RepVGG-A0] (main.py 282): INFO Train: [133/300][40/78]	eta 0:01:18 lr 3.749750	time 3.0607 (2.0788)	loss 3.3144 (3.1774)	grad_norm 0.4644 (0.4221)	mem 39782MB
[2023-07-07 12:19:53 RepVGG-A0] (main.py 282): INFO Train: [133/300][50/78]	eta 0:00:54 lr 3.745517	time 1.1741 (1.9621)	loss 3.1680 (3.1787)	grad_norm 0.3405 (0.4122)	mem 39782MB
[2023-07-07 12:20:08 RepVGG-A0] (main.py 282): INFO Train: [133/300][60/78]	eta 0:00:34 lr 3.741283	time 1.2586 (1.8894)	loss 3.0098 (3.1669)	grad_norm 0.3420 (0.4020)	mem 39782MB
[2023-07-07 12:20:24 RepVGG-A0] (main.py 282): INFO Train: [133/300][70/78]	eta 0:00:14 lr 3.737049	time 1.2800 (1.8389)	loss 3.0870 (3.1610)	grad_norm 0.3681 (0.3957)	mem 39782MB
[2023-07-07 12:20:35 RepVGG-A0] (main.py 291): INFO EPOCH 133 training takes 0:02:21
[2023-07-07 12:20:56 RepVGG-A0] (main.py 282): INFO Train: [134/300][0/78]	eta 0:27:50 lr 3.733660	time 21.4139 (21.4139)	loss 3.0845 (3.0845)	grad_norm 0.4067 (0.4067)	mem 39782MB
[2023-07-07 12:21:10 RepVGG-A0] (main.py 282): INFO Train: [134/300][10/78]	eta 0:03:33 lr 3.729423	time 1.1925 (3.1463)	loss 3.0477 (3.0791)	grad_norm 0.3856 (0.3913)	mem 39782MB
[2023-07-07 12:21:24 RepVGG-A0] (main.py 282): INFO Train: [134/300][20/78]	eta 0:02:15 lr 3.725186	time 1.1712 (2.3387)	loss 3.0968 (3.0770)	grad_norm 0.3655 (0.3833)	mem 39782MB
[2023-07-07 12:21:39 RepVGG-A0] (main.py 282): INFO Train: [134/300][30/78]	eta 0:01:38 lr 3.720948	time 1.3307 (2.0601)	loss 3.1240 (3.0879)	grad_norm 0.3957 (0.3810)	mem 39782MB
[2023-07-07 12:21:58 RepVGG-A0] (main.py 282): INFO Train: [134/300][40/78]	eta 0:01:17 lr 3.716708	time 4.1643 (2.0283)	loss 3.1306 (3.0947)	grad_norm 0.4246 (0.3872)	mem 39782MB
[2023-07-07 12:22:13 RepVGG-A0] (main.py 282): INFO Train: [134/300][50/78]	eta 0:00:53 lr 3.712468	time 1.1936 (1.9197)	loss 3.0966 (3.1040)	grad_norm 0.3637 (0.3909)	mem 39782MB
[2023-07-07 12:22:27 RepVGG-A0] (main.py 282): INFO Train: [134/300][60/78]	eta 0:00:33 lr 3.708227	time 1.1742 (1.8426)	loss 3.1236 (3.1020)	grad_norm 0.3580 (0.3857)	mem 39782MB
[2023-07-07 12:22:42 RepVGG-A0] (main.py 282): INFO Train: [134/300][70/78]	eta 0:00:14 lr 3.703985	time 1.2106 (1.7933)	loss 3.2522 (3.1060)	grad_norm 0.4400 (0.3887)	mem 39782MB
[2023-07-07 12:22:56 RepVGG-A0] (main.py 291): INFO EPOCH 134 training takes 0:02:20
[2023-07-07 12:23:17 RepVGG-A0] (main.py 282): INFO Train: [135/300][0/78]	eta 0:27:37 lr 3.700590	time 21.2474 (21.2474)	loss 3.0522 (3.0522)	grad_norm 0.3975 (0.3975)	mem 39782MB
[2023-07-07 12:23:31 RepVGG-A0] (main.py 282): INFO Train: [135/300][10/78]	eta 0:03:37 lr 3.696347	time 1.1702 (3.2039)	loss 3.0318 (3.0494)	grad_norm 0.3464 (0.3517)	mem 39782MB
[2023-07-07 12:23:46 RepVGG-A0] (main.py 282): INFO Train: [135/300][20/78]	eta 0:02:20 lr 3.692102	time 1.1726 (2.4217)	loss 3.2975 (3.1109)	grad_norm 0.5393 (0.4071)	mem 39782MB
[2023-07-07 12:24:02 RepVGG-A0] (main.py 282): INFO Train: [135/300][30/78]	eta 0:01:42 lr 3.687856	time 1.5003 (2.1390)	loss 2.9749 (3.1181)	grad_norm 0.3365 (0.4024)	mem 39782MB
[2023-07-07 12:24:20 RepVGG-A0] (main.py 282): INFO Train: [135/300][40/78]	eta 0:01:17 lr 3.683610	time 3.5985 (2.0510)	loss 2.9852 (3.1057)	grad_norm 0.3426 (0.3885)	mem 39782MB
[2023-07-07 12:24:35 RepVGG-A0] (main.py 282): INFO Train: [135/300][50/78]	eta 0:00:54 lr 3.679363	time 1.1774 (1.9427)	loss 3.0030 (3.1042)	grad_norm 0.3445 (0.3864)	mem 39782MB
[2023-07-07 12:24:50 RepVGG-A0] (main.py 282): INFO Train: [135/300][60/78]	eta 0:00:33 lr 3.675115	time 1.3475 (1.8702)	loss 3.0384 (3.0996)	grad_norm 0.3513 (0.3794)	mem 39782MB
[2023-07-07 12:25:04 RepVGG-A0] (main.py 282): INFO Train: [135/300][70/78]	eta 0:00:14 lr 3.670866	time 1.2661 (1.8137)	loss 3.3003 (3.1131)	grad_norm 0.4666 (0.3906)	mem 39782MB
[2023-07-07 12:25:16 RepVGG-A0] (main.py 291): INFO EPOCH 135 training takes 0:02:20
[2023-07-07 12:25:38 RepVGG-A0] (main.py 282): INFO Train: [136/300][0/78]	eta 0:28:27 lr 3.667466	time 21.8866 (21.8866)	loss 3.0819 (3.0819)	grad_norm 0.3493 (0.3493)	mem 39782MB
[2023-07-07 12:25:53 RepVGG-A0] (main.py 282): INFO Train: [136/300][10/78]	eta 0:03:47 lr 3.663215	time 1.2002 (3.3515)	loss 3.0973 (3.0527)	grad_norm 0.3979 (0.3630)	mem 39782MB
[2023-07-07 12:26:08 RepVGG-A0] (main.py 282): INFO Train: [136/300][20/78]	eta 0:02:22 lr 3.658964	time 1.1710 (2.4520)	loss 3.0566 (3.0538)	grad_norm 0.3678 (0.3712)	mem 39782MB
[2023-07-07 12:26:23 RepVGG-A0] (main.py 282): INFO Train: [136/300][30/78]	eta 0:01:43 lr 3.654712	time 1.3085 (2.1599)	loss 3.0549 (3.0645)	grad_norm 0.3802 (0.3806)	mem 39782MB
[2023-07-07 12:26:41 RepVGG-A0] (main.py 282): INFO Train: [136/300][40/78]	eta 0:01:18 lr 3.650459	time 3.2428 (2.0625)	loss 3.0503 (3.0592)	grad_norm 0.3895 (0.3786)	mem 39782MB
[2023-07-07 12:26:56 RepVGG-A0] (main.py 282): INFO Train: [136/300][50/78]	eta 0:00:54 lr 3.646205	time 1.2339 (1.9567)	loss 3.2559 (3.0723)	grad_norm 0.4674 (0.3877)	mem 39782MB
[2023-07-07 12:27:11 RepVGG-A0] (main.py 282): INFO Train: [136/300][60/78]	eta 0:00:33 lr 3.641950	time 1.2698 (1.8693)	loss 3.0901 (3.0816)	grad_norm 0.3659 (0.3899)	mem 39782MB
[2023-07-07 12:27:26 RepVGG-A0] (main.py 282): INFO Train: [136/300][70/78]	eta 0:00:14 lr 3.637695	time 1.2985 (1.8238)	loss 3.0879 (3.0778)	grad_norm 0.3520 (0.3849)	mem 39782MB
[2023-07-07 12:27:37 RepVGG-A0] (main.py 291): INFO EPOCH 136 training takes 0:02:20
[2023-07-07 12:27:59 RepVGG-A0] (main.py 282): INFO Train: [137/300][0/78]	eta 0:28:03 lr 3.634290	time 21.5785 (21.5785)	loss 3.0220 (3.0220)	grad_norm 0.3797 (0.3797)	mem 39782MB
[2023-07-07 12:28:14 RepVGG-A0] (main.py 282): INFO Train: [137/300][10/78]	eta 0:03:44 lr 3.630033	time 1.1729 (3.3047)	loss 3.1982 (3.1390)	grad_norm 0.4715 (0.4509)	mem 39782MB
[2023-07-07 12:28:28 RepVGG-A0] (main.py 282): INFO Train: [137/300][20/78]	eta 0:02:19 lr 3.625775	time 1.1722 (2.4133)	loss 3.1541 (3.1260)	grad_norm 0.4067 (0.4225)	mem 39782MB
[2023-07-07 12:28:45 RepVGG-A0] (main.py 282): INFO Train: [137/300][30/78]	eta 0:01:44 lr 3.621517	time 1.6706 (2.1831)	loss 2.9964 (3.1037)	grad_norm 0.3459 (0.3985)	mem 39782MB
[2023-07-07 12:29:02 RepVGG-A0] (main.py 282): INFO Train: [137/300][40/78]	eta 0:01:18 lr 3.617258	time 3.4145 (2.0576)	loss 3.0899 (3.1054)	grad_norm 0.3950 (0.3992)	mem 39782MB
[2023-07-07 12:29:16 RepVGG-A0] (main.py 282): INFO Train: [137/300][50/78]	eta 0:00:54 lr 3.612998	time 1.1745 (1.9410)	loss 3.1912 (3.1059)	grad_norm 0.4106 (0.4028)	mem 39782MB
[2023-07-07 12:29:32 RepVGG-A0] (main.py 282): INFO Train: [137/300][60/78]	eta 0:00:33 lr 3.608737	time 1.3481 (1.8715)	loss 3.0579 (3.1024)	grad_norm 0.3766 (0.3988)	mem 39782MB
[2023-07-07 12:29:48 RepVGG-A0] (main.py 282): INFO Train: [137/300][70/78]	eta 0:00:14 lr 3.604476	time 1.3781 (1.8385)	loss 3.0901 (3.0978)	grad_norm 0.3647 (0.3944)	mem 39782MB
[2023-07-07 12:29:59 RepVGG-A0] (main.py 291): INFO EPOCH 137 training takes 0:02:21
[2023-07-07 12:30:20 RepVGG-A0] (main.py 282): INFO Train: [138/300][0/78]	eta 0:27:47 lr 3.601066	time 21.3817 (21.3817)	loss 2.9612 (2.9612)	grad_norm 0.3662 (0.3662)	mem 39782MB
[2023-07-07 12:30:35 RepVGG-A0] (main.py 282): INFO Train: [138/300][10/78]	eta 0:03:44 lr 3.596804	time 1.1733 (3.3003)	loss 3.0420 (3.0879)	grad_norm 0.4469 (0.4457)	mem 39782MB
[2023-07-07 12:30:50 RepVGG-A0] (main.py 282): INFO Train: [138/300][20/78]	eta 0:02:21 lr 3.592540	time 1.1730 (2.4376)	loss 3.0954 (3.0839)	grad_norm 0.3703 (0.4149)	mem 39782MB
[2023-07-07 12:31:05 RepVGG-A0] (main.py 282): INFO Train: [138/300][30/78]	eta 0:01:42 lr 3.588276	time 1.3764 (2.1286)	loss 3.0464 (3.0705)	grad_norm 0.4117 (0.4038)	mem 39782MB
[2023-07-07 12:31:23 RepVGG-A0] (main.py 282): INFO Train: [138/300][40/78]	eta 0:01:17 lr 3.584011	time 4.0881 (2.0481)	loss 3.0127 (3.0620)	grad_norm 0.3636 (0.3978)	mem 39782MB
[2023-07-07 12:31:38 RepVGG-A0] (main.py 282): INFO Train: [138/300][50/78]	eta 0:00:54 lr 3.579746	time 1.1925 (1.9366)	loss 3.0086 (3.0660)	grad_norm 0.3665 (0.3944)	mem 39782MB
[2023-07-07 12:31:53 RepVGG-A0] (main.py 282): INFO Train: [138/300][60/78]	eta 0:00:33 lr 3.575480	time 1.1270 (1.8751)	loss 3.1540 (3.0737)	grad_norm 0.4636 (0.3988)	mem 39782MB
[2023-07-07 12:32:09 RepVGG-A0] (main.py 282): INFO Train: [138/300][70/78]	eta 0:00:14 lr 3.571213	time 1.1268 (1.8270)	loss 3.1476 (3.0958)	grad_norm 0.3824 (0.4076)	mem 39782MB
[2023-07-07 12:32:20 RepVGG-A0] (main.py 291): INFO EPOCH 138 training takes 0:02:21
[2023-07-07 12:32:41 RepVGG-A0] (main.py 282): INFO Train: [139/300][0/78]	eta 0:27:12 lr 3.567799	time 20.9326 (20.9326)	loss 3.0203 (3.0203)	grad_norm 0.3523 (0.3523)	mem 39782MB
[2023-07-07 12:32:56 RepVGG-A0] (main.py 282): INFO Train: [139/300][10/78]	eta 0:03:42 lr 3.563531	time 1.1924 (3.2748)	loss 3.0338 (3.0681)	grad_norm 0.3781 (0.3952)	mem 39782MB
[2023-07-07 12:33:12 RepVGG-A0] (main.py 282): INFO Train: [139/300][20/78]	eta 0:02:23 lr 3.559262	time 1.3980 (2.4735)	loss 3.0844 (3.0415)	grad_norm 0.4609 (0.3871)	mem 39782MB
[2023-07-07 12:33:25 RepVGG-A0] (main.py 282): INFO Train: [139/300][30/78]	eta 0:01:40 lr 3.554993	time 1.1264 (2.1019)	loss 3.0726 (3.0618)	grad_norm 0.3551 (0.3905)	mem 39782MB
[2023-07-07 12:33:43 RepVGG-A0] (main.py 282): INFO Train: [139/300][40/78]	eta 0:01:16 lr 3.550723	time 3.6513 (2.0243)	loss 3.0919 (3.0647)	grad_norm 0.4109 (0.3861)	mem 39782MB
[2023-07-07 12:33:59 RepVGG-A0] (main.py 282): INFO Train: [139/300][50/78]	eta 0:00:54 lr 3.546452	time 1.1721 (1.9395)	loss 3.0529 (3.0662)	grad_norm 0.3252 (0.3840)	mem 39782MB
[2023-07-07 12:34:14 RepVGG-A0] (main.py 282): INFO Train: [139/300][60/78]	eta 0:00:33 lr 3.542181	time 1.3613 (1.8679)	loss 3.1675 (3.0713)	grad_norm 0.4667 (0.3906)	mem 39782MB
[2023-07-07 12:34:29 RepVGG-A0] (main.py 282): INFO Train: [139/300][70/78]	eta 0:00:14 lr 3.537909	time 1.3704 (1.8175)	loss 3.0696 (3.0759)	grad_norm 0.3444 (0.3918)	mem 39782MB
[2023-07-07 12:34:41 RepVGG-A0] (main.py 291): INFO EPOCH 139 training takes 0:02:21
[2023-07-07 12:35:03 RepVGG-A0] (main.py 282): INFO Train: [140/300][0/78]	eta 0:28:52 lr 3.534491	time 22.2166 (22.2166)	loss 2.9390 (2.9390)	grad_norm 0.3325 (0.3325)	mem 39782MB
[2023-07-07 12:35:17 RepVGG-A0] (main.py 282): INFO Train: [140/300][10/78]	eta 0:03:45 lr 3.530218	time 1.1836 (3.3138)	loss 3.0418 (3.0256)	grad_norm 0.4228 (0.3946)	mem 39782MB
[2023-07-07 12:35:31 RepVGG-A0] (main.py 282): INFO Train: [140/300][20/78]	eta 0:02:17 lr 3.525945	time 1.1710 (2.3705)	loss 3.0297 (3.0441)	grad_norm 0.3781 (0.3896)	mem 39782MB
[2023-07-07 12:35:46 RepVGG-A0] (main.py 282): INFO Train: [140/300][30/78]	eta 0:01:40 lr 3.521670	time 1.3660 (2.0982)	loss 3.0061 (3.0405)	grad_norm 0.3498 (0.3859)	mem 39782MB
[2023-07-07 12:36:04 RepVGG-A0] (main.py 282): INFO Train: [140/300][40/78]	eta 0:01:16 lr 3.517396	time 3.7230 (2.0160)	loss 3.0823 (3.0564)	grad_norm 0.3589 (0.3966)	mem 39782MB
[2023-07-07 12:36:19 RepVGG-A0] (main.py 282): INFO Train: [140/300][50/78]	eta 0:00:53 lr 3.513120	time 1.1727 (1.9265)	loss 3.0355 (3.0493)	grad_norm 0.3936 (0.3909)	mem 39782MB
[2023-07-07 12:36:34 RepVGG-A0] (main.py 282): INFO Train: [140/300][60/78]	eta 0:00:33 lr 3.508845	time 1.1790 (1.8590)	loss 3.0166 (3.0573)	grad_norm 0.3913 (0.3921)	mem 39782MB
[2023-07-07 12:36:50 RepVGG-A0] (main.py 282): INFO Train: [140/300][70/78]	eta 0:00:14 lr 3.504568	time 1.3562 (1.8134)	loss 3.0604 (3.0594)	grad_norm 0.3965 (0.3920)	mem 39782MB
[2023-07-07 12:37:01 RepVGG-A0] (main.py 291): INFO EPOCH 140 training takes 0:02:20
[2023-07-07 12:37:18 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.359 (17.359)	Loss 3.0108 (3.0108)	Acc@1 38.049 (38.049)	Acc@5 64.020 (64.020)	Mem 39782MB
[2023-07-07 12:37:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 38.532 Acc@5 64.328
[2023-07-07 12:37:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 140: 38.532%
[2023-07-07 12:37:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 12:37:40 RepVGG-A0] (main.py 282): INFO Train: [141/300][0/78]	eta 0:26:34 lr 3.501147	time 20.4485 (20.4485)	loss 3.0599 (3.0599)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 12:37:55 RepVGG-A0] (main.py 282): INFO Train: [141/300][10/78]	eta 0:03:39 lr 3.496869	time 1.1963 (3.2302)	loss 2.9780 (3.0364)	grad_norm 0.3821 (0.3968)	mem 39782MB
[2023-07-07 12:38:10 RepVGG-A0] (main.py 282): INFO Train: [141/300][20/78]	eta 0:02:19 lr 3.492591	time 1.1754 (2.4109)	loss 3.0521 (3.0412)	grad_norm 0.3761 (0.3932)	mem 39782MB
[2023-07-07 12:38:25 RepVGG-A0] (main.py 282): INFO Train: [141/300][30/78]	eta 0:01:41 lr 3.488313	time 1.4082 (2.1165)	loss 3.0408 (3.0359)	grad_norm 0.3603 (0.3842)	mem 39782MB
[2023-07-07 12:38:43 RepVGG-A0] (main.py 282): INFO Train: [141/300][40/78]	eta 0:01:17 lr 3.484034	time 2.8428 (2.0326)	loss 3.0718 (3.0439)	grad_norm 0.4305 (0.3917)	mem 39782MB
[2023-07-07 12:38:59 RepVGG-A0] (main.py 282): INFO Train: [141/300][50/78]	eta 0:00:54 lr 3.479754	time 1.2982 (1.9369)	loss 3.0183 (3.0447)	grad_norm 0.3592 (0.3885)	mem 39782MB
[2023-07-07 12:39:13 RepVGG-A0] (main.py 282): INFO Train: [141/300][60/78]	eta 0:00:33 lr 3.475474	time 1.2083 (1.8584)	loss 3.0021 (3.0501)	grad_norm 0.3673 (0.3943)	mem 39782MB
[2023-07-07 12:39:29 RepVGG-A0] (main.py 282): INFO Train: [141/300][70/78]	eta 0:00:14 lr 3.471194	time 1.1568 (1.8122)	loss 3.0790 (3.0510)	grad_norm 0.4624 (0.3934)	mem 39782MB
[2023-07-07 12:39:40 RepVGG-A0] (main.py 291): INFO EPOCH 141 training takes 0:02:20
[2023-07-07 12:40:02 RepVGG-A0] (main.py 282): INFO Train: [142/300][0/78]	eta 0:27:46 lr 3.467769	time 21.3687 (21.3687)	loss 3.0305 (3.0305)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 12:40:16 RepVGG-A0] (main.py 282): INFO Train: [142/300][10/78]	eta 0:03:40 lr 3.463488	time 1.1731 (3.2434)	loss 3.0058 (3.0033)	grad_norm 0.3824 (0.3771)	mem 39782MB
[2023-07-07 12:40:31 RepVGG-A0] (main.py 282): INFO Train: [142/300][20/78]	eta 0:02:21 lr 3.459206	time 1.2754 (2.4372)	loss 3.0087 (3.0089)	grad_norm 0.4019 (0.3849)	mem 39782MB
[2023-07-07 12:40:46 RepVGG-A0] (main.py 282): INFO Train: [142/300][30/78]	eta 0:01:42 lr 3.454924	time 1.6108 (2.1305)	loss 3.1165 (3.0151)	grad_norm 0.4027 (0.3831)	mem 39782MB
[2023-07-07 12:41:04 RepVGG-A0] (main.py 282): INFO Train: [142/300][40/78]	eta 0:01:17 lr 3.450641	time 2.7731 (2.0366)	loss 3.1895 (3.0435)	grad_norm 0.4964 (0.4087)	mem 39782MB
[2023-07-07 12:41:18 RepVGG-A0] (main.py 282): INFO Train: [142/300][50/78]	eta 0:00:53 lr 3.446358	time 1.3411 (1.9193)	loss 2.9677 (3.0456)	grad_norm 0.3573 (0.4009)	mem 39782MB
[2023-07-07 12:41:34 RepVGG-A0] (main.py 282): INFO Train: [142/300][60/78]	eta 0:00:33 lr 3.442074	time 1.1808 (1.8571)	loss 3.0495 (3.0459)	grad_norm 0.3691 (0.3967)	mem 39782MB
[2023-07-07 12:41:49 RepVGG-A0] (main.py 282): INFO Train: [142/300][70/78]	eta 0:00:14 lr 3.437790	time 1.2601 (1.8114)	loss 3.1083 (3.0458)	grad_norm 0.4186 (0.3950)	mem 39782MB
[2023-07-07 12:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 142 training takes 0:02:19
[2023-07-07 12:42:20 RepVGG-A0] (main.py 282): INFO Train: [143/300][0/78]	eta 0:26:16 lr 3.434362	time 20.2117 (20.2117)	loss 3.0590 (3.0590)	grad_norm 0.3851 (0.3851)	mem 39782MB
[2023-07-07 12:42:39 RepVGG-A0] (main.py 282): INFO Train: [143/300][10/78]	eta 0:03:57 lr 3.430077	time 1.1258 (3.4966)	loss 2.9819 (2.9775)	grad_norm 0.4055 (0.3765)	mem 39782MB
[2023-07-07 12:42:52 RepVGG-A0] (main.py 282): INFO Train: [143/300][20/78]	eta 0:02:23 lr 3.425792	time 1.1981 (2.4692)	loss 3.0837 (3.0047)	grad_norm 0.4733 (0.3959)	mem 39782MB
[2023-07-07 12:43:06 RepVGG-A0] (main.py 282): INFO Train: [143/300][30/78]	eta 0:01:41 lr 3.421506	time 1.1827 (2.1134)	loss 3.1363 (3.0239)	grad_norm 0.3792 (0.3978)	mem 39782MB
[2023-07-07 12:43:25 RepVGG-A0] (main.py 282): INFO Train: [143/300][40/78]	eta 0:01:18 lr 3.417220	time 4.8374 (2.0603)	loss 3.1627 (3.0334)	grad_norm 0.4165 (0.3976)	mem 39782MB
[2023-07-07 12:43:40 RepVGG-A0] (main.py 282): INFO Train: [143/300][50/78]	eta 0:00:54 lr 3.412934	time 1.1275 (1.9584)	loss 3.0152 (3.0367)	grad_norm 0.3946 (0.3977)	mem 39782MB
[2023-07-07 12:43:55 RepVGG-A0] (main.py 282): INFO Train: [143/300][60/78]	eta 0:00:34 lr 3.408647	time 1.1749 (1.8895)	loss 3.1276 (3.0380)	grad_norm 0.4138 (0.3988)	mem 39782MB
[2023-07-07 12:44:10 RepVGG-A0] (main.py 282): INFO Train: [143/300][70/78]	eta 0:00:14 lr 3.404360	time 1.6428 (1.8292)	loss 2.9785 (3.0406)	grad_norm 0.4123 (0.3991)	mem 39782MB
[2023-07-07 12:44:22 RepVGG-A0] (main.py 291): INFO EPOCH 143 training takes 0:02:22
[2023-07-07 12:44:44 RepVGG-A0] (main.py 282): INFO Train: [144/300][0/78]	eta 0:27:55 lr 3.400930	time 21.4769 (21.4769)	loss 2.9607 (2.9607)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:44:58 RepVGG-A0] (main.py 282): INFO Train: [144/300][10/78]	eta 0:03:41 lr 3.396642	time 1.1716 (3.2550)	loss 3.0794 (2.9911)	grad_norm 0.4112 (0.4074)	mem 39782MB
[2023-07-07 12:45:12 RepVGG-A0] (main.py 282): INFO Train: [144/300][20/78]	eta 0:02:17 lr 3.392354	time 1.1736 (2.3628)	loss 3.0262 (3.0051)	grad_norm 0.3925 (0.4080)	mem 39782MB
[2023-07-07 12:45:27 RepVGG-A0] (main.py 282): INFO Train: [144/300][30/78]	eta 0:01:39 lr 3.388065	time 1.3644 (2.0738)	loss 3.0180 (3.0116)	grad_norm 0.3883 (0.4014)	mem 39782MB
[2023-07-07 12:45:45 RepVGG-A0] (main.py 282): INFO Train: [144/300][40/78]	eta 0:01:16 lr 3.383776	time 3.6952 (2.0258)	loss 3.0784 (3.0101)	grad_norm 0.4080 (0.3968)	mem 39782MB
[2023-07-07 12:46:01 RepVGG-A0] (main.py 282): INFO Train: [144/300][50/78]	eta 0:00:53 lr 3.379487	time 1.1727 (1.9267)	loss 3.0224 (3.0261)	grad_norm 0.3644 (0.4038)	mem 39782MB
[2023-07-07 12:46:16 RepVGG-A0] (main.py 282): INFO Train: [144/300][60/78]	eta 0:00:33 lr 3.375197	time 1.3042 (1.8602)	loss 3.0036 (3.0267)	grad_norm 0.3939 (0.4006)	mem 39782MB
[2023-07-07 12:46:31 RepVGG-A0] (main.py 282): INFO Train: [144/300][70/78]	eta 0:00:14 lr 3.370907	time 1.3941 (1.8121)	loss 3.1138 (3.0345)	grad_norm 0.4046 (0.4025)	mem 39782MB
[2023-07-07 12:46:43 RepVGG-A0] (main.py 291): INFO EPOCH 144 training takes 0:02:20
[2023-07-07 12:47:05 RepVGG-A0] (main.py 282): INFO Train: [145/300][0/78]	eta 0:28:34 lr 3.367475	time 21.9764 (21.9764)	loss 3.1167 (3.1167)	grad_norm 0.4466 (0.4466)	mem 39782MB
[2023-07-07 12:47:20 RepVGG-A0] (main.py 282): INFO Train: [145/300][10/78]	eta 0:03:47 lr 3.363185	time 1.1715 (3.3387)	loss 3.1032 (3.0335)	grad_norm 0.4192 (0.4218)	mem 39782MB
[2023-07-07 12:47:35 RepVGG-A0] (main.py 282): INFO Train: [145/300][20/78]	eta 0:02:22 lr 3.358894	time 1.1814 (2.4508)	loss 3.0048 (3.0326)	grad_norm 0.4341 (0.4198)	mem 39782MB
[2023-07-07 12:47:50 RepVGG-A0] (main.py 282): INFO Train: [145/300][30/78]	eta 0:01:42 lr 3.354603	time 1.4114 (2.1376)	loss 3.0166 (3.0331)	grad_norm 0.3616 (0.4094)	mem 39782MB
[2023-07-07 12:48:08 RepVGG-A0] (main.py 282): INFO Train: [145/300][40/78]	eta 0:01:18 lr 3.350311	time 4.0426 (2.0745)	loss 2.9423 (3.0218)	grad_norm 0.3599 (0.4018)	mem 39782MB
[2023-07-07 12:48:23 RepVGG-A0] (main.py 282): INFO Train: [145/300][50/78]	eta 0:00:54 lr 3.346020	time 1.1737 (1.9583)	loss 2.9328 (3.0231)	grad_norm 0.3457 (0.4026)	mem 39782MB
[2023-07-07 12:48:39 RepVGG-A0] (main.py 282): INFO Train: [145/300][60/78]	eta 0:00:33 lr 3.341728	time 1.1781 (1.8880)	loss 3.1162 (3.0205)	grad_norm 0.4584 (0.3997)	mem 39782MB
[2023-07-07 12:48:54 RepVGG-A0] (main.py 282): INFO Train: [145/300][70/78]	eta 0:00:14 lr 3.337436	time 1.4226 (1.8367)	loss 5.6534 (3.1047)	grad_norm 1.6408 (0.4593)	mem 39782MB
[2023-07-07 12:49:05 RepVGG-A0] (main.py 291): INFO EPOCH 145 training takes 0:02:21
[2023-07-07 12:49:27 RepVGG-A0] (main.py 282): INFO Train: [146/300][0/78]	eta 0:29:10 lr 3.334002	time 22.4485 (22.4485)	loss 5.7511 (5.7511)	grad_norm 0.4792 (0.4792)	mem 39782MB
[2023-07-07 12:49:41 RepVGG-A0] (main.py 282): INFO Train: [146/300][10/78]	eta 0:03:44 lr 3.329710	time 1.1728 (3.3075)	loss 4.7435 (5.2548)	grad_norm 0.3540 (0.4210)	mem 39782MB
[2023-07-07 12:49:57 RepVGG-A0] (main.py 282): INFO Train: [146/300][20/78]	eta 0:02:22 lr 3.325417	time 1.4382 (2.4585)	loss 4.3744 (4.9485)	grad_norm 0.3067 (0.4277)	mem 39782MB
[2023-07-07 12:50:11 RepVGG-A0] (main.py 282): INFO Train: [146/300][30/78]	eta 0:01:42 lr 3.321124	time 1.6101 (2.1434)	loss 4.0473 (4.6774)	grad_norm 0.3535 (0.3978)	mem 39782MB
[2023-07-07 12:50:28 RepVGG-A0] (main.py 282): INFO Train: [146/300][40/78]	eta 0:01:16 lr 3.316831	time 2.7502 (2.0236)	loss 3.7745 (4.4752)	grad_norm 0.3586 (0.3782)	mem 39782MB
[2023-07-07 12:50:44 RepVGG-A0] (main.py 282): INFO Train: [146/300][50/78]	eta 0:00:54 lr 3.312537	time 1.2316 (1.9455)	loss 3.6487 (4.3300)	grad_norm 0.3339 (0.3789)	mem 39782MB
[2023-07-07 12:50:59 RepVGG-A0] (main.py 282): INFO Train: [146/300][60/78]	eta 0:00:33 lr 3.308243	time 1.4027 (1.8723)	loss 3.5598 (4.2071)	grad_norm 0.3752 (0.3709)	mem 39782MB
[2023-07-07 12:51:14 RepVGG-A0] (main.py 282): INFO Train: [146/300][70/78]	eta 0:00:14 lr 3.303950	time 1.5007 (1.8200)	loss 3.5313 (4.1084)	grad_norm 0.4020 (0.3701)	mem 39782MB
[2023-07-07 12:51:26 RepVGG-A0] (main.py 291): INFO EPOCH 146 training takes 0:02:20
[2023-07-07 12:51:49 RepVGG-A0] (main.py 282): INFO Train: [147/300][0/78]	eta 0:29:50 lr 3.300514	time 22.9575 (22.9575)	loss 3.4571 (3.4571)	grad_norm 0.3848 (0.3848)	mem 39782MB
[2023-07-07 12:52:03 RepVGG-A0] (main.py 282): INFO Train: [147/300][10/78]	eta 0:03:49 lr 3.296220	time 1.1727 (3.3819)	loss 3.3381 (3.3975)	grad_norm 0.2838 (0.3664)	mem 39782MB
[2023-07-07 12:52:17 RepVGG-A0] (main.py 282): INFO Train: [147/300][20/78]	eta 0:02:22 lr 3.291926	time 1.1747 (2.4585)	loss 3.4567 (3.3692)	grad_norm 0.4730 (0.3555)	mem 39782MB
[2023-07-07 12:52:32 RepVGG-A0] (main.py 282): INFO Train: [147/300][30/78]	eta 0:01:43 lr 3.287631	time 1.1274 (2.1502)	loss 3.4023 (3.3659)	grad_norm 0.3753 (0.3671)	mem 39782MB
[2023-07-07 12:52:50 RepVGG-A0] (main.py 282): INFO Train: [147/300][40/78]	eta 0:01:18 lr 3.283337	time 3.4340 (2.0700)	loss 3.3152 (3.3504)	grad_norm 0.3578 (0.3627)	mem 39782MB
[2023-07-07 12:53:05 RepVGG-A0] (main.py 282): INFO Train: [147/300][50/78]	eta 0:00:54 lr 3.279042	time 1.1718 (1.9439)	loss 3.2088 (3.3388)	grad_norm 0.3598 (0.3630)	mem 39782MB
[2023-07-07 12:53:20 RepVGG-A0] (main.py 282): INFO Train: [147/300][60/78]	eta 0:00:33 lr 3.274747	time 1.3055 (1.8743)	loss 3.1953 (3.3283)	grad_norm 0.3440 (0.3625)	mem 39782MB
[2023-07-07 12:53:36 RepVGG-A0] (main.py 282): INFO Train: [147/300][70/78]	eta 0:00:14 lr 3.270452	time 1.5060 (1.8305)	loss 3.3506 (3.3245)	grad_norm 0.3847 (0.3696)	mem 39782MB
[2023-07-07 12:53:47 RepVGG-A0] (main.py 291): INFO EPOCH 147 training takes 0:02:21
[2023-07-07 12:54:10 RepVGG-A0] (main.py 282): INFO Train: [148/300][0/78]	eta 0:30:01 lr 3.267016	time 23.1011 (23.1011)	loss 3.2125 (3.2125)	grad_norm 0.3653 (0.3653)	mem 39782MB
[2023-07-07 12:54:24 RepVGG-A0] (main.py 282): INFO Train: [148/300][10/78]	eta 0:03:47 lr 3.262720	time 1.1723 (3.3466)	loss 3.1334 (3.1936)	grad_norm 0.3601 (0.3765)	mem 39782MB
[2023-07-07 12:54:37 RepVGG-A0] (main.py 282): INFO Train: [148/300][20/78]	eta 0:02:18 lr 3.258425	time 1.1732 (2.3896)	loss 3.2595 (3.2053)	grad_norm 0.4312 (0.3857)	mem 39782MB
[2023-07-07 12:54:53 RepVGG-A0] (main.py 282): INFO Train: [148/300][30/78]	eta 0:01:42 lr 3.254129	time 1.8231 (2.1443)	loss 3.2016 (3.1953)	grad_norm 0.3788 (0.3801)	mem 39782MB
[2023-07-07 12:55:11 RepVGG-A0] (main.py 282): INFO Train: [148/300][40/78]	eta 0:01:17 lr 3.249834	time 4.0087 (2.0521)	loss 3.2255 (3.1961)	grad_norm 0.3711 (0.3819)	mem 39782MB
[2023-07-07 12:55:26 RepVGG-A0] (main.py 282): INFO Train: [148/300][50/78]	eta 0:00:54 lr 3.245538	time 1.1735 (1.9440)	loss 3.2555 (3.1943)	grad_norm 0.4977 (0.3843)	mem 39782MB
[2023-07-07 12:55:40 RepVGG-A0] (main.py 282): INFO Train: [148/300][60/78]	eta 0:00:33 lr 3.241242	time 1.3426 (1.8645)	loss 3.1766 (3.2089)	grad_norm 0.3681 (0.3927)	mem 39782MB
[2023-07-07 12:55:55 RepVGG-A0] (main.py 282): INFO Train: [148/300][70/78]	eta 0:00:14 lr 3.236946	time 1.1269 (1.8131)	loss 3.1530 (3.2072)	grad_norm 0.3063 (0.3898)	mem 39782MB
[2023-07-07 12:56:07 RepVGG-A0] (main.py 291): INFO EPOCH 148 training takes 0:02:20
[2023-07-07 12:56:30 RepVGG-A0] (main.py 282): INFO Train: [149/300][0/78]	eta 0:29:17 lr 3.233510	time 22.5271 (22.5271)	loss 3.1357 (3.1357)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:56:45 RepVGG-A0] (main.py 282): INFO Train: [149/300][10/78]	eta 0:03:49 lr 3.229214	time 1.1714 (3.3815)	loss 3.1587 (3.1200)	grad_norm 0.4202 (0.3863)	mem 39782MB
[2023-07-07 12:57:00 RepVGG-A0] (main.py 282): INFO Train: [149/300][20/78]	eta 0:02:26 lr 3.224918	time 1.1768 (2.5205)	loss 3.0411 (3.1171)	grad_norm 0.3391 (0.3832)	mem 39782MB
[2023-07-07 12:57:16 RepVGG-A0] (main.py 282): INFO Train: [149/300][30/78]	eta 0:01:46 lr 3.220622	time 1.5540 (2.2115)	loss 3.1360 (3.1330)	grad_norm 0.3770 (0.3956)	mem 39782MB
[2023-07-07 12:57:33 RepVGG-A0] (main.py 282): INFO Train: [149/300][40/78]	eta 0:01:19 lr 3.216325	time 2.9383 (2.0998)	loss 3.0721 (3.1295)	grad_norm 0.4092 (0.3872)	mem 39782MB
[2023-07-07 12:57:49 RepVGG-A0] (main.py 282): INFO Train: [149/300][50/78]	eta 0:00:55 lr 3.212029	time 1.1728 (1.9865)	loss 3.1390 (3.1337)	grad_norm 0.4082 (0.3911)	mem 39782MB
[2023-07-07 12:58:04 RepVGG-A0] (main.py 282): INFO Train: [149/300][60/78]	eta 0:00:34 lr 3.207733	time 1.3702 (1.9115)	loss 3.0842 (3.1348)	grad_norm 0.3677 (0.3913)	mem 39782MB
[2023-07-07 12:58:19 RepVGG-A0] (main.py 282): INFO Train: [149/300][70/78]	eta 0:00:14 lr 3.203437	time 1.2484 (1.8557)	loss 3.3661 (3.1440)	grad_norm 0.5420 (0.3976)	mem 39782MB
[2023-07-07 12:58:30 RepVGG-A0] (main.py 291): INFO EPOCH 149 training takes 0:02:23
[2023-07-07 12:58:53 RepVGG-A0] (main.py 282): INFO Train: [150/300][0/78]	eta 0:28:39 lr 3.200000	time 22.0479 (22.0479)	loss 3.4341 (3.4341)	grad_norm 0.5789 (0.5789)	mem 39782MB
[2023-07-07 12:59:07 RepVGG-A0] (main.py 282): INFO Train: [150/300][10/78]	eta 0:03:43 lr 3.195704	time 1.1718 (3.2898)	loss 3.0959 (3.2216)	grad_norm 0.3354 (0.3925)	mem 39782MB
[2023-07-07 12:59:22 RepVGG-A0] (main.py 282): INFO Train: [150/300][20/78]	eta 0:02:21 lr 3.191408	time 1.4029 (2.4479)	loss 3.1546 (3.1684)	grad_norm 0.4256 (0.3746)	mem 39782MB
[2023-07-07 12:59:36 RepVGG-A0] (main.py 282): INFO Train: [150/300][30/78]	eta 0:01:42 lr 3.187111	time 1.4931 (2.1295)	loss 3.0735 (3.1407)	grad_norm 0.3508 (0.3665)	mem 39782MB
[2023-07-07 12:59:54 RepVGG-A0] (main.py 282): INFO Train: [150/300][40/78]	eta 0:01:17 lr 3.182815	time 3.5910 (2.0453)	loss 3.1139 (3.1320)	grad_norm 0.3752 (0.3712)	mem 39782MB
[2023-07-07 13:00:09 RepVGG-A0] (main.py 282): INFO Train: [150/300][50/78]	eta 0:00:54 lr 3.178519	time 1.1724 (1.9387)	loss 3.0429 (3.1217)	grad_norm 0.3473 (0.3678)	mem 39782MB
[2023-07-07 13:00:24 RepVGG-A0] (main.py 282): INFO Train: [150/300][60/78]	eta 0:00:33 lr 3.174223	time 1.1803 (1.8678)	loss 3.0728 (3.1133)	grad_norm 0.3779 (0.3675)	mem 39782MB
[2023-07-07 13:00:40 RepVGG-A0] (main.py 282): INFO Train: [150/300][70/78]	eta 0:00:14 lr 3.169927	time 1.2568 (1.8193)	loss 3.1494 (3.1116)	grad_norm 0.4487 (0.3727)	mem 39782MB
[2023-07-07 13:00:51 RepVGG-A0] (main.py 291): INFO EPOCH 150 training takes 0:02:20
[2023-07-07 13:01:12 RepVGG-A0] (main.py 282): INFO Train: [151/300][0/78]	eta 0:26:29 lr 3.166490	time 20.3729 (20.3729)	loss 3.0923 (3.0923)	grad_norm 0.3840 (0.3840)	mem 39782MB
[2023-07-07 13:01:28 RepVGG-A0] (main.py 282): INFO Train: [151/300][10/78]	eta 0:03:46 lr 3.162194	time 1.1707 (3.3328)	loss 3.0394 (3.0493)	grad_norm 0.3811 (0.3730)	mem 39782MB
[2023-07-07 13:01:42 RepVGG-A0] (main.py 282): INFO Train: [151/300][20/78]	eta 0:02:20 lr 3.157899	time 1.2364 (2.4304)	loss 3.0441 (3.0673)	grad_norm 0.3919 (0.3801)	mem 39782MB
[2023-07-07 13:01:57 RepVGG-A0] (main.py 282): INFO Train: [151/300][30/78]	eta 0:01:41 lr 3.153603	time 1.3912 (2.1248)	loss 3.1563 (3.0829)	grad_norm 0.3902 (0.3928)	mem 39782MB
[2023-07-07 13:02:14 RepVGG-A0] (main.py 282): INFO Train: [151/300][40/78]	eta 0:01:16 lr 3.149307	time 3.5785 (2.0222)	loss 3.1010 (3.0836)	grad_norm 0.4150 (0.3921)	mem 39782MB
[2023-07-07 13:02:29 RepVGG-A0] (main.py 282): INFO Train: [151/300][50/78]	eta 0:00:53 lr 3.145011	time 1.1729 (1.9154)	loss 3.0922 (3.0867)	grad_norm 0.4151 (0.3928)	mem 39782MB
[2023-07-07 13:02:45 RepVGG-A0] (main.py 282): INFO Train: [151/300][60/78]	eta 0:00:33 lr 3.140716	time 1.1792 (1.8571)	loss 3.0394 (3.0896)	grad_norm 0.3924 (0.3960)	mem 39782MB
[2023-07-07 13:02:59 RepVGG-A0] (main.py 282): INFO Train: [151/300][70/78]	eta 0:00:14 lr 3.136420	time 1.2887 (1.8028)	loss 3.0039 (3.0955)	grad_norm 0.3548 (0.4000)	mem 39782MB
[2023-07-07 13:03:11 RepVGG-A0] (main.py 291): INFO EPOCH 151 training takes 0:02:19
[2023-07-07 13:03:33 RepVGG-A0] (main.py 282): INFO Train: [152/300][0/78]	eta 0:28:19 lr 3.132984	time 21.7948 (21.7948)	loss 3.0666 (3.0666)	grad_norm 0.4497 (0.4497)	mem 39782MB
[2023-07-07 13:03:48 RepVGG-A0] (main.py 282): INFO Train: [152/300][10/78]	eta 0:03:44 lr 3.128689	time 1.1948 (3.3027)	loss 3.0419 (3.0278)	grad_norm 0.3745 (0.3943)	mem 39782MB
[2023-07-07 13:04:03 RepVGG-A0] (main.py 282): INFO Train: [152/300][20/78]	eta 0:02:22 lr 3.124394	time 1.3969 (2.4645)	loss 3.0750 (3.0300)	grad_norm 0.4298 (0.3839)	mem 39782MB
[2023-07-07 13:04:18 RepVGG-A0] (main.py 282): INFO Train: [152/300][30/78]	eta 0:01:43 lr 3.120099	time 1.3788 (2.1622)	loss 3.0902 (3.0625)	grad_norm 0.3830 (0.4053)	mem 39782MB
[2023-07-07 13:04:36 RepVGG-A0] (main.py 282): INFO Train: [152/300][40/78]	eta 0:01:18 lr 3.115804	time 3.5646 (2.0662)	loss 3.0272 (3.0636)	grad_norm 0.4093 (0.4006)	mem 39782MB
[2023-07-07 13:04:51 RepVGG-A0] (main.py 282): INFO Train: [152/300][50/78]	eta 0:00:54 lr 3.111510	time 1.1922 (1.9500)	loss 3.0460 (3.0604)	grad_norm 0.3895 (0.3977)	mem 39782MB
[2023-07-07 13:05:06 RepVGG-A0] (main.py 282): INFO Train: [152/300][60/78]	eta 0:00:33 lr 3.107215	time 1.1733 (1.8794)	loss 3.1249 (3.0633)	grad_norm 0.4042 (0.3981)	mem 39782MB
[2023-07-07 13:05:21 RepVGG-A0] (main.py 282): INFO Train: [152/300][70/78]	eta 0:00:14 lr 3.102921	time 1.1776 (1.8319)	loss 3.0232 (3.0607)	grad_norm 0.3651 (0.3966)	mem 39782MB
[2023-07-07 13:05:33 RepVGG-A0] (main.py 291): INFO EPOCH 152 training takes 0:02:21
[2023-07-07 13:05:56 RepVGG-A0] (main.py 282): INFO Train: [153/300][0/78]	eta 0:29:35 lr 3.099486	time 22.7569 (22.7569)	loss 3.0715 (3.0715)	grad_norm 0.3790 (0.3790)	mem 39782MB
[2023-07-07 13:06:10 RepVGG-A0] (main.py 282): INFO Train: [153/300][10/78]	eta 0:03:50 lr 3.095192	time 1.1727 (3.3845)	loss 3.0466 (3.0324)	grad_norm 0.4287 (0.4123)	mem 39782MB
[2023-07-07 13:06:26 RepVGG-A0] (main.py 282): INFO Train: [153/300][20/78]	eta 0:02:24 lr 3.090898	time 1.4288 (2.4918)	loss 3.0517 (3.0225)	grad_norm 0.4022 (0.4028)	mem 39782MB
[2023-07-07 13:06:40 RepVGG-A0] (main.py 282): INFO Train: [153/300][30/78]	eta 0:01:43 lr 3.086604	time 1.1285 (2.1588)	loss 2.9882 (3.0259)	grad_norm 0.3835 (0.4120)	mem 39782MB
[2023-07-07 13:06:59 RepVGG-A0] (main.py 282): INFO Train: [153/300][40/78]	eta 0:01:19 lr 3.082311	time 3.1114 (2.0812)	loss 3.0254 (3.0199)	grad_norm 0.3912 (0.4003)	mem 39782MB
[2023-07-07 13:07:13 RepVGG-A0] (main.py 282): INFO Train: [153/300][50/78]	eta 0:00:55 lr 3.078018	time 1.1912 (1.9644)	loss 3.0874 (3.0282)	grad_norm 0.4246 (0.4045)	mem 39782MB
[2023-07-07 13:07:29 RepVGG-A0] (main.py 282): INFO Train: [153/300][60/78]	eta 0:00:34 lr 3.073725	time 1.5385 (1.8965)	loss 3.0577 (3.0337)	grad_norm 0.4018 (0.4046)	mem 39782MB
[2023-07-07 13:07:45 RepVGG-A0] (main.py 282): INFO Train: [153/300][70/78]	eta 0:00:14 lr 3.069432	time 1.3005 (1.8531)	loss 2.9771 (3.0299)	grad_norm 0.3880 (0.4005)	mem 39782MB
[2023-07-07 13:07:55 RepVGG-A0] (main.py 291): INFO EPOCH 153 training takes 0:02:22
[2023-07-07 13:08:18 RepVGG-A0] (main.py 282): INFO Train: [154/300][0/78]	eta 0:29:06 lr 3.065998	time 22.3849 (22.3849)	loss 2.9846 (2.9846)	grad_norm 0.4179 (0.4179)	mem 39782MB
[2023-07-07 13:08:32 RepVGG-A0] (main.py 282): INFO Train: [154/300][10/78]	eta 0:03:48 lr 3.061706	time 1.1970 (3.3672)	loss 2.9538 (2.9950)	grad_norm 0.3944 (0.4052)	mem 39782MB
[2023-07-07 13:08:48 RepVGG-A0] (main.py 282): INFO Train: [154/300][20/78]	eta 0:02:24 lr 3.057414	time 1.5185 (2.4907)	loss 2.9376 (2.9975)	grad_norm 0.3801 (0.4055)	mem 39782MB
[2023-07-07 13:09:03 RepVGG-A0] (main.py 282): INFO Train: [154/300][30/78]	eta 0:01:44 lr 3.053122	time 1.1261 (2.1783)	loss 3.0891 (3.0059)	grad_norm 0.4335 (0.4096)	mem 39782MB
[2023-07-07 13:09:21 RepVGG-A0] (main.py 282): INFO Train: [154/300][40/78]	eta 0:01:18 lr 3.048830	time 2.9873 (2.0779)	loss 3.0326 (3.0139)	grad_norm 0.3554 (0.4097)	mem 39782MB
[2023-07-07 13:09:36 RepVGG-A0] (main.py 282): INFO Train: [154/300][50/78]	eta 0:00:55 lr 3.044539	time 1.7446 (1.9710)	loss 2.9670 (3.0126)	grad_norm 0.3664 (0.4070)	mem 39782MB
[2023-07-07 13:09:51 RepVGG-A0] (main.py 282): INFO Train: [154/300][60/78]	eta 0:00:34 lr 3.040248	time 1.2478 (1.8904)	loss 3.0561 (3.0150)	grad_norm 0.4155 (0.4075)	mem 39782MB
[2023-07-07 13:10:06 RepVGG-A0] (main.py 282): INFO Train: [154/300][70/78]	eta 0:00:14 lr 3.035957	time 1.3595 (1.8413)	loss 3.0132 (3.0177)	grad_norm 0.4036 (0.4070)	mem 39782MB
[2023-07-07 13:10:18 RepVGG-A0] (main.py 291): INFO EPOCH 154 training takes 0:02:22
[2023-07-07 13:10:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][0/78]	eta 0:28:06 lr 3.032525	time 21.6273 (21.6273)	loss 3.0235 (3.0235)	grad_norm 0.3518 (0.3518)	mem 39782MB
[2023-07-07 13:10:54 RepVGG-A0] (main.py 282): INFO Train: [155/300][10/78]	eta 0:03:45 lr 3.028235	time 1.1728 (3.3142)	loss 3.8356 (3.1587)	grad_norm 1.1281 (0.5835)	mem 39782MB
[2023-07-07 13:11:08 RepVGG-A0] (main.py 282): INFO Train: [155/300][20/78]	eta 0:02:17 lr 3.023945	time 1.1717 (2.3705)	loss 5.7186 (4.3630)	grad_norm 0.5419 (0.8188)	mem 39782MB
[2023-07-07 13:11:22 RepVGG-A0] (main.py 282): INFO Train: [155/300][30/78]	eta 0:01:39 lr 3.019655	time 1.1279 (2.0717)	loss 4.5576 (4.5620)	grad_norm 0.3827 (0.6999)	mem 39782MB
[2023-07-07 13:11:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][40/78]	eta 0:01:15 lr 3.015366	time 2.8684 (1.9974)	loss 4.0347 (4.4799)	grad_norm 0.3370 (0.6117)	mem 39782MB
[2023-07-07 13:11:56 RepVGG-A0] (main.py 282): INFO Train: [155/300][50/78]	eta 0:00:53 lr 3.011077	time 1.1761 (1.9159)	loss 3.9218 (4.3677)	grad_norm 0.4179 (0.5589)	mem 39782MB
[2023-07-07 13:12:11 RepVGG-A0] (main.py 282): INFO Train: [155/300][60/78]	eta 0:00:33 lr 3.006789	time 1.1795 (1.8464)	loss 3.6191 (4.2554)	grad_norm 0.2972 (0.5206)	mem 39782MB
[2023-07-07 13:12:26 RepVGG-A0] (main.py 282): INFO Train: [155/300][70/78]	eta 0:00:14 lr 3.002501	time 1.3033 (1.8069)	loss 3.4312 (4.1548)	grad_norm 0.3013 (0.4941)	mem 39782MB
[2023-07-07 13:12:38 RepVGG-A0] (main.py 291): INFO EPOCH 155 training takes 0:02:19
[2023-07-07 13:12:59 RepVGG-A0] (main.py 282): INFO Train: [156/300][0/78]	eta 0:27:22 lr 2.999070	time 21.0603 (21.0603)	loss 3.5120 (3.5120)	grad_norm 0.3452 (0.3452)	mem 39782MB
[2023-07-07 13:13:16 RepVGG-A0] (main.py 282): INFO Train: [156/300][10/78]	eta 0:03:53 lr 2.994783	time 1.1732 (3.4291)	loss 3.2602 (3.3834)	grad_norm 0.3327 (0.3296)	mem 39782MB
[2023-07-07 13:13:30 RepVGG-A0] (main.py 282): INFO Train: [156/300][20/78]	eta 0:02:24 lr 2.990496	time 1.1941 (2.4837)	loss 3.2872 (3.3510)	grad_norm 0.3448 (0.3362)	mem 39782MB
[2023-07-07 13:13:46 RepVGG-A0] (main.py 282): INFO Train: [156/300][30/78]	eta 0:01:44 lr 2.986209	time 1.4894 (2.1827)	loss 3.3047 (3.3334)	grad_norm 0.3727 (0.3414)	mem 39782MB
[2023-07-07 13:14:03 RepVGG-A0] (main.py 282): INFO Train: [156/300][40/78]	eta 0:01:18 lr 2.981922	time 3.0438 (2.0736)	loss 3.1939 (3.3339)	grad_norm 0.3332 (0.3497)	mem 39782MB
[2023-07-07 13:14:19 RepVGG-A0] (main.py 282): INFO Train: [156/300][50/78]	eta 0:00:55 lr 2.977636	time 1.3223 (1.9745)	loss 3.2588 (3.3154)	grad_norm 0.3488 (0.3481)	mem 39782MB
[2023-07-07 13:14:34 RepVGG-A0] (main.py 282): INFO Train: [156/300][60/78]	eta 0:00:34 lr 2.973351	time 1.3798 (1.9112)	loss 3.2645 (3.3022)	grad_norm 0.3679 (0.3528)	mem 39782MB
[2023-07-07 13:14:49 RepVGG-A0] (main.py 282): INFO Train: [156/300][70/78]	eta 0:00:14 lr 2.969066	time 1.3976 (1.8543)	loss 3.1689 (3.2902)	grad_norm 0.3609 (0.3550)	mem 39782MB
[2023-07-07 13:15:02 RepVGG-A0] (main.py 291): INFO EPOCH 156 training takes 0:02:23
[2023-07-07 13:15:23 RepVGG-A0] (main.py 282): INFO Train: [157/300][0/78]	eta 0:28:23 lr 2.965638	time 21.8396 (21.8396)	loss 3.1824 (3.1824)	grad_norm 0.3462 (0.3462)	mem 39782MB
[2023-07-07 13:15:38 RepVGG-A0] (main.py 282): INFO Train: [157/300][10/78]	eta 0:03:46 lr 2.961353	time 1.1724 (3.3341)	loss 3.2192 (3.1713)	grad_norm 0.3874 (0.3658)	mem 39782MB
[2023-07-07 13:15:52 RepVGG-A0] (main.py 282): INFO Train: [157/300][20/78]	eta 0:02:18 lr 2.957069	time 1.1739 (2.3850)	loss 3.1571 (3.1707)	grad_norm 0.3753 (0.3879)	mem 39782MB
[2023-07-07 13:16:08 RepVGG-A0] (main.py 282): INFO Train: [157/300][30/78]	eta 0:01:43 lr 2.952786	time 1.3671 (2.1569)	loss 3.0352 (3.1570)	grad_norm 0.3456 (0.3768)	mem 39782MB
[2023-07-07 13:16:26 RepVGG-A0] (main.py 282): INFO Train: [157/300][40/78]	eta 0:01:18 lr 2.948503	time 4.8365 (2.0628)	loss 3.1387 (3.1569)	grad_norm 0.3783 (0.3821)	mem 39782MB
[2023-07-07 13:16:41 RepVGG-A0] (main.py 282): INFO Train: [157/300][50/78]	eta 0:00:54 lr 2.944220	time 1.2467 (1.9542)	loss 3.1581 (3.1468)	grad_norm 0.4047 (0.3796)	mem 39782MB
[2023-07-07 13:16:57 RepVGG-A0] (main.py 282): INFO Train: [157/300][60/78]	eta 0:00:33 lr 2.939938	time 1.1770 (1.8848)	loss 3.1407 (3.1430)	grad_norm 0.4442 (0.3806)	mem 39782MB
[2023-07-07 13:17:10 RepVGG-A0] (main.py 282): INFO Train: [157/300][70/78]	eta 0:00:14 lr 2.935656	time 1.2194 (1.8116)	loss 3.0830 (3.1479)	grad_norm 0.3872 (0.3874)	mem 39782MB
[2023-07-07 13:17:23 RepVGG-A0] (main.py 291): INFO EPOCH 157 training takes 0:02:21
[2023-07-07 13:17:45 RepVGG-A0] (main.py 282): INFO Train: [158/300][0/78]	eta 0:28:51 lr 2.932231	time 22.1985 (22.1985)	loss 3.1346 (3.1346)	grad_norm 0.3878 (0.3878)	mem 39782MB
[2023-07-07 13:17:59 RepVGG-A0] (main.py 282): INFO Train: [158/300][10/78]	eta 0:03:46 lr 2.927950	time 1.1719 (3.3310)	loss 3.0447 (3.0609)	grad_norm 0.3798 (0.3710)	mem 39782MB
[2023-07-07 13:18:13 RepVGG-A0] (main.py 282): INFO Train: [158/300][20/78]	eta 0:02:19 lr 2.923670	time 1.1755 (2.4115)	loss 3.0584 (3.0644)	grad_norm 0.3635 (0.3752)	mem 39782MB
[2023-07-07 13:18:29 RepVGG-A0] (main.py 282): INFO Train: [158/300][30/78]	eta 0:01:43 lr 2.919390	time 1.4175 (2.1518)	loss 3.0984 (3.0638)	grad_norm 0.3642 (0.3777)	mem 39782MB
[2023-07-07 13:18:48 RepVGG-A0] (main.py 282): INFO Train: [158/300][40/78]	eta 0:01:19 lr 2.915110	time 4.4636 (2.0846)	loss 3.1646 (3.0744)	grad_norm 0.4779 (0.3854)	mem 39782MB
[2023-07-07 13:19:03 RepVGG-A0] (main.py 282): INFO Train: [158/300][50/78]	eta 0:00:55 lr 2.910831	time 1.1724 (1.9656)	loss 3.0634 (3.0813)	grad_norm 0.4053 (0.3954)	mem 39782MB
[2023-07-07 13:19:18 RepVGG-A0] (main.py 282): INFO Train: [158/300][60/78]	eta 0:00:34 lr 2.906553	time 1.1779 (1.8889)	loss 3.1904 (3.0871)	grad_norm 0.4078 (0.3960)	mem 39782MB
[2023-07-07 13:19:33 RepVGG-A0] (main.py 282): INFO Train: [158/300][70/78]	eta 0:00:14 lr 2.902275	time 1.1275 (1.8285)	loss 3.0681 (3.0882)	grad_norm 0.4382 (0.3976)	mem 39782MB
[2023-07-07 13:19:44 RepVGG-A0] (main.py 291): INFO EPOCH 158 training takes 0:02:21
[2023-07-07 13:20:07 RepVGG-A0] (main.py 282): INFO Train: [159/300][0/78]	eta 0:29:53 lr 2.898853	time 22.9936 (22.9936)	loss 2.9832 (2.9832)	grad_norm 0.3711 (0.3711)	mem 39782MB
[2023-07-07 13:20:21 RepVGG-A0] (main.py 282): INFO Train: [159/300][10/78]	eta 0:03:48 lr 2.894577	time 1.1726 (3.3598)	loss 3.0466 (3.0081)	grad_norm 0.3875 (0.3844)	mem 39782MB
[2023-07-07 13:20:35 RepVGG-A0] (main.py 282): INFO Train: [159/300][20/78]	eta 0:02:20 lr 2.890300	time 1.1984 (2.4302)	loss 3.1685 (3.0435)	grad_norm 0.5703 (0.4232)	mem 39782MB
[2023-07-07 13:20:49 RepVGG-A0] (main.py 282): INFO Train: [159/300][30/78]	eta 0:01:41 lr 2.886024	time 1.2649 (2.1134)	loss 3.0001 (3.0549)	grad_norm 0.3473 (0.4154)	mem 39782MB
[2023-07-07 13:21:08 RepVGG-A0] (main.py 282): INFO Train: [159/300][40/78]	eta 0:01:17 lr 2.881749	time 3.7145 (2.0448)	loss 3.0772 (3.0548)	grad_norm 0.4536 (0.4129)	mem 39782MB
[2023-07-07 13:21:23 RepVGG-A0] (main.py 282): INFO Train: [159/300][50/78]	eta 0:00:54 lr 2.877475	time 1.1728 (1.9439)	loss 2.9003 (3.0543)	grad_norm 0.3559 (0.4114)	mem 39782MB
[2023-07-07 13:21:39 RepVGG-A0] (main.py 282): INFO Train: [159/300][60/78]	eta 0:00:34 lr 2.873201	time 1.1276 (1.8902)	loss 3.0483 (3.0520)	grad_norm 0.3696 (0.4046)	mem 39782MB
[2023-07-07 13:21:54 RepVGG-A0] (main.py 282): INFO Train: [159/300][70/78]	eta 0:00:14 lr 2.868927	time 1.4138 (1.8366)	loss 2.9840 (3.0506)	grad_norm 0.3634 (0.4023)	mem 39782MB
[2023-07-07 13:22:06 RepVGG-A0] (main.py 291): INFO EPOCH 159 training takes 0:02:22
[2023-07-07 13:22:28 RepVGG-A0] (main.py 282): INFO Train: [160/300][0/78]	eta 0:28:48 lr 2.865509	time 22.1592 (22.1592)	loss 2.9860 (2.9860)	grad_norm 0.3670 (0.3670)	mem 39782MB
[2023-07-07 13:22:43 RepVGG-A0] (main.py 282): INFO Train: [160/300][10/78]	eta 0:03:47 lr 2.861237	time 1.1719 (3.3503)	loss 3.1159 (3.0447)	grad_norm 0.4970 (0.4653)	mem 39782MB
[2023-07-07 13:22:58 RepVGG-A0] (main.py 282): INFO Train: [160/300][20/78]	eta 0:02:23 lr 2.856965	time 1.4364 (2.4802)	loss 2.9248 (3.0341)	grad_norm 0.3629 (0.4239)	mem 39782MB
[2023-07-07 13:23:14 RepVGG-A0] (main.py 282): INFO Train: [160/300][30/78]	eta 0:01:44 lr 2.852694	time 1.4695 (2.1784)	loss 3.0044 (3.0208)	grad_norm 0.4084 (0.4091)	mem 39782MB
[2023-07-07 13:23:31 RepVGG-A0] (main.py 282): INFO Train: [160/300][40/78]	eta 0:01:18 lr 2.848423	time 2.6831 (2.0676)	loss 2.9922 (3.0248)	grad_norm 0.3805 (0.4102)	mem 39782MB
[2023-07-07 13:23:47 RepVGG-A0] (main.py 282): INFO Train: [160/300][50/78]	eta 0:00:55 lr 2.844153	time 1.1782 (1.9676)	loss 2.9629 (3.0241)	grad_norm 0.3968 (0.4078)	mem 39782MB
[2023-07-07 13:24:01 RepVGG-A0] (main.py 282): INFO Train: [160/300][60/78]	eta 0:00:33 lr 2.839884	time 1.2819 (1.8780)	loss 3.0052 (3.0289)	grad_norm 0.3754 (0.4087)	mem 39782MB
[2023-07-07 13:24:17 RepVGG-A0] (main.py 282): INFO Train: [160/300][70/78]	eta 0:00:14 lr 2.835616	time 1.6432 (1.8425)	loss 3.0591 (3.0412)	grad_norm 0.3880 (0.4187)	mem 39782MB
[2023-07-07 13:24:29 RepVGG-A0] (main.py 291): INFO EPOCH 160 training takes 0:02:22
[2023-07-07 13:24:47 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 18.189 (18.189)	Loss 2.4704 (2.4704)	Acc@1 47.650 (47.650)	Acc@5 72.766 (72.766)	Mem 39782MB
[2023-07-07 13:24:48 RepVGG-A0] (main.py 342): INFO  * Acc@1 48.562 Acc@5 72.958
[2023-07-07 13:24:48 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 160: 48.562%
[2023-07-07 13:24:48 RepVGG-A0] (main.py 172): INFO Max accuracy: 48.56%
[2023-07-07 13:25:09 RepVGG-A0] (main.py 282): INFO Train: [161/300][0/78]	eta 0:27:21 lr 2.832201	time 21.0466 (21.0466)	loss 2.9490 (2.9490)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 13:25:26 RepVGG-A0] (main.py 282): INFO Train: [161/300][10/78]	eta 0:03:52 lr 2.827934	time 1.1725 (3.4240)	loss 3.0153 (2.9710)	grad_norm 0.4074 (0.3967)	mem 39782MB
[2023-07-07 13:25:40 RepVGG-A0] (main.py 282): INFO Train: [161/300][20/78]	eta 0:02:24 lr 2.823667	time 1.2173 (2.4908)	loss 2.9815 (2.9776)	grad_norm 0.4197 (0.4031)	mem 39782MB
[2023-07-07 13:25:55 RepVGG-A0] (main.py 282): INFO Train: [161/300][30/78]	eta 0:01:44 lr 2.819401	time 1.1287 (2.1717)	loss 2.9505 (2.9834)	grad_norm 0.3911 (0.3961)	mem 39782MB
[2023-07-07 13:26:13 RepVGG-A0] (main.py 282): INFO Train: [161/300][40/78]	eta 0:01:18 lr 2.815136	time 3.6956 (2.0601)	loss 2.9392 (2.9850)	grad_norm 0.4257 (0.3975)	mem 39782MB
[2023-07-07 13:26:28 RepVGG-A0] (main.py 282): INFO Train: [161/300][50/78]	eta 0:00:54 lr 2.810871	time 1.1613 (1.9534)	loss 3.0055 (2.9948)	grad_norm 0.4067 (0.4060)	mem 39782MB
[2023-07-07 13:26:43 RepVGG-A0] (main.py 282): INFO Train: [161/300][60/78]	eta 0:00:33 lr 2.806607	time 1.1737 (1.8775)	loss 3.0347 (2.9970)	grad_norm 0.4276 (0.4064)	mem 39782MB
[2023-07-07 13:26:58 RepVGG-A0] (main.py 282): INFO Train: [161/300][70/78]	eta 0:00:14 lr 2.802344	time 1.1285 (1.8307)	loss 2.9549 (2.9990)	grad_norm 0.3827 (0.4061)	mem 39782MB
[2023-07-07 13:27:09 RepVGG-A0] (main.py 291): INFO EPOCH 161 training takes 0:02:21
[2023-07-07 13:27:29 RepVGG-A0] (main.py 282): INFO Train: [162/300][0/78]	eta 0:26:08 lr 2.798934	time 20.1051 (20.1051)	loss 3.0267 (3.0267)	grad_norm 0.4832 (0.4832)	mem 39782MB
[2023-07-07 13:27:45 RepVGG-A0] (main.py 282): INFO Train: [162/300][10/78]	eta 0:03:38 lr 2.794672	time 1.1711 (3.2159)	loss 2.9355 (2.9726)	grad_norm 0.4627 (0.4106)	mem 39782MB
[2023-07-07 13:28:00 RepVGG-A0] (main.py 282): INFO Train: [162/300][20/78]	eta 0:02:20 lr 2.790410	time 1.1956 (2.4269)	loss 3.0638 (2.9718)	grad_norm 0.4551 (0.4074)	mem 39782MB
[2023-07-07 13:28:14 RepVGG-A0] (main.py 282): INFO Train: [162/300][30/78]	eta 0:01:40 lr 2.786150	time 1.3242 (2.1026)	loss 2.9334 (2.9753)	grad_norm 0.3686 (0.4090)	mem 39782MB
[2023-07-07 13:28:33 RepVGG-A0] (main.py 282): INFO Train: [162/300][40/78]	eta 0:01:17 lr 2.781890	time 3.7189 (2.0346)	loss 3.1040 (2.9769)	grad_norm 0.5544 (0.4113)	mem 39782MB
[2023-07-07 13:28:48 RepVGG-A0] (main.py 282): INFO Train: [162/300][50/78]	eta 0:00:54 lr 2.777631	time 1.1735 (1.9360)	loss 6.3181 (3.2296)	grad_norm 1.1968 (0.5421)	mem 39782MB
[2023-07-07 13:29:04 RepVGG-A0] (main.py 282): INFO Train: [162/300][60/78]	eta 0:00:33 lr 2.773373	time 1.4707 (1.8744)	loss 4.9892 (3.5886)	grad_norm 0.6170 (0.5680)	mem 39782MB
[2023-07-07 13:29:19 RepVGG-A0] (main.py 282): INFO Train: [162/300][70/78]	eta 0:00:14 lr 2.769116	time 1.7353 (1.8307)	loss 4.2048 (3.7019)	grad_norm 0.4402 (0.5401)	mem 39782MB
[2023-07-07 13:29:31 RepVGG-A0] (main.py 291): INFO EPOCH 162 training takes 0:02:21
[2023-07-07 13:29:53 RepVGG-A0] (main.py 282): INFO Train: [163/300][0/78]	eta 0:29:05 lr 2.765710	time 22.3821 (22.3821)	loss 3.7657 (3.7657)	grad_norm 0.3159 (0.3159)	mem 39782MB
[2023-07-07 13:30:07 RepVGG-A0] (main.py 282): INFO Train: [163/300][10/78]	eta 0:03:41 lr 2.761454	time 1.1933 (3.2546)	loss 3.6018 (3.6923)	grad_norm 0.3559 (0.3428)	mem 39782MB
[2023-07-07 13:30:21 RepVGG-A0] (main.py 282): INFO Train: [163/300][20/78]	eta 0:02:17 lr 2.757199	time 1.1718 (2.3705)	loss 3.5020 (3.6202)	grad_norm 0.3433 (0.3434)	mem 39782MB
[2023-07-07 13:30:36 RepVGG-A0] (main.py 282): INFO Train: [163/300][30/78]	eta 0:01:41 lr 2.752944	time 1.6254 (2.1108)	loss 3.3531 (3.5519)	grad_norm 0.3365 (0.3408)	mem 39782MB
[2023-07-07 13:30:54 RepVGG-A0] (main.py 282): INFO Train: [163/300][40/78]	eta 0:01:16 lr 2.748691	time 3.7239 (2.0161)	loss 3.3464 (3.5037)	grad_norm 0.3382 (0.3436)	mem 39782MB
[2023-07-07 13:31:09 RepVGG-A0] (main.py 282): INFO Train: [163/300][50/78]	eta 0:00:53 lr 2.744438	time 1.1717 (1.9277)	loss 3.2498 (3.4639)	grad_norm 0.3159 (0.3447)	mem 39782MB
[2023-07-07 13:31:24 RepVGG-A0] (main.py 282): INFO Train: [163/300][60/78]	eta 0:00:33 lr 2.740186	time 1.2605 (1.8568)	loss 3.2637 (3.4328)	grad_norm 0.4374 (0.3462)	mem 39782MB
[2023-07-07 13:31:40 RepVGG-A0] (main.py 282): INFO Train: [163/300][70/78]	eta 0:00:14 lr 2.735935	time 1.2935 (1.8109)	loss 3.2475 (3.4074)	grad_norm 0.4030 (0.3485)	mem 39782MB
[2023-07-07 13:31:51 RepVGG-A0] (main.py 291): INFO EPOCH 163 training takes 0:02:20
[2023-07-07 13:32:12 RepVGG-A0] (main.py 282): INFO Train: [164/300][0/78]	eta 0:27:02 lr 2.732534	time 20.8056 (20.8056)	loss 3.1876 (3.1876)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 13:32:28 RepVGG-A0] (main.py 282): INFO Train: [164/300][10/78]	eta 0:03:44 lr 2.728285	time 1.1900 (3.3019)	loss 3.1755 (3.1428)	grad_norm 0.3385 (0.3550)	mem 39782MB
[2023-07-07 13:32:43 RepVGG-A0] (main.py 282): INFO Train: [164/300][20/78]	eta 0:02:22 lr 2.724036	time 1.1989 (2.4516)	loss 3.2346 (3.1265)	grad_norm 0.4180 (0.3588)	mem 39782MB
[2023-07-07 13:32:58 RepVGG-A0] (main.py 282): INFO Train: [164/300][30/78]	eta 0:01:43 lr 2.719788	time 1.2826 (2.1587)	loss 3.1160 (3.1309)	grad_norm 0.3496 (0.3657)	mem 39782MB
[2023-07-07 13:33:15 RepVGG-A0] (main.py 282): INFO Train: [164/300][40/78]	eta 0:01:17 lr 2.715541	time 2.7650 (2.0419)	loss 3.0787 (3.1294)	grad_norm 0.3559 (0.3653)	mem 39782MB
[2023-07-07 13:33:30 RepVGG-A0] (main.py 282): INFO Train: [164/300][50/78]	eta 0:00:53 lr 2.711294	time 1.1728 (1.9263)	loss 3.0722 (3.1243)	grad_norm 0.3679 (0.3675)	mem 39782MB
[2023-07-07 13:33:45 RepVGG-A0] (main.py 282): INFO Train: [164/300][60/78]	eta 0:00:33 lr 2.707049	time 1.2709 (1.8677)	loss 3.0856 (3.1234)	grad_norm 0.3913 (0.3753)	mem 39782MB
[2023-07-07 13:34:01 RepVGG-A0] (main.py 282): INFO Train: [164/300][70/78]	eta 0:00:14 lr 2.702805	time 1.4556 (1.8239)	loss 3.0935 (3.1192)	grad_norm 0.3562 (0.3726)	mem 39782MB
[2023-07-07 13:34:13 RepVGG-A0] (main.py 291): INFO EPOCH 164 training takes 0:02:21
[2023-07-07 13:34:34 RepVGG-A0] (main.py 282): INFO Train: [165/300][0/78]	eta 0:27:08 lr 2.699410	time 20.8769 (20.8769)	loss 3.0498 (3.0498)	grad_norm 0.4425 (0.4425)	mem 39782MB
[2023-07-07 13:34:48 RepVGG-A0] (main.py 282): INFO Train: [165/300][10/78]	eta 0:03:38 lr 2.695167	time 1.1727 (3.2129)	loss 2.9947 (3.0352)	grad_norm 0.3568 (0.3907)	mem 39782MB
[2023-07-07 13:35:02 RepVGG-A0] (main.py 282): INFO Train: [165/300][20/78]	eta 0:02:16 lr 2.690925	time 1.1733 (2.3588)	loss 3.0230 (3.0421)	grad_norm 0.4137 (0.3881)	mem 39782MB
[2023-07-07 13:35:18 RepVGG-A0] (main.py 282): INFO Train: [165/300][30/78]	eta 0:01:40 lr 2.686684	time 1.2057 (2.0992)	loss 3.0028 (3.0349)	grad_norm 0.3612 (0.3808)	mem 39782MB
[2023-07-07 13:35:37 RepVGG-A0] (main.py 282): INFO Train: [165/300][40/78]	eta 0:01:17 lr 2.682444	time 4.1491 (2.0469)	loss 3.1646 (3.0497)	grad_norm 0.5732 (0.3978)	mem 39782MB
[2023-07-07 13:35:51 RepVGG-A0] (main.py 282): INFO Train: [165/300][50/78]	eta 0:00:54 lr 2.678205	time 1.1974 (1.9293)	loss 3.0360 (3.0643)	grad_norm 0.3507 (0.4036)	mem 39782MB
[2023-07-07 13:36:06 RepVGG-A0] (main.py 282): INFO Train: [165/300][60/78]	eta 0:00:33 lr 2.673966	time 1.2541 (1.8651)	loss 3.0254 (3.0631)	grad_norm 0.3515 (0.3972)	mem 39782MB
[2023-07-07 13:36:22 RepVGG-A0] (main.py 282): INFO Train: [165/300][70/78]	eta 0:00:14 lr 2.669729	time 1.3339 (1.8191)	loss 3.1144 (3.0613)	grad_norm 0.3679 (0.3942)	mem 39782MB
[2023-07-07 13:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 165 training takes 0:02:21
[2023-07-07 13:36:55 RepVGG-A0] (main.py 282): INFO Train: [166/300][0/78]	eta 0:27:24 lr 2.666340	time 21.0863 (21.0863)	loss 2.9753 (2.9753)	grad_norm 0.3898 (0.3898)	mem 39782MB
[2023-07-07 13:37:11 RepVGG-A0] (main.py 282): INFO Train: [166/300][10/78]	eta 0:03:49 lr 2.662104	time 1.1925 (3.3820)	loss 2.9437 (2.9998)	grad_norm 0.3915 (0.4194)	mem 39782MB
[2023-07-07 13:37:26 RepVGG-A0] (main.py 282): INFO Train: [166/300][20/78]	eta 0:02:23 lr 2.657870	time 1.1741 (2.4824)	loss 3.0391 (3.0160)	grad_norm 0.4045 (0.4189)	mem 39782MB
[2023-07-07 13:37:41 RepVGG-A0] (main.py 282): INFO Train: [166/300][30/78]	eta 0:01:44 lr 2.653636	time 1.1808 (2.1697)	loss 3.0161 (3.0088)	grad_norm 0.4185 (0.4064)	mem 39782MB
[2023-07-07 13:37:59 RepVGG-A0] (main.py 282): INFO Train: [166/300][40/78]	eta 0:01:19 lr 2.649404	time 4.1555 (2.0822)	loss 2.9643 (3.0087)	grad_norm 0.3645 (0.4017)	mem 39782MB
[2023-07-07 13:38:14 RepVGG-A0] (main.py 282): INFO Train: [166/300][50/78]	eta 0:00:55 lr 2.645172	time 1.1956 (1.9711)	loss 3.0193 (3.0067)	grad_norm 0.3789 (0.4005)	mem 39782MB
[2023-07-07 13:38:30 RepVGG-A0] (main.py 282): INFO Train: [166/300][60/78]	eta 0:00:34 lr 2.640941	time 1.3564 (1.8999)	loss 3.0051 (3.0078)	grad_norm 0.4208 (0.4027)	mem 39782MB
[2023-07-07 13:38:45 RepVGG-A0] (main.py 282): INFO Train: [166/300][70/78]	eta 0:00:14 lr 2.636712	time 1.4647 (1.8455)	loss 3.0385 (3.0102)	grad_norm 0.4131 (0.4046)	mem 39782MB
[2023-07-07 13:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 166 training takes 0:02:21
[2023-07-07 13:39:17 RepVGG-A0] (main.py 282): INFO Train: [167/300][0/78]	eta 0:28:38 lr 2.633329	time 22.0370 (22.0370)	loss 3.0374 (3.0374)	grad_norm 0.4661 (0.4661)	mem 39782MB
[2023-07-07 13:39:32 RepVGG-A0] (main.py 282): INFO Train: [167/300][10/78]	eta 0:03:48 lr 2.629101	time 1.1720 (3.3672)	loss 3.0567 (2.9807)	grad_norm 0.4084 (0.4003)	mem 39782MB
[2023-07-07 13:39:47 RepVGG-A0] (main.py 282): INFO Train: [167/300][20/78]	eta 0:02:23 lr 2.624874	time 1.3244 (2.4704)	loss 2.9782 (2.9873)	grad_norm 0.4423 (0.4032)	mem 39782MB
[2023-07-07 13:40:01 RepVGG-A0] (main.py 282): INFO Train: [167/300][30/78]	eta 0:01:42 lr 2.620649	time 1.2853 (2.1284)	loss 2.9216 (2.9889)	grad_norm 0.3657 (0.4048)	mem 39782MB
[2023-07-07 13:40:20 RepVGG-A0] (main.py 282): INFO Train: [167/300][40/78]	eta 0:01:18 lr 2.616424	time 2.5087 (2.0695)	loss 2.9483 (2.9832)	grad_norm 0.3943 (0.3999)	mem 39782MB
[2023-07-07 13:40:35 RepVGG-A0] (main.py 282): INFO Train: [167/300][50/78]	eta 0:00:54 lr 2.612200	time 1.1768 (1.9523)	loss 2.9943 (2.9920)	grad_norm 0.3784 (0.4076)	mem 39782MB
[2023-07-07 13:40:50 RepVGG-A0] (main.py 282): INFO Train: [167/300][60/78]	eta 0:00:33 lr 2.607978	time 1.1874 (1.8833)	loss 3.1271 (2.9953)	grad_norm 0.4593 (0.4087)	mem 39782MB
[2023-07-07 13:41:06 RepVGG-A0] (main.py 282): INFO Train: [167/300][70/78]	eta 0:00:14 lr 2.603756	time 1.4652 (1.8374)	loss 3.0503 (2.9982)	grad_norm 0.4433 (0.4107)	mem 39782MB
[2023-07-07 13:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 167 training takes 0:02:21
[2023-07-07 13:41:38 RepVGG-A0] (main.py 282): INFO Train: [168/300][0/78]	eta 0:28:02 lr 2.600380	time 21.5676 (21.5676)	loss 2.9471 (2.9471)	grad_norm 0.3901 (0.3901)	mem 39782MB
[2023-07-07 13:41:53 RepVGG-A0] (main.py 282): INFO Train: [168/300][10/78]	eta 0:03:45 lr 2.596160	time 1.1721 (3.3090)	loss 2.9498 (2.9374)	grad_norm 0.4271 (0.3940)	mem 39782MB
[2023-07-07 13:42:09 RepVGG-A0] (main.py 282): INFO Train: [168/300][20/78]	eta 0:02:23 lr 2.591942	time 1.4959 (2.4684)	loss 2.9226 (2.9639)	grad_norm 0.4163 (0.4163)	mem 39782MB
[2023-07-07 13:42:24 RepVGG-A0] (main.py 282): INFO Train: [168/300][30/78]	eta 0:01:43 lr 2.587724	time 1.4757 (2.1559)	loss 2.9855 (2.9694)	grad_norm 0.4310 (0.4117)	mem 39782MB
[2023-07-07 13:42:41 RepVGG-A0] (main.py 282): INFO Train: [168/300][40/78]	eta 0:01:17 lr 2.583508	time 3.3224 (2.0506)	loss 2.9329 (2.9711)	grad_norm 0.3683 (0.4127)	mem 39782MB
[2023-07-07 13:42:56 RepVGG-A0] (main.py 282): INFO Train: [168/300][50/78]	eta 0:00:54 lr 2.579293	time 1.1732 (1.9450)	loss 3.0116 (2.9696)	grad_norm 0.4635 (0.4107)	mem 39782MB
[2023-07-07 13:43:11 RepVGG-A0] (main.py 282): INFO Train: [168/300][60/78]	eta 0:00:33 lr 2.575079	time 1.3591 (1.8813)	loss 2.9665 (2.9766)	grad_norm 0.4068 (0.4137)	mem 39782MB
[2023-07-07 13:43:27 RepVGG-A0] (main.py 282): INFO Train: [168/300][70/78]	eta 0:00:14 lr 2.570866	time 1.1753 (1.8372)	loss 3.0352 (2.9790)	grad_norm 0.4133 (0.4139)	mem 39782MB
[2023-07-07 13:43:39 RepVGG-A0] (main.py 291): INFO EPOCH 168 training takes 0:02:21
[2023-07-07 13:43:59 RepVGG-A0] (main.py 282): INFO Train: [169/300][0/78]	eta 0:26:59 lr 2.567497	time 20.7688 (20.7688)	loss 2.8738 (2.8738)	grad_norm 0.3882 (0.3882)	mem 39782MB
[2023-07-07 13:44:15 RepVGG-A0] (main.py 282): INFO Train: [169/300][10/78]	eta 0:03:47 lr 2.563286	time 1.1727 (3.3459)	loss 3.0107 (2.9408)	grad_norm 0.4695 (0.4336)	mem 39782MB
[2023-07-07 13:44:29 RepVGG-A0] (main.py 282): INFO Train: [169/300][20/78]	eta 0:02:18 lr 2.559076	time 1.1722 (2.3965)	loss 2.9785 (2.9448)	grad_norm 0.4118 (0.4210)	mem 39782MB
[2023-07-07 13:44:44 RepVGG-A0] (main.py 282): INFO Train: [169/300][30/78]	eta 0:01:41 lr 2.554867	time 1.3217 (2.1212)	loss 2.9624 (2.9606)	grad_norm 0.4428 (0.4221)	mem 39782MB
[2023-07-07 13:45:02 RepVGG-A0] (main.py 282): INFO Train: [169/300][40/78]	eta 0:01:17 lr 2.550660	time 4.0410 (2.0428)	loss 2.9605 (2.9601)	grad_norm 0.4374 (0.4156)	mem 39782MB
[2023-07-07 13:45:18 RepVGG-A0] (main.py 282): INFO Train: [169/300][50/78]	eta 0:00:54 lr 2.546454	time 1.1743 (1.9524)	loss 2.9091 (2.9625)	grad_norm 0.3932 (0.4165)	mem 39782MB
[2023-07-07 13:45:32 RepVGG-A0] (main.py 282): INFO Train: [169/300][60/78]	eta 0:00:33 lr 2.542249	time 1.1963 (1.8657)	loss 2.9871 (2.9680)	grad_norm 0.4186 (0.4186)	mem 39782MB
[2023-07-07 13:45:47 RepVGG-A0] (main.py 282): INFO Train: [169/300][70/78]	eta 0:00:14 lr 2.538045	time 1.3269 (1.8158)	loss 2.8879 (2.9669)	grad_norm 0.3849 (0.4143)	mem 39782MB
[2023-07-07 13:45:59 RepVGG-A0] (main.py 291): INFO EPOCH 169 training takes 0:02:20
[2023-07-07 13:46:20 RepVGG-A0] (main.py 282): INFO Train: [170/300][0/78]	eta 0:27:38 lr 2.534683	time 21.2674 (21.2674)	loss 2.9910 (2.9910)	grad_norm 0.4632 (0.4632)	mem 39782MB
[2023-07-07 13:46:35 RepVGG-A0] (main.py 282): INFO Train: [170/300][10/78]	eta 0:03:38 lr 2.530481	time 1.1728 (3.2195)	loss 2.9200 (2.9177)	grad_norm 0.4123 (0.4232)	mem 39782MB
[2023-07-07 13:46:49 RepVGG-A0] (main.py 282): INFO Train: [170/300][20/78]	eta 0:02:18 lr 2.526280	time 1.1748 (2.3868)	loss 2.8959 (2.9238)	grad_norm 0.3891 (0.4195)	mem 39782MB
[2023-07-07 13:47:05 RepVGG-A0] (main.py 282): INFO Train: [170/300][30/78]	eta 0:01:42 lr 2.522081	time 1.4953 (2.1282)	loss 2.9074 (2.9198)	grad_norm 0.3868 (0.4124)	mem 39782MB
[2023-07-07 13:47:24 RepVGG-A0] (main.py 282): INFO Train: [170/300][40/78]	eta 0:01:18 lr 2.517883	time 4.1083 (2.0560)	loss 2.9317 (2.9248)	grad_norm 0.4497 (0.4109)	mem 39782MB
[2023-07-07 13:47:38 RepVGG-A0] (main.py 282): INFO Train: [170/300][50/78]	eta 0:00:54 lr 2.513686	time 1.1895 (1.9309)	loss 2.9843 (2.9341)	grad_norm 0.4956 (0.4200)	mem 39782MB
[2023-07-07 13:47:52 RepVGG-A0] (main.py 282): INFO Train: [170/300][60/78]	eta 0:00:33 lr 2.509491	time 1.1885 (1.8542)	loss 2.9505 (2.9384)	grad_norm 0.3695 (0.4194)	mem 39782MB
[2023-07-07 13:48:07 RepVGG-A0] (main.py 282): INFO Train: [170/300][70/78]	eta 0:00:14 lr 2.505296	time 1.4131 (1.8046)	loss 2.9558 (2.9405)	grad_norm 0.4598 (0.4178)	mem 39782MB
[2023-07-07 13:48:19 RepVGG-A0] (main.py 291): INFO EPOCH 170 training takes 0:02:20
[2023-07-07 13:48:41 RepVGG-A0] (main.py 282): INFO Train: [171/300][0/78]	eta 0:28:39 lr 2.501942	time 22.0480 (22.0480)	loss 2.8522 (2.8522)	grad_norm 0.4047 (0.4047)	mem 39782MB
[2023-07-07 13:48:56 RepVGG-A0] (main.py 282): INFO Train: [171/300][10/78]	eta 0:03:45 lr 2.497750	time 1.1721 (3.3177)	loss 2.8976 (2.9214)	grad_norm 0.4071 (0.4257)	mem 39782MB
[2023-07-07 13:49:10 RepVGG-A0] (main.py 282): INFO Train: [171/300][20/78]	eta 0:02:19 lr 2.493559	time 1.1737 (2.4075)	loss 2.9597 (2.9166)	grad_norm 0.4124 (0.4168)	mem 39782MB
[2023-07-07 13:49:26 RepVGG-A0] (main.py 282): INFO Train: [171/300][30/78]	eta 0:01:43 lr 2.489369	time 1.4089 (2.1635)	loss 2.9325 (2.9278)	grad_norm 0.4142 (0.4192)	mem 39782MB
[2023-07-07 13:49:45 RepVGG-A0] (main.py 282): INFO Train: [171/300][40/78]	eta 0:01:19 lr 2.485181	time 3.6172 (2.0991)	loss 2.9989 (2.9332)	grad_norm 0.4302 (0.4287)	mem 39782MB
[2023-07-07 13:50:00 RepVGG-A0] (main.py 282): INFO Train: [171/300][50/78]	eta 0:00:55 lr 2.480994	time 1.1749 (1.9724)	loss 2.9059 (2.9357)	grad_norm 0.4170 (0.4232)	mem 39782MB
[2023-07-07 13:50:15 RepVGG-A0] (main.py 282): INFO Train: [171/300][60/78]	eta 0:00:34 lr 2.476808	time 1.2742 (1.9007)	loss 2.9255 (2.9356)	grad_norm 0.4056 (0.4211)	mem 39782MB
[2023-07-07 13:50:31 RepVGG-A0] (main.py 282): INFO Train: [171/300][70/78]	eta 0:00:14 lr 2.472624	time 1.3796 (1.8487)	loss 2.9775 (2.9348)	grad_norm 0.3904 (0.4189)	mem 39782MB
[2023-07-07 13:50:42 RepVGG-A0] (main.py 291): INFO EPOCH 171 training takes 0:02:22
[2023-07-07 13:51:02 RepVGG-A0] (main.py 282): INFO Train: [172/300][0/78]	eta 0:26:06 lr 2.469277	time 20.0828 (20.0828)	loss 2.9923 (2.9923)	grad_norm 0.4223 (0.4223)	mem 39782MB
[2023-07-07 13:51:18 RepVGG-A0] (main.py 282): INFO Train: [172/300][10/78]	eta 0:03:45 lr 2.465095	time 1.1897 (3.3199)	loss 2.9000 (2.8825)	grad_norm 0.3867 (0.4099)	mem 39782MB
[2023-07-07 13:51:32 RepVGG-A0] (main.py 282): INFO Train: [172/300][20/78]	eta 0:02:18 lr 2.460914	time 1.1731 (2.3944)	loss 2.9694 (2.9011)	grad_norm 0.4396 (0.4193)	mem 39782MB
[2023-07-07 13:51:47 RepVGG-A0] (main.py 282): INFO Train: [172/300][30/78]	eta 0:01:41 lr 2.456735	time 1.1810 (2.1167)	loss 2.9029 (2.9043)	grad_norm 0.4349 (0.4197)	mem 39782MB
[2023-07-07 13:52:04 RepVGG-A0] (main.py 282): INFO Train: [172/300][40/78]	eta 0:01:16 lr 2.452557	time 2.1029 (2.0031)	loss 2.9800 (2.9077)	grad_norm 0.4100 (0.4195)	mem 39782MB
[2023-07-07 13:52:19 RepVGG-A0] (main.py 282): INFO Train: [172/300][50/78]	eta 0:00:53 lr 2.448380	time 1.6115 (1.8988)	loss 3.0015 (2.9106)	grad_norm 0.4344 (0.4189)	mem 39782MB
[2023-07-07 13:52:35 RepVGG-A0] (main.py 282): INFO Train: [172/300][60/78]	eta 0:00:33 lr 2.444205	time 1.3529 (1.8540)	loss 2.9554 (2.9175)	grad_norm 0.3808 (0.4183)	mem 39782MB
[2023-07-07 13:52:50 RepVGG-A0] (main.py 282): INFO Train: [172/300][70/78]	eta 0:00:14 lr 2.440031	time 1.3013 (1.8085)	loss 2.9836 (2.9200)	grad_norm 0.5303 (0.4188)	mem 39782MB
[2023-07-07 13:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 172 training takes 0:02:20
[2023-07-07 13:53:23 RepVGG-A0] (main.py 282): INFO Train: [173/300][0/78]	eta 0:26:57 lr 2.436693	time 20.7378 (20.7378)	loss 3.1333 (3.1333)	grad_norm 0.5914 (0.5914)	mem 39782MB
[2023-07-07 13:53:37 RepVGG-A0] (main.py 282): INFO Train: [173/300][10/78]	eta 0:03:40 lr 2.432521	time 1.1735 (3.2444)	loss 2.9317 (3.0338)	grad_norm 0.3664 (0.4833)	mem 39782MB
[2023-07-07 13:53:52 RepVGG-A0] (main.py 282): INFO Train: [173/300][20/78]	eta 0:02:18 lr 2.428351	time 1.2070 (2.3893)	loss 2.9283 (2.9758)	grad_norm 0.3851 (0.4326)	mem 39782MB
[2023-07-07 13:54:07 RepVGG-A0] (main.py 282): INFO Train: [173/300][30/78]	eta 0:01:41 lr 2.424183	time 1.4113 (2.1087)	loss 2.9741 (2.9552)	grad_norm 0.3749 (0.4145)	mem 39782MB
[2023-07-07 13:54:24 RepVGG-A0] (main.py 282): INFO Train: [173/300][40/78]	eta 0:01:16 lr 2.420015	time 3.6126 (2.0169)	loss 2.8784 (2.9410)	grad_norm 0.3728 (0.4113)	mem 39782MB
[2023-07-07 13:54:41 RepVGG-A0] (main.py 282): INFO Train: [173/300][50/78]	eta 0:00:54 lr 2.415849	time 1.3006 (1.9371)	loss 2.8910 (2.9384)	grad_norm 0.3827 (0.4085)	mem 39782MB
[2023-07-07 13:54:56 RepVGG-A0] (main.py 282): INFO Train: [173/300][60/78]	eta 0:00:33 lr 2.411685	time 1.4120 (1.8690)	loss 2.9093 (2.9335)	grad_norm 0.4212 (0.4086)	mem 39782MB
[2023-07-07 13:55:11 RepVGG-A0] (main.py 282): INFO Train: [173/300][70/78]	eta 0:00:14 lr 2.407522	time 1.1684 (1.8156)	loss 2.9034 (2.9296)	grad_norm 0.3730 (0.4077)	mem 39782MB
[2023-07-07 13:55:22 RepVGG-A0] (main.py 291): INFO EPOCH 173 training takes 0:02:20
[2023-07-07 13:55:45 RepVGG-A0] (main.py 282): INFO Train: [174/300][0/78]	eta 0:28:54 lr 2.404192	time 22.2412 (22.2412)	loss 2.9132 (2.9132)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 13:55:59 RepVGG-A0] (main.py 282): INFO Train: [174/300][10/78]	eta 0:03:44 lr 2.400032	time 1.1719 (3.2947)	loss 2.8631 (2.8888)	grad_norm 0.3906 (0.4351)	mem 39782MB
[2023-07-07 13:56:13 RepVGG-A0] (main.py 282): INFO Train: [174/300][20/78]	eta 0:02:19 lr 2.395873	time 1.1914 (2.4096)	loss 2.8972 (2.8791)	grad_norm 0.4054 (0.4213)	mem 39782MB
[2023-07-07 13:56:29 RepVGG-A0] (main.py 282): INFO Train: [174/300][30/78]	eta 0:01:42 lr 2.391715	time 1.6162 (2.1331)	loss 2.8851 (2.8727)	grad_norm 0.4346 (0.4207)	mem 39782MB
[2023-07-07 13:56:46 RepVGG-A0] (main.py 282): INFO Train: [174/300][40/78]	eta 0:01:17 lr 2.387559	time 3.8213 (2.0414)	loss 2.9377 (2.8814)	grad_norm 0.4119 (0.4222)	mem 39782MB
[2023-07-07 13:57:01 RepVGG-A0] (main.py 282): INFO Train: [174/300][50/78]	eta 0:00:54 lr 2.383404	time 1.1893 (1.9409)	loss 2.8847 (2.8895)	grad_norm 0.3976 (0.4227)	mem 39782MB
[2023-07-07 13:57:17 RepVGG-A0] (main.py 282): INFO Train: [174/300][60/78]	eta 0:00:33 lr 2.379251	time 1.2054 (1.8763)	loss 2.8185 (2.8916)	grad_norm 0.3892 (0.4201)	mem 39782MB
[2023-07-07 13:57:32 RepVGG-A0] (main.py 282): INFO Train: [174/300][70/78]	eta 0:00:14 lr 2.375099	time 1.1741 (1.8262)	loss 3.0552 (2.8965)	grad_norm 0.4304 (0.4233)	mem 39782MB
[2023-07-07 13:57:44 RepVGG-A0] (main.py 291): INFO EPOCH 174 training takes 0:02:21
[2023-07-07 13:58:06 RepVGG-A0] (main.py 282): INFO Train: [175/300][0/78]	eta 0:28:50 lr 2.371779	time 22.1803 (22.1803)	loss 2.9270 (2.9270)	grad_norm 0.4550 (0.4550)	mem 39782MB
[2023-07-07 13:58:20 RepVGG-A0] (main.py 282): INFO Train: [175/300][10/78]	eta 0:03:45 lr 2.367630	time 1.1722 (3.3216)	loss 2.8391 (2.8540)	grad_norm 0.3782 (0.4255)	mem 39782MB
[2023-07-07 13:58:34 RepVGG-A0] (main.py 282): INFO Train: [175/300][20/78]	eta 0:02:18 lr 2.363482	time 1.1727 (2.3932)	loss 2.9292 (2.8677)	grad_norm 0.4397 (0.4166)	mem 39782MB
[2023-07-07 13:58:50 RepVGG-A0] (main.py 282): INFO Train: [175/300][30/78]	eta 0:01:42 lr 2.359336	time 1.5399 (2.1330)	loss 2.8975 (2.8809)	grad_norm 0.3908 (0.4234)	mem 39782MB
[2023-07-07 13:59:08 RepVGG-A0] (main.py 282): INFO Train: [175/300][40/78]	eta 0:01:18 lr 2.355192	time 3.6410 (2.0596)	loss 2.9044 (2.8830)	grad_norm 0.4323 (0.4225)	mem 39782MB
[2023-07-07 13:59:23 RepVGG-A0] (main.py 282): INFO Train: [175/300][50/78]	eta 0:00:54 lr 2.351049	time 1.1742 (1.9516)	loss 2.8937 (2.8955)	grad_norm 0.4569 (0.4365)	mem 39782MB
[2023-07-07 13:59:38 RepVGG-A0] (main.py 282): INFO Train: [175/300][60/78]	eta 0:00:33 lr 2.346907	time 1.1326 (1.8780)	loss 2.9344 (2.8976)	grad_norm 0.4288 (0.4316)	mem 39782MB
[2023-07-07 13:59:52 RepVGG-A0] (main.py 282): INFO Train: [175/300][70/78]	eta 0:00:14 lr 2.342767	time 1.2484 (1.8099)	loss 2.9353 (2.8985)	grad_norm 0.4479 (0.4276)	mem 39782MB
[2023-07-07 14:00:04 RepVGG-A0] (main.py 291): INFO EPOCH 175 training takes 0:02:20
[2023-07-07 14:00:26 RepVGG-A0] (main.py 282): INFO Train: [176/300][0/78]	eta 0:28:44 lr 2.339457	time 22.1093 (22.1093)	loss 2.8449 (2.8449)	grad_norm 0.4049 (0.4049)	mem 39782MB
[2023-07-07 14:00:40 RepVGG-A0] (main.py 282): INFO Train: [176/300][10/78]	eta 0:03:41 lr 2.335319	time 1.1724 (3.2582)	loss 2.9274 (2.8559)	grad_norm 0.4052 (0.4060)	mem 39782MB
[2023-07-07 14:00:54 RepVGG-A0] (main.py 282): INFO Train: [176/300][20/78]	eta 0:02:19 lr 2.331184	time 1.1916 (2.3988)	loss 2.8551 (2.8618)	grad_norm 0.3774 (0.4057)	mem 39782MB
[2023-07-07 14:01:11 RepVGG-A0] (main.py 282): INFO Train: [176/300][30/78]	eta 0:01:43 lr 2.327050	time 1.5969 (2.1530)	loss 2.9309 (2.8686)	grad_norm 0.4550 (0.4164)	mem 39782MB
[2023-07-07 14:01:28 RepVGG-A0] (main.py 282): INFO Train: [176/300][40/78]	eta 0:01:17 lr 2.322917	time 3.5383 (2.0467)	loss 2.8781 (2.8814)	grad_norm 0.4153 (0.4206)	mem 39782MB
[2023-07-07 14:01:44 RepVGG-A0] (main.py 282): INFO Train: [176/300][50/78]	eta 0:00:54 lr 2.318786	time 1.2356 (1.9496)	loss 2.8817 (2.8820)	grad_norm 0.4460 (0.4203)	mem 39782MB
[2023-07-07 14:01:59 RepVGG-A0] (main.py 282): INFO Train: [176/300][60/78]	eta 0:00:33 lr 2.314657	time 1.2307 (1.8817)	loss 2.8436 (2.8808)	grad_norm 0.4125 (0.4201)	mem 39782MB
[2023-07-07 14:02:14 RepVGG-A0] (main.py 282): INFO Train: [176/300][70/78]	eta 0:00:14 lr 2.310529	time 1.4508 (1.8286)	loss 2.9042 (2.8809)	grad_norm 0.4762 (0.4207)	mem 39782MB
[2023-07-07 14:02:25 RepVGG-A0] (main.py 291): INFO EPOCH 176 training takes 0:02:20
[2023-07-07 14:02:47 RepVGG-A0] (main.py 282): INFO Train: [177/300][0/78]	eta 0:28:26 lr 2.307228	time 21.8759 (21.8759)	loss 2.8167 (2.8167)	grad_norm 0.4294 (0.4294)	mem 39782MB
[2023-07-07 14:03:03 RepVGG-A0] (main.py 282): INFO Train: [177/300][10/78]	eta 0:03:52 lr 2.303104	time 1.1713 (3.4188)	loss 2.8152 (2.8729)	grad_norm 0.4109 (0.4347)	mem 39782MB
[2023-07-07 14:03:17 RepVGG-A0] (main.py 282): INFO Train: [177/300][20/78]	eta 0:02:24 lr 2.298980	time 1.3388 (2.4933)	loss 2.8148 (2.8701)	grad_norm 0.4054 (0.4214)	mem 39782MB
[2023-07-07 14:03:32 RepVGG-A0] (main.py 282): INFO Train: [177/300][30/78]	eta 0:01:43 lr 2.294859	time 1.2794 (2.1632)	loss 2.8598 (2.8724)	grad_norm 0.4534 (0.4241)	mem 39782MB
[2023-07-07 14:03:51 RepVGG-A0] (main.py 282): INFO Train: [177/300][40/78]	eta 0:01:19 lr 2.290739	time 3.3493 (2.0876)	loss 2.9102 (2.8785)	grad_norm 0.4210 (0.4281)	mem 39782MB
[2023-07-07 14:04:05 RepVGG-A0] (main.py 282): INFO Train: [177/300][50/78]	eta 0:00:55 lr 2.286621	time 1.1846 (1.9699)	loss 2.8477 (2.8781)	grad_norm 0.4044 (0.4290)	mem 39782MB
[2023-07-07 14:04:20 RepVGG-A0] (main.py 282): INFO Train: [177/300][60/78]	eta 0:00:33 lr 2.282504	time 1.1748 (1.8811)	loss 2.8703 (2.8790)	grad_norm 0.4053 (0.4258)	mem 39782MB
[2023-07-07 14:04:36 RepVGG-A0] (main.py 282): INFO Train: [177/300][70/78]	eta 0:00:14 lr 2.278389	time 1.4439 (1.8408)	loss 2.8745 (2.8770)	grad_norm 0.4117 (0.4240)	mem 39782MB
[2023-07-07 14:04:48 RepVGG-A0] (main.py 291): INFO EPOCH 177 training takes 0:02:22
[2023-07-07 14:05:08 RepVGG-A0] (main.py 282): INFO Train: [178/300][0/78]	eta 0:26:37 lr 2.275098	time 20.4860 (20.4860)	loss 2.8527 (2.8527)	grad_norm 0.5030 (0.5030)	mem 39782MB
[2023-07-07 14:05:23 RepVGG-A0] (main.py 282): INFO Train: [178/300][10/78]	eta 0:03:40 lr 2.270986	time 1.1723 (3.2395)	loss 2.9194 (2.8943)	grad_norm 0.4013 (0.4872)	mem 39782MB
[2023-07-07 14:05:39 RepVGG-A0] (main.py 282): INFO Train: [178/300][20/78]	eta 0:02:20 lr 2.266876	time 1.1739 (2.4217)	loss 2.9159 (2.8701)	grad_norm 0.4032 (0.4468)	mem 39782MB
[2023-07-07 14:05:54 RepVGG-A0] (main.py 282): INFO Train: [178/300][30/78]	eta 0:01:42 lr 2.262767	time 1.3391 (2.1379)	loss 2.8822 (2.8715)	grad_norm 0.5090 (0.4396)	mem 39782MB
[2023-07-07 14:06:12 RepVGG-A0] (main.py 282): INFO Train: [178/300][40/78]	eta 0:01:18 lr 2.258660	time 3.1708 (2.0588)	loss 2.7984 (2.8733)	grad_norm 0.3990 (0.4328)	mem 39782MB
[2023-07-07 14:06:27 RepVGG-A0] (main.py 282): INFO Train: [178/300][50/78]	eta 0:00:54 lr 2.254555	time 1.1714 (1.9439)	loss 2.8881 (2.8752)	grad_norm 0.4083 (0.4322)	mem 39782MB
[2023-07-07 14:06:42 RepVGG-A0] (main.py 282): INFO Train: [178/300][60/78]	eta 0:00:33 lr 2.250452	time 1.2942 (1.8748)	loss 2.8600 (2.8687)	grad_norm 0.4020 (0.4271)	mem 39782MB
[2023-07-07 14:06:57 RepVGG-A0] (main.py 282): INFO Train: [178/300][70/78]	eta 0:00:14 lr 2.246350	time 1.1713 (1.8230)	loss 2.9155 (2.8695)	grad_norm 0.4972 (0.4286)	mem 39782MB
[2023-07-07 14:07:09 RepVGG-A0] (main.py 291): INFO EPOCH 178 training takes 0:02:20
[2023-07-07 14:07:31 RepVGG-A0] (main.py 282): INFO Train: [179/300][0/78]	eta 0:29:36 lr 2.243069	time 22.7761 (22.7761)	loss 2.7860 (2.7860)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 14:07:45 RepVGG-A0] (main.py 282): INFO Train: [179/300][10/78]	eta 0:03:45 lr 2.238971	time 1.1721 (3.3165)	loss 2.8692 (2.8222)	grad_norm 0.4358 (0.4013)	mem 39782MB
[2023-07-07 14:08:00 RepVGG-A0] (main.py 282): INFO Train: [179/300][20/78]	eta 0:02:22 lr 2.234874	time 1.1741 (2.4605)	loss 2.8431 (2.8448)	grad_norm 0.4070 (0.4127)	mem 39782MB
[2023-07-07 14:08:15 RepVGG-A0] (main.py 282): INFO Train: [179/300][30/78]	eta 0:01:43 lr 2.230778	time 1.2866 (2.1500)	loss 2.8842 (2.8490)	grad_norm 0.3977 (0.4138)	mem 39782MB
[2023-07-07 14:08:33 RepVGG-A0] (main.py 282): INFO Train: [179/300][40/78]	eta 0:01:17 lr 2.226685	time 1.6302 (2.0523)	loss 2.8646 (2.8489)	grad_norm 0.4566 (0.4153)	mem 39782MB
[2023-07-07 14:08:48 RepVGG-A0] (main.py 282): INFO Train: [179/300][50/78]	eta 0:00:54 lr 2.222593	time 1.1747 (1.9507)	loss 2.8095 (2.8576)	grad_norm 0.4202 (0.4243)	mem 39782MB
[2023-07-07 14:09:03 RepVGG-A0] (main.py 282): INFO Train: [179/300][60/78]	eta 0:00:33 lr 2.218503	time 1.1925 (1.8786)	loss 2.8426 (2.8588)	grad_norm 0.4486 (0.4242)	mem 39782MB
[2023-07-07 14:09:18 RepVGG-A0] (main.py 282): INFO Train: [179/300][70/78]	eta 0:00:14 lr 2.214415	time 1.2422 (1.8250)	loss 2.9287 (2.8648)	grad_norm 0.4134 (0.4272)	mem 39782MB
[2023-07-07 14:09:30 RepVGG-A0] (main.py 291): INFO EPOCH 179 training takes 0:02:21
[2023-07-07 14:09:52 RepVGG-A0] (main.py 282): INFO Train: [180/300][0/78]	eta 0:28:53 lr 2.211146	time 22.2229 (22.2229)	loss 2.7827 (2.7827)	grad_norm 0.4234 (0.4234)	mem 39782MB
[2023-07-07 14:10:06 RepVGG-A0] (main.py 282): INFO Train: [180/300][10/78]	eta 0:03:42 lr 2.207061	time 1.1736 (3.2787)	loss 2.8476 (2.8183)	grad_norm 0.4227 (0.4185)	mem 39782MB
[2023-07-07 14:10:21 RepVGG-A0] (main.py 282): INFO Train: [180/300][20/78]	eta 0:02:21 lr 2.202977	time 1.1785 (2.4410)	loss 2.8250 (2.8293)	grad_norm 0.4307 (0.4238)	mem 39782MB
[2023-07-07 14:10:38 RepVGG-A0] (main.py 282): INFO Train: [180/300][30/78]	eta 0:01:45 lr 2.198896	time 2.1960 (2.1908)	loss 2.8472 (2.8461)	grad_norm 0.4013 (0.4360)	mem 39782MB
[2023-07-07 14:10:55 RepVGG-A0] (main.py 282): INFO Train: [180/300][40/78]	eta 0:01:18 lr 2.194816	time 3.4075 (2.0665)	loss 2.8656 (2.8478)	grad_norm 0.4398 (0.4329)	mem 39782MB
[2023-07-07 14:11:09 RepVGG-A0] (main.py 282): INFO Train: [180/300][50/78]	eta 0:00:54 lr 2.190738	time 1.1735 (1.9484)	loss 2.8477 (2.8467)	grad_norm 0.4570 (0.4285)	mem 39782MB
[2023-07-07 14:11:25 RepVGG-A0] (main.py 282): INFO Train: [180/300][60/78]	eta 0:00:34 lr 2.186662	time 1.5992 (1.8903)	loss 2.8549 (2.8514)	grad_norm 0.4141 (0.4297)	mem 39782MB
[2023-07-07 14:11:38 RepVGG-A0] (main.py 282): INFO Train: [180/300][70/78]	eta 0:00:14 lr 2.182588	time 1.1766 (1.8085)	loss 2.8589 (2.8541)	grad_norm 0.4716 (0.4313)	mem 39782MB
[2023-07-07 14:11:51 RepVGG-A0] (main.py 291): INFO EPOCH 180 training takes 0:02:20
[2023-07-07 14:12:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.611 (17.611)	Loss 2.2331 (2.2331)	Acc@1 51.160 (51.160)	Acc@5 75.751 (75.751)	Mem 39782MB
[2023-07-07 14:12:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 51.752 Acc@5 76.092
[2023-07-07 14:12:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 180: 51.752%
[2023-07-07 14:12:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 51.75%
[2023-07-07 14:12:30 RepVGG-A0] (main.py 282): INFO Train: [181/300][0/78]	eta 0:27:11 lr 2.179330	time 20.9167 (20.9167)	loss 2.8395 (2.8395)	grad_norm 0.4137 (0.4137)	mem 39782MB
[2023-07-07 14:12:47 RepVGG-A0] (main.py 282): INFO Train: [181/300][10/78]	eta 0:03:50 lr 2.175259	time 1.1713 (3.3915)	loss 2.7928 (2.8306)	grad_norm 0.3866 (0.4094)	mem 39782MB
[2023-07-07 14:13:01 RepVGG-A0] (main.py 282): INFO Train: [181/300][20/78]	eta 0:02:23 lr 2.171190	time 1.2637 (2.4691)	loss 2.8620 (2.8244)	grad_norm 0.4492 (0.4071)	mem 39782MB
[2023-07-07 14:13:17 RepVGG-A0] (main.py 282): INFO Train: [181/300][30/78]	eta 0:01:44 lr 2.167123	time 1.8837 (2.1791)	loss 2.9023 (2.8450)	grad_norm 0.4161 (0.4194)	mem 39782MB
[2023-07-07 14:13:34 RepVGG-A0] (main.py 282): INFO Train: [181/300][40/78]	eta 0:01:18 lr 2.163058	time 4.2175 (2.0632)	loss 2.8558 (2.8433)	grad_norm 0.4424 (0.4200)	mem 39782MB
[2023-07-07 14:13:49 RepVGG-A0] (main.py 282): INFO Train: [181/300][50/78]	eta 0:00:54 lr 2.158994	time 1.1742 (1.9533)	loss 2.8288 (2.8464)	grad_norm 0.4372 (0.4223)	mem 39782MB
[2023-07-07 14:14:03 RepVGG-A0] (main.py 282): INFO Train: [181/300][60/78]	eta 0:00:33 lr 2.154933	time 1.1729 (1.8716)	loss 2.8019 (2.8511)	grad_norm 0.4500 (0.4270)	mem 39782MB
[2023-07-07 14:14:19 RepVGG-A0] (main.py 282): INFO Train: [181/300][70/78]	eta 0:00:14 lr 2.150873	time 1.1274 (1.8324)	loss 2.8001 (2.8472)	grad_norm 0.4354 (0.4248)	mem 39782MB
[2023-07-07 14:14:30 RepVGG-A0] (main.py 291): INFO EPOCH 181 training takes 0:02:20
[2023-07-07 14:14:51 RepVGG-A0] (main.py 282): INFO Train: [182/300][0/78]	eta 0:27:08 lr 2.147627	time 20.8838 (20.8838)	loss 2.8198 (2.8198)	grad_norm 0.4604 (0.4604)	mem 39782MB
[2023-07-07 14:15:05 RepVGG-A0] (main.py 282): INFO Train: [182/300][10/78]	eta 0:03:37 lr 2.143570	time 1.1734 (3.1916)	loss 2.7698 (2.8173)	grad_norm 0.3832 (0.4279)	mem 39782MB
[2023-07-07 14:15:20 RepVGG-A0] (main.py 282): INFO Train: [182/300][20/78]	eta 0:02:17 lr 2.139516	time 1.1723 (2.3708)	loss 2.8589 (2.8174)	grad_norm 0.4696 (0.4289)	mem 39782MB
[2023-07-07 14:15:35 RepVGG-A0] (main.py 282): INFO Train: [182/300][30/78]	eta 0:01:40 lr 2.135464	time 1.2125 (2.0949)	loss 2.7912 (2.8406)	grad_norm 0.4038 (0.4527)	mem 39782MB
[2023-07-07 14:15:53 RepVGG-A0] (main.py 282): INFO Train: [182/300][40/78]	eta 0:01:17 lr 2.131413	time 3.9430 (2.0311)	loss 2.8208 (2.8337)	grad_norm 0.4073 (0.4402)	mem 39782MB
[2023-07-07 14:16:08 RepVGG-A0] (main.py 282): INFO Train: [182/300][50/78]	eta 0:00:54 lr 2.127364	time 1.1734 (1.9306)	loss 2.8110 (2.8344)	grad_norm 0.3986 (0.4338)	mem 39782MB
[2023-07-07 14:16:23 RepVGG-A0] (main.py 282): INFO Train: [182/300][60/78]	eta 0:00:33 lr 2.123318	time 1.1656 (1.8560)	loss 2.8218 (2.8345)	grad_norm 0.4175 (0.4315)	mem 39782MB
[2023-07-07 14:16:39 RepVGG-A0] (main.py 282): INFO Train: [182/300][70/78]	eta 0:00:14 lr 2.119273	time 1.1804 (1.8142)	loss 2.9304 (2.8419)	grad_norm 0.5108 (0.4387)	mem 39782MB
[2023-07-07 14:16:51 RepVGG-A0] (main.py 291): INFO EPOCH 182 training takes 0:02:20
[2023-07-07 14:17:12 RepVGG-A0] (main.py 282): INFO Train: [183/300][0/78]	eta 0:27:52 lr 2.116039	time 21.4420 (21.4420)	loss 2.8884 (2.8884)	grad_norm 0.4088 (0.4088)	mem 39782MB
[2023-07-07 14:17:27 RepVGG-A0] (main.py 282): INFO Train: [183/300][10/78]	eta 0:03:45 lr 2.111997	time 1.1725 (3.3229)	loss 2.8879 (2.8336)	grad_norm 0.4117 (0.4263)	mem 39782MB
[2023-07-07 14:17:41 RepVGG-A0] (main.py 282): INFO Train: [183/300][20/78]	eta 0:02:19 lr 2.107958	time 1.1749 (2.4121)	loss 2.8268 (2.8221)	grad_norm 0.4094 (0.4277)	mem 39782MB
[2023-07-07 14:17:57 RepVGG-A0] (main.py 282): INFO Train: [183/300][30/78]	eta 0:01:43 lr 2.103921	time 1.4270 (2.1484)	loss 2.8590 (2.8269)	grad_norm 0.4136 (0.4238)	mem 39782MB
[2023-07-07 14:18:15 RepVGG-A0] (main.py 282): INFO Train: [183/300][40/78]	eta 0:01:17 lr 2.099886	time 3.9871 (2.0445)	loss 2.8160 (2.8278)	grad_norm 0.4417 (0.4279)	mem 39782MB
[2023-07-07 14:18:30 RepVGG-A0] (main.py 282): INFO Train: [183/300][50/78]	eta 0:00:54 lr 2.095852	time 1.1751 (1.9381)	loss 2.8302 (2.8261)	grad_norm 0.4075 (0.4246)	mem 39782MB
[2023-07-07 14:18:44 RepVGG-A0] (main.py 282): INFO Train: [183/300][60/78]	eta 0:00:33 lr 2.091821	time 1.2915 (1.8618)	loss 2.8152 (2.8260)	grad_norm 0.3917 (0.4247)	mem 39782MB
[2023-07-07 14:19:00 RepVGG-A0] (main.py 282): INFO Train: [183/300][70/78]	eta 0:00:14 lr 2.087791	time 1.2043 (1.8166)	loss 2.7702 (2.8298)	grad_norm 0.4519 (0.4292)	mem 39782MB
[2023-07-07 14:19:11 RepVGG-A0] (main.py 291): INFO EPOCH 183 training takes 0:02:20
[2023-07-07 14:19:33 RepVGG-A0] (main.py 282): INFO Train: [184/300][0/78]	eta 0:28:35 lr 2.084569	time 21.9934 (21.9934)	loss 2.7739 (2.7739)	grad_norm 0.4164 (0.4164)	mem 39782MB
[2023-07-07 14:19:48 RepVGG-A0] (main.py 282): INFO Train: [184/300][10/78]	eta 0:03:51 lr 2.080544	time 1.1716 (3.4036)	loss 2.7967 (2.7861)	grad_norm 0.4092 (0.4290)	mem 39782MB
[2023-07-07 14:20:04 RepVGG-A0] (main.py 282): INFO Train: [184/300][20/78]	eta 0:02:25 lr 2.076520	time 1.1969 (2.5006)	loss 2.8101 (2.7997)	grad_norm 0.4272 (0.4374)	mem 39782MB
[2023-07-07 14:20:19 RepVGG-A0] (main.py 282): INFO Train: [184/300][30/78]	eta 0:01:44 lr 2.072498	time 1.4264 (2.1801)	loss 2.7991 (2.8016)	grad_norm 0.4715 (0.4347)	mem 39782MB
[2023-07-07 14:20:34 RepVGG-A0] (main.py 282): INFO Train: [184/300][40/78]	eta 0:01:16 lr 2.068479	time 1.7262 (2.0188)	loss 2.9094 (2.8075)	grad_norm 0.4266 (0.4359)	mem 39782MB
[2023-07-07 14:20:52 RepVGG-A0] (main.py 282): INFO Train: [184/300][50/78]	eta 0:00:55 lr 2.064461	time 1.3114 (1.9746)	loss 2.7984 (2.8146)	grad_norm 0.4441 (0.4355)	mem 39782MB
[2023-07-07 14:21:07 RepVGG-A0] (main.py 282): INFO Train: [184/300][60/78]	eta 0:00:34 lr 2.060445	time 1.3048 (1.8956)	loss 2.8406 (2.8164)	grad_norm 0.4380 (0.4349)	mem 39782MB
[2023-07-07 14:21:21 RepVGG-A0] (main.py 282): INFO Train: [184/300][70/78]	eta 0:00:14 lr 2.056432	time 1.2146 (1.8265)	loss 2.8214 (2.8193)	grad_norm 0.4162 (0.4350)	mem 39782MB
[2023-07-07 14:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 184 training takes 0:02:21
[2023-07-07 14:21:55 RepVGG-A0] (main.py 282): INFO Train: [185/300][0/78]	eta 0:29:02 lr 2.053223	time 22.3426 (22.3426)	loss 2.7567 (2.7567)	grad_norm 0.4285 (0.4285)	mem 39782MB
[2023-07-07 14:22:10 RepVGG-A0] (main.py 282): INFO Train: [185/300][10/78]	eta 0:03:49 lr 2.049213	time 1.1709 (3.3812)	loss 2.8220 (2.8076)	grad_norm 0.4397 (0.4510)	mem 39782MB
[2023-07-07 14:22:25 RepVGG-A0] (main.py 282): INFO Train: [185/300][20/78]	eta 0:02:24 lr 2.045205	time 1.1754 (2.4868)	loss 2.7687 (2.8043)	grad_norm 0.4867 (0.4514)	mem 39782MB
[2023-07-07 14:22:40 RepVGG-A0] (main.py 282): INFO Train: [185/300][30/78]	eta 0:01:43 lr 2.041199	time 1.6803 (2.1630)	loss 2.8219 (2.8005)	grad_norm 0.4233 (0.4425)	mem 39782MB
[2023-07-07 14:22:59 RepVGG-A0] (main.py 282): INFO Train: [185/300][40/78]	eta 0:01:19 lr 2.037196	time 4.5904 (2.0956)	loss 2.7515 (2.8036)	grad_norm 0.4123 (0.4435)	mem 39782MB
[2023-07-07 14:23:14 RepVGG-A0] (main.py 282): INFO Train: [185/300][50/78]	eta 0:00:55 lr 2.033194	time 1.2501 (1.9763)	loss 2.7414 (2.8024)	grad_norm 0.4245 (0.4378)	mem 39782MB
[2023-07-07 14:23:29 RepVGG-A0] (main.py 282): INFO Train: [185/300][60/78]	eta 0:00:34 lr 2.029195	time 1.1919 (1.9098)	loss 2.8801 (2.8079)	grad_norm 0.4865 (0.4370)	mem 39782MB
[2023-07-07 14:23:45 RepVGG-A0] (main.py 282): INFO Train: [185/300][70/78]	eta 0:00:14 lr 2.025198	time 1.4303 (1.8594)	loss 2.8244 (2.8220)	grad_norm 0.5153 (0.4496)	mem 39782MB
[2023-07-07 14:23:56 RepVGG-A0] (main.py 291): INFO EPOCH 185 training takes 0:02:22
[2023-07-07 14:24:16 RepVGG-A0] (main.py 282): INFO Train: [186/300][0/78]	eta 0:26:35 lr 2.022001	time 20.4507 (20.4507)	loss 2.7938 (2.7938)	grad_norm 0.3953 (0.3953)	mem 39782MB
[2023-07-07 14:24:32 RepVGG-A0] (main.py 282): INFO Train: [186/300][10/78]	eta 0:03:46 lr 2.018008	time 1.1733 (3.3318)	loss 2.8246 (2.7814)	grad_norm 0.4386 (0.4102)	mem 39782MB
[2023-07-07 14:24:47 RepVGG-A0] (main.py 282): INFO Train: [186/300][20/78]	eta 0:02:20 lr 2.014017	time 1.3808 (2.4221)	loss 2.7528 (2.7820)	grad_norm 0.4457 (0.4197)	mem 39782MB
[2023-07-07 14:25:01 RepVGG-A0] (main.py 282): INFO Train: [186/300][30/78]	eta 0:01:41 lr 2.010028	time 1.2870 (2.1093)	loss 2.8176 (2.7936)	grad_norm 0.4208 (0.4273)	mem 39782MB
[2023-07-07 14:25:19 RepVGG-A0] (main.py 282): INFO Train: [186/300][40/78]	eta 0:01:17 lr 2.006040	time 3.1363 (2.0436)	loss 2.7849 (2.7978)	grad_norm 0.3876 (0.4283)	mem 39782MB
[2023-07-07 14:25:35 RepVGG-A0] (main.py 282): INFO Train: [186/300][50/78]	eta 0:00:54 lr 2.002056	time 1.1718 (1.9459)	loss 2.7428 (2.7994)	grad_norm 0.4566 (0.4273)	mem 39782MB
[2023-07-07 14:25:50 RepVGG-A0] (main.py 282): INFO Train: [186/300][60/78]	eta 0:00:33 lr 1.998073	time 1.1351 (1.8702)	loss 2.8287 (2.8081)	grad_norm 0.4367 (0.4297)	mem 39782MB
[2023-07-07 14:26:04 RepVGG-A0] (main.py 282): INFO Train: [186/300][70/78]	eta 0:00:14 lr 1.994092	time 1.1714 (1.8137)	loss 2.8315 (2.8090)	grad_norm 0.4443 (0.4279)	mem 39782MB
[2023-07-07 14:26:16 RepVGG-A0] (main.py 291): INFO EPOCH 186 training takes 0:02:20
[2023-07-07 14:26:38 RepVGG-A0] (main.py 282): INFO Train: [187/300][0/78]	eta 0:28:30 lr 1.990909	time 21.9287 (21.9287)	loss 2.8001 (2.8001)	grad_norm 0.4073 (0.4073)	mem 39782MB
[2023-07-07 14:26:53 RepVGG-A0] (main.py 282): INFO Train: [187/300][10/78]	eta 0:03:46 lr 1.986933	time 1.1925 (3.3296)	loss 2.8113 (2.7803)	grad_norm 0.5060 (0.4395)	mem 39782MB
[2023-07-07 14:27:08 RepVGG-A0] (main.py 282): INFO Train: [187/300][20/78]	eta 0:02:23 lr 1.982958	time 1.1800 (2.4743)	loss 2.8302 (2.7881)	grad_norm 0.4179 (0.4472)	mem 39782MB
[2023-07-07 14:27:24 RepVGG-A0] (main.py 282): INFO Train: [187/300][30/78]	eta 0:01:44 lr 1.978986	time 1.2189 (2.1801)	loss 2.7854 (2.7953)	grad_norm 0.4245 (0.4434)	mem 39782MB
[2023-07-07 14:27:41 RepVGG-A0] (main.py 282): INFO Train: [187/300][40/78]	eta 0:01:18 lr 1.975016	time 1.9820 (2.0695)	loss 2.8561 (2.7952)	grad_norm 0.4820 (0.4404)	mem 39782MB
[2023-07-07 14:27:56 RepVGG-A0] (main.py 282): INFO Train: [187/300][50/78]	eta 0:00:54 lr 1.971048	time 1.2673 (1.9559)	loss 2.8025 (2.7956)	grad_norm 0.4164 (0.4371)	mem 39782MB
[2023-07-07 14:28:11 RepVGG-A0] (main.py 282): INFO Train: [187/300][60/78]	eta 0:00:33 lr 1.967083	time 1.2877 (1.8804)	loss 2.7453 (2.7974)	grad_norm 0.4245 (0.4376)	mem 39782MB
[2023-07-07 14:28:26 RepVGG-A0] (main.py 282): INFO Train: [187/300][70/78]	eta 0:00:14 lr 1.963119	time 1.1267 (1.8308)	loss 2.7399 (2.7976)	grad_norm 0.3970 (0.4364)	mem 39782MB
[2023-07-07 14:28:38 RepVGG-A0] (main.py 291): INFO EPOCH 187 training takes 0:02:21
[2023-07-07 14:28:59 RepVGG-A0] (main.py 282): INFO Train: [188/300][0/78]	eta 0:27:25 lr 1.959950	time 21.0978 (21.0978)	loss 2.7400 (2.7400)	grad_norm 0.4687 (0.4687)	mem 39782MB
[2023-07-07 14:29:14 RepVGG-A0] (main.py 282): INFO Train: [188/300][10/78]	eta 0:03:40 lr 1.955991	time 1.1914 (3.2451)	loss 2.8074 (2.7934)	grad_norm 0.5163 (0.4936)	mem 39782MB
[2023-07-07 14:29:28 RepVGG-A0] (main.py 282): INFO Train: [188/300][20/78]	eta 0:02:18 lr 1.952034	time 1.1724 (2.3890)	loss 2.7456 (2.7959)	grad_norm 0.4126 (0.4590)	mem 39782MB
[2023-07-07 14:29:44 RepVGG-A0] (main.py 282): INFO Train: [188/300][30/78]	eta 0:01:42 lr 1.948079	time 1.4354 (2.1289)	loss 2.8117 (2.7968)	grad_norm 0.4578 (0.4553)	mem 39782MB
[2023-07-07 14:30:01 RepVGG-A0] (main.py 282): INFO Train: [188/300][40/78]	eta 0:01:16 lr 1.944126	time 2.9184 (2.0201)	loss 2.8699 (2.8007)	grad_norm 0.4701 (0.4472)	mem 39782MB
[2023-07-07 14:30:16 RepVGG-A0] (main.py 282): INFO Train: [188/300][50/78]	eta 0:00:53 lr 1.940176	time 1.1915 (1.9222)	loss 2.7644 (2.8014)	grad_norm 0.4409 (0.4484)	mem 39782MB
[2023-07-07 14:30:31 RepVGG-A0] (main.py 282): INFO Train: [188/300][60/78]	eta 0:00:33 lr 1.936228	time 1.1774 (1.8540)	loss 2.7824 (2.7990)	grad_norm 0.4234 (0.4458)	mem 39782MB
[2023-07-07 14:30:46 RepVGG-A0] (main.py 282): INFO Train: [188/300][70/78]	eta 0:00:14 lr 1.932282	time 1.1724 (1.8052)	loss 2.8612 (2.8020)	grad_norm 0.4376 (0.4440)	mem 39782MB
[2023-07-07 14:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 188 training takes 0:02:19
[2023-07-07 14:31:19 RepVGG-A0] (main.py 282): INFO Train: [189/300][0/78]	eta 0:27:27 lr 1.929127	time 21.1180 (21.1180)	loss 2.7668 (2.7668)	grad_norm 0.4253 (0.4253)	mem 39782MB
[2023-07-07 14:31:34 RepVGG-A0] (main.py 282): INFO Train: [189/300][10/78]	eta 0:03:46 lr 1.925185	time 1.1922 (3.3240)	loss 2.7021 (2.7649)	grad_norm 0.4329 (0.4367)	mem 39782MB
[2023-07-07 14:31:48 RepVGG-A0] (main.py 282): INFO Train: [189/300][20/78]	eta 0:02:19 lr 1.921246	time 1.2056 (2.4096)	loss 2.8294 (2.7801)	grad_norm 0.5442 (0.4628)	mem 39782MB
[2023-07-07 14:32:04 RepVGG-A0] (main.py 282): INFO Train: [189/300][30/78]	eta 0:01:42 lr 1.917309	time 1.3180 (2.1380)	loss 2.8166 (2.7926)	grad_norm 0.4085 (0.4646)	mem 39782MB
[2023-07-07 14:32:21 RepVGG-A0] (main.py 282): INFO Train: [189/300][40/78]	eta 0:01:17 lr 1.913374	time 3.4488 (2.0391)	loss 2.7975 (2.7946)	grad_norm 0.4250 (0.4580)	mem 39782MB
[2023-07-07 14:32:37 RepVGG-A0] (main.py 282): INFO Train: [189/300][50/78]	eta 0:00:54 lr 1.909441	time 1.2176 (1.9409)	loss 2.8886 (2.7998)	grad_norm 0.5137 (0.4555)	mem 39782MB
[2023-07-07 14:32:52 RepVGG-A0] (main.py 282): INFO Train: [189/300][60/78]	eta 0:00:33 lr 1.905511	time 1.1923 (1.8656)	loss 2.8234 (2.8013)	grad_norm 0.4503 (0.4533)	mem 39782MB
[2023-07-07 14:33:07 RepVGG-A0] (main.py 282): INFO Train: [189/300][70/78]	eta 0:00:14 lr 1.901583	time 1.4255 (1.8237)	loss 2.8119 (2.8004)	grad_norm 0.3960 (0.4496)	mem 39782MB
[2023-07-07 14:33:19 RepVGG-A0] (main.py 291): INFO EPOCH 189 training takes 0:02:21
[2023-07-07 14:33:41 RepVGG-A0] (main.py 282): INFO Train: [190/300][0/78]	eta 0:28:56 lr 1.898443	time 22.2647 (22.2647)	loss 2.7204 (2.7204)	grad_norm 0.4072 (0.4072)	mem 39782MB
[2023-07-07 14:33:56 RepVGG-A0] (main.py 282): INFO Train: [190/300][10/78]	eta 0:03:47 lr 1.894519	time 1.1716 (3.3434)	loss 2.7446 (2.7359)	grad_norm 0.4427 (0.4193)	mem 39782MB
[2023-07-07 14:34:10 RepVGG-A0] (main.py 282): INFO Train: [190/300][20/78]	eta 0:02:20 lr 1.890598	time 1.1720 (2.4175)	loss 2.7567 (2.7474)	grad_norm 0.4369 (0.4279)	mem 39782MB
[2023-07-07 14:34:25 RepVGG-A0] (main.py 282): INFO Train: [190/300][30/78]	eta 0:01:42 lr 1.886679	time 1.4705 (2.1338)	loss 2.7866 (2.7581)	grad_norm 0.4388 (0.4329)	mem 39782MB
[2023-07-07 14:34:43 RepVGG-A0] (main.py 282): INFO Train: [190/300][40/78]	eta 0:01:17 lr 1.882763	time 2.6333 (2.0480)	loss 2.7639 (2.7591)	grad_norm 0.4305 (0.4336)	mem 39782MB
[2023-07-07 14:34:59 RepVGG-A0] (main.py 282): INFO Train: [190/300][50/78]	eta 0:00:54 lr 1.878848	time 1.3312 (1.9601)	loss 2.7815 (2.7661)	grad_norm 0.4950 (0.4375)	mem 39782MB
[2023-07-07 14:35:14 RepVGG-A0] (main.py 282): INFO Train: [190/300][60/78]	eta 0:00:33 lr 1.874937	time 1.3303 (1.8861)	loss 2.7940 (2.7711)	grad_norm 0.4458 (0.4381)	mem 39782MB
[2023-07-07 14:35:29 RepVGG-A0] (main.py 282): INFO Train: [190/300][70/78]	eta 0:00:14 lr 1.871027	time 1.1759 (1.8257)	loss 2.8283 (2.7762)	grad_norm 0.4468 (0.4383)	mem 39782MB
[2023-07-07 14:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 190 training takes 0:02:21
[2023-07-07 14:36:02 RepVGG-A0] (main.py 282): INFO Train: [191/300][0/78]	eta 0:28:02 lr 1.867901	time 21.5667 (21.5667)	loss 2.7681 (2.7681)	grad_norm 0.4486 (0.4486)	mem 39782MB
[2023-07-07 14:36:17 RepVGG-A0] (main.py 282): INFO Train: [191/300][10/78]	eta 0:03:48 lr 1.863996	time 1.1723 (3.3554)	loss 2.7842 (2.7585)	grad_norm 0.4554 (0.4545)	mem 39782MB
[2023-07-07 14:36:33 RepVGG-A0] (main.py 282): INFO Train: [191/300][20/78]	eta 0:02:24 lr 1.860094	time 1.3026 (2.4867)	loss 2.7890 (2.7522)	grad_norm 0.4229 (0.4408)	mem 39782MB
[2023-07-07 14:36:48 RepVGG-A0] (main.py 282): INFO Train: [191/300][30/78]	eta 0:01:45 lr 1.856194	time 1.5515 (2.1922)	loss 2.7932 (2.7654)	grad_norm 0.4214 (0.4470)	mem 39782MB
[2023-07-07 14:37:06 RepVGG-A0] (main.py 282): INFO Train: [191/300][40/78]	eta 0:01:19 lr 1.852296	time 3.1635 (2.0948)	loss 2.7696 (2.7700)	grad_norm 0.4349 (0.4468)	mem 39782MB
[2023-07-07 14:37:21 RepVGG-A0] (main.py 282): INFO Train: [191/300][50/78]	eta 0:00:55 lr 1.848400	time 1.1733 (1.9691)	loss 2.8170 (2.7729)	grad_norm 0.4610 (0.4467)	mem 39782MB
[2023-07-07 14:37:36 RepVGG-A0] (main.py 282): INFO Train: [191/300][60/78]	eta 0:00:34 lr 1.844507	time 1.1689 (1.9027)	loss 2.7497 (2.7764)	grad_norm 0.4316 (0.4449)	mem 39782MB
[2023-07-07 14:37:51 RepVGG-A0] (main.py 282): INFO Train: [191/300][70/78]	eta 0:00:14 lr 1.840617	time 1.3075 (1.8425)	loss 2.8351 (2.7771)	grad_norm 0.4229 (0.4425)	mem 39782MB
[2023-07-07 14:38:03 RepVGG-A0] (main.py 291): INFO EPOCH 191 training takes 0:02:22
[2023-07-07 14:38:25 RepVGG-A0] (main.py 282): INFO Train: [192/300][0/78]	eta 0:28:30 lr 1.837506	time 21.9278 (21.9278)	loss 2.7469 (2.7469)	grad_norm 0.4034 (0.4034)	mem 39782MB
[2023-07-07 14:38:39 RepVGG-A0] (main.py 282): INFO Train: [192/300][10/78]	eta 0:03:42 lr 1.833620	time 1.1720 (3.2759)	loss 2.8105 (2.7540)	grad_norm 0.5598 (0.4831)	mem 39782MB
[2023-07-07 14:38:53 RepVGG-A0] (main.py 282): INFO Train: [192/300][20/78]	eta 0:02:18 lr 1.829737	time 1.1723 (2.3833)	loss 2.7609 (2.7740)	grad_norm 0.4680 (0.4719)	mem 39782MB
[2023-07-07 14:39:08 RepVGG-A0] (main.py 282): INFO Train: [192/300][30/78]	eta 0:01:40 lr 1.825855	time 1.4887 (2.0856)	loss 2.7839 (2.7766)	grad_norm 0.4811 (0.4643)	mem 39782MB
[2023-07-07 14:39:27 RepVGG-A0] (main.py 282): INFO Train: [192/300][40/78]	eta 0:01:17 lr 1.821977	time 3.4447 (2.0378)	loss 2.6911 (2.7754)	grad_norm 0.4207 (0.4582)	mem 39782MB
[2023-07-07 14:39:42 RepVGG-A0] (main.py 282): INFO Train: [192/300][50/78]	eta 0:00:54 lr 1.818101	time 1.1727 (1.9357)	loss 2.7577 (2.7751)	grad_norm 0.4156 (0.4537)	mem 39782MB
[2023-07-07 14:39:57 RepVGG-A0] (main.py 282): INFO Train: [192/300][60/78]	eta 0:00:33 lr 1.814227	time 1.3091 (1.8678)	loss 2.7515 (2.7734)	grad_norm 0.4297 (0.4495)	mem 39782MB
[2023-07-07 14:40:12 RepVGG-A0] (main.py 282): INFO Train: [192/300][70/78]	eta 0:00:14 lr 1.810356	time 1.2883 (1.8163)	loss 2.7516 (2.7728)	grad_norm 0.4640 (0.4472)	mem 39782MB
[2023-07-07 14:40:23 RepVGG-A0] (main.py 291): INFO EPOCH 192 training takes 0:02:20
[2023-07-07 14:40:46 RepVGG-A0] (main.py 282): INFO Train: [193/300][0/78]	eta 0:29:18 lr 1.807260	time 22.5491 (22.5491)	loss 2.7693 (2.7693)	grad_norm 0.4036 (0.4036)	mem 39782MB
[2023-07-07 14:41:00 RepVGG-A0] (main.py 282): INFO Train: [193/300][10/78]	eta 0:03:48 lr 1.803394	time 1.1711 (3.3662)	loss 2.7541 (2.7394)	grad_norm 0.4517 (0.4502)	mem 39782MB
[2023-07-07 14:41:14 RepVGG-A0] (main.py 282): INFO Train: [193/300][20/78]	eta 0:02:20 lr 1.799530	time 1.1732 (2.4290)	loss 2.8162 (2.7560)	grad_norm 0.4116 (0.4525)	mem 39782MB
[2023-07-07 14:41:29 RepVGG-A0] (main.py 282): INFO Train: [193/300][30/78]	eta 0:01:41 lr 1.795668	time 1.2992 (2.1223)	loss 2.7419 (2.7572)	grad_norm 0.4694 (0.4457)	mem 39782MB
[2023-07-07 14:41:47 RepVGG-A0] (main.py 282): INFO Train: [193/300][40/78]	eta 0:01:17 lr 1.791809	time 3.7090 (2.0486)	loss 2.7553 (2.7606)	grad_norm 0.4968 (0.4518)	mem 39782MB
[2023-07-07 14:42:03 RepVGG-A0] (main.py 282): INFO Train: [193/300][50/78]	eta 0:00:54 lr 1.787952	time 1.2543 (1.9507)	loss 2.7335 (2.7620)	grad_norm 0.4137 (0.4515)	mem 39782MB
[2023-07-07 14:42:18 RepVGG-A0] (main.py 282): INFO Train: [193/300][60/78]	eta 0:00:33 lr 1.784098	time 1.2183 (1.8869)	loss 2.7486 (2.7615)	grad_norm 0.4364 (0.4494)	mem 39782MB
[2023-07-07 14:42:33 RepVGG-A0] (main.py 282): INFO Train: [193/300][70/78]	eta 0:00:14 lr 1.780247	time 1.1727 (1.8206)	loss 2.7714 (2.7628)	grad_norm 0.4380 (0.4486)	mem 39782MB
[2023-07-07 14:42:44 RepVGG-A0] (main.py 291): INFO EPOCH 193 training takes 0:02:20
[2023-07-07 14:43:05 RepVGG-A0] (main.py 282): INFO Train: [194/300][0/78]	eta 0:26:53 lr 1.777167	time 20.6815 (20.6815)	loss 2.7617 (2.7617)	grad_norm 0.4310 (0.4310)	mem 39782MB
[2023-07-07 14:43:20 RepVGG-A0] (main.py 282): INFO Train: [194/300][10/78]	eta 0:03:44 lr 1.773321	time 1.1720 (3.3034)	loss 2.7109 (2.7159)	grad_norm 0.4425 (0.4408)	mem 39782MB
[2023-07-07 14:43:35 RepVGG-A0] (main.py 282): INFO Train: [194/300][20/78]	eta 0:02:22 lr 1.769476	time 1.2362 (2.4518)	loss 2.7078 (2.7137)	grad_norm 0.4360 (0.4388)	mem 39782MB
[2023-07-07 14:43:51 RepVGG-A0] (main.py 282): INFO Train: [194/300][30/78]	eta 0:01:43 lr 1.765635	time 1.4249 (2.1572)	loss 2.7283 (2.7299)	grad_norm 0.4448 (0.4482)	mem 39782MB
[2023-07-07 14:44:10 RepVGG-A0] (main.py 282): INFO Train: [194/300][40/78]	eta 0:01:19 lr 1.761795	time 3.6640 (2.0966)	loss 2.8130 (2.7377)	grad_norm 0.4704 (0.4508)	mem 39782MB
[2023-07-07 14:44:24 RepVGG-A0] (main.py 282): INFO Train: [194/300][50/78]	eta 0:00:54 lr 1.757959	time 1.1920 (1.9594)	loss 2.8154 (2.7448)	grad_norm 0.4269 (0.4521)	mem 39782MB
[2023-07-07 14:44:40 RepVGG-A0] (main.py 282): INFO Train: [194/300][60/78]	eta 0:00:34 lr 1.754125	time 1.3968 (1.9111)	loss 2.7948 (2.7471)	grad_norm 0.4041 (0.4469)	mem 39782MB
[2023-07-07 14:44:55 RepVGG-A0] (main.py 282): INFO Train: [194/300][70/78]	eta 0:00:14 lr 1.750294	time 1.4050 (1.8409)	loss 2.8385 (2.7535)	grad_norm 0.4861 (0.4503)	mem 39782MB
[2023-07-07 14:45:06 RepVGG-A0] (main.py 291): INFO EPOCH 194 training takes 0:02:22
[2023-07-07 14:45:28 RepVGG-A0] (main.py 282): INFO Train: [195/300][0/78]	eta 0:28:36 lr 1.747230	time 22.0083 (22.0083)	loss 2.6836 (2.6836)	grad_norm 0.4089 (0.4089)	mem 39782MB
[2023-07-07 14:45:43 RepVGG-A0] (main.py 282): INFO Train: [195/300][10/78]	eta 0:03:45 lr 1.743404	time 1.1748 (3.3180)	loss 2.8123 (2.7277)	grad_norm 0.4321 (0.4382)	mem 39782MB
[2023-07-07 14:45:57 RepVGG-A0] (main.py 282): INFO Train: [195/300][20/78]	eta 0:02:20 lr 1.739580	time 1.1720 (2.4238)	loss 2.7448 (2.7356)	grad_norm 0.4999 (0.4435)	mem 39782MB
[2023-07-07 14:46:13 RepVGG-A0] (main.py 282): INFO Train: [195/300][30/78]	eta 0:01:42 lr 1.735758	time 1.2764 (2.1452)	loss 2.7270 (2.7346)	grad_norm 0.3932 (0.4407)	mem 39782MB
[2023-07-07 14:46:31 RepVGG-A0] (main.py 282): INFO Train: [195/300][40/78]	eta 0:01:18 lr 1.731940	time 3.5265 (2.0682)	loss 2.7212 (2.7357)	grad_norm 0.4674 (0.4386)	mem 39782MB
[2023-07-07 14:46:46 RepVGG-A0] (main.py 282): INFO Train: [195/300][50/78]	eta 0:00:54 lr 1.728124	time 1.1743 (1.9572)	loss 2.7828 (2.7349)	grad_norm 0.4913 (0.4462)	mem 39782MB
[2023-07-07 14:47:01 RepVGG-A0] (main.py 282): INFO Train: [195/300][60/78]	eta 0:00:33 lr 1.724310	time 1.1787 (1.8827)	loss 2.8357 (2.7387)	grad_norm 0.4378 (0.4458)	mem 39782MB
[2023-07-07 14:47:16 RepVGG-A0] (main.py 282): INFO Train: [195/300][70/78]	eta 0:00:14 lr 1.720499	time 1.1273 (1.8304)	loss 2.7530 (2.7414)	grad_norm 0.4418 (0.4459)	mem 39782MB
[2023-07-07 14:47:28 RepVGG-A0] (main.py 291): INFO EPOCH 195 training takes 0:02:21
[2023-07-07 14:47:49 RepVGG-A0] (main.py 282): INFO Train: [196/300][0/78]	eta 0:27:50 lr 1.717453	time 21.4152 (21.4152)	loss 2.6827 (2.6827)	grad_norm 0.4320 (0.4320)	mem 39782MB
[2023-07-07 14:48:04 RepVGG-A0] (main.py 282): INFO Train: [196/300][10/78]	eta 0:03:41 lr 1.713647	time 1.1723 (3.2598)	loss 2.7322 (2.7005)	grad_norm 0.4881 (0.4478)	mem 39782MB
[2023-07-07 14:48:18 RepVGG-A0] (main.py 282): INFO Train: [196/300][20/78]	eta 0:02:18 lr 1.709843	time 1.1733 (2.3815)	loss 2.7125 (2.7226)	grad_norm 0.4865 (0.4532)	mem 39782MB
[2023-07-07 14:48:34 RepVGG-A0] (main.py 282): INFO Train: [196/300][30/78]	eta 0:01:42 lr 1.706043	time 1.3886 (2.1353)	loss 2.7666 (2.7335)	grad_norm 0.4468 (0.4531)	mem 39782MB
[2023-07-07 14:48:52 RepVGG-A0] (main.py 282): INFO Train: [196/300][40/78]	eta 0:01:17 lr 1.702245	time 3.8573 (2.0487)	loss 2.7335 (2.7403)	grad_norm 0.4458 (0.4542)	mem 39782MB
[2023-07-07 14:49:07 RepVGG-A0] (main.py 282): INFO Train: [196/300][50/78]	eta 0:00:54 lr 1.698450	time 1.1721 (1.9407)	loss 2.7303 (2.7416)	grad_norm 0.4323 (0.4534)	mem 39782MB
[2023-07-07 14:49:22 RepVGG-A0] (main.py 282): INFO Train: [196/300][60/78]	eta 0:00:33 lr 1.694657	time 1.3288 (1.8703)	loss 2.8012 (2.7405)	grad_norm 0.4516 (0.4499)	mem 39782MB
[2023-07-07 14:49:38 RepVGG-A0] (main.py 282): INFO Train: [196/300][70/78]	eta 0:00:14 lr 1.690867	time 1.1709 (1.8343)	loss 2.7715 (2.7400)	grad_norm 0.4302 (0.4485)	mem 39782MB
[2023-07-07 14:49:49 RepVGG-A0] (main.py 291): INFO EPOCH 196 training takes 0:02:21
[2023-07-07 14:50:11 RepVGG-A0] (main.py 282): INFO Train: [197/300][0/78]	eta 0:28:32 lr 1.687838	time 21.9584 (21.9584)	loss 2.7013 (2.7013)	grad_norm 0.4770 (0.4770)	mem 39782MB
[2023-07-07 14:50:26 RepVGG-A0] (main.py 282): INFO Train: [197/300][10/78]	eta 0:03:48 lr 1.684053	time 1.1706 (3.3579)	loss 2.7314 (2.7147)	grad_norm 0.4498 (0.4401)	mem 39782MB
[2023-07-07 14:50:41 RepVGG-A0] (main.py 282): INFO Train: [197/300][20/78]	eta 0:02:23 lr 1.680271	time 1.4754 (2.4752)	loss 2.7086 (2.7179)	grad_norm 0.4524 (0.4523)	mem 39782MB
[2023-07-07 14:50:56 RepVGG-A0] (main.py 282): INFO Train: [197/300][30/78]	eta 0:01:43 lr 1.676491	time 1.2724 (2.1527)	loss 2.8343 (2.7181)	grad_norm 0.4815 (0.4515)	mem 39782MB
[2023-07-07 14:51:14 RepVGG-A0] (main.py 282): INFO Train: [197/300][40/78]	eta 0:01:18 lr 1.672714	time 4.1685 (2.0642)	loss 2.7542 (2.7274)	grad_norm 0.4727 (0.4603)	mem 39782MB
[2023-07-07 14:51:29 RepVGG-A0] (main.py 282): INFO Train: [197/300][50/78]	eta 0:00:54 lr 1.668941	time 1.1733 (1.9587)	loss 2.7514 (2.7292)	grad_norm 0.4550 (0.4557)	mem 39782MB
[2023-07-07 14:51:45 RepVGG-A0] (main.py 282): INFO Train: [197/300][60/78]	eta 0:00:34 lr 1.665169	time 1.3053 (1.8956)	loss 2.7084 (2.7338)	grad_norm 0.4759 (0.4596)	mem 39782MB
[2023-07-07 14:52:00 RepVGG-A0] (main.py 282): INFO Train: [197/300][70/78]	eta 0:00:14 lr 1.661401	time 1.2516 (1.8413)	loss 2.6454 (2.7348)	grad_norm 0.4191 (0.4553)	mem 39782MB
[2023-07-07 14:52:13 RepVGG-A0] (main.py 291): INFO EPOCH 197 training takes 0:02:23
[2023-07-07 14:52:34 RepVGG-A0] (main.py 282): INFO Train: [198/300][0/78]	eta 0:27:33 lr 1.658388	time 21.1998 (21.1998)	loss 2.6949 (2.6949)	grad_norm 0.4569 (0.4569)	mem 39782MB
[2023-07-07 14:52:50 RepVGG-A0] (main.py 282): INFO Train: [198/300][10/78]	eta 0:03:49 lr 1.654625	time 1.1730 (3.3806)	loss 2.7267 (2.7035)	grad_norm 0.4549 (0.4517)	mem 39782MB
[2023-07-07 14:53:04 RepVGG-A0] (main.py 282): INFO Train: [198/300][20/78]	eta 0:02:22 lr 1.650864	time 1.1736 (2.4615)	loss 2.6607 (2.7043)	grad_norm 0.4598 (0.4501)	mem 39782MB
[2023-07-07 14:53:19 RepVGG-A0] (main.py 282): INFO Train: [198/300][30/78]	eta 0:01:43 lr 1.647106	time 1.3537 (2.1528)	loss 2.6997 (2.7046)	grad_norm 0.4697 (0.4514)	mem 39782MB
[2023-07-07 14:53:39 RepVGG-A0] (main.py 282): INFO Train: [198/300][40/78]	eta 0:01:19 lr 1.643351	time 3.2566 (2.0938)	loss 2.7315 (2.7155)	grad_norm 0.4484 (0.4539)	mem 39782MB
[2023-07-07 14:53:53 RepVGG-A0] (main.py 282): INFO Train: [198/300][50/78]	eta 0:00:55 lr 1.639599	time 1.2776 (1.9740)	loss 2.7535 (2.7173)	grad_norm 0.4767 (0.4527)	mem 39782MB
[2023-07-07 14:54:08 RepVGG-A0] (main.py 282): INFO Train: [198/300][60/78]	eta 0:00:33 lr 1.635850	time 1.2151 (1.8831)	loss 2.7899 (2.7235)	grad_norm 0.4818 (0.4556)	mem 39782MB
[2023-07-07 14:54:23 RepVGG-A0] (main.py 282): INFO Train: [198/300][70/78]	eta 0:00:14 lr 1.632103	time 1.2887 (1.8415)	loss 2.7201 (2.7258)	grad_norm 0.4412 (0.4538)	mem 39782MB
[2023-07-07 14:54:35 RepVGG-A0] (main.py 291): INFO EPOCH 198 training takes 0:02:22
[2023-07-07 14:54:55 RepVGG-A0] (main.py 282): INFO Train: [199/300][0/78]	eta 0:25:40 lr 1.629108	time 19.7470 (19.7470)	loss 2.6764 (2.6764)	grad_norm 0.5080 (0.5080)	mem 39782MB
[2023-07-07 14:55:11 RepVGG-A0] (main.py 282): INFO Train: [199/300][10/78]	eta 0:03:39 lr 1.625367	time 1.1927 (3.2343)	loss 2.7382 (2.6818)	grad_norm 0.4871 (0.4536)	mem 39782MB
[2023-07-07 14:55:25 RepVGG-A0] (main.py 282): INFO Train: [199/300][20/78]	eta 0:02:17 lr 1.621628	time 1.2999 (2.3755)	loss 2.6867 (2.7110)	grad_norm 0.4320 (0.4726)	mem 39782MB
[2023-07-07 14:55:41 RepVGG-A0] (main.py 282): INFO Train: [199/300][30/78]	eta 0:01:41 lr 1.617892	time 1.4193 (2.1103)	loss 2.6903 (2.7033)	grad_norm 0.4160 (0.4564)	mem 39782MB
[2023-07-07 14:55:57 RepVGG-A0] (main.py 282): INFO Train: [199/300][40/78]	eta 0:01:15 lr 1.614159	time 2.5373 (1.9806)	loss 2.7389 (2.7035)	grad_norm 0.4930 (0.4578)	mem 39782MB
[2023-07-07 14:56:13 RepVGG-A0] (main.py 282): INFO Train: [199/300][50/78]	eta 0:00:53 lr 1.610429	time 1.3418 (1.9074)	loss 2.7309 (2.7083)	grad_norm 0.4328 (0.4530)	mem 39782MB
[2023-07-07 14:56:28 RepVGG-A0] (main.py 282): INFO Train: [199/300][60/78]	eta 0:00:33 lr 1.606702	time 1.2568 (1.8462)	loss 2.6580 (2.7084)	grad_norm 0.4593 (0.4521)	mem 39782MB
[2023-07-07 14:56:43 RepVGG-A0] (main.py 282): INFO Train: [199/300][70/78]	eta 0:00:14 lr 1.602977	time 1.1714 (1.7953)	loss 2.6718 (2.7114)	grad_norm 0.4478 (0.4521)	mem 39782MB
[2023-07-07 14:56:55 RepVGG-A0] (main.py 291): INFO EPOCH 199 training takes 0:02:19
[2023-07-07 14:57:17 RepVGG-A0] (main.py 282): INFO Train: [200/300][0/78]	eta 0:28:23 lr 1.600000	time 21.8388 (21.8388)	loss 2.6848 (2.6848)	grad_norm 0.4235 (0.4235)	mem 39782MB
[2023-07-07 14:57:32 RepVGG-A0] (main.py 282): INFO Train: [200/300][10/78]	eta 0:03:48 lr 1.596281	time 1.1720 (3.3630)	loss 2.7536 (2.7052)	grad_norm 0.4494 (0.4678)	mem 39782MB
[2023-07-07 14:57:46 RepVGG-A0] (main.py 282): INFO Train: [200/300][20/78]	eta 0:02:21 lr 1.592565	time 1.2061 (2.4386)	loss 2.7303 (2.7004)	grad_norm 0.4626 (0.4614)	mem 39782MB
[2023-07-07 14:58:02 RepVGG-A0] (main.py 282): INFO Train: [200/300][30/78]	eta 0:01:43 lr 1.588851	time 1.3457 (2.1610)	loss 2.7199 (2.7040)	grad_norm 0.4165 (0.4536)	mem 39782MB
[2023-07-07 14:58:19 RepVGG-A0] (main.py 282): INFO Train: [200/300][40/78]	eta 0:01:17 lr 1.585141	time 3.7354 (2.0516)	loss 2.7149 (2.7073)	grad_norm 0.4453 (0.4541)	mem 39782MB
[2023-07-07 14:58:35 RepVGG-A0] (main.py 282): INFO Train: [200/300][50/78]	eta 0:00:54 lr 1.581433	time 1.1946 (1.9619)	loss 2.7438 (2.7132)	grad_norm 0.4563 (0.4536)	mem 39782MB
[2023-07-07 14:58:50 RepVGG-A0] (main.py 282): INFO Train: [200/300][60/78]	eta 0:00:34 lr 1.577728	time 1.1767 (1.8909)	loss 2.7728 (2.7141)	grad_norm 0.4873 (0.4545)	mem 39782MB
[2023-07-07 14:59:06 RepVGG-A0] (main.py 282): INFO Train: [200/300][70/78]	eta 0:00:14 lr 1.574027	time 1.4787 (1.8453)	loss 2.7629 (2.7178)	grad_norm 0.4348 (0.4551)	mem 39782MB
[2023-07-07 14:59:17 RepVGG-A0] (main.py 291): INFO EPOCH 200 training takes 0:02:22
[2023-07-07 14:59:34 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.574 (17.574)	Loss 2.1103 (2.1103)	Acc@1 54.468 (54.468)	Acc@5 78.546 (78.546)	Mem 39782MB
[2023-07-07 14:59:35 RepVGG-A0] (main.py 342): INFO  * Acc@1 54.550 Acc@5 78.434
[2023-07-07 14:59:35 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 200: 54.550%
[2023-07-07 14:59:35 RepVGG-A0] (main.py 172): INFO Max accuracy: 54.55%
[2023-07-07 14:59:58 RepVGG-A0] (main.py 282): INFO Train: [201/300][0/78]	eta 0:29:09 lr 1.571067	time 22.4266 (22.4266)	loss 2.6823 (2.6823)	grad_norm 0.4643 (0.4643)	mem 39782MB
[2023-07-07 15:00:12 RepVGG-A0] (main.py 282): INFO Train: [201/300][10/78]	eta 0:03:48 lr 1.567371	time 1.1723 (3.3634)	loss 2.6875 (2.6833)	grad_norm 0.4720 (0.4569)	mem 39782MB
[2023-07-07 15:00:27 RepVGG-A0] (main.py 282): INFO Train: [201/300][20/78]	eta 0:02:21 lr 1.563678	time 1.2361 (2.4404)	loss 2.6948 (2.6874)	grad_norm 0.4784 (0.4527)	mem 39782MB
[2023-07-07 15:00:42 RepVGG-A0] (main.py 282): INFO Train: [201/300][30/78]	eta 0:01:42 lr 1.559987	time 1.1264 (2.1346)	loss 2.7275 (2.6845)	grad_norm 0.4531 (0.4595)	mem 39782MB
[2023-07-07 15:01:00 RepVGG-A0] (main.py 282): INFO Train: [201/300][40/78]	eta 0:01:18 lr 1.556299	time 4.1780 (2.0615)	loss 2.6938 (2.6871)	grad_norm 0.4294 (0.4565)	mem 39782MB
[2023-07-07 15:01:15 RepVGG-A0] (main.py 282): INFO Train: [201/300][50/78]	eta 0:00:54 lr 1.552615	time 1.1719 (1.9448)	loss 2.7640 (2.6928)	grad_norm 0.4932 (0.4562)	mem 39782MB
[2023-07-07 15:01:30 RepVGG-A0] (main.py 282): INFO Train: [201/300][60/78]	eta 0:00:33 lr 1.548933	time 1.3054 (1.8813)	loss 2.8395 (2.7030)	grad_norm 0.4492 (0.4645)	mem 39782MB
[2023-07-07 15:01:45 RepVGG-A0] (main.py 282): INFO Train: [201/300][70/78]	eta 0:00:14 lr 1.545254	time 1.1709 (1.8249)	loss 2.7355 (2.7061)	grad_norm 0.4466 (0.4634)	mem 39782MB
[2023-07-07 15:01:57 RepVGG-A0] (main.py 291): INFO EPOCH 201 training takes 0:02:21
[2023-07-07 15:02:19 RepVGG-A0] (main.py 282): INFO Train: [202/300][0/78]	eta 0:28:02 lr 1.542314	time 21.5734 (21.5734)	loss 2.6207 (2.6207)	grad_norm 0.4479 (0.4479)	mem 39782MB
[2023-07-07 15:02:33 RepVGG-A0] (main.py 282): INFO Train: [202/300][10/78]	eta 0:03:43 lr 1.538640	time 1.1703 (3.2904)	loss 2.6866 (2.6887)	grad_norm 0.4152 (0.4501)	mem 39782MB
[2023-07-07 15:02:48 RepVGG-A0] (main.py 282): INFO Train: [202/300][20/78]	eta 0:02:22 lr 1.534970	time 1.3009 (2.4539)	loss 2.7140 (2.6898)	grad_norm 0.4604 (0.4558)	mem 39782MB
[2023-07-07 15:03:03 RepVGG-A0] (main.py 282): INFO Train: [202/300][30/78]	eta 0:01:42 lr 1.531303	time 1.1820 (2.1342)	loss 2.6822 (2.6890)	grad_norm 0.4561 (0.4486)	mem 39782MB
[2023-07-07 15:03:22 RepVGG-A0] (main.py 282): INFO Train: [202/300][40/78]	eta 0:01:18 lr 1.527638	time 3.8717 (2.0693)	loss 2.8094 (2.6977)	grad_norm 0.5535 (0.4623)	mem 39782MB
[2023-07-07 15:03:36 RepVGG-A0] (main.py 282): INFO Train: [202/300][50/78]	eta 0:00:54 lr 1.523977	time 1.1763 (1.9481)	loss 2.6874 (2.6997)	grad_norm 0.4480 (0.4585)	mem 39782MB
[2023-07-07 15:03:52 RepVGG-A0] (main.py 282): INFO Train: [202/300][60/78]	eta 0:00:33 lr 1.520319	time 1.1777 (1.8814)	loss 2.7171 (2.7055)	grad_norm 0.4488 (0.4556)	mem 39782MB
[2023-07-07 15:04:06 RepVGG-A0] (main.py 282): INFO Train: [202/300][70/78]	eta 0:00:14 lr 1.516663	time 1.3991 (1.8216)	loss 2.6778 (2.7056)	grad_norm 0.4678 (0.4571)	mem 39782MB
[2023-07-07 15:04:18 RepVGG-A0] (main.py 291): INFO EPOCH 202 training takes 0:02:20
[2023-07-07 15:04:39 RepVGG-A0] (main.py 282): INFO Train: [203/300][0/78]	eta 0:27:41 lr 1.513741	time 21.3061 (21.3061)	loss 2.6568 (2.6568)	grad_norm 0.4610 (0.4610)	mem 39782MB
[2023-07-07 15:04:54 RepVGG-A0] (main.py 282): INFO Train: [203/300][10/78]	eta 0:03:42 lr 1.510092	time 1.1718 (3.2775)	loss 2.6337 (2.6588)	grad_norm 0.4398 (0.4600)	mem 39782MB
[2023-07-07 15:05:09 RepVGG-A0] (main.py 282): INFO Train: [203/300][20/78]	eta 0:02:22 lr 1.506445	time 1.3569 (2.4543)	loss 2.6550 (2.6560)	grad_norm 0.4564 (0.4558)	mem 39782MB
[2023-07-07 15:05:24 RepVGG-A0] (main.py 282): INFO Train: [203/300][30/78]	eta 0:01:42 lr 1.502801	time 1.1848 (2.1348)	loss 2.6462 (2.6631)	grad_norm 0.4566 (0.4520)	mem 39782MB
[2023-07-07 15:05:41 RepVGG-A0] (main.py 282): INFO Train: [203/300][40/78]	eta 0:01:17 lr 1.499161	time 2.1000 (2.0302)	loss 2.7107 (2.6707)	grad_norm 0.4678 (0.4598)	mem 39782MB
[2023-07-07 15:05:56 RepVGG-A0] (main.py 282): INFO Train: [203/300][50/78]	eta 0:00:54 lr 1.495523	time 1.1714 (1.9343)	loss 2.7533 (2.6783)	grad_norm 0.4720 (0.4575)	mem 39782MB
[2023-07-07 15:06:11 RepVGG-A0] (main.py 282): INFO Train: [203/300][60/78]	eta 0:00:33 lr 1.491889	time 1.3930 (1.8628)	loss 2.6801 (2.6794)	grad_norm 0.4767 (0.4594)	mem 39782MB
[2023-07-07 15:06:26 RepVGG-A0] (main.py 282): INFO Train: [203/300][70/78]	eta 0:00:14 lr 1.488257	time 1.1262 (1.8081)	loss 2.7026 (2.6852)	grad_norm 0.4470 (0.4568)	mem 39782MB
[2023-07-07 15:06:38 RepVGG-A0] (main.py 291): INFO EPOCH 203 training takes 0:02:20
[2023-07-07 15:06:58 RepVGG-A0] (main.py 282): INFO Train: [204/300][0/78]	eta 0:26:10 lr 1.485354	time 20.1408 (20.1408)	loss 2.6158 (2.6158)	grad_norm 0.4325 (0.4325)	mem 39782MB
[2023-07-07 15:07:13 RepVGG-A0] (main.py 282): INFO Train: [204/300][10/78]	eta 0:03:37 lr 1.481728	time 1.1723 (3.1976)	loss 2.5816 (2.6781)	grad_norm 0.4687 (0.4776)	mem 39782MB
[2023-07-07 15:07:29 RepVGG-A0] (main.py 282): INFO Train: [204/300][20/78]	eta 0:02:20 lr 1.478106	time 1.1758 (2.4145)	loss 2.7467 (2.6734)	grad_norm 0.4837 (0.4665)	mem 39782MB
[2023-07-07 15:07:45 RepVGG-A0] (main.py 282): INFO Train: [204/300][30/78]	eta 0:01:43 lr 1.474486	time 1.7319 (2.1541)	loss 2.6881 (2.6817)	grad_norm 0.4788 (0.4724)	mem 39782MB
[2023-07-07 15:08:02 RepVGG-A0] (main.py 282): INFO Train: [204/300][40/78]	eta 0:01:18 lr 1.470869	time 2.7567 (2.0560)	loss 2.7215 (2.6812)	grad_norm 0.4729 (0.4648)	mem 39782MB
[2023-07-07 15:08:17 RepVGG-A0] (main.py 282): INFO Train: [204/300][50/78]	eta 0:00:54 lr 1.467256	time 1.1736 (1.9412)	loss 2.7958 (2.6913)	grad_norm 0.4387 (0.4709)	mem 39782MB
[2023-07-07 15:08:33 RepVGG-A0] (main.py 282): INFO Train: [204/300][60/78]	eta 0:00:33 lr 1.463646	time 1.2599 (1.8779)	loss 2.6640 (2.6917)	grad_norm 0.4452 (0.4674)	mem 39782MB
[2023-07-07 15:08:47 RepVGG-A0] (main.py 282): INFO Train: [204/300][70/78]	eta 0:00:14 lr 1.460039	time 1.1922 (1.8151)	loss 2.7576 (2.6953)	grad_norm 0.5104 (0.4689)	mem 39782MB
[2023-07-07 15:08:59 RepVGG-A0] (main.py 291): INFO EPOCH 204 training takes 0:02:20
[2023-07-07 15:09:18 RepVGG-A0] (main.py 282): INFO Train: [205/300][0/78]	eta 0:25:15 lr 1.457155	time 19.4245 (19.4245)	loss 2.6493 (2.6493)	grad_norm 0.4268 (0.4268)	mem 39782MB
[2023-07-07 15:09:35 RepVGG-A0] (main.py 282): INFO Train: [205/300][10/78]	eta 0:03:41 lr 1.453554	time 1.1723 (3.2594)	loss 2.6720 (2.6384)	grad_norm 0.5214 (0.4603)	mem 39782MB
[2023-07-07 15:09:51 RepVGG-A0] (main.py 282): INFO Train: [205/300][20/78]	eta 0:02:23 lr 1.449955	time 1.2847 (2.4772)	loss 2.6786 (2.6489)	grad_norm 0.4474 (0.4633)	mem 39782MB
[2023-07-07 15:10:06 RepVGG-A0] (main.py 282): INFO Train: [205/300][30/78]	eta 0:01:43 lr 1.446360	time 1.2849 (2.1599)	loss 2.5875 (2.6524)	grad_norm 0.4202 (0.4566)	mem 39782MB
[2023-07-07 15:10:23 RepVGG-A0] (main.py 282): INFO Train: [205/300][40/78]	eta 0:01:17 lr 1.442768	time 2.4381 (2.0488)	loss 2.6934 (2.6616)	grad_norm 0.4638 (0.4551)	mem 39782MB
[2023-07-07 15:10:38 RepVGG-A0] (main.py 282): INFO Train: [205/300][50/78]	eta 0:00:54 lr 1.439179	time 1.1734 (1.9353)	loss 2.7081 (2.6707)	grad_norm 0.4931 (0.4569)	mem 39782MB
[2023-07-07 15:10:53 RepVGG-A0] (main.py 282): INFO Train: [205/300][60/78]	eta 0:00:33 lr 1.435593	time 1.1900 (1.8633)	loss 2.6547 (2.6742)	grad_norm 0.4572 (0.4584)	mem 39782MB
[2023-07-07 15:11:10 RepVGG-A0] (main.py 282): INFO Train: [205/300][70/78]	eta 0:00:14 lr 1.432011	time 1.4702 (1.8381)	loss 2.7466 (2.6780)	grad_norm 0.4536 (0.4589)	mem 39782MB
[2023-07-07 15:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 205 training takes 0:02:21
[2023-07-07 15:11:42 RepVGG-A0] (main.py 282): INFO Train: [206/300][0/78]	eta 0:28:28 lr 1.429147	time 21.8984 (21.8984)	loss 2.6432 (2.6432)	grad_norm 0.4490 (0.4490)	mem 39782MB
[2023-07-07 15:11:58 RepVGG-A0] (main.py 282): INFO Train: [206/300][10/78]	eta 0:03:50 lr 1.425570	time 1.2046 (3.3921)	loss 2.6383 (2.6603)	grad_norm 0.5078 (0.4835)	mem 39782MB
[2023-07-07 15:12:13 RepVGG-A0] (main.py 282): INFO Train: [206/300][20/78]	eta 0:02:24 lr 1.421997	time 1.2897 (2.4858)	loss 2.6778 (2.6682)	grad_norm 0.4207 (0.4753)	mem 39782MB
[2023-07-07 15:12:28 RepVGG-A0] (main.py 282): INFO Train: [206/300][30/78]	eta 0:01:44 lr 1.418426	time 1.2421 (2.1753)	loss 2.7144 (2.6717)	grad_norm 0.4883 (0.4718)	mem 39782MB
[2023-07-07 15:12:48 RepVGG-A0] (main.py 282): INFO Train: [206/300][40/78]	eta 0:01:20 lr 1.414859	time 2.8364 (2.1246)	loss 2.6463 (2.6704)	grad_norm 0.4709 (0.4731)	mem 39782MB
[2023-07-07 15:13:03 RepVGG-A0] (main.py 282): INFO Train: [206/300][50/78]	eta 0:00:56 lr 1.411295	time 1.1702 (2.0036)	loss 2.6382 (2.6710)	grad_norm 0.4930 (0.4689)	mem 39782MB
[2023-07-07 15:13:19 RepVGG-A0] (main.py 282): INFO Train: [206/300][60/78]	eta 0:00:34 lr 1.407734	time 1.6338 (1.9377)	loss 2.6985 (2.6709)	grad_norm 0.4478 (0.4682)	mem 39782MB
[2023-07-07 15:13:34 RepVGG-A0] (main.py 282): INFO Train: [206/300][70/78]	eta 0:00:14 lr 1.404177	time 1.5701 (1.8748)	loss 2.7264 (2.6748)	grad_norm 0.5127 (0.4701)	mem 39782MB
[2023-07-07 15:13:45 RepVGG-A0] (main.py 291): INFO EPOCH 206 training takes 0:02:24
[2023-07-07 15:14:07 RepVGG-A0] (main.py 282): INFO Train: [207/300][0/78]	eta 0:28:37 lr 1.401333	time 22.0234 (22.0234)	loss 2.6353 (2.6353)	grad_norm 0.4561 (0.4561)	mem 39782MB
[2023-07-07 15:14:22 RepVGG-A0] (main.py 282): INFO Train: [207/300][10/78]	eta 0:03:48 lr 1.397782	time 1.1964 (3.3567)	loss 2.6204 (2.6385)	grad_norm 0.4834 (0.4459)	mem 39782MB
[2023-07-07 15:14:36 RepVGG-A0] (main.py 282): INFO Train: [207/300][20/78]	eta 0:02:20 lr 1.394233	time 1.1749 (2.4309)	loss 2.6696 (2.6446)	grad_norm 0.4360 (0.4585)	mem 39782MB
[2023-07-07 15:14:51 RepVGG-A0] (main.py 282): INFO Train: [207/300][30/78]	eta 0:01:41 lr 1.390688	time 1.3348 (2.1245)	loss 2.6231 (2.6486)	grad_norm 0.4687 (0.4598)	mem 39782MB
[2023-07-07 15:15:10 RepVGG-A0] (main.py 282): INFO Train: [207/300][40/78]	eta 0:01:18 lr 1.387146	time 3.1920 (2.0607)	loss 2.6016 (2.6514)	grad_norm 0.4621 (0.4605)	mem 39782MB
[2023-07-07 15:15:25 RepVGG-A0] (main.py 282): INFO Train: [207/300][50/78]	eta 0:00:54 lr 1.383607	time 1.1714 (1.9552)	loss 2.7208 (2.6561)	grad_norm 0.4694 (0.4593)	mem 39782MB
[2023-07-07 15:15:39 RepVGG-A0] (main.py 282): INFO Train: [207/300][60/78]	eta 0:00:33 lr 1.380072	time 1.1775 (1.8730)	loss 2.6950 (2.6573)	grad_norm 0.4483 (0.4621)	mem 39782MB
[2023-07-07 15:15:55 RepVGG-A0] (main.py 282): INFO Train: [207/300][70/78]	eta 0:00:14 lr 1.376540	time 1.4365 (1.8258)	loss 2.6754 (2.6606)	grad_norm 0.5273 (0.4610)	mem 39782MB
[2023-07-07 15:16:06 RepVGG-A0] (main.py 291): INFO EPOCH 207 training takes 0:02:20
[2023-07-07 15:16:27 RepVGG-A0] (main.py 282): INFO Train: [208/300][0/78]	eta 0:27:29 lr 1.373717	time 21.1490 (21.1490)	loss 2.6707 (2.6707)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:16:42 RepVGG-A0] (main.py 282): INFO Train: [208/300][10/78]	eta 0:03:40 lr 1.370190	time 1.1726 (3.2418)	loss 2.6238 (2.6365)	grad_norm 0.4304 (0.4576)	mem 39782MB
[2023-07-07 15:16:56 RepVGG-A0] (main.py 282): INFO Train: [208/300][20/78]	eta 0:02:17 lr 1.366668	time 1.1720 (2.3777)	loss 2.7244 (2.6519)	grad_norm 0.5722 (0.4871)	mem 39782MB
[2023-07-07 15:17:10 RepVGG-A0] (main.py 282): INFO Train: [208/300][30/78]	eta 0:01:39 lr 1.363148	time 1.2507 (2.0718)	loss 2.6820 (2.6599)	grad_norm 0.4372 (0.4908)	mem 39782MB
[2023-07-07 15:17:30 RepVGG-A0] (main.py 282): INFO Train: [208/300][40/78]	eta 0:01:17 lr 1.359632	time 5.2668 (2.0449)	loss 2.6572 (2.6593)	grad_norm 0.4529 (0.4803)	mem 39782MB
[2023-07-07 15:17:45 RepVGG-A0] (main.py 282): INFO Train: [208/300][50/78]	eta 0:00:54 lr 1.356119	time 1.1741 (1.9395)	loss 2.6528 (2.6560)	grad_norm 0.4589 (0.4742)	mem 39782MB
[2023-07-07 15:18:00 RepVGG-A0] (main.py 282): INFO Train: [208/300][60/78]	eta 0:00:33 lr 1.352609	time 1.1773 (1.8713)	loss 2.6808 (2.6605)	grad_norm 0.5027 (0.4740)	mem 39782MB
[2023-07-07 15:18:15 RepVGG-A0] (main.py 282): INFO Train: [208/300][70/78]	eta 0:00:14 lr 1.349103	time 1.3049 (1.8158)	loss 2.7030 (2.6636)	grad_norm 0.4364 (0.4734)	mem 39782MB
[2023-07-07 15:18:27 RepVGG-A0] (main.py 291): INFO EPOCH 208 training takes 0:02:20
[2023-07-07 15:18:48 RepVGG-A0] (main.py 282): INFO Train: [209/300][0/78]	eta 0:27:52 lr 1.346300	time 21.4470 (21.4470)	loss 2.6134 (2.6134)	grad_norm 0.4722 (0.4722)	mem 39782MB
[2023-07-07 15:19:04 RepVGG-A0] (main.py 282): INFO Train: [209/300][10/78]	eta 0:03:49 lr 1.342800	time 1.1723 (3.3801)	loss 2.6479 (2.6215)	grad_norm 0.4505 (0.4658)	mem 39782MB
[2023-07-07 15:19:19 RepVGG-A0] (main.py 282): INFO Train: [209/300][20/78]	eta 0:02:24 lr 1.339303	time 1.4119 (2.4842)	loss 2.6449 (2.6333)	grad_norm 0.4839 (0.4602)	mem 39782MB
[2023-07-07 15:19:35 RepVGG-A0] (main.py 282): INFO Train: [209/300][30/78]	eta 0:01:44 lr 1.335809	time 1.9142 (2.1870)	loss 2.6083 (2.6355)	grad_norm 0.4522 (0.4636)	mem 39782MB
[2023-07-07 15:19:53 RepVGG-A0] (main.py 282): INFO Train: [209/300][40/78]	eta 0:01:19 lr 1.332319	time 4.2611 (2.0918)	loss 2.6688 (2.6448)	grad_norm 0.4650 (0.4680)	mem 39782MB
[2023-07-07 15:20:07 RepVGG-A0] (main.py 282): INFO Train: [209/300][50/78]	eta 0:00:54 lr 1.328832	time 1.1756 (1.9642)	loss 2.6677 (2.6458)	grad_norm 0.4505 (0.4659)	mem 39782MB
[2023-07-07 15:20:23 RepVGG-A0] (main.py 282): INFO Train: [209/300][60/78]	eta 0:00:34 lr 1.325349	time 1.2874 (1.8960)	loss 2.7231 (2.6523)	grad_norm 0.4856 (0.4687)	mem 39782MB
[2023-07-07 15:20:38 RepVGG-A0] (main.py 282): INFO Train: [209/300][70/78]	eta 0:00:14 lr 1.321869	time 1.2965 (1.8425)	loss 2.6179 (2.6555)	grad_norm 0.4369 (0.4675)	mem 39782MB
[2023-07-07 15:20:49 RepVGG-A0] (main.py 291): INFO EPOCH 209 training takes 0:02:22
[2023-07-07 15:21:10 RepVGG-A0] (main.py 282): INFO Train: [210/300][0/78]	eta 0:27:14 lr 1.319087	time 20.9498 (20.9498)	loss 2.5937 (2.5937)	grad_norm 0.4836 (0.4836)	mem 39782MB
[2023-07-07 15:21:24 RepVGG-A0] (main.py 282): INFO Train: [210/300][10/78]	eta 0:03:34 lr 1.315613	time 1.1722 (3.1603)	loss 2.6390 (2.6245)	grad_norm 0.4594 (0.4600)	mem 39782MB
[2023-07-07 15:21:38 RepVGG-A0] (main.py 282): INFO Train: [210/300][20/78]	eta 0:02:15 lr 1.312143	time 1.1729 (2.3392)	loss 2.6164 (2.6327)	grad_norm 0.4737 (0.4724)	mem 39782MB
[2023-07-07 15:21:54 RepVGG-A0] (main.py 282): INFO Train: [210/300][30/78]	eta 0:01:39 lr 1.308675	time 1.3710 (2.0761)	loss 2.6282 (2.6385)	grad_norm 0.4746 (0.4716)	mem 39782MB
[2023-07-07 15:22:11 RepVGG-A0] (main.py 282): INFO Train: [210/300][40/78]	eta 0:01:15 lr 1.305212	time 3.0057 (1.9891)	loss 2.6679 (2.6408)	grad_norm 0.4621 (0.4693)	mem 39782MB
[2023-07-07 15:22:27 RepVGG-A0] (main.py 282): INFO Train: [210/300][50/78]	eta 0:00:53 lr 1.301751	time 1.2006 (1.9089)	loss 2.6884 (2.6397)	grad_norm 0.4663 (0.4668)	mem 39782MB
[2023-07-07 15:22:42 RepVGG-A0] (main.py 282): INFO Train: [210/300][60/78]	eta 0:00:33 lr 1.298294	time 1.1748 (1.8508)	loss 2.6614 (2.6445)	grad_norm 0.4484 (0.4675)	mem 39782MB
[2023-07-07 15:22:57 RepVGG-A0] (main.py 282): INFO Train: [210/300][70/78]	eta 0:00:14 lr 1.294841	time 1.1803 (1.8020)	loss 2.7426 (2.6482)	grad_norm 0.5262 (0.4707)	mem 39782MB
[2023-07-07 15:23:10 RepVGG-A0] (main.py 291): INFO EPOCH 210 training takes 0:02:20
[2023-07-07 15:23:31 RepVGG-A0] (main.py 282): INFO Train: [211/300][0/78]	eta 0:27:41 lr 1.292080	time 21.3055 (21.3055)	loss 2.6687 (2.6687)	grad_norm 0.4356 (0.4356)	mem 39782MB
[2023-07-07 15:23:46 RepVGG-A0] (main.py 282): INFO Train: [211/300][10/78]	eta 0:03:41 lr 1.288633	time 1.1746 (3.2595)	loss 2.5722 (2.6211)	grad_norm 0.4630 (0.4541)	mem 39782MB
[2023-07-07 15:24:00 RepVGG-A0] (main.py 282): INFO Train: [211/300][20/78]	eta 0:02:18 lr 1.285189	time 1.1729 (2.3923)	loss 2.5539 (2.6262)	grad_norm 0.4485 (0.4595)	mem 39782MB
[2023-07-07 15:24:15 RepVGG-A0] (main.py 282): INFO Train: [211/300][30/78]	eta 0:01:41 lr 1.281749	time 1.1267 (2.1100)	loss 2.6219 (2.6316)	grad_norm 0.4985 (0.4621)	mem 39782MB
[2023-07-07 15:24:33 RepVGG-A0] (main.py 282): INFO Train: [211/300][40/78]	eta 0:01:17 lr 1.278312	time 4.2104 (2.0389)	loss 2.6262 (2.6351)	grad_norm 0.4584 (0.4635)	mem 39782MB
[2023-07-07 15:24:48 RepVGG-A0] (main.py 282): INFO Train: [211/300][50/78]	eta 0:00:53 lr 1.274878	time 1.1907 (1.9246)	loss 2.7164 (2.6399)	grad_norm 0.5000 (0.4648)	mem 39782MB
[2023-07-07 15:25:03 RepVGG-A0] (main.py 282): INFO Train: [211/300][60/78]	eta 0:00:33 lr 1.271448	time 1.1770 (1.8605)	loss 2.6149 (2.6419)	grad_norm 0.4516 (0.4671)	mem 39782MB
[2023-07-07 15:25:18 RepVGG-A0] (main.py 282): INFO Train: [211/300][70/78]	eta 0:00:14 lr 1.268022	time 1.2139 (1.8065)	loss 2.6976 (2.6452)	grad_norm 0.5160 (0.4688)	mem 39782MB
[2023-07-07 15:25:30 RepVGG-A0] (main.py 291): INFO EPOCH 211 training takes 0:02:20
[2023-07-07 15:25:52 RepVGG-A0] (main.py 282): INFO Train: [212/300][0/78]	eta 0:28:19 lr 1.265283	time 21.7823 (21.7823)	loss 2.5617 (2.5617)	grad_norm 0.4468 (0.4468)	mem 39782MB
[2023-07-07 15:26:06 RepVGG-A0] (main.py 282): INFO Train: [212/300][10/78]	eta 0:03:41 lr 1.261863	time 1.1725 (3.2514)	loss 2.6617 (2.6027)	grad_norm 0.4791 (0.4590)	mem 39782MB
[2023-07-07 15:26:21 RepVGG-A0] (main.py 282): INFO Train: [212/300][20/78]	eta 0:02:20 lr 1.258446	time 1.4192 (2.4231)	loss 2.5748 (2.6165)	grad_norm 0.4377 (0.4671)	mem 39782MB
[2023-07-07 15:26:36 RepVGG-A0] (main.py 282): INFO Train: [212/300][30/78]	eta 0:01:42 lr 1.255032	time 1.5670 (2.1263)	loss 2.6050 (2.6224)	grad_norm 0.4815 (0.4687)	mem 39782MB
[2023-07-07 15:26:54 RepVGG-A0] (main.py 282): INFO Train: [212/300][40/78]	eta 0:01:17 lr 1.251623	time 4.0882 (2.0517)	loss 2.6225 (2.6253)	grad_norm 0.4764 (0.4668)	mem 39782MB
[2023-07-07 15:27:09 RepVGG-A0] (main.py 282): INFO Train: [212/300][50/78]	eta 0:00:54 lr 1.248216	time 1.1714 (1.9372)	loss 2.6118 (2.6320)	grad_norm 0.4431 (0.4696)	mem 39782MB
[2023-07-07 15:27:25 RepVGG-A0] (main.py 282): INFO Train: [212/300][60/78]	eta 0:00:33 lr 1.244814	time 1.2923 (1.8801)	loss 2.6725 (2.6335)	grad_norm 0.4883 (0.4686)	mem 39782MB
[2023-07-07 15:27:39 RepVGG-A0] (main.py 282): INFO Train: [212/300][70/78]	eta 0:00:14 lr 1.241414	time 1.1745 (1.8087)	loss 2.6573 (2.6355)	grad_norm 0.4819 (0.4687)	mem 39782MB
[2023-07-07 15:27:52 RepVGG-A0] (main.py 291): INFO EPOCH 212 training takes 0:02:21
[2023-07-07 15:28:12 RepVGG-A0] (main.py 282): INFO Train: [213/300][0/78]	eta 0:26:43 lr 1.238697	time 20.5626 (20.5626)	loss 2.6213 (2.6213)	grad_norm 0.4698 (0.4698)	mem 39782MB
[2023-07-07 15:28:27 RepVGG-A0] (main.py 282): INFO Train: [213/300][10/78]	eta 0:03:36 lr 1.235305	time 1.1702 (3.1851)	loss 2.6392 (2.5819)	grad_norm 0.4888 (0.4668)	mem 39782MB
[2023-07-07 15:28:42 RepVGG-A0] (main.py 282): INFO Train: [213/300][20/78]	eta 0:02:17 lr 1.231915	time 1.1730 (2.3785)	loss 2.6291 (2.5951)	grad_norm 0.4763 (0.4782)	mem 39782MB
[2023-07-07 15:28:56 RepVGG-A0] (main.py 282): INFO Train: [213/300][30/78]	eta 0:01:40 lr 1.228529	time 1.3012 (2.0944)	loss 2.6147 (2.6033)	grad_norm 0.4601 (0.4699)	mem 39782MB
[2023-07-07 15:29:15 RepVGG-A0] (main.py 282): INFO Train: [213/300][40/78]	eta 0:01:16 lr 1.225147	time 4.1879 (2.0251)	loss 2.6669 (2.6172)	grad_norm 0.5136 (0.4774)	mem 39782MB
[2023-07-07 15:29:30 RepVGG-A0] (main.py 282): INFO Train: [213/300][50/78]	eta 0:00:53 lr 1.221768	time 1.1937 (1.9254)	loss 2.5967 (2.6199)	grad_norm 0.4761 (0.4741)	mem 39782MB
[2023-07-07 15:29:45 RepVGG-A0] (main.py 282): INFO Train: [213/300][60/78]	eta 0:00:33 lr 1.218393	time 1.1810 (1.8636)	loss 2.6196 (2.6229)	grad_norm 0.5029 (0.4761)	mem 39782MB
[2023-07-07 15:30:01 RepVGG-A0] (main.py 282): INFO Train: [213/300][70/78]	eta 0:00:14 lr 1.215022	time 1.4359 (1.8267)	loss 2.6075 (2.6274)	grad_norm 0.4545 (0.4756)	mem 39782MB
[2023-07-07 15:30:13 RepVGG-A0] (main.py 291): INFO EPOCH 213 training takes 0:02:21
[2023-07-07 15:30:33 RepVGG-A0] (main.py 282): INFO Train: [214/300][0/78]	eta 0:25:55 lr 1.212327	time 19.9398 (19.9398)	loss 2.6160 (2.6160)	grad_norm 0.4605 (0.4605)	mem 39782MB
[2023-07-07 15:30:49 RepVGG-A0] (main.py 282): INFO Train: [214/300][10/78]	eta 0:03:41 lr 1.208962	time 1.1707 (3.2527)	loss 2.5691 (2.5845)	grad_norm 0.4649 (0.4605)	mem 39782MB
[2023-07-07 15:31:05 RepVGG-A0] (main.py 282): INFO Train: [214/300][20/78]	eta 0:02:24 lr 1.205600	time 1.5009 (2.4961)	loss 2.6874 (2.5984)	grad_norm 0.5483 (0.4681)	mem 39782MB
[2023-07-07 15:31:19 RepVGG-A0] (main.py 282): INFO Train: [214/300][30/78]	eta 0:01:42 lr 1.202243	time 1.1280 (2.1419)	loss 2.6167 (2.6066)	grad_norm 0.4734 (0.4799)	mem 39782MB
[2023-07-07 15:31:37 RepVGG-A0] (main.py 282): INFO Train: [214/300][40/78]	eta 0:01:18 lr 1.198888	time 3.6350 (2.0536)	loss 2.6095 (2.6052)	grad_norm 0.4667 (0.4781)	mem 39782MB
[2023-07-07 15:31:52 RepVGG-A0] (main.py 282): INFO Train: [214/300][50/78]	eta 0:00:54 lr 1.195538	time 1.1947 (1.9413)	loss 2.6430 (2.6119)	grad_norm 0.4861 (0.4744)	mem 39782MB
[2023-07-07 15:32:07 RepVGG-A0] (main.py 282): INFO Train: [214/300][60/78]	eta 0:00:33 lr 1.192190	time 1.1818 (1.8697)	loss 2.6882 (2.6189)	grad_norm 0.4660 (0.4822)	mem 39782MB
[2023-07-07 15:32:23 RepVGG-A0] (main.py 282): INFO Train: [214/300][70/78]	eta 0:00:14 lr 1.188847	time 1.3156 (1.8327)	loss 2.6462 (2.6214)	grad_norm 0.4832 (0.4792)	mem 39782MB
[2023-07-07 15:32:33 RepVGG-A0] (main.py 291): INFO EPOCH 214 training takes 0:02:20
[2023-07-07 15:32:55 RepVGG-A0] (main.py 282): INFO Train: [215/300][0/78]	eta 0:27:45 lr 1.186175	time 21.3575 (21.3575)	loss 2.6296 (2.6296)	grad_norm 0.4838 (0.4838)	mem 39782MB
[2023-07-07 15:33:09 RepVGG-A0] (main.py 282): INFO Train: [215/300][10/78]	eta 0:03:40 lr 1.182838	time 1.1734 (3.2489)	loss 2.6277 (2.6057)	grad_norm 0.4760 (0.4567)	mem 39782MB
[2023-07-07 15:33:25 RepVGG-A0] (main.py 282): INFO Train: [215/300][20/78]	eta 0:02:23 lr 1.179504	time 1.1738 (2.4687)	loss 2.5933 (2.5959)	grad_norm 0.5156 (0.4638)	mem 39782MB
[2023-07-07 15:33:42 RepVGG-A0] (main.py 282): INFO Train: [215/300][30/78]	eta 0:01:45 lr 1.176175	time 1.5048 (2.1966)	loss 2.5997 (2.6068)	grad_norm 0.4806 (0.4775)	mem 39782MB
[2023-07-07 15:33:59 RepVGG-A0] (main.py 282): INFO Train: [215/300][40/78]	eta 0:01:19 lr 1.172849	time 3.6816 (2.0839)	loss 2.6088 (2.6096)	grad_norm 0.4640 (0.4733)	mem 39782MB
[2023-07-07 15:34:14 RepVGG-A0] (main.py 282): INFO Train: [215/300][50/78]	eta 0:00:55 lr 1.169526	time 1.1727 (1.9795)	loss 2.6949 (2.6166)	grad_norm 0.5113 (0.4762)	mem 39782MB
[2023-07-07 15:34:29 RepVGG-A0] (main.py 282): INFO Train: [215/300][60/78]	eta 0:00:34 lr 1.166208	time 1.1773 (1.8926)	loss 2.6048 (2.6190)	grad_norm 0.4671 (0.4752)	mem 39782MB
[2023-07-07 15:34:44 RepVGG-A0] (main.py 282): INFO Train: [215/300][70/78]	eta 0:00:14 lr 1.162893	time 1.1777 (1.8393)	loss 2.5846 (2.6228)	grad_norm 0.4564 (0.4789)	mem 39782MB
[2023-07-07 15:34:55 RepVGG-A0] (main.py 291): INFO EPOCH 215 training takes 0:02:22
[2023-07-07 15:35:17 RepVGG-A0] (main.py 282): INFO Train: [216/300][0/78]	eta 0:27:25 lr 1.160243	time 21.0994 (21.0994)	loss 2.5961 (2.5961)	grad_norm 0.5179 (0.5179)	mem 39782MB
[2023-07-07 15:35:33 RepVGG-A0] (main.py 282): INFO Train: [216/300][10/78]	eta 0:03:51 lr 1.156935	time 1.1722 (3.4038)	loss 2.5995 (2.5856)	grad_norm 0.4784 (0.4752)	mem 39782MB
[2023-07-07 15:35:47 RepVGG-A0] (main.py 282): INFO Train: [216/300][20/78]	eta 0:02:22 lr 1.153630	time 1.1792 (2.4600)	loss 2.6038 (2.5905)	grad_norm 0.4568 (0.4693)	mem 39782MB
[2023-07-07 15:36:03 RepVGG-A0] (main.py 282): INFO Train: [216/300][30/78]	eta 0:01:44 lr 1.150329	time 1.2671 (2.1745)	loss 2.5943 (2.5910)	grad_norm 0.5016 (0.4759)	mem 39782MB
[2023-07-07 15:36:21 RepVGG-A0] (main.py 282): INFO Train: [216/300][40/78]	eta 0:01:18 lr 1.147032	time 4.3345 (2.0744)	loss 2.6689 (2.6030)	grad_norm 0.4737 (0.4743)	mem 39782MB
[2023-07-07 15:36:36 RepVGG-A0] (main.py 282): INFO Train: [216/300][50/78]	eta 0:00:55 lr 1.143738	time 1.2809 (1.9682)	loss 2.6791 (2.6109)	grad_norm 0.5457 (0.4820)	mem 39782MB
[2023-07-07 15:36:51 RepVGG-A0] (main.py 282): INFO Train: [216/300][60/78]	eta 0:00:34 lr 1.140448	time 1.2647 (1.8929)	loss 2.6252 (2.6150)	grad_norm 0.4538 (0.4853)	mem 39782MB
[2023-07-07 15:37:06 RepVGG-A0] (main.py 282): INFO Train: [216/300][70/78]	eta 0:00:14 lr 1.137162	time 1.4524 (1.8436)	loss 2.6577 (2.6168)	grad_norm 0.4704 (0.4836)	mem 39782MB
[2023-07-07 15:37:17 RepVGG-A0] (main.py 291): INFO EPOCH 216 training takes 0:02:21
[2023-07-07 15:37:38 RepVGG-A0] (main.py 282): INFO Train: [217/300][0/78]	eta 0:28:19 lr 1.134535	time 21.7881 (21.7881)	loss 2.4876 (2.4876)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:37:52 RepVGG-A0] (main.py 282): INFO Train: [217/300][10/78]	eta 0:03:40 lr 1.131256	time 1.1708 (3.2405)	loss 2.6132 (2.5691)	grad_norm 0.4741 (0.4763)	mem 39782MB
[2023-07-07 15:38:07 RepVGG-A0] (main.py 282): INFO Train: [217/300][20/78]	eta 0:02:19 lr 1.127980	time 1.1749 (2.4061)	loss 2.5178 (2.5759)	grad_norm 0.4497 (0.4682)	mem 39782MB
[2023-07-07 15:38:22 RepVGG-A0] (main.py 282): INFO Train: [217/300][30/78]	eta 0:01:41 lr 1.124708	time 1.1928 (2.1118)	loss 2.6211 (2.5895)	grad_norm 0.4814 (0.4721)	mem 39782MB
[2023-07-07 15:38:40 RepVGG-A0] (main.py 282): INFO Train: [217/300][40/78]	eta 0:01:17 lr 1.121440	time 3.9689 (2.0402)	loss 2.6399 (2.5893)	grad_norm 0.4837 (0.4768)	mem 39782MB
[2023-07-07 15:38:55 RepVGG-A0] (main.py 282): INFO Train: [217/300][50/78]	eta 0:00:54 lr 1.118175	time 1.1734 (1.9327)	loss 2.5749 (2.5838)	grad_norm 0.4781 (0.4750)	mem 39782MB
[2023-07-07 15:39:10 RepVGG-A0] (main.py 282): INFO Train: [217/300][60/78]	eta 0:00:33 lr 1.114914	time 1.3727 (1.8593)	loss 2.5799 (2.5870)	grad_norm 0.5024 (0.4758)	mem 39782MB
[2023-07-07 15:39:26 RepVGG-A0] (main.py 282): INFO Train: [217/300][70/78]	eta 0:00:14 lr 1.111657	time 1.2886 (1.8183)	loss 2.6370 (2.5898)	grad_norm 0.4819 (0.4764)	mem 39782MB
[2023-07-07 15:39:37 RepVGG-A0] (main.py 291): INFO EPOCH 217 training takes 0:02:20
[2023-07-07 15:39:59 RepVGG-A0] (main.py 282): INFO Train: [218/300][0/78]	eta 0:28:32 lr 1.109054	time 21.9594 (21.9594)	loss 2.5638 (2.5638)	grad_norm 0.4891 (0.4891)	mem 39782MB
[2023-07-07 15:40:15 RepVGG-A0] (main.py 282): INFO Train: [218/300][10/78]	eta 0:03:53 lr 1.105804	time 1.1721 (3.4307)	loss 2.5845 (2.5604)	grad_norm 0.5280 (0.4843)	mem 39782MB
[2023-07-07 15:40:30 RepVGG-A0] (main.py 282): INFO Train: [218/300][20/78]	eta 0:02:25 lr 1.102557	time 1.3652 (2.5147)	loss 2.6050 (2.5790)	grad_norm 0.4757 (0.4871)	mem 39782MB
[2023-07-07 15:40:45 RepVGG-A0] (main.py 282): INFO Train: [218/300][30/78]	eta 0:01:45 lr 1.099314	time 1.2011 (2.1879)	loss 2.5835 (2.5867)	grad_norm 0.4633 (0.4888)	mem 39782MB
[2023-07-07 15:41:03 RepVGG-A0] (main.py 282): INFO Train: [218/300][40/78]	eta 0:01:19 lr 1.096075	time 3.5098 (2.0900)	loss 2.6288 (2.5858)	grad_norm 0.4775 (0.4850)	mem 39782MB
[2023-07-07 15:41:18 RepVGG-A0] (main.py 282): INFO Train: [218/300][50/78]	eta 0:00:55 lr 1.092840	time 1.1755 (1.9720)	loss 2.5904 (2.5881)	grad_norm 0.4559 (0.4835)	mem 39782MB
[2023-07-07 15:41:33 RepVGG-A0] (main.py 282): INFO Train: [218/300][60/78]	eta 0:00:34 lr 1.089609	time 1.1267 (1.9012)	loss 2.5879 (2.5933)	grad_norm 0.4809 (0.4809)	mem 39782MB
[2023-07-07 15:41:48 RepVGG-A0] (main.py 282): INFO Train: [218/300][70/78]	eta 0:00:14 lr 1.086381	time 1.2706 (1.8464)	loss 2.6525 (2.5962)	grad_norm 0.5080 (0.4838)	mem 39782MB
[2023-07-07 15:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 218 training takes 0:02:22
[2023-07-07 15:42:22 RepVGG-A0] (main.py 282): INFO Train: [219/300][0/78]	eta 0:28:01 lr 1.083802	time 21.5634 (21.5634)	loss 2.5870 (2.5870)	grad_norm 0.4598 (0.4598)	mem 39782MB
[2023-07-07 15:42:36 RepVGG-A0] (main.py 282): INFO Train: [219/300][10/78]	eta 0:03:44 lr 1.080581	time 1.1718 (3.2998)	loss 2.5372 (2.5557)	grad_norm 0.5098 (0.4698)	mem 39782MB
[2023-07-07 15:42:51 RepVGG-A0] (main.py 282): INFO Train: [219/300][20/78]	eta 0:02:20 lr 1.077364	time 1.1272 (2.4212)	loss 2.5730 (2.5753)	grad_norm 0.5126 (0.4855)	mem 39782MB
[2023-07-07 15:43:07 RepVGG-A0] (main.py 282): INFO Train: [219/300][30/78]	eta 0:01:43 lr 1.074151	time 1.1264 (2.1593)	loss 2.5832 (2.5780)	grad_norm 0.4718 (0.4858)	mem 39782MB
[2023-07-07 15:43:24 RepVGG-A0] (main.py 282): INFO Train: [219/300][40/78]	eta 0:01:18 lr 1.070942	time 2.3601 (2.0573)	loss 2.6516 (2.5819)	grad_norm 0.4710 (0.4841)	mem 39782MB
[2023-07-07 15:43:39 RepVGG-A0] (main.py 282): INFO Train: [219/300][50/78]	eta 0:00:54 lr 1.067737	time 1.1944 (1.9485)	loss 2.6098 (2.5841)	grad_norm 0.5241 (0.4860)	mem 39782MB
[2023-07-07 15:43:53 RepVGG-A0] (main.py 282): INFO Train: [219/300][60/78]	eta 0:00:33 lr 1.064535	time 1.1774 (1.8572)	loss 2.5986 (2.5889)	grad_norm 0.4939 (0.4877)	mem 39782MB
[2023-07-07 15:44:09 RepVGG-A0] (main.py 282): INFO Train: [219/300][70/78]	eta 0:00:14 lr 1.061337	time 1.2639 (1.8105)	loss 2.5569 (2.5887)	grad_norm 0.4977 (0.4861)	mem 39782MB
[2023-07-07 15:44:20 RepVGG-A0] (main.py 291): INFO EPOCH 219 training takes 0:02:20
[2023-07-07 15:44:41 RepVGG-A0] (main.py 282): INFO Train: [220/300][0/78]	eta 0:27:30 lr 1.058782	time 21.1635 (21.1635)	loss 2.5444 (2.5444)	grad_norm 0.4640 (0.4640)	mem 39782MB
[2023-07-07 15:44:56 RepVGG-A0] (main.py 282): INFO Train: [220/300][10/78]	eta 0:03:39 lr 1.055591	time 1.1709 (3.2276)	loss 2.5207 (2.5550)	grad_norm 0.4841 (0.4878)	mem 39782MB
[2023-07-07 15:45:10 RepVGG-A0] (main.py 282): INFO Train: [220/300][20/78]	eta 0:02:18 lr 1.052404	time 1.1744 (2.3876)	loss 2.5832 (2.5724)	grad_norm 0.4704 (0.5001)	mem 39782MB
[2023-07-07 15:45:26 RepVGG-A0] (main.py 282): INFO Train: [220/300][30/78]	eta 0:01:42 lr 1.049221	time 1.5338 (2.1345)	loss 2.5902 (2.5755)	grad_norm 0.4838 (0.4927)	mem 39782MB
[2023-07-07 15:45:44 RepVGG-A0] (main.py 282): INFO Train: [220/300][40/78]	eta 0:01:17 lr 1.046042	time 4.1123 (2.0514)	loss 2.6202 (2.5807)	grad_norm 0.4764 (0.4889)	mem 39782MB
[2023-07-07 15:45:59 RepVGG-A0] (main.py 282): INFO Train: [220/300][50/78]	eta 0:00:54 lr 1.042867	time 1.1723 (1.9432)	loss 2.6218 (2.5808)	grad_norm 0.4897 (0.4882)	mem 39782MB
[2023-07-07 15:46:14 RepVGG-A0] (main.py 282): INFO Train: [220/300][60/78]	eta 0:00:33 lr 1.039696	time 1.1264 (1.8716)	loss 2.5939 (2.5871)	grad_norm 0.4994 (0.4913)	mem 39782MB
[2023-07-07 15:46:30 RepVGG-A0] (main.py 282): INFO Train: [220/300][70/78]	eta 0:00:14 lr 1.036528	time 1.3935 (1.8260)	loss 2.6494 (2.5886)	grad_norm 0.4628 (0.4894)	mem 39782MB
[2023-07-07 15:46:41 RepVGG-A0] (main.py 291): INFO EPOCH 220 training takes 0:02:20
[2023-07-07 15:46:58 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.010 (17.010)	Loss 1.8846 (1.8846)	Acc@1 60.229 (60.229)	Acc@5 82.672 (82.672)	Mem 39782MB
[2023-07-07 15:46:59 RepVGG-A0] (main.py 342): INFO  * Acc@1 60.430 Acc@5 82.872
[2023-07-07 15:46:59 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 220: 60.430%
[2023-07-07 15:46:59 RepVGG-A0] (main.py 172): INFO Max accuracy: 60.43%
[2023-07-07 15:47:20 RepVGG-A0] (main.py 282): INFO Train: [221/300][0/78]	eta 0:26:30 lr 1.033997	time 20.3929 (20.3929)	loss 2.5579 (2.5579)	grad_norm 0.4686 (0.4686)	mem 39782MB
[2023-07-07 15:47:35 RepVGG-A0] (main.py 282): INFO Train: [221/300][10/78]	eta 0:03:40 lr 1.030836	time 1.1926 (3.2438)	loss 2.6145 (2.5638)	grad_norm 0.5104 (0.5007)	mem 39782MB
[2023-07-07 15:47:51 RepVGG-A0] (main.py 282): INFO Train: [221/300][20/78]	eta 0:02:22 lr 1.027680	time 1.3268 (2.4487)	loss 2.5804 (2.5624)	grad_norm 0.4605 (0.4899)	mem 39782MB
[2023-07-07 15:48:07 RepVGG-A0] (main.py 282): INFO Train: [221/300][30/78]	eta 0:01:44 lr 1.024527	time 1.6291 (2.1725)	loss 2.5114 (2.5650)	grad_norm 0.5106 (0.4890)	mem 39782MB
[2023-07-07 15:48:24 RepVGG-A0] (main.py 282): INFO Train: [221/300][40/78]	eta 0:01:18 lr 1.021379	time 3.4384 (2.0664)	loss 2.5496 (2.5676)	grad_norm 0.4713 (0.4880)	mem 39782MB
[2023-07-07 15:48:39 RepVGG-A0] (main.py 282): INFO Train: [221/300][50/78]	eta 0:00:54 lr 1.018234	time 1.3346 (1.9600)	loss 2.5256 (2.5678)	grad_norm 0.5240 (0.4871)	mem 39782MB
[2023-07-07 15:48:54 RepVGG-A0] (main.py 282): INFO Train: [221/300][60/78]	eta 0:00:33 lr 1.015093	time 1.1796 (1.8854)	loss 2.6098 (2.5765)	grad_norm 0.4760 (0.4858)	mem 39782MB
[2023-07-07 15:49:10 RepVGG-A0] (main.py 282): INFO Train: [221/300][70/78]	eta 0:00:14 lr 1.011956	time 1.4153 (1.8468)	loss 2.6173 (2.5780)	grad_norm 0.5042 (0.4868)	mem 39782MB
[2023-07-07 15:49:23 RepVGG-A0] (main.py 291): INFO EPOCH 221 training takes 0:02:23
[2023-07-07 15:49:45 RepVGG-A0] (main.py 282): INFO Train: [222/300][0/78]	eta 0:29:36 lr 1.009449	time 22.7805 (22.7805)	loss 2.5542 (2.5542)	grad_norm 0.4914 (0.4914)	mem 39782MB
[2023-07-07 15:50:00 RepVGG-A0] (main.py 282): INFO Train: [222/300][10/78]	eta 0:03:52 lr 1.006319	time 1.1723 (3.4163)	loss 2.5708 (2.5300)	grad_norm 0.4525 (0.4776)	mem 39782MB
[2023-07-07 15:50:14 RepVGG-A0] (main.py 282): INFO Train: [222/300][20/78]	eta 0:02:21 lr 1.003194	time 1.1725 (2.4414)	loss 2.5242 (2.5324)	grad_norm 0.4798 (0.4826)	mem 39782MB
[2023-07-07 15:50:28 RepVGG-A0] (main.py 282): INFO Train: [222/300][30/78]	eta 0:01:41 lr 1.000072	time 1.2504 (2.1221)	loss 2.6130 (2.5486)	grad_norm 0.4730 (0.4815)	mem 39782MB
[2023-07-07 15:50:46 RepVGG-A0] (main.py 282): INFO Train: [222/300][40/78]	eta 0:01:17 lr 0.996954	time 2.9462 (2.0315)	loss 2.5710 (2.5531)	grad_norm 0.5011 (0.4845)	mem 39782MB
[2023-07-07 15:51:01 RepVGG-A0] (main.py 282): INFO Train: [222/300][50/78]	eta 0:00:54 lr 0.993840	time 1.4803 (1.9367)	loss 2.5379 (2.5549)	grad_norm 0.4818 (0.4836)	mem 39782MB
[2023-07-07 15:51:17 RepVGG-A0] (main.py 282): INFO Train: [222/300][60/78]	eta 0:00:33 lr 0.990730	time 1.1754 (1.8800)	loss 2.5586 (2.5616)	grad_norm 0.4855 (0.4862)	mem 39782MB
[2023-07-07 15:51:32 RepVGG-A0] (main.py 282): INFO Train: [222/300][70/78]	eta 0:00:14 lr 0.987624	time 1.3423 (1.8238)	loss 2.5868 (2.5634)	grad_norm 0.4788 (0.4853)	mem 39782MB
[2023-07-07 15:51:44 RepVGG-A0] (main.py 291): INFO EPOCH 222 training takes 0:02:21
[2023-07-07 15:52:07 RepVGG-A0] (main.py 282): INFO Train: [223/300][0/78]	eta 0:29:40 lr 0.985142	time 22.8275 (22.8275)	loss 2.4953 (2.4953)	grad_norm 0.4824 (0.4824)	mem 39782MB
[2023-07-07 15:52:22 RepVGG-A0] (main.py 282): INFO Train: [223/300][10/78]	eta 0:03:53 lr 0.982043	time 1.1962 (3.4393)	loss 2.5243 (2.5367)	grad_norm 0.5013 (0.4981)	mem 39782MB
[2023-07-07 15:52:35 RepVGG-A0] (main.py 282): INFO Train: [223/300][20/78]	eta 0:02:22 lr 0.978948	time 1.1730 (2.4541)	loss 2.6382 (2.5584)	grad_norm 0.4780 (0.5029)	mem 39782MB
[2023-07-07 15:52:52 RepVGG-A0] (main.py 282): INFO Train: [223/300][30/78]	eta 0:01:46 lr 0.975857	time 1.5385 (2.2091)	loss 2.5351 (2.5572)	grad_norm 0.4752 (0.4952)	mem 39782MB
[2023-07-07 15:53:09 RepVGG-A0] (main.py 282): INFO Train: [223/300][40/78]	eta 0:01:19 lr 0.972771	time 2.5096 (2.0808)	loss 2.5793 (2.5621)	grad_norm 0.4764 (0.4953)	mem 39782MB
[2023-07-07 15:53:24 RepVGG-A0] (main.py 282): INFO Train: [223/300][50/78]	eta 0:00:55 lr 0.969688	time 1.1728 (1.9655)	loss 2.5351 (2.5638)	grad_norm 0.4945 (0.4948)	mem 39782MB
[2023-07-07 15:53:39 RepVGG-A0] (main.py 282): INFO Train: [223/300][60/78]	eta 0:00:34 lr 0.966609	time 1.2879 (1.8910)	loss 2.5800 (2.5646)	grad_norm 0.4734 (0.4932)	mem 39782MB
[2023-07-07 15:53:55 RepVGG-A0] (main.py 282): INFO Train: [223/300][70/78]	eta 0:00:14 lr 0.963534	time 1.3963 (1.8425)	loss 2.6008 (2.5657)	grad_norm 0.4944 (0.4923)	mem 39782MB
[2023-07-07 15:54:06 RepVGG-A0] (main.py 291): INFO EPOCH 223 training takes 0:02:22
[2023-07-07 15:54:27 RepVGG-A0] (main.py 282): INFO Train: [224/300][0/78]	eta 0:27:06 lr 0.961077	time 20.8471 (20.8471)	loss 2.5562 (2.5562)	grad_norm 0.4953 (0.4953)	mem 39782MB
[2023-07-07 15:54:41 RepVGG-A0] (main.py 282): INFO Train: [224/300][10/78]	eta 0:03:37 lr 0.958010	time 1.1705 (3.1941)	loss 2.5198 (2.5413)	grad_norm 0.4578 (0.5028)	mem 39782MB
[2023-07-07 15:54:57 RepVGG-A0] (main.py 282): INFO Train: [224/300][20/78]	eta 0:02:20 lr 0.954946	time 1.1930 (2.4244)	loss 2.5264 (2.5400)	grad_norm 0.4992 (0.5000)	mem 39782MB
[2023-07-07 15:55:12 RepVGG-A0] (main.py 282): INFO Train: [224/300][30/78]	eta 0:01:42 lr 0.951887	time 1.6694 (2.1346)	loss 2.6213 (2.5454)	grad_norm 0.4729 (0.4954)	mem 39782MB
[2023-07-07 15:55:31 RepVGG-A0] (main.py 282): INFO Train: [224/300][40/78]	eta 0:01:18 lr 0.948832	time 3.0889 (2.0710)	loss 2.5981 (2.5471)	grad_norm 0.5102 (0.4970)	mem 39782MB
[2023-07-07 15:55:46 RepVGG-A0] (main.py 282): INFO Train: [224/300][50/78]	eta 0:00:54 lr 0.945780	time 1.2076 (1.9572)	loss 2.5666 (2.5505)	grad_norm 0.4963 (0.4969)	mem 39782MB
[2023-07-07 15:56:01 RepVGG-A0] (main.py 282): INFO Train: [224/300][60/78]	eta 0:00:33 lr 0.942733	time 1.6199 (1.8834)	loss 2.5618 (2.5532)	grad_norm 0.4766 (0.4956)	mem 39782MB
[2023-07-07 15:56:16 RepVGG-A0] (main.py 282): INFO Train: [224/300][70/78]	eta 0:00:14 lr 0.939690	time 1.6228 (1.8357)	loss 2.5882 (2.5563)	grad_norm 0.4975 (0.4972)	mem 39782MB
[2023-07-07 15:56:28 RepVGG-A0] (main.py 291): INFO EPOCH 224 training takes 0:02:21
[2023-07-07 15:56:50 RepVGG-A0] (main.py 282): INFO Train: [225/300][0/78]	eta 0:28:28 lr 0.937258	time 21.9100 (21.9100)	loss 2.5086 (2.5086)	grad_norm 0.5075 (0.5075)	mem 39782MB
[2023-07-07 15:57:04 RepVGG-A0] (main.py 282): INFO Train: [225/300][10/78]	eta 0:03:43 lr 0.934222	time 1.1714 (3.2880)	loss 2.5689 (2.5183)	grad_norm 0.4895 (0.4909)	mem 39782MB
[2023-07-07 15:57:18 RepVGG-A0] (main.py 282): INFO Train: [225/300][20/78]	eta 0:02:19 lr 0.931191	time 1.1729 (2.4034)	loss 2.4701 (2.5173)	grad_norm 0.4810 (0.4851)	mem 39782MB
[2023-07-07 15:57:34 RepVGG-A0] (main.py 282): INFO Train: [225/300][30/78]	eta 0:01:42 lr 0.928163	time 1.4739 (2.1377)	loss 2.5815 (2.5311)	grad_norm 0.4985 (0.4874)	mem 39782MB
[2023-07-07 15:57:51 RepVGG-A0] (main.py 282): INFO Train: [225/300][40/78]	eta 0:01:16 lr 0.925140	time 3.5816 (2.0259)	loss 2.5381 (2.5342)	grad_norm 0.5378 (0.4909)	mem 39782MB
[2023-07-07 15:58:07 RepVGG-A0] (main.py 282): INFO Train: [225/300][50/78]	eta 0:00:54 lr 0.922120	time 1.2167 (1.9397)	loss 2.5360 (2.5398)	grad_norm 0.4918 (0.4955)	mem 39782MB
[2023-07-07 15:58:23 RepVGG-A0] (main.py 282): INFO Train: [225/300][60/78]	eta 0:00:33 lr 0.919105	time 1.2206 (1.8820)	loss 2.5621 (2.5427)	grad_norm 0.4952 (0.4940)	mem 39782MB
[2023-07-07 15:58:38 RepVGG-A0] (main.py 282): INFO Train: [225/300][70/78]	eta 0:00:14 lr 0.916093	time 1.2382 (1.8292)	loss 2.5380 (2.5448)	grad_norm 0.5021 (0.4925)	mem 39782MB
[2023-07-07 15:58:50 RepVGG-A0] (main.py 291): INFO EPOCH 225 training takes 0:02:21
[2023-07-07 15:59:10 RepVGG-A0] (main.py 282): INFO Train: [226/300][0/78]	eta 0:26:50 lr 0.913687	time 20.6524 (20.6524)	loss 2.4337 (2.4337)	grad_norm 0.4776 (0.4776)	mem 39782MB
[2023-07-07 15:59:27 RepVGG-A0] (main.py 282): INFO Train: [226/300][10/78]	eta 0:03:49 lr 0.910684	time 1.1709 (3.3775)	loss 2.5212 (2.5276)	grad_norm 0.4954 (0.4838)	mem 39782MB
[2023-07-07 15:59:42 RepVGG-A0] (main.py 282): INFO Train: [226/300][20/78]	eta 0:02:24 lr 0.907684	time 1.1875 (2.4887)	loss 2.5227 (2.5343)	grad_norm 0.4981 (0.4960)	mem 39782MB
[2023-07-07 15:59:57 RepVGG-A0] (main.py 282): INFO Train: [226/300][30/78]	eta 0:01:43 lr 0.904688	time 1.6884 (2.1611)	loss 2.5559 (2.5368)	grad_norm 0.4910 (0.4935)	mem 39782MB
[2023-07-07 16:00:14 RepVGG-A0] (main.py 282): INFO Train: [226/300][40/78]	eta 0:01:18 lr 0.901697	time 2.6402 (2.0589)	loss 2.5621 (2.5410)	grad_norm 0.5053 (0.4947)	mem 39782MB
[2023-07-07 16:00:29 RepVGG-A0] (main.py 282): INFO Train: [226/300][50/78]	eta 0:00:54 lr 0.898710	time 1.1955 (1.9511)	loss 2.5583 (2.5410)	grad_norm 0.5148 (0.4937)	mem 39782MB
[2023-07-07 16:00:45 RepVGG-A0] (main.py 282): INFO Train: [226/300][60/78]	eta 0:00:33 lr 0.895726	time 1.1336 (1.8845)	loss 2.6063 (2.5458)	grad_norm 0.5291 (0.4971)	mem 39782MB
[2023-07-07 16:00:59 RepVGG-A0] (main.py 282): INFO Train: [226/300][70/78]	eta 0:00:14 lr 0.892747	time 1.1823 (1.8253)	loss 2.5332 (2.5503)	grad_norm 0.5015 (0.4992)	mem 39782MB
[2023-07-07 16:01:11 RepVGG-A0] (main.py 291): INFO EPOCH 226 training takes 0:02:21
[2023-07-07 16:01:33 RepVGG-A0] (main.py 282): INFO Train: [227/300][0/78]	eta 0:28:21 lr 0.890367	time 21.8164 (21.8164)	loss 2.5583 (2.5583)	grad_norm 0.4839 (0.4839)	mem 39782MB
[2023-07-07 16:01:47 RepVGG-A0] (main.py 282): INFO Train: [227/300][10/78]	eta 0:03:43 lr 0.887396	time 1.1726 (3.2802)	loss 2.5463 (2.5097)	grad_norm 0.5000 (0.4859)	mem 39782MB
[2023-07-07 16:02:02 RepVGG-A0] (main.py 282): INFO Train: [227/300][20/78]	eta 0:02:21 lr 0.884428	time 1.1302 (2.4332)	loss 2.5276 (2.5112)	grad_norm 0.5048 (0.4904)	mem 39782MB
[2023-07-07 16:02:18 RepVGG-A0] (main.py 282): INFO Train: [227/300][30/78]	eta 0:01:43 lr 0.881465	time 1.4982 (2.1574)	loss 2.5433 (2.5158)	grad_norm 0.5313 (0.4920)	mem 39782MB
[2023-07-07 16:02:35 RepVGG-A0] (main.py 282): INFO Train: [227/300][40/78]	eta 0:01:17 lr 0.878506	time 4.0349 (2.0398)	loss 2.6126 (2.5241)	grad_norm 0.4835 (0.4962)	mem 39782MB
[2023-07-07 16:02:51 RepVGG-A0] (main.py 282): INFO Train: [227/300][50/78]	eta 0:00:54 lr 0.875552	time 1.1736 (1.9576)	loss 2.5752 (2.5264)	grad_norm 0.5101 (0.4968)	mem 39782MB
[2023-07-07 16:03:06 RepVGG-A0] (main.py 282): INFO Train: [227/300][60/78]	eta 0:00:33 lr 0.872601	time 1.3471 (1.8849)	loss 2.4885 (2.5276)	grad_norm 0.5010 (0.4974)	mem 39782MB
[2023-07-07 16:03:21 RepVGG-A0] (main.py 282): INFO Train: [227/300][70/78]	eta 0:00:14 lr 0.869654	time 1.2880 (1.8326)	loss 2.6009 (2.5339)	grad_norm 0.4780 (0.4987)	mem 39782MB
[2023-07-07 16:03:31 RepVGG-A0] (main.py 291): INFO EPOCH 227 training takes 0:02:20
[2023-07-07 16:03:52 RepVGG-A0] (main.py 282): INFO Train: [228/300][0/78]	eta 0:26:24 lr 0.867300	time 20.3122 (20.3122)	loss 2.5355 (2.5355)	grad_norm 0.4888 (0.4888)	mem 39782MB
[2023-07-07 16:04:06 RepVGG-A0] (main.py 282): INFO Train: [228/300][10/78]	eta 0:03:36 lr 0.864362	time 1.1903 (3.1812)	loss 2.5788 (2.5310)	grad_norm 0.5211 (0.5037)	mem 39782MB
[2023-07-07 16:04:21 RepVGG-A0] (main.py 282): INFO Train: [228/300][20/78]	eta 0:02:18 lr 0.861427	time 1.1725 (2.3831)	loss 2.5572 (2.5126)	grad_norm 0.4989 (0.4966)	mem 39782MB
[2023-07-07 16:04:37 RepVGG-A0] (main.py 282): INFO Train: [228/300][30/78]	eta 0:01:42 lr 0.858496	time 1.3247 (2.1330)	loss 2.5632 (2.5164)	grad_norm 0.4733 (0.4940)	mem 39782MB
[2023-07-07 16:04:55 RepVGG-A0] (main.py 282): INFO Train: [228/300][40/78]	eta 0:01:17 lr 0.855570	time 2.4571 (2.0359)	loss 2.5552 (2.5189)	grad_norm 0.5176 (0.4957)	mem 39782MB
[2023-07-07 16:05:10 RepVGG-A0] (main.py 282): INFO Train: [228/300][50/78]	eta 0:00:53 lr 0.852648	time 1.1879 (1.9270)	loss 2.5179 (2.5232)	grad_norm 0.4996 (0.5002)	mem 39782MB
[2023-07-07 16:05:25 RepVGG-A0] (main.py 282): INFO Train: [228/300][60/78]	eta 0:00:33 lr 0.849731	time 1.4973 (1.8621)	loss 2.5920 (2.5259)	grad_norm 0.4959 (0.4983)	mem 39782MB
[2023-07-07 16:05:40 RepVGG-A0] (main.py 282): INFO Train: [228/300][70/78]	eta 0:00:14 lr 0.846817	time 1.1986 (1.8093)	loss 2.5279 (2.5302)	grad_norm 0.5037 (0.4973)	mem 39782MB
[2023-07-07 16:05:51 RepVGG-A0] (main.py 291): INFO EPOCH 228 training takes 0:02:19
[2023-07-07 16:06:13 RepVGG-A0] (main.py 282): INFO Train: [229/300][0/78]	eta 0:28:38 lr 0.844489	time 22.0383 (22.0383)	loss 2.5193 (2.5193)	grad_norm 0.4955 (0.4955)	mem 39782MB
[2023-07-07 16:06:28 RepVGG-A0] (main.py 282): INFO Train: [229/300][10/78]	eta 0:03:45 lr 0.841583	time 1.1737 (3.3226)	loss 2.4514 (2.5085)	grad_norm 0.4885 (0.4975)	mem 39782MB
[2023-07-07 16:06:42 RepVGG-A0] (main.py 282): INFO Train: [229/300][20/78]	eta 0:02:20 lr 0.838682	time 1.1919 (2.4282)	loss 2.4942 (2.5149)	grad_norm 0.5325 (0.5072)	mem 39782MB
[2023-07-07 16:06:58 RepVGG-A0] (main.py 282): INFO Train: [229/300][30/78]	eta 0:01:42 lr 0.835784	time 1.1281 (2.1405)	loss 2.5259 (2.5192)	grad_norm 0.4963 (0.5021)	mem 39782MB
[2023-07-07 16:07:16 RepVGG-A0] (main.py 282): INFO Train: [229/300][40/78]	eta 0:01:18 lr 0.832891	time 2.6694 (2.0662)	loss 2.5110 (2.5170)	grad_norm 0.5258 (0.5019)	mem 39782MB
[2023-07-07 16:07:31 RepVGG-A0] (main.py 282): INFO Train: [229/300][50/78]	eta 0:00:54 lr 0.830003	time 1.1740 (1.9573)	loss 2.4809 (2.5163)	grad_norm 0.5343 (0.5030)	mem 39782MB
[2023-07-07 16:07:46 RepVGG-A0] (main.py 282): INFO Train: [229/300][60/78]	eta 0:00:33 lr 0.827118	time 1.1781 (1.8827)	loss 2.4716 (2.5200)	grad_norm 0.4989 (0.5037)	mem 39782MB
[2023-07-07 16:08:02 RepVGG-A0] (main.py 282): INFO Train: [229/300][70/78]	eta 0:00:14 lr 0.824238	time 1.5299 (1.8352)	loss 2.5576 (2.5221)	grad_norm 0.5166 (0.5035)	mem 39782MB
[2023-07-07 16:08:13 RepVGG-A0] (main.py 291): INFO EPOCH 229 training takes 0:02:21
[2023-07-07 16:08:34 RepVGG-A0] (main.py 282): INFO Train: [230/300][0/78]	eta 0:28:09 lr 0.821937	time 21.6638 (21.6638)	loss 2.4801 (2.4801)	grad_norm 0.4908 (0.4908)	mem 39782MB
[2023-07-07 16:08:49 RepVGG-A0] (main.py 282): INFO Train: [230/300][10/78]	eta 0:03:46 lr 0.819064	time 1.1705 (3.3293)	loss 2.4924 (2.4902)	grad_norm 0.5070 (0.4987)	mem 39782MB
[2023-07-07 16:09:05 RepVGG-A0] (main.py 282): INFO Train: [230/300][20/78]	eta 0:02:25 lr 0.816196	time 1.4154 (2.5058)	loss 2.5685 (2.4982)	grad_norm 0.4918 (0.5001)	mem 39782MB
[2023-07-07 16:09:19 RepVGG-A0] (main.py 282): INFO Train: [230/300][30/78]	eta 0:01:42 lr 0.813332	time 1.6832 (2.1430)	loss 2.5299 (2.5051)	grad_norm 0.4943 (0.5026)	mem 39782MB
[2023-07-07 16:09:36 RepVGG-A0] (main.py 282): INFO Train: [230/300][40/78]	eta 0:01:17 lr 0.810472	time 3.3141 (2.0372)	loss 2.5012 (2.5073)	grad_norm 0.4874 (0.5005)	mem 39782MB
[2023-07-07 16:09:52 RepVGG-A0] (main.py 282): INFO Train: [230/300][50/78]	eta 0:00:54 lr 0.807617	time 1.1718 (1.9501)	loss 2.5779 (2.5119)	grad_norm 0.5224 (0.5003)	mem 39782MB
[2023-07-07 16:10:07 RepVGG-A0] (main.py 282): INFO Train: [230/300][60/78]	eta 0:00:33 lr 0.804766	time 1.3697 (1.8769)	loss 2.4860 (2.5151)	grad_norm 0.5131 (0.5037)	mem 39782MB
[2023-07-07 16:10:22 RepVGG-A0] (main.py 282): INFO Train: [230/300][70/78]	eta 0:00:14 lr 0.801919	time 1.4744 (1.8255)	loss 2.5436 (2.5170)	grad_norm 0.4890 (0.5033)	mem 39782MB
[2023-07-07 16:10:34 RepVGG-A0] (main.py 291): INFO EPOCH 230 training takes 0:02:20
[2023-07-07 16:10:55 RepVGG-A0] (main.py 282): INFO Train: [231/300][0/78]	eta 0:28:30 lr 0.799645	time 21.9291 (21.9291)	loss 2.4663 (2.4663)	grad_norm 0.4890 (0.4890)	mem 39782MB
[2023-07-07 16:11:09 RepVGG-A0] (main.py 282): INFO Train: [231/300][10/78]	eta 0:03:41 lr 0.796806	time 1.1706 (3.2628)	loss 2.4457 (2.4704)	grad_norm 0.5044 (0.4964)	mem 39782MB
[2023-07-07 16:11:25 RepVGG-A0] (main.py 282): INFO Train: [231/300][20/78]	eta 0:02:20 lr 0.793971	time 1.1747 (2.4288)	loss 2.5080 (2.4824)	grad_norm 0.5226 (0.5073)	mem 39782MB
[2023-07-07 16:11:40 RepVGG-A0] (main.py 282): INFO Train: [231/300][30/78]	eta 0:01:43 lr 0.791141	time 1.2429 (2.1521)	loss 2.5121 (2.4891)	grad_norm 0.4892 (0.5057)	mem 39782MB
[2023-07-07 16:11:58 RepVGG-A0] (main.py 282): INFO Train: [231/300][40/78]	eta 0:01:18 lr 0.788315	time 3.4239 (2.0709)	loss 2.5287 (2.4976)	grad_norm 0.4973 (0.5028)	mem 39782MB
[2023-07-07 16:12:13 RepVGG-A0] (main.py 282): INFO Train: [231/300][50/78]	eta 0:00:54 lr 0.785493	time 1.1784 (1.9588)	loss 2.5153 (2.5017)	grad_norm 0.5195 (0.5043)	mem 39782MB
[2023-07-07 16:12:28 RepVGG-A0] (main.py 282): INFO Train: [231/300][60/78]	eta 0:00:33 lr 0.782676	time 1.4770 (1.8814)	loss 2.4922 (2.5043)	grad_norm 0.5058 (0.5039)	mem 39782MB
[2023-07-07 16:12:44 RepVGG-A0] (main.py 282): INFO Train: [231/300][70/78]	eta 0:00:14 lr 0.779863	time 1.4116 (1.8345)	loss 2.4812 (2.5058)	grad_norm 0.4934 (0.5065)	mem 39782MB
[2023-07-07 16:12:55 RepVGG-A0] (main.py 291): INFO EPOCH 231 training takes 0:02:21
[2023-07-07 16:13:17 RepVGG-A0] (main.py 282): INFO Train: [232/300][0/78]	eta 0:28:04 lr 0.777616	time 21.6013 (21.6013)	loss 2.5188 (2.5188)	grad_norm 0.5016 (0.5016)	mem 39782MB
[2023-07-07 16:13:31 RepVGG-A0] (main.py 282): INFO Train: [232/300][10/78]	eta 0:03:44 lr 0.774811	time 1.1708 (3.3067)	loss 2.5464 (2.4949)	grad_norm 0.5215 (0.5087)	mem 39782MB
[2023-07-07 16:13:46 RepVGG-A0] (main.py 282): INFO Train: [232/300][20/78]	eta 0:02:21 lr 0.772010	time 1.1770 (2.4396)	loss 2.5282 (2.4969)	grad_norm 0.5125 (0.5089)	mem 39782MB
[2023-07-07 16:14:00 RepVGG-A0] (main.py 282): INFO Train: [232/300][30/78]	eta 0:01:40 lr 0.769214	time 1.3540 (2.0974)	loss 2.4366 (2.4969)	grad_norm 0.5037 (0.5062)	mem 39782MB
[2023-07-07 16:14:20 RepVGG-A0] (main.py 282): INFO Train: [232/300][40/78]	eta 0:01:18 lr 0.766422	time 3.9716 (2.0639)	loss 2.5015 (2.4970)	grad_norm 0.5148 (0.5051)	mem 39782MB
[2023-07-07 16:14:35 RepVGG-A0] (main.py 282): INFO Train: [232/300][50/78]	eta 0:00:54 lr 0.763634	time 1.2502 (1.9539)	loss 2.5417 (2.5005)	grad_norm 0.4926 (0.5051)	mem 39782MB
[2023-07-07 16:14:51 RepVGG-A0] (main.py 282): INFO Train: [232/300][60/78]	eta 0:00:34 lr 0.760851	time 1.4590 (1.8958)	loss 2.5290 (2.5058)	grad_norm 0.5255 (0.5054)	mem 39782MB
[2023-07-07 16:15:04 RepVGG-A0] (main.py 282): INFO Train: [232/300][70/78]	eta 0:00:14 lr 0.758073	time 1.2672 (1.8133)	loss 2.4954 (2.5076)	grad_norm 0.5199 (0.5059)	mem 39782MB
[2023-07-07 16:15:16 RepVGG-A0] (main.py 291): INFO EPOCH 232 training takes 0:02:21
[2023-07-07 16:15:38 RepVGG-A0] (main.py 282): INFO Train: [233/300][0/78]	eta 0:28:25 lr 0.755853	time 21.8596 (21.8596)	loss 2.4655 (2.4655)	grad_norm 0.4861 (0.4861)	mem 39782MB
[2023-07-07 16:15:52 RepVGG-A0] (main.py 282): INFO Train: [233/300][10/78]	eta 0:03:44 lr 0.753082	time 1.1729 (3.2979)	loss 2.4744 (2.4561)	grad_norm 0.5264 (0.5047)	mem 39782MB
[2023-07-07 16:16:07 RepVGG-A0] (main.py 282): INFO Train: [233/300][20/78]	eta 0:02:20 lr 0.750316	time 1.1763 (2.4174)	loss 2.5353 (2.4810)	grad_norm 0.5059 (0.5057)	mem 39782MB
[2023-07-07 16:16:23 RepVGG-A0] (main.py 282): INFO Train: [233/300][30/78]	eta 0:01:43 lr 0.747554	time 1.5289 (2.1596)	loss 2.5558 (2.4856)	grad_norm 0.5195 (0.5117)	mem 39782MB
[2023-07-07 16:16:40 RepVGG-A0] (main.py 282): INFO Train: [233/300][40/78]	eta 0:01:17 lr 0.744796	time 3.5435 (2.0349)	loss 2.4801 (2.4913)	grad_norm 0.4857 (0.5098)	mem 39782MB
[2023-07-07 16:16:55 RepVGG-A0] (main.py 282): INFO Train: [233/300][50/78]	eta 0:00:54 lr 0.742043	time 1.1736 (1.9300)	loss 2.5008 (2.4955)	grad_norm 0.5036 (0.5124)	mem 39782MB
[2023-07-07 16:17:10 RepVGG-A0] (main.py 282): INFO Train: [233/300][60/78]	eta 0:00:33 lr 0.739294	time 1.3928 (1.8656)	loss 2.5047 (2.4988)	grad_norm 0.4957 (0.5112)	mem 39782MB
[2023-07-07 16:17:25 RepVGG-A0] (main.py 282): INFO Train: [233/300][70/78]	eta 0:00:14 lr 0.736550	time 1.1957 (1.8127)	loss 2.5048 (2.5030)	grad_norm 0.5257 (0.5134)	mem 39782MB
[2023-07-07 16:17:37 RepVGG-A0] (main.py 291): INFO EPOCH 233 training takes 0:02:20
[2023-07-07 16:18:00 RepVGG-A0] (main.py 282): INFO Train: [234/300][0/78]	eta 0:29:10 lr 0.734358	time 22.4449 (22.4449)	loss 2.4446 (2.4446)	grad_norm 0.5111 (0.5111)	mem 39782MB
[2023-07-07 16:18:14 RepVGG-A0] (main.py 282): INFO Train: [234/300][10/78]	eta 0:03:48 lr 0.731621	time 1.1722 (3.3651)	loss 2.5228 (2.4970)	grad_norm 0.5129 (0.5066)	mem 39782MB
[2023-07-07 16:18:29 RepVGG-A0] (main.py 282): INFO Train: [234/300][20/78]	eta 0:02:23 lr 0.728890	time 1.4144 (2.4728)	loss 2.5169 (2.4855)	grad_norm 0.5179 (0.5055)	mem 39782MB
[2023-07-07 16:18:44 RepVGG-A0] (main.py 282): INFO Train: [234/300][30/78]	eta 0:01:42 lr 0.726162	time 1.2142 (2.1424)	loss 2.4839 (2.4848)	grad_norm 0.5414 (0.5103)	mem 39782MB
[2023-07-07 16:19:02 RepVGG-A0] (main.py 282): INFO Train: [234/300][40/78]	eta 0:01:18 lr 0.723439	time 3.9386 (2.0668)	loss 2.5355 (2.4873)	grad_norm 0.5134 (0.5097)	mem 39782MB
[2023-07-07 16:19:18 RepVGG-A0] (main.py 282): INFO Train: [234/300][50/78]	eta 0:00:55 lr 0.720721	time 1.1728 (1.9765)	loss 2.4856 (2.4883)	grad_norm 0.4892 (0.5068)	mem 39782MB
[2023-07-07 16:19:32 RepVGG-A0] (main.py 282): INFO Train: [234/300][60/78]	eta 0:00:33 lr 0.718007	time 1.1879 (1.8780)	loss 2.5607 (2.4926)	grad_norm 0.5074 (0.5100)	mem 39782MB
[2023-07-07 16:19:48 RepVGG-A0] (main.py 282): INFO Train: [234/300][70/78]	eta 0:00:14 lr 0.715297	time 1.1862 (1.8441)	loss 2.4170 (2.4942)	grad_norm 0.5236 (0.5097)	mem 39782MB
[2023-07-07 16:19:59 RepVGG-A0] (main.py 291): INFO EPOCH 234 training takes 0:02:22
[2023-07-07 16:20:21 RepVGG-A0] (main.py 282): INFO Train: [235/300][0/78]	eta 0:27:49 lr 0.713133	time 21.4074 (21.4074)	loss 2.4594 (2.4594)	grad_norm 0.5096 (0.5096)	mem 39782MB
[2023-07-07 16:20:35 RepVGG-A0] (main.py 282): INFO Train: [235/300][10/78]	eta 0:03:43 lr 0.710431	time 1.1739 (3.2936)	loss 2.5140 (2.4644)	grad_norm 0.5333 (0.5153)	mem 39782MB
[2023-07-07 16:20:51 RepVGG-A0] (main.py 282): INFO Train: [235/300][20/78]	eta 0:02:22 lr 0.707735	time 1.2113 (2.4489)	loss 2.4778 (2.4702)	grad_norm 0.5101 (0.5163)	mem 39782MB
[2023-07-07 16:21:06 RepVGG-A0] (main.py 282): INFO Train: [235/300][30/78]	eta 0:01:43 lr 0.705042	time 1.1857 (2.1659)	loss 2.5023 (2.4729)	grad_norm 0.4835 (0.5139)	mem 39782MB
[2023-07-07 16:21:24 RepVGG-A0] (main.py 282): INFO Train: [235/300][40/78]	eta 0:01:18 lr 0.702354	time 3.7953 (2.0759)	loss 2.5021 (2.4735)	grad_norm 0.5222 (0.5125)	mem 39782MB
[2023-07-07 16:21:39 RepVGG-A0] (main.py 282): INFO Train: [235/300][50/78]	eta 0:00:54 lr 0.699671	time 1.1737 (1.9620)	loss 2.4348 (2.4741)	grad_norm 0.5040 (0.5119)	mem 39782MB
[2023-07-07 16:21:55 RepVGG-A0] (main.py 282): INFO Train: [235/300][60/78]	eta 0:00:34 lr 0.696992	time 1.4536 (1.8925)	loss 2.5285 (2.4789)	grad_norm 0.5282 (0.5113)	mem 39782MB
[2023-07-07 16:22:10 RepVGG-A0] (main.py 282): INFO Train: [235/300][70/78]	eta 0:00:14 lr 0.694317	time 1.1753 (1.8392)	loss 2.5703 (2.4832)	grad_norm 0.5023 (0.5132)	mem 39782MB
[2023-07-07 16:22:21 RepVGG-A0] (main.py 291): INFO EPOCH 235 training takes 0:02:22
[2023-07-07 16:22:43 RepVGG-A0] (main.py 282): INFO Train: [236/300][0/78]	eta 0:28:10 lr 0.692181	time 21.6695 (21.6695)	loss 2.3961 (2.3961)	grad_norm 0.5067 (0.5067)	mem 39782MB
[2023-07-07 16:22:58 RepVGG-A0] (main.py 282): INFO Train: [236/300][10/78]	eta 0:03:44 lr 0.689515	time 1.1740 (3.3076)	loss 2.4628 (2.4606)	grad_norm 0.5149 (0.5207)	mem 39782MB
[2023-07-07 16:23:12 RepVGG-A0] (main.py 282): INFO Train: [236/300][20/78]	eta 0:02:20 lr 0.686853	time 1.4356 (2.4248)	loss 2.4776 (2.4661)	grad_norm 0.5042 (0.5174)	mem 39782MB
[2023-07-07 16:23:28 RepVGG-A0] (main.py 282): INFO Train: [236/300][30/78]	eta 0:01:42 lr 0.684196	time 1.2233 (2.1432)	loss 2.3895 (2.4617)	grad_norm 0.5256 (0.5191)	mem 39782MB
[2023-07-07 16:23:45 RepVGG-A0] (main.py 282): INFO Train: [236/300][40/78]	eta 0:01:17 lr 0.681543	time 3.2700 (2.0492)	loss 2.5983 (2.4679)	grad_norm 0.5654 (0.5184)	mem 39782MB
[2023-07-07 16:24:00 RepVGG-A0] (main.py 282): INFO Train: [236/300][50/78]	eta 0:00:54 lr 0.678895	time 1.1728 (1.9385)	loss 2.4420 (2.4665)	grad_norm 0.5100 (0.5184)	mem 39782MB
[2023-07-07 16:24:15 RepVGG-A0] (main.py 282): INFO Train: [236/300][60/78]	eta 0:00:33 lr 0.676251	time 1.1860 (1.8682)	loss 2.5159 (2.4700)	grad_norm 0.5365 (0.5205)	mem 39782MB
[2023-07-07 16:24:31 RepVGG-A0] (main.py 282): INFO Train: [236/300][70/78]	eta 0:00:14 lr 0.673612	time 1.4895 (1.8243)	loss 2.5133 (2.4732)	grad_norm 0.5180 (0.5196)	mem 39782MB
[2023-07-07 16:24:43 RepVGG-A0] (main.py 291): INFO EPOCH 236 training takes 0:02:21
[2023-07-07 16:25:04 RepVGG-A0] (main.py 282): INFO Train: [237/300][0/78]	eta 0:27:27 lr 0.671504	time 21.1238 (21.1238)	loss 2.4021 (2.4021)	grad_norm 0.5018 (0.5018)	mem 39782MB
[2023-07-07 16:25:21 RepVGG-A0] (main.py 282): INFO Train: [237/300][10/78]	eta 0:03:51 lr 0.668873	time 1.1710 (3.4027)	loss 2.4721 (2.4453)	grad_norm 0.5053 (0.5123)	mem 39782MB
[2023-07-07 16:25:35 RepVGG-A0] (main.py 282): INFO Train: [237/300][20/78]	eta 0:02:24 lr 0.666247	time 1.2074 (2.4855)	loss 2.4983 (2.4596)	grad_norm 0.4952 (0.5129)	mem 39782MB
[2023-07-07 16:25:51 RepVGG-A0] (main.py 282): INFO Train: [237/300][30/78]	eta 0:01:44 lr 0.663625	time 1.7586 (2.1862)	loss 2.4553 (2.4589)	grad_norm 0.5083 (0.5118)	mem 39782MB
[2023-07-07 16:26:09 RepVGG-A0] (main.py 282): INFO Train: [237/300][40/78]	eta 0:01:19 lr 0.661008	time 2.8785 (2.0906)	loss 2.5011 (2.4654)	grad_norm 0.5057 (0.5110)	mem 39782MB
[2023-07-07 16:26:24 RepVGG-A0] (main.py 282): INFO Train: [237/300][50/78]	eta 0:00:55 lr 0.658395	time 1.1754 (1.9753)	loss 2.5135 (2.4686)	grad_norm 0.5189 (0.5121)	mem 39782MB
[2023-07-07 16:26:39 RepVGG-A0] (main.py 282): INFO Train: [237/300][60/78]	eta 0:00:34 lr 0.655787	time 1.2917 (1.9046)	loss 2.5147 (2.4737)	grad_norm 0.5117 (0.5155)	mem 39782MB
[2023-07-07 16:26:54 RepVGG-A0] (main.py 282): INFO Train: [237/300][70/78]	eta 0:00:14 lr 0.653184	time 1.1256 (1.8425)	loss 2.4295 (2.4746)	grad_norm 0.4989 (0.5149)	mem 39782MB
[2023-07-07 16:27:06 RepVGG-A0] (main.py 291): INFO EPOCH 237 training takes 0:02:23
[2023-07-07 16:27:27 RepVGG-A0] (main.py 282): INFO Train: [238/300][0/78]	eta 0:27:09 lr 0.651104	time 20.8936 (20.8936)	loss 2.3856 (2.3856)	grad_norm 0.5201 (0.5201)	mem 39782MB
[2023-07-07 16:27:43 RepVGG-A0] (main.py 282): INFO Train: [238/300][10/78]	eta 0:03:48 lr 0.648509	time 1.1715 (3.3661)	loss 2.4546 (2.4357)	grad_norm 0.5409 (0.5316)	mem 39782MB
[2023-07-07 16:27:58 RepVGG-A0] (main.py 282): INFO Train: [238/300][20/78]	eta 0:02:21 lr 0.645919	time 1.2400 (2.4364)	loss 2.4699 (2.4457)	grad_norm 0.5059 (0.5210)	mem 39782MB
[2023-07-07 16:28:12 RepVGG-A0] (main.py 282): INFO Train: [238/300][30/78]	eta 0:01:42 lr 0.643333	time 1.1775 (2.1261)	loss 2.4515 (2.4530)	grad_norm 0.5094 (0.5194)	mem 39782MB
[2023-07-07 16:28:29 RepVGG-A0] (main.py 282): INFO Train: [238/300][40/78]	eta 0:01:16 lr 0.640751	time 1.8152 (2.0232)	loss 2.4902 (2.4553)	grad_norm 0.5411 (0.5217)	mem 39782MB
[2023-07-07 16:28:46 RepVGG-A0] (main.py 282): INFO Train: [238/300][50/78]	eta 0:00:54 lr 0.638174	time 1.1831 (1.9458)	loss 2.4324 (2.4583)	grad_norm 0.5207 (0.5190)	mem 39782MB
[2023-07-07 16:29:01 RepVGG-A0] (main.py 282): INFO Train: [238/300][60/78]	eta 0:00:33 lr 0.635602	time 1.1737 (1.8781)	loss 2.4819 (2.4647)	grad_norm 0.5533 (0.5213)	mem 39782MB
[2023-07-07 16:29:17 RepVGG-A0] (main.py 282): INFO Train: [238/300][70/78]	eta 0:00:14 lr 0.633035	time 1.2465 (1.8426)	loss 2.5336 (2.4657)	grad_norm 0.5158 (0.5216)	mem 39782MB
[2023-07-07 16:29:31 RepVGG-A0] (main.py 291): INFO EPOCH 238 training takes 0:02:24
[2023-07-07 16:29:50 RepVGG-A0] (main.py 282): INFO Train: [239/300][0/78]	eta 0:25:37 lr 0.630984	time 19.7112 (19.7112)	loss 2.4338 (2.4338)	grad_norm 0.5044 (0.5044)	mem 39782MB
[2023-07-07 16:30:08 RepVGG-A0] (main.py 282): INFO Train: [239/300][10/78]	eta 0:03:49 lr 0.628425	time 1.1725 (3.3810)	loss 2.4428 (2.4335)	grad_norm 0.5167 (0.5076)	mem 39782MB
[2023-07-07 16:30:22 RepVGG-A0] (main.py 282): INFO Train: [239/300][20/78]	eta 0:02:22 lr 0.625870	time 1.1723 (2.4557)	loss 2.4116 (2.4291)	grad_norm 0.5082 (0.5065)	mem 39782MB
[2023-07-07 16:30:37 RepVGG-A0] (main.py 282): INFO Train: [239/300][30/78]	eta 0:01:42 lr 0.623320	time 1.2695 (2.1434)	loss 2.3492 (2.4377)	grad_norm 0.5131 (0.5116)	mem 39782MB
[2023-07-07 16:30:52 RepVGG-A0] (main.py 282): INFO Train: [239/300][40/78]	eta 0:01:15 lr 0.620775	time 1.4112 (1.9883)	loss 2.5383 (2.4401)	grad_norm 0.5239 (0.5122)	mem 39782MB
[2023-07-07 16:31:09 RepVGG-A0] (main.py 282): INFO Train: [239/300][50/78]	eta 0:00:54 lr 0.618235	time 1.3621 (1.9298)	loss 2.4436 (2.4449)	grad_norm 0.5131 (0.5181)	mem 39782MB
[2023-07-07 16:31:24 RepVGG-A0] (main.py 282): INFO Train: [239/300][60/78]	eta 0:00:33 lr 0.615699	time 1.1741 (1.8615)	loss 2.4317 (2.4478)	grad_norm 0.5130 (0.5182)	mem 39782MB
[2023-07-07 16:31:39 RepVGG-A0] (main.py 282): INFO Train: [239/300][70/78]	eta 0:00:14 lr 0.613167	time 1.2010 (1.8129)	loss 2.4660 (2.4520)	grad_norm 0.5155 (0.5188)	mem 39782MB
[2023-07-07 16:31:52 RepVGG-A0] (main.py 291): INFO EPOCH 239 training takes 0:02:21
[2023-07-07 16:32:13 RepVGG-A0] (main.py 282): INFO Train: [240/300][0/78]	eta 0:27:41 lr 0.611146	time 21.2978 (21.2978)	loss 2.4609 (2.4609)	grad_norm 0.5347 (0.5347)	mem 39782MB
[2023-07-07 16:32:27 RepVGG-A0] (main.py 282): INFO Train: [240/300][10/78]	eta 0:03:39 lr 0.608623	time 1.1905 (3.2281)	loss 2.5140 (2.4376)	grad_norm 0.5065 (0.5107)	mem 39782MB
[2023-07-07 16:32:42 RepVGG-A0] (main.py 282): INFO Train: [240/300][20/78]	eta 0:02:17 lr 0.606104	time 1.1929 (2.3677)	loss 2.4312 (2.4345)	grad_norm 0.5195 (0.5150)	mem 39782MB
[2023-07-07 16:32:57 RepVGG-A0] (main.py 282): INFO Train: [240/300][30/78]	eta 0:01:40 lr 0.603591	time 1.1755 (2.0858)	loss 2.4961 (2.4466)	grad_norm 0.5357 (0.5225)	mem 39782MB
[2023-07-07 16:33:15 RepVGG-A0] (main.py 282): INFO Train: [240/300][40/78]	eta 0:01:17 lr 0.601082	time 4.0789 (2.0265)	loss 2.4279 (2.4459)	grad_norm 0.5102 (0.5195)	mem 39782MB
[2023-07-07 16:33:30 RepVGG-A0] (main.py 282): INFO Train: [240/300][50/78]	eta 0:00:53 lr 0.598578	time 1.1713 (1.9228)	loss 2.4003 (2.4480)	grad_norm 0.5417 (0.5226)	mem 39782MB
[2023-07-07 16:33:45 RepVGG-A0] (main.py 282): INFO Train: [240/300][60/78]	eta 0:00:33 lr 0.596078	time 1.1669 (1.8555)	loss 2.4504 (2.4539)	grad_norm 0.5251 (0.5232)	mem 39782MB
[2023-07-07 16:34:01 RepVGG-A0] (main.py 282): INFO Train: [240/300][70/78]	eta 0:00:14 lr 0.593584	time 1.5252 (1.8118)	loss 2.4005 (2.4547)	grad_norm 0.5203 (0.5220)	mem 39782MB
[2023-07-07 16:34:12 RepVGG-A0] (main.py 291): INFO EPOCH 240 training takes 0:02:20
[2023-07-07 16:34:29 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.511 (17.511)	Loss 1.6567 (1.6567)	Acc@1 63.867 (63.867)	Acc@5 85.229 (85.229)	Mem 39782MB
[2023-07-07 16:34:31 RepVGG-A0] (main.py 342): INFO  * Acc@1 63.708 Acc@5 85.256
[2023-07-07 16:34:31 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 240: 63.708%
[2023-07-07 16:34:31 RepVGG-A0] (main.py 172): INFO Max accuracy: 63.71%
[2023-07-07 16:34:53 RepVGG-A0] (main.py 282): INFO Train: [241/300][0/78]	eta 0:28:56 lr 0.591591	time 22.2646 (22.2646)	loss 2.4148 (2.4148)	grad_norm 0.5200 (0.5200)	mem 39782MB
[2023-07-07 16:35:09 RepVGG-A0] (main.py 282): INFO Train: [241/300][10/78]	eta 0:03:55 lr 0.589105	time 1.1932 (3.4572)	loss 2.4160 (2.4260)	grad_norm 0.5386 (0.5268)	mem 39782MB
[2023-07-07 16:35:23 RepVGG-A0] (main.py 282): INFO Train: [241/300][20/78]	eta 0:02:23 lr 0.586623	time 1.2897 (2.4814)	loss 2.4126 (2.4267)	grad_norm 0.5181 (0.5230)	mem 39782MB
[2023-07-07 16:35:38 RepVGG-A0] (main.py 282): INFO Train: [241/300][30/78]	eta 0:01:44 lr 0.584146	time 1.6217 (2.1754)	loss 2.4659 (2.4323)	grad_norm 0.5373 (0.5264)	mem 39782MB
[2023-07-07 16:35:56 RepVGG-A0] (main.py 282): INFO Train: [241/300][40/78]	eta 0:01:18 lr 0.581674	time 2.9030 (2.0756)	loss 2.3977 (2.4320)	grad_norm 0.5300 (0.5295)	mem 39782MB
[2023-07-07 16:36:11 RepVGG-A0] (main.py 282): INFO Train: [241/300][50/78]	eta 0:00:54 lr 0.579206	time 1.1802 (1.9623)	loss 2.4153 (2.4356)	grad_norm 0.5122 (0.5267)	mem 39782MB
[2023-07-07 16:36:26 RepVGG-A0] (main.py 282): INFO Train: [241/300][60/78]	eta 0:00:34 lr 0.576744	time 1.3102 (1.8917)	loss 2.4709 (2.4353)	grad_norm 0.5366 (0.5284)	mem 39782MB
[2023-07-07 16:36:41 RepVGG-A0] (main.py 282): INFO Train: [241/300][70/78]	eta 0:00:14 lr 0.574286	time 1.2560 (1.8377)	loss 2.4253 (2.4387)	grad_norm 0.5246 (0.5284)	mem 39782MB
[2023-07-07 16:36:53 RepVGG-A0] (main.py 291): INFO EPOCH 241 training takes 0:02:22
[2023-07-07 16:37:15 RepVGG-A0] (main.py 282): INFO Train: [242/300][0/78]	eta 0:29:01 lr 0.572323	time 22.3298 (22.3298)	loss 2.4096 (2.4096)	grad_norm 0.4983 (0.4983)	mem 39782MB
[2023-07-07 16:37:30 RepVGG-A0] (main.py 282): INFO Train: [242/300][10/78]	eta 0:03:48 lr 0.569873	time 1.1712 (3.3646)	loss 2.4459 (2.3972)	grad_norm 0.5256 (0.5114)	mem 39782MB
[2023-07-07 16:37:45 RepVGG-A0] (main.py 282): INFO Train: [242/300][20/78]	eta 0:02:24 lr 0.567428	time 1.1817 (2.4979)	loss 2.4521 (2.4118)	grad_norm 0.5348 (0.5161)	mem 39782MB
[2023-07-07 16:38:00 RepVGG-A0] (main.py 282): INFO Train: [242/300][30/78]	eta 0:01:43 lr 0.564988	time 1.1866 (2.1586)	loss 2.4214 (2.4224)	grad_norm 0.5473 (0.5234)	mem 39782MB
[2023-07-07 16:38:17 RepVGG-A0] (main.py 282): INFO Train: [242/300][40/78]	eta 0:01:18 lr 0.562553	time 2.9804 (2.0627)	loss 2.4859 (2.4291)	grad_norm 0.5147 (0.5238)	mem 39782MB
[2023-07-07 16:38:33 RepVGG-A0] (main.py 282): INFO Train: [242/300][50/78]	eta 0:00:54 lr 0.560122	time 1.2638 (1.9544)	loss 2.4101 (2.4336)	grad_norm 0.5428 (0.5256)	mem 39782MB
[2023-07-07 16:38:47 RepVGG-A0] (main.py 282): INFO Train: [242/300][60/78]	eta 0:00:33 lr 0.557697	time 1.1719 (1.8779)	loss 2.4967 (2.4346)	grad_norm 0.5336 (0.5258)	mem 39782MB
[2023-07-07 16:39:03 RepVGG-A0] (main.py 282): INFO Train: [242/300][70/78]	eta 0:00:14 lr 0.555276	time 1.3417 (1.8267)	loss 2.3795 (2.4336)	grad_norm 0.5259 (0.5274)	mem 39782MB
[2023-07-07 16:39:15 RepVGG-A0] (main.py 291): INFO EPOCH 242 training takes 0:02:21
[2023-07-07 16:39:37 RepVGG-A0] (main.py 282): INFO Train: [243/300][0/78]	eta 0:28:57 lr 0.553342	time 22.2779 (22.2779)	loss 2.4170 (2.4170)	grad_norm 0.5264 (0.5264)	mem 39782MB
[2023-07-07 16:39:51 RepVGG-A0] (main.py 282): INFO Train: [243/300][10/78]	eta 0:03:45 lr 0.550930	time 1.1731 (3.3219)	loss 2.4333 (2.4212)	grad_norm 0.5474 (0.5210)	mem 39782MB
[2023-07-07 16:40:06 RepVGG-A0] (main.py 282): INFO Train: [243/300][20/78]	eta 0:02:21 lr 0.548522	time 1.1731 (2.4449)	loss 2.4712 (2.4207)	grad_norm 0.5586 (0.5246)	mem 39782MB
[2023-07-07 16:40:21 RepVGG-A0] (main.py 282): INFO Train: [243/300][30/78]	eta 0:01:42 lr 0.546119	time 1.3513 (2.1453)	loss 2.4448 (2.4259)	grad_norm 0.5263 (0.5280)	mem 39782MB
[2023-07-07 16:40:39 RepVGG-A0] (main.py 282): INFO Train: [243/300][40/78]	eta 0:01:18 lr 0.543721	time 4.4363 (2.0694)	loss 2.4999 (2.4334)	grad_norm 0.5355 (0.5277)	mem 39782MB
[2023-07-07 16:40:54 RepVGG-A0] (main.py 282): INFO Train: [243/300][50/78]	eta 0:00:54 lr 0.541328	time 1.1926 (1.9484)	loss 2.5116 (2.4358)	grad_norm 0.5468 (0.5269)	mem 39782MB
[2023-07-07 16:41:09 RepVGG-A0] (main.py 282): INFO Train: [243/300][60/78]	eta 0:00:33 lr 0.538939	time 1.1922 (1.8797)	loss 2.4673 (2.4406)	grad_norm 0.5250 (0.5287)	mem 39782MB
[2023-07-07 16:41:25 RepVGG-A0] (main.py 282): INFO Train: [243/300][70/78]	eta 0:00:14 lr 0.536556	time 1.2539 (1.8329)	loss 2.4553 (2.4431)	grad_norm 0.5215 (0.5294)	mem 39782MB
[2023-07-07 16:41:36 RepVGG-A0] (main.py 291): INFO EPOCH 243 training takes 0:02:21
[2023-07-07 16:41:58 RepVGG-A0] (main.py 282): INFO Train: [244/300][0/78]	eta 0:28:03 lr 0.534652	time 21.5818 (21.5818)	loss 2.4339 (2.4339)	grad_norm 0.5363 (0.5363)	mem 39782MB
[2023-07-07 16:42:12 RepVGG-A0] (main.py 282): INFO Train: [244/300][10/78]	eta 0:03:41 lr 0.532277	time 1.1729 (3.2609)	loss 2.4202 (2.4129)	grad_norm 0.5216 (0.5318)	mem 39782MB
[2023-07-07 16:42:27 RepVGG-A0] (main.py 282): INFO Train: [244/300][20/78]	eta 0:02:20 lr 0.529907	time 1.3115 (2.4143)	loss 2.4551 (2.4254)	grad_norm 0.5616 (0.5337)	mem 39782MB
[2023-07-07 16:42:43 RepVGG-A0] (main.py 282): INFO Train: [244/300][30/78]	eta 0:01:43 lr 0.527541	time 1.4480 (2.1536)	loss 2.4581 (2.4213)	grad_norm 0.5230 (0.5312)	mem 39782MB
[2023-07-07 16:43:01 RepVGG-A0] (main.py 282): INFO Train: [244/300][40/78]	eta 0:01:18 lr 0.525181	time 3.7175 (2.0569)	loss 2.4030 (2.4184)	grad_norm 0.5274 (0.5338)	mem 39782MB
[2023-07-07 16:43:17 RepVGG-A0] (main.py 282): INFO Train: [244/300][50/78]	eta 0:00:55 lr 0.522825	time 1.3602 (1.9671)	loss 2.4193 (2.4241)	grad_norm 0.5291 (0.5338)	mem 39782MB
[2023-07-07 16:43:32 RepVGG-A0] (main.py 282): INFO Train: [244/300][60/78]	eta 0:00:34 lr 0.520474	time 1.4233 (1.9001)	loss 2.4788 (2.4243)	grad_norm 0.5210 (0.5318)	mem 39782MB
[2023-07-07 16:43:47 RepVGG-A0] (main.py 282): INFO Train: [244/300][70/78]	eta 0:00:14 lr 0.518128	time 1.3698 (1.8451)	loss 2.4091 (2.4277)	grad_norm 0.5280 (0.5313)	mem 39782MB
[2023-07-07 16:43:58 RepVGG-A0] (main.py 291): INFO EPOCH 244 training takes 0:02:22
[2023-07-07 16:44:20 RepVGG-A0] (main.py 282): INFO Train: [245/300][0/78]	eta 0:27:44 lr 0.516254	time 21.3422 (21.3422)	loss 2.4149 (2.4149)	grad_norm 0.5272 (0.5272)	mem 39782MB
[2023-07-07 16:44:35 RepVGG-A0] (main.py 282): INFO Train: [245/300][10/78]	eta 0:03:46 lr 0.513917	time 1.1722 (3.3317)	loss 2.4600 (2.3906)	grad_norm 0.5456 (0.5333)	mem 39782MB
[2023-07-07 16:44:49 RepVGG-A0] (main.py 282): INFO Train: [245/300][20/78]	eta 0:02:20 lr 0.511584	time 1.1724 (2.4211)	loss 2.4405 (2.4002)	grad_norm 0.5279 (0.5315)	mem 39782MB
[2023-07-07 16:45:05 RepVGG-A0] (main.py 282): INFO Train: [245/300][30/78]	eta 0:01:42 lr 0.509256	time 1.2488 (2.1457)	loss 2.4644 (2.4111)	grad_norm 0.5196 (0.5296)	mem 39782MB
[2023-07-07 16:45:24 RepVGG-A0] (main.py 282): INFO Train: [245/300][40/78]	eta 0:01:19 lr 0.506933	time 4.6062 (2.0863)	loss 2.4669 (2.4134)	grad_norm 0.5629 (0.5344)	mem 39782MB
[2023-07-07 16:45:38 RepVGG-A0] (main.py 282): INFO Train: [245/300][50/78]	eta 0:00:54 lr 0.504615	time 1.1813 (1.9558)	loss 2.4710 (2.4148)	grad_norm 0.5365 (0.5367)	mem 39782MB
[2023-07-07 16:45:54 RepVGG-A0] (main.py 282): INFO Train: [245/300][60/78]	eta 0:00:34 lr 0.502302	time 1.3715 (1.8896)	loss 2.4310 (2.4202)	grad_norm 0.5408 (0.5354)	mem 39782MB
[2023-07-07 16:46:09 RepVGG-A0] (main.py 282): INFO Train: [245/300][70/78]	eta 0:00:14 lr 0.499994	time 1.2049 (1.8426)	loss 2.3953 (2.4212)	grad_norm 0.5221 (0.5342)	mem 39782MB
[2023-07-07 16:46:20 RepVGG-A0] (main.py 291): INFO EPOCH 245 training takes 0:02:21
[2023-07-07 16:46:40 RepVGG-A0] (main.py 282): INFO Train: [246/300][0/78]	eta 0:27:00 lr 0.498151	time 20.7719 (20.7719)	loss 2.3735 (2.3735)	grad_norm 0.5154 (0.5154)	mem 39782MB
[2023-07-07 16:46:56 RepVGG-A0] (main.py 282): INFO Train: [246/300][10/78]	eta 0:03:41 lr 0.495851	time 1.1741 (3.2635)	loss 2.3674 (2.3964)	grad_norm 0.5220 (0.5350)	mem 39782MB
[2023-07-07 16:47:10 RepVGG-A0] (main.py 282): INFO Train: [246/300][20/78]	eta 0:02:19 lr 0.493556	time 1.1739 (2.4026)	loss 2.4591 (2.4020)	grad_norm 0.5343 (0.5351)	mem 39782MB
[2023-07-07 16:47:25 RepVGG-A0] (main.py 282): INFO Train: [246/300][30/78]	eta 0:01:41 lr 0.491267	time 1.2800 (2.1108)	loss 2.3934 (2.4065)	grad_norm 0.5511 (0.5362)	mem 39782MB
[2023-07-07 16:47:44 RepVGG-A0] (main.py 282): INFO Train: [246/300][40/78]	eta 0:01:17 lr 0.488982	time 4.3058 (2.0491)	loss 2.4120 (2.4110)	grad_norm 0.5395 (0.5391)	mem 39782MB
[2023-07-07 16:47:59 RepVGG-A0] (main.py 282): INFO Train: [246/300][50/78]	eta 0:00:54 lr 0.486702	time 1.1942 (1.9461)	loss 2.3904 (2.4107)	grad_norm 0.5357 (0.5385)	mem 39782MB
[2023-07-07 16:48:14 RepVGG-A0] (main.py 282): INFO Train: [246/300][60/78]	eta 0:00:33 lr 0.484426	time 1.4013 (1.8749)	loss 2.4319 (2.4129)	grad_norm 0.5322 (0.5378)	mem 39782MB
[2023-07-07 16:48:30 RepVGG-A0] (main.py 282): INFO Train: [246/300][70/78]	eta 0:00:14 lr 0.482156	time 1.3642 (1.8336)	loss 2.3772 (2.4115)	grad_norm 0.5437 (0.5383)	mem 39782MB
[2023-07-07 16:48:42 RepVGG-A0] (main.py 291): INFO EPOCH 246 training takes 0:02:22
[2023-07-07 16:49:04 RepVGG-A0] (main.py 282): INFO Train: [247/300][0/78]	eta 0:27:58 lr 0.480343	time 21.5255 (21.5255)	loss 2.3956 (2.3956)	grad_norm 0.5318 (0.5318)	mem 39782MB
[2023-07-07 16:49:19 RepVGG-A0] (main.py 282): INFO Train: [247/300][10/78]	eta 0:03:45 lr 0.478082	time 1.1737 (3.3217)	loss 2.4300 (2.3926)	grad_norm 0.5305 (0.5308)	mem 39782MB
[2023-07-07 16:49:33 RepVGG-A0] (main.py 282): INFO Train: [247/300][20/78]	eta 0:02:20 lr 0.475825	time 1.1862 (2.4267)	loss 2.4366 (2.3949)	grad_norm 0.5342 (0.5354)	mem 39782MB
[2023-07-07 16:49:49 RepVGG-A0] (main.py 282): INFO Train: [247/300][30/78]	eta 0:01:42 lr 0.473574	time 1.4503 (2.1440)	loss 2.4022 (2.3931)	grad_norm 0.5426 (0.5353)	mem 39782MB
[2023-07-07 16:50:06 RepVGG-A0] (main.py 282): INFO Train: [247/300][40/78]	eta 0:01:17 lr 0.471327	time 3.2119 (2.0426)	loss 2.4156 (2.3975)	grad_norm 0.5285 (0.5371)	mem 39782MB
[2023-07-07 16:50:21 RepVGG-A0] (main.py 282): INFO Train: [247/300][50/78]	eta 0:00:54 lr 0.469085	time 1.2953 (1.9352)	loss 2.4295 (2.4003)	grad_norm 0.5415 (0.5373)	mem 39782MB
[2023-07-07 16:50:36 RepVGG-A0] (main.py 282): INFO Train: [247/300][60/78]	eta 0:00:33 lr 0.466848	time 1.2425 (1.8734)	loss 2.4048 (2.4004)	grad_norm 0.5326 (0.5376)	mem 39782MB
[2023-07-07 16:50:52 RepVGG-A0] (main.py 282): INFO Train: [247/300][70/78]	eta 0:00:14 lr 0.464616	time 1.2644 (1.8225)	loss 2.3788 (2.4025)	grad_norm 0.5408 (0.5387)	mem 39782MB
[2023-07-07 16:51:03 RepVGG-A0] (main.py 291): INFO EPOCH 247 training takes 0:02:21
[2023-07-07 16:51:25 RepVGG-A0] (main.py 282): INFO Train: [248/300][0/78]	eta 0:28:19 lr 0.462834	time 21.7866 (21.7866)	loss 2.4014 (2.4014)	grad_norm 0.5286 (0.5286)	mem 39782MB
[2023-07-07 16:51:40 RepVGG-A0] (main.py 282): INFO Train: [248/300][10/78]	eta 0:03:48 lr 0.460611	time 1.1708 (3.3652)	loss 2.3644 (2.3694)	grad_norm 0.5408 (0.5415)	mem 39782MB
[2023-07-07 16:51:56 RepVGG-A0] (main.py 282): INFO Train: [248/300][20/78]	eta 0:02:23 lr 0.458393	time 1.2873 (2.4825)	loss 2.3248 (2.3694)	grad_norm 0.5374 (0.5391)	mem 39782MB
[2023-07-07 16:52:11 RepVGG-A0] (main.py 282): INFO Train: [248/300][30/78]	eta 0:01:43 lr 0.456180	time 1.7528 (2.1664)	loss 2.3711 (2.3786)	grad_norm 0.5345 (0.5420)	mem 39782MB
[2023-07-07 16:52:28 RepVGG-A0] (main.py 282): INFO Train: [248/300][40/78]	eta 0:01:18 lr 0.453972	time 3.8445 (2.0684)	loss 2.4202 (2.3849)	grad_norm 0.5308 (0.5417)	mem 39782MB
[2023-07-07 16:52:44 RepVGG-A0] (main.py 282): INFO Train: [248/300][50/78]	eta 0:00:54 lr 0.451768	time 1.1721 (1.9620)	loss 2.4285 (2.3879)	grad_norm 0.5242 (0.5407)	mem 39782MB
[2023-07-07 16:52:59 RepVGG-A0] (main.py 282): INFO Train: [248/300][60/78]	eta 0:00:34 lr 0.449570	time 1.6133 (1.9008)	loss 2.3758 (2.3940)	grad_norm 0.5247 (0.5394)	mem 39782MB
[2023-07-07 16:53:14 RepVGG-A0] (main.py 282): INFO Train: [248/300][70/78]	eta 0:00:14 lr 0.447377	time 1.1264 (1.8344)	loss 2.4305 (2.3957)	grad_norm 0.5516 (0.5400)	mem 39782MB
[2023-07-07 16:53:25 RepVGG-A0] (main.py 291): INFO EPOCH 248 training takes 0:02:21
[2023-07-07 16:53:47 RepVGG-A0] (main.py 282): INFO Train: [249/300][0/78]	eta 0:28:21 lr 0.445626	time 21.8195 (21.8195)	loss 2.3567 (2.3567)	grad_norm 0.5415 (0.5415)	mem 39782MB
[2023-07-07 16:54:03 RepVGG-A0] (main.py 282): INFO Train: [249/300][10/78]	eta 0:03:53 lr 0.443441	time 1.1705 (3.4322)	loss 2.3938 (2.3639)	grad_norm 0.5613 (0.5463)	mem 39782MB
[2023-07-07 16:54:19 RepVGG-A0] (main.py 282): INFO Train: [249/300][20/78]	eta 0:02:26 lr 0.441262	time 1.3163 (2.5326)	loss 2.3536 (2.3697)	grad_norm 0.5299 (0.5436)	mem 39782MB
[2023-07-07 16:54:33 RepVGG-A0] (main.py 282): INFO Train: [249/300][30/78]	eta 0:01:44 lr 0.439087	time 1.2700 (2.1761)	loss 2.3865 (2.3719)	grad_norm 0.5466 (0.5423)	mem 39782MB
[2023-07-07 16:54:52 RepVGG-A0] (main.py 282): INFO Train: [249/300][40/78]	eta 0:01:20 lr 0.436918	time 3.5693 (2.1108)	loss 2.3469 (2.3783)	grad_norm 0.5560 (0.5440)	mem 39782MB
[2023-07-07 16:55:07 RepVGG-A0] (main.py 282): INFO Train: [249/300][50/78]	eta 0:00:55 lr 0.434753	time 1.1746 (1.9910)	loss 2.3437 (2.3818)	grad_norm 0.5436 (0.5435)	mem 39782MB
[2023-07-07 16:55:23 RepVGG-A0] (main.py 282): INFO Train: [249/300][60/78]	eta 0:00:34 lr 0.432593	time 1.2868 (1.9252)	loss 2.4097 (2.3865)	grad_norm 0.5453 (0.5442)	mem 39782MB
[2023-07-07 16:55:37 RepVGG-A0] (main.py 282): INFO Train: [249/300][70/78]	eta 0:00:14 lr 0.430439	time 1.4858 (1.8613)	loss 2.3756 (2.3900)	grad_norm 0.5415 (0.5455)	mem 39782MB
[2023-07-07 16:55:49 RepVGG-A0] (main.py 291): INFO EPOCH 249 training takes 0:02:23
[2023-07-07 16:56:12 RepVGG-A0] (main.py 282): INFO Train: [250/300][0/78]	eta 0:29:06 lr 0.428719	time 22.3847 (22.3847)	loss 2.3569 (2.3569)	grad_norm 0.5473 (0.5473)	mem 39782MB
[2023-07-07 16:56:25 RepVGG-A0] (main.py 282): INFO Train: [250/300][10/78]	eta 0:03:43 lr 0.426573	time 1.1723 (3.2836)	loss 2.3901 (2.3635)	grad_norm 0.5381 (0.5453)	mem 39782MB
[2023-07-07 16:56:41 RepVGG-A0] (main.py 282): INFO Train: [250/300][20/78]	eta 0:02:24 lr 0.424433	time 1.3852 (2.4915)	loss 2.3642 (2.3623)	grad_norm 0.5433 (0.5451)	mem 39782MB
[2023-07-07 16:56:56 RepVGG-A0] (main.py 282): INFO Train: [250/300][30/78]	eta 0:01:43 lr 0.422297	time 1.6865 (2.1568)	loss 2.3978 (2.3659)	grad_norm 0.5434 (0.5436)	mem 39782MB
[2023-07-07 16:57:13 RepVGG-A0] (main.py 282): INFO Train: [250/300][40/78]	eta 0:01:17 lr 0.420166	time 3.5302 (2.0480)	loss 2.4091 (2.3664)	grad_norm 0.5405 (0.5441)	mem 39782MB
[2023-07-07 16:57:28 RepVGG-A0] (main.py 282): INFO Train: [250/300][50/78]	eta 0:00:54 lr 0.418041	time 1.2916 (1.9436)	loss 2.4027 (2.3722)	grad_norm 0.5372 (0.5442)	mem 39782MB
[2023-07-07 16:57:44 RepVGG-A0] (main.py 282): INFO Train: [250/300][60/78]	eta 0:00:33 lr 0.415920	time 1.2936 (1.8767)	loss 2.3491 (2.3765)	grad_norm 0.5433 (0.5445)	mem 39782MB
[2023-07-07 16:57:58 RepVGG-A0] (main.py 282): INFO Train: [250/300][70/78]	eta 0:00:14 lr 0.413805	time 1.1275 (1.8208)	loss 2.4203 (2.3813)	grad_norm 0.5415 (0.5441)	mem 39782MB
[2023-07-07 16:58:10 RepVGG-A0] (main.py 291): INFO EPOCH 250 training takes 0:02:21
[2023-07-07 16:58:33 RepVGG-A0] (main.py 282): INFO Train: [251/300][0/78]	eta 0:29:23 lr 0.412116	time 22.6030 (22.6030)	loss 2.3602 (2.3602)	grad_norm 0.5354 (0.5354)	mem 39782MB
[2023-07-07 16:58:47 RepVGG-A0] (main.py 282): INFO Train: [251/300][10/78]	eta 0:03:47 lr 0.410009	time 1.1721 (3.3429)	loss 2.3955 (2.3664)	grad_norm 0.5519 (0.5437)	mem 39782MB
[2023-07-07 16:59:03 RepVGG-A0] (main.py 282): INFO Train: [251/300][20/78]	eta 0:02:25 lr 0.407908	time 1.1960 (2.5054)	loss 2.3363 (2.3652)	grad_norm 0.5602 (0.5462)	mem 39782MB
[2023-07-07 16:59:17 RepVGG-A0] (main.py 282): INFO Train: [251/300][30/78]	eta 0:01:44 lr 0.405811	time 1.3669 (2.1688)	loss 2.3143 (2.3708)	grad_norm 0.5405 (0.5464)	mem 39782MB
[2023-07-07 16:59:35 RepVGG-A0] (main.py 282): INFO Train: [251/300][40/78]	eta 0:01:18 lr 0.403720	time 3.8060 (2.0596)	loss 2.3628 (2.3730)	grad_norm 0.5541 (0.5469)	mem 39782MB
[2023-07-07 16:59:50 RepVGG-A0] (main.py 282): INFO Train: [251/300][50/78]	eta 0:00:54 lr 0.401634	time 1.2717 (1.9573)	loss 2.3950 (2.3722)	grad_norm 0.5494 (0.5473)	mem 39782MB
[2023-07-07 17:00:06 RepVGG-A0] (main.py 282): INFO Train: [251/300][60/78]	eta 0:00:34 lr 0.399552	time 1.1944 (1.8899)	loss 2.4173 (2.3756)	grad_norm 0.5450 (0.5477)	mem 39782MB
[2023-07-07 17:00:20 RepVGG-A0] (main.py 282): INFO Train: [251/300][70/78]	eta 0:00:14 lr 0.397476	time 1.2456 (1.8305)	loss 2.3796 (2.3778)	grad_norm 0.5406 (0.5481)	mem 39782MB
[2023-07-07 17:00:32 RepVGG-A0] (main.py 291): INFO EPOCH 251 training takes 0:02:21
[2023-07-07 17:00:54 RepVGG-A0] (main.py 282): INFO Train: [252/300][0/78]	eta 0:28:29 lr 0.395819	time 21.9141 (21.9141)	loss 2.3768 (2.3768)	grad_norm 0.5385 (0.5385)	mem 39782MB
[2023-07-07 17:01:10 RepVGG-A0] (main.py 282): INFO Train: [252/300][10/78]	eta 0:03:54 lr 0.393751	time 1.1738 (3.4544)	loss 2.2995 (2.3546)	grad_norm 0.5492 (0.5555)	mem 39782MB
[2023-07-07 17:01:25 RepVGG-A0] (main.py 282): INFO Train: [252/300][20/78]	eta 0:02:27 lr 0.391689	time 1.2794 (2.5432)	loss 2.4034 (2.3588)	grad_norm 0.5463 (0.5476)	mem 39782MB
[2023-07-07 17:01:41 RepVGG-A0] (main.py 282): INFO Train: [252/300][30/78]	eta 0:01:46 lr 0.389632	time 1.3782 (2.2206)	loss 2.3211 (2.3582)	grad_norm 0.5640 (0.5487)	mem 39782MB
[2023-07-07 17:01:58 RepVGG-A0] (main.py 282): INFO Train: [252/300][40/78]	eta 0:01:19 lr 0.387580	time 2.4838 (2.0997)	loss 2.2850 (2.3590)	grad_norm 0.5449 (0.5482)	mem 39782MB
[2023-07-07 17:02:14 RepVGG-A0] (main.py 282): INFO Train: [252/300][50/78]	eta 0:00:55 lr 0.385533	time 1.1924 (1.9899)	loss 2.3939 (2.3630)	grad_norm 0.5438 (0.5501)	mem 39782MB
[2023-07-07 17:02:29 RepVGG-A0] (main.py 282): INFO Train: [252/300][60/78]	eta 0:00:34 lr 0.383491	time 1.4799 (1.9157)	loss 2.4031 (2.3653)	grad_norm 0.5508 (0.5500)	mem 39782MB
[2023-07-07 17:02:44 RepVGG-A0] (main.py 282): INFO Train: [252/300][70/78]	eta 0:00:14 lr 0.381455	time 1.4122 (1.8608)	loss 2.3881 (2.3660)	grad_norm 0.5554 (0.5510)	mem 39782MB
[2023-07-07 17:02:56 RepVGG-A0] (main.py 291): INFO EPOCH 252 training takes 0:02:23
[2023-07-07 17:03:18 RepVGG-A0] (main.py 282): INFO Train: [253/300][0/78]	eta 0:28:53 lr 0.379829	time 22.2205 (22.2205)	loss 2.3623 (2.3623)	grad_norm 0.5560 (0.5560)	mem 39782MB
[2023-07-07 17:03:33 RepVGG-A0] (main.py 282): INFO Train: [253/300][10/78]	eta 0:03:51 lr 0.377801	time 1.1915 (3.4058)	loss 2.3795 (2.3447)	grad_norm 0.5352 (0.5418)	mem 39782MB
[2023-07-07 17:03:48 RepVGG-A0] (main.py 282): INFO Train: [253/300][20/78]	eta 0:02:24 lr 0.375779	time 1.3390 (2.4878)	loss 2.3688 (2.3462)	grad_norm 0.5387 (0.5432)	mem 39782MB
[2023-07-07 17:04:04 RepVGG-A0] (main.py 282): INFO Train: [253/300][30/78]	eta 0:01:45 lr 0.373761	time 1.8404 (2.2009)	loss 2.4512 (2.3536)	grad_norm 0.5472 (0.5463)	mem 39782MB
[2023-07-07 17:04:22 RepVGG-A0] (main.py 282): INFO Train: [253/300][40/78]	eta 0:01:20 lr 0.371749	time 2.8991 (2.1071)	loss 2.3722 (2.3590)	grad_norm 0.5497 (0.5491)	mem 39782MB
[2023-07-07 17:04:36 RepVGG-A0] (main.py 282): INFO Train: [253/300][50/78]	eta 0:00:55 lr 0.369742	time 1.1726 (1.9723)	loss 2.3480 (2.3615)	grad_norm 0.5633 (0.5515)	mem 39782MB
[2023-07-07 17:04:52 RepVGG-A0] (main.py 282): INFO Train: [253/300][60/78]	eta 0:00:34 lr 0.367740	time 1.3255 (1.9096)	loss 2.3482 (2.3617)	grad_norm 0.5622 (0.5516)	mem 39782MB
[2023-07-07 17:05:07 RepVGG-A0] (main.py 282): INFO Train: [253/300][70/78]	eta 0:00:14 lr 0.365743	time 1.2162 (1.8483)	loss 2.3468 (2.3644)	grad_norm 0.5523 (0.5535)	mem 39782MB
[2023-07-07 17:05:19 RepVGG-A0] (main.py 291): INFO EPOCH 253 training takes 0:02:23
[2023-07-07 17:05:40 RepVGG-A0] (main.py 282): INFO Train: [254/300][0/78]	eta 0:27:31 lr 0.364149	time 21.1716 (21.1716)	loss 2.3249 (2.3249)	grad_norm 0.5703 (0.5703)	mem 39782MB
[2023-07-07 17:05:55 RepVGG-A0] (main.py 282): INFO Train: [254/300][10/78]	eta 0:03:46 lr 0.362161	time 1.1723 (3.3305)	loss 2.3137 (2.3300)	grad_norm 0.5651 (0.5628)	mem 39782MB
[2023-07-07 17:06:11 RepVGG-A0] (main.py 282): INFO Train: [254/300][20/78]	eta 0:02:22 lr 0.360178	time 1.3013 (2.4631)	loss 2.3122 (2.3395)	grad_norm 0.5542 (0.5571)	mem 39782MB
[2023-07-07 17:06:27 RepVGG-A0] (main.py 282): INFO Train: [254/300][30/78]	eta 0:01:45 lr 0.358200	time 2.0140 (2.1898)	loss 2.3646 (2.3447)	grad_norm 0.5460 (0.5571)	mem 39782MB
[2023-07-07 17:06:44 RepVGG-A0] (main.py 282): INFO Train: [254/300][40/78]	eta 0:01:19 lr 0.356228	time 3.4558 (2.0793)	loss 2.3681 (2.3511)	grad_norm 0.5505 (0.5565)	mem 39782MB
[2023-07-07 17:06:58 RepVGG-A0] (main.py 282): INFO Train: [254/300][50/78]	eta 0:00:54 lr 0.354260	time 1.2005 (1.9497)	loss 2.3983 (2.3543)	grad_norm 0.5571 (0.5577)	mem 39782MB
[2023-07-07 17:07:13 RepVGG-A0] (main.py 282): INFO Train: [254/300][60/78]	eta 0:00:33 lr 0.352298	time 1.3050 (1.8756)	loss 2.3306 (2.3577)	grad_norm 0.5771 (0.5577)	mem 39782MB
[2023-07-07 17:07:28 RepVGG-A0] (main.py 282): INFO Train: [254/300][70/78]	eta 0:00:14 lr 0.350341	time 1.1757 (1.8207)	loss 2.3518 (2.3600)	grad_norm 0.5646 (0.5588)	mem 39782MB
[2023-07-07 17:07:40 RepVGG-A0] (main.py 291): INFO EPOCH 254 training takes 0:02:21
[2023-07-07 17:08:02 RepVGG-A0] (main.py 282): INFO Train: [255/300][0/78]	eta 0:28:13 lr 0.348779	time 21.7173 (21.7173)	loss 2.3190 (2.3190)	grad_norm 0.5669 (0.5669)	mem 39782MB
[2023-07-07 17:08:16 RepVGG-A0] (main.py 282): INFO Train: [255/300][10/78]	eta 0:03:40 lr 0.346831	time 1.1712 (3.2416)	loss 2.3170 (2.3399)	grad_norm 0.5479 (0.5538)	mem 39782MB
[2023-07-07 17:08:30 RepVGG-A0] (main.py 282): INFO Train: [255/300][20/78]	eta 0:02:18 lr 0.344889	time 1.1856 (2.3921)	loss 2.3362 (2.3436)	grad_norm 0.5469 (0.5539)	mem 39782MB
[2023-07-07 17:08:47 RepVGG-A0] (main.py 282): INFO Train: [255/300][30/78]	eta 0:01:43 lr 0.342951	time 1.4979 (2.1508)	loss 2.3617 (2.3452)	grad_norm 0.5710 (0.5572)	mem 39782MB
[2023-07-07 17:09:05 RepVGG-A0] (main.py 282): INFO Train: [255/300][40/78]	eta 0:01:19 lr 0.341019	time 3.5122 (2.0837)	loss 2.3672 (2.3493)	grad_norm 0.5662 (0.5588)	mem 39782MB
[2023-07-07 17:09:20 RepVGG-A0] (main.py 282): INFO Train: [255/300][50/78]	eta 0:00:55 lr 0.339091	time 1.3036 (1.9696)	loss 2.3366 (2.3521)	grad_norm 0.5755 (0.5597)	mem 39782MB
[2023-07-07 17:09:35 RepVGG-A0] (main.py 282): INFO Train: [255/300][60/78]	eta 0:00:34 lr 0.337169	time 1.2187 (1.8931)	loss 2.3819 (2.3546)	grad_norm 0.5575 (0.5600)	mem 39782MB
[2023-07-07 17:09:51 RepVGG-A0] (main.py 282): INFO Train: [255/300][70/78]	eta 0:00:14 lr 0.335252	time 1.1259 (1.8431)	loss 2.3631 (2.3547)	grad_norm 0.5533 (0.5602)	mem 39782MB
[2023-07-07 17:10:01 RepVGG-A0] (main.py 291): INFO EPOCH 255 training takes 0:02:21
[2023-07-07 17:10:23 RepVGG-A0] (main.py 282): INFO Train: [256/300][0/78]	eta 0:28:12 lr 0.333722	time 21.6948 (21.6948)	loss 2.3594 (2.3594)	grad_norm 0.5691 (0.5691)	mem 39782MB
[2023-07-07 17:10:38 RepVGG-A0] (main.py 282): INFO Train: [256/300][10/78]	eta 0:03:44 lr 0.331815	time 1.1724 (3.2986)	loss 2.3746 (2.3439)	grad_norm 0.5738 (0.5588)	mem 39782MB
[2023-07-07 17:10:53 RepVGG-A0] (main.py 282): INFO Train: [256/300][20/78]	eta 0:02:22 lr 0.329912	time 1.2180 (2.4573)	loss 2.3645 (2.3423)	grad_norm 0.5591 (0.5602)	mem 39782MB
[2023-07-07 17:11:08 RepVGG-A0] (main.py 282): INFO Train: [256/300][30/78]	eta 0:01:43 lr 0.328015	time 1.6682 (2.1597)	loss 2.3697 (2.3477)	grad_norm 0.5674 (0.5626)	mem 39782MB
[2023-07-07 17:11:26 RepVGG-A0] (main.py 282): INFO Train: [256/300][40/78]	eta 0:01:18 lr 0.326123	time 2.4279 (2.0586)	loss 2.3812 (2.3483)	grad_norm 0.5526 (0.5633)	mem 39782MB
[2023-07-07 17:11:41 RepVGG-A0] (main.py 282): INFO Train: [256/300][50/78]	eta 0:00:54 lr 0.324236	time 1.1721 (1.9466)	loss 2.3770 (2.3487)	grad_norm 0.5577 (0.5630)	mem 39782MB
[2023-07-07 17:11:56 RepVGG-A0] (main.py 282): INFO Train: [256/300][60/78]	eta 0:00:33 lr 0.322354	time 1.2431 (1.8811)	loss 2.3139 (2.3479)	grad_norm 0.5718 (0.5624)	mem 39782MB
[2023-07-07 17:12:12 RepVGG-A0] (main.py 282): INFO Train: [256/300][70/78]	eta 0:00:14 lr 0.320477	time 1.3098 (1.8340)	loss 2.3320 (2.3487)	grad_norm 0.5744 (0.5625)	mem 39782MB
[2023-07-07 17:12:23 RepVGG-A0] (main.py 291): INFO EPOCH 256 training takes 0:02:21
[2023-07-07 17:12:44 RepVGG-A0] (main.py 282): INFO Train: [257/300][0/78]	eta 0:27:47 lr 0.318980	time 21.3822 (21.3822)	loss 2.3596 (2.3596)	grad_norm 0.5496 (0.5496)	mem 39782MB
[2023-07-07 17:13:00 RepVGG-A0] (main.py 282): INFO Train: [257/300][10/78]	eta 0:03:52 lr 0.317113	time 1.1722 (3.4207)	loss 2.3148 (2.3186)	grad_norm 0.5543 (0.5601)	mem 39782MB
[2023-07-07 17:13:15 RepVGG-A0] (main.py 282): INFO Train: [257/300][20/78]	eta 0:02:25 lr 0.315251	time 1.3539 (2.5034)	loss 2.3007 (2.3269)	grad_norm 0.5422 (0.5634)	mem 39782MB
[2023-07-07 17:13:30 RepVGG-A0] (main.py 282): INFO Train: [257/300][30/78]	eta 0:01:44 lr 0.313394	time 1.3200 (2.1823)	loss 2.3602 (2.3337)	grad_norm 0.5773 (0.5651)	mem 39782MB
[2023-07-07 17:13:49 RepVGG-A0] (main.py 282): INFO Train: [257/300][40/78]	eta 0:01:19 lr 0.311542	time 2.6227 (2.0961)	loss 2.4181 (2.3374)	grad_norm 0.5564 (0.5640)	mem 39782MB
[2023-07-07 17:14:04 RepVGG-A0] (main.py 282): INFO Train: [257/300][50/78]	eta 0:00:55 lr 0.309696	time 1.1746 (1.9962)	loss 2.3894 (2.3374)	grad_norm 0.5823 (0.5645)	mem 39782MB
[2023-07-07 17:14:20 RepVGG-A0] (main.py 282): INFO Train: [257/300][60/78]	eta 0:00:34 lr 0.307854	time 1.6764 (1.9252)	loss 2.2987 (2.3410)	grad_norm 0.5753 (0.5650)	mem 39782MB
[2023-07-07 17:14:35 RepVGG-A0] (main.py 282): INFO Train: [257/300][70/78]	eta 0:00:14 lr 0.306018	time 1.5018 (1.8666)	loss 2.3969 (2.3446)	grad_norm 0.5710 (0.5652)	mem 39782MB
[2023-07-07 17:14:46 RepVGG-A0] (main.py 291): INFO EPOCH 257 training takes 0:02:22
[2023-07-07 17:15:07 RepVGG-A0] (main.py 282): INFO Train: [258/300][0/78]	eta 0:28:22 lr 0.304553	time 21.8325 (21.8325)	loss 2.2927 (2.2927)	grad_norm 0.5610 (0.5610)	mem 39782MB
[2023-07-07 17:15:23 RepVGG-A0] (main.py 282): INFO Train: [258/300][10/78]	eta 0:03:48 lr 0.302727	time 1.1712 (3.3598)	loss 2.2915 (2.3031)	grad_norm 0.5682 (0.5617)	mem 39782MB
[2023-07-07 17:15:38 RepVGG-A0] (main.py 282): INFO Train: [258/300][20/78]	eta 0:02:24 lr 0.300905	time 1.3837 (2.4861)	loss 2.3204 (2.3069)	grad_norm 0.5610 (0.5649)	mem 39782MB
[2023-07-07 17:15:53 RepVGG-A0] (main.py 282): INFO Train: [258/300][30/78]	eta 0:01:44 lr 0.299089	time 1.1923 (2.1768)	loss 2.3459 (2.3171)	grad_norm 0.5888 (0.5667)	mem 39782MB
[2023-07-07 17:16:11 RepVGG-A0] (main.py 282): INFO Train: [258/300][40/78]	eta 0:01:19 lr 0.297278	time 3.7393 (2.0880)	loss 2.3642 (2.3273)	grad_norm 0.5585 (0.5660)	mem 39782MB
[2023-07-07 17:16:26 RepVGG-A0] (main.py 282): INFO Train: [258/300][50/78]	eta 0:00:55 lr 0.295473	time 1.1728 (1.9674)	loss 2.3680 (2.3316)	grad_norm 0.5721 (0.5666)	mem 39782MB
[2023-07-07 17:16:41 RepVGG-A0] (main.py 282): INFO Train: [258/300][60/78]	eta 0:00:34 lr 0.293672	time 1.1280 (1.8921)	loss 2.3410 (2.3353)	grad_norm 0.5658 (0.5671)	mem 39782MB
[2023-07-07 17:16:56 RepVGG-A0] (main.py 282): INFO Train: [258/300][70/78]	eta 0:00:14 lr 0.291877	time 1.2899 (1.8381)	loss 2.3249 (2.3374)	grad_norm 0.5701 (0.5676)	mem 39782MB
[2023-07-07 17:17:08 RepVGG-A0] (main.py 291): INFO EPOCH 258 training takes 0:02:22
[2023-07-07 17:17:30 RepVGG-A0] (main.py 282): INFO Train: [259/300][0/78]	eta 0:28:36 lr 0.290444	time 22.0103 (22.0103)	loss 2.3015 (2.3015)	grad_norm 0.5662 (0.5662)	mem 39782MB
[2023-07-07 17:17:45 RepVGG-A0] (main.py 282): INFO Train: [259/300][10/78]	eta 0:03:47 lr 0.288659	time 1.1699 (3.3472)	loss 2.3049 (2.3359)	grad_norm 0.5638 (0.5631)	mem 39782MB
[2023-07-07 17:18:00 RepVGG-A0] (main.py 282): INFO Train: [259/300][20/78]	eta 0:02:24 lr 0.286878	time 1.2818 (2.4904)	loss 2.3539 (2.3336)	grad_norm 0.5729 (0.5700)	mem 39782MB
[2023-07-07 17:18:14 RepVGG-A0] (main.py 282): INFO Train: [259/300][30/78]	eta 0:01:42 lr 0.285103	time 1.2046 (2.1253)	loss 2.2893 (2.3260)	grad_norm 0.5809 (0.5702)	mem 39782MB
[2023-07-07 17:18:32 RepVGG-A0] (main.py 282): INFO Train: [259/300][40/78]	eta 0:01:18 lr 0.283333	time 3.5332 (2.0661)	loss 2.3407 (2.3273)	grad_norm 0.5714 (0.5703)	mem 39782MB
[2023-07-07 17:18:47 RepVGG-A0] (main.py 282): INFO Train: [259/300][50/78]	eta 0:00:54 lr 0.281568	time 1.1715 (1.9409)	loss 2.3335 (2.3270)	grad_norm 0.5831 (0.5699)	mem 39782MB
[2023-07-07 17:19:02 RepVGG-A0] (main.py 282): INFO Train: [259/300][60/78]	eta 0:00:33 lr 0.279808	time 1.3227 (1.8759)	loss 2.2919 (2.3269)	grad_norm 0.5977 (0.5710)	mem 39782MB
[2023-07-07 17:19:17 RepVGG-A0] (main.py 282): INFO Train: [259/300][70/78]	eta 0:00:14 lr 0.278054	time 1.3277 (1.8238)	loss 2.3534 (2.3286)	grad_norm 0.5771 (0.5717)	mem 39782MB
[2023-07-07 17:19:29 RepVGG-A0] (main.py 291): INFO EPOCH 259 training takes 0:02:21
[2023-07-07 17:19:51 RepVGG-A0] (main.py 282): INFO Train: [260/300][0/78]	eta 0:27:35 lr 0.276655	time 21.2294 (21.2294)	loss 2.2606 (2.2606)	grad_norm 0.5650 (0.5650)	mem 39782MB
[2023-07-07 17:20:06 RepVGG-A0] (main.py 282): INFO Train: [260/300][10/78]	eta 0:03:43 lr 0.274910	time 1.1719 (3.2935)	loss 2.3118 (2.2873)	grad_norm 0.5658 (0.5689)	mem 39782MB
[2023-07-07 17:20:20 RepVGG-A0] (main.py 282): INFO Train: [260/300][20/78]	eta 0:02:19 lr 0.273170	time 1.3324 (2.4121)	loss 2.3244 (2.3027)	grad_norm 0.5763 (0.5697)	mem 39782MB
[2023-07-07 17:20:35 RepVGG-A0] (main.py 282): INFO Train: [260/300][30/78]	eta 0:01:41 lr 0.271436	time 1.1907 (2.1047)	loss 2.3145 (2.3083)	grad_norm 0.5676 (0.5700)	mem 39782MB
[2023-07-07 17:20:53 RepVGG-A0] (main.py 282): INFO Train: [260/300][40/78]	eta 0:01:17 lr 0.269707	time 3.6825 (2.0366)	loss 2.3238 (2.3095)	grad_norm 0.5700 (0.5724)	mem 39782MB
[2023-07-07 17:21:08 RepVGG-A0] (main.py 282): INFO Train: [260/300][50/78]	eta 0:00:54 lr 0.267983	time 1.3088 (1.9382)	loss 2.2922 (2.3148)	grad_norm 0.5723 (0.5737)	mem 39782MB
[2023-07-07 17:21:23 RepVGG-A0] (main.py 282): INFO Train: [260/300][60/78]	eta 0:00:33 lr 0.266265	time 1.2094 (1.8641)	loss 2.3317 (2.3165)	grad_norm 0.5727 (0.5749)	mem 39782MB
[2023-07-07 17:21:38 RepVGG-A0] (main.py 282): INFO Train: [260/300][70/78]	eta 0:00:14 lr 0.264552	time 1.1860 (1.8152)	loss 2.3252 (2.3192)	grad_norm 0.5777 (0.5755)	mem 39782MB
[2023-07-07 17:21:51 RepVGG-A0] (main.py 291): INFO EPOCH 260 training takes 0:02:21
[2023-07-07 17:22:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.950 (16.950)	Loss 1.4969 (1.4969)	Acc@1 67.114 (67.114)	Acc@5 87.482 (87.482)	Mem 39782MB
[2023-07-07 17:22:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 67.272 Acc@5 87.486
[2023-07-07 17:22:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 260: 67.272%
[2023-07-07 17:22:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 67.27%
[2023-07-07 17:22:30 RepVGG-A0] (main.py 282): INFO Train: [261/300][0/78]	eta 0:27:45 lr 0.263185	time 21.3556 (21.3556)	loss 2.2714 (2.2714)	grad_norm 0.5742 (0.5742)	mem 39782MB
[2023-07-07 17:22:46 RepVGG-A0] (main.py 282): INFO Train: [261/300][10/78]	eta 0:03:47 lr 0.261482	time 1.1710 (3.3522)	loss 2.2995 (2.2910)	grad_norm 0.5759 (0.5737)	mem 39782MB
[2023-07-07 17:23:00 RepVGG-A0] (main.py 282): INFO Train: [261/300][20/78]	eta 0:02:21 lr 0.259783	time 1.1754 (2.4408)	loss 2.2508 (2.2927)	grad_norm 0.5811 (0.5762)	mem 39782MB
[2023-07-07 17:23:14 RepVGG-A0] (main.py 282): INFO Train: [261/300][30/78]	eta 0:01:41 lr 0.258090	time 1.2566 (2.1164)	loss 2.3315 (2.3006)	grad_norm 0.5711 (0.5770)	mem 39782MB
[2023-07-07 17:23:32 RepVGG-A0] (main.py 282): INFO Train: [261/300][40/78]	eta 0:01:17 lr 0.256403	time 1.9080 (2.0309)	loss 2.3556 (2.3014)	grad_norm 0.5813 (0.5768)	mem 39782MB
[2023-07-07 17:23:48 RepVGG-A0] (main.py 282): INFO Train: [261/300][50/78]	eta 0:00:54 lr 0.254720	time 1.3169 (1.9493)	loss 2.2676 (2.3056)	grad_norm 0.5722 (0.5772)	mem 39782MB
[2023-07-07 17:24:03 RepVGG-A0] (main.py 282): INFO Train: [261/300][60/78]	eta 0:00:33 lr 0.253043	time 1.1937 (1.8656)	loss 2.3384 (2.3101)	grad_norm 0.5751 (0.5766)	mem 39782MB
[2023-07-07 17:24:18 RepVGG-A0] (main.py 282): INFO Train: [261/300][70/78]	eta 0:00:14 lr 0.251371	time 1.3470 (1.8223)	loss 2.2919 (2.3130)	grad_norm 0.5704 (0.5782)	mem 39782MB
[2023-07-07 17:24:30 RepVGG-A0] (main.py 291): INFO EPOCH 261 training takes 0:02:21
[2023-07-07 17:24:52 RepVGG-A0] (main.py 282): INFO Train: [262/300][0/78]	eta 0:28:15 lr 0.250038	time 21.7353 (21.7353)	loss 2.2819 (2.2819)	grad_norm 0.5803 (0.5803)	mem 39782MB
[2023-07-07 17:25:07 RepVGG-A0] (main.py 282): INFO Train: [262/300][10/78]	eta 0:03:44 lr 0.248376	time 1.1907 (3.3030)	loss 2.3403 (2.2869)	grad_norm 0.5728 (0.5734)	mem 39782MB
[2023-07-07 17:25:22 RepVGG-A0] (main.py 282): INFO Train: [262/300][20/78]	eta 0:02:21 lr 0.246719	time 1.1739 (2.4426)	loss 2.3323 (2.2957)	grad_norm 0.5873 (0.5748)	mem 39782MB
[2023-07-07 17:25:38 RepVGG-A0] (main.py 282): INFO Train: [262/300][30/78]	eta 0:01:44 lr 0.245067	time 1.4594 (2.1770)	loss 2.2799 (2.2999)	grad_norm 0.5979 (0.5759)	mem 39782MB
[2023-07-07 17:25:56 RepVGG-A0] (main.py 282): INFO Train: [262/300][40/78]	eta 0:01:18 lr 0.243421	time 3.6132 (2.0775)	loss 2.3634 (2.3048)	grad_norm 0.5793 (0.5774)	mem 39782MB
[2023-07-07 17:26:10 RepVGG-A0] (main.py 282): INFO Train: [262/300][50/78]	eta 0:00:54 lr 0.241780	time 1.1742 (1.9611)	loss 2.2837 (2.3081)	grad_norm 0.5810 (0.5782)	mem 39782MB
[2023-07-07 17:26:26 RepVGG-A0] (main.py 282): INFO Train: [262/300][60/78]	eta 0:00:33 lr 0.240145	time 1.3067 (1.8865)	loss 2.3074 (2.3090)	grad_norm 0.5828 (0.5782)	mem 39782MB
[2023-07-07 17:26:41 RepVGG-A0] (main.py 282): INFO Train: [262/300][70/78]	eta 0:00:14 lr 0.238514	time 1.5173 (1.8346)	loss 2.3312 (2.3112)	grad_norm 0.5824 (0.5790)	mem 39782MB
[2023-07-07 17:26:52 RepVGG-A0] (main.py 291): INFO EPOCH 262 training takes 0:02:21
[2023-07-07 17:27:13 RepVGG-A0] (main.py 282): INFO Train: [263/300][0/78]	eta 0:27:14 lr 0.237214	time 20.9591 (20.9591)	loss 2.3082 (2.3082)	grad_norm 0.6101 (0.6101)	mem 39782MB
[2023-07-07 17:27:28 RepVGG-A0] (main.py 282): INFO Train: [263/300][10/78]	eta 0:03:39 lr 0.235594	time 1.1727 (3.2217)	loss 2.3106 (2.3045)	grad_norm 0.5813 (0.6169)	mem 39782MB
[2023-07-07 17:27:43 RepVGG-A0] (main.py 282): INFO Train: [263/300][20/78]	eta 0:02:20 lr 0.233978	time 1.2839 (2.4249)	loss 2.3261 (2.3062)	grad_norm 0.5791 (0.5982)	mem 39782MB
[2023-07-07 17:28:05 RepVGG-A0] (main.py 282): INFO Train: [263/300][30/78]	eta 0:01:51 lr 0.232368	time 1.1725 (2.3279)	loss 2.2890 (2.3063)	grad_norm 0.5789 (0.5924)	mem 39782MB
[2023-07-07 17:28:21 RepVGG-A0] (main.py 282): INFO Train: [263/300][40/78]	eta 0:01:21 lr 0.230764	time 1.1748 (2.1514)	loss 2.3079 (2.3072)	grad_norm 0.5843 (0.5906)	mem 39782MB
[2023-07-07 17:28:36 RepVGG-A0] (main.py 282): INFO Train: [263/300][50/78]	eta 0:00:57 lr 0.229165	time 1.1782 (2.0358)	loss 2.2484 (2.3052)	grad_norm 0.5638 (0.5889)	mem 39782MB
[2023-07-07 17:28:51 RepVGG-A0] (main.py 282): INFO Train: [263/300][60/78]	eta 0:00:35 lr 0.227571	time 1.2579 (1.9447)	loss 2.3137 (2.3046)	grad_norm 0.5914 (0.5885)	mem 39782MB
[2023-07-07 17:29:06 RepVGG-A0] (main.py 282): INFO Train: [263/300][70/78]	eta 0:00:15 lr 0.225982	time 1.2252 (1.8801)	loss 2.3499 (2.3068)	grad_norm 0.5738 (0.5882)	mem 39782MB
[2023-07-07 17:29:17 RepVGG-A0] (main.py 291): INFO EPOCH 263 training takes 0:02:24
[2023-07-07 17:29:37 RepVGG-A0] (main.py 282): INFO Train: [264/300][0/78]	eta 0:26:52 lr 0.224715	time 20.6698 (20.6698)	loss 2.2473 (2.2473)	grad_norm 0.5828 (0.5828)	mem 39782MB
[2023-07-07 17:29:53 RepVGG-A0] (main.py 282): INFO Train: [264/300][10/78]	eta 0:03:41 lr 0.223136	time 1.1717 (3.2588)	loss 2.3134 (2.2686)	grad_norm 0.5700 (0.5851)	mem 39782MB
[2023-07-07 17:30:07 RepVGG-A0] (main.py 282): INFO Train: [264/300][20/78]	eta 0:02:19 lr 0.221563	time 1.1728 (2.4049)	loss 2.3053 (2.2806)	grad_norm 0.5929 (0.5869)	mem 39782MB
[2023-07-07 17:30:23 RepVGG-A0] (main.py 282): INFO Train: [264/300][30/78]	eta 0:01:41 lr 0.219995	time 1.2670 (2.1206)	loss 2.2690 (2.2814)	grad_norm 0.6009 (0.5866)	mem 39782MB
[2023-07-07 17:30:40 RepVGG-A0] (main.py 282): INFO Train: [264/300][40/78]	eta 0:01:17 lr 0.218432	time 3.2569 (2.0292)	loss 2.2767 (2.2840)	grad_norm 0.5828 (0.5865)	mem 39782MB
[2023-07-07 17:30:55 RepVGG-A0] (main.py 282): INFO Train: [264/300][50/78]	eta 0:00:54 lr 0.216875	time 1.1730 (1.9339)	loss 2.3157 (2.2876)	grad_norm 0.5860 (0.5859)	mem 39782MB
[2023-07-07 17:31:11 RepVGG-A0] (main.py 282): INFO Train: [264/300][60/78]	eta 0:00:33 lr 0.215323	time 1.4959 (1.8748)	loss 2.2777 (2.2881)	grad_norm 0.5947 (0.5869)	mem 39782MB
[2023-07-07 17:31:26 RepVGG-A0] (main.py 282): INFO Train: [264/300][70/78]	eta 0:00:14 lr 0.213776	time 1.2228 (1.8139)	loss 2.3892 (2.2912)	grad_norm 0.5859 (0.5867)	mem 39782MB
[2023-07-07 17:31:38 RepVGG-A0] (main.py 291): INFO EPOCH 264 training takes 0:02:20
[2023-07-07 17:32:00 RepVGG-A0] (main.py 282): INFO Train: [265/300][0/78]	eta 0:28:30 lr 0.212543	time 21.9350 (21.9350)	loss 2.3120 (2.3120)	grad_norm 0.5911 (0.5911)	mem 39782MB
[2023-07-07 17:32:15 RepVGG-A0] (main.py 282): INFO Train: [265/300][10/78]	eta 0:03:48 lr 0.211006	time 1.1918 (3.3660)	loss 2.2939 (2.2799)	grad_norm 0.5899 (0.5860)	mem 39782MB
[2023-07-07 17:32:29 RepVGG-A0] (main.py 282): INFO Train: [265/300][20/78]	eta 0:02:23 lr 0.209474	time 1.1586 (2.4671)	loss 2.3017 (2.2879)	grad_norm 0.5889 (0.5902)	mem 39782MB
[2023-07-07 17:32:44 RepVGG-A0] (main.py 282): INFO Train: [265/300][30/78]	eta 0:01:43 lr 0.207948	time 1.1280 (2.1513)	loss 2.3027 (2.2912)	grad_norm 0.5842 (0.5901)	mem 39782MB
[2023-07-07 17:33:02 RepVGG-A0] (main.py 282): INFO Train: [265/300][40/78]	eta 0:01:18 lr 0.206427	time 3.7175 (2.0642)	loss 2.3764 (2.2956)	grad_norm 0.6056 (0.5899)	mem 39782MB
[2023-07-07 17:33:17 RepVGG-A0] (main.py 282): INFO Train: [265/300][50/78]	eta 0:00:54 lr 0.204912	time 1.1724 (1.9489)	loss 2.2802 (2.2957)	grad_norm 0.5949 (0.5911)	mem 39782MB
[2023-07-07 17:33:33 RepVGG-A0] (main.py 282): INFO Train: [265/300][60/78]	eta 0:00:33 lr 0.203402	time 1.3261 (1.8837)	loss 2.2737 (2.2960)	grad_norm 0.5862 (0.5911)	mem 39782MB
[2023-07-07 17:33:48 RepVGG-A0] (main.py 282): INFO Train: [265/300][70/78]	eta 0:00:14 lr 0.201897	time 1.3213 (1.8411)	loss 2.2878 (2.2962)	grad_norm 0.5918 (0.5905)	mem 39782MB
[2023-07-07 17:33:59 RepVGG-A0] (main.py 291): INFO EPOCH 265 training takes 0:02:21
[2023-07-07 17:34:21 RepVGG-A0] (main.py 282): INFO Train: [266/300][0/78]	eta 0:28:18 lr 0.200698	time 21.7731 (21.7731)	loss 2.3187 (2.3187)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 17:34:36 RepVGG-A0] (main.py 282): INFO Train: [266/300][10/78]	eta 0:03:47 lr 0.199203	time 1.1731 (3.3477)	loss 2.2995 (2.2593)	grad_norm 0.5801 (0.5881)	mem 39782MB
[2023-07-07 17:34:51 RepVGG-A0] (main.py 282): INFO Train: [266/300][20/78]	eta 0:02:23 lr 0.197713	time 1.2877 (2.4662)	loss 2.2800 (2.2690)	grad_norm 0.5976 (0.5885)	mem 39782MB
[2023-07-07 17:35:06 RepVGG-A0] (main.py 282): INFO Train: [266/300][30/78]	eta 0:01:43 lr 0.196229	time 1.3128 (2.1657)	loss 2.2761 (2.2714)	grad_norm 0.5975 (0.5891)	mem 39782MB
[2023-07-07 17:35:23 RepVGG-A0] (main.py 282): INFO Train: [266/300][40/78]	eta 0:01:17 lr 0.194751	time 2.5924 (2.0450)	loss 2.2391 (2.2737)	grad_norm 0.5995 (0.5908)	mem 39782MB
[2023-07-07 17:35:39 RepVGG-A0] (main.py 282): INFO Train: [266/300][50/78]	eta 0:00:54 lr 0.193278	time 1.1727 (1.9518)	loss 2.3039 (2.2774)	grad_norm 0.5956 (0.5913)	mem 39782MB
[2023-07-07 17:35:54 RepVGG-A0] (main.py 282): INFO Train: [266/300][60/78]	eta 0:00:33 lr 0.191810	time 1.1278 (1.8733)	loss 2.2491 (2.2797)	grad_norm 0.5952 (0.5922)	mem 39782MB
[2023-07-07 17:36:09 RepVGG-A0] (main.py 282): INFO Train: [266/300][70/78]	eta 0:00:14 lr 0.190348	time 1.4102 (1.8209)	loss 2.2793 (2.2798)	grad_norm 0.6125 (0.5929)	mem 39782MB
[2023-07-07 17:36:21 RepVGG-A0] (main.py 291): INFO EPOCH 266 training takes 0:02:21
[2023-07-07 17:36:41 RepVGG-A0] (main.py 282): INFO Train: [267/300][0/78]	eta 0:26:12 lr 0.189182	time 20.1566 (20.1566)	loss 2.2390 (2.2390)	grad_norm 0.5900 (0.5900)	mem 39782MB
[2023-07-07 17:36:56 RepVGG-A0] (main.py 282): INFO Train: [267/300][10/78]	eta 0:03:34 lr 0.187729	time 1.1896 (3.1541)	loss 2.2430 (2.2598)	grad_norm 0.5996 (0.5898)	mem 39782MB
[2023-07-07 17:37:13 RepVGG-A0] (main.py 282): INFO Train: [267/300][20/78]	eta 0:02:22 lr 0.186282	time 1.6339 (2.4486)	loss 2.2480 (2.2673)	grad_norm 0.6010 (0.5914)	mem 39782MB
[2023-07-07 17:37:27 RepVGG-A0] (main.py 282): INFO Train: [267/300][30/78]	eta 0:01:41 lr 0.184840	time 1.3363 (2.1229)	loss 2.2502 (2.2686)	grad_norm 0.5988 (0.5931)	mem 39782MB
[2023-07-07 17:37:43 RepVGG-A0] (main.py 282): INFO Train: [267/300][40/78]	eta 0:01:16 lr 0.183404	time 3.1925 (2.0002)	loss 2.2265 (2.2731)	grad_norm 0.5921 (0.5955)	mem 39782MB
[2023-07-07 17:37:58 RepVGG-A0] (main.py 282): INFO Train: [267/300][50/78]	eta 0:00:53 lr 0.181973	time 1.1742 (1.9043)	loss 2.2683 (2.2734)	grad_norm 0.6023 (0.5957)	mem 39782MB
[2023-07-07 17:38:13 RepVGG-A0] (main.py 282): INFO Train: [267/300][60/78]	eta 0:00:33 lr 0.180548	time 1.1729 (1.8373)	loss 2.3186 (2.2768)	grad_norm 0.6014 (0.5958)	mem 39782MB
[2023-07-07 17:38:28 RepVGG-A0] (main.py 282): INFO Train: [267/300][70/78]	eta 0:00:14 lr 0.179128	time 1.3666 (1.7902)	loss 2.3102 (2.2774)	grad_norm 0.6048 (0.5967)	mem 39782MB
[2023-07-07 17:38:40 RepVGG-A0] (main.py 291): INFO EPOCH 267 training takes 0:02:18
[2023-07-07 17:39:00 RepVGG-A0] (main.py 282): INFO Train: [268/300][0/78]	eta 0:27:02 lr 0.177996	time 20.8034 (20.8034)	loss 2.2622 (2.2622)	grad_norm 0.5898 (0.5898)	mem 39782MB
[2023-07-07 17:39:16 RepVGG-A0] (main.py 282): INFO Train: [268/300][10/78]	eta 0:03:42 lr 0.176585	time 1.1722 (3.2707)	loss 2.2622 (2.2442)	grad_norm 0.5931 (0.5918)	mem 39782MB
[2023-07-07 17:39:31 RepVGG-A0] (main.py 282): INFO Train: [268/300][20/78]	eta 0:02:22 lr 0.175181	time 1.2106 (2.4515)	loss 2.2597 (2.2467)	grad_norm 0.5965 (0.5918)	mem 39782MB
[2023-07-07 17:39:46 RepVGG-A0] (main.py 282): INFO Train: [268/300][30/78]	eta 0:01:42 lr 0.173782	time 1.3610 (2.1359)	loss 2.2103 (2.2506)	grad_norm 0.5863 (0.5934)	mem 39782MB
[2023-07-07 17:40:03 RepVGG-A0] (main.py 282): INFO Train: [268/300][40/78]	eta 0:01:17 lr 0.172388	time 3.2260 (2.0426)	loss 2.2578 (2.2555)	grad_norm 0.5968 (0.5946)	mem 39782MB
[2023-07-07 17:40:19 RepVGG-A0] (main.py 282): INFO Train: [268/300][50/78]	eta 0:00:54 lr 0.170999	time 1.1720 (1.9452)	loss 2.2710 (2.2582)	grad_norm 0.5996 (0.5957)	mem 39782MB
[2023-07-07 17:40:34 RepVGG-A0] (main.py 282): INFO Train: [268/300][60/78]	eta 0:00:33 lr 0.169617	time 1.4369 (1.8749)	loss 2.2582 (2.2620)	grad_norm 0.5948 (0.5972)	mem 39782MB
[2023-07-07 17:40:49 RepVGG-A0] (main.py 282): INFO Train: [268/300][70/78]	eta 0:00:14 lr 0.168239	time 1.2745 (1.8177)	loss 2.2551 (2.2649)	grad_norm 0.6081 (0.5977)	mem 39782MB
[2023-07-07 17:41:00 RepVGG-A0] (main.py 291): INFO EPOCH 268 training takes 0:02:20
[2023-07-07 17:41:21 RepVGG-A0] (main.py 282): INFO Train: [269/300][0/78]	eta 0:27:24 lr 0.167141	time 21.0810 (21.0810)	loss 2.2957 (2.2957)	grad_norm 0.5896 (0.5896)	mem 39782MB
[2023-07-07 17:41:36 RepVGG-A0] (main.py 282): INFO Train: [269/300][10/78]	eta 0:03:43 lr 0.165774	time 1.1747 (3.2864)	loss 2.3465 (2.2699)	grad_norm 0.6026 (0.5946)	mem 39782MB
[2023-07-07 17:41:52 RepVGG-A0] (main.py 282): INFO Train: [269/300][20/78]	eta 0:02:22 lr 0.164411	time 1.3881 (2.4494)	loss 2.2375 (2.2627)	grad_norm 0.6027 (0.5969)	mem 39782MB
[2023-07-07 17:42:07 RepVGG-A0] (main.py 282): INFO Train: [269/300][30/78]	eta 0:01:42 lr 0.163055	time 1.2727 (2.1438)	loss 2.2677 (2.2647)	grad_norm 0.5956 (0.5978)	mem 39782MB
[2023-07-07 17:42:26 RepVGG-A0] (main.py 282): INFO Train: [269/300][40/78]	eta 0:01:19 lr 0.161704	time 3.2563 (2.0803)	loss 2.2710 (2.2630)	grad_norm 0.6046 (0.5996)	mem 39782MB
[2023-07-07 17:42:40 RepVGG-A0] (main.py 282): INFO Train: [269/300][50/78]	eta 0:00:54 lr 0.160358	time 1.1990 (1.9598)	loss 2.2875 (2.2627)	grad_norm 0.5963 (0.6004)	mem 39782MB
[2023-07-07 17:42:55 RepVGG-A0] (main.py 282): INFO Train: [269/300][60/78]	eta 0:00:33 lr 0.159018	time 1.1760 (1.8871)	loss 2.2494 (2.2626)	grad_norm 0.6096 (0.6003)	mem 39782MB
[2023-07-07 17:43:10 RepVGG-A0] (main.py 282): INFO Train: [269/300][70/78]	eta 0:00:14 lr 0.157683	time 1.3695 (1.8306)	loss 2.2582 (2.2652)	grad_norm 0.5994 (0.6009)	mem 39782MB
[2023-07-07 17:43:21 RepVGG-A0] (main.py 291): INFO EPOCH 269 training takes 0:02:21
[2023-07-07 17:43:43 RepVGG-A0] (main.py 282): INFO Train: [270/300][0/78]	eta 0:28:47 lr 0.156619	time 22.1483 (22.1483)	loss 2.2602 (2.2602)	grad_norm 0.6002 (0.6002)	mem 39782MB
[2023-07-07 17:43:58 RepVGG-A0] (main.py 282): INFO Train: [270/300][10/78]	eta 0:03:49 lr 0.155294	time 1.1736 (3.3818)	loss 2.2525 (2.2250)	grad_norm 0.5950 (0.6043)	mem 39782MB
[2023-07-07 17:44:14 RepVGG-A0] (main.py 282): INFO Train: [270/300][20/78]	eta 0:02:24 lr 0.153975	time 1.1904 (2.4885)	loss 2.3564 (2.2439)	grad_norm 0.5992 (0.6035)	mem 39782MB
[2023-07-07 17:44:28 RepVGG-A0] (main.py 282): INFO Train: [270/300][30/78]	eta 0:01:44 lr 0.152661	time 1.2917 (2.1673)	loss 2.2400 (2.2464)	grad_norm 0.6050 (0.6041)	mem 39782MB
[2023-07-07 17:44:46 RepVGG-A0] (main.py 282): INFO Train: [270/300][40/78]	eta 0:01:18 lr 0.151353	time 3.2310 (2.0646)	loss 2.3336 (2.2530)	grad_norm 0.6112 (0.6051)	mem 39782MB
[2023-07-07 17:45:01 RepVGG-A0] (main.py 282): INFO Train: [270/300][50/78]	eta 0:00:54 lr 0.150050	time 1.3936 (1.9574)	loss 2.2371 (2.2534)	grad_norm 0.6031 (0.6053)	mem 39782MB
[2023-07-07 17:45:16 RepVGG-A0] (main.py 282): INFO Train: [270/300][60/78]	eta 0:00:33 lr 0.148752	time 1.3368 (1.8806)	loss 2.2958 (2.2547)	grad_norm 0.6040 (0.6058)	mem 39782MB
[2023-07-07 17:45:31 RepVGG-A0] (main.py 282): INFO Train: [270/300][70/78]	eta 0:00:14 lr 0.147460	time 1.2459 (1.8266)	loss 2.2802 (2.2551)	grad_norm 0.6121 (0.6065)	mem 39782MB
[2023-07-07 17:45:43 RepVGG-A0] (main.py 291): INFO EPOCH 270 training takes 0:02:21
[2023-07-07 17:46:02 RepVGG-A0] (main.py 282): INFO Train: [271/300][0/78]	eta 0:25:37 lr 0.146431	time 19.7159 (19.7159)	loss 2.2351 (2.2351)	grad_norm 0.6115 (0.6115)	mem 39782MB
[2023-07-07 17:46:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][10/78]	eta 0:03:49 lr 0.145149	time 1.1715 (3.3761)	loss 2.2080 (2.2369)	grad_norm 0.5993 (0.6003)	mem 39782MB
[2023-07-07 17:46:33 RepVGG-A0] (main.py 282): INFO Train: [271/300][20/78]	eta 0:02:20 lr 0.143872	time 1.3534 (2.4250)	loss 2.2352 (2.2342)	grad_norm 0.5962 (0.6028)	mem 39782MB
[2023-07-07 17:46:48 RepVGG-A0] (main.py 282): INFO Train: [271/300][30/78]	eta 0:01:40 lr 0.142602	time 1.1347 (2.1037)	loss 2.2459 (2.2378)	grad_norm 0.6090 (0.6048)	mem 39782MB
[2023-07-07 17:47:05 RepVGG-A0] (main.py 282): INFO Train: [271/300][40/78]	eta 0:01:16 lr 0.141336	time 3.3186 (2.0119)	loss 2.2233 (2.2357)	grad_norm 0.6036 (0.6051)	mem 39782MB
[2023-07-07 17:47:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][50/78]	eta 0:00:53 lr 0.140076	time 1.1799 (1.9117)	loss 2.2305 (2.2405)	grad_norm 0.6162 (0.6058)	mem 39782MB
[2023-07-07 17:47:36 RepVGG-A0] (main.py 282): INFO Train: [271/300][60/78]	eta 0:00:33 lr 0.138822	time 1.1264 (1.8525)	loss 2.2680 (2.2426)	grad_norm 0.6106 (0.6069)	mem 39782MB
[2023-07-07 17:47:50 RepVGG-A0] (main.py 282): INFO Train: [271/300][70/78]	eta 0:00:14 lr 0.137573	time 1.3907 (1.7994)	loss 2.3086 (2.2447)	grad_norm 0.6113 (0.6073)	mem 39782MB
[2023-07-07 17:48:02 RepVGG-A0] (main.py 291): INFO EPOCH 271 training takes 0:02:19
[2023-07-07 17:48:24 RepVGG-A0] (main.py 282): INFO Train: [272/300][0/78]	eta 0:28:46 lr 0.136578	time 22.1323 (22.1323)	loss 2.1815 (2.1815)	grad_norm 0.6081 (0.6081)	mem 39782MB
[2023-07-07 17:48:39 RepVGG-A0] (main.py 282): INFO Train: [272/300][10/78]	eta 0:03:47 lr 0.135339	time 1.1723 (3.3401)	loss 2.2277 (2.2362)	grad_norm 0.6057 (0.6103)	mem 39782MB
[2023-07-07 17:48:53 RepVGG-A0] (main.py 282): INFO Train: [272/300][20/78]	eta 0:02:21 lr 0.134105	time 1.1866 (2.4443)	loss 2.1979 (2.2389)	grad_norm 0.6070 (0.6112)	mem 39782MB
[2023-07-07 17:49:08 RepVGG-A0] (main.py 282): INFO Train: [272/300][30/78]	eta 0:01:41 lr 0.132877	time 1.1463 (2.1229)	loss 2.2629 (2.2456)	grad_norm 0.6172 (0.6116)	mem 39782MB
[2023-07-07 17:49:25 RepVGG-A0] (main.py 282): INFO Train: [272/300][40/78]	eta 0:01:17 lr 0.131655	time 3.7548 (2.0312)	loss 2.3027 (2.2457)	grad_norm 0.6209 (0.6121)	mem 39782MB
[2023-07-07 17:49:41 RepVGG-A0] (main.py 282): INFO Train: [272/300][50/78]	eta 0:00:54 lr 0.130438	time 1.1846 (1.9354)	loss 2.2229 (2.2476)	grad_norm 0.6034 (0.6133)	mem 39782MB
[2023-07-07 17:49:56 RepVGG-A0] (main.py 282): INFO Train: [272/300][60/78]	eta 0:00:33 lr 0.129227	time 1.1756 (1.8683)	loss 2.2341 (2.2487)	grad_norm 0.6289 (0.6136)	mem 39782MB
[2023-07-07 17:50:12 RepVGG-A0] (main.py 282): INFO Train: [272/300][70/78]	eta 0:00:14 lr 0.128021	time 1.2814 (1.8250)	loss 2.2575 (2.2485)	grad_norm 0.6133 (0.6140)	mem 39782MB
[2023-07-07 17:50:24 RepVGG-A0] (main.py 291): INFO EPOCH 272 training takes 0:02:21
[2023-07-07 17:50:45 RepVGG-A0] (main.py 282): INFO Train: [273/300][0/78]	eta 0:27:04 lr 0.127060	time 20.8307 (20.8307)	loss 2.2560 (2.2560)	grad_norm 0.6025 (0.6025)	mem 39782MB
[2023-07-07 17:51:01 RepVGG-A0] (main.py 282): INFO Train: [273/300][10/78]	eta 0:03:51 lr 0.125864	time 1.1721 (3.4025)	loss 2.2371 (2.2223)	grad_norm 0.6136 (0.6100)	mem 39782MB
[2023-07-07 17:51:17 RepVGG-A0] (main.py 282): INFO Train: [273/300][20/78]	eta 0:02:27 lr 0.124674	time 1.2386 (2.5394)	loss 2.2193 (2.2248)	grad_norm 0.6155 (0.6130)	mem 39782MB
[2023-07-07 17:51:33 RepVGG-A0] (main.py 282): INFO Train: [273/300][30/78]	eta 0:01:46 lr 0.123489	time 1.3007 (2.2166)	loss 2.2291 (2.2298)	grad_norm 0.6181 (0.6123)	mem 39782MB
[2023-07-07 17:51:50 RepVGG-A0] (main.py 282): INFO Train: [273/300][40/78]	eta 0:01:19 lr 0.122310	time 2.4965 (2.1028)	loss 2.2170 (2.2297)	grad_norm 0.6127 (0.6129)	mem 39782MB
[2023-07-07 17:52:05 RepVGG-A0] (main.py 282): INFO Train: [273/300][50/78]	eta 0:00:55 lr 0.121136	time 1.1924 (1.9924)	loss 2.2244 (2.2321)	grad_norm 0.6200 (0.6141)	mem 39782MB
[2023-07-07 17:52:20 RepVGG-A0] (main.py 282): INFO Train: [273/300][60/78]	eta 0:00:34 lr 0.119968	time 1.3082 (1.9082)	loss 2.2555 (2.2327)	grad_norm 0.6246 (0.6147)	mem 39782MB
[2023-07-07 17:52:35 RepVGG-A0] (main.py 282): INFO Train: [273/300][70/78]	eta 0:00:14 lr 0.118806	time 1.4283 (1.8491)	loss 2.2623 (2.2338)	grad_norm 0.6233 (0.6163)	mem 39782MB
[2023-07-07 17:52:46 RepVGG-A0] (main.py 291): INFO EPOCH 273 training takes 0:02:22
[2023-07-07 17:53:07 RepVGG-A0] (main.py 282): INFO Train: [274/300][0/78]	eta 0:26:45 lr 0.117880	time 20.5895 (20.5895)	loss 2.2436 (2.2436)	grad_norm 0.6061 (0.6061)	mem 39782MB
[2023-07-07 17:53:22 RepVGG-A0] (main.py 282): INFO Train: [274/300][10/78]	eta 0:03:40 lr 0.116727	time 1.1902 (3.2430)	loss 2.2555 (2.2153)	grad_norm 0.6169 (0.6088)	mem 39782MB
[2023-07-07 17:53:37 RepVGG-A0] (main.py 282): INFO Train: [274/300][20/78]	eta 0:02:20 lr 0.115580	time 1.1901 (2.4257)	loss 2.2905 (2.2233)	grad_norm 0.6198 (0.6120)	mem 39782MB
[2023-07-07 17:53:52 RepVGG-A0] (main.py 282): INFO Train: [274/300][30/78]	eta 0:01:42 lr 0.114439	time 1.3715 (2.1314)	loss 2.2212 (2.2262)	grad_norm 0.6142 (0.6141)	mem 39782MB
[2023-07-07 17:54:11 RepVGG-A0] (main.py 282): INFO Train: [274/300][40/78]	eta 0:01:18 lr 0.113303	time 3.4685 (2.0607)	loss 2.2458 (2.2297)	grad_norm 0.6123 (0.6146)	mem 39782MB
[2023-07-07 17:54:26 RepVGG-A0] (main.py 282): INFO Train: [274/300][50/78]	eta 0:00:54 lr 0.112173	time 1.4139 (1.9529)	loss 2.2426 (2.2307)	grad_norm 0.6258 (0.6161)	mem 39782MB
[2023-07-07 17:54:40 RepVGG-A0] (main.py 282): INFO Train: [274/300][60/78]	eta 0:00:33 lr 0.111048	time 1.1988 (1.8689)	loss 2.2347 (2.2259)	grad_norm 0.6216 (0.6162)	mem 39782MB
[2023-07-07 17:54:55 RepVGG-A0] (main.py 282): INFO Train: [274/300][70/78]	eta 0:00:14 lr 0.109929	time 1.1716 (1.8131)	loss 2.2103 (2.2239)	grad_norm 0.6171 (0.6171)	mem 39782MB
[2023-07-07 17:55:07 RepVGG-A0] (main.py 291): INFO EPOCH 274 training takes 0:02:20
[2023-07-07 17:55:28 RepVGG-A0] (main.py 282): INFO Train: [275/300][0/78]	eta 0:26:59 lr 0.109037	time 20.7589 (20.7589)	loss 2.2315 (2.2315)	grad_norm 0.6124 (0.6124)	mem 39782MB
[2023-07-07 17:55:43 RepVGG-A0] (main.py 282): INFO Train: [275/300][10/78]	eta 0:03:40 lr 0.107928	time 1.1709 (3.2449)	loss 2.2129 (2.2197)	grad_norm 0.6142 (0.6143)	mem 39782MB
[2023-07-07 17:55:57 RepVGG-A0] (main.py 282): INFO Train: [275/300][20/78]	eta 0:02:18 lr 0.106825	time 1.1724 (2.3940)	loss 2.2210 (2.2155)	grad_norm 0.6073 (0.6151)	mem 39782MB
[2023-07-07 17:56:13 RepVGG-A0] (main.py 282): INFO Train: [275/300][30/78]	eta 0:01:41 lr 0.105727	time 1.3066 (2.1212)	loss 2.2342 (2.2185)	grad_norm 0.6171 (0.6158)	mem 39782MB
[2023-07-07 17:56:30 RepVGG-A0] (main.py 282): INFO Train: [275/300][40/78]	eta 0:01:17 lr 0.104634	time 3.4503 (2.0281)	loss 2.2692 (2.2201)	grad_norm 0.6200 (0.6171)	mem 39782MB
[2023-07-07 17:56:45 RepVGG-A0] (main.py 282): INFO Train: [275/300][50/78]	eta 0:00:53 lr 0.103547	time 1.1724 (1.9179)	loss 2.2664 (2.2221)	grad_norm 0.6284 (0.6182)	mem 39782MB
[2023-07-07 17:57:00 RepVGG-A0] (main.py 282): INFO Train: [275/300][60/78]	eta 0:00:33 lr 0.102466	time 1.3294 (1.8545)	loss 2.1711 (2.2211)	grad_norm 0.6174 (0.6187)	mem 39782MB
[2023-07-07 17:57:15 RepVGG-A0] (main.py 282): INFO Train: [275/300][70/78]	eta 0:00:14 lr 0.101390	time 1.4148 (1.8072)	loss 2.2406 (2.2235)	grad_norm 0.6305 (0.6191)	mem 39782MB
[2023-07-07 17:57:26 RepVGG-A0] (main.py 291): INFO EPOCH 275 training takes 0:02:19
[2023-07-07 17:57:49 RepVGG-A0] (main.py 282): INFO Train: [276/300][0/78]	eta 0:29:13 lr 0.100534	time 22.4851 (22.4851)	loss 2.2289 (2.2289)	grad_norm 0.6158 (0.6158)	mem 39782MB
[2023-07-07 17:58:03 RepVGG-A0] (main.py 282): INFO Train: [276/300][10/78]	eta 0:03:42 lr 0.099468	time 1.1921 (3.2757)	loss 2.2397 (2.2171)	grad_norm 0.6254 (0.6183)	mem 39782MB
[2023-07-07 17:58:17 RepVGG-A0] (main.py 282): INFO Train: [276/300][20/78]	eta 0:02:18 lr 0.098408	time 1.1726 (2.3894)	loss 2.1684 (2.2151)	grad_norm 0.6192 (0.6210)	mem 39782MB
[2023-07-07 17:58:33 RepVGG-A0] (main.py 282): INFO Train: [276/300][30/78]	eta 0:01:43 lr 0.097354	time 1.1955 (2.1479)	loss 2.2538 (2.2120)	grad_norm 0.6238 (0.6215)	mem 39782MB
[2023-07-07 17:58:50 RepVGG-A0] (main.py 282): INFO Train: [276/300][40/78]	eta 0:01:17 lr 0.096305	time 3.4808 (2.0478)	loss 2.1952 (2.2148)	grad_norm 0.6140 (0.6213)	mem 39782MB
[2023-07-07 17:59:06 RepVGG-A0] (main.py 282): INFO Train: [276/300][50/78]	eta 0:00:54 lr 0.095262	time 1.1739 (1.9421)	loss 2.2389 (2.2171)	grad_norm 0.6189 (0.6214)	mem 39782MB
[2023-07-07 17:59:22 RepVGG-A0] (main.py 282): INFO Train: [276/300][60/78]	eta 0:00:34 lr 0.094224	time 1.4817 (1.8948)	loss 2.2581 (2.2195)	grad_norm 0.6191 (0.6219)	mem 39782MB
[2023-07-07 17:59:37 RepVGG-A0] (main.py 282): INFO Train: [276/300][70/78]	eta 0:00:14 lr 0.093192	time 1.2100 (1.8320)	loss 2.2652 (2.2222)	grad_norm 0.6211 (0.6219)	mem 39782MB
[2023-07-07 17:59:49 RepVGG-A0] (main.py 291): INFO EPOCH 276 training takes 0:02:22
[2023-07-07 18:00:11 RepVGG-A0] (main.py 282): INFO Train: [277/300][0/78]	eta 0:28:02 lr 0.092370	time 21.5713 (21.5713)	loss 2.2221 (2.2221)	grad_norm 0.6191 (0.6191)	mem 39782MB
[2023-07-07 18:00:25 RepVGG-A0] (main.py 282): INFO Train: [277/300][10/78]	eta 0:03:44 lr 0.091348	time 1.1725 (3.2978)	loss 2.1456 (2.2181)	grad_norm 0.6192 (0.6209)	mem 39782MB
[2023-07-07 18:00:41 RepVGG-A0] (main.py 282): INFO Train: [277/300][20/78]	eta 0:02:23 lr 0.090332	time 1.1753 (2.4697)	loss 2.1675 (2.2141)	grad_norm 0.6143 (0.6234)	mem 39782MB
[2023-07-07 18:00:56 RepVGG-A0] (main.py 282): INFO Train: [277/300][30/78]	eta 0:01:43 lr 0.089321	time 1.3797 (2.1528)	loss 2.2025 (2.2114)	grad_norm 0.6254 (0.6242)	mem 39782MB
[2023-07-07 18:01:13 RepVGG-A0] (main.py 282): INFO Train: [277/300][40/78]	eta 0:01:18 lr 0.088316	time 2.3349 (2.0541)	loss 2.2502 (2.2117)	grad_norm 0.6309 (0.6240)	mem 39782MB
[2023-07-07 18:01:29 RepVGG-A0] (main.py 282): INFO Train: [277/300][50/78]	eta 0:00:54 lr 0.087316	time 1.1717 (1.9601)	loss 2.1998 (2.2111)	grad_norm 0.6257 (0.6247)	mem 39782MB
[2023-07-07 18:01:44 RepVGG-A0] (main.py 282): INFO Train: [277/300][60/78]	eta 0:00:33 lr 0.086322	time 1.2030 (1.8872)	loss 2.1996 (2.2110)	grad_norm 0.6303 (0.6249)	mem 39782MB
[2023-07-07 18:01:59 RepVGG-A0] (main.py 282): INFO Train: [277/300][70/78]	eta 0:00:14 lr 0.085334	time 1.1741 (1.8298)	loss 2.2133 (2.2127)	grad_norm 0.6297 (0.6249)	mem 39782MB
[2023-07-07 18:02:11 RepVGG-A0] (main.py 291): INFO EPOCH 277 training takes 0:02:21
[2023-07-07 18:02:31 RepVGG-A0] (main.py 282): INFO Train: [278/300][0/78]	eta 0:25:56 lr 0.084548	time 19.9503 (19.9503)	loss 2.2399 (2.2399)	grad_norm 0.6245 (0.6245)	mem 39782MB
[2023-07-07 18:02:47 RepVGG-A0] (main.py 282): INFO Train: [278/300][10/78]	eta 0:03:41 lr 0.083569	time 1.1724 (3.2600)	loss 2.2215 (2.2159)	grad_norm 0.6288 (0.6279)	mem 39782MB
[2023-07-07 18:03:01 RepVGG-A0] (main.py 282): INFO Train: [278/300][20/78]	eta 0:02:18 lr 0.082597	time 1.2340 (2.3899)	loss 2.2241 (2.2096)	grad_norm 0.6294 (0.6258)	mem 39782MB
[2023-07-07 18:03:17 RepVGG-A0] (main.py 282): INFO Train: [278/300][30/78]	eta 0:01:42 lr 0.081630	time 1.4445 (2.1360)	loss 2.1821 (2.2120)	grad_norm 0.6267 (0.6270)	mem 39782MB
[2023-07-07 18:03:34 RepVGG-A0] (main.py 282): INFO Train: [278/300][40/78]	eta 0:01:16 lr 0.080668	time 3.8360 (2.0247)	loss 2.1253 (2.2064)	grad_norm 0.6280 (0.6274)	mem 39782MB
[2023-07-07 18:03:49 RepVGG-A0] (main.py 282): INFO Train: [278/300][50/78]	eta 0:00:53 lr 0.079713	time 1.1728 (1.9210)	loss 2.2134 (2.2091)	grad_norm 0.6328 (0.6273)	mem 39782MB
[2023-07-07 18:04:05 RepVGG-A0] (main.py 282): INFO Train: [278/300][60/78]	eta 0:00:33 lr 0.078762	time 1.2630 (1.8762)	loss 2.2155 (2.2090)	grad_norm 0.6323 (0.6273)	mem 39782MB
[2023-07-07 18:04:20 RepVGG-A0] (main.py 282): INFO Train: [278/300][70/78]	eta 0:00:14 lr 0.077818	time 1.2695 (1.8193)	loss 2.1566 (2.2086)	grad_norm 0.6310 (0.6271)	mem 39782MB
[2023-07-07 18:04:32 RepVGG-A0] (main.py 291): INFO EPOCH 278 training takes 0:02:21
[2023-07-07 18:04:54 RepVGG-A0] (main.py 282): INFO Train: [279/300][0/78]	eta 0:29:01 lr 0.077066	time 22.3283 (22.3283)	loss 2.1644 (2.1644)	grad_norm 0.6333 (0.6333)	mem 39782MB
[2023-07-07 18:05:08 RepVGG-A0] (main.py 282): INFO Train: [279/300][10/78]	eta 0:03:44 lr 0.076132	time 1.1813 (3.3053)	loss 2.2045 (2.1887)	grad_norm 0.6290 (0.6256)	mem 39782MB
[2023-07-07 18:05:22 RepVGG-A0] (main.py 282): INFO Train: [279/300][20/78]	eta 0:02:18 lr 0.075203	time 1.1718 (2.3931)	loss 2.1970 (2.1897)	grad_norm 0.6231 (0.6288)	mem 39782MB
[2023-07-07 18:05:38 RepVGG-A0] (main.py 282): INFO Train: [279/300][30/78]	eta 0:01:41 lr 0.074280	time 1.3608 (2.1243)	loss 2.1917 (2.1897)	grad_norm 0.6293 (0.6302)	mem 39782MB
[2023-07-07 18:05:55 RepVGG-A0] (main.py 282): INFO Train: [279/300][40/78]	eta 0:01:17 lr 0.073363	time 3.2053 (2.0368)	loss 2.2035 (2.1952)	grad_norm 0.6336 (0.6288)	mem 39782MB
[2023-07-07 18:06:11 RepVGG-A0] (main.py 282): INFO Train: [279/300][50/78]	eta 0:00:54 lr 0.072451	time 1.1722 (1.9329)	loss 2.1121 (2.1961)	grad_norm 0.6366 (0.6295)	mem 39782MB
[2023-07-07 18:06:26 RepVGG-A0] (main.py 282): INFO Train: [279/300][60/78]	eta 0:00:33 lr 0.071545	time 1.1797 (1.8614)	loss 2.1894 (2.1984)	grad_norm 0.6231 (0.6301)	mem 39782MB
[2023-07-07 18:06:41 RepVGG-A0] (main.py 282): INFO Train: [279/300][70/78]	eta 0:00:14 lr 0.070644	time 1.3483 (1.8117)	loss 2.1810 (2.1993)	grad_norm 0.6338 (0.6305)	mem 39782MB
[2023-07-07 18:06:52 RepVGG-A0] (main.py 291): INFO EPOCH 279 training takes 0:02:20
[2023-07-07 18:07:14 RepVGG-A0] (main.py 282): INFO Train: [280/300][0/78]	eta 0:28:27 lr 0.069928	time 21.8887 (21.8887)	loss 2.1410 (2.1410)	grad_norm 0.6307 (0.6307)	mem 39782MB
[2023-07-07 18:07:29 RepVGG-A0] (main.py 282): INFO Train: [280/300][10/78]	eta 0:03:46 lr 0.069037	time 1.1908 (3.3253)	loss 2.2135 (2.1918)	grad_norm 0.6386 (0.6312)	mem 39782MB
[2023-07-07 18:07:44 RepVGG-A0] (main.py 282): INFO Train: [280/300][20/78]	eta 0:02:22 lr 0.068153	time 1.3898 (2.4514)	loss 2.1387 (2.1855)	grad_norm 0.6311 (0.6313)	mem 39782MB
[2023-07-07 18:07:58 RepVGG-A0] (main.py 282): INFO Train: [280/300][30/78]	eta 0:01:41 lr 0.067273	time 1.2488 (2.1209)	loss 2.2155 (2.1879)	grad_norm 0.6304 (0.6313)	mem 39782MB
[2023-07-07 18:08:17 RepVGG-A0] (main.py 282): INFO Train: [280/300][40/78]	eta 0:01:19 lr 0.066400	time 4.6820 (2.0795)	loss 2.1662 (2.1924)	grad_norm 0.6321 (0.6312)	mem 39782MB
[2023-07-07 18:08:32 RepVGG-A0] (main.py 282): INFO Train: [280/300][50/78]	eta 0:00:54 lr 0.065532	time 1.1908 (1.9606)	loss 2.2303 (2.1956)	grad_norm 0.6427 (0.6314)	mem 39782MB
[2023-07-07 18:08:47 RepVGG-A0] (main.py 282): INFO Train: [280/300][60/78]	eta 0:00:33 lr 0.064670	time 1.1747 (1.8860)	loss 2.1932 (2.1973)	grad_norm 0.6401 (0.6316)	mem 39782MB
[2023-07-07 18:09:03 RepVGG-A0] (main.py 282): INFO Train: [280/300][70/78]	eta 0:00:14 lr 0.063813	time 1.1793 (1.8357)	loss 2.1651 (2.1967)	grad_norm 0.6405 (0.6322)	mem 39782MB
[2023-07-07 18:09:14 RepVGG-A0] (main.py 291): INFO EPOCH 280 training takes 0:02:22
[2023-07-07 18:09:32 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.610 (17.610)	Loss 1.3635 (1.3635)	Acc@1 69.037 (69.037)	Acc@5 88.812 (88.812)	Mem 39782MB
[2023-07-07 18:09:33 RepVGG-A0] (main.py 342): INFO  * Acc@1 69.638 Acc@5 88.854
[2023-07-07 18:09:33 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 280: 69.638%
[2023-07-07 18:09:33 RepVGG-A0] (main.py 172): INFO Max accuracy: 69.64%
[2023-07-07 18:09:52 RepVGG-A0] (main.py 282): INFO Train: [281/300][0/78]	eta 0:24:14 lr 0.063132	time 18.6445 (18.6445)	loss 2.2099 (2.2099)	grad_norm 0.6216 (0.6216)	mem 39782MB
[2023-07-07 18:10:08 RepVGG-A0] (main.py 282): INFO Train: [281/300][10/78]	eta 0:03:36 lr 0.062286	time 1.1711 (3.1886)	loss 2.1532 (2.1961)	grad_norm 0.6274 (0.6287)	mem 39782MB
[2023-07-07 18:10:24 RepVGG-A0] (main.py 282): INFO Train: [281/300][20/78]	eta 0:02:20 lr 0.061445	time 1.1926 (2.4228)	loss 2.1101 (2.1869)	grad_norm 0.6191 (0.6288)	mem 39782MB
[2023-07-07 18:10:39 RepVGG-A0] (main.py 282): INFO Train: [281/300][30/78]	eta 0:01:42 lr 0.060610	time 1.3033 (2.1308)	loss 2.1768 (2.1924)	grad_norm 0.6321 (0.6304)	mem 39782MB
[2023-07-07 18:10:58 RepVGG-A0] (main.py 282): INFO Train: [281/300][40/78]	eta 0:01:18 lr 0.059781	time 2.8544 (2.0576)	loss 2.2094 (2.1900)	grad_norm 0.6289 (0.6306)	mem 39782MB
[2023-07-07 18:11:12 RepVGG-A0] (main.py 282): INFO Train: [281/300][50/78]	eta 0:00:54 lr 0.058957	time 1.1725 (1.9380)	loss 2.2417 (2.1922)	grad_norm 0.6314 (0.6313)	mem 39782MB
[2023-07-07 18:11:28 RepVGG-A0] (main.py 282): INFO Train: [281/300][60/78]	eta 0:00:33 lr 0.058139	time 1.2554 (1.8753)	loss 2.2063 (2.1929)	grad_norm 0.6353 (0.6314)	mem 39782MB
[2023-07-07 18:11:43 RepVGG-A0] (main.py 282): INFO Train: [281/300][70/78]	eta 0:00:14 lr 0.057327	time 1.1724 (1.8294)	loss 2.2655 (2.1952)	grad_norm 0.6258 (0.6322)	mem 39782MB
[2023-07-07 18:11:54 RepVGG-A0] (main.py 291): INFO EPOCH 281 training takes 0:02:20
[2023-07-07 18:12:15 RepVGG-A0] (main.py 282): INFO Train: [282/300][0/78]	eta 0:27:35 lr 0.056681	time 21.2182 (21.2182)	loss 2.1857 (2.1857)	grad_norm 0.6240 (0.6240)	mem 39782MB
[2023-07-07 18:12:32 RepVGG-A0] (main.py 282): INFO Train: [282/300][10/78]	eta 0:03:51 lr 0.055879	time 1.1753 (3.4076)	loss 2.2499 (2.1882)	grad_norm 0.6307 (0.6304)	mem 39782MB
[2023-07-07 18:12:46 RepVGG-A0] (main.py 282): INFO Train: [282/300][20/78]	eta 0:02:24 lr 0.055082	time 1.1260 (2.4866)	loss 2.1276 (2.1841)	grad_norm 0.6330 (0.6300)	mem 39782MB
[2023-07-07 18:13:02 RepVGG-A0] (main.py 282): INFO Train: [282/300][30/78]	eta 0:01:44 lr 0.054291	time 1.4343 (2.1715)	loss 2.2229 (2.1763)	grad_norm 0.6427 (0.6300)	mem 39782MB
[2023-07-07 18:13:20 RepVGG-A0] (main.py 282): INFO Train: [282/300][40/78]	eta 0:01:19 lr 0.053506	time 4.4596 (2.0942)	loss 2.2044 (2.1801)	grad_norm 0.6304 (0.6312)	mem 39782MB
[2023-07-07 18:13:34 RepVGG-A0] (main.py 282): INFO Train: [282/300][50/78]	eta 0:00:55 lr 0.052727	time 1.1728 (1.9649)	loss 2.1535 (2.1781)	grad_norm 0.6291 (0.6317)	mem 39782MB
[2023-07-07 18:13:50 RepVGG-A0] (main.py 282): INFO Train: [282/300][60/78]	eta 0:00:34 lr 0.051953	time 1.1857 (1.8950)	loss 2.2107 (2.1818)	grad_norm 0.6489 (0.6326)	mem 39782MB
[2023-07-07 18:14:05 RepVGG-A0] (main.py 282): INFO Train: [282/300][70/78]	eta 0:00:14 lr 0.051185	time 1.3548 (1.8420)	loss 2.1581 (2.1813)	grad_norm 0.6391 (0.6338)	mem 39782MB
[2023-07-07 18:14:16 RepVGG-A0] (main.py 291): INFO EPOCH 282 training takes 0:02:22
[2023-07-07 18:14:35 RepVGG-A0] (main.py 282): INFO Train: [283/300][0/78]	eta 0:23:57 lr 0.050574	time 18.4305 (18.4305)	loss 2.1696 (2.1696)	grad_norm 0.6352 (0.6352)	mem 39782MB
[2023-07-07 18:14:52 RepVGG-A0] (main.py 282): INFO Train: [283/300][10/78]	eta 0:03:42 lr 0.049816	time 1.1719 (3.2787)	loss 2.1737 (2.1761)	grad_norm 0.6357 (0.6315)	mem 39782MB
[2023-07-07 18:15:07 RepVGG-A0] (main.py 282): INFO Train: [283/300][20/78]	eta 0:02:20 lr 0.049064	time 1.1753 (2.4148)	loss 2.2005 (2.1840)	grad_norm 0.6375 (0.6325)	mem 39782MB
[2023-07-07 18:15:22 RepVGG-A0] (main.py 282): INFO Train: [283/300][30/78]	eta 0:01:41 lr 0.048317	time 1.4530 (2.1058)	loss 2.2634 (2.1814)	grad_norm 0.6477 (0.6340)	mem 39782MB
[2023-07-07 18:15:40 RepVGG-A0] (main.py 282): INFO Train: [283/300][40/78]	eta 0:01:17 lr 0.047576	time 4.7302 (2.0440)	loss 2.2209 (2.1820)	grad_norm 0.6324 (0.6340)	mem 39782MB
[2023-07-07 18:15:54 RepVGG-A0] (main.py 282): INFO Train: [283/300][50/78]	eta 0:00:53 lr 0.046841	time 1.1738 (1.9238)	loss 2.1727 (2.1818)	grad_norm 0.6307 (0.6344)	mem 39782MB
[2023-07-07 18:16:09 RepVGG-A0] (main.py 282): INFO Train: [283/300][60/78]	eta 0:00:33 lr 0.046112	time 1.1724 (1.8539)	loss 2.2018 (2.1826)	grad_norm 0.6432 (0.6346)	mem 39782MB
[2023-07-07 18:16:25 RepVGG-A0] (main.py 282): INFO Train: [283/300][70/78]	eta 0:00:14 lr 0.045388	time 1.3349 (1.8158)	loss 2.1316 (2.1831)	grad_norm 0.6443 (0.6353)	mem 39782MB
[2023-07-07 18:16:37 RepVGG-A0] (main.py 291): INFO EPOCH 283 training takes 0:02:20
[2023-07-07 18:16:59 RepVGG-A0] (main.py 282): INFO Train: [284/300][0/78]	eta 0:28:37 lr 0.044813	time 22.0140 (22.0140)	loss 2.1687 (2.1687)	grad_norm 0.6296 (0.6296)	mem 39782MB
[2023-07-07 18:17:13 RepVGG-A0] (main.py 282): INFO Train: [284/300][10/78]	eta 0:03:43 lr 0.044099	time 1.1938 (3.2844)	loss 2.1242 (2.1603)	grad_norm 0.6321 (0.6322)	mem 39782MB
[2023-07-07 18:17:28 RepVGG-A0] (main.py 282): INFO Train: [284/300][20/78]	eta 0:02:21 lr 0.043391	time 1.2430 (2.4317)	loss 2.1514 (2.1563)	grad_norm 0.6344 (0.6327)	mem 39782MB
[2023-07-07 18:17:42 RepVGG-A0] (main.py 282): INFO Train: [284/300][30/78]	eta 0:01:41 lr 0.042689	time 1.4340 (2.1213)	loss 2.1814 (2.1654)	grad_norm 0.6331 (0.6334)	mem 39782MB
[2023-07-07 18:18:01 RepVGG-A0] (main.py 282): INFO Train: [284/300][40/78]	eta 0:01:18 lr 0.041992	time 4.5396 (2.0536)	loss 2.1303 (2.1692)	grad_norm 0.6395 (0.6343)	mem 39782MB
[2023-07-07 18:18:16 RepVGG-A0] (main.py 282): INFO Train: [284/300][50/78]	eta 0:00:54 lr 0.041301	time 1.1734 (1.9584)	loss 2.2119 (2.1695)	grad_norm 0.6439 (0.6352)	mem 39782MB
[2023-07-07 18:18:31 RepVGG-A0] (main.py 282): INFO Train: [284/300][60/78]	eta 0:00:33 lr 0.040616	time 1.1961 (1.8692)	loss 2.1583 (2.1716)	grad_norm 0.6367 (0.6358)	mem 39782MB
[2023-07-07 18:18:45 RepVGG-A0] (main.py 282): INFO Train: [284/300][70/78]	eta 0:00:14 lr 0.039937	time 1.3256 (1.8113)	loss 2.1682 (2.1716)	grad_norm 0.6448 (0.6363)	mem 39782MB
[2023-07-07 18:18:57 RepVGG-A0] (main.py 291): INFO EPOCH 284 training takes 0:02:20
[2023-07-07 18:19:19 RepVGG-A0] (main.py 282): INFO Train: [285/300][0/78]	eta 0:28:19 lr 0.039397	time 21.7946 (21.7946)	loss 2.1441 (2.1441)	grad_norm 0.6319 (0.6319)	mem 39782MB
[2023-07-07 18:19:33 RepVGG-A0] (main.py 282): INFO Train: [285/300][10/78]	eta 0:03:41 lr 0.038728	time 1.1716 (3.2557)	loss 2.1458 (2.1675)	grad_norm 0.6371 (0.6377)	mem 39782MB
[2023-07-07 18:19:48 RepVGG-A0] (main.py 282): INFO Train: [285/300][20/78]	eta 0:02:20 lr 0.038065	time 1.1744 (2.4213)	loss 2.1712 (2.1702)	grad_norm 0.6384 (0.6370)	mem 39782MB
[2023-07-07 18:20:04 RepVGG-A0] (main.py 282): INFO Train: [285/300][30/78]	eta 0:01:42 lr 0.037407	time 1.6439 (2.1448)	loss 2.1656 (2.1723)	grad_norm 0.6332 (0.6374)	mem 39782MB
[2023-07-07 18:20:22 RepVGG-A0] (main.py 282): INFO Train: [285/300][40/78]	eta 0:01:18 lr 0.036755	time 2.7682 (2.0587)	loss 2.1233 (2.1725)	grad_norm 0.6368 (0.6371)	mem 39782MB
[2023-07-07 18:20:37 RepVGG-A0] (main.py 282): INFO Train: [285/300][50/78]	eta 0:00:54 lr 0.036108	time 1.2446 (1.9618)	loss 2.2516 (2.1723)	grad_norm 0.6503 (0.6375)	mem 39782MB
[2023-07-07 18:20:52 RepVGG-A0] (main.py 282): INFO Train: [285/300][60/78]	eta 0:00:33 lr 0.035467	time 1.3681 (1.8815)	loss 2.1690 (2.1731)	grad_norm 0.6346 (0.6379)	mem 39782MB
[2023-07-07 18:21:07 RepVGG-A0] (main.py 282): INFO Train: [285/300][70/78]	eta 0:00:14 lr 0.034832	time 1.2063 (1.8330)	loss 2.1618 (2.1720)	grad_norm 0.6494 (0.6384)	mem 39782MB
[2023-07-07 18:21:19 RepVGG-A0] (main.py 291): INFO EPOCH 285 training takes 0:02:21
[2023-07-07 18:21:40 RepVGG-A0] (main.py 282): INFO Train: [286/300][0/78]	eta 0:28:07 lr 0.034329	time 21.6403 (21.6403)	loss 2.2084 (2.2084)	grad_norm 0.6346 (0.6346)	mem 39782MB
[2023-07-07 18:21:55 RepVGG-A0] (main.py 282): INFO Train: [286/300][10/78]	eta 0:03:46 lr 0.033704	time 1.1730 (3.3235)	loss 2.1489 (2.1577)	grad_norm 0.6388 (0.6375)	mem 39782MB
[2023-07-07 18:22:11 RepVGG-A0] (main.py 282): INFO Train: [286/300][20/78]	eta 0:02:23 lr 0.033085	time 1.2464 (2.4769)	loss 2.1469 (2.1626)	grad_norm 0.6456 (0.6377)	mem 39782MB
[2023-07-07 18:22:26 RepVGG-A0] (main.py 282): INFO Train: [286/300][30/78]	eta 0:01:44 lr 0.032471	time 1.2338 (2.1801)	loss 2.1402 (2.1658)	grad_norm 0.6315 (0.6382)	mem 39782MB
[2023-07-07 18:22:43 RepVGG-A0] (main.py 282): INFO Train: [286/300][40/78]	eta 0:01:18 lr 0.031864	time 3.1289 (2.0641)	loss 2.2114 (2.1690)	grad_norm 0.6351 (0.6383)	mem 39782MB
[2023-07-07 18:22:58 RepVGG-A0] (main.py 282): INFO Train: [286/300][50/78]	eta 0:00:54 lr 0.031262	time 1.1725 (1.9543)	loss 2.1783 (2.1677)	grad_norm 0.6456 (0.6389)	mem 39782MB
[2023-07-07 18:23:14 RepVGG-A0] (main.py 282): INFO Train: [286/300][60/78]	eta 0:00:33 lr 0.030666	time 1.1777 (1.8854)	loss 2.1411 (2.1677)	grad_norm 0.6461 (0.6393)	mem 39782MB
[2023-07-07 18:23:29 RepVGG-A0] (main.py 282): INFO Train: [286/300][70/78]	eta 0:00:14 lr 0.030075	time 1.3031 (1.8372)	loss 2.1406 (2.1674)	grad_norm 0.6385 (0.6391)	mem 39782MB
[2023-07-07 18:23:41 RepVGG-A0] (main.py 291): INFO EPOCH 286 training takes 0:02:22
[2023-07-07 18:24:02 RepVGG-A0] (main.py 282): INFO Train: [287/300][0/78]	eta 0:27:27 lr 0.029607	time 21.1168 (21.1168)	loss 2.1262 (2.1262)	grad_norm 0.6271 (0.6271)	mem 39782MB
[2023-07-07 18:24:16 RepVGG-A0] (main.py 282): INFO Train: [287/300][10/78]	eta 0:03:35 lr 0.029027	time 1.1719 (3.1692)	loss 2.1596 (2.1594)	grad_norm 0.6414 (0.6348)	mem 39782MB
[2023-07-07 18:24:30 RepVGG-A0] (main.py 282): INFO Train: [287/300][20/78]	eta 0:02:16 lr 0.028452	time 1.1737 (2.3541)	loss 2.2111 (2.1648)	grad_norm 0.6405 (0.6372)	mem 39782MB
[2023-07-07 18:24:47 RepVGG-A0] (main.py 282): INFO Train: [287/300][30/78]	eta 0:01:42 lr 0.027883	time 1.3025 (2.1368)	loss 2.1677 (2.1655)	grad_norm 0.6416 (0.6386)	mem 39782MB
[2023-07-07 18:25:04 RepVGG-A0] (main.py 282): INFO Train: [287/300][40/78]	eta 0:01:17 lr 0.027320	time 4.3709 (2.0285)	loss 2.1481 (2.1646)	grad_norm 0.6366 (0.6384)	mem 39782MB
[2023-07-07 18:25:19 RepVGG-A0] (main.py 282): INFO Train: [287/300][50/78]	eta 0:00:53 lr 0.026763	time 1.1727 (1.9242)	loss 2.1510 (2.1640)	grad_norm 0.6437 (0.6379)	mem 39782MB
[2023-07-07 18:25:34 RepVGG-A0] (main.py 282): INFO Train: [287/300][60/78]	eta 0:00:33 lr 0.026211	time 1.1786 (1.8549)	loss 2.2041 (2.1627)	grad_norm 0.6364 (0.6377)	mem 39782MB
[2023-07-07 18:25:49 RepVGG-A0] (main.py 282): INFO Train: [287/300][70/78]	eta 0:00:14 lr 0.025666	time 1.1708 (1.8099)	loss 2.2119 (2.1640)	grad_norm 0.6396 (0.6378)	mem 39782MB
[2023-07-07 18:26:02 RepVGG-A0] (main.py 291): INFO EPOCH 287 training takes 0:02:20
[2023-07-07 18:26:23 RepVGG-A0] (main.py 282): INFO Train: [288/300][0/78]	eta 0:28:07 lr 0.025233	time 21.6345 (21.6345)	loss 2.1550 (2.1550)	grad_norm 0.6299 (0.6299)	mem 39782MB
[2023-07-07 18:26:39 RepVGG-A0] (main.py 282): INFO Train: [288/300][10/78]	eta 0:03:49 lr 0.024697	time 1.1894 (3.3710)	loss 2.1173 (2.1496)	grad_norm 0.6283 (0.6344)	mem 39782MB
[2023-07-07 18:26:53 RepVGG-A0] (main.py 282): INFO Train: [288/300][20/78]	eta 0:02:22 lr 0.024167	time 1.2153 (2.4543)	loss 2.1821 (2.1601)	grad_norm 0.6313 (0.6354)	mem 39782MB
[2023-07-07 18:27:09 RepVGG-A0] (main.py 282): INFO Train: [288/300][30/78]	eta 0:01:43 lr 0.023643	time 1.3347 (2.1538)	loss 2.2230 (2.1661)	grad_norm 0.6364 (0.6366)	mem 39782MB
[2023-07-07 18:27:26 RepVGG-A0] (main.py 282): INFO Train: [288/300][40/78]	eta 0:01:18 lr 0.023125	time 3.7322 (2.0573)	loss 2.2067 (2.1697)	grad_norm 0.6396 (0.6369)	mem 39782MB
[2023-07-07 18:27:41 RepVGG-A0] (main.py 282): INFO Train: [288/300][50/78]	eta 0:00:54 lr 0.022612	time 1.1734 (1.9556)	loss 2.1657 (2.1706)	grad_norm 0.6432 (0.6380)	mem 39782MB
[2023-07-07 18:27:57 RepVGG-A0] (main.py 282): INFO Train: [288/300][60/78]	eta 0:00:34 lr 0.022105	time 1.4181 (1.8908)	loss 2.1864 (2.1703)	grad_norm 0.6505 (0.6383)	mem 39782MB
[2023-07-07 18:28:13 RepVGG-A0] (main.py 282): INFO Train: [288/300][70/78]	eta 0:00:14 lr 0.021604	time 1.3259 (1.8455)	loss 2.1393 (2.1681)	grad_norm 0.6443 (0.6382)	mem 39782MB
[2023-07-07 18:28:23 RepVGG-A0] (main.py 291): INFO EPOCH 288 training takes 0:02:21
[2023-07-07 18:28:45 RepVGG-A0] (main.py 282): INFO Train: [289/300][0/78]	eta 0:28:22 lr 0.021207	time 21.8317 (21.8317)	loss 2.1492 (2.1492)	grad_norm 0.6301 (0.6301)	mem 39782MB
[2023-07-07 18:28:59 RepVGG-A0] (main.py 282): INFO Train: [289/300][10/78]	eta 0:03:43 lr 0.020716	time 1.1734 (3.2828)	loss 2.2036 (2.1574)	grad_norm 0.6348 (0.6334)	mem 39782MB
[2023-07-07 18:29:14 RepVGG-A0] (main.py 282): INFO Train: [289/300][20/78]	eta 0:02:19 lr 0.020231	time 1.4280 (2.4061)	loss 2.1593 (2.1599)	grad_norm 0.6334 (0.6342)	mem 39782MB
[2023-07-07 18:29:29 RepVGG-A0] (main.py 282): INFO Train: [289/300][30/78]	eta 0:01:41 lr 0.019752	time 1.4600 (2.1193)	loss 2.1010 (2.1596)	grad_norm 0.6473 (0.6355)	mem 39782MB
[2023-07-07 18:29:47 RepVGG-A0] (main.py 282): INFO Train: [289/300][40/78]	eta 0:01:17 lr 0.019278	time 3.2525 (2.0316)	loss 2.1412 (2.1571)	grad_norm 0.6360 (0.6361)	mem 39782MB
[2023-07-07 18:30:02 RepVGG-A0] (main.py 282): INFO Train: [289/300][50/78]	eta 0:00:54 lr 0.018810	time 1.1732 (1.9332)	loss 2.1911 (2.1540)	grad_norm 0.6379 (0.6367)	mem 39782MB
[2023-07-07 18:30:17 RepVGG-A0] (main.py 282): INFO Train: [289/300][60/78]	eta 0:00:33 lr 0.018348	time 1.1273 (1.8642)	loss 2.1375 (2.1577)	grad_norm 0.6434 (0.6373)	mem 39782MB
[2023-07-07 18:30:32 RepVGG-A0] (main.py 282): INFO Train: [289/300][70/78]	eta 0:00:14 lr 0.017891	time 1.2588 (1.8087)	loss 2.1469 (2.1586)	grad_norm 0.6380 (0.6376)	mem 39782MB
[2023-07-07 18:30:44 RepVGG-A0] (main.py 291): INFO EPOCH 289 training takes 0:02:20
[2023-07-07 18:31:05 RepVGG-A0] (main.py 282): INFO Train: [290/300][0/78]	eta 0:27:56 lr 0.017530	time 21.4973 (21.4973)	loss 2.1439 (2.1439)	grad_norm 0.6331 (0.6331)	mem 39782MB
[2023-07-07 18:31:20 RepVGG-A0] (main.py 282): INFO Train: [290/300][10/78]	eta 0:03:45 lr 0.017084	time 1.1712 (3.3221)	loss 2.1525 (2.1537)	grad_norm 0.6345 (0.6371)	mem 39782MB
[2023-07-07 18:31:36 RepVGG-A0] (main.py 282): INFO Train: [290/300][20/78]	eta 0:02:24 lr 0.016643	time 1.4764 (2.4903)	loss 2.1880 (2.1511)	grad_norm 0.6403 (0.6375)	mem 39782MB
[2023-07-07 18:31:51 RepVGG-A0] (main.py 282): INFO Train: [290/300][30/78]	eta 0:01:43 lr 0.016209	time 1.3281 (2.1595)	loss 2.1806 (2.1510)	grad_norm 0.6392 (0.6381)	mem 39782MB
[2023-07-07 18:32:09 RepVGG-A0] (main.py 282): INFO Train: [290/300][40/78]	eta 0:01:19 lr 0.015780	time 4.0288 (2.0825)	loss 2.1365 (2.1498)	grad_norm 0.6362 (0.6382)	mem 39782MB
[2023-07-07 18:32:24 RepVGG-A0] (main.py 282): INFO Train: [290/300][50/78]	eta 0:00:55 lr 0.015356	time 1.1810 (1.9672)	loss 2.1728 (2.1518)	grad_norm 0.6442 (0.6385)	mem 39782MB
[2023-07-07 18:32:39 RepVGG-A0] (main.py 282): INFO Train: [290/300][60/78]	eta 0:00:33 lr 0.014939	time 1.3576 (1.8878)	loss 2.1010 (2.1484)	grad_norm 0.6374 (0.6388)	mem 39782MB
[2023-07-07 18:32:54 RepVGG-A0] (main.py 282): INFO Train: [290/300][70/78]	eta 0:00:14 lr 0.014527	time 1.1930 (1.8365)	loss 2.1419 (2.1499)	grad_norm 0.6340 (0.6390)	mem 39782MB
[2023-07-07 18:33:06 RepVGG-A0] (main.py 291): INFO EPOCH 290 training takes 0:02:21
[2023-07-07 18:33:23 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.684 (17.684)	Loss 1.3477 (1.3477)	Acc@1 70.551 (70.551)	Acc@5 89.075 (89.075)	Mem 39782MB
[2023-07-07 18:33:24 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.714 Acc@5 89.520
[2023-07-07 18:33:24 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 290: 70.714%
[2023-07-07 18:33:24 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:33:46 RepVGG-A0] (main.py 282): INFO Train: [291/300][0/78]	eta 0:27:49 lr 0.014202	time 21.4038 (21.4038)	loss 2.1491 (2.1491)	grad_norm 0.6434 (0.6434)	mem 39782MB
[2023-07-07 18:34:01 RepVGG-A0] (main.py 282): INFO Train: [291/300][10/78]	eta 0:03:48 lr 0.013800	time 1.1914 (3.3619)	loss 2.1712 (2.1507)	grad_norm 0.6438 (0.6372)	mem 39782MB
[2023-07-07 18:34:15 RepVGG-A0] (main.py 282): INFO Train: [291/300][20/78]	eta 0:02:20 lr 0.013405	time 1.1730 (2.4183)	loss 2.1234 (2.1415)	grad_norm 0.6340 (0.6360)	mem 39782MB
[2023-07-07 18:34:30 RepVGG-A0] (main.py 282): INFO Train: [291/300][30/78]	eta 0:01:41 lr 0.013015	time 1.1269 (2.1071)	loss 2.0819 (2.1424)	grad_norm 0.6422 (0.6367)	mem 39782MB
[2023-07-07 18:34:48 RepVGG-A0] (main.py 282): INFO Train: [291/300][40/78]	eta 0:01:17 lr 0.012630	time 3.3664 (2.0319)	loss 2.1262 (2.1458)	grad_norm 0.6372 (0.6366)	mem 39782MB
[2023-07-07 18:35:03 RepVGG-A0] (main.py 282): INFO Train: [291/300][50/78]	eta 0:00:53 lr 0.012252	time 1.3551 (1.9228)	loss 2.1296 (2.1448)	grad_norm 0.6398 (0.6368)	mem 39782MB
[2023-07-07 18:35:17 RepVGG-A0] (main.py 282): INFO Train: [291/300][60/78]	eta 0:00:33 lr 0.011879	time 1.1747 (1.8417)	loss 2.1387 (2.1469)	grad_norm 0.6288 (0.6369)	mem 39782MB
[2023-07-07 18:35:31 RepVGG-A0] (main.py 282): INFO Train: [291/300][70/78]	eta 0:00:14 lr 0.011512	time 1.1918 (1.7883)	loss 2.1914 (2.1480)	grad_norm 0.6503 (0.6372)	mem 39782MB
[2023-07-07 18:35:44 RepVGG-A0] (main.py 291): INFO EPOCH 291 training takes 0:02:19
[2023-07-07 18:36:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.304 (17.304)	Loss 1.3313 (1.3313)	Acc@1 70.636 (70.636)	Acc@5 89.459 (89.459)	Mem 39782MB
[2023-07-07 18:36:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.680 Acc@5 89.592
[2023-07-07 18:36:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 291: 70.680%
[2023-07-07 18:36:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:36:25 RepVGG-A0] (main.py 282): INFO Train: [292/300][0/78]	eta 0:28:59 lr 0.011223	time 22.3040 (22.3040)	loss 2.1200 (2.1200)	grad_norm 0.6248 (0.6248)	mem 39782MB
[2023-07-07 18:36:39 RepVGG-A0] (main.py 282): INFO Train: [292/300][10/78]	eta 0:03:47 lr 0.010866	time 1.1993 (3.3443)	loss 2.1357 (2.1548)	grad_norm 0.6354 (0.6333)	mem 39782MB
[2023-07-07 18:36:52 RepVGG-A0] (main.py 282): INFO Train: [292/300][20/78]	eta 0:02:17 lr 0.010515	time 1.1733 (2.3674)	loss 2.1204 (2.1486)	grad_norm 0.6346 (0.6351)	mem 39782MB
[2023-07-07 18:37:09 RepVGG-A0] (main.py 282): INFO Train: [292/300][30/78]	eta 0:01:43 lr 0.010170	time 1.7856 (2.1543)	loss 2.1202 (2.1477)	grad_norm 0.6324 (0.6356)	mem 39782MB
[2023-07-07 18:37:24 RepVGG-A0] (main.py 282): INFO Train: [292/300][40/78]	eta 0:01:15 lr 0.009831	time 1.3025 (1.9923)	loss 2.1682 (2.1497)	grad_norm 0.6360 (0.6356)	mem 39782MB
[2023-07-07 18:37:42 RepVGG-A0] (main.py 282): INFO Train: [292/300][50/78]	eta 0:00:54 lr 0.009497	time 1.1742 (1.9505)	loss 2.1787 (2.1510)	grad_norm 0.6320 (0.6359)	mem 39782MB
[2023-07-07 18:37:57 RepVGG-A0] (main.py 282): INFO Train: [292/300][60/78]	eta 0:00:33 lr 0.009169	time 1.5253 (1.8821)	loss 2.1655 (2.1524)	grad_norm 0.6324 (0.6360)	mem 39782MB
[2023-07-07 18:38:12 RepVGG-A0] (main.py 282): INFO Train: [292/300][70/78]	eta 0:00:14 lr 0.008847	time 1.3454 (1.8277)	loss 2.1730 (2.1511)	grad_norm 0.6374 (0.6361)	mem 39782MB
[2023-07-07 18:38:24 RepVGG-A0] (main.py 291): INFO EPOCH 292 training takes 0:02:21
[2023-07-07 18:38:41 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.242 (17.242)	Loss 1.3228 (1.3228)	Acc@1 70.398 (70.398)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:38:42 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.696 Acc@5 89.542
[2023-07-07 18:38:42 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 292: 70.696%
[2023-07-07 18:38:42 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:39:04 RepVGG-A0] (main.py 282): INFO Train: [293/300][0/78]	eta 0:28:23 lr 0.008594	time 21.8410 (21.8410)	loss 2.1669 (2.1669)	grad_norm 0.6353 (0.6353)	mem 39782MB
[2023-07-07 18:39:19 RepVGG-A0] (main.py 282): INFO Train: [293/300][10/78]	eta 0:03:46 lr 0.008282	time 1.1714 (3.3327)	loss 2.1395 (2.1368)	grad_norm 0.6343 (0.6344)	mem 39782MB
[2023-07-07 18:39:34 RepVGG-A0] (main.py 282): INFO Train: [293/300][20/78]	eta 0:02:22 lr 0.007976	time 1.2610 (2.4578)	loss 2.1305 (2.1452)	grad_norm 0.6426 (0.6347)	mem 39782MB
[2023-07-07 18:39:48 RepVGG-A0] (main.py 282): INFO Train: [293/300][30/78]	eta 0:01:42 lr 0.007676	time 1.3762 (2.1308)	loss 2.1611 (2.1465)	grad_norm 0.6335 (0.6353)	mem 39782MB
[2023-07-07 18:40:06 RepVGG-A0] (main.py 282): INFO Train: [293/300][40/78]	eta 0:01:17 lr 0.007381	time 3.1003 (2.0441)	loss 2.1433 (2.1476)	grad_norm 0.6293 (0.6353)	mem 39782MB
[2023-07-07 18:40:21 RepVGG-A0] (main.py 282): INFO Train: [293/300][50/78]	eta 0:00:54 lr 0.007092	time 1.1729 (1.9329)	loss 2.1448 (2.1480)	grad_norm 0.6350 (0.6354)	mem 39782MB
[2023-07-07 18:40:36 RepVGG-A0] (main.py 282): INFO Train: [293/300][60/78]	eta 0:00:33 lr 0.006809	time 1.2049 (1.8725)	loss 2.1192 (2.1461)	grad_norm 0.6328 (0.6346)	mem 39782MB
[2023-07-07 18:40:51 RepVGG-A0] (main.py 282): INFO Train: [293/300][70/78]	eta 0:00:14 lr 0.006532	time 1.4239 (1.8195)	loss 2.1057 (2.1449)	grad_norm 0.6330 (0.6345)	mem 39782MB
[2023-07-07 18:41:04 RepVGG-A0] (main.py 291): INFO EPOCH 293 training takes 0:02:21
[2023-07-07 18:41:21 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.209 (17.209)	Loss 1.3155 (1.3155)	Acc@1 70.862 (70.862)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:41:22 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.908 Acc@5 89.588
[2023-07-07 18:41:22 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 293: 70.908%
[2023-07-07 18:41:22 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:41:45 RepVGG-A0] (main.py 282): INFO Train: [294/300][0/78]	eta 0:29:27 lr 0.006314	time 22.6570 (22.6570)	loss 2.1402 (2.1402)	grad_norm 0.6317 (0.6317)	mem 39782MB
[2023-07-07 18:41:59 RepVGG-A0] (main.py 282): INFO Train: [294/300][10/78]	eta 0:03:49 lr 0.006048	time 1.1705 (3.3749)	loss 2.1540 (2.1506)	grad_norm 0.6324 (0.6331)	mem 39782MB
[2023-07-07 18:42:13 RepVGG-A0] (main.py 282): INFO Train: [294/300][20/78]	eta 0:02:21 lr 0.005786	time 1.1743 (2.4358)	loss 2.1270 (2.1390)	grad_norm 0.6389 (0.6340)	mem 39782MB
[2023-07-07 18:42:29 RepVGG-A0] (main.py 282): INFO Train: [294/300][30/78]	eta 0:01:42 lr 0.005531	time 1.1925 (2.1451)	loss 2.1302 (2.1392)	grad_norm 0.6441 (0.6348)	mem 39782MB
[2023-07-07 18:42:47 RepVGG-A0] (main.py 282): INFO Train: [294/300][40/78]	eta 0:01:18 lr 0.005281	time 3.9316 (2.0667)	loss 2.1083 (2.1418)	grad_norm 0.6303 (0.6342)	mem 39782MB
[2023-07-07 18:43:01 RepVGG-A0] (main.py 282): INFO Train: [294/300][50/78]	eta 0:00:54 lr 0.005038	time 1.1728 (1.9490)	loss 2.1319 (2.1400)	grad_norm 0.6358 (0.6345)	mem 39782MB
[2023-07-07 18:43:16 RepVGG-A0] (main.py 282): INFO Train: [294/300][60/78]	eta 0:00:33 lr 0.004800	time 1.3435 (1.8747)	loss 2.1215 (2.1391)	grad_norm 0.6295 (0.6341)	mem 39782MB
[2023-07-07 18:43:32 RepVGG-A0] (main.py 282): INFO Train: [294/300][70/78]	eta 0:00:14 lr 0.004567	time 1.1255 (1.8277)	loss 2.1158 (2.1407)	grad_norm 0.6185 (0.6338)	mem 39782MB
[2023-07-07 18:43:43 RepVGG-A0] (main.py 291): INFO EPOCH 294 training takes 0:02:20
[2023-07-07 18:44:00 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.472 (17.472)	Loss 1.3250 (1.3250)	Acc@1 70.532 (70.532)	Acc@5 89.752 (89.752)	Mem 39782MB
[2023-07-07 18:44:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.842 Acc@5 89.598
[2023-07-07 18:44:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 294: 70.842%
[2023-07-07 18:44:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:44:23 RepVGG-A0] (main.py 282): INFO Train: [295/300][0/78]	eta 0:27:19 lr 0.004385	time 21.0173 (21.0173)	loss 2.1467 (2.1467)	grad_norm 0.6282 (0.6282)	mem 39782MB
[2023-07-07 18:44:38 RepVGG-A0] (main.py 282): INFO Train: [295/300][10/78]	eta 0:03:42 lr 0.004164	time 1.1700 (3.2761)	loss 2.1671 (2.1525)	grad_norm 0.6271 (0.6331)	mem 39782MB
[2023-07-07 18:44:52 RepVGG-A0] (main.py 282): INFO Train: [295/300][20/78]	eta 0:02:18 lr 0.003947	time 1.1724 (2.3958)	loss 2.1192 (2.1559)	grad_norm 0.6318 (0.6325)	mem 39782MB
[2023-07-07 18:45:07 RepVGG-A0] (main.py 282): INFO Train: [295/300][30/78]	eta 0:01:41 lr 0.003737	time 1.5120 (2.1170)	loss 2.1014 (2.1473)	grad_norm 0.6297 (0.6330)	mem 39782MB
[2023-07-07 18:45:25 RepVGG-A0] (main.py 282): INFO Train: [295/300][40/78]	eta 0:01:17 lr 0.003532	time 3.4540 (2.0296)	loss 2.1173 (2.1492)	grad_norm 0.6445 (0.6335)	mem 39782MB
[2023-07-07 18:45:40 RepVGG-A0] (main.py 282): INFO Train: [295/300][50/78]	eta 0:00:54 lr 0.003333	time 1.1735 (1.9342)	loss 2.0983 (2.1478)	grad_norm 0.6327 (0.6334)	mem 39782MB
[2023-07-07 18:45:55 RepVGG-A0] (main.py 282): INFO Train: [295/300][60/78]	eta 0:00:33 lr 0.003140	time 1.1291 (1.8631)	loss 2.1834 (2.1486)	grad_norm 0.6386 (0.6334)	mem 39782MB
[2023-07-07 18:46:10 RepVGG-A0] (main.py 282): INFO Train: [295/300][70/78]	eta 0:00:14 lr 0.002953	time 1.4041 (1.8060)	loss 2.1506 (2.1467)	grad_norm 0.6326 (0.6333)	mem 39782MB
[2023-07-07 18:46:22 RepVGG-A0] (main.py 291): INFO EPOCH 295 training takes 0:02:20
[2023-07-07 18:46:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.295 (17.295)	Loss 1.3213 (1.3213)	Acc@1 70.807 (70.807)	Acc@5 89.526 (89.526)	Mem 39782MB
[2023-07-07 18:46:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.834 Acc@5 89.672
[2023-07-07 18:46:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 295: 70.834%
[2023-07-07 18:46:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:47:03 RepVGG-A0] (main.py 282): INFO Train: [296/300][0/78]	eta 0:29:07 lr 0.002807	time 22.4047 (22.4047)	loss 2.1282 (2.1282)	grad_norm 0.6409 (0.6409)	mem 39782MB
[2023-07-07 18:47:18 RepVGG-A0] (main.py 282): INFO Train: [296/300][10/78]	eta 0:03:48 lr 0.002630	time 1.1728 (3.3642)	loss 2.1446 (2.1223)	grad_norm 0.6360 (0.6313)	mem 39782MB
[2023-07-07 18:47:32 RepVGG-A0] (main.py 282): INFO Train: [296/300][20/78]	eta 0:02:22 lr 0.002459	time 1.3659 (2.4517)	loss 2.1594 (2.1317)	grad_norm 0.6263 (0.6316)	mem 39782MB
[2023-07-07 18:47:48 RepVGG-A0] (main.py 282): INFO Train: [296/300][30/78]	eta 0:01:44 lr 0.002293	time 1.5147 (2.1704)	loss 2.0950 (2.1277)	grad_norm 0.6213 (0.6309)	mem 39782MB
[2023-07-07 18:48:05 RepVGG-A0] (main.py 282): INFO Train: [296/300][40/78]	eta 0:01:17 lr 0.002133	time 3.8370 (2.0465)	loss 2.0943 (2.1277)	grad_norm 0.6220 (0.6305)	mem 39782MB
[2023-07-07 18:48:20 RepVGG-A0] (main.py 282): INFO Train: [296/300][50/78]	eta 0:00:54 lr 0.001979	time 1.1716 (1.9419)	loss 2.1841 (2.1307)	grad_norm 0.6307 (0.6305)	mem 39782MB
[2023-07-07 18:48:35 RepVGG-A0] (main.py 282): INFO Train: [296/300][60/78]	eta 0:00:33 lr 0.001831	time 1.1747 (1.8774)	loss 2.1754 (2.1349)	grad_norm 0.6358 (0.6309)	mem 39782MB
[2023-07-07 18:48:51 RepVGG-A0] (main.py 282): INFO Train: [296/300][70/78]	eta 0:00:14 lr 0.001689	time 1.7973 (1.8394)	loss 2.1723 (2.1366)	grad_norm 0.6276 (0.6312)	mem 39782MB
[2023-07-07 18:49:02 RepVGG-A0] (main.py 291): INFO EPOCH 296 training takes 0:02:21
[2023-07-07 18:49:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.667 (17.667)	Loss 1.3167 (1.3167)	Acc@1 70.837 (70.837)	Acc@5 89.807 (89.807)	Mem 39782MB
[2023-07-07 18:49:21 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.906 Acc@5 89.658
[2023-07-07 18:49:21 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 296: 70.906%
[2023-07-07 18:49:21 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:49:41 RepVGG-A0] (main.py 282): INFO Train: [297/300][0/78]	eta 0:27:06 lr 0.001579	time 20.8492 (20.8492)	loss 2.0952 (2.0952)	grad_norm 0.6238 (0.6238)	mem 39782MB
[2023-07-07 18:49:57 RepVGG-A0] (main.py 282): INFO Train: [297/300][10/78]	eta 0:03:42 lr 0.001447	time 1.1720 (3.2731)	loss 2.1210 (2.1382)	grad_norm 0.6274 (0.6294)	mem 39782MB
[2023-07-07 18:50:12 RepVGG-A0] (main.py 282): INFO Train: [297/300][20/78]	eta 0:02:21 lr 0.001321	time 1.2802 (2.4350)	loss 2.1273 (2.1427)	grad_norm 0.6337 (0.6296)	mem 39782MB
[2023-07-07 18:50:27 RepVGG-A0] (main.py 282): INFO Train: [297/300][30/78]	eta 0:01:42 lr 0.001200	time 1.3840 (2.1407)	loss 2.1427 (2.1475)	grad_norm 0.6343 (0.6302)	mem 39782MB
[2023-07-07 18:50:44 RepVGG-A0] (main.py 282): INFO Train: [297/300][40/78]	eta 0:01:17 lr 0.001085	time 3.6904 (2.0384)	loss 2.1989 (2.1449)	grad_norm 0.6336 (0.6305)	mem 39782MB
[2023-07-07 18:51:00 RepVGG-A0] (main.py 282): INFO Train: [297/300][50/78]	eta 0:00:54 lr 0.000976	time 1.2309 (1.9429)	loss 2.1507 (2.1442)	grad_norm 0.6287 (0.6300)	mem 39782MB
[2023-07-07 18:51:15 RepVGG-A0] (main.py 282): INFO Train: [297/300][60/78]	eta 0:00:33 lr 0.000873	time 1.6844 (1.8755)	loss 2.1616 (2.1410)	grad_norm 0.6384 (0.6298)	mem 39782MB
[2023-07-07 18:51:31 RepVGG-A0] (main.py 282): INFO Train: [297/300][70/78]	eta 0:00:14 lr 0.000776	time 1.2784 (1.8382)	loss 2.1075 (2.1422)	grad_norm 0.6278 (0.6301)	mem 39782MB
[2023-07-07 18:51:42 RepVGG-A0] (main.py 291): INFO EPOCH 297 training takes 0:02:21
[2023-07-07 18:51:59 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.002 (17.002)	Loss 1.3204 (1.3204)	Acc@1 70.703 (70.703)	Acc@5 89.709 (89.709)	Mem 39782MB
[2023-07-07 18:52:01 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.910 Acc@5 89.666
[2023-07-07 18:52:01 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 297: 70.910%
[2023-07-07 18:52:01 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:52:24 RepVGG-A0] (main.py 282): INFO Train: [298/300][0/78]	eta 0:29:17 lr 0.000702	time 22.5284 (22.5284)	loss 2.1245 (2.1245)	grad_norm 0.6243 (0.6243)	mem 39782MB
[2023-07-07 18:52:37 RepVGG-A0] (main.py 282): INFO Train: [298/300][10/78]	eta 0:03:44 lr 0.000615	time 1.1739 (3.2959)	loss 2.1501 (2.1214)	grad_norm 0.6289 (0.6289)	mem 39782MB
[2023-07-07 18:52:52 RepVGG-A0] (main.py 282): INFO Train: [298/300][20/78]	eta 0:02:20 lr 0.000533	time 1.1719 (2.4156)	loss 2.1408 (2.1317)	grad_norm 0.6324 (0.6287)	mem 39782MB
[2023-07-07 18:53:07 RepVGG-A0] (main.py 282): INFO Train: [298/300][30/78]	eta 0:01:42 lr 0.000458	time 1.3217 (2.1340)	loss 2.0766 (2.1318)	grad_norm 0.6304 (0.6298)	mem 39782MB
[2023-07-07 18:53:26 RepVGG-A0] (main.py 282): INFO Train: [298/300][40/78]	eta 0:01:18 lr 0.000388	time 3.9256 (2.0756)	loss 2.1391 (2.1349)	grad_norm 0.6381 (0.6295)	mem 39782MB
[2023-07-07 18:53:41 RepVGG-A0] (main.py 282): INFO Train: [298/300][50/78]	eta 0:00:55 lr 0.000324	time 1.3568 (1.9683)	loss 2.1826 (2.1372)	grad_norm 0.6352 (0.6292)	mem 39782MB
[2023-07-07 18:53:56 RepVGG-A0] (main.py 282): INFO Train: [298/300][60/78]	eta 0:00:33 lr 0.000266	time 1.2006 (1.8832)	loss 2.1210 (2.1386)	grad_norm 0.6251 (0.6291)	mem 39782MB
[2023-07-07 18:54:11 RepVGG-A0] (main.py 282): INFO Train: [298/300][70/78]	eta 0:00:14 lr 0.000213	time 1.3950 (1.8314)	loss 2.1175 (2.1403)	grad_norm 0.6323 (0.6295)	mem 39782MB
[2023-07-07 18:54:23 RepVGG-A0] (main.py 291): INFO EPOCH 298 training takes 0:02:21
[2023-07-07 18:54:40 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.121 (17.121)	Loss 1.3234 (1.3234)	Acc@1 70.844 (70.844)	Acc@5 89.368 (89.368)	Mem 39782MB
[2023-07-07 18:54:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.926 Acc@5 89.596
[2023-07-07 18:54:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 298: 70.926%
[2023-07-07 18:54:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:55:02 RepVGG-A0] (main.py 282): INFO Train: [299/300][0/78]	eta 0:26:45 lr 0.000175	time 20.5894 (20.5894)	loss 2.1118 (2.1118)	grad_norm 0.6278 (0.6278)	mem 39782MB
[2023-07-07 18:55:18 RepVGG-A0] (main.py 282): INFO Train: [299/300][10/78]	eta 0:03:45 lr 0.000133	time 1.1731 (3.3195)	loss 2.1660 (2.1446)	grad_norm 0.6257 (0.6300)	mem 39782MB
[2023-07-07 18:55:33 RepVGG-A0] (main.py 282): INFO Train: [299/300][20/78]	eta 0:02:22 lr 0.000097	time 1.3577 (2.4549)	loss 2.1181 (2.1380)	grad_norm 0.6276 (0.6300)	mem 39782MB
[2023-07-07 18:55:48 RepVGG-A0] (main.py 282): INFO Train: [299/300][30/78]	eta 0:01:43 lr 0.000066	time 1.3311 (2.1536)	loss 2.1354 (2.1365)	grad_norm 0.6263 (0.6297)	mem 39782MB
[2023-07-07 18:56:06 RepVGG-A0] (main.py 282): INFO Train: [299/300][40/78]	eta 0:01:18 lr 0.000042	time 3.3018 (2.0576)	loss 2.2034 (2.1392)	grad_norm 0.6283 (0.6291)	mem 39782MB
[2023-07-07 18:56:21 RepVGG-A0] (main.py 282): INFO Train: [299/300][50/78]	eta 0:00:54 lr 0.000023	time 1.1729 (1.9426)	loss 2.1841 (2.1402)	grad_norm 0.6304 (0.6295)	mem 39782MB
[2023-07-07 18:56:35 RepVGG-A0] (main.py 282): INFO Train: [299/300][60/78]	eta 0:00:33 lr 0.000009	time 1.2568 (1.8626)	loss 2.1253 (2.1399)	grad_norm 0.6289 (0.6294)	mem 39782MB
[2023-07-07 18:56:50 RepVGG-A0] (main.py 282): INFO Train: [299/300][70/78]	eta 0:00:14 lr 0.000002	time 1.3925 (1.8173)	loss 2.1544 (2.1409)	grad_norm 0.6317 (0.6294)	mem 39782MB
[2023-07-07 18:57:02 RepVGG-A0] (main.py 291): INFO EPOCH 299 training takes 0:02:20
[2023-07-07 18:57:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.030 (17.030)	Loss 1.3233 (1.3233)	Acc@1 70.471 (70.471)	Acc@5 89.478 (89.478)	Mem 39782MB
[2023-07-07 18:57:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.892 Acc@5 89.628
[2023-07-07 18:57:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 299: 70.892%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 194): INFO Training time 11:54:08
