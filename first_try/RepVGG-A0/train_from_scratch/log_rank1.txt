[2023-07-07 06:57:03 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 1
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 06:57:07 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 06:57:07 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 06:57:07 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 06:57:07 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 06:58:00 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 1:08:55 lr 0.000000	time 53.0157 (53.0157)	loss 6.9290 (6.9290)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 06:58:12 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:06:42 lr 0.164103	time 1.2056 (5.9152)	loss 6.8746 (6.9131)	grad_norm 0.3863 (0.4375)	mem 39782MB
[2023-07-07 06:58:25 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:36 lr 0.328205	time 1.2971 (3.7283)	loss 6.8504 (6.8835)	grad_norm 0.6087 (0.4656)	mem 39782MB
[2023-07-07 06:58:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:22 lr 0.492308	time 1.1294 (2.9750)	loss 6.7062 (6.8433)	grad_norm 0.3451 (0.4584)	mem 39782MB
[2023-07-07 06:58:52 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:37 lr 0.656410	time 1.4448 (2.5782)	loss 6.6314 (6.8035)	grad_norm 0.2875 (0.4779)	mem 39782MB
[2023-07-07 06:59:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:06 lr 0.820513	time 1.9147 (2.3583)	loss 6.5650 (6.7568)	grad_norm 0.4756 (0.4584)	mem 39782MB
[2023-07-07 06:59:24 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:40 lr 0.984615	time 1.9471 (2.2518)	loss 6.5199 (6.7192)	grad_norm 0.2836 (0.4587)	mem 39782MB
[2023-07-07 06:59:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:17 lr 1.148718	time 1.3554 (2.1501)	loss 6.4425 (6.6888)	grad_norm 0.2158 (0.4426)	mem 39782MB
[2023-07-07 06:59:50 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:43
[2023-07-07 07:01:01 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 4096
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 4096
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 1
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 12.8
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:01:05 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:01:05 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:01:05 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:01:05 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:09 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 1
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:03:12 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:03:12 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:03:12 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:03:12 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:55 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 0:56:13 lr 0.000000	time 43.2464 (43.2464)	loss 6.9290 (6.9290)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 07:04:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:05:41 lr 0.164103	time 1.1710 (5.0184)	loss 6.8701 (6.9126)	grad_norm 0.3837 (0.4372)	mem 39782MB
[2023-07-07 07:04:20 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:06 lr 0.328205	time 1.1722 (3.2159)	loss 6.8328 (6.8799)	grad_norm 0.6673 (0.4541)	mem 39782MB
[2023-07-07 07:04:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:04 lr 0.492308	time 1.1723 (2.5842)	loss 6.7318 (6.8462)	grad_norm 0.3204 (0.5029)	mem 39782MB
[2023-07-07 07:04:45 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:26 lr 0.656410	time 1.1729 (2.2744)	loss 6.6189 (6.8023)	grad_norm 0.2427 (0.4866)	mem 39782MB
[2023-07-07 07:05:02 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:00 lr 0.820513	time 2.4319 (2.1513)	loss 6.5370 (6.7600)	grad_norm 0.2072 (0.4704)	mem 39782MB
[2023-07-07 07:05:17 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:36 lr 0.984615	time 1.6805 (2.0477)	loss 6.4461 (6.7134)	grad_norm 0.3638 (0.4523)	mem 39782MB
[2023-07-07 07:05:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:15 lr 1.148718	time 1.1732 (1.9721)	loss 6.3772 (6.6722)	grad_norm 0.2930 (0.4425)	mem 39782MB
[2023-07-07 07:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:32
[2023-07-07 07:06:02 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.492 (17.492)	Loss 8.4176 (8.4176)	Acc@1 0.433 (0.433)	Acc@5 1.807 (1.807)	Mem 39782MB
[2023-07-07 07:06:04 RepVGG-A0] (main.py 342): INFO  * Acc@1 0.438 Acc@5 1.750
[2023-07-07 07:06:04 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 0: 0.438%
[2023-07-07 07:06:04 RepVGG-A0] (main.py 172): INFO Max accuracy: 0.44%
[2023-07-07 07:06:25 RepVGG-A0] (main.py 282): INFO Train: [1/300][0/78]	eta 0:27:44 lr 1.280000	time 21.3425 (21.3425)	loss 6.4347 (6.4347)	grad_norm 0.3022 (0.3022)	mem 39782MB
[2023-07-07 07:06:39 RepVGG-A0] (main.py 282): INFO Train: [1/300][10/78]	eta 0:03:36 lr 1.444103	time 1.1705 (3.1881)	loss 6.2615 (6.3383)	grad_norm 0.2858 (0.3078)	mem 39782MB
[2023-07-07 07:06:53 RepVGG-A0] (main.py 282): INFO Train: [1/300][20/78]	eta 0:02:15 lr 1.608205	time 1.1887 (2.3411)	loss 6.2880 (6.3067)	grad_norm 0.3848 (0.3558)	mem 39782MB
[2023-07-07 07:07:09 RepVGG-A0] (main.py 282): INFO Train: [1/300][30/78]	eta 0:01:39 lr 1.772308	time 1.2815 (2.0815)	loss 6.1685 (6.2748)	grad_norm 0.3921 (0.3527)	mem 39782MB
[2023-07-07 07:07:28 RepVGG-A0] (main.py 282): INFO Train: [1/300][40/78]	eta 0:01:17 lr 1.936410	time 4.3348 (2.0526)	loss 6.1172 (6.2430)	grad_norm 0.3742 (0.3538)	mem 39782MB
[2023-07-07 07:07:44 RepVGG-A0] (main.py 282): INFO Train: [1/300][50/78]	eta 0:00:54 lr 2.100513	time 1.1723 (1.9514)	loss 6.1127 (6.2173)	grad_norm 0.5806 (0.3590)	mem 39782MB
[2023-07-07 07:07:59 RepVGG-A0] (main.py 282): INFO Train: [1/300][60/78]	eta 0:00:33 lr 2.264615	time 1.1284 (1.8781)	loss 6.1002 (6.1949)	grad_norm 0.4412 (0.3583)	mem 39782MB
[2023-07-07 07:08:14 RepVGG-A0] (main.py 282): INFO Train: [1/300][70/78]	eta 0:00:14 lr 2.428718	time 1.3955 (1.8334)	loss 5.9748 (6.1670)	grad_norm 0.4348 (0.3595)	mem 39782MB
[2023-07-07 07:08:25 RepVGG-A0] (main.py 291): INFO EPOCH 1 training takes 0:02:21
[2023-07-07 07:08:47 RepVGG-A0] (main.py 282): INFO Train: [2/300][0/78]	eta 0:28:01 lr 2.560000	time 21.5535 (21.5535)	loss 5.8033 (5.8033)	grad_norm 0.3089 (0.3089)	mem 39782MB
[2023-07-07 07:09:01 RepVGG-A0] (main.py 282): INFO Train: [2/300][10/78]	eta 0:03:39 lr 2.724103	time 1.1841 (3.2256)	loss 5.8492 (5.8820)	grad_norm 0.3208 (0.3754)	mem 39782MB
[2023-07-07 07:09:16 RepVGG-A0] (main.py 282): INFO Train: [2/300][20/78]	eta 0:02:19 lr 2.888205	time 1.1730 (2.3979)	loss 5.8865 (5.8528)	grad_norm 0.5859 (0.3874)	mem 39782MB
[2023-07-07 07:09:31 RepVGG-A0] (main.py 282): INFO Train: [2/300][30/78]	eta 0:01:41 lr 3.052308	time 1.1369 (2.1118)	loss 5.8241 (5.8699)	grad_norm 0.3534 (0.3930)	mem 39782MB
[2023-07-07 07:09:49 RepVGG-A0] (main.py 282): INFO Train: [2/300][40/78]	eta 0:01:17 lr 3.216410	time 3.6718 (2.0267)	loss 5.6411 (5.8500)	grad_norm 0.2448 (0.3795)	mem 39782MB
[2023-07-07 07:10:04 RepVGG-A0] (main.py 282): INFO Train: [2/300][50/78]	eta 0:00:54 lr 3.380513	time 1.3521 (1.9300)	loss 5.6182 (5.8213)	grad_norm 0.2856 (0.3737)	mem 39782MB
[2023-07-07 07:10:20 RepVGG-A0] (main.py 282): INFO Train: [2/300][60/78]	eta 0:00:33 lr 3.544615	time 1.3329 (1.8776)	loss 5.6230 (5.7879)	grad_norm 0.3870 (0.3667)	mem 39782MB
[2023-07-07 07:10:35 RepVGG-A0] (main.py 282): INFO Train: [2/300][70/78]	eta 0:00:14 lr 3.708718	time 1.3858 (1.8206)	loss 5.4339 (5.7615)	grad_norm 0.2952 (0.3666)	mem 39782MB
[2023-07-07 07:10:47 RepVGG-A0] (main.py 291): INFO EPOCH 2 training takes 0:02:21
[2023-07-07 07:11:07 RepVGG-A0] (main.py 282): INFO Train: [3/300][0/78]	eta 0:26:35 lr 3.840000	time 20.4561 (20.4561)	loss 5.5228 (5.5228)	grad_norm 0.4211 (0.4211)	mem 39782MB
[2023-07-07 07:11:22 RepVGG-A0] (main.py 282): INFO Train: [3/300][10/78]	eta 0:03:36 lr 4.004103	time 1.1893 (3.1781)	loss 5.6662 (5.7231)	grad_norm 0.3348 (0.4536)	mem 39782MB
[2023-07-07 07:11:37 RepVGG-A0] (main.py 282): INFO Train: [3/300][20/78]	eta 0:02:18 lr 4.168205	time 1.2782 (2.3899)	loss 5.4584 (5.6445)	grad_norm 0.2892 (0.3932)	mem 39782MB
[2023-07-07 07:11:52 RepVGG-A0] (main.py 282): INFO Train: [3/300][30/78]	eta 0:01:41 lr 4.332308	time 1.1375 (2.1043)	loss 5.5169 (5.5727)	grad_norm 0.4183 (0.3690)	mem 39782MB
[2023-07-07 07:12:09 RepVGG-A0] (main.py 282): INFO Train: [3/300][40/78]	eta 0:01:16 lr 4.496410	time 3.7351 (2.0101)	loss 5.4733 (5.5207)	grad_norm 0.4425 (0.3594)	mem 39782MB
[2023-07-07 07:12:24 RepVGG-A0] (main.py 282): INFO Train: [3/300][50/78]	eta 0:00:53 lr 4.660513	time 1.1733 (1.8998)	loss 5.4136 (5.5156)	grad_norm 0.3540 (0.3620)	mem 39782MB
[2023-07-07 07:12:39 RepVGG-A0] (main.py 282): INFO Train: [3/300][60/78]	eta 0:00:33 lr 4.824615	time 1.2408 (1.8390)	loss 5.2599 (5.4794)	grad_norm 0.3398 (0.3547)	mem 39782MB
[2023-07-07 07:12:53 RepVGG-A0] (main.py 282): INFO Train: [3/300][70/78]	eta 0:00:14 lr 4.988718	time 1.1259 (1.7820)	loss 5.1437 (5.4435)	grad_norm 0.3245 (0.3490)	mem 39782MB
[2023-07-07 07:13:05 RepVGG-A0] (main.py 291): INFO EPOCH 3 training takes 0:02:18
[2023-07-07 07:13:26 RepVGG-A0] (main.py 282): INFO Train: [4/300][0/78]	eta 0:27:03 lr 5.120000	time 20.8121 (20.8121)	loss 5.1713 (5.1713)	grad_norm 0.3194 (0.3194)	mem 39782MB
[2023-07-07 07:13:40 RepVGG-A0] (main.py 282): INFO Train: [4/300][10/78]	eta 0:03:38 lr 5.284103	time 1.1910 (3.2100)	loss 5.2910 (5.2505)	grad_norm 0.3480 (0.3871)	mem 39782MB
[2023-07-07 07:13:55 RepVGG-A0] (main.py 282): INFO Train: [4/300][20/78]	eta 0:02:18 lr 5.448205	time 1.4208 (2.3855)	loss 5.0495 (5.2144)	grad_norm 0.3079 (0.3590)	mem 39782MB
[2023-07-07 07:14:10 RepVGG-A0] (main.py 282): INFO Train: [4/300][30/78]	eta 0:01:40 lr 5.612308	time 1.2888 (2.0906)	loss 5.1145 (5.1659)	grad_norm 0.4055 (0.3539)	mem 39782MB
[2023-07-07 07:14:28 RepVGG-A0] (main.py 282): INFO Train: [4/300][40/78]	eta 0:01:16 lr 5.776410	time 4.7332 (2.0255)	loss 5.1453 (5.1981)	grad_norm 0.2796 (0.3646)	mem 39782MB
[2023-07-07 07:14:44 RepVGG-A0] (main.py 282): INFO Train: [4/300][50/78]	eta 0:00:54 lr 5.940513	time 1.3982 (1.9307)	loss 5.0912 (5.1991)	grad_norm 0.2789 (0.3640)	mem 39782MB
[2023-07-07 07:14:59 RepVGG-A0] (main.py 282): INFO Train: [4/300][60/78]	eta 0:00:33 lr 6.104615	time 1.1728 (1.8586)	loss 5.1012 (5.1669)	grad_norm 0.4101 (0.3544)	mem 39782MB
[2023-07-07 07:15:14 RepVGG-A0] (main.py 282): INFO Train: [4/300][70/78]	eta 0:00:14 lr 6.268718	time 1.3743 (1.8147)	loss 4.9785 (5.1401)	grad_norm 0.3424 (0.3485)	mem 39782MB
[2023-07-07 07:15:26 RepVGG-A0] (main.py 291): INFO EPOCH 4 training takes 0:02:20
[2023-07-07 07:15:47 RepVGG-A0] (main.py 282): INFO Train: [5/300][0/78]	eta 0:27:57 lr 6.395615	time 21.5057 (21.5057)	loss 4.9861 (4.9861)	grad_norm 0.3501 (0.3501)	mem 39782MB
[2023-07-07 07:16:03 RepVGG-A0] (main.py 282): INFO Train: [5/300][10/78]	eta 0:03:49 lr 6.395387	time 1.1736 (3.3700)	loss 4.8560 (4.8963)	grad_norm 0.3121 (0.3207)	mem 39782MB
[2023-07-07 07:16:17 RepVGG-A0] (main.py 282): INFO Train: [5/300][20/78]	eta 0:02:21 lr 6.395153	time 1.2864 (2.4325)	loss 4.7357 (4.8556)	grad_norm 0.3066 (0.3194)	mem 39782MB
[2023-07-07 07:16:33 RepVGG-A0] (main.py 282): INFO Train: [5/300][30/78]	eta 0:01:43 lr 6.394914	time 1.2216 (2.1640)	loss 4.7542 (4.8403)	grad_norm 0.3153 (0.3274)	mem 39782MB
[2023-07-07 07:16:50 RepVGG-A0] (main.py 282): INFO Train: [5/300][40/78]	eta 0:01:18 lr 6.394669	time 3.6856 (2.0588)	loss 4.9267 (4.8327)	grad_norm 0.4065 (0.3341)	mem 39782MB
[2023-07-07 07:17:05 RepVGG-A0] (main.py 282): INFO Train: [5/300][50/78]	eta 0:00:54 lr 6.394418	time 1.1707 (1.9416)	loss 4.7249 (4.8251)	grad_norm 0.3186 (0.3363)	mem 39782MB
[2023-07-07 07:17:20 RepVGG-A0] (main.py 282): INFO Train: [5/300][60/78]	eta 0:00:33 lr 6.394162	time 1.3330 (1.8676)	loss 4.6403 (4.8070)	grad_norm 0.2947 (0.3370)	mem 39782MB
[2023-07-07 07:17:35 RepVGG-A0] (main.py 282): INFO Train: [5/300][70/78]	eta 0:00:14 lr 6.393899	time 1.3449 (1.8199)	loss 4.7660 (4.7866)	grad_norm 0.3928 (0.3394)	mem 39782MB
[2023-07-07 07:17:47 RepVGG-A0] (main.py 291): INFO EPOCH 5 training takes 0:02:21
[2023-07-07 07:18:09 RepVGG-A0] (main.py 282): INFO Train: [6/300][0/78]	eta 0:28:27 lr 6.393686	time 21.8902 (21.8902)	loss 4.4635 (4.4635)	grad_norm 0.3199 (0.3199)	mem 39782MB
[2023-07-07 07:18:24 RepVGG-A0] (main.py 282): INFO Train: [6/300][10/78]	eta 0:03:47 lr 6.393413	time 1.1721 (3.3446)	loss 4.6670 (4.5789)	grad_norm 0.3654 (0.3503)	mem 39782MB
[2023-07-07 07:18:38 RepVGG-A0] (main.py 282): INFO Train: [6/300][20/78]	eta 0:02:21 lr 6.393134	time 1.1969 (2.4421)	loss 4.6725 (4.5682)	grad_norm 0.4356 (0.3452)	mem 39782MB
[2023-07-07 07:18:53 RepVGG-A0] (main.py 282): INFO Train: [6/300][30/78]	eta 0:01:41 lr 6.392850	time 1.3768 (2.1208)	loss 4.7736 (4.6855)	grad_norm 0.3324 (0.3829)	mem 39782MB
[2023-07-07 07:19:11 RepVGG-A0] (main.py 282): INFO Train: [6/300][40/78]	eta 0:01:17 lr 6.392560	time 3.2681 (2.0412)	loss 4.5526 (4.6626)	grad_norm 0.3424 (0.3618)	mem 39782MB
[2023-07-07 07:19:27 RepVGG-A0] (main.py 282): INFO Train: [6/300][50/78]	eta 0:00:54 lr 6.392265	time 1.1721 (1.9517)	loss 4.4435 (4.6310)	grad_norm 0.2716 (0.3537)	mem 39782MB
[2023-07-07 07:19:42 RepVGG-A0] (main.py 282): INFO Train: [6/300][60/78]	eta 0:00:33 lr 6.391963	time 1.1941 (1.8812)	loss 4.5191 (4.6029)	grad_norm 0.4000 (0.3523)	mem 39782MB
[2023-07-07 07:19:57 RepVGG-A0] (main.py 282): INFO Train: [6/300][70/78]	eta 0:00:14 lr 6.391656	time 1.2031 (1.8293)	loss 4.4560 (4.5831)	grad_norm 0.3288 (0.3490)	mem 39782MB
[2023-07-07 07:20:09 RepVGG-A0] (main.py 291): INFO EPOCH 6 training takes 0:02:22
[2023-07-07 07:20:31 RepVGG-A0] (main.py 282): INFO Train: [7/300][0/78]	eta 0:27:50 lr 6.391406	time 21.4215 (21.4215)	loss 4.7690 (4.7690)	grad_norm 0.6078 (0.6078)	mem 39782MB
[2023-07-07 07:20:45 RepVGG-A0] (main.py 282): INFO Train: [7/300][10/78]	eta 0:03:39 lr 6.391089	time 1.1710 (3.2248)	loss 5.0805 (5.1900)	grad_norm 0.3224 (0.5314)	mem 39782MB
[2023-07-07 07:20:59 RepVGG-A0] (main.py 282): INFO Train: [7/300][20/78]	eta 0:02:18 lr 6.390766	time 1.1719 (2.3805)	loss 4.5290 (4.9776)	grad_norm 0.2351 (0.4205)	mem 39782MB
[2023-07-07 07:21:15 RepVGG-A0] (main.py 282): INFO Train: [7/300][30/78]	eta 0:01:41 lr 6.390437	time 1.5447 (2.1154)	loss 4.4312 (4.8432)	grad_norm 0.2142 (0.3827)	mem 39782MB
[2023-07-07 07:21:34 RepVGG-A0] (main.py 282): INFO Train: [7/300][40/78]	eta 0:01:18 lr 6.390102	time 3.8741 (2.0572)	loss 4.3794 (4.7260)	grad_norm 0.3031 (0.3593)	mem 39782MB
[2023-07-07 07:21:50 RepVGG-A0] (main.py 282): INFO Train: [7/300][50/78]	eta 0:00:55 lr 6.389761	time 1.2675 (1.9705)	loss 4.3577 (4.6505)	grad_norm 0.3885 (0.3520)	mem 39782MB
[2023-07-07 07:22:05 RepVGG-A0] (main.py 282): INFO Train: [7/300][60/78]	eta 0:00:34 lr 6.389415	time 1.2972 (1.8966)	loss 4.1859 (4.5960)	grad_norm 0.2802 (0.3473)	mem 39782MB
[2023-07-07 07:22:20 RepVGG-A0] (main.py 282): INFO Train: [7/300][70/78]	eta 0:00:14 lr 6.389063	time 1.1760 (1.8380)	loss 4.4346 (4.5639)	grad_norm 0.3772 (0.3502)	mem 39782MB
[2023-07-07 07:22:31 RepVGG-A0] (main.py 291): INFO EPOCH 7 training takes 0:02:21
[2023-07-07 07:22:53 RepVGG-A0] (main.py 282): INFO Train: [8/300][0/78]	eta 0:28:07 lr 6.388777	time 21.6373 (21.6373)	loss 4.2278 (4.2278)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 07:23:06 RepVGG-A0] (main.py 282): INFO Train: [8/300][10/78]	eta 0:03:36 lr 6.388415	time 1.1729 (3.1800)	loss 4.1542 (4.2202)	grad_norm 0.3247 (0.3365)	mem 39782MB
[2023-07-07 07:23:20 RepVGG-A0] (main.py 282): INFO Train: [8/300][20/78]	eta 0:02:16 lr 6.388047	time 1.3878 (2.3514)	loss 4.3622 (4.2528)	grad_norm 0.3676 (0.3602)	mem 39782MB
[2023-07-07 07:23:35 RepVGG-A0] (main.py 282): INFO Train: [8/300][30/78]	eta 0:01:39 lr 6.387673	time 1.1944 (2.0786)	loss 4.2794 (4.2543)	grad_norm 0.3572 (0.3583)	mem 39782MB
[2023-07-07 07:23:54 RepVGG-A0] (main.py 282): INFO Train: [8/300][40/78]	eta 0:01:16 lr 6.387293	time 4.0299 (2.0145)	loss 4.1614 (4.2362)	grad_norm 0.3285 (0.3522)	mem 39782MB
[2023-07-07 07:24:09 RepVGG-A0] (main.py 282): INFO Train: [8/300][50/78]	eta 0:00:53 lr 6.386908	time 1.1724 (1.9160)	loss 4.1378 (4.2362)	grad_norm 0.3480 (0.3560)	mem 39782MB
[2023-07-07 07:24:23 RepVGG-A0] (main.py 282): INFO Train: [8/300][60/78]	eta 0:00:33 lr 6.386517	time 1.2025 (1.8404)	loss 4.0368 (4.2191)	grad_norm 0.3056 (0.3526)	mem 39782MB
[2023-07-07 07:24:39 RepVGG-A0] (main.py 282): INFO Train: [8/300][70/78]	eta 0:00:14 lr 6.386120	time 1.4130 (1.8034)	loss 4.7016 (4.2418)	grad_norm 0.5369 (0.3675)	mem 39782MB
[2023-07-07 07:24:51 RepVGG-A0] (main.py 291): INFO EPOCH 8 training takes 0:02:20
[2023-07-07 07:25:13 RepVGG-A0] (main.py 282): INFO Train: [9/300][0/78]	eta 0:28:42 lr 6.385798	time 22.0816 (22.0816)	loss 4.5797 (4.5797)	grad_norm 0.3629 (0.3629)	mem 39782MB
[2023-07-07 07:25:27 RepVGG-A0] (main.py 282): INFO Train: [9/300][10/78]	eta 0:03:41 lr 6.385391	time 1.1727 (3.2502)	loss 4.1241 (4.3102)	grad_norm 0.2382 (0.2936)	mem 39782MB
[2023-07-07 07:25:43 RepVGG-A0] (main.py 282): INFO Train: [9/300][20/78]	eta 0:02:22 lr 6.384978	time 1.1821 (2.4484)	loss 4.0629 (4.2232)	grad_norm 0.3011 (0.2995)	mem 39782MB
[2023-07-07 07:25:57 RepVGG-A0] (main.py 282): INFO Train: [9/300][30/78]	eta 0:01:42 lr 6.384560	time 1.4524 (2.1282)	loss 4.0062 (4.1835)	grad_norm 0.2605 (0.3031)	mem 39782MB
[2023-07-07 07:26:14 RepVGG-A0] (main.py 282): INFO Train: [9/300][40/78]	eta 0:01:16 lr 6.384135	time 2.5161 (2.0185)	loss 3.9913 (4.1536)	grad_norm 0.3226 (0.3117)	mem 39782MB
[2023-07-07 07:26:30 RepVGG-A0] (main.py 282): INFO Train: [9/300][50/78]	eta 0:00:54 lr 6.383705	time 1.1733 (1.9368)	loss 4.3086 (4.1695)	grad_norm 0.4367 (0.3327)	mem 39782MB
[2023-07-07 07:26:45 RepVGG-A0] (main.py 282): INFO Train: [9/300][60/78]	eta 0:00:33 lr 6.383269	time 1.1765 (1.8662)	loss 4.0498 (4.1584)	grad_norm 0.3265 (0.3286)	mem 39782MB
[2023-07-07 07:27:00 RepVGG-A0] (main.py 282): INFO Train: [9/300][70/78]	eta 0:00:14 lr 6.382827	time 1.2826 (1.8124)	loss 4.0245 (4.1392)	grad_norm 0.3517 (0.3280)	mem 39782MB
[2023-07-07 07:27:11 RepVGG-A0] (main.py 291): INFO EPOCH 9 training takes 0:02:19
[2023-07-07 07:27:32 RepVGG-A0] (main.py 282): INFO Train: [10/300][0/78]	eta 0:27:13 lr 6.382470	time 20.9413 (20.9413)	loss 4.2363 (4.2363)	grad_norm 0.4651 (0.4651)	mem 39782MB
[2023-07-07 07:27:47 RepVGG-A0] (main.py 282): INFO Train: [10/300][10/78]	eta 0:03:40 lr 6.382018	time 1.1715 (3.2468)	loss 4.0220 (4.0912)	grad_norm 0.3140 (0.3522)	mem 39782MB
[2023-07-07 07:28:02 RepVGG-A0] (main.py 282): INFO Train: [10/300][20/78]	eta 0:02:20 lr 6.381560	time 1.4281 (2.4268)	loss 4.0175 (4.0552)	grad_norm 0.3932 (0.3513)	mem 39782MB
[2023-07-07 07:28:17 RepVGG-A0] (main.py 282): INFO Train: [10/300][30/78]	eta 0:01:41 lr 6.381097	time 1.2709 (2.1173)	loss 4.1514 (4.0305)	grad_norm 0.4598 (0.3468)	mem 39782MB
[2023-07-07 07:28:34 RepVGG-A0] (main.py 282): INFO Train: [10/300][40/78]	eta 0:01:17 lr 6.380628	time 4.0558 (2.0360)	loss 4.0688 (4.0446)	grad_norm 0.3532 (0.3555)	mem 39782MB
[2023-07-07 07:28:50 RepVGG-A0] (main.py 282): INFO Train: [10/300][50/78]	eta 0:00:54 lr 6.380153	time 1.1741 (1.9420)	loss 3.9514 (4.0355)	grad_norm 0.3167 (0.3534)	mem 39782MB
[2023-07-07 07:29:05 RepVGG-A0] (main.py 282): INFO Train: [10/300][60/78]	eta 0:00:33 lr 6.379672	time 1.1816 (1.8764)	loss 3.9849 (4.0241)	grad_norm 0.3627 (0.3533)	mem 39782MB
[2023-07-07 07:29:21 RepVGG-A0] (main.py 282): INFO Train: [10/300][70/78]	eta 0:00:14 lr 6.379186	time 1.3859 (1.8352)	loss 3.8770 (4.0119)	grad_norm 0.3247 (0.3522)	mem 39782MB
[2023-07-07 07:29:33 RepVGG-A0] (main.py 291): INFO EPOCH 10 training takes 0:02:21
[2023-07-07 07:29:55 RepVGG-A0] (main.py 282): INFO Train: [11/300][0/78]	eta 0:28:48 lr 6.378793	time 22.1635 (22.1635)	loss 4.2610 (4.2610)	grad_norm 0.4965 (0.4965)	mem 39782MB
[2023-07-07 07:30:09 RepVGG-A0] (main.py 282): INFO Train: [11/300][10/78]	eta 0:03:46 lr 6.378296	time 1.1906 (3.3236)	loss 4.5377 (4.6067)	grad_norm 0.4137 (0.5417)	mem 39782MB
[2023-07-07 07:30:23 RepVGG-A0] (main.py 282): INFO Train: [11/300][20/78]	eta 0:02:19 lr 6.377794	time 1.1760 (2.4134)	loss 3.9926 (4.4194)	grad_norm 0.2363 (0.4263)	mem 39782MB
[2023-07-07 07:30:39 RepVGG-A0] (main.py 282): INFO Train: [11/300][30/78]	eta 0:01:43 lr 6.377286	time 1.3710 (2.1471)	loss 3.7798 (4.2773)	grad_norm 0.2683 (0.3847)	mem 39782MB
[2023-07-07 07:30:57 RepVGG-A0] (main.py 282): INFO Train: [11/300][40/78]	eta 0:01:18 lr 6.376772	time 3.1782 (2.0610)	loss 3.8434 (4.1878)	grad_norm 0.3163 (0.3636)	mem 39782MB
[2023-07-07 07:31:12 RepVGG-A0] (main.py 282): INFO Train: [11/300][50/78]	eta 0:00:54 lr 6.376252	time 1.1714 (1.9453)	loss 3.9082 (4.1208)	grad_norm 0.3426 (0.3517)	mem 39782MB
[2023-07-07 07:31:28 RepVGG-A0] (main.py 282): INFO Train: [11/300][60/78]	eta 0:00:33 lr 6.375727	time 1.2861 (1.8837)	loss 3.8830 (4.1006)	grad_norm 0.3005 (0.3552)	mem 39782MB
[2023-07-07 07:31:42 RepVGG-A0] (main.py 282): INFO Train: [11/300][70/78]	eta 0:00:14 lr 6.375196	time 1.3164 (1.8255)	loss 4.3088 (4.0872)	grad_norm 0.5178 (0.3610)	mem 39782MB
[2023-07-07 07:31:54 RepVGG-A0] (main.py 291): INFO EPOCH 11 training takes 0:02:21
[2023-07-07 07:32:16 RepVGG-A0] (main.py 282): INFO Train: [12/300][0/78]	eta 0:28:07 lr 6.374767	time 21.6398 (21.6398)	loss 3.9745 (3.9745)	grad_norm 0.3421 (0.3421)	mem 39782MB
[2023-07-07 07:32:30 RepVGG-A0] (main.py 282): INFO Train: [12/300][10/78]	eta 0:03:43 lr 6.374226	time 1.1722 (3.2804)	loss 3.8484 (3.8965)	grad_norm 0.3571 (0.3158)	mem 39782MB
[2023-07-07 07:32:45 RepVGG-A0] (main.py 282): INFO Train: [12/300][20/78]	eta 0:02:20 lr 6.373679	time 1.2390 (2.4265)	loss 3.8388 (3.8717)	grad_norm 0.3231 (0.3243)	mem 39782MB
[2023-07-07 07:33:00 RepVGG-A0] (main.py 282): INFO Train: [12/300][30/78]	eta 0:01:42 lr 6.373126	time 1.2247 (2.1409)	loss 4.0914 (3.8798)	grad_norm 0.4718 (0.3424)	mem 39782MB
[2023-07-07 07:33:18 RepVGG-A0] (main.py 282): INFO Train: [12/300][40/78]	eta 0:01:17 lr 6.372567	time 3.1837 (2.0362)	loss 3.7419 (3.8915)	grad_norm 0.2953 (0.3434)	mem 39782MB
[2023-07-07 07:33:33 RepVGG-A0] (main.py 282): INFO Train: [12/300][50/78]	eta 0:00:54 lr 6.372003	time 1.1735 (1.9364)	loss 3.8962 (3.8805)	grad_norm 0.3674 (0.3439)	mem 39782MB
[2023-07-07 07:33:49 RepVGG-A0] (main.py 282): INFO Train: [12/300][60/78]	eta 0:00:33 lr 6.371433	time 1.2768 (1.8823)	loss 3.9301 (3.8787)	grad_norm 0.3711 (0.3458)	mem 39782MB
[2023-07-07 07:34:03 RepVGG-A0] (main.py 282): INFO Train: [12/300][70/78]	eta 0:00:14 lr 6.370858	time 1.4525 (1.8185)	loss 4.2094 (3.8833)	grad_norm 0.5503 (0.3526)	mem 39782MB
[2023-07-07 07:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 12 training takes 0:02:20
[2023-07-07 07:34:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][0/78]	eta 0:28:24 lr 6.370393	time 21.8482 (21.8482)	loss 4.5252 (4.5252)	grad_norm 0.5121 (0.5121)	mem 39782MB
[2023-07-07 07:34:50 RepVGG-A0] (main.py 282): INFO Train: [13/300][10/78]	eta 0:03:42 lr 6.369807	time 1.1705 (3.2680)	loss 4.0366 (4.2502)	grad_norm 0.3029 (0.3710)	mem 39782MB
[2023-07-07 07:35:05 RepVGG-A0] (main.py 282): INFO Train: [13/300][20/78]	eta 0:02:18 lr 6.369216	time 1.1730 (2.3942)	loss 3.8120 (4.0677)	grad_norm 0.2852 (0.3273)	mem 39782MB
[2023-07-07 07:35:19 RepVGG-A0] (main.py 282): INFO Train: [13/300][30/78]	eta 0:01:40 lr 6.368618	time 1.4174 (2.0971)	loss 3.8213 (3.9907)	grad_norm 0.3547 (0.3255)	mem 39782MB
[2023-07-07 07:35:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][40/78]	eta 0:01:15 lr 6.368015	time 3.1136 (1.9948)	loss 3.7314 (3.9466)	grad_norm 0.3138 (0.3253)	mem 39782MB
[2023-07-07 07:35:52 RepVGG-A0] (main.py 282): INFO Train: [13/300][50/78]	eta 0:00:53 lr 6.367406	time 1.1270 (1.9129)	loss 4.0042 (3.9311)	grad_norm 0.4586 (0.3365)	mem 39782MB
[2023-07-07 07:36:07 RepVGG-A0] (main.py 282): INFO Train: [13/300][60/78]	eta 0:00:33 lr 6.366792	time 1.1730 (1.8422)	loss 3.7215 (3.9181)	grad_norm 0.3021 (0.3360)	mem 39782MB
[2023-07-07 07:36:22 RepVGG-A0] (main.py 282): INFO Train: [13/300][70/78]	eta 0:00:14 lr 6.366172	time 1.3699 (1.7994)	loss 3.8093 (3.8959)	grad_norm 0.3652 (0.3343)	mem 39782MB
[2023-07-07 07:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 13 training takes 0:02:19
[2023-07-07 07:36:55 RepVGG-A0] (main.py 282): INFO Train: [14/300][0/78]	eta 0:27:02 lr 6.365671	time 20.7952 (20.7952)	loss 3.9053 (3.9053)	grad_norm 0.3951 (0.3951)	mem 39782MB
[2023-07-07 07:37:10 RepVGG-A0] (main.py 282): INFO Train: [14/300][10/78]	eta 0:03:42 lr 6.365041	time 1.1731 (3.2745)	loss 3.8015 (3.8098)	grad_norm 0.3136 (0.3536)	mem 39782MB
[2023-07-07 07:37:25 RepVGG-A0] (main.py 282): INFO Train: [14/300][20/78]	eta 0:02:20 lr 6.364405	time 1.1724 (2.4232)	loss 3.7321 (3.7600)	grad_norm 0.3702 (0.3490)	mem 39782MB
[2023-07-07 07:37:40 RepVGG-A0] (main.py 282): INFO Train: [14/300][30/78]	eta 0:01:42 lr 6.363763	time 1.1815 (2.1255)	loss 3.9398 (3.7787)	grad_norm 0.3959 (0.3608)	mem 39782MB
[2023-07-07 07:37:59 RepVGG-A0] (main.py 282): INFO Train: [14/300][40/78]	eta 0:01:18 lr 6.363115	time 4.3127 (2.0610)	loss 3.8201 (3.7825)	grad_norm 0.3423 (0.3600)	mem 39782MB
[2023-07-07 07:38:14 RepVGG-A0] (main.py 282): INFO Train: [14/300][50/78]	eta 0:00:54 lr 6.362462	time 1.2452 (1.9519)	loss 3.7838 (3.7770)	grad_norm 0.3715 (0.3569)	mem 39782MB
[2023-07-07 07:38:29 RepVGG-A0] (main.py 282): INFO Train: [14/300][60/78]	eta 0:00:33 lr 6.361803	time 1.1814 (1.8778)	loss 4.3201 (3.8405)	grad_norm 0.5011 (0.3816)	mem 39782MB
[2023-07-07 07:38:44 RepVGG-A0] (main.py 282): INFO Train: [14/300][70/78]	eta 0:00:14 lr 6.361139	time 1.4325 (1.8297)	loss 3.7510 (3.8733)	grad_norm 0.2397 (0.3792)	mem 39782MB
[2023-07-07 07:38:56 RepVGG-A0] (main.py 291): INFO EPOCH 14 training takes 0:02:21
[2023-07-07 07:39:16 RepVGG-A0] (main.py 282): INFO Train: [15/300][0/78]	eta 0:26:02 lr 6.360603	time 20.0345 (20.0345)	loss 3.6626 (3.6626)	grad_norm 0.2818 (0.2818)	mem 39782MB
[2023-07-07 07:39:32 RepVGG-A0] (main.py 282): INFO Train: [15/300][10/78]	eta 0:03:45 lr 6.359928	time 1.1745 (3.3181)	loss 3.6556 (3.7261)	grad_norm 0.2760 (0.3218)	mem 39782MB
[2023-07-07 07:39:46 RepVGG-A0] (main.py 282): INFO Train: [15/300][20/78]	eta 0:02:20 lr 6.359247	time 1.1897 (2.4175)	loss 3.7035 (3.6986)	grad_norm 0.3307 (0.3248)	mem 39782MB
[2023-07-07 07:40:02 RepVGG-A0] (main.py 282): INFO Train: [15/300][30/78]	eta 0:01:42 lr 6.358561	time 1.6579 (2.1379)	loss 3.6793 (3.6799)	grad_norm 0.3374 (0.3216)	mem 39782MB
[2023-07-07 07:40:20 RepVGG-A0] (main.py 282): INFO Train: [15/300][40/78]	eta 0:01:17 lr 6.357869	time 3.6500 (2.0486)	loss 3.7961 (3.6934)	grad_norm 0.3651 (0.3323)	mem 39782MB
[2023-07-07 07:40:35 RepVGG-A0] (main.py 282): INFO Train: [15/300][50/78]	eta 0:00:54 lr 6.357171	time 1.1734 (1.9405)	loss 4.3535 (3.7409)	grad_norm 0.6949 (0.3576)	mem 39782MB
[2023-07-07 07:40:50 RepVGG-A0] (main.py 282): INFO Train: [15/300][60/78]	eta 0:00:33 lr 6.356468	time 1.3141 (1.8702)	loss 5.2724 (4.0159)	grad_norm 0.4850 (0.4067)	mem 39782MB
[2023-07-07 07:41:05 RepVGG-A0] (main.py 282): INFO Train: [15/300][70/78]	eta 0:00:14 lr 6.355759	time 1.2072 (1.8170)	loss 4.3967 (4.1213)	grad_norm 0.2292 (0.3932)	mem 39782MB
[2023-07-07 07:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 15 training takes 0:02:21
[2023-07-07 07:41:37 RepVGG-A0] (main.py 282): INFO Train: [16/300][0/78]	eta 0:26:21 lr 6.355187	time 20.2757 (20.2757)	loss 4.2191 (4.2191)	grad_norm 0.2985 (0.2985)	mem 39782MB
[2023-07-07 07:41:53 RepVGG-A0] (main.py 282): INFO Train: [16/300][10/78]	eta 0:03:43 lr 6.354468	time 1.1705 (3.2831)	loss 3.8555 (4.0633)	grad_norm 0.2392 (0.2544)	mem 39782MB
[2023-07-07 07:42:07 RepVGG-A0] (main.py 282): INFO Train: [16/300][20/78]	eta 0:02:19 lr 6.353743	time 1.1721 (2.4013)	loss 3.9510 (4.0090)	grad_norm 0.3623 (0.2789)	mem 39782MB
[2023-07-07 07:42:23 RepVGG-A0] (main.py 282): INFO Train: [16/300][30/78]	eta 0:01:42 lr 6.353012	time 1.6328 (2.1296)	loss 3.7502 (3.9738)	grad_norm 0.2343 (0.2871)	mem 39782MB
[2023-07-07 07:42:40 RepVGG-A0] (main.py 282): INFO Train: [16/300][40/78]	eta 0:01:17 lr 6.352276	time 3.4341 (2.0373)	loss 3.9945 (3.9469)	grad_norm 0.4042 (0.2984)	mem 39782MB
[2023-07-07 07:42:55 RepVGG-A0] (main.py 282): INFO Train: [16/300][50/78]	eta 0:00:54 lr 6.351534	time 1.1728 (1.9319)	loss 3.7096 (3.9160)	grad_norm 0.3138 (0.2998)	mem 39782MB
[2023-07-07 07:43:11 RepVGG-A0] (main.py 282): INFO Train: [16/300][60/78]	eta 0:00:33 lr 6.350786	time 1.2719 (1.8751)	loss 3.9704 (3.9087)	grad_norm 0.4180 (0.3114)	mem 39782MB
[2023-07-07 07:43:26 RepVGG-A0] (main.py 282): INFO Train: [16/300][70/78]	eta 0:00:14 lr 6.350033	time 1.2895 (1.8224)	loss 3.8471 (3.8975)	grad_norm 0.3425 (0.3142)	mem 39782MB
[2023-07-07 07:43:38 RepVGG-A0] (main.py 291): INFO EPOCH 16 training takes 0:02:20
[2023-07-07 07:43:58 RepVGG-A0] (main.py 282): INFO Train: [17/300][0/78]	eta 0:26:52 lr 6.349426	time 20.6685 (20.6685)	loss 3.6419 (3.6419)	grad_norm 0.3172 (0.3172)	mem 39782MB
[2023-07-07 07:44:14 RepVGG-A0] (main.py 282): INFO Train: [17/300][10/78]	eta 0:03:43 lr 6.348662	time 1.1702 (3.2884)	loss 3.7557 (3.7435)	grad_norm 0.3768 (0.3612)	mem 39782MB
[2023-07-07 07:44:29 RepVGG-A0] (main.py 282): INFO Train: [17/300][20/78]	eta 0:02:21 lr 6.347893	time 1.1771 (2.4374)	loss 3.7091 (3.7276)	grad_norm 0.3442 (0.3521)	mem 39782MB
[2023-07-07 07:44:44 RepVGG-A0] (main.py 282): INFO Train: [17/300][30/78]	eta 0:01:43 lr 6.347118	time 1.6494 (2.1515)	loss 3.7958 (3.7373)	grad_norm 0.3819 (0.3557)	mem 39782MB
[2023-07-07 07:45:02 RepVGG-A0] (main.py 282): INFO Train: [17/300][40/78]	eta 0:01:18 lr 6.346337	time 3.9551 (2.0583)	loss 3.6671 (3.7331)	grad_norm 0.3219 (0.3521)	mem 39782MB
[2023-07-07 07:45:18 RepVGG-A0] (main.py 282): INFO Train: [17/300][50/78]	eta 0:00:54 lr 6.345551	time 1.2788 (1.9635)	loss 3.8284 (3.7430)	grad_norm 0.4348 (0.3601)	mem 39782MB
[2023-07-07 07:45:32 RepVGG-A0] (main.py 282): INFO Train: [17/300][60/78]	eta 0:00:33 lr 6.344759	time 1.1846 (1.8788)	loss 3.6189 (3.7554)	grad_norm 0.2790 (0.3611)	mem 39782MB
[2023-07-07 07:45:47 RepVGG-A0] (main.py 282): INFO Train: [17/300][70/78]	eta 0:00:14 lr 6.343961	time 1.2781 (1.8258)	loss 3.6161 (3.7423)	grad_norm 0.3194 (0.3548)	mem 39782MB
[2023-07-07 07:46:00 RepVGG-A0] (main.py 291): INFO EPOCH 17 training takes 0:02:22
[2023-07-07 07:46:22 RepVGG-A0] (main.py 282): INFO Train: [18/300][0/78]	eta 0:27:31 lr 6.343319	time 21.1694 (21.1694)	loss 6.1834 (6.1834)	grad_norm 1.0156 (1.0156)	mem 39782MB
[2023-07-07 07:46:36 RepVGG-A0] (main.py 282): INFO Train: [18/300][10/78]	eta 0:03:42 lr 6.342511	time 1.1914 (3.2674)	loss 5.4290 (5.8257)	grad_norm 0.4270 (0.5488)	mem 39782MB
[2023-07-07 07:46:51 RepVGG-A0] (main.py 282): INFO Train: [18/300][20/78]	eta 0:02:19 lr 6.341698	time 1.1739 (2.3971)	loss 4.7850 (5.4207)	grad_norm 0.3467 (0.4279)	mem 39782MB
[2023-07-07 07:47:06 RepVGG-A0] (main.py 282): INFO Train: [18/300][30/78]	eta 0:01:41 lr 6.340879	time 1.4159 (2.1072)	loss 4.4019 (5.1693)	grad_norm 0.2444 (0.3872)	mem 39782MB
[2023-07-07 07:47:24 RepVGG-A0] (main.py 282): INFO Train: [18/300][40/78]	eta 0:01:17 lr 6.340054	time 4.0679 (2.0454)	loss 4.2915 (4.9529)	grad_norm 0.3201 (0.3564)	mem 39782MB
[2023-07-07 07:47:39 RepVGG-A0] (main.py 282): INFO Train: [18/300][50/78]	eta 0:00:54 lr 6.339223	time 1.1719 (1.9424)	loss 4.0749 (4.8046)	grad_norm 0.2617 (0.3466)	mem 39782MB
[2023-07-07 07:47:55 RepVGG-A0] (main.py 282): INFO Train: [18/300][60/78]	eta 0:00:33 lr 6.338387	time 1.2267 (1.8796)	loss 4.1022 (4.6898)	grad_norm 0.3505 (0.3408)	mem 39782MB
[2023-07-07 07:48:11 RepVGG-A0] (main.py 282): INFO Train: [18/300][70/78]	eta 0:00:14 lr 6.337545	time 1.1391 (1.8396)	loss 3.9990 (4.5902)	grad_norm 0.3598 (0.3366)	mem 39782MB
[2023-07-07 07:48:22 RepVGG-A0] (main.py 291): INFO EPOCH 18 training takes 0:02:21
[2023-07-07 07:48:43 RepVGG-A0] (main.py 282): INFO Train: [19/300][0/78]	eta 0:27:26 lr 6.336868	time 21.1152 (21.1152)	loss 3.8965 (3.8965)	grad_norm 0.3231 (0.3231)	mem 39782MB
[2023-07-07 07:48:57 RepVGG-A0] (main.py 282): INFO Train: [19/300][10/78]	eta 0:03:36 lr 6.336016	time 1.1707 (3.1830)	loss 3.9095 (3.9066)	grad_norm 0.3505 (0.3401)	mem 39782MB
[2023-07-07 07:49:12 RepVGG-A0] (main.py 282): INFO Train: [19/300][20/78]	eta 0:02:18 lr 6.335158	time 1.1914 (2.3933)	loss 3.9538 (3.9031)	grad_norm 0.3872 (0.3436)	mem 39782MB
[2023-07-07 07:49:27 RepVGG-A0] (main.py 282): INFO Train: [19/300][30/78]	eta 0:01:40 lr 6.334295	time 1.2677 (2.0850)	loss 3.7538 (3.9047)	grad_norm 0.3336 (0.3445)	mem 39782MB
[2023-07-07 07:49:44 RepVGG-A0] (main.py 282): INFO Train: [19/300][40/78]	eta 0:01:16 lr 6.333426	time 4.0416 (2.0007)	loss 4.0216 (3.8826)	grad_norm 0.4114 (0.3415)	mem 39782MB
[2023-07-07 07:50:00 RepVGG-A0] (main.py 282): INFO Train: [19/300][50/78]	eta 0:00:53 lr 6.332551	time 1.1735 (1.9084)	loss 3.8168 (3.8759)	grad_norm 0.3259 (0.3416)	mem 39782MB
[2023-07-07 07:50:14 RepVGG-A0] (main.py 282): INFO Train: [19/300][60/78]	eta 0:00:33 lr 6.331671	time 1.1275 (1.8409)	loss 3.8882 (3.8628)	grad_norm 0.3858 (0.3434)	mem 39782MB
[2023-07-07 07:50:30 RepVGG-A0] (main.py 282): INFO Train: [19/300][70/78]	eta 0:00:14 lr 6.330785	time 1.1260 (1.7997)	loss 4.0565 (3.8633)	grad_norm 0.4791 (0.3495)	mem 39782MB
[2023-07-07 07:50:41 RepVGG-A0] (main.py 291): INFO EPOCH 19 training takes 0:02:19
[2023-07-07 07:51:03 RepVGG-A0] (main.py 282): INFO Train: [20/300][0/78]	eta 0:28:08 lr 6.330072	time 21.6501 (21.6501)	loss 3.8048 (3.8048)	grad_norm 0.2921 (0.2921)	mem 39782MB
[2023-07-07 07:51:17 RepVGG-A0] (main.py 282): INFO Train: [20/300][10/78]	eta 0:03:42 lr 6.329176	time 1.1803 (3.2708)	loss 4.0587 (3.8545)	grad_norm 0.4776 (0.3881)	mem 39782MB
[2023-07-07 07:51:33 RepVGG-A0] (main.py 282): INFO Train: [20/300][20/78]	eta 0:02:22 lr 6.328275	time 1.1759 (2.4553)	loss 3.7536 (3.8397)	grad_norm 0.3171 (0.3670)	mem 39782MB
[2023-07-07 07:51:49 RepVGG-A0] (main.py 282): INFO Train: [20/300][30/78]	eta 0:01:44 lr 6.327367	time 1.4979 (2.1724)	loss 3.8242 (3.8583)	grad_norm 0.3293 (0.3753)	mem 39782MB
[2023-07-07 07:52:06 RepVGG-A0] (main.py 282): INFO Train: [20/300][40/78]	eta 0:01:18 lr 6.326454	time 3.9685 (2.0661)	loss 3.7891 (3.8259)	grad_norm 0.3773 (0.3609)	mem 39782MB
[2023-07-07 07:52:21 RepVGG-A0] (main.py 282): INFO Train: [20/300][50/78]	eta 0:00:54 lr 6.325536	time 1.1926 (1.9507)	loss 3.6404 (3.7988)	grad_norm 0.2934 (0.3514)	mem 39782MB
[2023-07-07 07:52:36 RepVGG-A0] (main.py 282): INFO Train: [20/300][60/78]	eta 0:00:33 lr 6.324611	time 1.3659 (1.8815)	loss 3.9314 (3.7995)	grad_norm 0.4276 (0.3578)	mem 39782MB
[2023-07-07 07:52:51 RepVGG-A0] (main.py 282): INFO Train: [20/300][70/78]	eta 0:00:14 lr 6.323682	time 1.1455 (1.8265)	loss 3.7110 (3.8010)	grad_norm 0.3177 (0.3581)	mem 39782MB
[2023-07-07 07:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 20 training takes 0:02:20
[2023-07-07 07:53:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.625 (17.625)	Loss 3.2837 (3.2837)	Acc@1 32.971 (32.971)	Acc@5 57.623 (57.623)	Mem 39782MB
[2023-07-07 07:53:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 32.742 Acc@5 57.506
[2023-07-07 07:53:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 20: 32.742%
[2023-07-07 07:53:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 07:53:42 RepVGG-A0] (main.py 282): INFO Train: [21/300][0/78]	eta 0:27:34 lr 6.322934	time 21.2168 (21.2168)	loss 3.6170 (3.6170)	grad_norm 0.3284 (0.3284)	mem 39782MB
[2023-07-07 07:53:57 RepVGG-A0] (main.py 282): INFO Train: [21/300][10/78]	eta 0:03:45 lr 6.321994	time 1.1734 (3.3119)	loss 3.8321 (3.7238)	grad_norm 0.4108 (0.3748)	mem 39782MB
[2023-07-07 07:54:12 RepVGG-A0] (main.py 282): INFO Train: [21/300][20/78]	eta 0:02:21 lr 6.321048	time 1.1912 (2.4335)	loss 3.7940 (3.7538)	grad_norm 0.3869 (0.3783)	mem 39782MB
[2023-07-07 07:54:27 RepVGG-A0] (main.py 282): INFO Train: [21/300][30/78]	eta 0:01:42 lr 6.320097	time 1.5132 (2.1451)	loss 3.6768 (3.7413)	grad_norm 0.3176 (0.3678)	mem 39782MB
[2023-07-07 07:54:44 RepVGG-A0] (main.py 282): INFO Train: [21/300][40/78]	eta 0:01:17 lr 6.319140	time 3.0535 (2.0434)	loss 3.6845 (3.7096)	grad_norm 0.4025 (0.3611)	mem 39782MB
[2023-07-07 07:54:59 RepVGG-A0] (main.py 282): INFO Train: [21/300][50/78]	eta 0:00:54 lr 6.318177	time 1.1720 (1.9409)	loss 3.6018 (3.7012)	grad_norm 0.3152 (0.3574)	mem 39782MB
[2023-07-07 07:55:15 RepVGG-A0] (main.py 282): INFO Train: [21/300][60/78]	eta 0:00:33 lr 6.317209	time 1.1864 (1.8723)	loss 3.6628 (3.6997)	grad_norm 0.3534 (0.3590)	mem 39782MB
[2023-07-07 07:55:30 RepVGG-A0] (main.py 282): INFO Train: [21/300][70/78]	eta 0:00:14 lr 6.316236	time 1.4062 (1.8232)	loss 3.8384 (3.7060)	grad_norm 0.4265 (0.3649)	mem 39782MB
[2023-07-07 07:55:42 RepVGG-A0] (main.py 291): INFO EPOCH 21 training takes 0:02:21
[2023-07-07 07:56:03 RepVGG-A0] (main.py 282): INFO Train: [22/300][0/78]	eta 0:27:57 lr 6.315452	time 21.5056 (21.5056)	loss 4.4676 (4.4676)	grad_norm 0.5225 (0.5225)	mem 39782MB
[2023-07-07 07:56:18 RepVGG-A0] (main.py 282): INFO Train: [22/300][10/78]	eta 0:03:43 lr 6.314469	time 1.1961 (3.2800)	loss 3.8358 (4.1094)	grad_norm 0.3035 (0.3728)	mem 39782MB
[2023-07-07 07:56:32 RepVGG-A0] (main.py 282): INFO Train: [22/300][20/78]	eta 0:02:19 lr 6.313479	time 1.1734 (2.4014)	loss 3.6095 (3.9202)	grad_norm 0.2631 (0.3263)	mem 39782MB
[2023-07-07 07:56:48 RepVGG-A0] (main.py 282): INFO Train: [22/300][30/78]	eta 0:01:43 lr 6.312484	time 1.4319 (2.1555)	loss 3.6787 (3.8292)	grad_norm 0.3040 (0.3154)	mem 39782MB
[2023-07-07 07:57:06 RepVGG-A0] (main.py 282): INFO Train: [22/300][40/78]	eta 0:01:17 lr 6.311483	time 3.8902 (2.0499)	loss 3.5933 (3.7746)	grad_norm 0.3168 (0.3164)	mem 39782MB
[2023-07-07 07:57:20 RepVGG-A0] (main.py 282): INFO Train: [22/300][50/78]	eta 0:00:54 lr 6.310477	time 1.3182 (1.9374)	loss 3.7571 (3.7564)	grad_norm 0.3499 (0.3246)	mem 39782MB
[2023-07-07 07:57:35 RepVGG-A0] (main.py 282): INFO Train: [22/300][60/78]	eta 0:00:33 lr 6.309465	time 1.1712 (1.8628)	loss 3.6818 (3.7324)	grad_norm 0.3477 (0.3247)	mem 39782MB
[2023-07-07 07:57:50 RepVGG-A0] (main.py 282): INFO Train: [22/300][70/78]	eta 0:00:14 lr 6.308448	time 1.1702 (1.8149)	loss 3.6607 (3.7204)	grad_norm 0.3597 (0.3286)	mem 39782MB
[2023-07-07 07:58:03 RepVGG-A0] (main.py 291): INFO EPOCH 22 training takes 0:02:21
[2023-07-07 07:58:24 RepVGG-A0] (main.py 282): INFO Train: [23/300][0/78]	eta 0:27:23 lr 6.307630	time 21.0701 (21.0701)	loss 3.4655 (3.4655)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 07:58:39 RepVGG-A0] (main.py 282): INFO Train: [23/300][10/78]	eta 0:03:41 lr 6.306602	time 1.1718 (3.2521)	loss 3.6795 (3.6324)	grad_norm 0.3604 (0.3686)	mem 39782MB
[2023-07-07 07:58:54 RepVGG-A0] (main.py 282): INFO Train: [23/300][20/78]	eta 0:02:22 lr 6.305569	time 1.3818 (2.4495)	loss 3.5754 (3.6277)	grad_norm 0.3414 (0.3583)	mem 39782MB
[2023-07-07 07:59:09 RepVGG-A0] (main.py 282): INFO Train: [23/300][30/78]	eta 0:01:42 lr 6.304530	time 1.3659 (2.1365)	loss 3.5708 (3.6168)	grad_norm 0.3500 (0.3585)	mem 39782MB
[2023-07-07 07:59:27 RepVGG-A0] (main.py 282): INFO Train: [23/300][40/78]	eta 0:01:18 lr 6.303486	time 3.5115 (2.0537)	loss 3.5666 (3.6186)	grad_norm 0.3400 (0.3606)	mem 39782MB
[2023-07-07 07:59:42 RepVGG-A0] (main.py 282): INFO Train: [23/300][50/78]	eta 0:00:54 lr 6.302436	time 1.1947 (1.9451)	loss 3.5878 (3.6077)	grad_norm 0.3568 (0.3566)	mem 39782MB
[2023-07-07 07:59:57 RepVGG-A0] (main.py 282): INFO Train: [23/300][60/78]	eta 0:00:33 lr 6.301380	time 1.1804 (1.8769)	loss 3.6656 (3.6144)	grad_norm 0.3734 (0.3597)	mem 39782MB
[2023-07-07 08:00:13 RepVGG-A0] (main.py 282): INFO Train: [23/300][70/78]	eta 0:00:14 lr 6.300319	time 1.2496 (1.8289)	loss 3.6676 (3.6116)	grad_norm 0.3992 (0.3592)	mem 39782MB
[2023-07-07 08:00:24 RepVGG-A0] (main.py 291): INFO EPOCH 23 training takes 0:02:20
[2023-07-07 08:00:46 RepVGG-A0] (main.py 282): INFO Train: [24/300][0/78]	eta 0:28:36 lr 6.299466	time 22.0043 (22.0043)	loss 3.6155 (3.6155)	grad_norm 0.3645 (0.3645)	mem 39782MB
[2023-07-07 08:00:59 RepVGG-A0] (main.py 282): INFO Train: [24/300][10/78]	eta 0:03:41 lr 6.298395	time 1.1719 (3.2517)	loss 3.4707 (3.4963)	grad_norm 0.3359 (0.3254)	mem 39782MB
[2023-07-07 08:01:14 RepVGG-A0] (main.py 282): INFO Train: [24/300][20/78]	eta 0:02:19 lr 6.297318	time 1.1717 (2.3985)	loss 4.4244 (3.6529)	grad_norm 0.7927 (0.4109)	mem 39782MB
[2023-07-07 08:01:29 RepVGG-A0] (main.py 282): INFO Train: [24/300][30/78]	eta 0:01:41 lr 6.296236	time 1.2967 (2.1086)	loss 5.5341 (4.3548)	grad_norm 0.3807 (0.4860)	mem 39782MB
[2023-07-07 08:01:47 RepVGG-A0] (main.py 282): INFO Train: [24/300][40/78]	eta 0:01:17 lr 6.295148	time 3.0153 (2.0287)	loss 4.8318 (4.5647)	grad_norm 0.2415 (0.4467)	mem 39782MB
[2023-07-07 08:02:02 RepVGG-A0] (main.py 282): INFO Train: [24/300][50/78]	eta 0:00:53 lr 6.294054	time 1.1893 (1.9203)	loss 4.4032 (4.5798)	grad_norm 0.2658 (0.4163)	mem 39782MB
[2023-07-07 08:02:17 RepVGG-A0] (main.py 282): INFO Train: [24/300][60/78]	eta 0:00:33 lr 6.292955	time 1.1799 (1.8519)	loss 4.3554 (4.5417)	grad_norm 0.3431 (0.3977)	mem 39782MB
[2023-07-07 08:02:32 RepVGG-A0] (main.py 282): INFO Train: [24/300][70/78]	eta 0:00:14 lr 6.291850	time 1.1715 (1.8025)	loss 4.3012 (4.4873)	grad_norm 0.4236 (0.3862)	mem 39782MB
[2023-07-07 08:02:44 RepVGG-A0] (main.py 291): INFO EPOCH 24 training takes 0:02:19
[2023-07-07 08:03:04 RepVGG-A0] (main.py 282): INFO Train: [25/300][0/78]	eta 0:26:33 lr 6.290963	time 20.4292 (20.4292)	loss 3.9668 (3.9668)	grad_norm 0.2841 (0.2841)	mem 39782MB
[2023-07-07 08:03:21 RepVGG-A0] (main.py 282): INFO Train: [25/300][10/78]	eta 0:03:49 lr 6.289848	time 1.1718 (3.3774)	loss 4.0321 (3.9743)	grad_norm 0.3544 (0.3094)	mem 39782MB
[2023-07-07 08:03:35 RepVGG-A0] (main.py 282): INFO Train: [25/300][20/78]	eta 0:02:21 lr 6.288728	time 1.1452 (2.4405)	loss 3.8602 (3.9364)	grad_norm 0.2953 (0.3101)	mem 39782MB
[2023-07-07 08:03:50 RepVGG-A0] (main.py 282): INFO Train: [25/300][30/78]	eta 0:01:42 lr 6.287602	time 1.6362 (2.1452)	loss 3.8185 (3.9101)	grad_norm 0.3473 (0.3172)	mem 39782MB
[2023-07-07 08:04:07 RepVGG-A0] (main.py 282): INFO Train: [25/300][40/78]	eta 0:01:17 lr 6.286470	time 4.0328 (2.0404)	loss 3.8714 (3.9113)	grad_norm 0.3601 (0.3316)	mem 39782MB
[2023-07-07 08:04:22 RepVGG-A0] (main.py 282): INFO Train: [25/300][50/78]	eta 0:00:54 lr 6.285333	time 1.1709 (1.9402)	loss 3.8651 (3.8889)	grad_norm 0.3959 (0.3312)	mem 39782MB
[2023-07-07 08:04:38 RepVGG-A0] (main.py 282): INFO Train: [25/300][60/78]	eta 0:00:33 lr 6.284191	time 1.1721 (1.8743)	loss 3.7364 (3.8758)	grad_norm 0.3242 (0.3322)	mem 39782MB
[2023-07-07 08:04:54 RepVGG-A0] (main.py 282): INFO Train: [25/300][70/78]	eta 0:00:14 lr 6.283043	time 1.2763 (1.8309)	loss 3.9788 (3.8625)	grad_norm 0.4574 (0.3368)	mem 39782MB
[2023-07-07 08:05:06 RepVGG-A0] (main.py 291): INFO EPOCH 25 training takes 0:02:22
[2023-07-07 08:05:27 RepVGG-A0] (main.py 282): INFO Train: [26/300][0/78]	eta 0:27:33 lr 6.282120	time 21.2048 (21.2048)	loss 3.6013 (3.6013)	grad_norm 0.3104 (0.3104)	mem 39782MB
[2023-07-07 08:05:42 RepVGG-A0] (main.py 282): INFO Train: [26/300][10/78]	eta 0:03:44 lr 6.280962	time 1.1721 (3.3050)	loss 4.2998 (3.7886)	grad_norm 0.7122 (0.4144)	mem 39782MB
[2023-07-07 08:05:56 RepVGG-A0] (main.py 282): INFO Train: [26/300][20/78]	eta 0:02:19 lr 6.279798	time 1.1736 (2.3970)	loss 4.7788 (4.3872)	grad_norm 0.3648 (0.5107)	mem 39782MB
[2023-07-07 08:06:11 RepVGG-A0] (main.py 282): INFO Train: [26/300][30/78]	eta 0:01:41 lr 6.278629	time 1.2976 (2.1184)	loss 4.2599 (4.3811)	grad_norm 0.3739 (0.4444)	mem 39782MB
[2023-07-07 08:06:30 RepVGG-A0] (main.py 282): INFO Train: [26/300][40/78]	eta 0:01:18 lr 6.277454	time 4.5108 (2.0543)	loss 3.9048 (4.3158)	grad_norm 0.2316 (0.4091)	mem 39782MB
[2023-07-07 08:06:45 RepVGG-A0] (main.py 282): INFO Train: [26/300][50/78]	eta 0:00:54 lr 6.276274	time 1.1746 (1.9415)	loss 3.8583 (4.2267)	grad_norm 0.2624 (0.3826)	mem 39782MB
[2023-07-07 08:07:00 RepVGG-A0] (main.py 282): INFO Train: [26/300][60/78]	eta 0:00:33 lr 6.275088	time 1.3372 (1.8768)	loss 3.8692 (4.1535)	grad_norm 0.3173 (0.3659)	mem 39782MB
[2023-07-07 08:07:14 RepVGG-A0] (main.py 282): INFO Train: [26/300][70/78]	eta 0:00:14 lr 6.273897	time 1.1715 (1.8130)	loss 3.7367 (4.0934)	grad_norm 0.3091 (0.3571)	mem 39782MB
[2023-07-07 08:07:26 RepVGG-A0] (main.py 291): INFO EPOCH 26 training takes 0:02:20
[2023-07-07 08:07:48 RepVGG-A0] (main.py 282): INFO Train: [27/300][0/78]	eta 0:27:54 lr 6.272940	time 21.4632 (21.4632)	loss 3.7023 (3.7023)	grad_norm 0.3342 (0.3342)	mem 39782MB
[2023-07-07 08:08:03 RepVGG-A0] (main.py 282): INFO Train: [27/300][10/78]	eta 0:03:44 lr 6.271738	time 1.1720 (3.2970)	loss 3.7804 (3.7150)	grad_norm 0.3630 (0.3613)	mem 39782MB
[2023-07-07 08:08:17 RepVGG-A0] (main.py 282): INFO Train: [27/300][20/78]	eta 0:02:20 lr 6.270532	time 1.1781 (2.4301)	loss 3.8027 (3.7264)	grad_norm 0.3418 (0.3543)	mem 39782MB
[2023-07-07 08:08:32 RepVGG-A0] (main.py 282): INFO Train: [27/300][30/78]	eta 0:01:41 lr 6.269319	time 1.1292 (2.1215)	loss 3.5398 (3.6922)	grad_norm 0.3159 (0.3384)	mem 39782MB
[2023-07-07 08:08:50 RepVGG-A0] (main.py 282): INFO Train: [27/300][40/78]	eta 0:01:17 lr 6.268101	time 3.0175 (2.0461)	loss 4.1063 (3.7088)	grad_norm 0.5404 (0.3534)	mem 39782MB
[2023-07-07 08:09:05 RepVGG-A0] (main.py 282): INFO Train: [27/300][50/78]	eta 0:00:54 lr 6.266878	time 1.2475 (1.9356)	loss 3.9088 (3.8086)	grad_norm 0.3163 (0.3780)	mem 39782MB
[2023-07-07 08:09:20 RepVGG-A0] (main.py 282): INFO Train: [27/300][60/78]	eta 0:00:33 lr 6.265649	time 1.1761 (1.8613)	loss 3.7624 (3.8095)	grad_norm 0.2731 (0.3623)	mem 39782MB
[2023-07-07 08:09:35 RepVGG-A0] (main.py 282): INFO Train: [27/300][70/78]	eta 0:00:14 lr 6.264414	time 1.1718 (1.8126)	loss 3.6118 (3.7850)	grad_norm 0.3163 (0.3513)	mem 39782MB
[2023-07-07 08:09:47 RepVGG-A0] (main.py 291): INFO EPOCH 27 training takes 0:02:20
[2023-07-07 08:10:09 RepVGG-A0] (main.py 282): INFO Train: [28/300][0/78]	eta 0:28:20 lr 6.263422	time 21.7961 (21.7961)	loss 3.6038 (3.6038)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 08:10:24 RepVGG-A0] (main.py 282): INFO Train: [28/300][10/78]	eta 0:03:48 lr 6.262178	time 1.1716 (3.3669)	loss 3.5835 (3.5558)	grad_norm 0.3147 (0.2939)	mem 39782MB
[2023-07-07 08:10:38 RepVGG-A0] (main.py 282): INFO Train: [28/300][20/78]	eta 0:02:21 lr 6.260928	time 1.2216 (2.4419)	loss 3.5430 (3.5671)	grad_norm 0.3378 (0.3093)	mem 39782MB
[2023-07-07 08:10:53 RepVGG-A0] (main.py 282): INFO Train: [28/300][30/78]	eta 0:01:42 lr 6.259672	time 1.6051 (2.1288)	loss 3.7852 (3.6196)	grad_norm 0.3801 (0.3378)	mem 39782MB
[2023-07-07 08:11:11 RepVGG-A0] (main.py 282): INFO Train: [28/300][40/78]	eta 0:01:17 lr 6.258411	time 3.3648 (2.0448)	loss 3.6033 (3.6242)	grad_norm 0.3011 (0.3368)	mem 39782MB
[2023-07-07 08:11:26 RepVGG-A0] (main.py 282): INFO Train: [28/300][50/78]	eta 0:00:54 lr 6.257145	time 1.1719 (1.9402)	loss 3.6681 (3.6239)	grad_norm 0.3926 (0.3398)	mem 39782MB
[2023-07-07 08:11:41 RepVGG-A0] (main.py 282): INFO Train: [28/300][60/78]	eta 0:00:33 lr 6.255873	time 1.5949 (1.8697)	loss 3.5620 (3.6295)	grad_norm 0.3168 (0.3440)	mem 39782MB
[2023-07-07 08:11:56 RepVGG-A0] (main.py 282): INFO Train: [28/300][70/78]	eta 0:00:14 lr 6.254595	time 1.1968 (1.8188)	loss 3.5492 (3.6223)	grad_norm 0.3334 (0.3408)	mem 39782MB
[2023-07-07 08:12:09 RepVGG-A0] (main.py 291): INFO EPOCH 28 training takes 0:02:21
[2023-07-07 08:12:31 RepVGG-A0] (main.py 282): INFO Train: [29/300][0/78]	eta 0:28:43 lr 6.253569	time 22.0951 (22.0951)	loss 3.5452 (3.5452)	grad_norm 0.3577 (0.3577)	mem 39782MB
[2023-07-07 08:12:45 RepVGG-A0] (main.py 282): INFO Train: [29/300][10/78]	eta 0:03:45 lr 6.252282	time 1.1714 (3.3209)	loss 6.0972 (4.6267)	grad_norm 0.7011 (0.6846)	mem 39782MB
[2023-07-07 08:13:00 RepVGG-A0] (main.py 282): INFO Train: [29/300][20/78]	eta 0:02:20 lr 6.250989	time 1.3901 (2.4287)	loss 4.9901 (5.0589)	grad_norm 0.3091 (0.5526)	mem 39782MB
[2023-07-07 08:13:15 RepVGG-A0] (main.py 282): INFO Train: [29/300][30/78]	eta 0:01:41 lr 6.249690	time 1.2510 (2.1188)	loss 4.4881 (4.9420)	grad_norm 0.3007 (0.4655)	mem 39782MB
[2023-07-07 08:13:33 RepVGG-A0] (main.py 282): INFO Train: [29/300][40/78]	eta 0:01:18 lr 6.248386	time 4.6223 (2.0564)	loss 4.2197 (4.7885)	grad_norm 0.2924 (0.4179)	mem 39782MB
[2023-07-07 08:13:48 RepVGG-A0] (main.py 282): INFO Train: [29/300][50/78]	eta 0:00:54 lr 6.247077	time 1.1740 (1.9469)	loss 4.0649 (4.6531)	grad_norm 0.3205 (0.3931)	mem 39782MB
[2023-07-07 08:14:04 RepVGG-A0] (main.py 282): INFO Train: [29/300][60/78]	eta 0:00:34 lr 6.245762	time 1.5889 (1.8897)	loss 3.9580 (4.5496)	grad_norm 0.3041 (0.3779)	mem 39782MB
[2023-07-07 08:14:18 RepVGG-A0] (main.py 282): INFO Train: [29/300][70/78]	eta 0:00:14 lr 6.244441	time 1.1263 (1.8200)	loss 3.8696 (4.4665)	grad_norm 0.2823 (0.3697)	mem 39782MB
[2023-07-07 08:14:31 RepVGG-A0] (main.py 291): INFO EPOCH 29 training takes 0:02:21
[2023-07-07 08:14:51 RepVGG-A0] (main.py 282): INFO Train: [30/300][0/78]	eta 0:27:08 lr 6.243381	time 20.8729 (20.8729)	loss 3.8680 (3.8680)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 08:15:06 RepVGG-A0] (main.py 282): INFO Train: [30/300][10/78]	eta 0:03:38 lr 6.242051	time 1.1705 (3.2152)	loss 3.9206 (3.8395)	grad_norm 0.3725 (0.3390)	mem 39782MB
[2023-07-07 08:15:20 RepVGG-A0] (main.py 282): INFO Train: [30/300][20/78]	eta 0:02:17 lr 6.240715	time 1.1910 (2.3762)	loss 3.8667 (3.8331)	grad_norm 0.3284 (0.3372)	mem 39782MB
[2023-07-07 08:15:35 RepVGG-A0] (main.py 282): INFO Train: [30/300][30/78]	eta 0:01:39 lr 6.239373	time 1.3240 (2.0708)	loss 3.7243 (3.8233)	grad_norm 0.3047 (0.3383)	mem 39782MB
[2023-07-07 08:15:53 RepVGG-A0] (main.py 282): INFO Train: [30/300][40/78]	eta 0:01:16 lr 6.238027	time 5.4196 (2.0206)	loss 3.8980 (3.8145)	grad_norm 0.3972 (0.3407)	mem 39782MB
[2023-07-07 08:16:08 RepVGG-A0] (main.py 282): INFO Train: [30/300][50/78]	eta 0:00:53 lr 6.236674	time 1.1726 (1.9153)	loss 3.6896 (3.8002)	grad_norm 0.3080 (0.3382)	mem 39782MB
[2023-07-07 08:16:24 RepVGG-A0] (main.py 282): INFO Train: [30/300][60/78]	eta 0:00:33 lr 6.235317	time 1.1807 (1.8626)	loss 3.6895 (3.7933)	grad_norm 0.3292 (0.3433)	mem 39782MB
[2023-07-07 08:16:38 RepVGG-A0] (main.py 282): INFO Train: [30/300][70/78]	eta 0:00:14 lr 6.233953	time 1.1445 (1.8009)	loss 3.9183 (3.7837)	grad_norm 0.4951 (0.3462)	mem 39782MB
[2023-07-07 08:16:50 RepVGG-A0] (main.py 291): INFO EPOCH 30 training takes 0:02:19
[2023-07-07 08:17:12 RepVGG-A0] (main.py 282): INFO Train: [31/300][0/78]	eta 0:28:22 lr 6.232859	time 21.8214 (21.8214)	loss 5.3334 (5.3334)	grad_norm 0.5897 (0.5897)	mem 39782MB
[2023-07-07 08:17:27 RepVGG-A0] (main.py 282): INFO Train: [31/300][10/78]	eta 0:03:49 lr 6.231486	time 1.1726 (3.3786)	loss 4.2019 (4.6424)	grad_norm 0.2788 (0.3600)	mem 39782MB
[2023-07-07 08:17:42 RepVGG-A0] (main.py 282): INFO Train: [31/300][20/78]	eta 0:02:22 lr 6.230107	time 1.3027 (2.4637)	loss 3.9870 (4.3914)	grad_norm 0.3201 (0.3397)	mem 39782MB
[2023-07-07 08:17:57 RepVGG-A0] (main.py 282): INFO Train: [31/300][30/78]	eta 0:01:44 lr 6.228723	time 1.1793 (2.1690)	loss 3.8059 (4.2173)	grad_norm 0.2599 (0.3074)	mem 39782MB
[2023-07-07 08:18:15 RepVGG-A0] (main.py 282): INFO Train: [31/300][40/78]	eta 0:01:18 lr 6.227334	time 3.1907 (2.0713)	loss 3.7086 (4.1012)	grad_norm 0.3200 (0.2997)	mem 39782MB
[2023-07-07 08:18:30 RepVGG-A0] (main.py 282): INFO Train: [31/300][50/78]	eta 0:00:54 lr 6.225939	time 1.1708 (1.9577)	loss 3.7791 (4.0385)	grad_norm 0.3230 (0.3059)	mem 39782MB
[2023-07-07 08:18:45 RepVGG-A0] (main.py 282): INFO Train: [31/300][60/78]	eta 0:00:33 lr 6.224539	time 1.1793 (1.8818)	loss 3.7404 (3.9834)	grad_norm 0.3415 (0.3073)	mem 39782MB
[2023-07-07 08:19:00 RepVGG-A0] (main.py 282): INFO Train: [31/300][70/78]	eta 0:00:14 lr 6.223133	time 1.2244 (1.8336)	loss 3.6962 (3.9422)	grad_norm 0.3307 (0.3094)	mem 39782MB
[2023-07-07 08:19:12 RepVGG-A0] (main.py 291): INFO EPOCH 31 training takes 0:02:21
[2023-07-07 08:19:32 RepVGG-A0] (main.py 282): INFO Train: [32/300][0/78]	eta 0:26:38 lr 6.222004	time 20.4902 (20.4902)	loss 3.5554 (3.5554)	grad_norm 0.3058 (0.3058)	mem 39782MB
[2023-07-07 08:19:46 RepVGG-A0] (main.py 282): INFO Train: [32/300][10/78]	eta 0:03:32 lr 6.220589	time 1.1722 (3.1264)	loss 3.6776 (3.7137)	grad_norm 0.3673 (0.3759)	mem 39782MB
[2023-07-07 08:20:02 RepVGG-A0] (main.py 282): INFO Train: [32/300][20/78]	eta 0:02:18 lr 6.219168	time 1.1738 (2.3814)	loss 3.5997 (3.6881)	grad_norm 0.2875 (0.3475)	mem 39782MB
[2023-07-07 08:20:17 RepVGG-A0] (main.py 282): INFO Train: [32/300][30/78]	eta 0:01:41 lr 6.217741	time 1.1881 (2.1131)	loss 3.5263 (3.6625)	grad_norm 0.3112 (0.3431)	mem 39782MB
[2023-07-07 08:20:35 RepVGG-A0] (main.py 282): INFO Train: [32/300][40/78]	eta 0:01:17 lr 6.216309	time 4.7973 (2.0396)	loss 3.7603 (3.6631)	grad_norm 0.4289 (0.3510)	mem 39782MB
[2023-07-07 08:20:50 RepVGG-A0] (main.py 282): INFO Train: [32/300][50/78]	eta 0:00:54 lr 6.214872	time 1.1739 (1.9330)	loss 3.8604 (3.6702)	grad_norm 0.4604 (0.3518)	mem 39782MB
[2023-07-07 08:21:05 RepVGG-A0] (main.py 282): INFO Train: [32/300][60/78]	eta 0:00:33 lr 6.213429	time 1.3376 (1.8638)	loss 3.6666 (3.6840)	grad_norm 0.3088 (0.3563)	mem 39782MB
[2023-07-07 08:21:20 RepVGG-A0] (main.py 282): INFO Train: [32/300][70/78]	eta 0:00:14 lr 6.211981	time 1.4305 (1.8138)	loss 3.5283 (3.6658)	grad_norm 0.3149 (0.3469)	mem 39782MB
[2023-07-07 08:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 32 training takes 0:02:20
[2023-07-07 08:21:54 RepVGG-A0] (main.py 282): INFO Train: [33/300][0/78]	eta 0:27:57 lr 6.210818	time 21.5080 (21.5080)	loss 4.0708 (4.0708)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 08:22:09 RepVGG-A0] (main.py 282): INFO Train: [33/300][10/78]	eta 0:03:45 lr 6.209360	time 1.1730 (3.3127)	loss 5.5602 (4.9350)	grad_norm 0.5298 (0.7022)	mem 39782MB
[2023-07-07 08:22:24 RepVGG-A0] (main.py 282): INFO Train: [33/300][20/78]	eta 0:02:21 lr 6.207897	time 1.2147 (2.4431)	loss 4.4473 (4.8536)	grad_norm 0.2923 (0.5366)	mem 39782MB
[2023-07-07 08:22:39 RepVGG-A0] (main.py 282): INFO Train: [33/300][30/78]	eta 0:01:43 lr 6.206428	time 1.1887 (2.1516)	loss 4.0561 (4.6202)	grad_norm 0.2446 (0.4461)	mem 39782MB
[2023-07-07 08:22:57 RepVGG-A0] (main.py 282): INFO Train: [33/300][40/78]	eta 0:01:18 lr 6.204954	time 3.6847 (2.0633)	loss 3.9305 (4.4575)	grad_norm 0.3565 (0.4098)	mem 39782MB
[2023-07-07 08:23:12 RepVGG-A0] (main.py 282): INFO Train: [33/300][50/78]	eta 0:00:54 lr 6.203474	time 1.2406 (1.9548)	loss 3.8126 (4.3308)	grad_norm 0.2677 (0.3821)	mem 39782MB
[2023-07-07 08:23:27 RepVGG-A0] (main.py 282): INFO Train: [33/300][60/78]	eta 0:00:33 lr 6.201989	time 1.1278 (1.8775)	loss 3.6373 (4.2319)	grad_norm 0.3083 (0.3665)	mem 39782MB
[2023-07-07 08:23:42 RepVGG-A0] (main.py 282): INFO Train: [33/300][70/78]	eta 0:00:14 lr 6.200499	time 1.3699 (1.8298)	loss 3.6977 (4.1632)	grad_norm 0.3201 (0.3605)	mem 39782MB
[2023-07-07 08:23:54 RepVGG-A0] (main.py 291): INFO EPOCH 33 training takes 0:02:21
[2023-07-07 08:24:16 RepVGG-A0] (main.py 282): INFO Train: [34/300][0/78]	eta 0:29:32 lr 6.199302	time 22.7187 (22.7187)	loss 3.6529 (3.6529)	grad_norm 0.2979 (0.2979)	mem 39782MB
[2023-07-07 08:24:31 RepVGG-A0] (main.py 282): INFO Train: [34/300][10/78]	eta 0:03:50 lr 6.197802	time 1.1734 (3.3911)	loss 3.7014 (3.6299)	grad_norm 0.3314 (0.3289)	mem 39782MB
[2023-07-07 08:24:46 RepVGG-A0] (main.py 282): INFO Train: [34/300][20/78]	eta 0:02:23 lr 6.196296	time 1.4245 (2.4809)	loss 3.9095 (3.7043)	grad_norm 0.4196 (0.3657)	mem 39782MB
[2023-07-07 08:25:00 RepVGG-A0] (main.py 282): INFO Train: [34/300][30/78]	eta 0:01:43 lr 6.194785	time 1.1814 (2.1524)	loss 3.7169 (3.6957)	grad_norm 0.3606 (0.3504)	mem 39782MB
[2023-07-07 08:25:17 RepVGG-A0] (main.py 282): INFO Train: [34/300][40/78]	eta 0:01:17 lr 6.193269	time 3.4557 (2.0410)	loss 3.6340 (3.6766)	grad_norm 0.3824 (0.3458)	mem 39782MB
[2023-07-07 08:25:32 RepVGG-A0] (main.py 282): INFO Train: [34/300][50/78]	eta 0:00:54 lr 6.191747	time 1.2760 (1.9376)	loss 3.6655 (3.6721)	grad_norm 0.3597 (0.3452)	mem 39782MB
[2023-07-07 08:25:47 RepVGG-A0] (main.py 282): INFO Train: [34/300][60/78]	eta 0:00:33 lr 6.190220	time 1.3179 (1.8615)	loss 3.5718 (3.6626)	grad_norm 0.3250 (0.3445)	mem 39782MB
[2023-07-07 08:26:02 RepVGG-A0] (main.py 282): INFO Train: [34/300][70/78]	eta 0:00:14 lr 6.188687	time 1.2133 (1.8041)	loss 3.7443 (3.6538)	grad_norm 0.4421 (0.3453)	mem 39782MB
[2023-07-07 08:26:14 RepVGG-A0] (main.py 291): INFO EPOCH 34 training takes 0:02:20
[2023-07-07 08:26:35 RepVGG-A0] (main.py 282): INFO Train: [35/300][0/78]	eta 0:27:21 lr 6.187457	time 21.0482 (21.0482)	loss 3.5608 (3.5608)	grad_norm 0.3010 (0.3010)	mem 39782MB
[2023-07-07 08:26:51 RepVGG-A0] (main.py 282): INFO Train: [35/300][10/78]	eta 0:03:46 lr 6.185915	time 1.1710 (3.3362)	loss 3.7283 (3.5764)	grad_norm 0.4171 (0.3401)	mem 39782MB
[2023-07-07 08:27:06 RepVGG-A0] (main.py 282): INFO Train: [35/300][20/78]	eta 0:02:22 lr 6.184367	time 1.3209 (2.4564)	loss 3.5719 (3.5976)	grad_norm 0.3161 (0.3442)	mem 39782MB
[2023-07-07 08:27:20 RepVGG-A0] (main.py 282): INFO Train: [35/300][30/78]	eta 0:01:42 lr 6.182814	time 1.4936 (2.1413)	loss 3.4878 (3.5794)	grad_norm 0.3487 (0.3416)	mem 39782MB
[2023-07-07 08:27:39 RepVGG-A0] (main.py 282): INFO Train: [35/300][40/78]	eta 0:01:18 lr 6.181256	time 3.1154 (2.0611)	loss 3.5544 (3.5823)	grad_norm 0.3401 (0.3428)	mem 39782MB
[2023-07-07 08:27:53 RepVGG-A0] (main.py 282): INFO Train: [35/300][50/78]	eta 0:00:54 lr 6.179692	time 1.1829 (1.9500)	loss 3.5156 (3.5893)	grad_norm 0.2910 (0.3484)	mem 39782MB
[2023-07-07 08:28:10 RepVGG-A0] (main.py 282): INFO Train: [35/300][60/78]	eta 0:00:34 lr 6.178123	time 1.1719 (1.8996)	loss 3.6236 (3.5794)	grad_norm 0.4451 (0.3473)	mem 39782MB
[2023-07-07 08:28:24 RepVGG-A0] (main.py 282): INFO Train: [35/300][70/78]	eta 0:00:14 lr 6.176548	time 1.3951 (1.8261)	loss 5.9653 (3.7959)	grad_norm 0.6339 (0.4042)	mem 39782MB
[2023-07-07 08:28:36 RepVGG-A0] (main.py 291): INFO EPOCH 35 training takes 0:02:22
[2023-07-07 08:28:57 RepVGG-A0] (main.py 282): INFO Train: [36/300][0/78]	eta 0:27:38 lr 6.175285	time 21.2611 (21.2611)	loss 5.1049 (5.1049)	grad_norm 0.3020 (0.3020)	mem 39782MB
[2023-07-07 08:29:13 RepVGG-A0] (main.py 282): INFO Train: [36/300][10/78]	eta 0:03:49 lr 6.173701	time 1.1721 (3.3796)	loss 4.5486 (4.8270)	grad_norm 0.2546 (0.2981)	mem 39782MB
[2023-07-07 08:29:29 RepVGG-A0] (main.py 282): INFO Train: [36/300][20/78]	eta 0:02:25 lr 6.172111	time 1.1792 (2.5105)	loss 4.2212 (4.6123)	grad_norm 0.2571 (0.2900)	mem 39782MB
[2023-07-07 08:29:45 RepVGG-A0] (main.py 282): INFO Train: [36/300][30/78]	eta 0:01:45 lr 6.170516	time 1.3831 (2.2076)	loss 4.0799 (4.4785)	grad_norm 0.2667 (0.2970)	mem 39782MB
[2023-07-07 08:30:02 RepVGG-A0] (main.py 282): INFO Train: [36/300][40/78]	eta 0:01:19 lr 6.168916	time 3.0811 (2.0966)	loss 3.9326 (4.3599)	grad_norm 0.2985 (0.2937)	mem 39782MB
[2023-07-07 08:30:18 RepVGG-A0] (main.py 282): INFO Train: [36/300][50/78]	eta 0:00:55 lr 6.167310	time 1.2829 (1.9881)	loss 3.8445 (4.2774)	grad_norm 0.2791 (0.2976)	mem 39782MB
[2023-07-07 08:30:32 RepVGG-A0] (main.py 282): INFO Train: [36/300][60/78]	eta 0:00:34 lr 6.165699	time 1.1738 (1.8960)	loss 3.7667 (4.2083)	grad_norm 0.2899 (0.3001)	mem 39782MB
[2023-07-07 08:30:47 RepVGG-A0] (main.py 282): INFO Train: [36/300][70/78]	eta 0:00:14 lr 6.164083	time 1.5064 (1.8490)	loss 3.9761 (4.1608)	grad_norm 0.3755 (0.3072)	mem 39782MB
[2023-07-07 08:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 36 training takes 0:02:22
[2023-07-07 08:31:20 RepVGG-A0] (main.py 282): INFO Train: [37/300][0/78]	eta 0:27:45 lr 6.162786	time 21.3496 (21.3496)	loss 3.7030 (3.7030)	grad_norm 0.2641 (0.2641)	mem 39782MB
[2023-07-07 08:31:35 RepVGG-A0] (main.py 282): INFO Train: [37/300][10/78]	eta 0:03:49 lr 6.161160	time 1.1713 (3.3805)	loss 4.1519 (3.8396)	grad_norm 0.5285 (0.3896)	mem 39782MB
[2023-07-07 08:31:51 RepVGG-A0] (main.py 282): INFO Train: [37/300][20/78]	eta 0:02:24 lr 6.159529	time 1.2101 (2.4905)	loss 3.7725 (3.8472)	grad_norm 0.2866 (0.3609)	mem 39782MB
[2023-07-07 08:32:06 RepVGG-A0] (main.py 282): INFO Train: [37/300][30/78]	eta 0:01:44 lr 6.157892	time 1.4263 (2.1741)	loss 3.6714 (3.7950)	grad_norm 0.3098 (0.3445)	mem 39782MB
[2023-07-07 08:32:24 RepVGG-A0] (main.py 282): INFO Train: [37/300][40/78]	eta 0:01:19 lr 6.156250	time 3.6280 (2.0806)	loss 3.9583 (3.7884)	grad_norm 0.4558 (0.3483)	mem 39782MB
[2023-07-07 08:32:38 RepVGG-A0] (main.py 282): INFO Train: [37/300][50/78]	eta 0:00:54 lr 6.154603	time 1.1724 (1.9638)	loss 3.7901 (3.7750)	grad_norm 0.3601 (0.3421)	mem 39782MB
[2023-07-07 08:32:54 RepVGG-A0] (main.py 282): INFO Train: [37/300][60/78]	eta 0:00:34 lr 6.152950	time 1.1754 (1.8951)	loss 3.6297 (3.7680)	grad_norm 0.2920 (0.3431)	mem 39782MB
[2023-07-07 08:33:10 RepVGG-A0] (main.py 282): INFO Train: [37/300][70/78]	eta 0:00:14 lr 6.151292	time 1.7833 (1.8521)	loss 3.6078 (3.7457)	grad_norm 0.3624 (0.3397)	mem 39782MB
[2023-07-07 08:33:21 RepVGG-A0] (main.py 291): INFO EPOCH 37 training takes 0:02:22
[2023-07-07 08:33:41 RepVGG-A0] (main.py 282): INFO Train: [38/300][0/78]	eta 0:26:21 lr 6.149962	time 20.2789 (20.2789)	loss 3.9816 (3.9816)	grad_norm 0.4791 (0.4791)	mem 39782MB
[2023-07-07 08:33:55 RepVGG-A0] (main.py 282): INFO Train: [38/300][10/78]	eta 0:03:34 lr 6.148295	time 1.1953 (3.1537)	loss 3.7099 (3.8339)	grad_norm 0.3382 (0.3775)	mem 39782MB
[2023-07-07 08:34:11 RepVGG-A0] (main.py 282): INFO Train: [38/300][20/78]	eta 0:02:17 lr 6.146622	time 1.1704 (2.3771)	loss 3.6451 (3.8304)	grad_norm 0.3023 (0.3812)	mem 39782MB
[2023-07-07 08:34:27 RepVGG-A0] (main.py 282): INFO Train: [38/300][30/78]	eta 0:01:42 lr 6.144944	time 1.3999 (2.1293)	loss 3.5607 (3.7545)	grad_norm 0.3173 (0.3514)	mem 39782MB
[2023-07-07 08:34:44 RepVGG-A0] (main.py 282): INFO Train: [38/300][40/78]	eta 0:01:17 lr 6.143260	time 3.2541 (2.0438)	loss 3.7031 (3.7307)	grad_norm 0.4193 (0.3488)	mem 39782MB
[2023-07-07 08:35:00 RepVGG-A0] (main.py 282): INFO Train: [38/300][50/78]	eta 0:00:54 lr 6.141571	time 1.1732 (1.9400)	loss 3.5569 (3.7302)	grad_norm 0.2784 (0.3514)	mem 39782MB
[2023-07-07 08:35:14 RepVGG-A0] (main.py 282): INFO Train: [38/300][60/78]	eta 0:00:33 lr 6.139877	time 1.2931 (1.8576)	loss 3.6423 (3.7077)	grad_norm 0.4043 (0.3475)	mem 39782MB
[2023-07-07 08:35:29 RepVGG-A0] (main.py 282): INFO Train: [38/300][70/78]	eta 0:00:14 lr 6.138178	time 1.1948 (1.8031)	loss 3.6465 (3.6946)	grad_norm 0.3260 (0.3473)	mem 39782MB
[2023-07-07 08:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 38 training takes 0:02:19
[2023-07-07 08:36:00 RepVGG-A0] (main.py 282): INFO Train: [39/300][0/78]	eta 0:25:30 lr 6.136815	time 19.6268 (19.6268)	loss 3.5126 (3.5126)	grad_norm 0.3211 (0.3211)	mem 39782MB
[2023-07-07 08:36:16 RepVGG-A0] (main.py 282): INFO Train: [39/300][10/78]	eta 0:03:42 lr 6.135106	time 1.1712 (3.2736)	loss 3.9874 (3.7081)	grad_norm 0.5231 (0.4356)	mem 39782MB
[2023-07-07 08:36:32 RepVGG-A0] (main.py 282): INFO Train: [39/300][20/78]	eta 0:02:21 lr 6.133392	time 1.1833 (2.4403)	loss 3.5877 (3.7465)	grad_norm 0.2831 (0.4031)	mem 39782MB
[2023-07-07 08:36:47 RepVGG-A0] (main.py 282): INFO Train: [39/300][30/78]	eta 0:01:43 lr 6.131672	time 1.2146 (2.1505)	loss 3.5287 (3.6817)	grad_norm 0.3069 (0.3710)	mem 39782MB
[2023-07-07 08:37:05 RepVGG-A0] (main.py 282): INFO Train: [39/300][40/78]	eta 0:01:18 lr 6.129948	time 3.7478 (2.0633)	loss 3.6131 (3.6583)	grad_norm 0.3971 (0.3680)	mem 39782MB
[2023-07-07 08:37:20 RepVGG-A0] (main.py 282): INFO Train: [39/300][50/78]	eta 0:00:54 lr 6.128218	time 1.2056 (1.9574)	loss 3.5775 (3.6338)	grad_norm 0.3044 (0.3579)	mem 39782MB
[2023-07-07 08:37:35 RepVGG-A0] (main.py 282): INFO Train: [39/300][60/78]	eta 0:00:33 lr 6.126482	time 1.2494 (1.8844)	loss 3.6885 (3.6258)	grad_norm 0.4063 (0.3590)	mem 39782MB
[2023-07-07 08:37:50 RepVGG-A0] (main.py 282): INFO Train: [39/300][70/78]	eta 0:00:14 lr 6.124742	time 1.3774 (1.8282)	loss 5.9715 (3.7980)	grad_norm 0.7251 (0.4069)	mem 39782MB
[2023-07-07 08:38:02 RepVGG-A0] (main.py 291): INFO EPOCH 39 training takes 0:02:21
[2023-07-07 08:38:24 RepVGG-A0] (main.py 282): INFO Train: [40/300][0/78]	eta 0:28:12 lr 6.123345	time 21.7022 (21.7022)	loss 5.0014 (5.0014)	grad_norm 0.3385 (0.3385)	mem 39782MB
[2023-07-07 08:38:38 RepVGG-A0] (main.py 282): INFO Train: [40/300][10/78]	eta 0:03:44 lr 6.121595	time 1.1905 (3.2955)	loss 4.3142 (4.6989)	grad_norm 0.2171 (0.3292)	mem 39782MB
[2023-07-07 08:38:54 RepVGG-A0] (main.py 282): INFO Train: [40/300][20/78]	eta 0:02:22 lr 6.119840	time 1.2017 (2.4644)	loss 4.1799 (4.4663)	grad_norm 0.2960 (0.2941)	mem 39782MB
[2023-07-07 08:39:09 RepVGG-A0] (main.py 282): INFO Train: [40/300][30/78]	eta 0:01:43 lr 6.118080	time 1.1852 (2.1492)	loss 4.0734 (4.3338)	grad_norm 0.3498 (0.2936)	mem 39782MB
[2023-07-07 08:39:26 RepVGG-A0] (main.py 282): INFO Train: [40/300][40/78]	eta 0:01:18 lr 6.116314	time 4.4594 (2.0584)	loss 3.7895 (4.2282)	grad_norm 0.2709 (0.2886)	mem 39782MB
[2023-07-07 08:39:42 RepVGG-A0] (main.py 282): INFO Train: [40/300][50/78]	eta 0:00:54 lr 6.114543	time 1.1728 (1.9533)	loss 3.8570 (4.1491)	grad_norm 0.3507 (0.2931)	mem 39782MB
[2023-07-07 08:39:56 RepVGG-A0] (main.py 282): INFO Train: [40/300][60/78]	eta 0:00:33 lr 6.112766	time 1.2667 (1.8616)	loss 3.7614 (4.0947)	grad_norm 0.2797 (0.2978)	mem 39782MB
[2023-07-07 08:40:11 RepVGG-A0] (main.py 282): INFO Train: [40/300][70/78]	eta 0:00:14 lr 6.110985	time 1.1770 (1.8151)	loss 4.1494 (4.0550)	grad_norm 0.4053 (0.3037)	mem 39782MB
[2023-07-07 08:40:22 RepVGG-A0] (main.py 291): INFO EPOCH 40 training takes 0:02:20
[2023-07-07 08:40:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.993 (16.993)	Loss 3.4978 (3.4978)	Acc@1 30.176 (30.176)	Acc@5 54.333 (54.333)	Mem 39782MB
[2023-07-07 08:40:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 30.152 Acc@5 53.964
[2023-07-07 08:40:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 40: 30.152%
[2023-07-07 08:40:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 08:41:03 RepVGG-A0] (main.py 282): INFO Train: [41/300][0/78]	eta 0:28:13 lr 6.109556	time 21.7177 (21.7177)	loss 3.5907 (3.5907)	grad_norm 0.2828 (0.2828)	mem 39782MB
[2023-07-07 08:41:17 RepVGG-A0] (main.py 282): INFO Train: [41/300][10/78]	eta 0:03:43 lr 6.107765	time 1.1716 (3.2882)	loss 3.7078 (3.6874)	grad_norm 0.3373 (0.3208)	mem 39782MB
[2023-07-07 08:41:33 RepVGG-A0] (main.py 282): INFO Train: [41/300][20/78]	eta 0:02:23 lr 6.105968	time 1.1791 (2.4699)	loss 3.6506 (3.6684)	grad_norm 0.3243 (0.3212)	mem 39782MB
[2023-07-07 08:41:47 RepVGG-A0] (main.py 282): INFO Train: [41/300][30/78]	eta 0:01:42 lr 6.104167	time 1.1274 (2.1320)	loss 3.7188 (3.6968)	grad_norm 0.3527 (0.3398)	mem 39782MB
[2023-07-07 08:42:06 RepVGG-A0] (main.py 282): INFO Train: [41/300][40/78]	eta 0:01:18 lr 6.102360	time 4.6467 (2.0711)	loss 4.8523 (3.7944)	grad_norm 0.7509 (0.3882)	mem 39782MB
[2023-07-07 08:42:21 RepVGG-A0] (main.py 282): INFO Train: [41/300][50/78]	eta 0:00:54 lr 6.100548	time 1.1297 (1.9572)	loss 4.1717 (3.9429)	grad_norm 0.2980 (0.4007)	mem 39782MB
[2023-07-07 08:42:36 RepVGG-A0] (main.py 282): INFO Train: [41/300][60/78]	eta 0:00:33 lr 6.098731	time 1.2990 (1.8802)	loss 3.8106 (3.9353)	grad_norm 0.2564 (0.3769)	mem 39782MB
[2023-07-07 08:42:51 RepVGG-A0] (main.py 282): INFO Train: [41/300][70/78]	eta 0:00:14 lr 6.096908	time 1.1797 (1.8248)	loss 3.7020 (3.9171)	grad_norm 0.2968 (0.3665)	mem 39782MB
[2023-07-07 08:43:03 RepVGG-A0] (main.py 291): INFO EPOCH 41 training takes 0:02:21
[2023-07-07 08:43:23 RepVGG-A0] (main.py 282): INFO Train: [42/300][0/78]	eta 0:25:44 lr 6.095447	time 19.7980 (19.7980)	loss 3.5927 (3.5927)	grad_norm 0.2683 (0.2683)	mem 39782MB
[2023-07-07 08:43:39 RepVGG-A0] (main.py 282): INFO Train: [42/300][10/78]	eta 0:03:45 lr 6.093615	time 1.1710 (3.3111)	loss 3.5682 (3.6087)	grad_norm 0.3046 (0.3101)	mem 39782MB
[2023-07-07 08:43:54 RepVGG-A0] (main.py 282): INFO Train: [42/300][20/78]	eta 0:02:22 lr 6.091778	time 1.1809 (2.4533)	loss 3.7037 (3.6153)	grad_norm 0.3314 (0.3194)	mem 39782MB
[2023-07-07 08:44:09 RepVGG-A0] (main.py 282): INFO Train: [42/300][30/78]	eta 0:01:42 lr 6.089935	time 1.2377 (2.1442)	loss 3.6988 (3.6164)	grad_norm 0.3844 (0.3224)	mem 39782MB
[2023-07-07 08:44:27 RepVGG-A0] (main.py 282): INFO Train: [42/300][40/78]	eta 0:01:18 lr 6.088088	time 2.8606 (2.0634)	loss 3.6299 (3.6237)	grad_norm 0.3619 (0.3305)	mem 39782MB
[2023-07-07 08:44:43 RepVGG-A0] (main.py 282): INFO Train: [42/300][50/78]	eta 0:00:54 lr 6.086235	time 1.1751 (1.9584)	loss 3.6488 (3.6216)	grad_norm 0.3298 (0.3319)	mem 39782MB
[2023-07-07 08:44:58 RepVGG-A0] (main.py 282): INFO Train: [42/300][60/78]	eta 0:00:34 lr 6.084377	time 1.1996 (1.8931)	loss 3.5636 (3.6122)	grad_norm 0.3289 (0.3301)	mem 39782MB
[2023-07-07 08:45:13 RepVGG-A0] (main.py 282): INFO Train: [42/300][70/78]	eta 0:00:14 lr 6.082514	time 1.4078 (1.8321)	loss 5.3857 (3.7360)	grad_norm 0.6171 (0.3765)	mem 39782MB
[2023-07-07 08:45:25 RepVGG-A0] (main.py 291): INFO EPOCH 42 training takes 0:02:22
[2023-07-07 08:45:48 RepVGG-A0] (main.py 282): INFO Train: [43/300][0/78]	eta 0:30:04 lr 6.081020	time 23.1342 (23.1342)	loss 4.3807 (4.3807)	grad_norm 0.2995 (0.2995)	mem 39782MB
[2023-07-07 08:46:03 RepVGG-A0] (main.py 282): INFO Train: [43/300][10/78]	eta 0:03:55 lr 6.079148	time 1.1725 (3.4592)	loss 3.9782 (4.1413)	grad_norm 0.3257 (0.2908)	mem 39782MB
[2023-07-07 08:46:19 RepVGG-A0] (main.py 282): INFO Train: [43/300][20/78]	eta 0:02:30 lr 6.077270	time 1.1722 (2.5914)	loss 3.8262 (4.0291)	grad_norm 0.2543 (0.2742)	mem 39782MB
[2023-07-07 08:46:34 RepVGG-A0] (main.py 282): INFO Train: [43/300][30/78]	eta 0:01:46 lr 6.075387	time 1.2012 (2.2165)	loss 3.6867 (3.9554)	grad_norm 0.2847 (0.2890)	mem 39782MB
[2023-07-07 08:46:52 RepVGG-A0] (main.py 282): INFO Train: [43/300][40/78]	eta 0:01:21 lr 6.073499	time 4.2399 (2.1316)	loss 3.6268 (3.8832)	grad_norm 0.2838 (0.2848)	mem 39782MB
[2023-07-07 08:47:07 RepVGG-A0] (main.py 282): INFO Train: [43/300][50/78]	eta 0:00:55 lr 6.071606	time 1.1742 (1.9992)	loss 3.6534 (3.8387)	grad_norm 0.3253 (0.2884)	mem 39782MB
[2023-07-07 08:47:24 RepVGG-A0] (main.py 282): INFO Train: [43/300][60/78]	eta 0:00:35 lr 6.069708	time 1.3981 (1.9451)	loss 3.6075 (3.8085)	grad_norm 0.3038 (0.2949)	mem 39782MB
[2023-07-07 08:47:40 RepVGG-A0] (main.py 282): INFO Train: [43/300][70/78]	eta 0:00:15 lr 6.067804	time 1.1717 (1.8979)	loss 3.7290 (3.7831)	grad_norm 0.3611 (0.2987)	mem 39782MB
[2023-07-07 08:47:50 RepVGG-A0] (main.py 291): INFO EPOCH 43 training takes 0:02:24
[2023-07-07 08:48:14 RepVGG-A0] (main.py 282): INFO Train: [44/300][0/78]	eta 0:30:58 lr 6.066278	time 23.8314 (23.8314)	loss 3.5991 (3.5991)	grad_norm 0.2954 (0.2954)	mem 39782MB
[2023-07-07 08:48:29 RepVGG-A0] (main.py 282): INFO Train: [44/300][10/78]	eta 0:03:59 lr 6.064365	time 1.1991 (3.5241)	loss 3.8431 (3.6583)	grad_norm 0.4345 (0.3724)	mem 39782MB
[2023-07-07 08:48:42 RepVGG-A0] (main.py 282): INFO Train: [44/300][20/78]	eta 0:02:25 lr 6.062447	time 1.1731 (2.5091)	loss 3.5890 (3.6539)	grad_norm 0.2973 (0.3572)	mem 39782MB
[2023-07-07 08:48:59 RepVGG-A0] (main.py 282): INFO Train: [44/300][30/78]	eta 0:01:47 lr 6.060524	time 1.5892 (2.2367)	loss 3.5015 (3.6164)	grad_norm 0.3415 (0.3459)	mem 39782MB
[2023-07-07 08:49:17 RepVGG-A0] (main.py 282): INFO Train: [44/300][40/78]	eta 0:01:20 lr 6.058595	time 2.4915 (2.1244)	loss 3.6355 (3.6115)	grad_norm 0.3129 (0.3475)	mem 39782MB
[2023-07-07 08:49:32 RepVGG-A0] (main.py 282): INFO Train: [44/300][50/78]	eta 0:00:56 lr 6.056662	time 1.1778 (2.0106)	loss 3.6359 (3.6006)	grad_norm 0.3771 (0.3424)	mem 39782MB
[2023-07-07 08:49:47 RepVGG-A0] (main.py 282): INFO Train: [44/300][60/78]	eta 0:00:34 lr 6.054723	time 1.1771 (1.9250)	loss 6.1395 (3.8424)	grad_norm 0.5306 (0.4077)	mem 39782MB
[2023-07-07 08:50:02 RepVGG-A0] (main.py 282): INFO Train: [44/300][70/78]	eta 0:00:14 lr 6.052780	time 1.6794 (1.8665)	loss 5.0309 (4.0751)	grad_norm 0.2979 (0.4005)	mem 39782MB
[2023-07-07 08:50:14 RepVGG-A0] (main.py 291): INFO EPOCH 44 training takes 0:02:24
[2023-07-07 08:50:35 RepVGG-A0] (main.py 282): INFO Train: [45/300][0/78]	eta 0:26:39 lr 6.051221	time 20.5033 (20.5033)	loss 4.8610 (4.8610)	grad_norm 0.4593 (0.4593)	mem 39782MB
[2023-07-07 08:50:49 RepVGG-A0] (main.py 282): INFO Train: [45/300][10/78]	eta 0:03:37 lr 6.049268	time 1.1714 (3.2021)	loss 4.1741 (4.4555)	grad_norm 0.2622 (0.2962)	mem 39782MB
[2023-07-07 08:51:03 RepVGG-A0] (main.py 282): INFO Train: [45/300][20/78]	eta 0:02:16 lr 6.047310	time 1.1900 (2.3461)	loss 4.1778 (4.3344)	grad_norm 0.3535 (0.3022)	mem 39782MB
[2023-07-07 08:51:18 RepVGG-A0] (main.py 282): INFO Train: [45/300][30/78]	eta 0:01:39 lr 6.045346	time 1.2022 (2.0691)	loss 3.9759 (4.2343)	grad_norm 0.3194 (0.2951)	mem 39782MB
[2023-07-07 08:51:37 RepVGG-A0] (main.py 282): INFO Train: [45/300][40/78]	eta 0:01:16 lr 6.043378	time 4.4179 (2.0145)	loss 3.8533 (4.1601)	grad_norm 0.2758 (0.3002)	mem 39782MB
[2023-07-07 08:51:51 RepVGG-A0] (main.py 282): INFO Train: [45/300][50/78]	eta 0:00:53 lr 6.041405	time 1.1710 (1.9068)	loss 3.8738 (4.1079)	grad_norm 0.3430 (0.3055)	mem 39782MB
[2023-07-07 08:52:07 RepVGG-A0] (main.py 282): INFO Train: [45/300][60/78]	eta 0:00:33 lr 6.039426	time 1.3604 (1.8504)	loss 4.3577 (4.0837)	grad_norm 0.6054 (0.3205)	mem 39782MB
[2023-07-07 08:52:22 RepVGG-A0] (main.py 282): INFO Train: [45/300][70/78]	eta 0:00:14 lr 6.037442	time 1.5198 (1.8064)	loss 3.9905 (4.1173)	grad_norm 0.2760 (0.3360)	mem 39782MB
[2023-07-07 08:52:34 RepVGG-A0] (main.py 291): INFO EPOCH 45 training takes 0:02:19
[2023-07-07 08:52:55 RepVGG-A0] (main.py 282): INFO Train: [46/300][0/78]	eta 0:27:07 lr 6.035851	time 20.8603 (20.8603)	loss 3.8094 (3.8094)	grad_norm 0.2596 (0.2596)	mem 39782MB
[2023-07-07 08:53:10 RepVGG-A0] (main.py 282): INFO Train: [46/300][10/78]	eta 0:03:44 lr 6.033858	time 1.1727 (3.3088)	loss 3.7379 (3.7340)	grad_norm 0.3166 (0.2873)	mem 39782MB
[2023-07-07 08:53:26 RepVGG-A0] (main.py 282): INFO Train: [46/300][20/78]	eta 0:02:22 lr 6.031860	time 1.3036 (2.4536)	loss 3.7179 (3.7400)	grad_norm 0.2918 (0.3043)	mem 39782MB
[2023-07-07 08:53:42 RepVGG-A0] (main.py 282): INFO Train: [46/300][30/78]	eta 0:01:44 lr 6.029857	time 1.3768 (2.1871)	loss 3.7944 (3.7342)	grad_norm 0.3898 (0.3162)	mem 39782MB
[2023-07-07 08:54:00 RepVGG-A0] (main.py 282): INFO Train: [46/300][40/78]	eta 0:01:19 lr 6.027849	time 3.7382 (2.0856)	loss 3.7546 (3.7371)	grad_norm 0.3323 (0.3213)	mem 39782MB
[2023-07-07 08:54:14 RepVGG-A0] (main.py 282): INFO Train: [46/300][50/78]	eta 0:00:55 lr 6.025836	time 1.1729 (1.9644)	loss 3.6914 (3.7243)	grad_norm 0.3697 (0.3247)	mem 39782MB
[2023-07-07 08:54:29 RepVGG-A0] (main.py 282): INFO Train: [46/300][60/78]	eta 0:00:33 lr 6.023817	time 1.3044 (1.8803)	loss 3.6916 (3.7328)	grad_norm 0.3131 (0.3347)	mem 39782MB
[2023-07-07 08:54:45 RepVGG-A0] (main.py 282): INFO Train: [46/300][70/78]	eta 0:00:14 lr 6.021794	time 1.1265 (1.8412)	loss 3.8625 (3.7296)	grad_norm 0.4250 (0.3374)	mem 39782MB
[2023-07-07 08:54:56 RepVGG-A0] (main.py 291): INFO EPOCH 46 training takes 0:02:22
[2023-07-07 08:55:19 RepVGG-A0] (main.py 282): INFO Train: [47/300][0/78]	eta 0:28:50 lr 6.020171	time 22.1877 (22.1877)	loss 3.5438 (3.5438)	grad_norm 0.2796 (0.2796)	mem 39782MB
[2023-07-07 08:55:32 RepVGG-A0] (main.py 282): INFO Train: [47/300][10/78]	eta 0:03:39 lr 6.018138	time 1.1886 (3.2313)	loss 3.6725 (3.6163)	grad_norm 0.3517 (0.3406)	mem 39782MB
[2023-07-07 08:55:48 RepVGG-A0] (main.py 282): INFO Train: [47/300][20/78]	eta 0:02:22 lr 6.016101	time 1.1822 (2.4503)	loss 3.6315 (3.6246)	grad_norm 0.3655 (0.3468)	mem 39782MB
[2023-07-07 08:56:02 RepVGG-A0] (main.py 282): INFO Train: [47/300][30/78]	eta 0:01:41 lr 6.014058	time 1.4717 (2.1209)	loss 3.9125 (3.6365)	grad_norm 0.5037 (0.3573)	mem 39782MB
[2023-07-07 08:56:20 RepVGG-A0] (main.py 282): INFO Train: [47/300][40/78]	eta 0:01:17 lr 6.012010	time 3.8288 (2.0352)	loss 3.7533 (3.7254)	grad_norm 0.2925 (0.3810)	mem 39782MB
[2023-07-07 08:56:34 RepVGG-A0] (main.py 282): INFO Train: [47/300][50/78]	eta 0:00:53 lr 6.009957	time 1.1715 (1.9170)	loss 3.7569 (3.7071)	grad_norm 0.4113 (0.3637)	mem 39782MB
[2023-07-07 08:56:50 RepVGG-A0] (main.py 282): INFO Train: [47/300][60/78]	eta 0:00:33 lr 6.007899	time 1.4513 (1.8557)	loss 3.4766 (3.7003)	grad_norm 0.2575 (0.3587)	mem 39782MB
[2023-07-07 08:57:04 RepVGG-A0] (main.py 282): INFO Train: [47/300][70/78]	eta 0:00:14 lr 6.005836	time 1.3447 (1.8020)	loss 3.6527 (3.6850)	grad_norm 0.3760 (0.3543)	mem 39782MB
[2023-07-07 08:57:16 RepVGG-A0] (main.py 291): INFO EPOCH 47 training takes 0:02:19
[2023-07-07 08:57:38 RepVGG-A0] (main.py 282): INFO Train: [48/300][0/78]	eta 0:27:27 lr 6.004181	time 21.1192 (21.1192)	loss 3.5020 (3.5020)	grad_norm 0.3321 (0.3321)	mem 39782MB
[2023-07-07 08:57:52 RepVGG-A0] (main.py 282): INFO Train: [48/300][10/78]	eta 0:03:41 lr 6.002109	time 1.1717 (3.2534)	loss 3.5887 (3.5752)	grad_norm 0.3679 (0.3627)	mem 39782MB
[2023-07-07 08:58:07 RepVGG-A0] (main.py 282): INFO Train: [48/300][20/78]	eta 0:02:20 lr 6.000032	time 1.1747 (2.4236)	loss 3.5707 (3.5698)	grad_norm 0.3330 (0.3525)	mem 39782MB
[2023-07-07 08:58:22 RepVGG-A0] (main.py 282): INFO Train: [48/300][30/78]	eta 0:01:42 lr 5.997950	time 1.2990 (2.1251)	loss 3.5483 (3.5582)	grad_norm 0.3271 (0.3473)	mem 39782MB
[2023-07-07 08:58:41 RepVGG-A0] (main.py 282): INFO Train: [48/300][40/78]	eta 0:01:18 lr 5.995862	time 4.1592 (2.0703)	loss 6.1300 (3.6979)	grad_norm 1.0851 (0.4075)	mem 39782MB
[2023-07-07 08:58:55 RepVGG-A0] (main.py 282): INFO Train: [48/300][50/78]	eta 0:00:54 lr 5.993770	time 1.1720 (1.9385)	loss 5.4235 (4.1411)	grad_norm 0.3712 (0.4201)	mem 39782MB
[2023-07-07 08:59:11 RepVGG-A0] (main.py 282): INFO Train: [48/300][60/78]	eta 0:00:33 lr 5.991672	time 1.2435 (1.8770)	loss 4.6332 (4.2817)	grad_norm 0.2745 (0.4012)	mem 39782MB
[2023-07-07 08:59:26 RepVGG-A0] (main.py 282): INFO Train: [48/300][70/78]	eta 0:00:14 lr 5.989570	time 1.2254 (1.8227)	loss 4.3598 (4.3095)	grad_norm 0.2977 (0.3865)	mem 39782MB
[2023-07-07 08:59:37 RepVGG-A0] (main.py 291): INFO EPOCH 48 training takes 0:02:20
[2023-07-07 08:59:58 RepVGG-A0] (main.py 282): INFO Train: [49/300][0/78]	eta 0:27:25 lr 5.987884	time 21.0923 (21.0923)	loss 4.1017 (4.1017)	grad_norm 0.3038 (0.3038)	mem 39782MB
[2023-07-07 09:00:13 RepVGG-A0] (main.py 282): INFO Train: [49/300][10/78]	eta 0:03:41 lr 5.985773	time 1.1726 (3.2586)	loss 4.1257 (4.0557)	grad_norm 0.4388 (0.3053)	mem 39782MB
[2023-07-07 09:00:28 RepVGG-A0] (main.py 282): INFO Train: [49/300][20/78]	eta 0:02:21 lr 5.983656	time 1.2050 (2.4367)	loss 3.9062 (4.0873)	grad_norm 0.2403 (0.3206)	mem 39782MB
[2023-07-07 09:00:44 RepVGG-A0] (main.py 282): INFO Train: [49/300][30/78]	eta 0:01:43 lr 5.981535	time 1.5742 (2.1619)	loss 3.9032 (4.0181)	grad_norm 0.3422 (0.3050)	mem 39782MB
[2023-07-07 09:01:02 RepVGG-A0] (main.py 282): INFO Train: [49/300][40/78]	eta 0:01:19 lr 5.979408	time 2.7605 (2.0793)	loss 3.8505 (3.9705)	grad_norm 0.3663 (0.3073)	mem 39782MB
[2023-07-07 09:01:17 RepVGG-A0] (main.py 282): INFO Train: [49/300][50/78]	eta 0:00:54 lr 5.977276	time 1.3710 (1.9640)	loss 3.7600 (3.9417)	grad_norm 0.2899 (0.3088)	mem 39782MB
[2023-07-07 09:01:32 RepVGG-A0] (main.py 282): INFO Train: [49/300][60/78]	eta 0:00:34 lr 5.975140	time 1.2961 (1.8891)	loss 3.9329 (3.9236)	grad_norm 0.4693 (0.3180)	mem 39782MB
[2023-07-07 09:01:47 RepVGG-A0] (main.py 282): INFO Train: [49/300][70/78]	eta 0:00:14 lr 5.972998	time 1.1450 (1.8229)	loss 3.9689 (3.9613)	grad_norm 0.3394 (0.3382)	mem 39782MB
[2023-07-07 09:01:59 RepVGG-A0] (main.py 291): INFO EPOCH 49 training takes 0:02:21
[2023-07-07 09:02:20 RepVGG-A0] (main.py 282): INFO Train: [50/300][0/78]	eta 0:26:58 lr 5.971281	time 20.7437 (20.7437)	loss 3.7603 (3.7603)	grad_norm 0.2950 (0.2950)	mem 39782MB
[2023-07-07 09:02:35 RepVGG-A0] (main.py 282): INFO Train: [50/300][10/78]	eta 0:03:42 lr 5.969131	time 1.1924 (3.2750)	loss 3.6047 (3.7140)	grad_norm 0.2737 (0.2964)	mem 39782MB
[2023-07-07 09:02:50 RepVGG-A0] (main.py 282): INFO Train: [50/300][20/78]	eta 0:02:21 lr 5.966975	time 1.1961 (2.4352)	loss 3.8437 (3.7134)	grad_norm 0.3660 (0.3141)	mem 39782MB
[2023-07-07 09:03:06 RepVGG-A0] (main.py 282): INFO Train: [50/300][30/78]	eta 0:01:43 lr 5.964815	time 1.2154 (2.1627)	loss 3.6754 (3.7142)	grad_norm 0.3405 (0.3242)	mem 39782MB
[2023-07-07 09:03:23 RepVGG-A0] (main.py 282): INFO Train: [50/300][40/78]	eta 0:01:18 lr 5.962649	time 2.6989 (2.0545)	loss 3.5562 (3.6892)	grad_norm 0.3403 (0.3205)	mem 39782MB
[2023-07-07 09:03:37 RepVGG-A0] (main.py 282): INFO Train: [50/300][50/78]	eta 0:00:53 lr 5.960478	time 1.1910 (1.9221)	loss 3.7033 (3.7162)	grad_norm 0.3356 (0.3412)	mem 39782MB
[2023-07-07 09:03:53 RepVGG-A0] (main.py 282): INFO Train: [50/300][60/78]	eta 0:00:33 lr 5.958303	time 1.1978 (1.8679)	loss 3.6596 (3.7056)	grad_norm 0.3280 (0.3350)	mem 39782MB
[2023-07-07 09:04:07 RepVGG-A0] (main.py 282): INFO Train: [50/300][70/78]	eta 0:00:14 lr 5.956122	time 1.4042 (1.8056)	loss 3.6130 (3.6954)	grad_norm 0.3263 (0.3350)	mem 39782MB
[2023-07-07 09:04:19 RepVGG-A0] (main.py 291): INFO EPOCH 50 training takes 0:02:20
[2023-07-07 09:04:40 RepVGG-A0] (main.py 282): INFO Train: [51/300][0/78]	eta 0:26:51 lr 5.954374	time 20.6564 (20.6564)	loss 3.6402 (3.6402)	grad_norm 0.3777 (0.3777)	mem 39782MB
[2023-07-07 09:04:54 RepVGG-A0] (main.py 282): INFO Train: [51/300][10/78]	eta 0:03:36 lr 5.952185	time 1.1723 (3.1903)	loss 3.5712 (3.6619)	grad_norm 0.3116 (0.3741)	mem 39782MB
[2023-07-07 09:05:09 RepVGG-A0] (main.py 282): INFO Train: [51/300][20/78]	eta 0:02:18 lr 5.949991	time 1.1758 (2.3943)	loss 3.6003 (3.6436)	grad_norm 0.3179 (0.3613)	mem 39782MB
[2023-07-07 09:05:25 RepVGG-A0] (main.py 282): INFO Train: [51/300][30/78]	eta 0:01:41 lr 5.947791	time 1.4235 (2.1193)	loss 3.5820 (3.6232)	grad_norm 0.3729 (0.3550)	mem 39782MB
[2023-07-07 09:05:43 RepVGG-A0] (main.py 282): INFO Train: [51/300][40/78]	eta 0:01:17 lr 5.945587	time 3.9000 (2.0390)	loss 3.6078 (3.6259)	grad_norm 0.3457 (0.3568)	mem 39782MB
[2023-07-07 09:05:57 RepVGG-A0] (main.py 282): INFO Train: [51/300][50/78]	eta 0:00:53 lr 5.943378	time 1.1709 (1.9280)	loss 3.6343 (3.6209)	grad_norm 0.3412 (0.3562)	mem 39782MB
[2023-07-07 09:06:12 RepVGG-A0] (main.py 282): INFO Train: [51/300][60/78]	eta 0:00:33 lr 5.941164	time 1.3721 (1.8603)	loss 6.0714 (3.8126)	grad_norm 0.5566 (0.4047)	mem 39782MB
[2023-07-07 09:06:27 RepVGG-A0] (main.py 282): INFO Train: [51/300][70/78]	eta 0:00:14 lr 5.938944	time 1.2585 (1.8028)	loss 5.2144 (4.0857)	grad_norm 0.2728 (0.4118)	mem 39782MB
[2023-07-07 09:06:39 RepVGG-A0] (main.py 291): INFO EPOCH 51 training takes 0:02:19
[2023-07-07 09:07:00 RepVGG-A0] (main.py 282): INFO Train: [52/300][0/78]	eta 0:27:27 lr 5.937166	time 21.1245 (21.1245)	loss 4.7326 (4.7326)	grad_norm 0.3029 (0.3029)	mem 39782MB
[2023-07-07 09:07:15 RepVGG-A0] (main.py 282): INFO Train: [52/300][10/78]	eta 0:03:42 lr 5.934938	time 1.1719 (3.2694)	loss 4.3577 (4.5059)	grad_norm 0.3327 (0.2876)	mem 39782MB
[2023-07-07 09:07:29 RepVGG-A0] (main.py 282): INFO Train: [52/300][20/78]	eta 0:02:18 lr 5.932705	time 1.1744 (2.3924)	loss 4.2749 (4.3829)	grad_norm 0.3075 (0.2900)	mem 39782MB
[2023-07-07 09:07:44 RepVGG-A0] (main.py 282): INFO Train: [52/300][30/78]	eta 0:01:41 lr 5.930467	time 1.2243 (2.1093)	loss 4.0408 (4.2986)	grad_norm 0.2978 (0.2967)	mem 39782MB
[2023-07-07 09:08:03 RepVGG-A0] (main.py 282): INFO Train: [52/300][40/78]	eta 0:01:17 lr 5.928224	time 3.7026 (2.0458)	loss 3.9717 (4.2211)	grad_norm 0.2919 (0.2976)	mem 39782MB
[2023-07-07 09:08:18 RepVGG-A0] (main.py 282): INFO Train: [52/300][50/78]	eta 0:00:54 lr 5.925976	time 1.1746 (1.9444)	loss 3.9568 (4.1588)	grad_norm 0.3220 (0.2993)	mem 39782MB
[2023-07-07 09:08:33 RepVGG-A0] (main.py 282): INFO Train: [52/300][60/78]	eta 0:00:33 lr 5.923724	time 1.2385 (1.8758)	loss 3.9490 (4.1203)	grad_norm 0.3542 (0.3089)	mem 39782MB
[2023-07-07 09:08:48 RepVGG-A0] (main.py 282): INFO Train: [52/300][70/78]	eta 0:00:14 lr 5.921466	time 1.3070 (1.8184)	loss 4.4263 (4.0906)	grad_norm 0.7432 (0.3164)	mem 39782MB
[2023-07-07 09:09:01 RepVGG-A0] (main.py 291): INFO EPOCH 52 training takes 0:02:21
[2023-07-07 09:09:21 RepVGG-A0] (main.py 282): INFO Train: [53/300][0/78]	eta 0:26:02 lr 5.919657	time 20.0266 (20.0266)	loss 5.1604 (5.1604)	grad_norm 0.4777 (0.4777)	mem 39782MB
[2023-07-07 09:09:36 RepVGG-A0] (main.py 282): INFO Train: [53/300][10/78]	eta 0:03:39 lr 5.917390	time 1.1707 (3.2307)	loss 4.1988 (4.4932)	grad_norm 0.3043 (0.3298)	mem 39782MB
[2023-07-07 09:09:50 RepVGG-A0] (main.py 282): INFO Train: [53/300][20/78]	eta 0:02:17 lr 5.915119	time 1.2502 (2.3688)	loss 3.9929 (4.2871)	grad_norm 0.2308 (0.3019)	mem 39782MB
[2023-07-07 09:10:06 RepVGG-A0] (main.py 282): INFO Train: [53/300][30/78]	eta 0:01:40 lr 5.912843	time 1.2203 (2.0918)	loss 3.8896 (4.1604)	grad_norm 0.3032 (0.2942)	mem 39782MB
[2023-07-07 09:10:24 RepVGG-A0] (main.py 282): INFO Train: [53/300][40/78]	eta 0:01:16 lr 5.910562	time 3.7817 (2.0213)	loss 3.7682 (4.0718)	grad_norm 0.2973 (0.2907)	mem 39782MB
[2023-07-07 09:10:39 RepVGG-A0] (main.py 282): INFO Train: [53/300][50/78]	eta 0:00:53 lr 5.908276	time 1.1555 (1.9226)	loss 3.7771 (4.0159)	grad_norm 0.3332 (0.2959)	mem 39782MB
[2023-07-07 09:10:54 RepVGG-A0] (main.py 282): INFO Train: [53/300][60/78]	eta 0:00:33 lr 5.905985	time 1.3889 (1.8526)	loss 3.7342 (3.9854)	grad_norm 0.2992 (0.3058)	mem 39782MB
[2023-07-07 09:11:08 RepVGG-A0] (main.py 282): INFO Train: [53/300][70/78]	eta 0:00:14 lr 5.903689	time 1.2093 (1.7970)	loss 3.6458 (3.9461)	grad_norm 0.3184 (0.3045)	mem 39782MB
[2023-07-07 09:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 53 training takes 0:02:19
[2023-07-07 09:11:41 RepVGG-A0] (main.py 282): INFO Train: [54/300][0/78]	eta 0:27:06 lr 5.901849	time 20.8543 (20.8543)	loss 3.8649 (3.8649)	grad_norm 0.4143 (0.4143)	mem 39782MB
[2023-07-07 09:11:57 RepVGG-A0] (main.py 282): INFO Train: [54/300][10/78]	eta 0:03:47 lr 5.899545	time 1.1723 (3.3466)	loss 3.6953 (3.9435)	grad_norm 0.2811 (0.4191)	mem 39782MB
[2023-07-07 09:12:12 RepVGG-A0] (main.py 282): INFO Train: [54/300][20/78]	eta 0:02:23 lr 5.897236	time 1.1865 (2.4669)	loss 3.7716 (3.8219)	grad_norm 0.3360 (0.3612)	mem 39782MB
[2023-07-07 09:12:28 RepVGG-A0] (main.py 282): INFO Train: [54/300][30/78]	eta 0:01:44 lr 5.894921	time 1.1915 (2.1833)	loss 3.7512 (3.7879)	grad_norm 0.3742 (0.3560)	mem 39782MB
[2023-07-07 09:12:45 RepVGG-A0] (main.py 282): INFO Train: [54/300][40/78]	eta 0:01:19 lr 5.892602	time 3.0902 (2.0807)	loss 3.6365 (3.7569)	grad_norm 0.3055 (0.3458)	mem 39782MB
[2023-07-07 09:13:00 RepVGG-A0] (main.py 282): INFO Train: [54/300][50/78]	eta 0:00:54 lr 5.890278	time 1.1728 (1.9633)	loss 3.7064 (3.7436)	grad_norm 0.3613 (0.3470)	mem 39782MB
[2023-07-07 09:13:16 RepVGG-A0] (main.py 282): INFO Train: [54/300][60/78]	eta 0:00:34 lr 5.887950	time 1.3388 (1.8974)	loss 4.0743 (3.7375)	grad_norm 0.5986 (0.3528)	mem 39782MB
[2023-07-07 09:13:31 RepVGG-A0] (main.py 282): INFO Train: [54/300][70/78]	eta 0:00:14 lr 5.885616	time 1.2086 (1.8413)	loss 3.8294 (3.7866)	grad_norm 0.2966 (0.3676)	mem 39782MB
[2023-07-07 09:13:42 RepVGG-A0] (main.py 291): INFO EPOCH 54 training takes 0:02:22
[2023-07-07 09:14:04 RepVGG-A0] (main.py 282): INFO Train: [55/300][0/78]	eta 0:28:59 lr 5.883746	time 22.2978 (22.2978)	loss 3.6806 (3.6806)	grad_norm 0.3142 (0.3142)	mem 39782MB
[2023-07-07 09:14:18 RepVGG-A0] (main.py 282): INFO Train: [55/300][10/78]	eta 0:03:44 lr 5.881404	time 1.1699 (3.2995)	loss 3.5923 (3.6465)	grad_norm 0.2664 (0.3141)	mem 39782MB
[2023-07-07 09:14:32 RepVGG-A0] (main.py 282): INFO Train: [55/300][20/78]	eta 0:02:18 lr 5.879056	time 1.1912 (2.3935)	loss 3.5996 (3.6226)	grad_norm 0.3742 (0.3193)	mem 39782MB
[2023-07-07 09:14:48 RepVGG-A0] (main.py 282): INFO Train: [55/300][30/78]	eta 0:01:41 lr 5.876704	time 1.4852 (2.1161)	loss 3.6328 (3.6214)	grad_norm 0.3462 (0.3244)	mem 39782MB
[2023-07-07 09:15:05 RepVGG-A0] (main.py 282): INFO Train: [55/300][40/78]	eta 0:01:16 lr 5.874348	time 3.8874 (2.0227)	loss 3.7462 (3.6163)	grad_norm 0.4316 (0.3270)	mem 39782MB
[2023-07-07 09:15:22 RepVGG-A0] (main.py 282): INFO Train: [55/300][50/78]	eta 0:00:54 lr 5.871986	time 1.1722 (1.9529)	loss 3.5848 (3.6303)	grad_norm 0.3439 (0.3371)	mem 39782MB
[2023-07-07 09:15:37 RepVGG-A0] (main.py 282): INFO Train: [55/300][60/78]	eta 0:00:33 lr 5.869620	time 1.3428 (1.8833)	loss 3.5665 (3.6315)	grad_norm 0.3490 (0.3377)	mem 39782MB
[2023-07-07 09:15:52 RepVGG-A0] (main.py 282): INFO Train: [55/300][70/78]	eta 0:00:14 lr 5.867248	time 1.3620 (1.8279)	loss 4.2371 (3.6774)	grad_norm 0.5416 (0.3622)	mem 39782MB
[2023-07-07 09:16:03 RepVGG-A0] (main.py 291): INFO EPOCH 55 training takes 0:02:20
[2023-07-07 09:16:24 RepVGG-A0] (main.py 282): INFO Train: [56/300][0/78]	eta 0:27:31 lr 5.865348	time 21.1679 (21.1679)	loss 3.6035 (3.6035)	grad_norm 0.2869 (0.2869)	mem 39782MB
[2023-07-07 09:16:40 RepVGG-A0] (main.py 282): INFO Train: [56/300][10/78]	eta 0:03:48 lr 5.862968	time 1.1700 (3.3574)	loss 3.5429 (3.5819)	grad_norm 0.2982 (0.2909)	mem 39782MB
[2023-07-07 09:16:54 RepVGG-A0] (main.py 282): INFO Train: [56/300][20/78]	eta 0:02:21 lr 5.860583	time 1.1287 (2.4405)	loss 3.5355 (3.5645)	grad_norm 0.3235 (0.3030)	mem 39782MB
[2023-07-07 09:17:10 RepVGG-A0] (main.py 282): INFO Train: [56/300][30/78]	eta 0:01:43 lr 5.858194	time 1.2048 (2.1474)	loss 3.5492 (3.5520)	grad_norm 0.3312 (0.3073)	mem 39782MB
[2023-07-07 09:17:27 RepVGG-A0] (main.py 282): INFO Train: [56/300][40/78]	eta 0:01:18 lr 5.855800	time 3.0971 (2.0542)	loss 3.5775 (3.5468)	grad_norm 0.3846 (0.3146)	mem 39782MB
[2023-07-07 09:17:43 RepVGG-A0] (main.py 282): INFO Train: [56/300][50/78]	eta 0:00:54 lr 5.853401	time 1.1729 (1.9544)	loss 4.3245 (3.6305)	grad_norm 0.6707 (0.3569)	mem 39782MB
[2023-07-07 09:17:59 RepVGG-A0] (main.py 282): INFO Train: [56/300][60/78]	eta 0:00:34 lr 5.850997	time 1.4340 (1.8977)	loss 3.8621 (3.7213)	grad_norm 0.2702 (0.3711)	mem 39782MB
[2023-07-07 09:18:14 RepVGG-A0] (main.py 282): INFO Train: [56/300][70/78]	eta 0:00:14 lr 5.848588	time 1.2302 (1.8398)	loss 3.6242 (3.7150)	grad_norm 0.3020 (0.3574)	mem 39782MB
[2023-07-07 09:18:25 RepVGG-A0] (main.py 291): INFO EPOCH 56 training takes 0:02:21
[2023-07-07 09:18:46 RepVGG-A0] (main.py 282): INFO Train: [57/300][0/78]	eta 0:27:53 lr 5.846658	time 21.4526 (21.4526)	loss 3.4932 (3.4932)	grad_norm 0.2411 (0.2411)	mem 39782MB
[2023-07-07 09:19:00 RepVGG-A0] (main.py 282): INFO Train: [57/300][10/78]	eta 0:03:36 lr 5.844241	time 1.1724 (3.1864)	loss 3.5202 (3.4984)	grad_norm 0.3036 (0.2740)	mem 39782MB
[2023-07-07 09:19:15 RepVGG-A0] (main.py 282): INFO Train: [57/300][20/78]	eta 0:02:18 lr 5.841819	time 1.1919 (2.3891)	loss 3.6156 (3.5258)	grad_norm 0.3639 (0.3037)	mem 39782MB
[2023-07-07 09:19:31 RepVGG-A0] (main.py 282): INFO Train: [57/300][30/78]	eta 0:01:42 lr 5.839392	time 1.4374 (2.1454)	loss 3.5745 (3.5363)	grad_norm 0.3151 (0.3156)	mem 39782MB
[2023-07-07 09:19:48 RepVGG-A0] (main.py 282): INFO Train: [57/300][40/78]	eta 0:01:17 lr 5.836960	time 2.1795 (2.0350)	loss 3.5066 (3.5327)	grad_norm 0.3532 (0.3159)	mem 39782MB
[2023-07-07 09:20:03 RepVGG-A0] (main.py 282): INFO Train: [57/300][50/78]	eta 0:00:54 lr 5.834524	time 1.1712 (1.9335)	loss 3.5009 (3.5330)	grad_norm 0.3171 (0.3222)	mem 39782MB
[2023-07-07 09:20:19 RepVGG-A0] (main.py 282): INFO Train: [57/300][60/78]	eta 0:00:33 lr 5.832083	time 1.2716 (1.8688)	loss 3.7901 (3.5440)	grad_norm 0.4287 (0.3322)	mem 39782MB
[2023-07-07 09:20:35 RepVGG-A0] (main.py 282): INFO Train: [57/300][70/78]	eta 0:00:14 lr 5.829637	time 1.5635 (1.8353)	loss 3.5431 (3.5529)	grad_norm 0.3394 (0.3365)	mem 39782MB
[2023-07-07 09:20:46 RepVGG-A0] (main.py 291): INFO EPOCH 57 training takes 0:02:21
[2023-07-07 09:21:07 RepVGG-A0] (main.py 282): INFO Train: [58/300][0/78]	eta 0:28:08 lr 5.827677	time 21.6509 (21.6509)	loss 3.4176 (3.4176)	grad_norm 0.3257 (0.3257)	mem 39782MB
[2023-07-07 09:21:22 RepVGG-A0] (main.py 282): INFO Train: [58/300][10/78]	eta 0:03:41 lr 5.825223	time 1.2017 (3.2646)	loss 3.6532 (3.4856)	grad_norm 0.4379 (0.3458)	mem 39782MB
[2023-07-07 09:21:37 RepVGG-A0] (main.py 282): INFO Train: [58/300][20/78]	eta 0:02:21 lr 5.822764	time 1.1728 (2.4376)	loss 5.7782 (4.0110)	grad_norm 0.8552 (0.5332)	mem 39782MB
[2023-07-07 09:21:51 RepVGG-A0] (main.py 282): INFO Train: [58/300][30/78]	eta 0:01:41 lr 5.820300	time 1.6185 (2.1243)	loss 4.2502 (4.2697)	grad_norm 0.2507 (0.4912)	mem 39782MB
[2023-07-07 09:22:09 RepVGG-A0] (main.py 282): INFO Train: [58/300][40/78]	eta 0:01:17 lr 5.817832	time 4.0946 (2.0419)	loss 3.9174 (4.2283)	grad_norm 0.2199 (0.4393)	mem 39782MB
[2023-07-07 09:22:24 RepVGG-A0] (main.py 282): INFO Train: [58/300][50/78]	eta 0:00:54 lr 5.815359	time 1.1759 (1.9354)	loss 3.7895 (4.1565)	grad_norm 0.2943 (0.4105)	mem 39782MB
[2023-07-07 09:22:40 RepVGG-A0] (main.py 282): INFO Train: [58/300][60/78]	eta 0:00:33 lr 5.812881	time 1.1276 (1.8781)	loss 3.7163 (4.0856)	grad_norm 0.2548 (0.3863)	mem 39782MB
[2023-07-07 09:22:56 RepVGG-A0] (main.py 282): INFO Train: [58/300][70/78]	eta 0:00:14 lr 5.810398	time 1.4698 (1.8321)	loss 3.5643 (4.0245)	grad_norm 0.2529 (0.3735)	mem 39782MB
[2023-07-07 09:23:07 RepVGG-A0] (main.py 291): INFO EPOCH 58 training takes 0:02:21
[2023-07-07 09:23:27 RepVGG-A0] (main.py 282): INFO Train: [59/300][0/78]	eta 0:26:33 lr 5.808409	time 20.4232 (20.4232)	loss 3.6803 (3.6803)	grad_norm 0.4193 (0.4193)	mem 39782MB
[2023-07-07 09:23:43 RepVGG-A0] (main.py 282): INFO Train: [59/300][10/78]	eta 0:03:40 lr 5.805918	time 1.1906 (3.2424)	loss 3.4516 (3.5649)	grad_norm 0.2791 (0.3217)	mem 39782MB
[2023-07-07 09:23:58 RepVGG-A0] (main.py 282): INFO Train: [59/300][20/78]	eta 0:02:21 lr 5.803422	time 1.1734 (2.4346)	loss 3.5565 (3.5481)	grad_norm 0.3507 (0.3272)	mem 39782MB
[2023-07-07 09:24:14 RepVGG-A0] (main.py 282): INFO Train: [59/300][30/78]	eta 0:01:43 lr 5.800922	time 1.6040 (2.1649)	loss 3.5043 (3.5699)	grad_norm 0.2843 (0.3336)	mem 39782MB
[2023-07-07 09:24:32 RepVGG-A0] (main.py 282): INFO Train: [59/300][40/78]	eta 0:01:19 lr 5.798417	time 3.1283 (2.0873)	loss 3.4930 (3.5645)	grad_norm 0.3075 (0.3316)	mem 39782MB
[2023-07-07 09:24:47 RepVGG-A0] (main.py 282): INFO Train: [59/300][50/78]	eta 0:00:55 lr 5.795907	time 1.1753 (1.9712)	loss 3.6136 (3.5596)	grad_norm 0.3520 (0.3340)	mem 39782MB
[2023-07-07 09:25:02 RepVGG-A0] (main.py 282): INFO Train: [59/300][60/78]	eta 0:00:34 lr 5.793392	time 1.2414 (1.8937)	loss 3.6608 (3.5676)	grad_norm 0.3667 (0.3382)	mem 39782MB
[2023-07-07 09:25:18 RepVGG-A0] (main.py 282): INFO Train: [59/300][70/78]	eta 0:00:14 lr 5.790873	time 1.4880 (1.8525)	loss 3.4359 (3.5651)	grad_norm 0.2880 (0.3382)	mem 39782MB
[2023-07-07 09:25:29 RepVGG-A0] (main.py 291): INFO EPOCH 59 training takes 0:02:22
[2023-07-07 09:25:51 RepVGG-A0] (main.py 282): INFO Train: [60/300][0/78]	eta 0:28:31 lr 5.788854	time 21.9398 (21.9398)	loss 3.5073 (3.5073)	grad_norm 0.3800 (0.3800)	mem 39782MB
[2023-07-07 09:26:05 RepVGG-A0] (main.py 282): INFO Train: [60/300][10/78]	eta 0:03:41 lr 5.786327	time 1.1727 (3.2581)	loss 3.8586 (3.7586)	grad_norm 0.4371 (0.4711)	mem 39782MB
[2023-07-07 09:26:20 RepVGG-A0] (main.py 282): INFO Train: [60/300][20/78]	eta 0:02:19 lr 5.783795	time 1.1767 (2.4093)	loss 3.5113 (3.6625)	grad_norm 0.3213 (0.3947)	mem 39782MB
[2023-07-07 09:26:35 RepVGG-A0] (main.py 282): INFO Train: [60/300][30/78]	eta 0:01:41 lr 5.781258	time 1.1858 (2.1124)	loss 3.4418 (3.6032)	grad_norm 0.2783 (0.3676)	mem 39782MB
[2023-07-07 09:26:54 RepVGG-A0] (main.py 282): INFO Train: [60/300][40/78]	eta 0:01:18 lr 5.778716	time 4.8065 (2.0582)	loss 3.5456 (3.5789)	grad_norm 0.3812 (0.3604)	mem 39782MB
[2023-07-07 09:27:09 RepVGG-A0] (main.py 282): INFO Train: [60/300][50/78]	eta 0:00:54 lr 5.776170	time 1.3138 (1.9492)	loss 3.5017 (3.5892)	grad_norm 0.3176 (0.3683)	mem 39782MB
[2023-07-07 09:27:23 RepVGG-A0] (main.py 282): INFO Train: [60/300][60/78]	eta 0:00:33 lr 5.773619	time 1.1750 (1.8627)	loss 3.4540 (3.5688)	grad_norm 0.3014 (0.3571)	mem 39782MB
[2023-07-07 09:27:38 RepVGG-A0] (main.py 282): INFO Train: [60/300][70/78]	eta 0:00:14 lr 5.771064	time 1.3450 (1.8168)	loss 4.6654 (3.6192)	grad_norm 0.9074 (0.3854)	mem 39782MB
[2023-07-07 09:27:50 RepVGG-A0] (main.py 291): INFO EPOCH 60 training takes 0:02:21
[2023-07-07 09:28:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.416 (17.416)	Loss 9.5352 (9.5352)	Acc@1 1.117 (1.117)	Acc@5 4.065 (4.065)	Mem 39782MB
[2023-07-07 09:28:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 1.154 Acc@5 3.944
[2023-07-07 09:28:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 60: 1.154%
[2023-07-07 09:28:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 09:28:31 RepVGG-A0] (main.py 282): INFO Train: [61/300][0/78]	eta 0:28:33 lr 5.769016	time 21.9634 (21.9634)	loss 4.4128 (4.4128)	grad_norm 0.3837 (0.3837)	mem 39782MB
[2023-07-07 09:28:48 RepVGG-A0] (main.py 282): INFO Train: [61/300][10/78]	eta 0:04:00 lr 5.766452	time 1.1780 (3.5339)	loss 3.8325 (4.0505)	grad_norm 0.2932 (0.3212)	mem 39782MB
[2023-07-07 09:29:02 RepVGG-A0] (main.py 282): INFO Train: [61/300][20/78]	eta 0:02:26 lr 5.763884	time 1.1738 (2.5234)	loss 3.6873 (3.9035)	grad_norm 0.2410 (0.3010)	mem 39782MB
[2023-07-07 09:29:17 RepVGG-A0] (main.py 282): INFO Train: [61/300][30/78]	eta 0:01:44 lr 5.761311	time 1.1340 (2.1844)	loss 3.4867 (3.7960)	grad_norm 0.2852 (0.2923)	mem 39782MB
[2023-07-07 09:29:34 RepVGG-A0] (main.py 282): INFO Train: [61/300][40/78]	eta 0:01:18 lr 5.758733	time 3.0986 (2.0709)	loss 3.5190 (3.7288)	grad_norm 0.3038 (0.2913)	mem 39782MB
[2023-07-07 09:29:49 RepVGG-A0] (main.py 282): INFO Train: [61/300][50/78]	eta 0:00:54 lr 5.756151	time 1.2172 (1.9579)	loss 3.4375 (3.6833)	grad_norm 0.3334 (0.2957)	mem 39782MB
[2023-07-07 09:30:05 RepVGG-A0] (main.py 282): INFO Train: [61/300][60/78]	eta 0:00:34 lr 5.753564	time 1.4077 (1.8957)	loss 3.4710 (3.6439)	grad_norm 0.2989 (0.2962)	mem 39782MB
[2023-07-07 09:30:20 RepVGG-A0] (main.py 282): INFO Train: [61/300][70/78]	eta 0:00:14 lr 5.750972	time 1.2299 (1.8455)	loss 3.6629 (3.6286)	grad_norm 0.4232 (0.3059)	mem 39782MB
[2023-07-07 09:30:31 RepVGG-A0] (main.py 291): INFO EPOCH 61 training takes 0:02:22
[2023-07-07 09:30:52 RepVGG-A0] (main.py 282): INFO Train: [62/300][0/78]	eta 0:26:56 lr 5.748896	time 20.7192 (20.7192)	loss 3.4278 (3.4278)	grad_norm 0.3303 (0.3303)	mem 39782MB
[2023-07-07 09:31:06 RepVGG-A0] (main.py 282): INFO Train: [62/300][10/78]	eta 0:03:32 lr 5.746296	time 1.1727 (3.1206)	loss 3.4217 (3.4411)	grad_norm 0.3172 (0.3186)	mem 39782MB
[2023-07-07 09:31:21 RepVGG-A0] (main.py 282): INFO Train: [62/300][20/78]	eta 0:02:17 lr 5.743692	time 1.2826 (2.3760)	loss 3.4564 (3.4465)	grad_norm 0.3536 (0.3274)	mem 39782MB
[2023-07-07 09:31:37 RepVGG-A0] (main.py 282): INFO Train: [62/300][30/78]	eta 0:01:42 lr 5.741083	time 1.4405 (2.1310)	loss 3.6415 (3.4827)	grad_norm 0.4112 (0.3466)	mem 39782MB
[2023-07-07 09:31:55 RepVGG-A0] (main.py 282): INFO Train: [62/300][40/78]	eta 0:01:17 lr 5.738469	time 3.5954 (2.0294)	loss 3.7124 (3.5662)	grad_norm 0.3568 (0.3771)	mem 39782MB
[2023-07-07 09:32:10 RepVGG-A0] (main.py 282): INFO Train: [62/300][50/78]	eta 0:00:54 lr 5.735851	time 1.1716 (1.9290)	loss 3.4267 (3.5570)	grad_norm 0.2826 (0.3600)	mem 39782MB
[2023-07-07 09:32:25 RepVGG-A0] (main.py 282): INFO Train: [62/300][60/78]	eta 0:00:33 lr 5.733228	time 1.3078 (1.8596)	loss 3.4462 (3.5400)	grad_norm 0.3257 (0.3530)	mem 39782MB
[2023-07-07 09:32:40 RepVGG-A0] (main.py 282): INFO Train: [62/300][70/78]	eta 0:00:14 lr 5.730601	time 1.1270 (1.8080)	loss 3.4474 (3.5338)	grad_norm 0.3370 (0.3522)	mem 39782MB
[2023-07-07 09:32:52 RepVGG-A0] (main.py 291): INFO EPOCH 62 training takes 0:02:20
[2023-07-07 09:33:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][0/78]	eta 0:28:29 lr 5.728496	time 21.9122 (21.9122)	loss 3.3670 (3.3670)	grad_norm 0.3240 (0.3240)	mem 39782MB
[2023-07-07 09:33:28 RepVGG-A0] (main.py 282): INFO Train: [63/300][10/78]	eta 0:03:41 lr 5.725861	time 1.1739 (3.2592)	loss 3.4928 (3.3867)	grad_norm 0.4217 (0.3436)	mem 39782MB
[2023-07-07 09:33:42 RepVGG-A0] (main.py 282): INFO Train: [63/300][20/78]	eta 0:02:18 lr 5.723221	time 1.1268 (2.3796)	loss 5.2216 (3.8922)	grad_norm 0.7453 (0.5193)	mem 39782MB
[2023-07-07 09:33:57 RepVGG-A0] (main.py 282): INFO Train: [63/300][30/78]	eta 0:01:40 lr 5.720576	time 1.4736 (2.0939)	loss 4.2286 (4.1482)	grad_norm 0.2767 (0.4875)	mem 39782MB
[2023-07-07 09:34:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][40/78]	eta 0:01:16 lr 5.717927	time 3.3334 (2.0057)	loss 3.8771 (4.1048)	grad_norm 0.2881 (0.4358)	mem 39782MB
[2023-07-07 09:34:29 RepVGG-A0] (main.py 282): INFO Train: [63/300][50/78]	eta 0:00:53 lr 5.715273	time 1.3432 (1.9172)	loss 3.6619 (4.0338)	grad_norm 0.3010 (0.4041)	mem 39782MB
[2023-07-07 09:34:45 RepVGG-A0] (main.py 282): INFO Train: [63/300][60/78]	eta 0:00:33 lr 5.712615	time 1.1735 (1.8535)	loss 3.6269 (3.9683)	grad_norm 0.2600 (0.3830)	mem 39782MB
[2023-07-07 09:35:00 RepVGG-A0] (main.py 282): INFO Train: [63/300][70/78]	eta 0:00:14 lr 5.709952	time 1.3299 (1.8116)	loss 3.6034 (3.9106)	grad_norm 0.3287 (0.3677)	mem 39782MB
[2023-07-07 09:35:11 RepVGG-A0] (main.py 291): INFO EPOCH 63 training takes 0:02:19
[2023-07-07 09:35:33 RepVGG-A0] (main.py 282): INFO Train: [64/300][0/78]	eta 0:28:03 lr 5.707819	time 21.5877 (21.5877)	loss 3.4210 (3.4210)	grad_norm 0.3458 (0.3458)	mem 39782MB
[2023-07-07 09:35:49 RepVGG-A0] (main.py 282): INFO Train: [64/300][10/78]	eta 0:03:50 lr 5.705148	time 1.1708 (3.3934)	loss 3.4161 (3.4846)	grad_norm 0.2726 (0.3107)	mem 39782MB
[2023-07-07 09:36:05 RepVGG-A0] (main.py 282): INFO Train: [64/300][20/78]	eta 0:02:26 lr 5.702473	time 1.3717 (2.5274)	loss 3.5980 (3.4863)	grad_norm 0.4396 (0.3233)	mem 39782MB
[2023-07-07 09:36:20 RepVGG-A0] (main.py 282): INFO Train: [64/300][30/78]	eta 0:01:45 lr 5.699793	time 1.6514 (2.2029)	loss 3.4232 (3.5145)	grad_norm 0.2986 (0.3359)	mem 39782MB
[2023-07-07 09:36:38 RepVGG-A0] (main.py 282): INFO Train: [64/300][40/78]	eta 0:01:19 lr 5.697109	time 2.1339 (2.0983)	loss 3.5155 (3.5050)	grad_norm 0.3475 (0.3318)	mem 39782MB
[2023-07-07 09:36:53 RepVGG-A0] (main.py 282): INFO Train: [64/300][50/78]	eta 0:00:55 lr 5.694420	time 1.1763 (1.9882)	loss 3.5032 (3.4956)	grad_norm 0.3971 (0.3264)	mem 39782MB
[2023-07-07 09:37:07 RepVGG-A0] (main.py 282): INFO Train: [64/300][60/78]	eta 0:00:34 lr 5.691726	time 1.2860 (1.8966)	loss 3.6198 (3.5249)	grad_norm 0.3464 (0.3421)	mem 39782MB
[2023-07-07 09:37:22 RepVGG-A0] (main.py 282): INFO Train: [64/300][70/78]	eta 0:00:14 lr 5.689029	time 1.2917 (1.8375)	loss 3.4681 (3.5165)	grad_norm 0.3460 (0.3384)	mem 39782MB
[2023-07-07 09:37:34 RepVGG-A0] (main.py 291): INFO EPOCH 64 training takes 0:02:22
[2023-07-07 09:37:55 RepVGG-A0] (main.py 282): INFO Train: [65/300][0/78]	eta 0:27:30 lr 5.686867	time 21.1556 (21.1556)	loss 3.3531 (3.3531)	grad_norm 0.3390 (0.3390)	mem 39782MB
[2023-07-07 09:38:09 RepVGG-A0] (main.py 282): INFO Train: [65/300][10/78]	eta 0:03:39 lr 5.684161	time 1.1748 (3.2240)	loss 3.4492 (3.4642)	grad_norm 0.3396 (0.3593)	mem 39782MB
[2023-07-07 09:38:25 RepVGG-A0] (main.py 282): INFO Train: [65/300][20/78]	eta 0:02:22 lr 5.681451	time 1.2754 (2.4537)	loss 3.4725 (3.4390)	grad_norm 0.3700 (0.3420)	mem 39782MB
[2023-07-07 09:38:41 RepVGG-A0] (main.py 282): INFO Train: [65/300][30/78]	eta 0:01:43 lr 5.678736	time 1.7508 (2.1573)	loss 3.5241 (3.4558)	grad_norm 0.3616 (0.3542)	mem 39782MB
[2023-07-07 09:38:58 RepVGG-A0] (main.py 282): INFO Train: [65/300][40/78]	eta 0:01:17 lr 5.676017	time 3.2598 (2.0517)	loss 3.6111 (3.4517)	grad_norm 0.4233 (0.3501)	mem 39782MB
[2023-07-07 09:39:13 RepVGG-A0] (main.py 282): INFO Train: [65/300][50/78]	eta 0:00:54 lr 5.673293	time 1.1738 (1.9466)	loss 4.7992 (3.6230)	grad_norm 0.6230 (0.4151)	mem 39782MB
[2023-07-07 09:39:28 RepVGG-A0] (main.py 282): INFO Train: [65/300][60/78]	eta 0:00:33 lr 5.670564	time 1.2094 (1.8715)	loss 4.2624 (3.7929)	grad_norm 0.3560 (0.4301)	mem 39782MB
[2023-07-07 09:39:43 RepVGG-A0] (main.py 282): INFO Train: [65/300][70/78]	eta 0:00:14 lr 5.667832	time 1.2438 (1.8166)	loss 3.8472 (3.8151)	grad_norm 0.3073 (0.4077)	mem 39782MB
[2023-07-07 09:39:55 RepVGG-A0] (main.py 291): INFO EPOCH 65 training takes 0:02:21
[2023-07-07 09:40:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][0/78]	eta 0:27:03 lr 5.665642	time 20.8099 (20.8099)	loss 3.6220 (3.6220)	grad_norm 0.2577 (0.2577)	mem 39782MB
[2023-07-07 09:40:30 RepVGG-A0] (main.py 282): INFO Train: [66/300][10/78]	eta 0:03:33 lr 5.662902	time 1.1922 (3.1372)	loss 3.4282 (3.5501)	grad_norm 0.2528 (0.2668)	mem 39782MB
[2023-07-07 09:40:44 RepVGG-A0] (main.py 282): INFO Train: [66/300][20/78]	eta 0:02:14 lr 5.660156	time 1.1920 (2.3197)	loss 3.4743 (3.5238)	grad_norm 0.2966 (0.2720)	mem 39782MB
[2023-07-07 09:40:59 RepVGG-A0] (main.py 282): INFO Train: [66/300][30/78]	eta 0:01:38 lr 5.657407	time 1.1754 (2.0428)	loss 3.3906 (3.5018)	grad_norm 0.3068 (0.2793)	mem 39782MB
[2023-07-07 09:41:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][40/78]	eta 0:01:15 lr 5.654653	time 3.8216 (1.9758)	loss 3.3722 (3.4976)	grad_norm 0.2734 (0.2895)	mem 39782MB
[2023-07-07 09:41:32 RepVGG-A0] (main.py 282): INFO Train: [66/300][50/78]	eta 0:00:52 lr 5.651894	time 2.0432 (1.8915)	loss 3.5158 (3.4917)	grad_norm 0.3489 (0.2950)	mem 39782MB
[2023-07-07 09:41:47 RepVGG-A0] (main.py 282): INFO Train: [66/300][60/78]	eta 0:00:32 lr 5.649132	time 1.1763 (1.8267)	loss 5.2711 (3.6555)	grad_norm 0.5786 (0.3609)	mem 39782MB
[2023-07-07 09:42:03 RepVGG-A0] (main.py 282): INFO Train: [66/300][70/78]	eta 0:00:14 lr 5.646364	time 1.3524 (1.7914)	loss 4.4027 (3.8164)	grad_norm 0.3216 (0.3730)	mem 39782MB
[2023-07-07 09:42:15 RepVGG-A0] (main.py 291): INFO EPOCH 66 training takes 0:02:19
[2023-07-07 09:42:36 RepVGG-A0] (main.py 282): INFO Train: [67/300][0/78]	eta 0:27:44 lr 5.644147	time 21.3376 (21.3376)	loss 4.0055 (4.0055)	grad_norm 0.2578 (0.2578)	mem 39782MB
[2023-07-07 09:42:50 RepVGG-A0] (main.py 282): INFO Train: [67/300][10/78]	eta 0:03:40 lr 5.641372	time 1.1915 (3.2451)	loss 3.7564 (3.8613)	grad_norm 0.2625 (0.2836)	mem 39782MB
[2023-07-07 09:43:04 RepVGG-A0] (main.py 282): INFO Train: [67/300][20/78]	eta 0:02:16 lr 5.638592	time 1.1716 (2.3565)	loss 3.6434 (3.7877)	grad_norm 0.2765 (0.2761)	mem 39782MB
[2023-07-07 09:43:19 RepVGG-A0] (main.py 282): INFO Train: [67/300][30/78]	eta 0:01:39 lr 5.635808	time 1.1847 (2.0741)	loss 3.6617 (3.7422)	grad_norm 0.2977 (0.2811)	mem 39782MB
[2023-07-07 09:43:37 RepVGG-A0] (main.py 282): INFO Train: [67/300][40/78]	eta 0:01:16 lr 5.633020	time 3.5791 (2.0131)	loss 3.4940 (3.7158)	grad_norm 0.2655 (0.2931)	mem 39782MB
[2023-07-07 09:43:53 RepVGG-A0] (main.py 282): INFO Train: [67/300][50/78]	eta 0:00:53 lr 5.630227	time 1.1735 (1.9272)	loss 3.5221 (3.6878)	grad_norm 0.3324 (0.2952)	mem 39782MB
[2023-07-07 09:44:07 RepVGG-A0] (main.py 282): INFO Train: [67/300][60/78]	eta 0:00:33 lr 5.627430	time 1.3104 (1.8497)	loss 3.6025 (3.6625)	grad_norm 0.3992 (0.3004)	mem 39782MB
[2023-07-07 09:44:23 RepVGG-A0] (main.py 282): INFO Train: [67/300][70/78]	eta 0:00:14 lr 5.624629	time 1.5614 (1.8095)	loss 3.7093 (3.6563)	grad_norm 0.3790 (0.3068)	mem 39782MB
[2023-07-07 09:44:35 RepVGG-A0] (main.py 291): INFO EPOCH 67 training takes 0:02:20
[2023-07-07 09:44:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][0/78]	eta 0:27:50 lr 5.622384	time 21.4203 (21.4203)	loss 3.5205 (3.5205)	grad_norm 0.2924 (0.2924)	mem 39782MB
[2023-07-07 09:45:10 RepVGG-A0] (main.py 282): INFO Train: [68/300][10/78]	eta 0:03:36 lr 5.619575	time 1.1726 (3.1843)	loss 3.6204 (3.5179)	grad_norm 0.3247 (0.3421)	mem 39782MB
[2023-07-07 09:45:25 RepVGG-A0] (main.py 282): INFO Train: [68/300][20/78]	eta 0:02:18 lr 5.616761	time 1.1733 (2.3914)	loss 3.5437 (3.5011)	grad_norm 0.3365 (0.3351)	mem 39782MB
[2023-07-07 09:45:40 RepVGG-A0] (main.py 282): INFO Train: [68/300][30/78]	eta 0:01:41 lr 5.613943	time 1.3291 (2.1134)	loss 3.5082 (3.5066)	grad_norm 0.3669 (0.3429)	mem 39782MB
[2023-07-07 09:45:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][40/78]	eta 0:01:15 lr 5.611120	time 1.9894 (1.9875)	loss 3.3983 (3.5083)	grad_norm 0.3171 (0.3462)	mem 39782MB
[2023-07-07 09:46:13 RepVGG-A0] (main.py 282): INFO Train: [68/300][50/78]	eta 0:00:54 lr 5.608294	time 1.1725 (1.9334)	loss 3.4690 (3.5091)	grad_norm 0.3760 (0.3501)	mem 39782MB
[2023-07-07 09:46:29 RepVGG-A0] (main.py 282): INFO Train: [68/300][60/78]	eta 0:00:33 lr 5.605462	time 1.3293 (1.8645)	loss 3.5899 (3.5158)	grad_norm 0.3654 (0.3540)	mem 39782MB
[2023-07-07 09:46:44 RepVGG-A0] (main.py 282): INFO Train: [68/300][70/78]	eta 0:00:14 lr 5.602627	time 1.1788 (1.8184)	loss 3.4999 (3.5070)	grad_norm 0.3921 (0.3495)	mem 39782MB
[2023-07-07 09:46:56 RepVGG-A0] (main.py 291): INFO EPOCH 68 training takes 0:02:20
[2023-07-07 09:47:17 RepVGG-A0] (main.py 282): INFO Train: [69/300][0/78]	eta 0:28:14 lr 5.600355	time 21.7181 (21.7181)	loss 3.5359 (3.5359)	grad_norm 0.4097 (0.4097)	mem 39782MB
[2023-07-07 09:47:32 RepVGG-A0] (main.py 282): INFO Train: [69/300][10/78]	eta 0:03:45 lr 5.597512	time 1.1705 (3.3098)	loss 3.4741 (3.5322)	grad_norm 0.3140 (0.3957)	mem 39782MB
[2023-07-07 09:47:46 RepVGG-A0] (main.py 282): INFO Train: [69/300][20/78]	eta 0:02:19 lr 5.594665	time 1.2089 (2.4118)	loss 3.4719 (3.4893)	grad_norm 0.3201 (0.3725)	mem 39782MB
[2023-07-07 09:48:02 RepVGG-A0] (main.py 282): INFO Train: [69/300][30/78]	eta 0:01:42 lr 5.591813	time 1.1286 (2.1322)	loss 3.5324 (3.4729)	grad_norm 0.3596 (0.3596)	mem 39782MB
[2023-07-07 09:48:20 RepVGG-A0] (main.py 282): INFO Train: [69/300][40/78]	eta 0:01:17 lr 5.588956	time 3.9408 (2.0504)	loss 3.5183 (3.4665)	grad_norm 0.4635 (0.3623)	mem 39782MB
[2023-07-07 09:48:35 RepVGG-A0] (main.py 282): INFO Train: [69/300][50/78]	eta 0:00:54 lr 5.586096	time 1.1788 (1.9507)	loss 6.1923 (3.7770)	grad_norm 0.6966 (0.4551)	mem 39782MB
[2023-07-07 09:48:50 RepVGG-A0] (main.py 282): INFO Train: [69/300][60/78]	eta 0:00:33 lr 5.583231	time 1.2225 (1.8723)	loss 5.0120 (4.0673)	grad_norm 0.3042 (0.4439)	mem 39782MB
[2023-07-07 09:49:05 RepVGG-A0] (main.py 282): INFO Train: [69/300][70/78]	eta 0:00:14 lr 5.580362	time 1.1947 (1.8221)	loss 4.5313 (4.1578)	grad_norm 0.3020 (0.4236)	mem 39782MB
[2023-07-07 09:49:17 RepVGG-A0] (main.py 291): INFO EPOCH 69 training takes 0:02:21
[2023-07-07 09:49:39 RepVGG-A0] (main.py 282): INFO Train: [70/300][0/78]	eta 0:28:36 lr 5.578063	time 22.0072 (22.0072)	loss 4.1724 (4.1724)	grad_norm 0.2419 (0.2419)	mem 39782MB
[2023-07-07 09:49:53 RepVGG-A0] (main.py 282): INFO Train: [70/300][10/78]	eta 0:03:41 lr 5.575187	time 1.1718 (3.2612)	loss 4.1023 (4.0864)	grad_norm 0.3224 (0.2928)	mem 39782MB
[2023-07-07 09:50:09 RepVGG-A0] (main.py 282): INFO Train: [70/300][20/78]	eta 0:02:22 lr 5.572305	time 1.3950 (2.4629)	loss 3.8809 (4.0171)	grad_norm 0.2858 (0.2949)	mem 39782MB
[2023-07-07 09:50:25 RepVGG-A0] (main.py 282): INFO Train: [70/300][30/78]	eta 0:01:44 lr 5.569420	time 1.4937 (2.1796)	loss 3.7951 (3.9550)	grad_norm 0.2641 (0.2913)	mem 39782MB
[2023-07-07 09:50:41 RepVGG-A0] (main.py 282): INFO Train: [70/300][40/78]	eta 0:01:18 lr 5.566530	time 3.1761 (2.0600)	loss 3.8493 (3.9187)	grad_norm 0.3403 (0.3055)	mem 39782MB
[2023-07-07 09:50:56 RepVGG-A0] (main.py 282): INFO Train: [70/300][50/78]	eta 0:00:54 lr 5.563636	time 1.1741 (1.9406)	loss 3.6322 (3.8781)	grad_norm 0.2810 (0.3034)	mem 39782MB
[2023-07-07 09:51:11 RepVGG-A0] (main.py 282): INFO Train: [70/300][60/78]	eta 0:00:33 lr 5.560738	time 1.1792 (1.8711)	loss 3.8401 (3.8512)	grad_norm 0.4148 (0.3113)	mem 39782MB
[2023-07-07 09:51:25 RepVGG-A0] (main.py 282): INFO Train: [70/300][70/78]	eta 0:00:14 lr 5.557836	time 1.4559 (1.8030)	loss 3.6679 (3.8320)	grad_norm 0.2909 (0.3134)	mem 39782MB
[2023-07-07 09:51:36 RepVGG-A0] (main.py 291): INFO EPOCH 70 training takes 0:02:19
[2023-07-07 09:51:58 RepVGG-A0] (main.py 282): INFO Train: [71/300][0/78]	eta 0:28:23 lr 5.555511	time 21.8435 (21.8435)	loss 3.4829 (3.4829)	grad_norm 0.2949 (0.2949)	mem 39782MB
[2023-07-07 09:52:12 RepVGG-A0] (main.py 282): INFO Train: [71/300][10/78]	eta 0:03:42 lr 5.552601	time 1.1733 (3.2691)	loss 3.6700 (3.6502)	grad_norm 0.2917 (0.3733)	mem 39782MB
[2023-07-07 09:52:26 RepVGG-A0] (main.py 282): INFO Train: [71/300][20/78]	eta 0:02:17 lr 5.549686	time 1.1725 (2.3644)	loss 3.4995 (3.5976)	grad_norm 0.2888 (0.3414)	mem 39782MB
[2023-07-07 09:52:42 RepVGG-A0] (main.py 282): INFO Train: [71/300][30/78]	eta 0:01:41 lr 5.546768	time 1.4360 (2.1090)	loss 3.5859 (3.5910)	grad_norm 0.3619 (0.3468)	mem 39782MB
[2023-07-07 09:53:00 RepVGG-A0] (main.py 282): INFO Train: [71/300][40/78]	eta 0:01:17 lr 5.543845	time 4.2991 (2.0366)	loss 3.4744 (3.5772)	grad_norm 0.3471 (0.3410)	mem 39782MB
[2023-07-07 09:53:15 RepVGG-A0] (main.py 282): INFO Train: [71/300][50/78]	eta 0:00:53 lr 5.540918	time 1.1725 (1.9248)	loss 3.7647 (3.6480)	grad_norm 0.3041 (0.3686)	mem 39782MB
[2023-07-07 09:53:29 RepVGG-A0] (main.py 282): INFO Train: [71/300][60/78]	eta 0:00:33 lr 5.537986	time 1.2292 (1.8533)	loss 3.7212 (3.6469)	grad_norm 0.3630 (0.3598)	mem 39782MB
[2023-07-07 09:53:45 RepVGG-A0] (main.py 282): INFO Train: [71/300][70/78]	eta 0:00:14 lr 5.535051	time 1.2882 (1.8045)	loss 3.6014 (3.6314)	grad_norm 0.3185 (0.3501)	mem 39782MB
[2023-07-07 09:53:56 RepVGG-A0] (main.py 291): INFO EPOCH 71 training takes 0:02:20
[2023-07-07 09:54:18 RepVGG-A0] (main.py 282): INFO Train: [72/300][0/78]	eta 0:28:08 lr 5.532700	time 21.6469 (21.6469)	loss 3.4008 (3.4008)	grad_norm 0.2911 (0.2911)	mem 39782MB
[2023-07-07 09:54:32 RepVGG-A0] (main.py 282): INFO Train: [72/300][10/78]	eta 0:03:42 lr 5.529757	time 1.1720 (3.2719)	loss 3.4415 (3.4334)	grad_norm 0.3112 (0.3135)	mem 39782MB
[2023-07-07 09:54:48 RepVGG-A0] (main.py 282): INFO Train: [72/300][20/78]	eta 0:02:22 lr 5.526809	time 1.2751 (2.4553)	loss 3.5908 (3.5106)	grad_norm 0.3500 (0.3556)	mem 39782MB
[2023-07-07 09:55:04 RepVGG-A0] (main.py 282): INFO Train: [72/300][30/78]	eta 0:01:44 lr 5.523858	time 1.2779 (2.1737)	loss 3.5159 (3.5112)	grad_norm 0.3324 (0.3452)	mem 39782MB
[2023-07-07 09:55:21 RepVGG-A0] (main.py 282): INFO Train: [72/300][40/78]	eta 0:01:18 lr 5.520902	time 3.8687 (2.0570)	loss 3.4715 (3.5185)	grad_norm 0.3531 (0.3500)	mem 39782MB
[2023-07-07 09:55:36 RepVGG-A0] (main.py 282): INFO Train: [72/300][50/78]	eta 0:00:54 lr 5.517942	time 1.1717 (1.9463)	loss 3.4540 (3.5056)	grad_norm 0.3320 (0.3453)	mem 39782MB
[2023-07-07 09:55:51 RepVGG-A0] (main.py 282): INFO Train: [72/300][60/78]	eta 0:00:33 lr 5.514978	time 1.6338 (1.8727)	loss 3.5694 (3.5042)	grad_norm 0.4239 (0.3478)	mem 39782MB
[2023-07-07 09:56:06 RepVGG-A0] (main.py 282): INFO Train: [72/300][70/78]	eta 0:00:14 lr 5.512010	time 1.2443 (1.8221)	loss 5.5415 (3.6435)	grad_norm 0.8740 (0.4036)	mem 39782MB
[2023-07-07 09:56:18 RepVGG-A0] (main.py 291): INFO EPOCH 72 training takes 0:02:21
[2023-07-07 09:56:39 RepVGG-A0] (main.py 282): INFO Train: [73/300][0/78]	eta 0:28:15 lr 5.509633	time 21.7382 (21.7382)	loss 4.7735 (4.7735)	grad_norm 0.3197 (0.3197)	mem 39782MB
[2023-07-07 09:56:54 RepVGG-A0] (main.py 282): INFO Train: [73/300][10/78]	eta 0:03:45 lr 5.506657	time 1.1902 (3.3108)	loss 4.0735 (4.3825)	grad_norm 0.2373 (0.2861)	mem 39782MB
[2023-07-07 09:57:09 RepVGG-A0] (main.py 282): INFO Train: [73/300][20/78]	eta 0:02:21 lr 5.503677	time 1.1737 (2.4310)	loss 3.8449 (4.2306)	grad_norm 0.2448 (0.3022)	mem 39782MB
[2023-07-07 09:57:24 RepVGG-A0] (main.py 282): INFO Train: [73/300][30/78]	eta 0:01:42 lr 5.500693	time 1.2436 (2.1320)	loss 3.7208 (4.0880)	grad_norm 0.2543 (0.2828)	mem 39782MB
[2023-07-07 09:57:42 RepVGG-A0] (main.py 282): INFO Train: [73/300][40/78]	eta 0:01:18 lr 5.497705	time 3.8239 (2.0558)	loss 3.6567 (3.9843)	grad_norm 0.2672 (0.2799)	mem 39782MB
[2023-07-07 09:57:57 RepVGG-A0] (main.py 282): INFO Train: [73/300][50/78]	eta 0:00:54 lr 5.494713	time 1.2216 (1.9447)	loss 3.5977 (3.9142)	grad_norm 0.3221 (0.2826)	mem 39782MB
[2023-07-07 09:58:11 RepVGG-A0] (main.py 282): INFO Train: [73/300][60/78]	eta 0:00:33 lr 5.491716	time 1.1801 (1.8650)	loss 3.5899 (3.8654)	grad_norm 0.2941 (0.2880)	mem 39782MB
[2023-07-07 09:58:26 RepVGG-A0] (main.py 282): INFO Train: [73/300][70/78]	eta 0:00:14 lr 5.488716	time 1.3052 (1.8118)	loss 3.6392 (3.8222)	grad_norm 0.3572 (0.2900)	mem 39782MB
[2023-07-07 09:58:38 RepVGG-A0] (main.py 291): INFO EPOCH 73 training takes 0:02:20
[2023-07-07 09:59:00 RepVGG-A0] (main.py 282): INFO Train: [74/300][0/78]	eta 0:27:54 lr 5.486313	time 21.4711 (21.4711)	loss 3.5370 (3.5370)	grad_norm 0.3862 (0.3862)	mem 39782MB
[2023-07-07 09:59:15 RepVGG-A0] (main.py 282): INFO Train: [74/300][10/78]	eta 0:03:48 lr 5.483305	time 1.1718 (3.3574)	loss 3.4714 (3.5316)	grad_norm 0.2935 (0.3335)	mem 39782MB
[2023-07-07 09:59:30 RepVGG-A0] (main.py 282): INFO Train: [74/300][20/78]	eta 0:02:22 lr 5.480293	time 1.1754 (2.4590)	loss 3.6513 (3.5264)	grad_norm 0.3946 (0.3368)	mem 39782MB
[2023-07-07 09:59:46 RepVGG-A0] (main.py 282): INFO Train: [74/300][30/78]	eta 0:01:44 lr 5.477276	time 1.1548 (2.1748)	loss 3.4484 (3.5290)	grad_norm 0.2881 (0.3353)	mem 39782MB
[2023-07-07 10:00:04 RepVGG-A0] (main.py 282): INFO Train: [74/300][40/78]	eta 0:01:19 lr 5.474256	time 4.0086 (2.0880)	loss 3.4207 (3.5246)	grad_norm 0.3264 (0.3352)	mem 39782MB
[2023-07-07 10:00:18 RepVGG-A0] (main.py 282): INFO Train: [74/300][50/78]	eta 0:00:54 lr 5.471232	time 1.1727 (1.9598)	loss 3.5593 (3.5260)	grad_norm 0.3907 (0.3412)	mem 39782MB
[2023-07-07 10:00:34 RepVGG-A0] (main.py 282): INFO Train: [74/300][60/78]	eta 0:00:33 lr 5.468203	time 1.2791 (1.8874)	loss 3.4824 (3.5255)	grad_norm 0.3227 (0.3421)	mem 39782MB
[2023-07-07 10:00:50 RepVGG-A0] (main.py 282): INFO Train: [74/300][70/78]	eta 0:00:14 lr 5.465171	time 1.3090 (1.8513)	loss 3.6551 (3.5261)	grad_norm 0.4644 (0.3466)	mem 39782MB
[2023-07-07 10:01:01 RepVGG-A0] (main.py 291): INFO EPOCH 74 training takes 0:02:22
[2023-07-07 10:01:22 RepVGG-A0] (main.py 282): INFO Train: [75/300][0/78]	eta 0:26:53 lr 5.462742	time 20.6849 (20.6849)	loss 3.4715 (3.4715)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 10:01:36 RepVGG-A0] (main.py 282): INFO Train: [75/300][10/78]	eta 0:03:38 lr 5.459702	time 1.1723 (3.2138)	loss 3.5173 (3.4898)	grad_norm 0.3977 (0.3616)	mem 39782MB
[2023-07-07 10:01:51 RepVGG-A0] (main.py 282): INFO Train: [75/300][20/78]	eta 0:02:17 lr 5.456658	time 1.1711 (2.3767)	loss 3.3772 (3.4625)	grad_norm 0.3402 (0.3409)	mem 39782MB
[2023-07-07 10:02:07 RepVGG-A0] (main.py 282): INFO Train: [75/300][30/78]	eta 0:01:41 lr 5.453610	time 1.4357 (2.1152)	loss 3.6222 (3.5018)	grad_norm 0.4109 (0.3673)	mem 39782MB
[2023-07-07 10:02:24 RepVGG-A0] (main.py 282): INFO Train: [75/300][40/78]	eta 0:01:16 lr 5.450558	time 2.5461 (2.0142)	loss 3.3762 (3.4918)	grad_norm 0.2769 (0.3562)	mem 39782MB
[2023-07-07 10:02:41 RepVGG-A0] (main.py 282): INFO Train: [75/300][50/78]	eta 0:00:54 lr 5.447501	time 1.2001 (1.9626)	loss 3.4523 (3.4898)	grad_norm 0.3503 (0.3551)	mem 39782MB
[2023-07-07 10:02:57 RepVGG-A0] (main.py 282): INFO Train: [75/300][60/78]	eta 0:00:34 lr 5.444441	time 1.2691 (1.8952)	loss 3.4475 (3.4829)	grad_norm 0.3656 (0.3504)	mem 39782MB
[2023-07-07 10:03:12 RepVGG-A0] (main.py 282): INFO Train: [75/300][70/78]	eta 0:00:14 lr 5.441377	time 1.1706 (1.8438)	loss 3.5263 (3.5132)	grad_norm 0.3341 (0.3662)	mem 39782MB
[2023-07-07 10:03:23 RepVGG-A0] (main.py 291): INFO EPOCH 75 training takes 0:02:21
[2023-07-07 10:03:44 RepVGG-A0] (main.py 282): INFO Train: [76/300][0/78]	eta 0:27:44 lr 5.438923	time 21.3338 (21.3338)	loss 3.3181 (3.3181)	grad_norm 0.2974 (0.2974)	mem 39782MB
[2023-07-07 10:04:01 RepVGG-A0] (main.py 282): INFO Train: [76/300][10/78]	eta 0:03:52 lr 5.435851	time 1.1981 (3.4216)	loss 3.4519 (3.3823)	grad_norm 0.3213 (0.3309)	mem 39782MB
[2023-07-07 10:04:15 RepVGG-A0] (main.py 282): INFO Train: [76/300][20/78]	eta 0:02:23 lr 5.432776	time 1.3687 (2.4673)	loss 3.3769 (3.3837)	grad_norm 0.3448 (0.3281)	mem 39782MB
[2023-07-07 10:04:30 RepVGG-A0] (main.py 282): INFO Train: [76/300][30/78]	eta 0:01:43 lr 5.429696	time 1.4646 (2.1511)	loss 3.4849 (3.4186)	grad_norm 0.4127 (0.3527)	mem 39782MB
[2023-07-07 10:04:47 RepVGG-A0] (main.py 282): INFO Train: [76/300][40/78]	eta 0:01:18 lr 5.426612	time 3.6100 (2.0596)	loss 3.4146 (3.4284)	grad_norm 0.3175 (0.3496)	mem 39782MB
[2023-07-07 10:05:02 RepVGG-A0] (main.py 282): INFO Train: [76/300][50/78]	eta 0:00:54 lr 5.423525	time 1.1725 (1.9440)	loss 3.4456 (3.4320)	grad_norm 0.3627 (0.3508)	mem 39782MB
[2023-07-07 10:05:18 RepVGG-A0] (main.py 282): INFO Train: [76/300][60/78]	eta 0:00:33 lr 5.420433	time 1.1854 (1.8803)	loss 3.4516 (3.4301)	grad_norm 0.3779 (0.3503)	mem 39782MB
[2023-07-07 10:05:32 RepVGG-A0] (main.py 282): INFO Train: [76/300][70/78]	eta 0:00:14 lr 5.417338	time 1.1810 (1.8178)	loss 5.4563 (3.5160)	grad_norm 1.0900 (0.3931)	mem 39782MB
[2023-07-07 10:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 76 training takes 0:02:20
[2023-07-07 10:06:06 RepVGG-A0] (main.py 282): INFO Train: [77/300][0/78]	eta 0:28:56 lr 5.414858	time 22.2668 (22.2668)	loss 5.2301 (5.2301)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 10:06:20 RepVGG-A0] (main.py 282): INFO Train: [77/300][10/78]	eta 0:03:41 lr 5.411755	time 1.1718 (3.2573)	loss 4.4670 (4.8132)	grad_norm 0.3152 (0.3642)	mem 39782MB
[2023-07-07 10:06:34 RepVGG-A0] (main.py 282): INFO Train: [77/300][20/78]	eta 0:02:18 lr 5.408649	time 1.1910 (2.3810)	loss 3.9991 (4.5174)	grad_norm 0.2650 (0.3186)	mem 39782MB
[2023-07-07 10:06:50 RepVGG-A0] (main.py 282): INFO Train: [77/300][30/78]	eta 0:01:42 lr 5.405538	time 1.2473 (2.1251)	loss 3.9090 (4.3351)	grad_norm 0.3430 (0.3121)	mem 39782MB
[2023-07-07 10:07:08 RepVGG-A0] (main.py 282): INFO Train: [77/300][40/78]	eta 0:01:18 lr 5.402423	time 4.2060 (2.0601)	loss 3.7229 (4.2027)	grad_norm 0.3259 (0.3036)	mem 39782MB
[2023-07-07 10:07:23 RepVGG-A0] (main.py 282): INFO Train: [77/300][50/78]	eta 0:00:54 lr 5.399304	time 1.1730 (1.9346)	loss 3.7008 (4.1091)	grad_norm 0.3076 (0.3064)	mem 39782MB
[2023-07-07 10:07:39 RepVGG-A0] (main.py 282): INFO Train: [77/300][60/78]	eta 0:00:33 lr 5.396182	time 1.1964 (1.8797)	loss 3.6676 (4.0294)	grad_norm 0.3446 (0.3027)	mem 39782MB
[2023-07-07 10:07:54 RepVGG-A0] (main.py 282): INFO Train: [77/300][70/78]	eta 0:00:14 lr 5.393055	time 1.3753 (1.8307)	loss 3.5825 (3.9748)	grad_norm 0.2742 (0.3071)	mem 39782MB
[2023-07-07 10:08:06 RepVGG-A0] (main.py 291): INFO EPOCH 77 training takes 0:02:21
[2023-07-07 10:08:27 RepVGG-A0] (main.py 282): INFO Train: [78/300][0/78]	eta 0:28:17 lr 5.390551	time 21.7632 (21.7632)	loss 3.5177 (3.5177)	grad_norm 0.3382 (0.3382)	mem 39782MB
[2023-07-07 10:08:42 RepVGG-A0] (main.py 282): INFO Train: [78/300][10/78]	eta 0:03:43 lr 5.387417	time 1.1711 (3.2876)	loss 3.5767 (3.5449)	grad_norm 0.2988 (0.3343)	mem 39782MB
[2023-07-07 10:08:57 RepVGG-A0] (main.py 282): INFO Train: [78/300][20/78]	eta 0:02:22 lr 5.384279	time 1.3746 (2.4492)	loss 3.6056 (3.5585)	grad_norm 0.3817 (0.3522)	mem 39782MB
[2023-07-07 10:09:11 RepVGG-A0] (main.py 282): INFO Train: [78/300][30/78]	eta 0:01:41 lr 5.381138	time 1.1923 (2.1159)	loss 3.5479 (3.5420)	grad_norm 0.3380 (0.3396)	mem 39782MB
[2023-07-07 10:09:30 RepVGG-A0] (main.py 282): INFO Train: [78/300][40/78]	eta 0:01:18 lr 5.377992	time 3.3261 (2.0596)	loss 3.5550 (3.5352)	grad_norm 0.3562 (0.3401)	mem 39782MB
[2023-07-07 10:09:46 RepVGG-A0] (main.py 282): INFO Train: [78/300][50/78]	eta 0:00:54 lr 5.374843	time 1.1732 (1.9607)	loss 3.4465 (3.5327)	grad_norm 0.3894 (0.3455)	mem 39782MB
[2023-07-07 10:10:01 RepVGG-A0] (main.py 282): INFO Train: [78/300][60/78]	eta 0:00:33 lr 5.371689	time 1.4098 (1.8855)	loss 3.5875 (3.5326)	grad_norm 0.3290 (0.3454)	mem 39782MB
[2023-07-07 10:10:15 RepVGG-A0] (main.py 282): INFO Train: [78/300][70/78]	eta 0:00:14 lr 5.368532	time 1.1792 (1.8254)	loss 3.6880 (3.5275)	grad_norm 0.5386 (0.3483)	mem 39782MB
[2023-07-07 10:10:27 RepVGG-A0] (main.py 291): INFO EPOCH 78 training takes 0:02:21
[2023-07-07 10:10:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][0/78]	eta 0:28:35 lr 5.366003	time 21.9895 (21.9895)	loss 3.7738 (3.7738)	grad_norm 0.3883 (0.3883)	mem 39782MB
[2023-07-07 10:11:03 RepVGG-A0] (main.py 282): INFO Train: [79/300][10/78]	eta 0:03:42 lr 5.362839	time 1.1702 (3.2715)	loss 3.4483 (3.5860)	grad_norm 0.2665 (0.3224)	mem 39782MB
[2023-07-07 10:11:17 RepVGG-A0] (main.py 282): INFO Train: [79/300][20/78]	eta 0:02:16 lr 5.359670	time 1.1904 (2.3575)	loss 3.4457 (3.5052)	grad_norm 0.3262 (0.3080)	mem 39782MB
[2023-07-07 10:11:32 RepVGG-A0] (main.py 282): INFO Train: [79/300][30/78]	eta 0:01:40 lr 5.356498	time 1.1810 (2.0911)	loss 3.3843 (3.4886)	grad_norm 0.3432 (0.3223)	mem 39782MB
[2023-07-07 10:11:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][40/78]	eta 0:01:15 lr 5.353322	time 1.7538 (1.9994)	loss 3.3807 (3.4883)	grad_norm 0.3033 (0.3284)	mem 39782MB
[2023-07-07 10:12:05 RepVGG-A0] (main.py 282): INFO Train: [79/300][50/78]	eta 0:00:53 lr 5.350142	time 1.3028 (1.9206)	loss 3.5642 (3.4829)	grad_norm 0.3717 (0.3329)	mem 39782MB
[2023-07-07 10:12:21 RepVGG-A0] (main.py 282): INFO Train: [79/300][60/78]	eta 0:00:33 lr 5.346959	time 1.1283 (1.8648)	loss 3.4270 (3.4707)	grad_norm 0.3667 (0.3314)	mem 39782MB
[2023-07-07 10:12:36 RepVGG-A0] (main.py 282): INFO Train: [79/300][70/78]	eta 0:00:14 lr 5.343771	time 1.2698 (1.8181)	loss 4.1332 (3.5078)	grad_norm 0.7083 (0.3583)	mem 39782MB
[2023-07-07 10:12:47 RepVGG-A0] (main.py 291): INFO EPOCH 79 training takes 0:02:20
[2023-07-07 10:13:08 RepVGG-A0] (main.py 282): INFO Train: [80/300][0/78]	eta 0:26:08 lr 5.341218	time 20.1048 (20.1048)	loss 3.7640 (3.7640)	grad_norm 0.3243 (0.3243)	mem 39782MB
[2023-07-07 10:13:22 RepVGG-A0] (main.py 282): INFO Train: [80/300][10/78]	eta 0:03:36 lr 5.338023	time 1.1893 (3.1811)	loss 3.4771 (3.5846)	grad_norm 0.2977 (0.2853)	mem 39782MB
[2023-07-07 10:13:38 RepVGG-A0] (main.py 282): INFO Train: [80/300][20/78]	eta 0:02:19 lr 5.334825	time 1.1840 (2.4015)	loss 3.4714 (3.5359)	grad_norm 0.3072 (0.2960)	mem 39782MB
[2023-07-07 10:13:54 RepVGG-A0] (main.py 282): INFO Train: [80/300][30/78]	eta 0:01:42 lr 5.331623	time 1.3562 (2.1336)	loss 3.3416 (3.4890)	grad_norm 0.2722 (0.2921)	mem 39782MB
[2023-07-07 10:14:11 RepVGG-A0] (main.py 282): INFO Train: [80/300][40/78]	eta 0:01:17 lr 5.328416	time 4.3314 (2.0496)	loss 3.4865 (3.4600)	grad_norm 0.3658 (0.2937)	mem 39782MB
[2023-07-07 10:14:27 RepVGG-A0] (main.py 282): INFO Train: [80/300][50/78]	eta 0:00:54 lr 5.325206	time 1.1727 (1.9426)	loss 3.4498 (3.4657)	grad_norm 0.3275 (0.3082)	mem 39782MB
[2023-07-07 10:14:41 RepVGG-A0] (main.py 282): INFO Train: [80/300][60/78]	eta 0:00:33 lr 5.321993	time 1.2137 (1.8665)	loss 3.5511 (3.4551)	grad_norm 0.4813 (0.3119)	mem 39782MB
[2023-07-07 10:14:57 RepVGG-A0] (main.py 282): INFO Train: [80/300][70/78]	eta 0:00:14 lr 5.318775	time 1.7132 (1.8200)	loss 4.7696 (3.6117)	grad_norm 0.5154 (0.3707)	mem 39782MB
[2023-07-07 10:15:08 RepVGG-A0] (main.py 291): INFO EPOCH 80 training takes 0:02:20
[2023-07-07 10:15:25 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.061 (17.061)	Loss 5.1657 (5.1657)	Acc@1 11.731 (11.731)	Acc@5 27.191 (27.191)	Mem 39782MB
[2023-07-07 10:15:26 RepVGG-A0] (main.py 342): INFO  * Acc@1 11.640 Acc@5 26.608
[2023-07-07 10:15:26 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 80: 11.640%
[2023-07-07 10:15:26 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 10:15:46 RepVGG-A0] (main.py 282): INFO Train: [81/300][0/78]	eta 0:25:19 lr 5.316198	time 19.4865 (19.4865)	loss 3.8042 (3.8042)	grad_norm 0.2790 (0.2790)	mem 39782MB
[2023-07-07 10:16:01 RepVGG-A0] (main.py 282): INFO Train: [81/300][10/78]	eta 0:03:37 lr 5.312973	time 1.1699 (3.1913)	loss 3.5834 (3.7226)	grad_norm 0.2627 (0.2694)	mem 39782MB
[2023-07-07 10:16:16 RepVGG-A0] (main.py 282): INFO Train: [81/300][20/78]	eta 0:02:16 lr 5.309745	time 1.1906 (2.3547)	loss 3.4765 (3.6459)	grad_norm 0.2382 (0.2740)	mem 39782MB
[2023-07-07 10:16:31 RepVGG-A0] (main.py 282): INFO Train: [81/300][30/78]	eta 0:01:40 lr 5.306513	time 1.2254 (2.0846)	loss 3.4535 (3.5790)	grad_norm 0.2845 (0.2751)	mem 39782MB
[2023-07-07 10:16:49 RepVGG-A0] (main.py 282): INFO Train: [81/300][40/78]	eta 0:01:16 lr 5.303277	time 2.2513 (2.0189)	loss 3.4110 (3.5347)	grad_norm 0.2972 (0.2759)	mem 39782MB
[2023-07-07 10:17:06 RepVGG-A0] (main.py 282): INFO Train: [81/300][50/78]	eta 0:00:54 lr 5.300037	time 2.6884 (1.9507)	loss 3.4649 (3.5135)	grad_norm 0.3083 (0.2858)	mem 39782MB
[2023-07-07 10:17:21 RepVGG-A0] (main.py 282): INFO Train: [81/300][60/78]	eta 0:00:33 lr 5.296794	time 1.1971 (1.8732)	loss 3.3035 (3.4891)	grad_norm 0.3078 (0.2882)	mem 39782MB
[2023-07-07 10:17:36 RepVGG-A0] (main.py 282): INFO Train: [81/300][70/78]	eta 0:00:14 lr 5.293546	time 1.1724 (1.8219)	loss 3.4106 (3.4770)	grad_norm 0.3443 (0.2952)	mem 39782MB
[2023-07-07 10:17:48 RepVGG-A0] (main.py 291): INFO EPOCH 81 training takes 0:02:21
[2023-07-07 10:18:08 RepVGG-A0] (main.py 282): INFO Train: [82/300][0/78]	eta 0:26:54 lr 5.290946	time 20.7011 (20.7011)	loss 3.4231 (3.4231)	grad_norm 0.3601 (0.3601)	mem 39782MB
[2023-07-07 10:18:23 RepVGG-A0] (main.py 282): INFO Train: [82/300][10/78]	eta 0:03:37 lr 5.287692	time 1.1721 (3.2001)	loss 3.3521 (3.3973)	grad_norm 0.2981 (0.3495)	mem 39782MB
[2023-07-07 10:18:38 RepVGG-A0] (main.py 282): INFO Train: [82/300][20/78]	eta 0:02:19 lr 5.284434	time 1.1740 (2.4044)	loss 3.3903 (3.3828)	grad_norm 0.3628 (0.3463)	mem 39782MB
[2023-07-07 10:18:52 RepVGG-A0] (main.py 282): INFO Train: [82/300][30/78]	eta 0:01:39 lr 5.281172	time 1.1934 (2.0817)	loss 3.3474 (3.3696)	grad_norm 0.3732 (0.3417)	mem 39782MB
[2023-07-07 10:19:11 RepVGG-A0] (main.py 282): INFO Train: [82/300][40/78]	eta 0:01:16 lr 5.277907	time 3.9548 (2.0260)	loss 4.5767 (3.4822)	grad_norm 0.8830 (0.4006)	mem 39782MB
[2023-07-07 10:19:26 RepVGG-A0] (main.py 282): INFO Train: [82/300][50/78]	eta 0:00:53 lr 5.274638	time 1.1723 (1.9245)	loss 3.8616 (3.6322)	grad_norm 0.3246 (0.4212)	mem 39782MB
[2023-07-07 10:19:42 RepVGG-A0] (main.py 282): INFO Train: [82/300][60/78]	eta 0:00:33 lr 5.271365	time 1.3683 (1.8667)	loss 3.5927 (3.6408)	grad_norm 0.2857 (0.3992)	mem 39782MB
[2023-07-07 10:19:55 RepVGG-A0] (main.py 282): INFO Train: [82/300][70/78]	eta 0:00:14 lr 5.268089	time 1.1731 (1.7972)	loss 3.5033 (3.6232)	grad_norm 0.2560 (0.3825)	mem 39782MB
[2023-07-07 10:20:08 RepVGG-A0] (main.py 291): INFO EPOCH 82 training takes 0:02:20
[2023-07-07 10:20:29 RepVGG-A0] (main.py 282): INFO Train: [83/300][0/78]	eta 0:27:59 lr 5.265465	time 21.5347 (21.5347)	loss 3.3167 (3.3167)	grad_norm 0.3216 (0.3216)	mem 39782MB
[2023-07-07 10:20:44 RepVGG-A0] (main.py 282): INFO Train: [83/300][10/78]	eta 0:03:42 lr 5.262181	time 1.1728 (3.2721)	loss 3.3740 (3.3302)	grad_norm 0.3384 (0.3006)	mem 39782MB
[2023-07-07 10:20:58 RepVGG-A0] (main.py 282): INFO Train: [83/300][20/78]	eta 0:02:18 lr 5.258894	time 1.1711 (2.3929)	loss 3.3642 (3.3579)	grad_norm 0.3841 (0.3199)	mem 39782MB
[2023-07-07 10:21:14 RepVGG-A0] (main.py 282): INFO Train: [83/300][30/78]	eta 0:01:42 lr 5.255604	time 1.1879 (2.1252)	loss 3.2915 (3.3770)	grad_norm 0.3160 (0.3292)	mem 39782MB
[2023-07-07 10:21:32 RepVGG-A0] (main.py 282): INFO Train: [83/300][40/78]	eta 0:01:18 lr 5.252309	time 4.2953 (2.0620)	loss 3.4030 (3.3670)	grad_norm 0.3920 (0.3250)	mem 39782MB
[2023-07-07 10:21:46 RepVGG-A0] (main.py 282): INFO Train: [83/300][50/78]	eta 0:00:53 lr 5.249011	time 1.1904 (1.9284)	loss 3.3471 (3.3711)	grad_norm 0.3291 (0.3297)	mem 39782MB
[2023-07-07 10:22:02 RepVGG-A0] (main.py 282): INFO Train: [83/300][60/78]	eta 0:00:33 lr 5.245709	time 1.3596 (1.8678)	loss 3.3410 (3.3748)	grad_norm 0.3200 (0.3347)	mem 39782MB
[2023-07-07 10:22:16 RepVGG-A0] (main.py 282): INFO Train: [83/300][70/78]	eta 0:00:14 lr 5.242404	time 1.3839 (1.8115)	loss 3.4485 (3.3716)	grad_norm 0.3974 (0.3345)	mem 39782MB
[2023-07-07 10:22:28 RepVGG-A0] (main.py 291): INFO EPOCH 83 training takes 0:02:20
[2023-07-07 10:22:49 RepVGG-A0] (main.py 282): INFO Train: [84/300][0/78]	eta 0:27:30 lr 5.239757	time 21.1627 (21.1627)	loss 3.6204 (3.6204)	grad_norm 0.5047 (0.5047)	mem 39782MB
[2023-07-07 10:23:03 RepVGG-A0] (main.py 282): INFO Train: [84/300][10/78]	eta 0:03:37 lr 5.236445	time 1.1725 (3.2011)	loss 3.4213 (3.4237)	grad_norm 0.2995 (0.3506)	mem 39782MB
[2023-07-07 10:23:18 RepVGG-A0] (main.py 282): INFO Train: [84/300][20/78]	eta 0:02:19 lr 5.233129	time 1.1721 (2.3991)	loss 3.3437 (3.3955)	grad_norm 0.3304 (0.3447)	mem 39782MB
[2023-07-07 10:23:33 RepVGG-A0] (main.py 282): INFO Train: [84/300][30/78]	eta 0:01:41 lr 5.229809	time 1.3955 (2.1122)	loss 3.4661 (3.3883)	grad_norm 0.4088 (0.3489)	mem 39782MB
[2023-07-07 10:23:51 RepVGG-A0] (main.py 282): INFO Train: [84/300][40/78]	eta 0:01:17 lr 5.226486	time 4.6679 (2.0386)	loss 3.3170 (3.3762)	grad_norm 0.3027 (0.3448)	mem 39782MB
[2023-07-07 10:24:06 RepVGG-A0] (main.py 282): INFO Train: [84/300][50/78]	eta 0:00:53 lr 5.223160	time 1.1722 (1.9238)	loss 3.3853 (3.3743)	grad_norm 0.3730 (0.3488)	mem 39782MB
[2023-07-07 10:24:21 RepVGG-A0] (main.py 282): INFO Train: [84/300][60/78]	eta 0:00:33 lr 5.219829	time 1.1858 (1.8562)	loss 3.3736 (3.3702)	grad_norm 0.4371 (0.3504)	mem 39782MB
[2023-07-07 10:24:36 RepVGG-A0] (main.py 282): INFO Train: [84/300][70/78]	eta 0:00:14 lr 5.216495	time 1.1282 (1.8049)	loss 3.2579 (3.3755)	grad_norm 0.2982 (0.3514)	mem 39782MB
[2023-07-07 10:24:47 RepVGG-A0] (main.py 291): INFO EPOCH 84 training takes 0:02:19
[2023-07-07 10:25:09 RepVGG-A0] (main.py 282): INFO Train: [85/300][0/78]	eta 0:27:58 lr 5.213825	time 21.5201 (21.5201)	loss 3.3516 (3.3516)	grad_norm 0.4159 (0.4159)	mem 39782MB
[2023-07-07 10:25:22 RepVGG-A0] (main.py 282): INFO Train: [85/300][10/78]	eta 0:03:36 lr 5.210485	time 1.1885 (3.1894)	loss 3.9356 (3.6088)	grad_norm 0.5796 (0.5154)	mem 39782MB
[2023-07-07 10:25:37 RepVGG-A0] (main.py 282): INFO Train: [85/300][20/78]	eta 0:02:17 lr 5.207140	time 1.1723 (2.3781)	loss 3.3869 (3.5681)	grad_norm 0.2774 (0.4386)	mem 39782MB
[2023-07-07 10:25:52 RepVGG-A0] (main.py 282): INFO Train: [85/300][30/78]	eta 0:01:40 lr 5.203793	time 1.4346 (2.0931)	loss 3.2913 (3.4962)	grad_norm 0.3069 (0.3939)	mem 39782MB
[2023-07-07 10:26:10 RepVGG-A0] (main.py 282): INFO Train: [85/300][40/78]	eta 0:01:16 lr 5.200441	time 3.6016 (2.0254)	loss 3.2857 (3.4511)	grad_norm 0.3181 (0.3711)	mem 39782MB
[2023-07-07 10:26:25 RepVGG-A0] (main.py 282): INFO Train: [85/300][50/78]	eta 0:00:53 lr 5.197086	time 1.1780 (1.9270)	loss 3.3074 (3.4269)	grad_norm 0.3898 (0.3666)	mem 39782MB
[2023-07-07 10:26:41 RepVGG-A0] (main.py 282): INFO Train: [85/300][60/78]	eta 0:00:33 lr 5.193728	time 1.1811 (1.8618)	loss 3.3403 (3.4146)	grad_norm 0.3192 (0.3636)	mem 39782MB
[2023-07-07 10:26:56 RepVGG-A0] (main.py 282): INFO Train: [85/300][70/78]	eta 0:00:14 lr 5.190365	time 1.3239 (1.8186)	loss 3.2382 (3.3993)	grad_norm 0.3511 (0.3602)	mem 39782MB
[2023-07-07 10:27:07 RepVGG-A0] (main.py 291): INFO EPOCH 85 training takes 0:02:20
[2023-07-07 10:27:28 RepVGG-A0] (main.py 282): INFO Train: [86/300][0/78]	eta 0:27:10 lr 5.187673	time 20.9006 (20.9006)	loss 3.6916 (3.6916)	grad_norm 0.5963 (0.5963)	mem 39782MB
[2023-07-07 10:27:44 RepVGG-A0] (main.py 282): INFO Train: [86/300][10/78]	eta 0:03:45 lr 5.184304	time 1.1718 (3.3181)	loss 5.2114 (4.4778)	grad_norm 0.7889 (0.7841)	mem 39782MB
[2023-07-07 10:27:59 RepVGG-A0] (main.py 282): INFO Train: [86/300][20/78]	eta 0:02:21 lr 5.180932	time 1.3193 (2.4429)	loss 4.1618 (4.5550)	grad_norm 0.2884 (0.6187)	mem 39782MB
[2023-07-07 10:28:14 RepVGG-A0] (main.py 282): INFO Train: [86/300][30/78]	eta 0:01:42 lr 5.177556	time 1.3553 (2.1322)	loss 3.8320 (4.3397)	grad_norm 0.3546 (0.5155)	mem 39782MB
[2023-07-07 10:28:33 RepVGG-A0] (main.py 282): INFO Train: [86/300][40/78]	eta 0:01:18 lr 5.174177	time 4.3424 (2.0779)	loss 3.6217 (4.1703)	grad_norm 0.2587 (0.4501)	mem 39782MB
[2023-07-07 10:28:48 RepVGG-A0] (main.py 282): INFO Train: [86/300][50/78]	eta 0:00:54 lr 5.170794	time 1.3007 (1.9631)	loss 3.5008 (4.0410)	grad_norm 0.2524 (0.4154)	mem 39782MB
[2023-07-07 10:29:03 RepVGG-A0] (main.py 282): INFO Train: [86/300][60/78]	eta 0:00:34 lr 5.167407	time 1.4388 (1.8926)	loss 3.5175 (3.9452)	grad_norm 0.2897 (0.3935)	mem 39782MB
[2023-07-07 10:29:17 RepVGG-A0] (main.py 282): INFO Train: [86/300][70/78]	eta 0:00:14 lr 5.164017	time 1.1862 (1.8205)	loss 3.4244 (3.8744)	grad_norm 0.3005 (0.3827)	mem 39782MB
[2023-07-07 10:29:29 RepVGG-A0] (main.py 291): INFO EPOCH 86 training takes 0:02:21
[2023-07-07 10:29:50 RepVGG-A0] (main.py 282): INFO Train: [87/300][0/78]	eta 0:27:59 lr 5.161303	time 21.5327 (21.5327)	loss 3.3395 (3.3395)	grad_norm 0.3264 (0.3264)	mem 39782MB
[2023-07-07 10:30:06 RepVGG-A0] (main.py 282): INFO Train: [87/300][10/78]	eta 0:03:48 lr 5.157906	time 1.1888 (3.3661)	loss 3.3620 (3.3511)	grad_norm 0.3041 (0.3253)	mem 39782MB
[2023-07-07 10:30:21 RepVGG-A0] (main.py 282): INFO Train: [87/300][20/78]	eta 0:02:23 lr 5.154506	time 1.2151 (2.4707)	loss 3.5573 (3.3716)	grad_norm 0.4556 (0.3385)	mem 39782MB
[2023-07-07 10:30:36 RepVGG-A0] (main.py 282): INFO Train: [87/300][30/78]	eta 0:01:43 lr 5.151103	time 1.4639 (2.1601)	loss 3.3133 (3.3660)	grad_norm 0.3088 (0.3321)	mem 39782MB
[2023-07-07 10:30:54 RepVGG-A0] (main.py 282): INFO Train: [87/300][40/78]	eta 0:01:18 lr 5.147696	time 4.2338 (2.0737)	loss 3.3798 (3.3608)	grad_norm 0.3761 (0.3334)	mem 39782MB
[2023-07-07 10:31:09 RepVGG-A0] (main.py 282): INFO Train: [87/300][50/78]	eta 0:00:54 lr 5.144285	time 1.3378 (1.9597)	loss 3.2881 (3.3589)	grad_norm 0.2973 (0.3326)	mem 39782MB
[2023-07-07 10:31:23 RepVGG-A0] (main.py 282): INFO Train: [87/300][60/78]	eta 0:00:33 lr 5.140871	time 1.1738 (1.8794)	loss 3.4856 (3.3699)	grad_norm 0.3193 (0.3411)	mem 39782MB
[2023-07-07 10:31:39 RepVGG-A0] (main.py 282): INFO Train: [87/300][70/78]	eta 0:00:14 lr 5.137454	time 1.4566 (1.8368)	loss 3.4209 (3.3684)	grad_norm 0.3821 (0.3391)	mem 39782MB
[2023-07-07 10:31:50 RepVGG-A0] (main.py 291): INFO EPOCH 87 training takes 0:02:21
[2023-07-07 10:32:13 RepVGG-A0] (main.py 282): INFO Train: [88/300][0/78]	eta 0:28:45 lr 5.134717	time 22.1185 (22.1185)	loss 3.2950 (3.2950)	grad_norm 0.3599 (0.3599)	mem 39782MB
[2023-07-07 10:32:28 RepVGG-A0] (main.py 282): INFO Train: [88/300][10/78]	eta 0:03:53 lr 5.131293	time 1.1900 (3.4378)	loss 3.3095 (3.3421)	grad_norm 0.3363 (0.3783)	mem 39782MB
[2023-07-07 10:32:43 RepVGG-A0] (main.py 282): INFO Train: [88/300][20/78]	eta 0:02:25 lr 5.127866	time 1.3492 (2.5151)	loss 3.2801 (3.3181)	grad_norm 0.3279 (0.3545)	mem 39782MB
[2023-07-07 10:32:58 RepVGG-A0] (main.py 282): INFO Train: [88/300][30/78]	eta 0:01:44 lr 5.124435	time 1.3849 (2.1772)	loss 3.3608 (3.3183)	grad_norm 0.3467 (0.3561)	mem 39782MB
[2023-07-07 10:33:16 RepVGG-A0] (main.py 282): INFO Train: [88/300][40/78]	eta 0:01:19 lr 5.121001	time 4.8553 (2.0932)	loss 3.4851 (3.3220)	grad_norm 0.4504 (0.3562)	mem 39782MB
[2023-07-07 10:33:30 RepVGG-A0] (main.py 282): INFO Train: [88/300][50/78]	eta 0:00:54 lr 5.117563	time 1.1749 (1.9611)	loss 5.5669 (3.5996)	grad_norm 0.5972 (0.4390)	mem 39782MB
[2023-07-07 10:33:46 RepVGG-A0] (main.py 282): INFO Train: [88/300][60/78]	eta 0:00:34 lr 5.114122	time 1.1450 (1.8951)	loss 4.4626 (3.8343)	grad_norm 0.2926 (0.4385)	mem 39782MB
[2023-07-07 10:34:01 RepVGG-A0] (main.py 282): INFO Train: [88/300][70/78]	eta 0:00:14 lr 5.110678	time 1.2927 (1.8377)	loss 4.0119 (3.8900)	grad_norm 0.2949 (0.4208)	mem 39782MB
[2023-07-07 10:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 88 training takes 0:02:23
[2023-07-07 10:34:36 RepVGG-A0] (main.py 282): INFO Train: [89/300][0/78]	eta 0:28:39 lr 5.107920	time 22.0470 (22.0470)	loss 3.7292 (3.7292)	grad_norm 0.2494 (0.2494)	mem 39782MB
[2023-07-07 10:34:50 RepVGG-A0] (main.py 282): INFO Train: [89/300][10/78]	eta 0:03:46 lr 5.104469	time 1.1910 (3.3365)	loss 3.6854 (3.7083)	grad_norm 0.2979 (0.2737)	mem 39782MB
[2023-07-07 10:35:05 RepVGG-A0] (main.py 282): INFO Train: [89/300][20/78]	eta 0:02:22 lr 5.101015	time 1.3326 (2.4510)	loss 3.5901 (3.6459)	grad_norm 0.3213 (0.2793)	mem 39782MB
[2023-07-07 10:35:19 RepVGG-A0] (main.py 282): INFO Train: [89/300][30/78]	eta 0:01:41 lr 5.097557	time 1.4530 (2.1223)	loss 3.5354 (3.6088)	grad_norm 0.3384 (0.2874)	mem 39782MB
[2023-07-07 10:35:37 RepVGG-A0] (main.py 282): INFO Train: [89/300][40/78]	eta 0:01:17 lr 5.094096	time 3.2327 (2.0434)	loss 3.3856 (3.5809)	grad_norm 0.2683 (0.2941)	mem 39782MB
[2023-07-07 10:35:52 RepVGG-A0] (main.py 282): INFO Train: [89/300][50/78]	eta 0:00:54 lr 5.090631	time 1.1895 (1.9342)	loss 3.4640 (3.5555)	grad_norm 0.3317 (0.2978)	mem 39782MB
[2023-07-07 10:36:08 RepVGG-A0] (main.py 282): INFO Train: [89/300][60/78]	eta 0:00:33 lr 5.087164	time 1.3169 (1.8693)	loss 3.3439 (3.5353)	grad_norm 0.3111 (0.3032)	mem 39782MB
[2023-07-07 10:36:23 RepVGG-A0] (main.py 282): INFO Train: [89/300][70/78]	eta 0:00:14 lr 5.083692	time 1.2695 (1.8231)	loss 3.4711 (3.5206)	grad_norm 0.3837 (0.3085)	mem 39782MB
[2023-07-07 10:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 89 training takes 0:02:20
[2023-07-07 10:36:55 RepVGG-A0] (main.py 282): INFO Train: [90/300][0/78]	eta 0:27:59 lr 5.080913	time 21.5353 (21.5353)	loss 3.3517 (3.3517)	grad_norm 0.2854 (0.2854)	mem 39782MB
[2023-07-07 10:37:11 RepVGG-A0] (main.py 282): INFO Train: [90/300][10/78]	eta 0:03:49 lr 5.077435	time 1.1719 (3.3732)	loss 3.5993 (3.4873)	grad_norm 0.4454 (0.4168)	mem 39782MB
[2023-07-07 10:37:25 RepVGG-A0] (main.py 282): INFO Train: [90/300][20/78]	eta 0:02:21 lr 5.073955	time 1.1969 (2.4338)	loss 3.4562 (3.4868)	grad_norm 0.2934 (0.3839)	mem 39782MB
[2023-07-07 10:37:40 RepVGG-A0] (main.py 282): INFO Train: [90/300][30/78]	eta 0:01:42 lr 5.070470	time 1.4439 (2.1455)	loss 3.3036 (3.4446)	grad_norm 0.3416 (0.3664)	mem 39782MB
[2023-07-07 10:37:58 RepVGG-A0] (main.py 282): INFO Train: [90/300][40/78]	eta 0:01:18 lr 5.066983	time 3.7091 (2.0611)	loss 3.2279 (3.4175)	grad_norm 0.2938 (0.3541)	mem 39782MB
[2023-07-07 10:38:14 RepVGG-A0] (main.py 282): INFO Train: [90/300][50/78]	eta 0:00:54 lr 5.063492	time 1.1716 (1.9557)	loss 3.5066 (3.4110)	grad_norm 0.4873 (0.3578)	mem 39782MB
[2023-07-07 10:38:28 RepVGG-A0] (main.py 282): INFO Train: [90/300][60/78]	eta 0:00:33 lr 5.059998	time 1.2984 (1.8725)	loss 5.2180 (3.5982)	grad_norm 0.6534 (0.4244)	mem 39782MB
[2023-07-07 10:38:43 RepVGG-A0] (main.py 282): INFO Train: [90/300][70/78]	eta 0:00:14 lr 5.056500	time 1.2077 (1.8233)	loss 4.0133 (3.7183)	grad_norm 0.2893 (0.4222)	mem 39782MB
[2023-07-07 10:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 90 training takes 0:02:20
[2023-07-07 10:39:17 RepVGG-A0] (main.py 282): INFO Train: [91/300][0/78]	eta 0:28:44 lr 5.053700	time 22.1084 (22.1084)	loss 3.7336 (3.7336)	grad_norm 0.2900 (0.2900)	mem 39782MB
[2023-07-07 10:39:31 RepVGG-A0] (main.py 282): INFO Train: [91/300][10/78]	eta 0:03:42 lr 5.050196	time 1.1736 (3.2775)	loss 3.5556 (3.6512)	grad_norm 0.3048 (0.2744)	mem 39782MB
[2023-07-07 10:39:46 RepVGG-A0] (main.py 282): INFO Train: [91/300][20/78]	eta 0:02:20 lr 5.046689	time 1.3497 (2.4218)	loss 3.3748 (3.5845)	grad_norm 0.2436 (0.2787)	mem 39782MB
[2023-07-07 10:40:02 RepVGG-A0] (main.py 282): INFO Train: [91/300][30/78]	eta 0:01:44 lr 5.043179	time 1.8001 (2.1789)	loss 3.3930 (3.5406)	grad_norm 0.2710 (0.2819)	mem 39782MB
[2023-07-07 10:40:18 RepVGG-A0] (main.py 282): INFO Train: [91/300][40/78]	eta 0:01:16 lr 5.039665	time 2.4634 (2.0241)	loss 3.3849 (3.5170)	grad_norm 0.2918 (0.2888)	mem 39782MB
[2023-07-07 10:40:33 RepVGG-A0] (main.py 282): INFO Train: [91/300][50/78]	eta 0:00:53 lr 5.036148	time 1.1726 (1.9249)	loss 3.4245 (3.4953)	grad_norm 0.3607 (0.2909)	mem 39782MB
[2023-07-07 10:40:48 RepVGG-A0] (main.py 282): INFO Train: [91/300][60/78]	eta 0:00:33 lr 5.032628	time 1.1999 (1.8509)	loss 3.5262 (3.4878)	grad_norm 0.3677 (0.3011)	mem 39782MB
[2023-07-07 10:41:03 RepVGG-A0] (main.py 282): INFO Train: [91/300][70/78]	eta 0:00:14 lr 5.029105	time 1.3187 (1.8084)	loss 3.3171 (3.4683)	grad_norm 0.3018 (0.3001)	mem 39782MB
[2023-07-07 10:41:15 RepVGG-A0] (main.py 291): INFO EPOCH 91 training takes 0:02:20
[2023-07-07 10:41:36 RepVGG-A0] (main.py 282): INFO Train: [92/300][0/78]	eta 0:27:24 lr 5.026283	time 21.0852 (21.0852)	loss 3.5588 (3.5588)	grad_norm 0.4467 (0.4467)	mem 39782MB
[2023-07-07 10:41:51 RepVGG-A0] (main.py 282): INFO Train: [92/300][10/78]	eta 0:03:42 lr 5.022754	time 1.1723 (3.2681)	loss 3.3713 (3.4110)	grad_norm 0.3085 (0.3474)	mem 39782MB
[2023-07-07 10:42:05 RepVGG-A0] (main.py 282): INFO Train: [92/300][20/78]	eta 0:02:18 lr 5.019221	time 1.1721 (2.3881)	loss 3.3344 (3.3794)	grad_norm 0.3563 (0.3408)	mem 39782MB
[2023-07-07 10:42:20 RepVGG-A0] (main.py 282): INFO Train: [92/300][30/78]	eta 0:01:41 lr 5.015685	time 1.4380 (2.1110)	loss 3.3780 (3.3670)	grad_norm 0.3890 (0.3458)	mem 39782MB
[2023-07-07 10:42:38 RepVGG-A0] (main.py 282): INFO Train: [92/300][40/78]	eta 0:01:16 lr 5.012146	time 4.2061 (2.0247)	loss 3.3072 (3.3660)	grad_norm 0.3086 (0.3479)	mem 39782MB
[2023-07-07 10:42:53 RepVGG-A0] (main.py 282): INFO Train: [92/300][50/78]	eta 0:00:53 lr 5.008603	time 1.1738 (1.9233)	loss 3.3686 (3.3537)	grad_norm 0.3969 (0.3440)	mem 39782MB
[2023-07-07 10:43:09 RepVGG-A0] (main.py 282): INFO Train: [92/300][60/78]	eta 0:00:33 lr 5.005057	time 1.3664 (1.8609)	loss 3.3457 (3.3742)	grad_norm 0.3106 (0.3543)	mem 39782MB
[2023-07-07 10:43:23 RepVGG-A0] (main.py 282): INFO Train: [92/300][70/78]	eta 0:00:14 lr 5.001508	time 1.3670 (1.8085)	loss 3.3091 (3.3658)	grad_norm 0.3792 (0.3507)	mem 39782MB
[2023-07-07 10:43:35 RepVGG-A0] (main.py 291): INFO EPOCH 92 training takes 0:02:20
[2023-07-07 10:43:57 RepVGG-A0] (main.py 282): INFO Train: [93/300][0/78]	eta 0:28:37 lr 4.998667	time 22.0245 (22.0245)	loss 3.5093 (3.5093)	grad_norm 0.4690 (0.4690)	mem 39782MB
[2023-07-07 10:44:12 RepVGG-A0] (main.py 282): INFO Train: [93/300][10/78]	eta 0:03:46 lr 4.995112	time 1.1737 (3.3374)	loss 3.3760 (3.3620)	grad_norm 0.3758 (0.3627)	mem 39782MB
[2023-07-07 10:44:26 RepVGG-A0] (main.py 282): INFO Train: [93/300][20/78]	eta 0:02:18 lr 4.991554	time 1.1725 (2.3944)	loss 3.3088 (3.3244)	grad_norm 0.3243 (0.3417)	mem 39782MB
[2023-07-07 10:44:41 RepVGG-A0] (main.py 282): INFO Train: [93/300][30/78]	eta 0:01:42 lr 4.987992	time 1.4259 (2.1329)	loss 3.3883 (3.3245)	grad_norm 0.3700 (0.3540)	mem 39782MB
[2023-07-07 10:44:59 RepVGG-A0] (main.py 282): INFO Train: [93/300][40/78]	eta 0:01:17 lr 4.984428	time 3.4637 (2.0380)	loss 3.2886 (3.3262)	grad_norm 0.3630 (0.3527)	mem 39782MB
[2023-07-07 10:45:14 RepVGG-A0] (main.py 282): INFO Train: [93/300][50/78]	eta 0:00:54 lr 4.980860	time 1.1734 (1.9331)	loss 3.2454 (3.3208)	grad_norm 0.3187 (0.3509)	mem 39782MB
[2023-07-07 10:45:29 RepVGG-A0] (main.py 282): INFO Train: [93/300][60/78]	eta 0:00:33 lr 4.977289	time 1.2995 (1.8633)	loss 3.7857 (3.3537)	grad_norm 0.5721 (0.3726)	mem 39782MB
[2023-07-07 10:45:44 RepVGG-A0] (main.py 282): INFO Train: [93/300][70/78]	eta 0:00:14 lr 4.973715	time 1.3715 (1.8134)	loss 3.3748 (3.3911)	grad_norm 0.2790 (0.3798)	mem 39782MB
[2023-07-07 10:45:56 RepVGG-A0] (main.py 291): INFO EPOCH 93 training takes 0:02:20
[2023-07-07 10:46:16 RepVGG-A0] (main.py 282): INFO Train: [94/300][0/78]	eta 0:26:00 lr 4.970853	time 20.0105 (20.0105)	loss 3.2146 (3.2146)	grad_norm 0.2970 (0.2970)	mem 39782MB
[2023-07-07 10:46:33 RepVGG-A0] (main.py 282): INFO Train: [94/300][10/78]	eta 0:03:47 lr 4.967273	time 1.1709 (3.3421)	loss 3.2600 (3.2522)	grad_norm 0.3257 (0.3105)	mem 39782MB
[2023-07-07 10:46:49 RepVGG-A0] (main.py 282): INFO Train: [94/300][20/78]	eta 0:02:25 lr 4.963690	time 1.1781 (2.5047)	loss 3.2773 (3.2643)	grad_norm 0.3192 (0.3282)	mem 39782MB
[2023-07-07 10:47:05 RepVGG-A0] (main.py 282): INFO Train: [94/300][30/78]	eta 0:01:46 lr 4.960103	time 1.9005 (2.2207)	loss 3.3610 (3.2621)	grad_norm 0.3676 (0.3276)	mem 39782MB
[2023-07-07 10:47:21 RepVGG-A0] (main.py 282): INFO Train: [94/300][40/78]	eta 0:01:18 lr 4.956514	time 2.0018 (2.0733)	loss 3.4193 (3.3050)	grad_norm 0.3815 (0.3565)	mem 39782MB
[2023-07-07 10:47:36 RepVGG-A0] (main.py 282): INFO Train: [94/300][50/78]	eta 0:00:54 lr 4.952921	time 1.1943 (1.9621)	loss 3.2495 (3.3043)	grad_norm 0.3048 (0.3481)	mem 39782MB
[2023-07-07 10:47:51 RepVGG-A0] (main.py 282): INFO Train: [94/300][60/78]	eta 0:00:33 lr 4.949325	time 1.1868 (1.8828)	loss 3.3676 (3.3024)	grad_norm 0.3780 (0.3469)	mem 39782MB
[2023-07-07 10:48:06 RepVGG-A0] (main.py 282): INFO Train: [94/300][70/78]	eta 0:00:14 lr 4.945726	time 1.4561 (1.8247)	loss 3.2160 (3.3000)	grad_norm 0.3318 (0.3462)	mem 39782MB
[2023-07-07 10:48:18 RepVGG-A0] (main.py 291): INFO EPOCH 94 training takes 0:02:21
[2023-07-07 10:48:40 RepVGG-A0] (main.py 282): INFO Train: [95/300][0/78]	eta 0:28:41 lr 4.942845	time 22.0657 (22.0657)	loss 3.3637 (3.3637)	grad_norm 0.4473 (0.4473)	mem 39782MB
[2023-07-07 10:48:54 RepVGG-A0] (main.py 282): INFO Train: [95/300][10/78]	eta 0:03:44 lr 4.939240	time 1.1719 (3.3045)	loss 3.2836 (3.3649)	grad_norm 0.3206 (0.3940)	mem 39782MB
[2023-07-07 10:49:10 RepVGG-A0] (main.py 282): INFO Train: [95/300][20/78]	eta 0:02:23 lr 4.935632	time 1.3265 (2.4718)	loss 3.2443 (3.2975)	grad_norm 0.3305 (0.3543)	mem 39782MB
[2023-07-07 10:49:25 RepVGG-A0] (main.py 282): INFO Train: [95/300][30/78]	eta 0:01:44 lr 4.932022	time 1.4706 (2.1710)	loss 3.3037 (3.2955)	grad_norm 0.4079 (0.3655)	mem 39782MB
[2023-07-07 10:49:42 RepVGG-A0] (main.py 282): INFO Train: [95/300][40/78]	eta 0:01:17 lr 4.928407	time 2.7055 (2.0467)	loss 3.2571 (3.2997)	grad_norm 0.3472 (0.3665)	mem 39782MB
[2023-07-07 10:49:57 RepVGG-A0] (main.py 282): INFO Train: [95/300][50/78]	eta 0:00:54 lr 4.924790	time 1.1721 (1.9471)	loss 3.2607 (3.2927)	grad_norm 0.4050 (0.3629)	mem 39782MB
[2023-07-07 10:50:12 RepVGG-A0] (main.py 282): INFO Train: [95/300][60/78]	eta 0:00:33 lr 4.921170	time 1.5163 (1.8694)	loss 3.2253 (3.3034)	grad_norm 0.2904 (0.3676)	mem 39782MB
[2023-07-07 10:50:26 RepVGG-A0] (main.py 282): INFO Train: [95/300][70/78]	eta 0:00:14 lr 4.917547	time 1.3079 (1.8124)	loss 3.3100 (3.3022)	grad_norm 0.3459 (0.3644)	mem 39782MB
[2023-07-07 10:50:38 RepVGG-A0] (main.py 291): INFO EPOCH 95 training takes 0:02:20
[2023-07-07 10:50:59 RepVGG-A0] (main.py 282): INFO Train: [96/300][0/78]	eta 0:27:11 lr 4.914646	time 20.9185 (20.9185)	loss 3.4190 (3.4190)	grad_norm 0.4653 (0.4653)	mem 39782MB
[2023-07-07 10:51:14 RepVGG-A0] (main.py 282): INFO Train: [96/300][10/78]	eta 0:03:40 lr 4.911017	time 1.1921 (3.2447)	loss 6.3825 (4.4489)	grad_norm 0.8510 (0.8143)	mem 39782MB
[2023-07-07 10:51:29 RepVGG-A0] (main.py 282): INFO Train: [96/300][20/78]	eta 0:02:19 lr 4.907385	time 1.1723 (2.4007)	loss 5.1937 (5.0990)	grad_norm 0.2901 (0.6619)	mem 39782MB
[2023-07-07 10:51:43 RepVGG-A0] (main.py 282): INFO Train: [96/300][30/78]	eta 0:01:40 lr 4.903750	time 1.1846 (2.0925)	loss 4.5063 (5.0169)	grad_norm 0.2770 (0.5503)	mem 39782MB
[2023-07-07 10:52:02 RepVGG-A0] (main.py 282): INFO Train: [96/300][40/78]	eta 0:01:17 lr 4.900111	time 4.2237 (2.0282)	loss 4.1414 (4.8554)	grad_norm 0.2482 (0.4951)	mem 39782MB
[2023-07-07 10:52:16 RepVGG-A0] (main.py 282): INFO Train: [96/300][50/78]	eta 0:00:53 lr 4.896470	time 1.1721 (1.9157)	loss 3.8642 (4.6907)	grad_norm 0.2669 (0.4522)	mem 39782MB
[2023-07-07 10:52:31 RepVGG-A0] (main.py 282): INFO Train: [96/300][60/78]	eta 0:00:33 lr 4.892826	time 1.2331 (1.8457)	loss 3.7878 (4.5478)	grad_norm 0.3133 (0.4259)	mem 39782MB
[2023-07-07 10:52:47 RepVGG-A0] (main.py 282): INFO Train: [96/300][70/78]	eta 0:00:14 lr 4.889179	time 1.2862 (1.8049)	loss 3.7491 (4.4345)	grad_norm 0.3464 (0.4095)	mem 39782MB
[2023-07-07 10:52:58 RepVGG-A0] (main.py 291): INFO EPOCH 96 training takes 0:02:19
[2023-07-07 10:53:20 RepVGG-A0] (main.py 282): INFO Train: [97/300][0/78]	eta 0:28:42 lr 4.886259	time 22.0844 (22.0844)	loss 3.6007 (3.6007)	grad_norm 0.2730 (0.2730)	mem 39782MB
[2023-07-07 10:53:35 RepVGG-A0] (main.py 282): INFO Train: [97/300][10/78]	eta 0:03:44 lr 4.882606	time 1.1889 (3.3028)	loss 3.5053 (3.5604)	grad_norm 0.3142 (0.3169)	mem 39782MB
[2023-07-07 10:53:49 RepVGG-A0] (main.py 282): INFO Train: [97/300][20/78]	eta 0:02:19 lr 4.878950	time 1.1273 (2.4028)	loss 3.5421 (3.5501)	grad_norm 0.3494 (0.3215)	mem 39782MB
[2023-07-07 10:54:05 RepVGG-A0] (main.py 282): INFO Train: [97/300][30/78]	eta 0:01:43 lr 4.875291	time 1.2961 (2.1478)	loss 3.5625 (3.5486)	grad_norm 0.3804 (0.3323)	mem 39782MB
[2023-07-07 10:54:23 RepVGG-A0] (main.py 282): INFO Train: [97/300][40/78]	eta 0:01:17 lr 4.871629	time 3.2720 (2.0526)	loss 3.5043 (3.5319)	grad_norm 0.3200 (0.3301)	mem 39782MB
[2023-07-07 10:54:37 RepVGG-A0] (main.py 282): INFO Train: [97/300][50/78]	eta 0:00:54 lr 4.867964	time 1.1773 (1.9364)	loss 3.4139 (3.5292)	grad_norm 0.3250 (0.3386)	mem 39782MB
[2023-07-07 10:54:52 RepVGG-A0] (main.py 282): INFO Train: [97/300][60/78]	eta 0:00:33 lr 4.864296	time 1.2680 (1.8703)	loss 3.4911 (3.5217)	grad_norm 0.3264 (0.3380)	mem 39782MB
[2023-07-07 10:55:07 RepVGG-A0] (main.py 282): INFO Train: [97/300][70/78]	eta 0:00:14 lr 4.860625	time 1.2205 (1.8150)	loss 3.5218 (3.5162)	grad_norm 0.3968 (0.3426)	mem 39782MB
[2023-07-07 10:55:19 RepVGG-A0] (main.py 291): INFO EPOCH 97 training takes 0:02:20
[2023-07-07 10:55:40 RepVGG-A0] (main.py 282): INFO Train: [98/300][0/78]	eta 0:27:52 lr 4.857686	time 21.4414 (21.4414)	loss 3.3418 (3.3418)	grad_norm 0.3202 (0.3202)	mem 39782MB
[2023-07-07 10:55:54 RepVGG-A0] (main.py 282): INFO Train: [98/300][10/78]	eta 0:03:39 lr 4.854010	time 1.1926 (3.2293)	loss 3.5461 (3.5105)	grad_norm 0.3928 (0.4157)	mem 39782MB
[2023-07-07 10:56:09 RepVGG-A0] (main.py 282): INFO Train: [98/300][20/78]	eta 0:02:20 lr 4.850331	time 1.2980 (2.4227)	loss 3.3849 (3.4622)	grad_norm 0.3147 (0.3766)	mem 39782MB
[2023-07-07 10:56:24 RepVGG-A0] (main.py 282): INFO Train: [98/300][30/78]	eta 0:01:41 lr 4.846649	time 1.2454 (2.1180)	loss 3.3257 (3.4269)	grad_norm 0.3499 (0.3597)	mem 39782MB
[2023-07-07 10:56:42 RepVGG-A0] (main.py 282): INFO Train: [98/300][40/78]	eta 0:01:17 lr 4.842963	time 3.2573 (2.0461)	loss 3.4659 (3.4170)	grad_norm 0.4264 (0.3585)	mem 39782MB
[2023-07-07 10:56:57 RepVGG-A0] (main.py 282): INFO Train: [98/300][50/78]	eta 0:00:54 lr 4.839275	time 1.1727 (1.9390)	loss 3.5331 (3.4352)	grad_norm 0.3982 (0.3720)	mem 39782MB
[2023-07-07 10:57:13 RepVGG-A0] (main.py 282): INFO Train: [98/300][60/78]	eta 0:00:33 lr 4.835584	time 1.4566 (1.8701)	loss 3.3276 (3.4235)	grad_norm 0.3177 (0.3655)	mem 39782MB
[2023-07-07 10:57:28 RepVGG-A0] (main.py 282): INFO Train: [98/300][70/78]	eta 0:00:14 lr 4.831890	time 1.1601 (1.8190)	loss 3.3433 (3.4117)	grad_norm 0.3478 (0.3604)	mem 39782MB
[2023-07-07 10:57:40 RepVGG-A0] (main.py 291): INFO EPOCH 98 training takes 0:02:21
[2023-07-07 10:58:02 RepVGG-A0] (main.py 282): INFO Train: [99/300][0/78]	eta 0:28:09 lr 4.828933	time 21.6570 (21.6570)	loss 3.3884 (3.3884)	grad_norm 0.4066 (0.4066)	mem 39782MB
[2023-07-07 10:58:16 RepVGG-A0] (main.py 282): INFO Train: [99/300][10/78]	eta 0:03:40 lr 4.825233	time 1.1713 (3.2462)	loss 3.5110 (3.4370)	grad_norm 0.3805 (0.4299)	mem 39782MB
[2023-07-07 10:58:29 RepVGG-A0] (main.py 282): INFO Train: [99/300][20/78]	eta 0:02:15 lr 4.821531	time 1.1716 (2.3422)	loss 3.1940 (3.3659)	grad_norm 0.3074 (0.3755)	mem 39782MB
[2023-07-07 10:58:44 RepVGG-A0] (main.py 282): INFO Train: [99/300][30/78]	eta 0:01:39 lr 4.817826	time 1.1281 (2.0636)	loss 3.3992 (3.3498)	grad_norm 0.3995 (0.3717)	mem 39782MB
[2023-07-07 10:59:03 RepVGG-A0] (main.py 282): INFO Train: [99/300][40/78]	eta 0:01:16 lr 4.814117	time 4.4695 (2.0137)	loss 3.8188 (3.4087)	grad_norm 0.5800 (0.4067)	mem 39782MB
[2023-07-07 10:59:17 RepVGG-A0] (main.py 282): INFO Train: [99/300][50/78]	eta 0:00:53 lr 4.810406	time 1.2285 (1.9040)	loss 3.3842 (3.4295)	grad_norm 0.3095 (0.3978)	mem 39782MB
[2023-07-07 10:59:33 RepVGG-A0] (main.py 282): INFO Train: [99/300][60/78]	eta 0:00:33 lr 4.806692	time 1.1879 (1.8421)	loss 3.3354 (3.4164)	grad_norm 0.3078 (0.3838)	mem 39782MB
[2023-07-07 10:59:48 RepVGG-A0] (main.py 282): INFO Train: [99/300][70/78]	eta 0:00:14 lr 4.802976	time 1.2296 (1.7955)	loss 3.3382 (3.4034)	grad_norm 0.3218 (0.3770)	mem 39782MB
[2023-07-07 10:59:59 RepVGG-A0] (main.py 291): INFO EPOCH 99 training takes 0:02:18
[2023-07-07 11:00:20 RepVGG-A0] (main.py 282): INFO Train: [100/300][0/78]	eta 0:27:03 lr 4.800000	time 20.8197 (20.8197)	loss 3.3411 (3.3411)	grad_norm 0.3370 (0.3370)	mem 39782MB
[2023-07-07 11:00:33 RepVGG-A0] (main.py 282): INFO Train: [100/300][10/78]	eta 0:03:33 lr 4.796278	time 1.1734 (3.1333)	loss 3.2601 (3.3195)	grad_norm 0.3589 (0.3672)	mem 39782MB
[2023-07-07 11:00:48 RepVGG-A0] (main.py 282): INFO Train: [100/300][20/78]	eta 0:02:15 lr 4.792553	time 1.1714 (2.3347)	loss 3.2796 (3.3044)	grad_norm 0.3386 (0.3572)	mem 39782MB
[2023-07-07 11:01:03 RepVGG-A0] (main.py 282): INFO Train: [100/300][30/78]	eta 0:01:39 lr 4.788825	time 1.2665 (2.0798)	loss 3.3324 (3.3150)	grad_norm 0.3677 (0.3633)	mem 39782MB
[2023-07-07 11:01:21 RepVGG-A0] (main.py 282): INFO Train: [100/300][40/78]	eta 0:01:16 lr 4.785095	time 3.3962 (2.0031)	loss 3.2975 (3.3115)	grad_norm 0.3622 (0.3610)	mem 39782MB
[2023-07-07 11:01:36 RepVGG-A0] (main.py 282): INFO Train: [100/300][50/78]	eta 0:00:53 lr 4.781361	time 1.2910 (1.9046)	loss 3.3134 (3.3112)	grad_norm 0.3899 (0.3616)	mem 39782MB
[2023-07-07 11:01:51 RepVGG-A0] (main.py 282): INFO Train: [100/300][60/78]	eta 0:00:33 lr 4.777625	time 1.1935 (1.8359)	loss 3.3965 (3.3144)	grad_norm 0.3464 (0.3632)	mem 39782MB
[2023-07-07 11:02:06 RepVGG-A0] (main.py 282): INFO Train: [100/300][70/78]	eta 0:00:14 lr 4.773885	time 1.2159 (1.7930)	loss 3.4140 (3.3166)	grad_norm 0.4160 (0.3661)	mem 39782MB
[2023-07-07 11:02:18 RepVGG-A0] (main.py 291): INFO EPOCH 100 training takes 0:02:19
[2023-07-07 11:02:36 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.352 (17.352)	Loss 2.8196 (2.8196)	Acc@1 40.741 (40.741)	Acc@5 66.449 (66.449)	Mem 39782MB
[2023-07-07 11:02:37 RepVGG-A0] (main.py 342): INFO  * Acc@1 40.988 Acc@5 66.530
[2023-07-07 11:02:37 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 100: 40.988%
[2023-07-07 11:02:37 RepVGG-A0] (main.py 172): INFO Max accuracy: 40.99%
[2023-07-07 11:02:58 RepVGG-A0] (main.py 282): INFO Train: [101/300][0/78]	eta 0:27:24 lr 4.770892	time 21.0849 (21.0849)	loss 3.1169 (3.1169)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 11:03:15 RepVGG-A0] (main.py 282): INFO Train: [101/300][10/78]	eta 0:03:57 lr 4.767148	time 1.1761 (3.4952)	loss 3.2953 (3.2334)	grad_norm 0.3965 (0.3596)	mem 39782MB
[2023-07-07 11:03:29 RepVGG-A0] (main.py 282): INFO Train: [101/300][20/78]	eta 0:02:24 lr 4.763401	time 1.1765 (2.4880)	loss 3.2907 (3.2647)	grad_norm 0.3963 (0.3756)	mem 39782MB
[2023-07-07 11:03:45 RepVGG-A0] (main.py 282): INFO Train: [101/300][30/78]	eta 0:01:45 lr 4.759651	time 1.5063 (2.1876)	loss 3.3363 (3.2780)	grad_norm 0.3679 (0.3772)	mem 39782MB
[2023-07-07 11:04:03 RepVGG-A0] (main.py 282): INFO Train: [101/300][40/78]	eta 0:01:19 lr 4.755898	time 4.5346 (2.1032)	loss 3.2006 (3.2631)	grad_norm 0.3157 (0.3655)	mem 39782MB
[2023-07-07 11:04:17 RepVGG-A0] (main.py 282): INFO Train: [101/300][50/78]	eta 0:00:55 lr 4.752142	time 1.3051 (1.9698)	loss 6.4544 (3.4941)	grad_norm 0.9319 (0.4543)	mem 39782MB
[2023-07-07 11:04:33 RepVGG-A0] (main.py 282): INFO Train: [101/300][60/78]	eta 0:00:34 lr 4.748384	time 1.1941 (1.8959)	loss 5.5042 (3.9004)	grad_norm 0.3905 (0.4563)	mem 39782MB
[2023-07-07 11:04:48 RepVGG-A0] (main.py 282): INFO Train: [101/300][70/78]	eta 0:00:14 lr 4.744623	time 1.4282 (1.8464)	loss 4.7982 (4.0756)	grad_norm 0.2919 (0.4443)	mem 39782MB
[2023-07-07 11:04:58 RepVGG-A0] (main.py 291): INFO EPOCH 101 training takes 0:02:21
[2023-07-07 11:05:20 RepVGG-A0] (main.py 282): INFO Train: [102/300][0/78]	eta 0:27:43 lr 4.741612	time 21.3214 (21.3214)	loss 4.3462 (4.3462)	grad_norm 0.2890 (0.2890)	mem 39782MB
[2023-07-07 11:05:34 RepVGG-A0] (main.py 282): INFO Train: [102/300][10/78]	eta 0:03:41 lr 4.737846	time 1.1711 (3.2637)	loss 4.2247 (4.2721)	grad_norm 0.3381 (0.3161)	mem 39782MB
[2023-07-07 11:05:49 RepVGG-A0] (main.py 282): INFO Train: [102/300][20/78]	eta 0:02:19 lr 4.734077	time 1.1736 (2.3971)	loss 3.8797 (4.1715)	grad_norm 0.3016 (0.3182)	mem 39782MB
[2023-07-07 11:06:04 RepVGG-A0] (main.py 282): INFO Train: [102/300][30/78]	eta 0:01:41 lr 4.730305	time 1.1674 (2.1234)	loss 3.9775 (4.0840)	grad_norm 0.4031 (0.3212)	mem 39782MB
[2023-07-07 11:06:23 RepVGG-A0] (main.py 282): INFO Train: [102/300][40/78]	eta 0:01:18 lr 4.726530	time 3.8066 (2.0628)	loss 3.7954 (4.0145)	grad_norm 0.3427 (0.3224)	mem 39782MB
[2023-07-07 11:06:38 RepVGG-A0] (main.py 282): INFO Train: [102/300][50/78]	eta 0:00:54 lr 4.722753	time 1.2349 (1.9467)	loss 3.7500 (3.9536)	grad_norm 0.3630 (0.3240)	mem 39782MB
[2023-07-07 11:06:53 RepVGG-A0] (main.py 282): INFO Train: [102/300][60/78]	eta 0:00:33 lr 4.718973	time 1.1781 (1.8724)	loss 3.6691 (3.9093)	grad_norm 0.3410 (0.3284)	mem 39782MB
[2023-07-07 11:07:07 RepVGG-A0] (main.py 282): INFO Train: [102/300][70/78]	eta 0:00:14 lr 4.715191	time 1.2456 (1.8155)	loss 3.5757 (3.8623)	grad_norm 0.3241 (0.3260)	mem 39782MB
[2023-07-07 11:07:19 RepVGG-A0] (main.py 291): INFO EPOCH 102 training takes 0:02:20
[2023-07-07 11:07:42 RepVGG-A0] (main.py 282): INFO Train: [103/300][0/78]	eta 0:30:06 lr 4.712162	time 23.1581 (23.1581)	loss 3.6210 (3.6210)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 11:07:58 RepVGG-A0] (main.py 282): INFO Train: [103/300][10/78]	eta 0:04:02 lr 4.708375	time 1.2898 (3.5700)	loss 3.4799 (3.5438)	grad_norm 0.3307 (0.3436)	mem 39782MB
[2023-07-07 11:08:12 RepVGG-A0] (main.py 282): INFO Train: [103/300][20/78]	eta 0:02:28 lr 4.704585	time 1.1726 (2.5535)	loss 3.6285 (3.5220)	grad_norm 0.4160 (0.3458)	mem 39782MB
[2023-07-07 11:08:29 RepVGG-A0] (main.py 282): INFO Train: [103/300][30/78]	eta 0:01:48 lr 4.700791	time 1.6582 (2.2639)	loss 3.5653 (3.5134)	grad_norm 0.3507 (0.3477)	mem 39782MB
[2023-07-07 11:08:46 RepVGG-A0] (main.py 282): INFO Train: [103/300][40/78]	eta 0:01:20 lr 4.696996	time 4.1498 (2.1221)	loss 3.5607 (3.5120)	grad_norm 0.4226 (0.3557)	mem 39782MB
[2023-07-07 11:09:02 RepVGG-A0] (main.py 282): INFO Train: [103/300][50/78]	eta 0:00:56 lr 4.693197	time 1.3059 (2.0167)	loss 3.4845 (3.5071)	grad_norm 0.3632 (0.3557)	mem 39782MB
[2023-07-07 11:09:17 RepVGG-A0] (main.py 282): INFO Train: [103/300][60/78]	eta 0:00:34 lr 4.689396	time 1.2679 (1.9325)	loss 3.4230 (3.5009)	grad_norm 0.3377 (0.3563)	mem 39782MB
[2023-07-07 11:09:31 RepVGG-A0] (main.py 282): INFO Train: [103/300][70/78]	eta 0:00:14 lr 4.685592	time 1.1846 (1.8707)	loss 3.9806 (3.5230)	grad_norm 0.6074 (0.3754)	mem 39782MB
[2023-07-07 11:09:43 RepVGG-A0] (main.py 291): INFO EPOCH 103 training takes 0:02:24
[2023-07-07 11:10:05 RepVGG-A0] (main.py 282): INFO Train: [104/300][0/78]	eta 0:28:32 lr 4.682547	time 21.9540 (21.9540)	loss 3.5420 (3.5420)	grad_norm 0.3481 (0.3481)	mem 39782MB
[2023-07-07 11:10:21 RepVGG-A0] (main.py 282): INFO Train: [104/300][10/78]	eta 0:03:50 lr 4.678739	time 1.1725 (3.3940)	loss 3.3105 (3.4238)	grad_norm 0.2905 (0.3089)	mem 39782MB
[2023-07-07 11:10:36 RepVGG-A0] (main.py 282): INFO Train: [104/300][20/78]	eta 0:02:25 lr 4.674927	time 1.2061 (2.5064)	loss 3.2799 (3.4204)	grad_norm 0.3190 (0.3227)	mem 39782MB
[2023-07-07 11:10:52 RepVGG-A0] (main.py 282): INFO Train: [104/300][30/78]	eta 0:01:45 lr 4.671113	time 1.5295 (2.1954)	loss 3.4405 (3.4018)	grad_norm 0.4319 (0.3306)	mem 39782MB
[2023-07-07 11:11:09 RepVGG-A0] (main.py 282): INFO Train: [104/300][40/78]	eta 0:01:18 lr 4.667297	time 3.5081 (2.0780)	loss 3.3714 (3.3969)	grad_norm 0.3650 (0.3313)	mem 39782MB
[2023-07-07 11:11:23 RepVGG-A0] (main.py 282): INFO Train: [104/300][50/78]	eta 0:00:54 lr 4.663478	time 1.1740 (1.9597)	loss 3.4674 (3.3937)	grad_norm 0.3621 (0.3355)	mem 39782MB
[2023-07-07 11:11:39 RepVGG-A0] (main.py 282): INFO Train: [104/300][60/78]	eta 0:00:34 lr 4.659656	time 1.2942 (1.8983)	loss 3.4520 (3.3881)	grad_norm 0.4318 (0.3407)	mem 39782MB
[2023-07-07 11:11:54 RepVGG-A0] (main.py 282): INFO Train: [104/300][70/78]	eta 0:00:14 lr 4.655831	time 1.1732 (1.8398)	loss 5.5004 (3.5190)	grad_norm 0.8881 (0.3996)	mem 39782MB
[2023-07-07 11:12:06 RepVGG-A0] (main.py 291): INFO EPOCH 104 training takes 0:02:22
[2023-07-07 11:12:26 RepVGG-A0] (main.py 282): INFO Train: [105/300][0/78]	eta 0:26:14 lr 4.652770	time 20.1896 (20.1896)	loss 4.1431 (4.1431)	grad_norm 0.3295 (0.3295)	mem 39782MB
[2023-07-07 11:12:41 RepVGG-A0] (main.py 282): INFO Train: [105/300][10/78]	eta 0:03:35 lr 4.648940	time 1.1722 (3.1747)	loss 3.6690 (3.8780)	grad_norm 0.2783 (0.2920)	mem 39782MB
[2023-07-07 11:12:55 RepVGG-A0] (main.py 282): INFO Train: [105/300][20/78]	eta 0:02:16 lr 4.645108	time 1.1715 (2.3456)	loss 3.5590 (3.7618)	grad_norm 0.2957 (0.2914)	mem 39782MB
[2023-07-07 11:13:09 RepVGG-A0] (main.py 282): INFO Train: [105/300][30/78]	eta 0:01:38 lr 4.641274	time 1.1813 (2.0539)	loss 3.4687 (3.6752)	grad_norm 0.3138 (0.2870)	mem 39782MB
[2023-07-07 11:13:28 RepVGG-A0] (main.py 282): INFO Train: [105/300][40/78]	eta 0:01:15 lr 4.637437	time 3.5558 (1.9962)	loss 3.3813 (3.6173)	grad_norm 0.3247 (0.2892)	mem 39782MB
[2023-07-07 11:13:43 RepVGG-A0] (main.py 282): INFO Train: [105/300][50/78]	eta 0:00:53 lr 4.633597	time 1.1726 (1.9123)	loss 3.3784 (3.5757)	grad_norm 0.3176 (0.2935)	mem 39782MB
[2023-07-07 11:13:58 RepVGG-A0] (main.py 282): INFO Train: [105/300][60/78]	eta 0:00:33 lr 4.629755	time 1.1754 (1.8403)	loss 3.4081 (3.5423)	grad_norm 0.3564 (0.2974)	mem 39782MB
[2023-07-07 11:14:13 RepVGG-A0] (main.py 282): INFO Train: [105/300][70/78]	eta 0:00:14 lr 4.625910	time 1.2467 (1.7876)	loss 3.3285 (3.5173)	grad_norm 0.3480 (0.3017)	mem 39782MB
[2023-07-07 11:14:25 RepVGG-A0] (main.py 291): INFO EPOCH 105 training takes 0:02:19
[2023-07-07 11:14:46 RepVGG-A0] (main.py 282): INFO Train: [106/300][0/78]	eta 0:27:29 lr 4.622833	time 21.1524 (21.1524)	loss 3.4144 (3.4144)	grad_norm 0.4038 (0.4038)	mem 39782MB
[2023-07-07 11:15:01 RepVGG-A0] (main.py 282): INFO Train: [106/300][10/78]	eta 0:03:43 lr 4.618983	time 1.1723 (3.2818)	loss 3.2668 (3.3421)	grad_norm 0.3277 (0.3555)	mem 39782MB
[2023-07-07 11:15:15 RepVGG-A0] (main.py 282): INFO Train: [106/300][20/78]	eta 0:02:18 lr 4.615131	time 1.1724 (2.3931)	loss 3.3309 (3.3408)	grad_norm 0.3653 (0.3493)	mem 39782MB
[2023-07-07 11:15:31 RepVGG-A0] (main.py 282): INFO Train: [106/300][30/78]	eta 0:01:42 lr 4.611277	time 1.4232 (2.1383)	loss 3.2686 (3.3299)	grad_norm 0.3596 (0.3467)	mem 39782MB
[2023-07-07 11:15:49 RepVGG-A0] (main.py 282): INFO Train: [106/300][40/78]	eta 0:01:17 lr 4.607420	time 4.2324 (2.0469)	loss 3.2549 (3.3327)	grad_norm 0.3452 (0.3519)	mem 39782MB
[2023-07-07 11:16:04 RepVGG-A0] (main.py 282): INFO Train: [106/300][50/78]	eta 0:00:54 lr 4.603560	time 1.1718 (1.9435)	loss 3.3787 (3.3383)	grad_norm 0.3828 (0.3579)	mem 39782MB
[2023-07-07 11:16:19 RepVGG-A0] (main.py 282): INFO Train: [106/300][60/78]	eta 0:00:33 lr 4.599698	time 1.2930 (1.8777)	loss 3.3772 (3.3408)	grad_norm 0.3683 (0.3593)	mem 39782MB
[2023-07-07 11:16:34 RepVGG-A0] (main.py 282): INFO Train: [106/300][70/78]	eta 0:00:14 lr 4.595833	time 1.1720 (1.8209)	loss 3.2752 (3.3365)	grad_norm 0.3370 (0.3559)	mem 39782MB
[2023-07-07 11:16:47 RepVGG-A0] (main.py 291): INFO EPOCH 106 training takes 0:02:21
[2023-07-07 11:17:10 RepVGG-A0] (main.py 282): INFO Train: [107/300][0/78]	eta 0:29:45 lr 4.592740	time 22.8904 (22.8904)	loss 3.5103 (3.5103)	grad_norm 0.5276 (0.5276)	mem 39782MB
[2023-07-07 11:17:25 RepVGG-A0] (main.py 282): INFO Train: [107/300][10/78]	eta 0:03:55 lr 4.588870	time 1.1772 (3.4649)	loss 3.3196 (3.4078)	grad_norm 0.3273 (0.4080)	mem 39782MB
[2023-07-07 11:17:39 RepVGG-A0] (main.py 282): INFO Train: [107/300][20/78]	eta 0:02:24 lr 4.584999	time 1.1752 (2.4950)	loss 3.2481 (3.3401)	grad_norm 0.3680 (0.3765)	mem 39782MB
[2023-07-07 11:17:55 RepVGG-A0] (main.py 282): INFO Train: [107/300][30/78]	eta 0:01:45 lr 4.581124	time 1.4097 (2.1924)	loss 3.2702 (3.3260)	grad_norm 0.2996 (0.3620)	mem 39782MB
[2023-07-07 11:18:13 RepVGG-A0] (main.py 282): INFO Train: [107/300][40/78]	eta 0:01:19 lr 4.577248	time 3.6549 (2.1006)	loss 3.4680 (3.3446)	grad_norm 0.4557 (0.3777)	mem 39782MB
[2023-07-07 11:18:28 RepVGG-A0] (main.py 282): INFO Train: [107/300][50/78]	eta 0:00:55 lr 4.573369	time 1.1727 (1.9919)	loss 3.3239 (3.3665)	grad_norm 0.3145 (0.3829)	mem 39782MB
[2023-07-07 11:18:43 RepVGG-A0] (main.py 282): INFO Train: [107/300][60/78]	eta 0:00:34 lr 4.569487	time 1.2179 (1.9055)	loss 3.2965 (3.3497)	grad_norm 0.3167 (0.3693)	mem 39782MB
[2023-07-07 11:18:58 RepVGG-A0] (main.py 282): INFO Train: [107/300][70/78]	eta 0:00:14 lr 4.565603	time 1.1960 (1.8515)	loss 3.3272 (3.3430)	grad_norm 0.3865 (0.3690)	mem 39782MB
[2023-07-07 11:19:10 RepVGG-A0] (main.py 291): INFO EPOCH 107 training takes 0:02:23
[2023-07-07 11:19:32 RepVGG-A0] (main.py 282): INFO Train: [108/300][0/78]	eta 0:28:13 lr 4.562494	time 21.7116 (21.7116)	loss 3.2631 (3.2631)	grad_norm 0.3557 (0.3557)	mem 39782MB
[2023-07-07 11:19:46 RepVGG-A0] (main.py 282): INFO Train: [108/300][10/78]	eta 0:03:44 lr 4.558605	time 1.1718 (3.3042)	loss 3.2859 (3.2949)	grad_norm 0.3630 (0.3826)	mem 39782MB
[2023-07-07 11:20:01 RepVGG-A0] (main.py 282): INFO Train: [108/300][20/78]	eta 0:02:21 lr 4.554714	time 1.1764 (2.4372)	loss 3.2629 (3.2693)	grad_norm 0.3497 (0.3675)	mem 39782MB
[2023-07-07 11:20:17 RepVGG-A0] (main.py 282): INFO Train: [108/300][30/78]	eta 0:01:43 lr 4.550821	time 1.1980 (2.1581)	loss 3.6630 (3.2957)	grad_norm 0.6360 (0.3946)	mem 39782MB
[2023-07-07 11:20:34 RepVGG-A0] (main.py 282): INFO Train: [108/300][40/78]	eta 0:01:17 lr 4.546925	time 3.5657 (2.0520)	loss 6.1280 (3.7232)	grad_norm 0.7834 (0.5315)	mem 39782MB
[2023-07-07 11:20:49 RepVGG-A0] (main.py 282): INFO Train: [108/300][50/78]	eta 0:00:54 lr 4.543027	time 1.1862 (1.9316)	loss 4.7332 (4.0218)	grad_norm 0.3638 (0.5098)	mem 39782MB
[2023-07-07 11:21:03 RepVGG-A0] (main.py 282): INFO Train: [108/300][60/78]	eta 0:00:33 lr 4.539126	time 1.1977 (1.8562)	loss 4.1514 (4.0811)	grad_norm 0.3112 (0.4736)	mem 39782MB
[2023-07-07 11:21:19 RepVGG-A0] (main.py 282): INFO Train: [108/300][70/78]	eta 0:00:14 lr 4.535223	time 1.1736 (1.8111)	loss 3.9364 (4.0778)	grad_norm 0.3120 (0.4521)	mem 39782MB
[2023-07-07 11:21:31 RepVGG-A0] (main.py 291): INFO EPOCH 108 training takes 0:02:20
[2023-07-07 11:21:52 RepVGG-A0] (main.py 282): INFO Train: [109/300][0/78]	eta 0:27:21 lr 4.532099	time 21.0471 (21.0471)	loss 3.7513 (3.7513)	grad_norm 0.3026 (0.3026)	mem 39782MB
[2023-07-07 11:22:07 RepVGG-A0] (main.py 282): INFO Train: [109/300][10/78]	eta 0:03:43 lr 4.528191	time 1.1908 (3.2859)	loss 3.6000 (3.6714)	grad_norm 0.2990 (0.2913)	mem 39782MB
[2023-07-07 11:22:22 RepVGG-A0] (main.py 282): INFO Train: [109/300][20/78]	eta 0:02:20 lr 4.524281	time 1.1742 (2.4278)	loss 3.6538 (3.6284)	grad_norm 0.3674 (0.3030)	mem 39782MB
[2023-07-07 11:22:37 RepVGG-A0] (main.py 282): INFO Train: [109/300][30/78]	eta 0:01:42 lr 4.520369	time 1.3673 (2.1437)	loss 3.4943 (3.6240)	grad_norm 0.3363 (0.3214)	mem 39782MB
[2023-07-07 11:22:55 RepVGG-A0] (main.py 282): INFO Train: [109/300][40/78]	eta 0:01:18 lr 4.516454	time 2.5450 (2.0554)	loss 3.5059 (3.5953)	grad_norm 0.2979 (0.3182)	mem 39782MB
[2023-07-07 11:23:10 RepVGG-A0] (main.py 282): INFO Train: [109/300][50/78]	eta 0:00:54 lr 4.512537	time 1.2395 (1.9409)	loss 3.4813 (3.5677)	grad_norm 0.3396 (0.3165)	mem 39782MB
[2023-07-07 11:23:25 RepVGG-A0] (main.py 282): INFO Train: [109/300][60/78]	eta 0:00:33 lr 4.508618	time 1.1734 (1.8721)	loss 3.4699 (3.5535)	grad_norm 0.3085 (0.3234)	mem 39782MB
[2023-07-07 11:23:39 RepVGG-A0] (main.py 282): INFO Train: [109/300][70/78]	eta 0:00:14 lr 4.504696	time 1.1363 (1.8109)	loss 3.3933 (3.5385)	grad_norm 0.3000 (0.3251)	mem 39782MB
[2023-07-07 11:23:52 RepVGG-A0] (main.py 291): INFO EPOCH 109 training takes 0:02:20
[2023-07-07 11:24:11 RepVGG-A0] (main.py 282): INFO Train: [110/300][0/78]	eta 0:25:47 lr 4.501557	time 19.8395 (19.8395)	loss 3.3946 (3.3946)	grad_norm 0.3769 (0.3769)	mem 39782MB
[2023-07-07 11:24:28 RepVGG-A0] (main.py 282): INFO Train: [110/300][10/78]	eta 0:03:44 lr 4.497631	time 1.1714 (3.3004)	loss 3.4073 (3.4210)	grad_norm 0.3576 (0.3923)	mem 39782MB
[2023-07-07 11:24:43 RepVGG-A0] (main.py 282): INFO Train: [110/300][20/78]	eta 0:02:22 lr 4.493703	time 1.2549 (2.4652)	loss 3.3976 (3.3967)	grad_norm 0.3262 (0.3626)	mem 39782MB
[2023-07-07 11:24:58 RepVGG-A0] (main.py 282): INFO Train: [110/300][30/78]	eta 0:01:42 lr 4.489772	time 1.1965 (2.1431)	loss 3.3498 (3.3889)	grad_norm 0.3733 (0.3650)	mem 39782MB
[2023-07-07 11:25:16 RepVGG-A0] (main.py 282): INFO Train: [110/300][40/78]	eta 0:01:18 lr 4.485839	time 3.4124 (2.0719)	loss 3.3922 (3.3888)	grad_norm 0.3394 (0.3637)	mem 39782MB
[2023-07-07 11:25:30 RepVGG-A0] (main.py 282): INFO Train: [110/300][50/78]	eta 0:00:54 lr 4.481904	time 1.1921 (1.9336)	loss 3.3277 (3.3867)	grad_norm 0.3152 (0.3632)	mem 39782MB
[2023-07-07 11:25:45 RepVGG-A0] (main.py 282): INFO Train: [110/300][60/78]	eta 0:00:33 lr 4.477967	time 1.1721 (1.8569)	loss 3.3719 (3.3838)	grad_norm 0.4600 (0.3634)	mem 39782MB
[2023-07-07 11:26:00 RepVGG-A0] (main.py 282): INFO Train: [110/300][70/78]	eta 0:00:14 lr 4.474027	time 1.1710 (1.8092)	loss 5.6402 (3.5787)	grad_norm 0.7272 (0.4327)	mem 39782MB
[2023-07-07 11:26:11 RepVGG-A0] (main.py 291): INFO EPOCH 110 training takes 0:02:19
[2023-07-07 11:26:32 RepVGG-A0] (main.py 282): INFO Train: [111/300][0/78]	eta 0:28:07 lr 4.470873	time 21.6347 (21.6347)	loss 4.5115 (4.5115)	grad_norm 0.3477 (0.3477)	mem 39782MB
[2023-07-07 11:26:47 RepVGG-A0] (main.py 282): INFO Train: [111/300][10/78]	eta 0:03:41 lr 4.466929	time 1.1720 (3.2577)	loss 4.0133 (4.2618)	grad_norm 0.2552 (0.3349)	mem 39782MB
[2023-07-07 11:27:01 RepVGG-A0] (main.py 282): INFO Train: [111/300][20/78]	eta 0:02:18 lr 4.462983	time 1.1735 (2.3924)	loss 3.7246 (4.0693)	grad_norm 0.3483 (0.3131)	mem 39782MB
[2023-07-07 11:27:17 RepVGG-A0] (main.py 282): INFO Train: [111/300][30/78]	eta 0:01:43 lr 4.459034	time 1.9099 (2.1532)	loss 3.6684 (3.9469)	grad_norm 0.3363 (0.3081)	mem 39782MB
[2023-07-07 11:27:35 RepVGG-A0] (main.py 282): INFO Train: [111/300][40/78]	eta 0:01:17 lr 4.455084	time 4.4391 (2.0465)	loss 3.5757 (3.8609)	grad_norm 0.2866 (0.3069)	mem 39782MB
[2023-07-07 11:27:49 RepVGG-A0] (main.py 282): INFO Train: [111/300][50/78]	eta 0:00:54 lr 4.451130	time 1.3011 (1.9341)	loss 3.6273 (3.7958)	grad_norm 0.4533 (0.3089)	mem 39782MB
[2023-07-07 11:28:05 RepVGG-A0] (main.py 282): INFO Train: [111/300][60/78]	eta 0:00:33 lr 4.447175	time 1.1277 (1.8696)	loss 3.4376 (3.7515)	grad_norm 0.2819 (0.3109)	mem 39782MB
[2023-07-07 11:28:20 RepVGG-A0] (main.py 282): INFO Train: [111/300][70/78]	eta 0:00:14 lr 4.443218	time 1.3238 (1.8169)	loss 3.4574 (3.7109)	grad_norm 0.3564 (0.3111)	mem 39782MB
[2023-07-07 11:28:31 RepVGG-A0] (main.py 291): INFO EPOCH 111 training takes 0:02:20
[2023-07-07 11:28:52 RepVGG-A0] (main.py 282): INFO Train: [112/300][0/78]	eta 0:26:43 lr 4.440050	time 20.5540 (20.5540)	loss 3.3420 (3.3420)	grad_norm 0.2872 (0.2872)	mem 39782MB
[2023-07-07 11:29:08 RepVGG-A0] (main.py 282): INFO Train: [112/300][10/78]	eta 0:03:44 lr 4.436088	time 1.1720 (3.3065)	loss 3.2519 (3.3604)	grad_norm 0.2874 (0.3194)	mem 39782MB
[2023-07-07 11:29:23 RepVGG-A0] (main.py 282): INFO Train: [112/300][20/78]	eta 0:02:23 lr 4.432124	time 1.3975 (2.4753)	loss 3.5675 (3.4367)	grad_norm 0.4420 (0.3740)	mem 39782MB
[2023-07-07 11:29:39 RepVGG-A0] (main.py 282): INFO Train: [112/300][30/78]	eta 0:01:44 lr 4.428158	time 1.1312 (2.1724)	loss 3.4465 (3.4280)	grad_norm 0.3504 (0.3588)	mem 39782MB
[2023-07-07 11:29:57 RepVGG-A0] (main.py 282): INFO Train: [112/300][40/78]	eta 0:01:19 lr 4.424190	time 4.6901 (2.0812)	loss 3.3657 (3.4164)	grad_norm 0.3638 (0.3531)	mem 39782MB
[2023-07-07 11:30:11 RepVGG-A0] (main.py 282): INFO Train: [112/300][50/78]	eta 0:00:54 lr 4.420220	time 1.1705 (1.9448)	loss 3.3985 (3.4081)	grad_norm 0.3132 (0.3519)	mem 39782MB
[2023-07-07 11:30:26 RepVGG-A0] (main.py 282): INFO Train: [112/300][60/78]	eta 0:00:33 lr 4.416247	time 1.2101 (1.8748)	loss 3.4575 (3.4070)	grad_norm 0.4104 (0.3566)	mem 39782MB
[2023-07-07 11:30:41 RepVGG-A0] (main.py 282): INFO Train: [112/300][70/78]	eta 0:00:14 lr 4.412272	time 1.3425 (1.8296)	loss 3.3150 (3.4036)	grad_norm 0.3236 (0.3543)	mem 39782MB
[2023-07-07 11:30:53 RepVGG-A0] (main.py 291): INFO EPOCH 112 training takes 0:02:21
[2023-07-07 11:31:15 RepVGG-A0] (main.py 282): INFO Train: [113/300][0/78]	eta 0:29:18 lr 4.409091	time 22.5496 (22.5496)	loss 3.3602 (3.3602)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:31:29 RepVGG-A0] (main.py 282): INFO Train: [113/300][10/78]	eta 0:03:45 lr 4.405112	time 1.1723 (3.3164)	loss 3.4036 (3.3386)	grad_norm 0.4377 (0.3845)	mem 39782MB
[2023-07-07 11:31:44 RepVGG-A0] (main.py 282): INFO Train: [113/300][20/78]	eta 0:02:20 lr 4.401131	time 1.1737 (2.4297)	loss 3.2801 (3.3336)	grad_norm 0.3471 (0.3794)	mem 39782MB
[2023-07-07 11:31:58 RepVGG-A0] (main.py 282): INFO Train: [113/300][30/78]	eta 0:01:41 lr 4.397148	time 1.2482 (2.1168)	loss 3.3044 (3.3259)	grad_norm 0.3474 (0.3720)	mem 39782MB
[2023-07-07 11:32:17 RepVGG-A0] (main.py 282): INFO Train: [113/300][40/78]	eta 0:01:17 lr 4.393162	time 3.4044 (2.0422)	loss 3.3037 (3.3346)	grad_norm 0.3684 (0.3746)	mem 39782MB
[2023-07-07 11:32:32 RepVGG-A0] (main.py 282): INFO Train: [113/300][50/78]	eta 0:00:54 lr 4.389175	time 1.1786 (1.9405)	loss 3.3702 (3.3285)	grad_norm 0.3695 (0.3714)	mem 39782MB
[2023-07-07 11:32:47 RepVGG-A0] (main.py 282): INFO Train: [113/300][60/78]	eta 0:00:33 lr 4.385185	time 1.1776 (1.8656)	loss 3.3940 (3.3321)	grad_norm 0.4120 (0.3745)	mem 39782MB
[2023-07-07 11:33:02 RepVGG-A0] (main.py 282): INFO Train: [113/300][70/78]	eta 0:00:14 lr 4.381193	time 1.1278 (1.8170)	loss 3.3320 (3.3350)	grad_norm 0.3438 (0.3746)	mem 39782MB
[2023-07-07 11:33:13 RepVGG-A0] (main.py 291): INFO EPOCH 113 training takes 0:02:20
[2023-07-07 11:33:34 RepVGG-A0] (main.py 282): INFO Train: [114/300][0/78]	eta 0:27:36 lr 4.377999	time 21.2394 (21.2394)	loss 3.3004 (3.3004)	grad_norm 0.4531 (0.4531)	mem 39782MB
[2023-07-07 11:33:49 RepVGG-A0] (main.py 282): INFO Train: [114/300][10/78]	eta 0:03:43 lr 4.374003	time 1.1713 (3.2830)	loss 3.3358 (3.3434)	grad_norm 0.4236 (0.4216)	mem 39782MB
[2023-07-07 11:34:05 RepVGG-A0] (main.py 282): INFO Train: [114/300][20/78]	eta 0:02:23 lr 4.370005	time 1.3662 (2.4692)	loss 3.2605 (3.3181)	grad_norm 0.3482 (0.3937)	mem 39782MB
[2023-07-07 11:34:20 RepVGG-A0] (main.py 282): INFO Train: [114/300][30/78]	eta 0:01:43 lr 4.366006	time 1.7062 (2.1477)	loss 3.1743 (3.2887)	grad_norm 0.3508 (0.3768)	mem 39782MB
[2023-07-07 11:34:37 RepVGG-A0] (main.py 282): INFO Train: [114/300][40/78]	eta 0:01:17 lr 4.362004	time 3.1190 (2.0378)	loss 3.4586 (3.2955)	grad_norm 0.5292 (0.3844)	mem 39782MB
[2023-07-07 11:34:52 RepVGG-A0] (main.py 282): INFO Train: [114/300][50/78]	eta 0:00:53 lr 4.358000	time 1.1723 (1.9285)	loss 5.7577 (3.7073)	grad_norm 0.5064 (0.4853)	mem 39782MB
[2023-07-07 11:35:07 RepVGG-A0] (main.py 282): INFO Train: [114/300][60/78]	eta 0:00:33 lr 4.353994	time 1.1888 (1.8653)	loss 4.5561 (3.9152)	grad_norm 0.3221 (0.4664)	mem 39782MB
[2023-07-07 11:35:22 RepVGG-A0] (main.py 282): INFO Train: [114/300][70/78]	eta 0:00:14 lr 4.349985	time 1.3179 (1.8087)	loss 4.0651 (3.9709)	grad_norm 0.2630 (0.4472)	mem 39782MB
[2023-07-07 11:35:33 RepVGG-A0] (main.py 291): INFO EPOCH 114 training takes 0:02:20
[2023-07-07 11:35:55 RepVGG-A0] (main.py 282): INFO Train: [115/300][0/78]	eta 0:28:14 lr 4.346777	time 21.7275 (21.7275)	loss 3.9321 (3.9321)	grad_norm 0.3248 (0.3248)	mem 39782MB
[2023-07-07 11:36:11 RepVGG-A0] (main.py 282): INFO Train: [115/300][10/78]	eta 0:03:52 lr 4.342766	time 1.1706 (3.4251)	loss 3.6728 (3.7833)	grad_norm 0.3051 (0.3070)	mem 39782MB
[2023-07-07 11:36:25 RepVGG-A0] (main.py 282): INFO Train: [115/300][20/78]	eta 0:02:23 lr 4.338752	time 1.1413 (2.4701)	loss 3.6303 (3.7404)	grad_norm 0.2789 (0.3140)	mem 39782MB
[2023-07-07 11:36:42 RepVGG-A0] (main.py 282): INFO Train: [115/300][30/78]	eta 0:01:46 lr 4.334736	time 1.2378 (2.2179)	loss 3.5132 (3.6722)	grad_norm 0.3284 (0.3023)	mem 39782MB
[2023-07-07 11:36:58 RepVGG-A0] (main.py 282): INFO Train: [115/300][40/78]	eta 0:01:18 lr 4.330718	time 4.0560 (2.0727)	loss 3.5886 (3.6455)	grad_norm 0.3425 (0.3178)	mem 39782MB
[2023-07-07 11:37:13 RepVGG-A0] (main.py 282): INFO Train: [115/300][50/78]	eta 0:00:54 lr 4.326698	time 1.1722 (1.9561)	loss 3.4438 (3.6186)	grad_norm 0.3487 (0.3182)	mem 39782MB
[2023-07-07 11:37:28 RepVGG-A0] (main.py 282): INFO Train: [115/300][60/78]	eta 0:00:33 lr 4.322675	time 1.1836 (1.8749)	loss 3.4581 (3.5902)	grad_norm 0.3808 (0.3186)	mem 39782MB
[2023-07-07 11:37:43 RepVGG-A0] (main.py 282): INFO Train: [115/300][70/78]	eta 0:00:14 lr 4.318651	time 1.1725 (1.8286)	loss 3.3796 (3.5717)	grad_norm 0.3352 (0.3265)	mem 39782MB
[2023-07-07 11:37:55 RepVGG-A0] (main.py 291): INFO EPOCH 115 training takes 0:02:21
[2023-07-07 11:38:18 RepVGG-A0] (main.py 282): INFO Train: [116/300][0/78]	eta 0:29:26 lr 4.315431	time 22.6426 (22.6426)	loss 3.3521 (3.3521)	grad_norm 0.3650 (0.3650)	mem 39782MB
[2023-07-07 11:38:32 RepVGG-A0] (main.py 282): INFO Train: [116/300][10/78]	eta 0:03:49 lr 4.311403	time 1.1740 (3.3736)	loss 3.3583 (3.3813)	grad_norm 0.3171 (0.3505)	mem 39782MB
[2023-07-07 11:38:47 RepVGG-A0] (main.py 282): INFO Train: [116/300][20/78]	eta 0:02:23 lr 4.307373	time 1.1845 (2.4795)	loss 3.3389 (3.3661)	grad_norm 0.3678 (0.3540)	mem 39782MB
[2023-07-07 11:39:03 RepVGG-A0] (main.py 282): INFO Train: [116/300][30/78]	eta 0:01:44 lr 4.303341	time 1.4423 (2.1777)	loss 3.4049 (3.3643)	grad_norm 0.4433 (0.3512)	mem 39782MB
[2023-07-07 11:39:20 RepVGG-A0] (main.py 282): INFO Train: [116/300][40/78]	eta 0:01:19 lr 4.299308	time 3.9595 (2.0816)	loss 3.4328 (3.3797)	grad_norm 0.3991 (0.3630)	mem 39782MB
[2023-07-07 11:39:35 RepVGG-A0] (main.py 282): INFO Train: [116/300][50/78]	eta 0:00:54 lr 4.295272	time 1.1729 (1.9591)	loss 3.4745 (3.3839)	grad_norm 0.4535 (0.3668)	mem 39782MB
[2023-07-07 11:39:50 RepVGG-A0] (main.py 282): INFO Train: [116/300][60/78]	eta 0:00:34 lr 4.291234	time 1.2903 (1.8909)	loss 3.2700 (3.3810)	grad_norm 0.3718 (0.3664)	mem 39782MB
[2023-07-07 11:40:06 RepVGG-A0] (main.py 282): INFO Train: [116/300][70/78]	eta 0:00:14 lr 4.287194	time 1.5328 (1.8433)	loss 3.3200 (3.3722)	grad_norm 0.3259 (0.3620)	mem 39782MB
[2023-07-07 11:40:17 RepVGG-A0] (main.py 291): INFO EPOCH 116 training takes 0:02:22
[2023-07-07 11:40:39 RepVGG-A0] (main.py 282): INFO Train: [117/300][0/78]	eta 0:28:14 lr 4.283961	time 21.7204 (21.7204)	loss 3.3056 (3.3056)	grad_norm 0.3688 (0.3688)	mem 39782MB
[2023-07-07 11:40:53 RepVGG-A0] (main.py 282): INFO Train: [117/300][10/78]	eta 0:03:41 lr 4.279918	time 1.1721 (3.2608)	loss 3.4354 (3.3103)	grad_norm 0.5023 (0.3819)	mem 39782MB
[2023-07-07 11:41:08 RepVGG-A0] (main.py 282): INFO Train: [117/300][20/78]	eta 0:02:19 lr 4.275873	time 1.1741 (2.4046)	loss 3.8635 (3.5348)	grad_norm 0.5983 (0.4939)	mem 39782MB
[2023-07-07 11:41:23 RepVGG-A0] (main.py 282): INFO Train: [117/300][30/78]	eta 0:01:41 lr 4.271826	time 1.4151 (2.1137)	loss 3.3639 (3.5436)	grad_norm 0.2836 (0.4522)	mem 39782MB
[2023-07-07 11:41:42 RepVGG-A0] (main.py 282): INFO Train: [117/300][40/78]	eta 0:01:18 lr 4.267777	time 4.6563 (2.0687)	loss 3.2966 (3.4904)	grad_norm 0.3041 (0.4120)	mem 39782MB
[2023-07-07 11:41:56 RepVGG-A0] (main.py 282): INFO Train: [117/300][50/78]	eta 0:00:54 lr 4.263726	time 1.1762 (1.9398)	loss 3.2296 (3.4503)	grad_norm 0.3454 (0.3936)	mem 39782MB
[2023-07-07 11:42:12 RepVGG-A0] (main.py 282): INFO Train: [117/300][60/78]	eta 0:00:33 lr 4.259673	time 1.2697 (1.8806)	loss 3.3060 (3.4235)	grad_norm 0.3274 (0.3820)	mem 39782MB
[2023-07-07 11:42:27 RepVGG-A0] (main.py 282): INFO Train: [117/300][70/78]	eta 0:00:14 lr 4.255618	time 1.4901 (1.8275)	loss 3.2803 (3.4035)	grad_norm 0.3250 (0.3736)	mem 39782MB
[2023-07-07 11:42:38 RepVGG-A0] (main.py 291): INFO EPOCH 117 training takes 0:02:21
[2023-07-07 11:43:00 RepVGG-A0] (main.py 282): INFO Train: [118/300][0/78]	eta 0:28:08 lr 4.252373	time 21.6484 (21.6484)	loss 3.2711 (3.2711)	grad_norm 0.4037 (0.4037)	mem 39782MB
[2023-07-07 11:43:14 RepVGG-A0] (main.py 282): INFO Train: [118/300][10/78]	eta 0:03:40 lr 4.248315	time 1.1736 (3.2364)	loss 3.3351 (3.2513)	grad_norm 0.3842 (0.3773)	mem 39782MB
[2023-07-07 11:43:29 RepVGG-A0] (main.py 282): INFO Train: [118/300][20/78]	eta 0:02:20 lr 4.244255	time 1.1717 (2.4250)	loss 3.3239 (3.2709)	grad_norm 0.4043 (0.3773)	mem 39782MB
[2023-07-07 11:43:44 RepVGG-A0] (main.py 282): INFO Train: [118/300][30/78]	eta 0:01:42 lr 4.240193	time 1.3904 (2.1280)	loss 3.2329 (3.2699)	grad_norm 0.3339 (0.3742)	mem 39782MB
[2023-07-07 11:44:02 RepVGG-A0] (main.py 282): INFO Train: [118/300][40/78]	eta 0:01:17 lr 4.236129	time 3.3342 (2.0400)	loss 3.3347 (3.2755)	grad_norm 0.4177 (0.3778)	mem 39782MB
[2023-07-07 11:44:17 RepVGG-A0] (main.py 282): INFO Train: [118/300][50/78]	eta 0:00:54 lr 4.232064	time 1.1705 (1.9410)	loss 3.4167 (3.2797)	grad_norm 0.4319 (0.3776)	mem 39782MB
[2023-07-07 11:44:32 RepVGG-A0] (main.py 282): INFO Train: [118/300][60/78]	eta 0:00:33 lr 4.227996	time 1.2929 (1.8705)	loss 3.2235 (3.2826)	grad_norm 0.3622 (0.3796)	mem 39782MB
[2023-07-07 11:44:48 RepVGG-A0] (main.py 282): INFO Train: [118/300][70/78]	eta 0:00:14 lr 4.223927	time 1.2902 (1.8224)	loss 3.2626 (3.2779)	grad_norm 0.3388 (0.3744)	mem 39782MB
[2023-07-07 11:45:00 RepVGG-A0] (main.py 291): INFO EPOCH 118 training takes 0:02:21
[2023-07-07 11:45:21 RepVGG-A0] (main.py 282): INFO Train: [119/300][0/78]	eta 0:27:44 lr 4.220670	time 21.3406 (21.3406)	loss 3.2805 (3.2805)	grad_norm 0.4124 (0.4124)	mem 39782MB
[2023-07-07 11:45:36 RepVGG-A0] (main.py 282): INFO Train: [119/300][10/78]	eta 0:03:45 lr 4.216597	time 1.1955 (3.3204)	loss 3.3118 (3.3116)	grad_norm 0.4046 (0.4327)	mem 39782MB
[2023-07-07 11:45:52 RepVGG-A0] (main.py 282): INFO Train: [119/300][20/78]	eta 0:02:24 lr 4.212523	time 1.1538 (2.4914)	loss 3.2503 (3.2841)	grad_norm 0.3663 (0.3993)	mem 39782MB
[2023-07-07 11:46:07 RepVGG-A0] (main.py 282): INFO Train: [119/300][30/78]	eta 0:01:44 lr 4.208446	time 1.9319 (2.1725)	loss 3.1881 (3.2635)	grad_norm 0.3449 (0.3821)	mem 39782MB
[2023-07-07 11:46:25 RepVGG-A0] (main.py 282): INFO Train: [119/300][40/78]	eta 0:01:19 lr 4.204368	time 3.9192 (2.0833)	loss 3.8190 (3.3107)	grad_norm 0.7106 (0.4147)	mem 39782MB
[2023-07-07 11:46:40 RepVGG-A0] (main.py 282): INFO Train: [119/300][50/78]	eta 0:00:55 lr 4.200288	time 1.1783 (1.9674)	loss 4.4938 (3.5651)	grad_norm 0.5672 (0.4931)	mem 39782MB
[2023-07-07 11:46:55 RepVGG-A0] (main.py 282): INFO Train: [119/300][60/78]	eta 0:00:33 lr 4.196206	time 1.1822 (1.8832)	loss 3.7052 (3.6223)	grad_norm 0.2740 (0.4655)	mem 39782MB
[2023-07-07 11:47:10 RepVGG-A0] (main.py 282): INFO Train: [119/300][70/78]	eta 0:00:14 lr 4.192123	time 1.1267 (1.8334)	loss 3.4912 (3.6162)	grad_norm 0.2807 (0.4434)	mem 39782MB
[2023-07-07 11:47:23 RepVGG-A0] (main.py 291): INFO EPOCH 119 training takes 0:02:22
[2023-07-07 11:47:44 RepVGG-A0] (main.py 282): INFO Train: [120/300][0/78]	eta 0:27:28 lr 4.188854	time 21.1393 (21.1393)	loss 3.3527 (3.3527)	grad_norm 0.2635 (0.2635)	mem 39782MB
[2023-07-07 11:48:00 RepVGG-A0] (main.py 282): INFO Train: [120/300][10/78]	eta 0:03:47 lr 4.184768	time 1.1892 (3.3518)	loss 3.3052 (3.2931)	grad_norm 0.2956 (0.2783)	mem 39782MB
[2023-07-07 11:48:14 RepVGG-A0] (main.py 282): INFO Train: [120/300][20/78]	eta 0:02:20 lr 4.180679	time 1.1987 (2.4205)	loss 3.2201 (3.2832)	grad_norm 0.3431 (0.2922)	mem 39782MB
[2023-07-07 11:48:28 RepVGG-A0] (main.py 282): INFO Train: [120/300][30/78]	eta 0:01:41 lr 4.176589	time 1.3312 (2.1186)	loss 3.1361 (3.2627)	grad_norm 0.2969 (0.2938)	mem 39782MB
[2023-07-07 11:48:46 RepVGG-A0] (main.py 282): INFO Train: [120/300][40/78]	eta 0:01:17 lr 4.172497	time 3.9256 (2.0354)	loss 3.2698 (3.2588)	grad_norm 0.3494 (0.3035)	mem 39782MB
[2023-07-07 11:49:02 RepVGG-A0] (main.py 282): INFO Train: [120/300][50/78]	eta 0:00:54 lr 4.168403	time 1.1888 (1.9390)	loss 3.2172 (3.2492)	grad_norm 0.3221 (0.3095)	mem 39782MB
[2023-07-07 11:49:16 RepVGG-A0] (main.py 282): INFO Train: [120/300][60/78]	eta 0:00:33 lr 4.164307	time 1.3113 (1.8631)	loss 3.3749 (3.2510)	grad_norm 0.3574 (0.3145)	mem 39782MB
[2023-07-07 11:49:31 RepVGG-A0] (main.py 282): INFO Train: [120/300][70/78]	eta 0:00:14 lr 4.160210	time 1.2764 (1.8059)	loss 3.2278 (3.2567)	grad_norm 0.3350 (0.3239)	mem 39782MB
[2023-07-07 11:49:43 RepVGG-A0] (main.py 291): INFO EPOCH 120 training takes 0:02:19
[2023-07-07 11:50:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.900 (17.900)	Loss 2.7981 (2.7981)	Acc@1 41.357 (41.357)	Acc@5 67.542 (67.542)	Mem 39782MB
[2023-07-07 11:50:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 41.654 Acc@5 67.390
[2023-07-07 11:50:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 120: 41.654%
[2023-07-07 11:50:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 11:50:24 RepVGG-A0] (main.py 282): INFO Train: [121/300][0/78]	eta 0:28:48 lr 4.156931	time 22.1659 (22.1659)	loss 3.1653 (3.1653)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:50:39 RepVGG-A0] (main.py 282): INFO Train: [121/300][10/78]	eta 0:03:49 lr 4.152830	time 1.1733 (3.3794)	loss 3.1916 (3.1932)	grad_norm 0.3425 (0.3579)	mem 39782MB
[2023-07-07 11:50:54 RepVGG-A0] (main.py 282): INFO Train: [121/300][20/78]	eta 0:02:25 lr 4.148728	time 1.1793 (2.5051)	loss 3.3396 (3.2151)	grad_norm 0.4370 (0.3791)	mem 39782MB
[2023-07-07 11:51:10 RepVGG-A0] (main.py 282): INFO Train: [121/300][30/78]	eta 0:01:45 lr 4.144624	time 1.4622 (2.1897)	loss 3.2380 (3.2156)	grad_norm 0.3754 (0.3653)	mem 39782MB
[2023-07-07 11:51:28 RepVGG-A0] (main.py 282): INFO Train: [121/300][40/78]	eta 0:01:19 lr 4.140518	time 2.3536 (2.1034)	loss 3.1702 (3.2183)	grad_norm 0.3326 (0.3670)	mem 39782MB
[2023-07-07 11:51:43 RepVGG-A0] (main.py 282): INFO Train: [121/300][50/78]	eta 0:00:55 lr 4.136411	time 1.1277 (1.9879)	loss 3.2937 (3.2197)	grad_norm 0.3987 (0.3655)	mem 39782MB
[2023-07-07 11:51:58 RepVGG-A0] (main.py 282): INFO Train: [121/300][60/78]	eta 0:00:34 lr 4.132302	time 1.1737 (1.9020)	loss 3.2190 (3.2285)	grad_norm 0.3280 (0.3717)	mem 39782MB
[2023-07-07 11:52:12 RepVGG-A0] (main.py 282): INFO Train: [121/300][70/78]	eta 0:00:14 lr 4.128191	time 1.6963 (1.8349)	loss 3.3180 (3.2282)	grad_norm 0.4218 (0.3689)	mem 39782MB
[2023-07-07 11:52:23 RepVGG-A0] (main.py 291): INFO EPOCH 121 training takes 0:02:21
[2023-07-07 11:52:43 RepVGG-A0] (main.py 282): INFO Train: [122/300][0/78]	eta 0:26:41 lr 4.124902	time 20.5378 (20.5378)	loss 3.1639 (3.1639)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 11:52:59 RepVGG-A0] (main.py 282): INFO Train: [122/300][10/78]	eta 0:03:40 lr 4.120788	time 1.1701 (3.2485)	loss 3.2393 (3.2584)	grad_norm 0.3633 (0.4267)	mem 39782MB
[2023-07-07 11:53:15 RepVGG-A0] (main.py 282): INFO Train: [122/300][20/78]	eta 0:02:22 lr 4.116673	time 1.1865 (2.4576)	loss 3.1399 (3.2221)	grad_norm 0.3262 (0.3902)	mem 39782MB
[2023-07-07 11:53:29 RepVGG-A0] (main.py 282): INFO Train: [122/300][30/78]	eta 0:01:42 lr 4.112556	time 1.2275 (2.1355)	loss 3.2577 (3.2083)	grad_norm 0.4414 (0.3851)	mem 39782MB
[2023-07-07 11:53:49 RepVGG-A0] (main.py 282): INFO Train: [122/300][40/78]	eta 0:01:19 lr 4.108437	time 5.4859 (2.0905)	loss 3.2086 (3.2123)	grad_norm 0.3652 (0.3833)	mem 39782MB
[2023-07-07 11:54:03 RepVGG-A0] (main.py 282): INFO Train: [122/300][50/78]	eta 0:00:55 lr 4.104317	time 1.1765 (1.9707)	loss 3.2236 (3.2125)	grad_norm 0.4328 (0.3792)	mem 39782MB
[2023-07-07 11:54:20 RepVGG-A0] (main.py 282): INFO Train: [122/300][60/78]	eta 0:00:34 lr 4.100195	time 1.3283 (1.9131)	loss 3.1611 (3.2165)	grad_norm 0.3409 (0.3807)	mem 39782MB
[2023-07-07 11:54:34 RepVGG-A0] (main.py 282): INFO Train: [122/300][70/78]	eta 0:00:14 lr 4.096072	time 1.2096 (1.8531)	loss 3.2932 (3.2160)	grad_norm 0.4102 (0.3791)	mem 39782MB
[2023-07-07 11:54:45 RepVGG-A0] (main.py 291): INFO EPOCH 122 training takes 0:02:21
[2023-07-07 11:55:07 RepVGG-A0] (main.py 282): INFO Train: [123/300][0/78]	eta 0:28:12 lr 4.092772	time 21.6940 (21.6940)	loss 3.2422 (3.2422)	grad_norm 0.4251 (0.4251)	mem 39782MB
[2023-07-07 11:55:21 RepVGG-A0] (main.py 282): INFO Train: [123/300][10/78]	eta 0:03:44 lr 4.088645	time 1.1933 (3.3044)	loss 3.1637 (3.2482)	grad_norm 0.3225 (0.4078)	mem 39782MB
[2023-07-07 11:55:36 RepVGG-A0] (main.py 282): INFO Train: [123/300][20/78]	eta 0:02:21 lr 4.084517	time 1.1729 (2.4454)	loss 3.2184 (3.2134)	grad_norm 0.3635 (0.3850)	mem 39782MB
[2023-07-07 11:55:51 RepVGG-A0] (main.py 282): INFO Train: [123/300][30/78]	eta 0:01:42 lr 4.080388	time 1.4521 (2.1282)	loss 3.6806 (3.2363)	grad_norm 0.7181 (0.4055)	mem 39782MB
[2023-07-07 11:56:09 RepVGG-A0] (main.py 282): INFO Train: [123/300][40/78]	eta 0:01:17 lr 4.076256	time 3.8434 (2.0479)	loss 5.5922 (3.8224)	grad_norm 0.5610 (0.5285)	mem 39782MB
[2023-07-07 11:56:24 RepVGG-A0] (main.py 282): INFO Train: [123/300][50/78]	eta 0:00:54 lr 4.072124	time 1.1715 (1.9350)	loss 4.4287 (4.0108)	grad_norm 0.3829 (0.4949)	mem 39782MB
[2023-07-07 11:56:38 RepVGG-A0] (main.py 282): INFO Train: [123/300][60/78]	eta 0:00:33 lr 4.067989	time 1.1785 (1.8528)	loss 3.9910 (4.0417)	grad_norm 0.2804 (0.4687)	mem 39782MB
[2023-07-07 11:56:53 RepVGG-A0] (main.py 282): INFO Train: [123/300][70/78]	eta 0:00:14 lr 4.063853	time 1.4074 (1.8027)	loss 3.7237 (4.0168)	grad_norm 0.2780 (0.4430)	mem 39782MB
[2023-07-07 11:57:05 RepVGG-A0] (main.py 291): INFO EPOCH 123 training takes 0:02:19
[2023-07-07 11:57:26 RepVGG-A0] (main.py 282): INFO Train: [124/300][0/78]	eta 0:27:21 lr 4.060543	time 21.0420 (21.0420)	loss 3.7007 (3.7007)	grad_norm 0.3113 (0.3113)	mem 39782MB
[2023-07-07 11:57:40 RepVGG-A0] (main.py 282): INFO Train: [124/300][10/78]	eta 0:03:38 lr 4.056405	time 1.1703 (3.2144)	loss 3.5341 (3.5919)	grad_norm 0.2768 (0.3000)	mem 39782MB
[2023-07-07 11:57:55 RepVGG-A0] (main.py 282): INFO Train: [124/300][20/78]	eta 0:02:18 lr 4.052264	time 1.1729 (2.3962)	loss 3.4860 (3.5647)	grad_norm 0.3314 (0.3120)	mem 39782MB
[2023-07-07 11:58:11 RepVGG-A0] (main.py 282): INFO Train: [124/300][30/78]	eta 0:01:43 lr 4.048123	time 1.2132 (2.1503)	loss 3.4351 (3.5250)	grad_norm 0.3085 (0.3089)	mem 39782MB
[2023-07-07 11:58:29 RepVGG-A0] (main.py 282): INFO Train: [124/300][40/78]	eta 0:01:18 lr 4.043979	time 2.0327 (2.0582)	loss 3.4807 (3.5171)	grad_norm 0.3648 (0.3243)	mem 39782MB
[2023-07-07 11:58:45 RepVGG-A0] (main.py 282): INFO Train: [124/300][50/78]	eta 0:00:54 lr 4.039835	time 1.1780 (1.9613)	loss 3.3983 (3.4951)	grad_norm 0.3472 (0.3260)	mem 39782MB
[2023-07-07 11:58:59 RepVGG-A0] (main.py 282): INFO Train: [124/300][60/78]	eta 0:00:33 lr 4.035688	time 1.4485 (1.8800)	loss 3.3651 (3.4843)	grad_norm 0.3672 (0.3340)	mem 39782MB
[2023-07-07 11:59:15 RepVGG-A0] (main.py 282): INFO Train: [124/300][70/78]	eta 0:00:14 lr 4.031540	time 1.1939 (1.8308)	loss 3.3716 (3.4679)	grad_norm 0.3971 (0.3335)	mem 39782MB
[2023-07-07 11:59:26 RepVGG-A0] (main.py 291): INFO EPOCH 124 training takes 0:02:21
[2023-07-07 11:59:46 RepVGG-A0] (main.py 282): INFO Train: [125/300][0/78]	eta 0:26:30 lr 4.028221	time 20.3848 (20.3848)	loss 3.4400 (3.4400)	grad_norm 0.4339 (0.4339)	mem 39782MB
[2023-07-07 12:00:00 RepVGG-A0] (main.py 282): INFO Train: [125/300][10/78]	eta 0:03:33 lr 4.024070	time 1.1745 (3.1438)	loss 3.4152 (3.3244)	grad_norm 0.4142 (0.3486)	mem 39782MB
[2023-07-07 12:00:15 RepVGG-A0] (main.py 282): INFO Train: [125/300][20/78]	eta 0:02:15 lr 4.019918	time 1.1720 (2.3446)	loss 3.2375 (3.3273)	grad_norm 0.3500 (0.3644)	mem 39782MB
[2023-07-07 12:00:31 RepVGG-A0] (main.py 282): INFO Train: [125/300][30/78]	eta 0:01:40 lr 4.015765	time 1.6509 (2.0937)	loss 3.2380 (3.3079)	grad_norm 0.3681 (0.3536)	mem 39782MB
[2023-07-07 12:00:48 RepVGG-A0] (main.py 282): INFO Train: [125/300][40/78]	eta 0:01:16 lr 4.011610	time 3.9872 (2.0176)	loss 3.3095 (3.3159)	grad_norm 0.3332 (0.3625)	mem 39782MB
[2023-07-07 12:01:03 RepVGG-A0] (main.py 282): INFO Train: [125/300][50/78]	eta 0:00:53 lr 4.007453	time 1.1744 (1.9172)	loss 3.3592 (3.3141)	grad_norm 0.3658 (0.3631)	mem 39782MB
[2023-07-07 12:01:18 RepVGG-A0] (main.py 282): INFO Train: [125/300][60/78]	eta 0:00:33 lr 4.003296	time 1.1724 (1.8435)	loss 3.3668 (3.3151)	grad_norm 0.4948 (0.3656)	mem 39782MB
[2023-07-07 12:01:34 RepVGG-A0] (main.py 282): INFO Train: [125/300][70/78]	eta 0:00:14 lr 3.999136	time 1.3730 (1.8068)	loss 3.4138 (3.3189)	grad_norm 0.3758 (0.3696)	mem 39782MB
[2023-07-07 12:01:46 RepVGG-A0] (main.py 291): INFO EPOCH 125 training takes 0:02:19
[2023-07-07 12:02:09 RepVGG-A0] (main.py 282): INFO Train: [126/300][0/78]	eta 0:29:51 lr 3.995808	time 22.9698 (22.9698)	loss 3.1721 (3.1721)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 12:02:23 RepVGG-A0] (main.py 282): INFO Train: [126/300][10/78]	eta 0:03:48 lr 3.991646	time 1.1725 (3.3553)	loss 3.2622 (3.2366)	grad_norm 0.4313 (0.3699)	mem 39782MB
[2023-07-07 12:02:36 RepVGG-A0] (main.py 282): INFO Train: [126/300][20/78]	eta 0:02:19 lr 3.987482	time 1.2347 (2.4111)	loss 4.1004 (3.4903)	grad_norm 0.7351 (0.5165)	mem 39782MB
[2023-07-07 12:02:51 RepVGG-A0] (main.py 282): INFO Train: [126/300][30/78]	eta 0:01:40 lr 3.983318	time 1.1769 (2.0994)	loss 3.5243 (3.6016)	grad_norm 0.2850 (0.4961)	mem 39782MB
[2023-07-07 12:03:10 RepVGG-A0] (main.py 282): INFO Train: [126/300][40/78]	eta 0:01:17 lr 3.979151	time 4.5183 (2.0502)	loss 3.3173 (3.5479)	grad_norm 0.2782 (0.4436)	mem 39782MB
[2023-07-07 12:03:24 RepVGG-A0] (main.py 282): INFO Train: [126/300][50/78]	eta 0:00:54 lr 3.974984	time 1.1730 (1.9339)	loss 3.2500 (3.4930)	grad_norm 0.3118 (0.4131)	mem 39782MB
[2023-07-07 12:03:40 RepVGG-A0] (main.py 282): INFO Train: [126/300][60/78]	eta 0:00:33 lr 3.970815	time 1.3467 (1.8729)	loss 3.2159 (3.4524)	grad_norm 0.2914 (0.3957)	mem 39782MB
[2023-07-07 12:03:55 RepVGG-A0] (main.py 282): INFO Train: [126/300][70/78]	eta 0:00:14 lr 3.966644	time 1.3353 (1.8242)	loss 3.2142 (3.4184)	grad_norm 0.3286 (0.3824)	mem 39782MB
[2023-07-07 12:04:07 RepVGG-A0] (main.py 291): INFO EPOCH 126 training takes 0:02:21
[2023-07-07 12:04:28 RepVGG-A0] (main.py 282): INFO Train: [127/300][0/78]	eta 0:26:35 lr 3.963307	time 20.4538 (20.4538)	loss 3.2132 (3.2132)	grad_norm 0.3726 (0.3726)	mem 39782MB
[2023-07-07 12:04:42 RepVGG-A0] (main.py 282): INFO Train: [127/300][10/78]	eta 0:03:37 lr 3.959134	time 1.3359 (3.1976)	loss 3.1529 (3.1842)	grad_norm 0.2905 (0.3446)	mem 39782MB
[2023-07-07 12:04:59 RepVGG-A0] (main.py 282): INFO Train: [127/300][20/78]	eta 0:02:24 lr 3.954960	time 1.4435 (2.4922)	loss 3.3442 (3.2031)	grad_norm 0.4340 (0.3657)	mem 39782MB
[2023-07-07 12:05:15 RepVGG-A0] (main.py 282): INFO Train: [127/300][30/78]	eta 0:01:44 lr 3.950784	time 1.2702 (2.1819)	loss 3.1584 (3.2117)	grad_norm 0.3447 (0.3619)	mem 39782MB
[2023-07-07 12:05:32 RepVGG-A0] (main.py 282): INFO Train: [127/300][40/78]	eta 0:01:18 lr 3.946607	time 1.6184 (2.0654)	loss 3.1847 (3.2073)	grad_norm 0.3421 (0.3549)	mem 39782MB
[2023-07-07 12:05:46 RepVGG-A0] (main.py 282): INFO Train: [127/300][50/78]	eta 0:00:54 lr 3.942429	time 1.1916 (1.9306)	loss 3.2509 (3.2144)	grad_norm 0.3641 (0.3589)	mem 39782MB
[2023-07-07 12:06:01 RepVGG-A0] (main.py 282): INFO Train: [127/300][60/78]	eta 0:00:33 lr 3.938249	time 1.1757 (1.8650)	loss 3.2582 (3.2190)	grad_norm 0.3602 (0.3625)	mem 39782MB
[2023-07-07 12:06:16 RepVGG-A0] (main.py 282): INFO Train: [127/300][70/78]	eta 0:00:14 lr 3.934069	time 1.4493 (1.8131)	loss 3.2461 (3.2171)	grad_norm 0.3669 (0.3619)	mem 39782MB
[2023-07-07 12:06:27 RepVGG-A0] (main.py 291): INFO EPOCH 127 training takes 0:02:19
[2023-07-07 12:06:47 RepVGG-A0] (main.py 282): INFO Train: [128/300][0/78]	eta 0:26:34 lr 3.930723	time 20.4438 (20.4438)	loss 3.2150 (3.2150)	grad_norm 0.4096 (0.4096)	mem 39782MB
[2023-07-07 12:07:02 RepVGG-A0] (main.py 282): INFO Train: [128/300][10/78]	eta 0:03:37 lr 3.926539	time 1.1729 (3.1962)	loss 3.4033 (3.2084)	grad_norm 0.5200 (0.3976)	mem 39782MB
[2023-07-07 12:07:17 RepVGG-A0] (main.py 282): INFO Train: [128/300][20/78]	eta 0:02:17 lr 3.922355	time 1.1734 (2.3791)	loss 3.2237 (3.2414)	grad_norm 0.3907 (0.4163)	mem 39782MB
[2023-07-07 12:07:32 RepVGG-A0] (main.py 282): INFO Train: [128/300][30/78]	eta 0:01:41 lr 3.918169	time 1.5565 (2.1105)	loss 3.2151 (3.2209)	grad_norm 0.3474 (0.3936)	mem 39782MB
[2023-07-07 12:07:49 RepVGG-A0] (main.py 282): INFO Train: [128/300][40/78]	eta 0:01:16 lr 3.913982	time 2.1957 (2.0089)	loss 3.1516 (3.2120)	grad_norm 0.3579 (0.3849)	mem 39782MB
[2023-07-07 12:08:04 RepVGG-A0] (main.py 282): INFO Train: [128/300][50/78]	eta 0:00:53 lr 3.909793	time 1.1723 (1.9088)	loss 3.3755 (3.2441)	grad_norm 0.5066 (0.4082)	mem 39782MB
[2023-07-07 12:08:20 RepVGG-A0] (main.py 282): INFO Train: [128/300][60/78]	eta 0:00:33 lr 3.905603	time 1.3122 (1.8496)	loss 3.2974 (3.2602)	grad_norm 0.3325 (0.4079)	mem 39782MB
[2023-07-07 12:08:35 RepVGG-A0] (main.py 282): INFO Train: [128/300][70/78]	eta 0:00:14 lr 3.901412	time 1.3189 (1.7980)	loss 3.1968 (3.2521)	grad_norm 0.3498 (0.3960)	mem 39782MB
[2023-07-07 12:08:46 RepVGG-A0] (main.py 291): INFO EPOCH 128 training takes 0:02:19
[2023-07-07 12:09:07 RepVGG-A0] (main.py 282): INFO Train: [129/300][0/78]	eta 0:26:47 lr 3.898058	time 20.6127 (20.6127)	loss 3.1042 (3.1042)	grad_norm 0.3332 (0.3332)	mem 39782MB
[2023-07-07 12:09:22 RepVGG-A0] (main.py 282): INFO Train: [129/300][10/78]	eta 0:03:43 lr 3.893865	time 1.1725 (3.2906)	loss 3.1351 (3.1283)	grad_norm 0.3821 (0.3543)	mem 39782MB
[2023-07-07 12:09:37 RepVGG-A0] (main.py 282): INFO Train: [129/300][20/78]	eta 0:02:20 lr 3.889670	time 1.3169 (2.4281)	loss 3.0926 (3.1310)	grad_norm 0.3358 (0.3566)	mem 39782MB
[2023-07-07 12:09:53 RepVGG-A0] (main.py 282): INFO Train: [129/300][30/78]	eta 0:01:43 lr 3.885475	time 1.4403 (2.1517)	loss 3.2841 (3.1362)	grad_norm 0.3979 (0.3596)	mem 39782MB
[2023-07-07 12:10:11 RepVGG-A0] (main.py 282): INFO Train: [129/300][40/78]	eta 0:01:18 lr 3.881277	time 4.1826 (2.0717)	loss 3.4845 (3.1930)	grad_norm 0.4657 (0.3996)	mem 39782MB
[2023-07-07 12:10:26 RepVGG-A0] (main.py 282): INFO Train: [129/300][50/78]	eta 0:00:55 lr 3.877079	time 1.2949 (1.9649)	loss 3.1291 (3.2008)	grad_norm 0.3066 (0.3906)	mem 39782MB
[2023-07-07 12:10:41 RepVGG-A0] (main.py 282): INFO Train: [129/300][60/78]	eta 0:00:33 lr 3.872880	time 1.1832 (1.8755)	loss 3.2047 (3.1974)	grad_norm 0.3338 (0.3834)	mem 39782MB
[2023-07-07 12:10:56 RepVGG-A0] (main.py 282): INFO Train: [129/300][70/78]	eta 0:00:14 lr 3.868679	time 1.1269 (1.8236)	loss 3.1694 (3.1895)	grad_norm 0.3892 (0.3804)	mem 39782MB
[2023-07-07 12:11:07 RepVGG-A0] (main.py 291): INFO EPOCH 129 training takes 0:02:20
[2023-07-07 12:11:28 RepVGG-A0] (main.py 282): INFO Train: [130/300][0/78]	eta 0:26:56 lr 3.865317	time 20.7202 (20.7202)	loss 3.1163 (3.1163)	grad_norm 0.3896 (0.3896)	mem 39782MB
[2023-07-07 12:11:43 RepVGG-A0] (main.py 282): INFO Train: [130/300][10/78]	eta 0:03:42 lr 3.861114	time 1.1910 (3.2772)	loss 3.1731 (3.1167)	grad_norm 0.4363 (0.3777)	mem 39782MB
[2023-07-07 12:11:58 RepVGG-A0] (main.py 282): INFO Train: [130/300][20/78]	eta 0:02:20 lr 3.856910	time 1.1752 (2.4303)	loss 3.1666 (3.1437)	grad_norm 0.3774 (0.3877)	mem 39782MB
[2023-07-07 12:12:14 RepVGG-A0] (main.py 282): INFO Train: [130/300][30/78]	eta 0:01:43 lr 3.852705	time 1.3932 (2.1535)	loss 3.2247 (3.1655)	grad_norm 0.3818 (0.4039)	mem 39782MB
[2023-07-07 12:12:31 RepVGG-A0] (main.py 282): INFO Train: [130/300][40/78]	eta 0:01:18 lr 3.848499	time 3.6626 (2.0591)	loss 3.2308 (3.1654)	grad_norm 0.3226 (0.3881)	mem 39782MB
[2023-07-07 12:12:46 RepVGG-A0] (main.py 282): INFO Train: [130/300][50/78]	eta 0:00:54 lr 3.844291	time 1.1729 (1.9449)	loss 3.1404 (3.1640)	grad_norm 0.3681 (0.3855)	mem 39782MB
[2023-07-07 12:13:00 RepVGG-A0] (main.py 282): INFO Train: [130/300][60/78]	eta 0:00:33 lr 3.840082	time 1.2106 (1.8538)	loss 3.1693 (3.1617)	grad_norm 0.4122 (0.3846)	mem 39782MB
[2023-07-07 12:13:16 RepVGG-A0] (main.py 282): INFO Train: [130/300][70/78]	eta 0:00:14 lr 3.835872	time 1.2115 (1.8090)	loss 3.3261 (3.1660)	grad_norm 0.4715 (0.3867)	mem 39782MB
[2023-07-07 12:13:27 RepVGG-A0] (main.py 291): INFO EPOCH 130 training takes 0:02:20
[2023-07-07 12:13:49 RepVGG-A0] (main.py 282): INFO Train: [131/300][0/78]	eta 0:28:29 lr 3.832503	time 21.9136 (21.9136)	loss 3.1355 (3.1355)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 12:14:04 RepVGG-A0] (main.py 282): INFO Train: [131/300][10/78]	eta 0:03:48 lr 3.828291	time 1.1720 (3.3555)	loss 3.0100 (3.1385)	grad_norm 0.3330 (0.3943)	mem 39782MB
[2023-07-07 12:14:18 RepVGG-A0] (main.py 282): INFO Train: [131/300][20/78]	eta 0:02:21 lr 3.824078	time 1.1724 (2.4364)	loss 3.0755 (3.1272)	grad_norm 0.3571 (0.3748)	mem 39782MB
[2023-07-07 12:14:34 RepVGG-A0] (main.py 282): INFO Train: [131/300][30/78]	eta 0:01:43 lr 3.819864	time 1.1290 (2.1533)	loss 3.1851 (3.1259)	grad_norm 0.4180 (0.3766)	mem 39782MB
[2023-07-07 12:14:52 RepVGG-A0] (main.py 282): INFO Train: [131/300][40/78]	eta 0:01:18 lr 3.815649	time 4.1102 (2.0755)	loss 3.2699 (3.1413)	grad_norm 0.4111 (0.3874)	mem 39782MB
[2023-07-07 12:15:07 RepVGG-A0] (main.py 282): INFO Train: [131/300][50/78]	eta 0:00:54 lr 3.811432	time 1.1729 (1.9530)	loss 3.0646 (3.1395)	grad_norm 0.3226 (0.3814)	mem 39782MB
[2023-07-07 12:15:22 RepVGG-A0] (main.py 282): INFO Train: [131/300][60/78]	eta 0:00:33 lr 3.807215	time 1.4016 (1.8810)	loss 3.1826 (3.1448)	grad_norm 0.4056 (0.3848)	mem 39782MB
[2023-07-07 12:15:36 RepVGG-A0] (main.py 282): INFO Train: [131/300][70/78]	eta 0:00:14 lr 3.802996	time 1.3415 (1.8167)	loss 3.1720 (3.1509)	grad_norm 0.3524 (0.3884)	mem 39782MB
[2023-07-07 12:15:48 RepVGG-A0] (main.py 291): INFO EPOCH 131 training takes 0:02:21
[2023-07-07 12:16:10 RepVGG-A0] (main.py 282): INFO Train: [132/300][0/78]	eta 0:27:43 lr 3.799620	time 21.3298 (21.3298)	loss 3.1213 (3.1213)	grad_norm 0.3986 (0.3986)	mem 39782MB
[2023-07-07 12:16:25 RepVGG-A0] (main.py 282): INFO Train: [132/300][10/78]	eta 0:03:48 lr 3.795400	time 1.1733 (3.3631)	loss 3.1269 (3.1111)	grad_norm 0.3565 (0.3877)	mem 39782MB
[2023-07-07 12:16:41 RepVGG-A0] (main.py 282): INFO Train: [132/300][20/78]	eta 0:02:24 lr 3.791178	time 1.1715 (2.4874)	loss 3.1979 (3.1015)	grad_norm 0.4164 (0.3764)	mem 39782MB
[2023-07-07 12:16:56 RepVGG-A0] (main.py 282): INFO Train: [132/300][30/78]	eta 0:01:44 lr 3.786955	time 1.3821 (2.1867)	loss 3.1567 (3.1198)	grad_norm 0.4345 (0.3963)	mem 39782MB
[2023-07-07 12:17:14 RepVGG-A0] (main.py 282): INFO Train: [132/300][40/78]	eta 0:01:19 lr 3.782731	time 3.7201 (2.0922)	loss 3.1213 (3.1306)	grad_norm 0.3607 (0.3917)	mem 39782MB
[2023-07-07 12:17:30 RepVGG-A0] (main.py 282): INFO Train: [132/300][50/78]	eta 0:00:55 lr 3.778506	time 1.1738 (1.9847)	loss 3.1757 (3.1365)	grad_norm 0.3569 (0.3917)	mem 39782MB
[2023-07-07 12:17:45 RepVGG-A0] (main.py 282): INFO Train: [132/300][60/78]	eta 0:00:34 lr 3.774280	time 1.4249 (1.9124)	loss 3.2283 (3.1360)	grad_norm 0.4383 (0.3900)	mem 39782MB
[2023-07-07 12:18:01 RepVGG-A0] (main.py 282): INFO Train: [132/300][70/78]	eta 0:00:14 lr 3.770053	time 1.1804 (1.8714)	loss 3.0706 (3.1361)	grad_norm 0.3495 (0.3890)	mem 39782MB
[2023-07-07 12:18:13 RepVGG-A0] (main.py 291): INFO EPOCH 132 training takes 0:02:24
[2023-07-07 12:18:35 RepVGG-A0] (main.py 282): INFO Train: [133/300][0/78]	eta 0:27:40 lr 3.766671	time 21.2821 (21.2821)	loss 3.1603 (3.1603)	grad_norm 0.4493 (0.4493)	mem 39782MB
[2023-07-07 12:18:50 RepVGG-A0] (main.py 282): INFO Train: [133/300][10/78]	eta 0:03:49 lr 3.762442	time 1.1888 (3.3683)	loss 3.1182 (3.1749)	grad_norm 0.3868 (0.4279)	mem 39782MB
[2023-07-07 12:19:05 RepVGG-A0] (main.py 282): INFO Train: [133/300][20/78]	eta 0:02:21 lr 3.758213	time 1.4125 (2.4461)	loss 3.0863 (3.1293)	grad_norm 0.3395 (0.3970)	mem 39782MB
[2023-07-07 12:19:21 RepVGG-A0] (main.py 282): INFO Train: [133/300][30/78]	eta 0:01:44 lr 3.753982	time 1.6983 (2.1805)	loss 3.2590 (3.1298)	grad_norm 0.5089 (0.3999)	mem 39782MB
[2023-07-07 12:19:38 RepVGG-A0] (main.py 282): INFO Train: [133/300][40/78]	eta 0:01:18 lr 3.749750	time 3.4447 (2.0777)	loss 3.2793 (3.1711)	grad_norm 0.4644 (0.4221)	mem 39782MB
[2023-07-07 12:19:53 RepVGG-A0] (main.py 282): INFO Train: [133/300][50/78]	eta 0:00:54 lr 3.745517	time 1.1748 (1.9613)	loss 3.1360 (3.1746)	grad_norm 0.3405 (0.4122)	mem 39782MB
[2023-07-07 12:20:08 RepVGG-A0] (main.py 282): INFO Train: [133/300][60/78]	eta 0:00:33 lr 3.741283	time 1.2076 (1.8878)	loss 3.0775 (3.1610)	grad_norm 0.3420 (0.4020)	mem 39782MB
[2023-07-07 12:20:24 RepVGG-A0] (main.py 282): INFO Train: [133/300][70/78]	eta 0:00:14 lr 3.737049	time 1.1367 (1.8382)	loss 3.0664 (3.1509)	grad_norm 0.3681 (0.3957)	mem 39782MB
[2023-07-07 12:20:35 RepVGG-A0] (main.py 291): INFO EPOCH 133 training takes 0:02:21
[2023-07-07 12:20:56 RepVGG-A0] (main.py 282): INFO Train: [134/300][0/78]	eta 0:27:52 lr 3.733660	time 21.4449 (21.4449)	loss 3.1159 (3.1159)	grad_norm 0.4067 (0.4067)	mem 39782MB
[2023-07-07 12:21:10 RepVGG-A0] (main.py 282): INFO Train: [134/300][10/78]	eta 0:03:34 lr 3.729423	time 1.1922 (3.1493)	loss 3.1247 (3.1039)	grad_norm 0.3856 (0.3913)	mem 39782MB
[2023-07-07 12:21:24 RepVGG-A0] (main.py 282): INFO Train: [134/300][20/78]	eta 0:02:15 lr 3.725186	time 1.1732 (2.3402)	loss 3.0225 (3.0984)	grad_norm 0.3655 (0.3833)	mem 39782MB
[2023-07-07 12:21:39 RepVGG-A0] (main.py 282): INFO Train: [134/300][30/78]	eta 0:01:39 lr 3.720948	time 1.5110 (2.0669)	loss 3.1840 (3.0996)	grad_norm 0.3957 (0.3810)	mem 39782MB
[2023-07-07 12:21:58 RepVGG-A0] (main.py 282): INFO Train: [134/300][40/78]	eta 0:01:16 lr 3.716708	time 3.9632 (2.0219)	loss 3.1611 (3.1028)	grad_norm 0.4246 (0.3872)	mem 39782MB
[2023-07-07 12:22:13 RepVGG-A0] (main.py 282): INFO Train: [134/300][50/78]	eta 0:00:53 lr 3.712468	time 1.1937 (1.9203)	loss 3.0761 (3.1117)	grad_norm 0.3637 (0.3909)	mem 39782MB
[2023-07-07 12:22:27 RepVGG-A0] (main.py 282): INFO Train: [134/300][60/78]	eta 0:00:33 lr 3.708227	time 1.1738 (1.8431)	loss 3.0323 (3.1085)	grad_norm 0.3580 (0.3857)	mem 39782MB
[2023-07-07 12:22:42 RepVGG-A0] (main.py 282): INFO Train: [134/300][70/78]	eta 0:00:14 lr 3.703985	time 1.2106 (1.7938)	loss 3.1254 (3.1121)	grad_norm 0.4400 (0.3887)	mem 39782MB
[2023-07-07 12:22:56 RepVGG-A0] (main.py 291): INFO EPOCH 134 training takes 0:02:20
[2023-07-07 12:23:17 RepVGG-A0] (main.py 282): INFO Train: [135/300][0/78]	eta 0:27:37 lr 3.700590	time 21.2463 (21.2463)	loss 3.0780 (3.0780)	grad_norm 0.3975 (0.3975)	mem 39782MB
[2023-07-07 12:23:31 RepVGG-A0] (main.py 282): INFO Train: [135/300][10/78]	eta 0:03:37 lr 3.696347	time 1.1710 (3.2039)	loss 3.0268 (3.0523)	grad_norm 0.3464 (0.3517)	mem 39782MB
[2023-07-07 12:23:46 RepVGG-A0] (main.py 282): INFO Train: [135/300][20/78]	eta 0:02:20 lr 3.692102	time 1.1723 (2.4217)	loss 3.3254 (3.1053)	grad_norm 0.5393 (0.4071)	mem 39782MB
[2023-07-07 12:24:02 RepVGG-A0] (main.py 282): INFO Train: [135/300][30/78]	eta 0:01:42 lr 3.687856	time 1.5236 (2.1358)	loss 3.0653 (3.1263)	grad_norm 0.3365 (0.4024)	mem 39782MB
[2023-07-07 12:24:20 RepVGG-A0] (main.py 282): INFO Train: [135/300][40/78]	eta 0:01:17 lr 3.683610	time 3.6081 (2.0510)	loss 3.0862 (3.1114)	grad_norm 0.3426 (0.3885)	mem 39782MB
[2023-07-07 12:24:35 RepVGG-A0] (main.py 282): INFO Train: [135/300][50/78]	eta 0:00:54 lr 3.679363	time 1.1745 (1.9426)	loss 3.1354 (3.1091)	grad_norm 0.3445 (0.3864)	mem 39782MB
[2023-07-07 12:24:50 RepVGG-A0] (main.py 282): INFO Train: [135/300][60/78]	eta 0:00:33 lr 3.675115	time 1.2235 (1.8681)	loss 3.0411 (3.0984)	grad_norm 0.3513 (0.3794)	mem 39782MB
[2023-07-07 12:25:04 RepVGG-A0] (main.py 282): INFO Train: [135/300][70/78]	eta 0:00:14 lr 3.670866	time 1.2686 (1.8137)	loss 3.2578 (3.1109)	grad_norm 0.4666 (0.3906)	mem 39782MB
[2023-07-07 12:25:16 RepVGG-A0] (main.py 291): INFO EPOCH 135 training takes 0:02:20
[2023-07-07 12:25:38 RepVGG-A0] (main.py 282): INFO Train: [136/300][0/78]	eta 0:28:28 lr 3.667466	time 21.9055 (21.9055)	loss 3.0356 (3.0356)	grad_norm 0.3493 (0.3493)	mem 39782MB
[2023-07-07 12:25:53 RepVGG-A0] (main.py 282): INFO Train: [136/300][10/78]	eta 0:03:48 lr 3.663215	time 1.2007 (3.3533)	loss 3.0488 (3.0497)	grad_norm 0.3979 (0.3630)	mem 39782MB
[2023-07-07 12:26:08 RepVGG-A0] (main.py 282): INFO Train: [136/300][20/78]	eta 0:02:22 lr 3.658964	time 1.3868 (2.4632)	loss 3.0263 (3.0473)	grad_norm 0.3678 (0.3712)	mem 39782MB
[2023-07-07 12:26:23 RepVGG-A0] (main.py 282): INFO Train: [136/300][30/78]	eta 0:01:43 lr 3.654712	time 1.3083 (2.1605)	loss 3.1202 (3.0586)	grad_norm 0.3802 (0.3806)	mem 39782MB
[2023-07-07 12:26:41 RepVGG-A0] (main.py 282): INFO Train: [136/300][40/78]	eta 0:01:18 lr 3.650459	time 2.9770 (2.0630)	loss 3.0552 (3.0612)	grad_norm 0.3895 (0.3786)	mem 39782MB
[2023-07-07 12:26:56 RepVGG-A0] (main.py 282): INFO Train: [136/300][50/78]	eta 0:00:54 lr 3.646205	time 1.2340 (1.9571)	loss 3.2074 (3.0793)	grad_norm 0.4674 (0.3877)	mem 39782MB
[2023-07-07 12:27:11 RepVGG-A0] (main.py 282): INFO Train: [136/300][60/78]	eta 0:00:33 lr 3.641950	time 1.2693 (1.8696)	loss 3.0913 (3.0877)	grad_norm 0.3659 (0.3899)	mem 39782MB
[2023-07-07 12:27:26 RepVGG-A0] (main.py 282): INFO Train: [136/300][70/78]	eta 0:00:14 lr 3.637695	time 1.4801 (1.8266)	loss 3.0929 (3.0859)	grad_norm 0.3520 (0.3849)	mem 39782MB
[2023-07-07 12:27:37 RepVGG-A0] (main.py 291): INFO EPOCH 136 training takes 0:02:20
[2023-07-07 12:27:59 RepVGG-A0] (main.py 282): INFO Train: [137/300][0/78]	eta 0:28:04 lr 3.634290	time 21.5909 (21.5909)	loss 3.0432 (3.0432)	grad_norm 0.3797 (0.3797)	mem 39782MB
[2023-07-07 12:28:14 RepVGG-A0] (main.py 282): INFO Train: [137/300][10/78]	eta 0:03:44 lr 3.630033	time 1.1729 (3.3058)	loss 3.2171 (3.1260)	grad_norm 0.4715 (0.4509)	mem 39782MB
[2023-07-07 12:28:28 RepVGG-A0] (main.py 282): INFO Train: [137/300][20/78]	eta 0:02:20 lr 3.625775	time 1.1720 (2.4139)	loss 3.0967 (3.1214)	grad_norm 0.4067 (0.4225)	mem 39782MB
[2023-07-07 12:28:46 RepVGG-A0] (main.py 282): INFO Train: [137/300][30/78]	eta 0:01:45 lr 3.621517	time 2.0851 (2.1973)	loss 3.0672 (3.0965)	grad_norm 0.3459 (0.3985)	mem 39782MB
[2023-07-07 12:29:02 RepVGG-A0] (main.py 282): INFO Train: [137/300][40/78]	eta 0:01:18 lr 3.617258	time 3.3991 (2.0579)	loss 3.0653 (3.0957)	grad_norm 0.3950 (0.3992)	mem 39782MB
[2023-07-07 12:29:16 RepVGG-A0] (main.py 282): INFO Train: [137/300][50/78]	eta 0:00:54 lr 3.612998	time 1.1748 (1.9413)	loss 3.0537 (3.1009)	grad_norm 0.4106 (0.4028)	mem 39782MB
[2023-07-07 12:29:32 RepVGG-A0] (main.py 282): INFO Train: [137/300][60/78]	eta 0:00:33 lr 3.608737	time 1.3484 (1.8718)	loss 3.1232 (3.1033)	grad_norm 0.3766 (0.3988)	mem 39782MB
[2023-07-07 12:29:48 RepVGG-A0] (main.py 282): INFO Train: [137/300][70/78]	eta 0:00:14 lr 3.604476	time 1.1280 (1.8387)	loss 3.0626 (3.0996)	grad_norm 0.3647 (0.3944)	mem 39782MB
[2023-07-07 12:29:59 RepVGG-A0] (main.py 291): INFO EPOCH 137 training takes 0:02:21
[2023-07-07 12:30:20 RepVGG-A0] (main.py 282): INFO Train: [138/300][0/78]	eta 0:27:47 lr 3.601066	time 21.3782 (21.3782)	loss 3.0428 (3.0428)	grad_norm 0.3662 (0.3662)	mem 39782MB
[2023-07-07 12:30:35 RepVGG-A0] (main.py 282): INFO Train: [138/300][10/78]	eta 0:03:44 lr 3.596804	time 1.1733 (3.3003)	loss 3.1137 (3.1001)	grad_norm 0.4469 (0.4457)	mem 39782MB
[2023-07-07 12:30:50 RepVGG-A0] (main.py 282): INFO Train: [138/300][20/78]	eta 0:02:21 lr 3.592540	time 1.1734 (2.4376)	loss 3.0668 (3.0919)	grad_norm 0.3703 (0.4149)	mem 39782MB
[2023-07-07 12:31:05 RepVGG-A0] (main.py 282): INFO Train: [138/300][30/78]	eta 0:01:42 lr 3.588276	time 1.3982 (2.1371)	loss 3.0675 (3.0738)	grad_norm 0.4117 (0.4038)	mem 39782MB
[2023-07-07 12:31:23 RepVGG-A0] (main.py 282): INFO Train: [138/300][40/78]	eta 0:01:18 lr 3.584011	time 4.3288 (2.0540)	loss 2.9901 (3.0674)	grad_norm 0.3636 (0.3978)	mem 39782MB
[2023-07-07 12:31:38 RepVGG-A0] (main.py 282): INFO Train: [138/300][50/78]	eta 0:00:54 lr 3.579746	time 1.3330 (1.9394)	loss 3.0796 (3.0646)	grad_norm 0.3665 (0.3944)	mem 39782MB
[2023-07-07 12:31:53 RepVGG-A0] (main.py 282): INFO Train: [138/300][60/78]	eta 0:00:33 lr 3.575480	time 1.2476 (1.8751)	loss 3.1754 (3.0720)	grad_norm 0.4636 (0.3988)	mem 39782MB
[2023-07-07 12:32:09 RepVGG-A0] (main.py 282): INFO Train: [138/300][70/78]	eta 0:00:14 lr 3.571213	time 1.4126 (1.8270)	loss 3.1338 (3.0885)	grad_norm 0.3824 (0.4076)	mem 39782MB
[2023-07-07 12:32:20 RepVGG-A0] (main.py 291): INFO EPOCH 138 training takes 0:02:21
[2023-07-07 12:32:41 RepVGG-A0] (main.py 282): INFO Train: [139/300][0/78]	eta 0:27:11 lr 3.567799	time 20.9126 (20.9126)	loss 2.9756 (2.9756)	grad_norm 0.3523 (0.3523)	mem 39782MB
[2023-07-07 12:32:56 RepVGG-A0] (main.py 282): INFO Train: [139/300][10/78]	eta 0:03:42 lr 3.563531	time 1.1926 (3.2730)	loss 3.0593 (3.0454)	grad_norm 0.3781 (0.3952)	mem 39782MB
[2023-07-07 12:33:12 RepVGG-A0] (main.py 282): INFO Train: [139/300][20/78]	eta 0:02:23 lr 3.559262	time 1.3973 (2.4726)	loss 3.0848 (3.0467)	grad_norm 0.4609 (0.3871)	mem 39782MB
[2023-07-07 12:33:25 RepVGG-A0] (main.py 282): INFO Train: [139/300][30/78]	eta 0:01:41 lr 3.554993	time 1.4009 (2.1048)	loss 3.0079 (3.0626)	grad_norm 0.3551 (0.3905)	mem 39782MB
[2023-07-07 12:33:43 RepVGG-A0] (main.py 282): INFO Train: [139/300][40/78]	eta 0:01:16 lr 3.550723	time 3.2690 (2.0238)	loss 3.1560 (3.0588)	grad_norm 0.4109 (0.3861)	mem 39782MB
[2023-07-07 12:33:59 RepVGG-A0] (main.py 282): INFO Train: [139/300][50/78]	eta 0:00:54 lr 3.546452	time 1.1718 (1.9391)	loss 3.0359 (3.0549)	grad_norm 0.3252 (0.3840)	mem 39782MB
[2023-07-07 12:34:14 RepVGG-A0] (main.py 282): INFO Train: [139/300][60/78]	eta 0:00:33 lr 3.542181	time 1.1838 (1.8647)	loss 3.1842 (3.0633)	grad_norm 0.4667 (0.3906)	mem 39782MB
[2023-07-07 12:34:29 RepVGG-A0] (main.py 282): INFO Train: [139/300][70/78]	eta 0:00:14 lr 3.537909	time 1.2871 (1.8172)	loss 3.0298 (3.0717)	grad_norm 0.3444 (0.3918)	mem 39782MB
[2023-07-07 12:34:41 RepVGG-A0] (main.py 291): INFO EPOCH 139 training takes 0:02:20
[2023-07-07 12:35:03 RepVGG-A0] (main.py 282): INFO Train: [140/300][0/78]	eta 0:28:56 lr 3.534491	time 22.2571 (22.2571)	loss 2.9090 (2.9090)	grad_norm 0.3325 (0.3325)	mem 39782MB
[2023-07-07 12:35:17 RepVGG-A0] (main.py 282): INFO Train: [140/300][10/78]	eta 0:03:45 lr 3.530218	time 1.1831 (3.3174)	loss 3.0240 (3.0112)	grad_norm 0.4228 (0.3946)	mem 39782MB
[2023-07-07 12:35:31 RepVGG-A0] (main.py 282): INFO Train: [140/300][20/78]	eta 0:02:17 lr 3.525945	time 1.1712 (2.3724)	loss 3.0518 (3.0257)	grad_norm 0.3781 (0.3896)	mem 39782MB
[2023-07-07 12:35:46 RepVGG-A0] (main.py 282): INFO Train: [140/300][30/78]	eta 0:01:41 lr 3.521670	time 1.4407 (2.1056)	loss 2.9507 (3.0284)	grad_norm 0.3498 (0.3859)	mem 39782MB
[2023-07-07 12:36:04 RepVGG-A0] (main.py 282): INFO Train: [140/300][40/78]	eta 0:01:16 lr 3.517396	time 3.7237 (2.0169)	loss 3.0066 (3.0440)	grad_norm 0.3589 (0.3966)	mem 39782MB
[2023-07-07 12:36:19 RepVGG-A0] (main.py 282): INFO Train: [140/300][50/78]	eta 0:00:53 lr 3.513120	time 1.1730 (1.9273)	loss 3.0633 (3.0462)	grad_norm 0.3936 (0.3909)	mem 39782MB
[2023-07-07 12:36:34 RepVGG-A0] (main.py 282): INFO Train: [140/300][60/78]	eta 0:00:33 lr 3.508845	time 1.1794 (1.8597)	loss 3.1395 (3.0525)	grad_norm 0.3913 (0.3921)	mem 39782MB
[2023-07-07 12:36:50 RepVGG-A0] (main.py 282): INFO Train: [140/300][70/78]	eta 0:00:14 lr 3.504568	time 1.4232 (1.8140)	loss 3.1718 (3.0551)	grad_norm 0.3965 (0.3920)	mem 39782MB
[2023-07-07 12:37:01 RepVGG-A0] (main.py 291): INFO EPOCH 140 training takes 0:02:20
[2023-07-07 12:37:18 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.321 (17.321)	Loss 3.0108 (3.0108)	Acc@1 38.049 (38.049)	Acc@5 64.020 (64.020)	Mem 39782MB
[2023-07-07 12:37:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 38.532 Acc@5 64.328
[2023-07-07 12:37:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 140: 38.532%
[2023-07-07 12:37:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 12:37:40 RepVGG-A0] (main.py 282): INFO Train: [141/300][0/78]	eta 0:26:44 lr 3.501147	time 20.5699 (20.5699)	loss 3.0806 (3.0806)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 12:37:55 RepVGG-A0] (main.py 282): INFO Train: [141/300][10/78]	eta 0:03:39 lr 3.496869	time 1.1960 (3.2277)	loss 3.0546 (3.0375)	grad_norm 0.3821 (0.3968)	mem 39782MB
[2023-07-07 12:38:10 RepVGG-A0] (main.py 282): INFO Train: [141/300][20/78]	eta 0:02:19 lr 3.492591	time 1.1754 (2.4096)	loss 2.9801 (3.0326)	grad_norm 0.3761 (0.3932)	mem 39782MB
[2023-07-07 12:38:25 RepVGG-A0] (main.py 282): INFO Train: [141/300][30/78]	eta 0:01:41 lr 3.488313	time 1.2992 (2.1065)	loss 2.9811 (3.0288)	grad_norm 0.3603 (0.3842)	mem 39782MB
[2023-07-07 12:38:43 RepVGG-A0] (main.py 282): INFO Train: [141/300][40/78]	eta 0:01:17 lr 3.484034	time 2.8090 (2.0320)	loss 3.0725 (3.0323)	grad_norm 0.4305 (0.3917)	mem 39782MB
[2023-07-07 12:38:59 RepVGG-A0] (main.py 282): INFO Train: [141/300][50/78]	eta 0:00:54 lr 3.479754	time 1.2983 (1.9364)	loss 2.9928 (3.0303)	grad_norm 0.3592 (0.3885)	mem 39782MB
[2023-07-07 12:39:13 RepVGG-A0] (main.py 282): INFO Train: [141/300][60/78]	eta 0:00:33 lr 3.475474	time 1.4327 (1.8616)	loss 3.0383 (3.0412)	grad_norm 0.3673 (0.3943)	mem 39782MB
[2023-07-07 12:39:29 RepVGG-A0] (main.py 282): INFO Train: [141/300][70/78]	eta 0:00:14 lr 3.471194	time 1.2258 (1.8132)	loss 3.1315 (3.0442)	grad_norm 0.4624 (0.3934)	mem 39782MB
[2023-07-07 12:39:40 RepVGG-A0] (main.py 291): INFO EPOCH 141 training takes 0:02:20
[2023-07-07 12:40:02 RepVGG-A0] (main.py 282): INFO Train: [142/300][0/78]	eta 0:27:35 lr 3.467769	time 21.2242 (21.2242)	loss 3.0899 (3.0899)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 12:40:16 RepVGG-A0] (main.py 282): INFO Train: [142/300][10/78]	eta 0:03:39 lr 3.463488	time 1.1732 (3.2303)	loss 3.0230 (2.9991)	grad_norm 0.3824 (0.3771)	mem 39782MB
[2023-07-07 12:40:31 RepVGG-A0] (main.py 282): INFO Train: [142/300][20/78]	eta 0:02:20 lr 3.459206	time 1.1769 (2.4256)	loss 3.0569 (3.0243)	grad_norm 0.4019 (0.3849)	mem 39782MB
[2023-07-07 12:40:46 RepVGG-A0] (main.py 282): INFO Train: [142/300][30/78]	eta 0:01:42 lr 3.454924	time 1.7102 (2.1291)	loss 3.0585 (3.0268)	grad_norm 0.4027 (0.3831)	mem 39782MB
[2023-07-07 12:41:04 RepVGG-A0] (main.py 282): INFO Train: [142/300][40/78]	eta 0:01:17 lr 3.450641	time 2.6743 (2.0331)	loss 3.1620 (3.0628)	grad_norm 0.4964 (0.4087)	mem 39782MB
[2023-07-07 12:41:18 RepVGG-A0] (main.py 282): INFO Train: [142/300][50/78]	eta 0:00:53 lr 3.446358	time 1.3408 (1.9164)	loss 3.0886 (3.0704)	grad_norm 0.3573 (0.4009)	mem 39782MB
[2023-07-07 12:41:34 RepVGG-A0] (main.py 282): INFO Train: [142/300][60/78]	eta 0:00:33 lr 3.442074	time 1.1807 (1.8547)	loss 3.0624 (3.0668)	grad_norm 0.3691 (0.3967)	mem 39782MB
[2023-07-07 12:41:49 RepVGG-A0] (main.py 282): INFO Train: [142/300][70/78]	eta 0:00:14 lr 3.437790	time 1.1266 (1.8094)	loss 3.1268 (3.0651)	grad_norm 0.4186 (0.3950)	mem 39782MB
[2023-07-07 12:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 142 training takes 0:02:19
[2023-07-07 12:42:20 RepVGG-A0] (main.py 282): INFO Train: [143/300][0/78]	eta 0:26:14 lr 3.434362	time 20.1881 (20.1881)	loss 2.9776 (2.9776)	grad_norm 0.3851 (0.3851)	mem 39782MB
[2023-07-07 12:42:39 RepVGG-A0] (main.py 282): INFO Train: [143/300][10/78]	eta 0:03:58 lr 3.430077	time 1.3976 (3.5062)	loss 2.9634 (2.9689)	grad_norm 0.4055 (0.3765)	mem 39782MB
[2023-07-07 12:42:52 RepVGG-A0] (main.py 282): INFO Train: [143/300][20/78]	eta 0:02:23 lr 3.425792	time 1.1986 (2.4681)	loss 3.0364 (2.9949)	grad_norm 0.4733 (0.3959)	mem 39782MB
[2023-07-07 12:43:06 RepVGG-A0] (main.py 282): INFO Train: [143/300][30/78]	eta 0:01:41 lr 3.421506	time 1.1497 (2.1127)	loss 3.0032 (3.0125)	grad_norm 0.3792 (0.3978)	mem 39782MB
[2023-07-07 12:43:25 RepVGG-A0] (main.py 282): INFO Train: [143/300][40/78]	eta 0:01:18 lr 3.417220	time 5.1461 (2.0598)	loss 3.0417 (3.0139)	grad_norm 0.4165 (0.3976)	mem 39782MB
[2023-07-07 12:43:40 RepVGG-A0] (main.py 282): INFO Train: [143/300][50/78]	eta 0:00:54 lr 3.412934	time 1.1749 (1.9580)	loss 3.0210 (3.0238)	grad_norm 0.3946 (0.3977)	mem 39782MB
[2023-07-07 12:43:56 RepVGG-A0] (main.py 282): INFO Train: [143/300][60/78]	eta 0:00:34 lr 3.408647	time 1.4063 (1.8929)	loss 3.1123 (3.0315)	grad_norm 0.4138 (0.3988)	mem 39782MB
[2023-07-07 12:44:10 RepVGG-A0] (main.py 282): INFO Train: [143/300][70/78]	eta 0:00:14 lr 3.404360	time 1.4068 (1.8255)	loss 3.0326 (3.0341)	grad_norm 0.4123 (0.3991)	mem 39782MB
[2023-07-07 12:44:22 RepVGG-A0] (main.py 291): INFO EPOCH 143 training takes 0:02:22
[2023-07-07 12:44:44 RepVGG-A0] (main.py 282): INFO Train: [144/300][0/78]	eta 0:28:05 lr 3.400930	time 21.6114 (21.6114)	loss 3.0146 (3.0146)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:44:58 RepVGG-A0] (main.py 282): INFO Train: [144/300][10/78]	eta 0:03:42 lr 3.396642	time 1.1717 (3.2672)	loss 3.0088 (3.0112)	grad_norm 0.4112 (0.4074)	mem 39782MB
[2023-07-07 12:45:12 RepVGG-A0] (main.py 282): INFO Train: [144/300][20/78]	eta 0:02:17 lr 3.392354	time 1.1735 (2.3692)	loss 3.0461 (3.0240)	grad_norm 0.3925 (0.4080)	mem 39782MB
[2023-07-07 12:45:27 RepVGG-A0] (main.py 282): INFO Train: [144/300][30/78]	eta 0:01:39 lr 3.388065	time 1.3644 (2.0781)	loss 3.0027 (3.0223)	grad_norm 0.3883 (0.4014)	mem 39782MB
[2023-07-07 12:45:45 RepVGG-A0] (main.py 282): INFO Train: [144/300][40/78]	eta 0:01:17 lr 3.383776	time 3.6948 (2.0290)	loss 3.1039 (3.0165)	grad_norm 0.4080 (0.3968)	mem 39782MB
[2023-07-07 12:46:01 RepVGG-A0] (main.py 282): INFO Train: [144/300][50/78]	eta 0:00:54 lr 3.379487	time 1.1744 (1.9294)	loss 2.9897 (3.0283)	grad_norm 0.3644 (0.4038)	mem 39782MB
[2023-07-07 12:46:16 RepVGG-A0] (main.py 282): INFO Train: [144/300][60/78]	eta 0:00:33 lr 3.375197	time 1.3170 (1.8626)	loss 3.0109 (3.0280)	grad_norm 0.3939 (0.4006)	mem 39782MB
[2023-07-07 12:46:31 RepVGG-A0] (main.py 282): INFO Train: [144/300][70/78]	eta 0:00:14 lr 3.370907	time 1.3594 (1.8140)	loss 3.0686 (3.0272)	grad_norm 0.4046 (0.4025)	mem 39782MB
[2023-07-07 12:46:43 RepVGG-A0] (main.py 291): INFO EPOCH 144 training takes 0:02:21
[2023-07-07 12:47:05 RepVGG-A0] (main.py 282): INFO Train: [145/300][0/78]	eta 0:28:38 lr 3.367475	time 22.0303 (22.0303)	loss 3.0286 (3.0286)	grad_norm 0.4466 (0.4466)	mem 39782MB
[2023-07-07 12:47:20 RepVGG-A0] (main.py 282): INFO Train: [145/300][10/78]	eta 0:03:47 lr 3.363185	time 1.1714 (3.3436)	loss 2.9823 (3.0234)	grad_norm 0.4192 (0.4218)	mem 39782MB
[2023-07-07 12:47:35 RepVGG-A0] (main.py 282): INFO Train: [145/300][20/78]	eta 0:02:22 lr 3.358894	time 1.3181 (2.4599)	loss 3.0768 (3.0359)	grad_norm 0.4341 (0.4198)	mem 39782MB
[2023-07-07 12:47:50 RepVGG-A0] (main.py 282): INFO Train: [145/300][30/78]	eta 0:01:42 lr 3.354603	time 1.2043 (2.1393)	loss 2.9847 (3.0278)	grad_norm 0.3616 (0.4094)	mem 39782MB
[2023-07-07 12:48:08 RepVGG-A0] (main.py 282): INFO Train: [145/300][40/78]	eta 0:01:18 lr 3.350311	time 4.0422 (2.0758)	loss 3.0266 (3.0227)	grad_norm 0.3599 (0.4018)	mem 39782MB
[2023-07-07 12:48:23 RepVGG-A0] (main.py 282): INFO Train: [145/300][50/78]	eta 0:00:54 lr 3.346020	time 1.1737 (1.9593)	loss 3.0106 (3.0237)	grad_norm 0.3457 (0.4026)	mem 39782MB
[2023-07-07 12:48:39 RepVGG-A0] (main.py 282): INFO Train: [145/300][60/78]	eta 0:00:34 lr 3.341728	time 1.1777 (1.8889)	loss 3.0560 (3.0236)	grad_norm 0.4584 (0.3997)	mem 39782MB
[2023-07-07 12:48:54 RepVGG-A0] (main.py 282): INFO Train: [145/300][70/78]	eta 0:00:14 lr 3.337436	time 1.2467 (1.8375)	loss 5.6948 (3.1088)	grad_norm 1.6408 (0.4593)	mem 39782MB
[2023-07-07 12:49:05 RepVGG-A0] (main.py 291): INFO EPOCH 145 training takes 0:02:21
[2023-07-07 12:49:27 RepVGG-A0] (main.py 282): INFO Train: [146/300][0/78]	eta 0:29:05 lr 3.334002	time 22.3747 (22.3747)	loss 5.7340 (5.7340)	grad_norm 0.4792 (0.4792)	mem 39782MB
[2023-07-07 12:49:41 RepVGG-A0] (main.py 282): INFO Train: [146/300][10/78]	eta 0:03:44 lr 3.329710	time 1.1731 (3.3008)	loss 4.7981 (5.2691)	grad_norm 0.3540 (0.4210)	mem 39782MB
[2023-07-07 12:49:56 RepVGG-A0] (main.py 282): INFO Train: [146/300][20/78]	eta 0:02:21 lr 3.325417	time 1.2833 (2.4476)	loss 4.2761 (4.9503)	grad_norm 0.3067 (0.4277)	mem 39782MB
[2023-07-07 12:50:11 RepVGG-A0] (main.py 282): INFO Train: [146/300][30/78]	eta 0:01:42 lr 3.321124	time 1.4834 (2.1369)	loss 3.9854 (4.6732)	grad_norm 0.3535 (0.3978)	mem 39782MB
[2023-07-07 12:50:28 RepVGG-A0] (main.py 282): INFO Train: [146/300][40/78]	eta 0:01:16 lr 3.316831	time 2.7516 (2.0218)	loss 3.7537 (4.4657)	grad_norm 0.3586 (0.3782)	mem 39782MB
[2023-07-07 12:50:44 RepVGG-A0] (main.py 282): INFO Train: [146/300][50/78]	eta 0:00:54 lr 3.312537	time 1.1726 (1.9429)	loss 3.6889 (4.3269)	grad_norm 0.3339 (0.3789)	mem 39782MB
[2023-07-07 12:50:59 RepVGG-A0] (main.py 282): INFO Train: [146/300][60/78]	eta 0:00:33 lr 3.308243	time 1.1948 (1.8676)	loss 3.5196 (4.2062)	grad_norm 0.3752 (0.3709)	mem 39782MB
[2023-07-07 12:51:14 RepVGG-A0] (main.py 282): INFO Train: [146/300][70/78]	eta 0:00:14 lr 3.303950	time 1.4747 (1.8189)	loss 3.5123 (4.1092)	grad_norm 0.4020 (0.3701)	mem 39782MB
[2023-07-07 12:51:26 RepVGG-A0] (main.py 291): INFO EPOCH 146 training takes 0:02:20
[2023-07-07 12:51:49 RepVGG-A0] (main.py 282): INFO Train: [147/300][0/78]	eta 0:29:49 lr 3.300514	time 22.9413 (22.9413)	loss 3.4345 (3.4345)	grad_norm 0.3848 (0.3848)	mem 39782MB
[2023-07-07 12:52:03 RepVGG-A0] (main.py 282): INFO Train: [147/300][10/78]	eta 0:03:49 lr 3.296220	time 1.1727 (3.3804)	loss 3.2717 (3.3980)	grad_norm 0.2838 (0.3664)	mem 39782MB
[2023-07-07 12:52:17 RepVGG-A0] (main.py 282): INFO Train: [147/300][20/78]	eta 0:02:22 lr 3.291926	time 1.1750 (2.4577)	loss 3.4088 (3.3598)	grad_norm 0.4730 (0.3555)	mem 39782MB
[2023-07-07 12:52:32 RepVGG-A0] (main.py 282): INFO Train: [147/300][30/78]	eta 0:01:43 lr 3.287631	time 1.3001 (2.1496)	loss 3.3412 (3.3590)	grad_norm 0.3753 (0.3671)	mem 39782MB
[2023-07-07 12:52:50 RepVGG-A0] (main.py 282): INFO Train: [147/300][40/78]	eta 0:01:18 lr 3.283337	time 3.5117 (2.0696)	loss 3.2900 (3.3451)	grad_norm 0.3578 (0.3627)	mem 39782MB
[2023-07-07 12:53:05 RepVGG-A0] (main.py 282): INFO Train: [147/300][50/78]	eta 0:00:54 lr 3.279042	time 1.1720 (1.9436)	loss 3.2972 (3.3354)	grad_norm 0.3598 (0.3630)	mem 39782MB
[2023-07-07 12:53:20 RepVGG-A0] (main.py 282): INFO Train: [147/300][60/78]	eta 0:00:33 lr 3.274747	time 1.4174 (1.8758)	loss 3.2545 (3.3242)	grad_norm 0.3440 (0.3625)	mem 39782MB
[2023-07-07 12:53:35 RepVGG-A0] (main.py 282): INFO Train: [147/300][70/78]	eta 0:00:14 lr 3.270452	time 1.1761 (1.8276)	loss 3.2582 (3.3193)	grad_norm 0.3847 (0.3696)	mem 39782MB
[2023-07-07 12:53:47 RepVGG-A0] (main.py 291): INFO EPOCH 147 training takes 0:02:21
[2023-07-07 12:54:10 RepVGG-A0] (main.py 282): INFO Train: [148/300][0/78]	eta 0:30:00 lr 3.267016	time 23.0783 (23.0783)	loss 3.1720 (3.1720)	grad_norm 0.3653 (0.3653)	mem 39782MB
[2023-07-07 12:54:24 RepVGG-A0] (main.py 282): INFO Train: [148/300][10/78]	eta 0:03:47 lr 3.262720	time 1.1724 (3.3444)	loss 3.1721 (3.1851)	grad_norm 0.3601 (0.3765)	mem 39782MB
[2023-07-07 12:54:37 RepVGG-A0] (main.py 282): INFO Train: [148/300][20/78]	eta 0:02:18 lr 3.258425	time 1.1734 (2.3885)	loss 3.2028 (3.1926)	grad_norm 0.4312 (0.3857)	mem 39782MB
[2023-07-07 12:54:53 RepVGG-A0] (main.py 282): INFO Train: [148/300][30/78]	eta 0:01:42 lr 3.254129	time 1.4253 (2.1315)	loss 3.0808 (3.1929)	grad_norm 0.3788 (0.3801)	mem 39782MB
[2023-07-07 12:55:11 RepVGG-A0] (main.py 282): INFO Train: [148/300][40/78]	eta 0:01:17 lr 3.249834	time 4.0088 (2.0515)	loss 3.1679 (3.1923)	grad_norm 0.3711 (0.3819)	mem 39782MB
[2023-07-07 12:55:26 RepVGG-A0] (main.py 282): INFO Train: [148/300][50/78]	eta 0:00:54 lr 3.245538	time 1.1739 (1.9436)	loss 3.3131 (3.1934)	grad_norm 0.4977 (0.3843)	mem 39782MB
[2023-07-07 12:55:40 RepVGG-A0] (main.py 282): INFO Train: [148/300][60/78]	eta 0:00:33 lr 3.241242	time 1.1761 (1.8614)	loss 3.1934 (3.2063)	grad_norm 0.3681 (0.3927)	mem 39782MB
[2023-07-07 12:55:55 RepVGG-A0] (main.py 282): INFO Train: [148/300][70/78]	eta 0:00:14 lr 3.236946	time 1.3288 (1.8127)	loss 3.1160 (3.2058)	grad_norm 0.3063 (0.3898)	mem 39782MB
[2023-07-07 12:56:07 RepVGG-A0] (main.py 291): INFO EPOCH 148 training takes 0:02:20
[2023-07-07 12:56:30 RepVGG-A0] (main.py 282): INFO Train: [149/300][0/78]	eta 0:29:12 lr 3.233510	time 22.4645 (22.4645)	loss 3.1470 (3.1470)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:56:45 RepVGG-A0] (main.py 282): INFO Train: [149/300][10/78]	eta 0:03:49 lr 3.229214	time 1.1714 (3.3756)	loss 3.1382 (3.1043)	grad_norm 0.4202 (0.3863)	mem 39782MB
[2023-07-07 12:57:00 RepVGG-A0] (main.py 282): INFO Train: [149/300][20/78]	eta 0:02:26 lr 3.224918	time 1.1770 (2.5175)	loss 3.0648 (3.1100)	grad_norm 0.3391 (0.3832)	mem 39782MB
[2023-07-07 12:57:16 RepVGG-A0] (main.py 282): INFO Train: [149/300][30/78]	eta 0:01:45 lr 3.220622	time 1.5181 (2.2083)	loss 3.1059 (3.1310)	grad_norm 0.3770 (0.3956)	mem 39782MB
[2023-07-07 12:57:33 RepVGG-A0] (main.py 282): INFO Train: [149/300][40/78]	eta 0:01:19 lr 3.216325	time 2.9396 (2.0982)	loss 3.2018 (3.1313)	grad_norm 0.4092 (0.3872)	mem 39782MB
[2023-07-07 12:57:49 RepVGG-A0] (main.py 282): INFO Train: [149/300][50/78]	eta 0:00:55 lr 3.212029	time 1.1729 (1.9853)	loss 3.2103 (3.1370)	grad_norm 0.4082 (0.3911)	mem 39782MB
[2023-07-07 12:58:04 RepVGG-A0] (main.py 282): INFO Train: [149/300][60/78]	eta 0:00:34 lr 3.207733	time 1.1870 (1.9075)	loss 3.1408 (3.1402)	grad_norm 0.3677 (0.3913)	mem 39782MB
[2023-07-07 12:58:19 RepVGG-A0] (main.py 282): INFO Train: [149/300][70/78]	eta 0:00:14 lr 3.203437	time 1.1733 (1.8538)	loss 3.2836 (3.1443)	grad_norm 0.5420 (0.3976)	mem 39782MB
[2023-07-07 12:58:30 RepVGG-A0] (main.py 291): INFO EPOCH 149 training takes 0:02:23
[2023-07-07 12:58:53 RepVGG-A0] (main.py 282): INFO Train: [150/300][0/78]	eta 0:28:41 lr 3.200000	time 22.0701 (22.0701)	loss 3.4613 (3.4613)	grad_norm 0.5789 (0.5789)	mem 39782MB
[2023-07-07 12:59:07 RepVGG-A0] (main.py 282): INFO Train: [150/300][10/78]	eta 0:03:43 lr 3.195704	time 1.1719 (3.2919)	loss 3.1953 (3.2523)	grad_norm 0.3354 (0.3925)	mem 39782MB
[2023-07-07 12:59:22 RepVGG-A0] (main.py 282): INFO Train: [150/300][20/78]	eta 0:02:21 lr 3.191408	time 1.1743 (2.4381)	loss 3.2147 (3.1848)	grad_norm 0.4256 (0.3746)	mem 39782MB
[2023-07-07 12:59:36 RepVGG-A0] (main.py 282): INFO Train: [150/300][30/78]	eta 0:01:41 lr 3.187111	time 1.2469 (2.1223)	loss 3.0492 (3.1587)	grad_norm 0.3508 (0.3665)	mem 39782MB
[2023-07-07 12:59:55 RepVGG-A0] (main.py 282): INFO Train: [150/300][40/78]	eta 0:01:17 lr 3.182815	time 4.0897 (2.0514)	loss 3.1227 (3.1464)	grad_norm 0.3752 (0.3712)	mem 39782MB
[2023-07-07 13:00:09 RepVGG-A0] (main.py 282): INFO Train: [150/300][50/78]	eta 0:00:54 lr 3.178519	time 1.1725 (1.9392)	loss 3.0661 (3.1350)	grad_norm 0.3473 (0.3678)	mem 39782MB
[2023-07-07 13:00:24 RepVGG-A0] (main.py 282): INFO Train: [150/300][60/78]	eta 0:00:33 lr 3.174223	time 1.1804 (1.8682)	loss 3.0514 (3.1250)	grad_norm 0.3779 (0.3675)	mem 39782MB
[2023-07-07 13:00:40 RepVGG-A0] (main.py 282): INFO Train: [150/300][70/78]	eta 0:00:14 lr 3.169927	time 1.2567 (1.8196)	loss 3.1441 (3.1224)	grad_norm 0.4487 (0.3727)	mem 39782MB
[2023-07-07 13:00:51 RepVGG-A0] (main.py 291): INFO EPOCH 150 training takes 0:02:20
[2023-07-07 13:01:12 RepVGG-A0] (main.py 282): INFO Train: [151/300][0/78]	eta 0:26:12 lr 3.166490	time 20.1641 (20.1641)	loss 3.0157 (3.0157)	grad_norm 0.3840 (0.3840)	mem 39782MB
[2023-07-07 13:01:28 RepVGG-A0] (main.py 282): INFO Train: [151/300][10/78]	eta 0:03:46 lr 3.162194	time 1.1703 (3.3261)	loss 2.9631 (3.0400)	grad_norm 0.3811 (0.3730)	mem 39782MB
[2023-07-07 13:01:42 RepVGG-A0] (main.py 282): INFO Train: [151/300][20/78]	eta 0:02:20 lr 3.157899	time 1.2364 (2.4269)	loss 2.9935 (3.0428)	grad_norm 0.3919 (0.3801)	mem 39782MB
[2023-07-07 13:01:57 RepVGG-A0] (main.py 282): INFO Train: [151/300][30/78]	eta 0:01:41 lr 3.153603	time 1.3737 (2.1223)	loss 3.0883 (3.0711)	grad_norm 0.3902 (0.3928)	mem 39782MB
[2023-07-07 13:02:14 RepVGG-A0] (main.py 282): INFO Train: [151/300][40/78]	eta 0:01:16 lr 3.149307	time 3.5997 (2.0196)	loss 3.0800 (3.0745)	grad_norm 0.4150 (0.3921)	mem 39782MB
[2023-07-07 13:02:29 RepVGG-A0] (main.py 282): INFO Train: [151/300][50/78]	eta 0:00:53 lr 3.145011	time 1.1728 (1.9140)	loss 3.0743 (3.0791)	grad_norm 0.4151 (0.3928)	mem 39782MB
[2023-07-07 13:02:45 RepVGG-A0] (main.py 282): INFO Train: [151/300][60/78]	eta 0:00:33 lr 3.140716	time 1.1792 (1.8559)	loss 3.0109 (3.0837)	grad_norm 0.3924 (0.3960)	mem 39782MB
[2023-07-07 13:02:59 RepVGG-A0] (main.py 282): INFO Train: [151/300][70/78]	eta 0:00:14 lr 3.136420	time 1.3690 (1.8029)	loss 3.1516 (3.0916)	grad_norm 0.3548 (0.4000)	mem 39782MB
[2023-07-07 13:03:11 RepVGG-A0] (main.py 291): INFO EPOCH 151 training takes 0:02:19
[2023-07-07 13:03:33 RepVGG-A0] (main.py 282): INFO Train: [152/300][0/78]	eta 0:28:19 lr 3.132984	time 21.7874 (21.7874)	loss 3.0795 (3.0795)	grad_norm 0.4497 (0.4497)	mem 39782MB
[2023-07-07 13:03:48 RepVGG-A0] (main.py 282): INFO Train: [152/300][10/78]	eta 0:03:44 lr 3.128689	time 1.1947 (3.3021)	loss 2.9886 (3.0256)	grad_norm 0.3745 (0.3943)	mem 39782MB
[2023-07-07 13:04:03 RepVGG-A0] (main.py 282): INFO Train: [152/300][20/78]	eta 0:02:22 lr 3.124394	time 1.1724 (2.4535)	loss 3.0254 (3.0194)	grad_norm 0.4298 (0.3839)	mem 39782MB
[2023-07-07 13:04:18 RepVGG-A0] (main.py 282): INFO Train: [152/300][30/78]	eta 0:01:43 lr 3.120099	time 1.1456 (2.1619)	loss 3.0694 (3.0460)	grad_norm 0.3830 (0.4053)	mem 39782MB
[2023-07-07 13:04:36 RepVGG-A0] (main.py 282): INFO Train: [152/300][40/78]	eta 0:01:18 lr 3.115804	time 3.8696 (2.0660)	loss 3.0544 (3.0467)	grad_norm 0.4093 (0.4006)	mem 39782MB
[2023-07-07 13:04:51 RepVGG-A0] (main.py 282): INFO Train: [152/300][50/78]	eta 0:00:54 lr 3.111510	time 1.1924 (1.9499)	loss 3.0525 (3.0516)	grad_norm 0.3895 (0.3977)	mem 39782MB
[2023-07-07 13:05:06 RepVGG-A0] (main.py 282): INFO Train: [152/300][60/78]	eta 0:00:33 lr 3.107215	time 1.1756 (1.8793)	loss 3.0720 (3.0535)	grad_norm 0.4042 (0.3981)	mem 39782MB
[2023-07-07 13:05:21 RepVGG-A0] (main.py 282): INFO Train: [152/300][70/78]	eta 0:00:14 lr 3.102921	time 1.1774 (1.8318)	loss 3.0191 (3.0534)	grad_norm 0.3651 (0.3966)	mem 39782MB
[2023-07-07 13:05:33 RepVGG-A0] (main.py 291): INFO EPOCH 152 training takes 0:02:21
[2023-07-07 13:05:56 RepVGG-A0] (main.py 282): INFO Train: [153/300][0/78]	eta 0:29:36 lr 3.099486	time 22.7729 (22.7729)	loss 2.9515 (2.9515)	grad_norm 0.3790 (0.3790)	mem 39782MB
[2023-07-07 13:06:10 RepVGG-A0] (main.py 282): INFO Train: [153/300][10/78]	eta 0:03:50 lr 3.095192	time 1.1732 (3.3859)	loss 3.0652 (3.0455)	grad_norm 0.4287 (0.4123)	mem 39782MB
[2023-07-07 13:06:25 RepVGG-A0] (main.py 282): INFO Train: [153/300][20/78]	eta 0:02:24 lr 3.090898	time 1.3297 (2.4879)	loss 3.0021 (3.0204)	grad_norm 0.4022 (0.4028)	mem 39782MB
[2023-07-07 13:06:40 RepVGG-A0] (main.py 282): INFO Train: [153/300][30/78]	eta 0:01:43 lr 3.086604	time 1.3832 (2.1593)	loss 3.0463 (3.0329)	grad_norm 0.3835 (0.4120)	mem 39782MB
[2023-07-07 13:06:59 RepVGG-A0] (main.py 282): INFO Train: [153/300][40/78]	eta 0:01:19 lr 3.082311	time 2.9481 (2.0816)	loss 3.0542 (3.0248)	grad_norm 0.3912 (0.4003)	mem 39782MB
[2023-07-07 13:07:13 RepVGG-A0] (main.py 282): INFO Train: [153/300][50/78]	eta 0:00:55 lr 3.078018	time 1.1926 (1.9647)	loss 3.1113 (3.0361)	grad_norm 0.4246 (0.4045)	mem 39782MB
[2023-07-07 13:07:29 RepVGG-A0] (main.py 282): INFO Train: [153/300][60/78]	eta 0:00:34 lr 3.073725	time 1.3794 (1.8942)	loss 3.0936 (3.0427)	grad_norm 0.4018 (0.4046)	mem 39782MB
[2023-07-07 13:07:45 RepVGG-A0] (main.py 282): INFO Train: [153/300][70/78]	eta 0:00:14 lr 3.069432	time 1.1722 (1.8515)	loss 2.9782 (3.0354)	grad_norm 0.3880 (0.4005)	mem 39782MB
[2023-07-07 13:07:55 RepVGG-A0] (main.py 291): INFO EPOCH 153 training takes 0:02:22
[2023-07-07 13:08:18 RepVGG-A0] (main.py 282): INFO Train: [154/300][0/78]	eta 0:29:04 lr 3.065998	time 22.3700 (22.3700)	loss 3.0107 (3.0107)	grad_norm 0.4179 (0.4179)	mem 39782MB
[2023-07-07 13:08:32 RepVGG-A0] (main.py 282): INFO Train: [154/300][10/78]	eta 0:03:48 lr 3.061706	time 1.1969 (3.3658)	loss 3.0233 (3.0007)	grad_norm 0.3944 (0.4052)	mem 39782MB
[2023-07-07 13:08:47 RepVGG-A0] (main.py 282): INFO Train: [154/300][20/78]	eta 0:02:23 lr 3.057414	time 1.1844 (2.4741)	loss 2.9234 (3.0041)	grad_norm 0.3801 (0.4055)	mem 39782MB
[2023-07-07 13:09:03 RepVGG-A0] (main.py 282): INFO Train: [154/300][30/78]	eta 0:01:44 lr 3.053122	time 1.2790 (2.1778)	loss 3.0403 (3.0062)	grad_norm 0.4335 (0.4096)	mem 39782MB
[2023-07-07 13:09:21 RepVGG-A0] (main.py 282): INFO Train: [154/300][40/78]	eta 0:01:18 lr 3.048830	time 2.5603 (2.0775)	loss 2.9551 (3.0215)	grad_norm 0.3554 (0.4097)	mem 39782MB
[2023-07-07 13:09:36 RepVGG-A0] (main.py 282): INFO Train: [154/300][50/78]	eta 0:00:55 lr 3.044539	time 1.5866 (1.9676)	loss 3.0301 (3.0210)	grad_norm 0.3664 (0.4070)	mem 39782MB
[2023-07-07 13:09:51 RepVGG-A0] (main.py 282): INFO Train: [154/300][60/78]	eta 0:00:34 lr 3.040248	time 1.2478 (1.8902)	loss 2.9837 (3.0234)	grad_norm 0.4155 (0.4075)	mem 39782MB
[2023-07-07 13:10:06 RepVGG-A0] (main.py 282): INFO Train: [154/300][70/78]	eta 0:00:14 lr 3.035957	time 1.3592 (1.8411)	loss 3.0204 (3.0248)	grad_norm 0.4036 (0.4070)	mem 39782MB
[2023-07-07 13:10:18 RepVGG-A0] (main.py 291): INFO EPOCH 154 training takes 0:02:22
[2023-07-07 13:10:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][0/78]	eta 0:28:10 lr 3.032525	time 21.6746 (21.6746)	loss 2.9793 (2.9793)	grad_norm 0.3518 (0.3518)	mem 39782MB
[2023-07-07 13:10:54 RepVGG-A0] (main.py 282): INFO Train: [155/300][10/78]	eta 0:03:45 lr 3.028235	time 1.1730 (3.3185)	loss 3.8060 (3.1937)	grad_norm 1.1281 (0.5835)	mem 39782MB
[2023-07-07 13:11:08 RepVGG-A0] (main.py 282): INFO Train: [155/300][20/78]	eta 0:02:17 lr 3.023945	time 1.1716 (2.3727)	loss 5.6562 (4.3702)	grad_norm 0.5419 (0.8188)	mem 39782MB
[2023-07-07 13:11:22 RepVGG-A0] (main.py 282): INFO Train: [155/300][30/78]	eta 0:01:39 lr 3.019655	time 1.2591 (2.0747)	loss 4.5436 (4.5593)	grad_norm 0.3827 (0.6999)	mem 39782MB
[2023-07-07 13:11:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][40/78]	eta 0:01:15 lr 3.015366	time 2.8146 (1.9985)	loss 4.0078 (4.4784)	grad_norm 0.3370 (0.6117)	mem 39782MB
[2023-07-07 13:11:56 RepVGG-A0] (main.py 282): INFO Train: [155/300][50/78]	eta 0:00:53 lr 3.011077	time 1.1763 (1.9169)	loss 3.9182 (4.3686)	grad_norm 0.4179 (0.5589)	mem 39782MB
[2023-07-07 13:12:11 RepVGG-A0] (main.py 282): INFO Train: [155/300][60/78]	eta 0:00:33 lr 3.006789	time 1.1781 (1.8472)	loss 3.5766 (4.2560)	grad_norm 0.2972 (0.5206)	mem 39782MB
[2023-07-07 13:12:26 RepVGG-A0] (main.py 282): INFO Train: [155/300][70/78]	eta 0:00:14 lr 3.002501	time 1.3039 (1.8076)	loss 3.4209 (4.1598)	grad_norm 0.3013 (0.4941)	mem 39782MB
[2023-07-07 13:12:38 RepVGG-A0] (main.py 291): INFO EPOCH 155 training takes 0:02:19
[2023-07-07 13:12:59 RepVGG-A0] (main.py 282): INFO Train: [156/300][0/78]	eta 0:27:24 lr 2.999070	time 21.0862 (21.0862)	loss 3.4668 (3.4668)	grad_norm 0.3452 (0.3452)	mem 39782MB
[2023-07-07 13:13:16 RepVGG-A0] (main.py 282): INFO Train: [156/300][10/78]	eta 0:03:53 lr 2.994783	time 1.1726 (3.4314)	loss 3.3707 (3.3852)	grad_norm 0.3327 (0.3296)	mem 39782MB
[2023-07-07 13:13:30 RepVGG-A0] (main.py 282): INFO Train: [156/300][20/78]	eta 0:02:24 lr 2.990496	time 1.1753 (2.4841)	loss 3.2979 (3.3607)	grad_norm 0.3448 (0.3362)	mem 39782MB
[2023-07-07 13:13:46 RepVGG-A0] (main.py 282): INFO Train: [156/300][30/78]	eta 0:01:45 lr 2.986209	time 1.8602 (2.1955)	loss 3.3427 (3.3443)	grad_norm 0.3727 (0.3414)	mem 39782MB
[2023-07-07 13:14:03 RepVGG-A0] (main.py 282): INFO Train: [156/300][40/78]	eta 0:01:18 lr 2.981922	time 3.1732 (2.0742)	loss 3.2553 (3.3302)	grad_norm 0.3332 (0.3497)	mem 39782MB
[2023-07-07 13:14:18 RepVGG-A0] (main.py 282): INFO Train: [156/300][50/78]	eta 0:00:55 lr 2.977636	time 1.1776 (1.9721)	loss 3.2333 (3.3147)	grad_norm 0.3488 (0.3481)	mem 39782MB
[2023-07-07 13:14:34 RepVGG-A0] (main.py 282): INFO Train: [156/300][60/78]	eta 0:00:34 lr 2.973351	time 1.3796 (1.9116)	loss 3.2614 (3.3037)	grad_norm 0.3679 (0.3528)	mem 39782MB
[2023-07-07 13:14:50 RepVGG-A0] (main.py 282): INFO Train: [156/300][70/78]	eta 0:00:14 lr 2.969066	time 1.6348 (1.8580)	loss 3.1849 (3.2950)	grad_norm 0.3609 (0.3550)	mem 39782MB
[2023-07-07 13:15:02 RepVGG-A0] (main.py 291): INFO EPOCH 156 training takes 0:02:23
[2023-07-07 13:15:23 RepVGG-A0] (main.py 282): INFO Train: [157/300][0/78]	eta 0:28:21 lr 2.965638	time 21.8089 (21.8089)	loss 3.1315 (3.1315)	grad_norm 0.3462 (0.3462)	mem 39782MB
[2023-07-07 13:15:38 RepVGG-A0] (main.py 282): INFO Train: [157/300][10/78]	eta 0:03:46 lr 2.961353	time 1.1725 (3.3315)	loss 3.1993 (3.1268)	grad_norm 0.3874 (0.3658)	mem 39782MB
[2023-07-07 13:15:52 RepVGG-A0] (main.py 282): INFO Train: [157/300][20/78]	eta 0:02:18 lr 2.957069	time 1.1741 (2.3836)	loss 3.2202 (3.1571)	grad_norm 0.3753 (0.3879)	mem 39782MB
[2023-07-07 13:16:09 RepVGG-A0] (main.py 282): INFO Train: [157/300][30/78]	eta 0:01:43 lr 2.952786	time 1.5421 (2.1617)	loss 3.0415 (3.1478)	grad_norm 0.3456 (0.3768)	mem 39782MB
[2023-07-07 13:16:26 RepVGG-A0] (main.py 282): INFO Train: [157/300][40/78]	eta 0:01:18 lr 2.948503	time 4.8361 (2.0621)	loss 3.1157 (3.1422)	grad_norm 0.3783 (0.3821)	mem 39782MB
[2023-07-07 13:16:41 RepVGG-A0] (main.py 282): INFO Train: [157/300][50/78]	eta 0:00:54 lr 2.944220	time 1.4255 (1.9571)	loss 3.1462 (3.1343)	grad_norm 0.4047 (0.3796)	mem 39782MB
[2023-07-07 13:16:57 RepVGG-A0] (main.py 282): INFO Train: [157/300][60/78]	eta 0:00:33 lr 2.939938	time 1.1762 (1.8843)	loss 3.1640 (3.1320)	grad_norm 0.4442 (0.3806)	mem 39782MB
[2023-07-07 13:17:10 RepVGG-A0] (main.py 282): INFO Train: [157/300][70/78]	eta 0:00:14 lr 2.935656	time 1.3752 (1.8112)	loss 3.1545 (3.1345)	grad_norm 0.3872 (0.3874)	mem 39782MB
[2023-07-07 13:17:23 RepVGG-A0] (main.py 291): INFO EPOCH 157 training takes 0:02:21
[2023-07-07 13:17:45 RepVGG-A0] (main.py 282): INFO Train: [158/300][0/78]	eta 0:28:51 lr 2.932231	time 22.2006 (22.2006)	loss 3.0407 (3.0407)	grad_norm 0.3878 (0.3878)	mem 39782MB
[2023-07-07 13:17:59 RepVGG-A0] (main.py 282): INFO Train: [158/300][10/78]	eta 0:03:46 lr 2.927950	time 1.1722 (3.3313)	loss 3.0190 (3.0395)	grad_norm 0.3798 (0.3710)	mem 39782MB
[2023-07-07 13:18:13 RepVGG-A0] (main.py 282): INFO Train: [158/300][20/78]	eta 0:02:19 lr 2.923670	time 1.1768 (2.4117)	loss 3.0549 (3.0443)	grad_norm 0.3635 (0.3752)	mem 39782MB
[2023-07-07 13:18:29 RepVGG-A0] (main.py 282): INFO Train: [158/300][30/78]	eta 0:01:42 lr 2.919390	time 1.4547 (2.1457)	loss 3.1137 (3.0514)	grad_norm 0.3642 (0.3777)	mem 39782MB
[2023-07-07 13:18:48 RepVGG-A0] (main.py 282): INFO Train: [158/300][40/78]	eta 0:01:19 lr 2.915110	time 4.4650 (2.0847)	loss 3.1825 (3.0612)	grad_norm 0.4779 (0.3854)	mem 39782MB
[2023-07-07 13:19:03 RepVGG-A0] (main.py 282): INFO Train: [158/300][50/78]	eta 0:00:55 lr 2.910831	time 1.1721 (1.9657)	loss 3.0801 (3.0712)	grad_norm 0.4053 (0.3954)	mem 39782MB
[2023-07-07 13:19:18 RepVGG-A0] (main.py 282): INFO Train: [158/300][60/78]	eta 0:00:34 lr 2.906553	time 1.1966 (1.8893)	loss 3.1149 (3.0761)	grad_norm 0.4078 (0.3960)	mem 39782MB
[2023-07-07 13:19:33 RepVGG-A0] (main.py 282): INFO Train: [158/300][70/78]	eta 0:00:14 lr 2.902275	time 1.2046 (1.8285)	loss 3.1384 (3.0795)	grad_norm 0.4382 (0.3976)	mem 39782MB
[2023-07-07 13:19:44 RepVGG-A0] (main.py 291): INFO EPOCH 158 training takes 0:02:21
[2023-07-07 13:20:07 RepVGG-A0] (main.py 282): INFO Train: [159/300][0/78]	eta 0:29:52 lr 2.898853	time 22.9834 (22.9834)	loss 2.9717 (2.9717)	grad_norm 0.3711 (0.3711)	mem 39782MB
[2023-07-07 13:20:21 RepVGG-A0] (main.py 282): INFO Train: [159/300][10/78]	eta 0:03:48 lr 2.894577	time 1.1715 (3.3589)	loss 2.9873 (3.0134)	grad_norm 0.3875 (0.3844)	mem 39782MB
[2023-07-07 13:20:35 RepVGG-A0] (main.py 282): INFO Train: [159/300][20/78]	eta 0:02:20 lr 2.890300	time 1.1986 (2.4297)	loss 3.1352 (3.0456)	grad_norm 0.5703 (0.4232)	mem 39782MB
[2023-07-07 13:20:49 RepVGG-A0] (main.py 282): INFO Train: [159/300][30/78]	eta 0:01:41 lr 2.886024	time 1.2392 (2.1122)	loss 3.0933 (3.0562)	grad_norm 0.3473 (0.4154)	mem 39782MB
[2023-07-07 13:21:08 RepVGG-A0] (main.py 282): INFO Train: [159/300][40/78]	eta 0:01:17 lr 2.881749	time 3.5622 (2.0462)	loss 3.1082 (3.0569)	grad_norm 0.4536 (0.4129)	mem 39782MB
[2023-07-07 13:21:23 RepVGG-A0] (main.py 282): INFO Train: [159/300][50/78]	eta 0:00:54 lr 2.877475	time 1.2339 (1.9449)	loss 2.9734 (3.0598)	grad_norm 0.3559 (0.4114)	mem 39782MB
[2023-07-07 13:21:39 RepVGG-A0] (main.py 282): INFO Train: [159/300][60/78]	eta 0:00:34 lr 2.873201	time 1.3527 (1.8900)	loss 3.0634 (3.0578)	grad_norm 0.3696 (0.4046)	mem 39782MB
[2023-07-07 13:21:54 RepVGG-A0] (main.py 282): INFO Train: [159/300][70/78]	eta 0:00:14 lr 2.868927	time 1.1861 (1.8333)	loss 3.0530 (3.0551)	grad_norm 0.3634 (0.4023)	mem 39782MB
[2023-07-07 13:22:06 RepVGG-A0] (main.py 291): INFO EPOCH 159 training takes 0:02:22
[2023-07-07 13:22:28 RepVGG-A0] (main.py 282): INFO Train: [160/300][0/78]	eta 0:28:49 lr 2.865509	time 22.1709 (22.1709)	loss 2.9463 (2.9463)	grad_norm 0.3670 (0.3670)	mem 39782MB
[2023-07-07 13:22:43 RepVGG-A0] (main.py 282): INFO Train: [160/300][10/78]	eta 0:03:47 lr 2.861237	time 1.1719 (3.3514)	loss 3.1789 (3.0805)	grad_norm 0.4970 (0.4653)	mem 39782MB
[2023-07-07 13:22:58 RepVGG-A0] (main.py 282): INFO Train: [160/300][20/78]	eta 0:02:23 lr 2.856965	time 1.1789 (2.4685)	loss 2.9947 (3.0440)	grad_norm 0.3629 (0.4239)	mem 39782MB
[2023-07-07 13:23:14 RepVGG-A0] (main.py 282): INFO Train: [160/300][30/78]	eta 0:01:44 lr 2.852694	time 1.3221 (2.1800)	loss 3.0346 (3.0339)	grad_norm 0.4084 (0.4091)	mem 39782MB
[2023-07-07 13:23:31 RepVGG-A0] (main.py 282): INFO Train: [160/300][40/78]	eta 0:01:18 lr 2.848423	time 3.1550 (2.0679)	loss 3.0271 (3.0368)	grad_norm 0.3805 (0.4102)	mem 39782MB
[2023-07-07 13:23:47 RepVGG-A0] (main.py 282): INFO Train: [160/300][50/78]	eta 0:00:55 lr 2.844153	time 1.1773 (1.9678)	loss 3.0634 (3.0301)	grad_norm 0.3968 (0.4078)	mem 39782MB
[2023-07-07 13:24:01 RepVGG-A0] (main.py 282): INFO Train: [160/300][60/78]	eta 0:00:33 lr 2.839884	time 1.2818 (1.8782)	loss 3.0118 (3.0316)	grad_norm 0.3754 (0.4087)	mem 39782MB
[2023-07-07 13:24:17 RepVGG-A0] (main.py 282): INFO Train: [160/300][70/78]	eta 0:00:14 lr 2.835616	time 1.1275 (1.8394)	loss 3.0379 (3.0421)	grad_norm 0.3880 (0.4187)	mem 39782MB
[2023-07-07 13:24:29 RepVGG-A0] (main.py 291): INFO EPOCH 160 training takes 0:02:22
[2023-07-07 13:24:47 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 18.211 (18.211)	Loss 2.4704 (2.4704)	Acc@1 47.650 (47.650)	Acc@5 72.766 (72.766)	Mem 39782MB
[2023-07-07 13:24:48 RepVGG-A0] (main.py 342): INFO  * Acc@1 48.562 Acc@5 72.958
[2023-07-07 13:24:48 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 160: 48.562%
[2023-07-07 13:24:48 RepVGG-A0] (main.py 172): INFO Max accuracy: 48.56%
[2023-07-07 13:25:09 RepVGG-A0] (main.py 282): INFO Train: [161/300][0/78]	eta 0:27:20 lr 2.832201	time 21.0304 (21.0304)	loss 2.8953 (2.8953)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 13:25:26 RepVGG-A0] (main.py 282): INFO Train: [161/300][10/78]	eta 0:03:52 lr 2.827934	time 1.1725 (3.4225)	loss 3.0268 (2.9918)	grad_norm 0.4074 (0.3967)	mem 39782MB
[2023-07-07 13:25:41 RepVGG-A0] (main.py 282): INFO Train: [161/300][20/78]	eta 0:02:25 lr 2.823667	time 1.4852 (2.5024)	loss 2.9927 (2.9968)	grad_norm 0.4197 (0.4031)	mem 39782MB
[2023-07-07 13:25:56 RepVGG-A0] (main.py 282): INFO Train: [161/300][30/78]	eta 0:01:44 lr 2.819401	time 1.8045 (2.1836)	loss 2.9503 (2.9915)	grad_norm 0.3911 (0.3961)	mem 39782MB
[2023-07-07 13:26:13 RepVGG-A0] (main.py 282): INFO Train: [161/300][40/78]	eta 0:01:18 lr 2.815136	time 3.6973 (2.0597)	loss 3.0240 (2.9896)	grad_norm 0.4257 (0.3975)	mem 39782MB
[2023-07-07 13:26:28 RepVGG-A0] (main.py 282): INFO Train: [161/300][50/78]	eta 0:00:54 lr 2.810871	time 1.2963 (1.9531)	loss 3.0171 (2.9983)	grad_norm 0.4067 (0.4060)	mem 39782MB
[2023-07-07 13:26:43 RepVGG-A0] (main.py 282): INFO Train: [161/300][60/78]	eta 0:00:33 lr 2.806607	time 1.1738 (1.8772)	loss 3.0707 (3.0029)	grad_norm 0.4276 (0.4064)	mem 39782MB
[2023-07-07 13:26:58 RepVGG-A0] (main.py 282): INFO Train: [161/300][70/78]	eta 0:00:14 lr 2.802344	time 1.2436 (1.8305)	loss 2.9467 (3.0021)	grad_norm 0.3827 (0.4061)	mem 39782MB
[2023-07-07 13:27:09 RepVGG-A0] (main.py 291): INFO EPOCH 161 training takes 0:02:21
[2023-07-07 13:27:29 RepVGG-A0] (main.py 282): INFO Train: [162/300][0/78]	eta 0:26:11 lr 2.798934	time 20.1420 (20.1420)	loss 2.9519 (2.9519)	grad_norm 0.4832 (0.4832)	mem 39782MB
[2023-07-07 13:27:45 RepVGG-A0] (main.py 282): INFO Train: [162/300][10/78]	eta 0:03:38 lr 2.794672	time 1.1714 (3.2186)	loss 3.0117 (2.9774)	grad_norm 0.4627 (0.4106)	mem 39782MB
[2023-07-07 13:28:00 RepVGG-A0] (main.py 282): INFO Train: [162/300][20/78]	eta 0:02:20 lr 2.790410	time 1.1959 (2.4283)	loss 3.0491 (2.9850)	grad_norm 0.4551 (0.4074)	mem 39782MB
[2023-07-07 13:28:15 RepVGG-A0] (main.py 282): INFO Train: [162/300][30/78]	eta 0:01:41 lr 2.786150	time 1.4705 (2.1060)	loss 2.9961 (2.9937)	grad_norm 0.3686 (0.4090)	mem 39782MB
[2023-07-07 13:28:33 RepVGG-A0] (main.py 282): INFO Train: [162/300][40/78]	eta 0:01:17 lr 2.781890	time 3.7040 (2.0353)	loss 3.0863 (2.9945)	grad_norm 0.5544 (0.4113)	mem 39782MB
[2023-07-07 13:28:48 RepVGG-A0] (main.py 282): INFO Train: [162/300][50/78]	eta 0:00:54 lr 2.777631	time 1.1732 (1.9365)	loss 6.3651 (3.2471)	grad_norm 1.1968 (0.5421)	mem 39782MB
[2023-07-07 13:29:04 RepVGG-A0] (main.py 282): INFO Train: [162/300][60/78]	eta 0:00:33 lr 2.773373	time 1.4187 (1.8745)	loss 4.9938 (3.6054)	grad_norm 0.6170 (0.5680)	mem 39782MB
[2023-07-07 13:29:19 RepVGG-A0] (main.py 282): INFO Train: [162/300][70/78]	eta 0:00:14 lr 2.769116	time 1.7792 (1.8318)	loss 4.0925 (3.7141)	grad_norm 0.4402 (0.5401)	mem 39782MB
[2023-07-07 13:29:31 RepVGG-A0] (main.py 291): INFO EPOCH 162 training takes 0:02:21
[2023-07-07 13:29:53 RepVGG-A0] (main.py 282): INFO Train: [163/300][0/78]	eta 0:29:06 lr 2.765710	time 22.3916 (22.3916)	loss 3.7801 (3.7801)	grad_norm 0.3159 (0.3159)	mem 39782MB
[2023-07-07 13:30:07 RepVGG-A0] (main.py 282): INFO Train: [163/300][10/78]	eta 0:03:41 lr 2.761454	time 1.1931 (3.2553)	loss 3.6044 (3.6808)	grad_norm 0.3559 (0.3428)	mem 39782MB
[2023-07-07 13:30:21 RepVGG-A0] (main.py 282): INFO Train: [163/300][20/78]	eta 0:02:17 lr 2.757199	time 1.1722 (2.3709)	loss 3.4542 (3.6083)	grad_norm 0.3433 (0.3434)	mem 39782MB
[2023-07-07 13:30:36 RepVGG-A0] (main.py 282): INFO Train: [163/300][30/78]	eta 0:01:40 lr 2.752944	time 1.1844 (2.0968)	loss 3.2895 (3.5377)	grad_norm 0.3365 (0.3408)	mem 39782MB
[2023-07-07 13:30:54 RepVGG-A0] (main.py 282): INFO Train: [163/300][40/78]	eta 0:01:16 lr 2.748691	time 3.9112 (2.0222)	loss 3.2746 (3.4911)	grad_norm 0.3382 (0.3436)	mem 39782MB
[2023-07-07 13:31:09 RepVGG-A0] (main.py 282): INFO Train: [163/300][50/78]	eta 0:00:53 lr 2.744438	time 1.1719 (1.9279)	loss 3.2412 (3.4489)	grad_norm 0.3159 (0.3447)	mem 39782MB
[2023-07-07 13:31:24 RepVGG-A0] (main.py 282): INFO Train: [163/300][60/78]	eta 0:00:33 lr 2.740186	time 1.1283 (1.8569)	loss 3.3098 (3.4153)	grad_norm 0.4374 (0.3462)	mem 39782MB
[2023-07-07 13:31:40 RepVGG-A0] (main.py 282): INFO Train: [163/300][70/78]	eta 0:00:14 lr 2.735935	time 1.2071 (1.8110)	loss 3.2949 (3.3898)	grad_norm 0.4030 (0.3485)	mem 39782MB
[2023-07-07 13:31:51 RepVGG-A0] (main.py 291): INFO EPOCH 163 training takes 0:02:20
[2023-07-07 13:32:12 RepVGG-A0] (main.py 282): INFO Train: [164/300][0/78]	eta 0:27:03 lr 2.732534	time 20.8184 (20.8184)	loss 3.2505 (3.2505)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 13:32:28 RepVGG-A0] (main.py 282): INFO Train: [164/300][10/78]	eta 0:03:44 lr 2.728285	time 1.1875 (3.3027)	loss 3.1089 (3.1436)	grad_norm 0.3385 (0.3550)	mem 39782MB
[2023-07-07 13:32:43 RepVGG-A0] (main.py 282): INFO Train: [164/300][20/78]	eta 0:02:22 lr 2.724036	time 1.2670 (2.4553)	loss 3.1444 (3.1250)	grad_norm 0.4180 (0.3588)	mem 39782MB
[2023-07-07 13:32:58 RepVGG-A0] (main.py 282): INFO Train: [164/300][30/78]	eta 0:01:43 lr 2.719788	time 1.1936 (2.1561)	loss 3.1411 (3.1348)	grad_norm 0.3496 (0.3657)	mem 39782MB
[2023-07-07 13:33:15 RepVGG-A0] (main.py 282): INFO Train: [164/300][40/78]	eta 0:01:17 lr 2.715541	time 2.7658 (2.0422)	loss 3.1210 (3.1223)	grad_norm 0.3559 (0.3653)	mem 39782MB
[2023-07-07 13:33:30 RepVGG-A0] (main.py 282): INFO Train: [164/300][50/78]	eta 0:00:53 lr 2.711294	time 1.1731 (1.9265)	loss 3.0815 (3.1164)	grad_norm 0.3679 (0.3675)	mem 39782MB
[2023-07-07 13:33:45 RepVGG-A0] (main.py 282): INFO Train: [164/300][60/78]	eta 0:00:33 lr 2.707049	time 1.2708 (1.8679)	loss 3.0309 (3.1182)	grad_norm 0.3913 (0.3753)	mem 39782MB
[2023-07-07 13:34:01 RepVGG-A0] (main.py 282): INFO Train: [164/300][70/78]	eta 0:00:14 lr 2.702805	time 1.1817 (1.8202)	loss 3.0113 (3.1143)	grad_norm 0.3562 (0.3726)	mem 39782MB
[2023-07-07 13:34:13 RepVGG-A0] (main.py 291): INFO EPOCH 164 training takes 0:02:21
[2023-07-07 13:34:34 RepVGG-A0] (main.py 282): INFO Train: [165/300][0/78]	eta 0:27:13 lr 2.699410	time 20.9418 (20.9418)	loss 3.0444 (3.0444)	grad_norm 0.4425 (0.4425)	mem 39782MB
[2023-07-07 13:34:48 RepVGG-A0] (main.py 282): INFO Train: [165/300][10/78]	eta 0:03:38 lr 2.695167	time 1.1726 (3.2127)	loss 3.0079 (3.0439)	grad_norm 0.3568 (0.3907)	mem 39782MB
[2023-07-07 13:35:02 RepVGG-A0] (main.py 282): INFO Train: [165/300][20/78]	eta 0:02:16 lr 2.690925	time 1.1730 (2.3587)	loss 3.0267 (3.0513)	grad_norm 0.4137 (0.3881)	mem 39782MB
[2023-07-07 13:35:18 RepVGG-A0] (main.py 282): INFO Train: [165/300][30/78]	eta 0:01:40 lr 2.686684	time 1.2063 (2.0991)	loss 3.0329 (3.0395)	grad_norm 0.3612 (0.3808)	mem 39782MB
[2023-07-07 13:35:37 RepVGG-A0] (main.py 282): INFO Train: [165/300][40/78]	eta 0:01:17 lr 2.682444	time 4.1799 (2.0469)	loss 3.2123 (3.0469)	grad_norm 0.5732 (0.3978)	mem 39782MB
[2023-07-07 13:35:51 RepVGG-A0] (main.py 282): INFO Train: [165/300][50/78]	eta 0:00:54 lr 2.678205	time 1.1973 (1.9292)	loss 3.0413 (3.0639)	grad_norm 0.3507 (0.4036)	mem 39782MB
[2023-07-07 13:36:06 RepVGG-A0] (main.py 282): INFO Train: [165/300][60/78]	eta 0:00:33 lr 2.673966	time 1.2830 (1.8655)	loss 3.0795 (3.0621)	grad_norm 0.3515 (0.3972)	mem 39782MB
[2023-07-07 13:36:22 RepVGG-A0] (main.py 282): INFO Train: [165/300][70/78]	eta 0:00:14 lr 2.669729	time 1.3337 (1.8191)	loss 3.0046 (3.0601)	grad_norm 0.3679 (0.3942)	mem 39782MB
[2023-07-07 13:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 165 training takes 0:02:21
[2023-07-07 13:36:55 RepVGG-A0] (main.py 282): INFO Train: [166/300][0/78]	eta 0:27:21 lr 2.666340	time 21.0464 (21.0464)	loss 3.0251 (3.0251)	grad_norm 0.3898 (0.3898)	mem 39782MB
[2023-07-07 13:37:11 RepVGG-A0] (main.py 282): INFO Train: [166/300][10/78]	eta 0:03:49 lr 2.662104	time 1.1935 (3.3785)	loss 3.0736 (3.0207)	grad_norm 0.3915 (0.4194)	mem 39782MB
[2023-07-07 13:37:26 RepVGG-A0] (main.py 282): INFO Train: [166/300][20/78]	eta 0:02:23 lr 2.657870	time 1.1750 (2.4806)	loss 3.0244 (3.0190)	grad_norm 0.4045 (0.4189)	mem 39782MB
[2023-07-07 13:37:41 RepVGG-A0] (main.py 282): INFO Train: [166/300][30/78]	eta 0:01:44 lr 2.653636	time 1.2212 (2.1668)	loss 3.0087 (3.0182)	grad_norm 0.4185 (0.4064)	mem 39782MB
[2023-07-07 13:37:59 RepVGG-A0] (main.py 282): INFO Train: [166/300][40/78]	eta 0:01:19 lr 2.649404	time 4.1553 (2.0812)	loss 3.0173 (3.0146)	grad_norm 0.3645 (0.4017)	mem 39782MB
[2023-07-07 13:38:14 RepVGG-A0] (main.py 282): INFO Train: [166/300][50/78]	eta 0:00:55 lr 2.645172	time 1.1956 (1.9704)	loss 3.0313 (3.0123)	grad_norm 0.3789 (0.4005)	mem 39782MB
[2023-07-07 13:38:30 RepVGG-A0] (main.py 282): INFO Train: [166/300][60/78]	eta 0:00:34 lr 2.640941	time 1.4315 (1.8982)	loss 3.0653 (3.0182)	grad_norm 0.4208 (0.4027)	mem 39782MB
[2023-07-07 13:38:45 RepVGG-A0] (main.py 282): INFO Train: [166/300][70/78]	eta 0:00:14 lr 2.636712	time 1.4651 (1.8450)	loss 3.0450 (3.0186)	grad_norm 0.4131 (0.4046)	mem 39782MB
[2023-07-07 13:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 166 training takes 0:02:21
[2023-07-07 13:39:17 RepVGG-A0] (main.py 282): INFO Train: [167/300][0/78]	eta 0:28:39 lr 2.633329	time 22.0398 (22.0398)	loss 3.0398 (3.0398)	grad_norm 0.4661 (0.4661)	mem 39782MB
[2023-07-07 13:39:32 RepVGG-A0] (main.py 282): INFO Train: [167/300][10/78]	eta 0:03:48 lr 2.629101	time 1.1698 (3.3675)	loss 2.9260 (2.9518)	grad_norm 0.4084 (0.4003)	mem 39782MB
[2023-07-07 13:39:47 RepVGG-A0] (main.py 282): INFO Train: [167/300][20/78]	eta 0:02:23 lr 2.624874	time 1.3245 (2.4706)	loss 2.9992 (2.9645)	grad_norm 0.4423 (0.4032)	mem 39782MB
[2023-07-07 13:40:01 RepVGG-A0] (main.py 282): INFO Train: [167/300][30/78]	eta 0:01:42 lr 2.620649	time 1.1781 (2.1251)	loss 2.9778 (2.9745)	grad_norm 0.3657 (0.4048)	mem 39782MB
[2023-07-07 13:40:20 RepVGG-A0] (main.py 282): INFO Train: [167/300][40/78]	eta 0:01:18 lr 2.616424	time 2.3065 (2.0696)	loss 3.0186 (2.9802)	grad_norm 0.3943 (0.3999)	mem 39782MB
[2023-07-07 13:40:35 RepVGG-A0] (main.py 282): INFO Train: [167/300][50/78]	eta 0:00:54 lr 2.612200	time 1.1766 (1.9523)	loss 2.9580 (2.9892)	grad_norm 0.3784 (0.4076)	mem 39782MB
[2023-07-07 13:40:50 RepVGG-A0] (main.py 282): INFO Train: [167/300][60/78]	eta 0:00:33 lr 2.607978	time 1.1369 (1.8833)	loss 2.9867 (2.9927)	grad_norm 0.4593 (0.4087)	mem 39782MB
[2023-07-07 13:41:06 RepVGG-A0] (main.py 282): INFO Train: [167/300][70/78]	eta 0:00:14 lr 2.603756	time 1.1813 (1.8375)	loss 2.9929 (2.9989)	grad_norm 0.4433 (0.4107)	mem 39782MB
[2023-07-07 13:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 167 training takes 0:02:21
[2023-07-07 13:41:38 RepVGG-A0] (main.py 282): INFO Train: [168/300][0/78]	eta 0:28:03 lr 2.600380	time 21.5853 (21.5853)	loss 2.9911 (2.9911)	grad_norm 0.3901 (0.3901)	mem 39782MB
[2023-07-07 13:41:53 RepVGG-A0] (main.py 282): INFO Train: [168/300][10/78]	eta 0:03:45 lr 2.596160	time 1.1720 (3.3110)	loss 2.9557 (2.9305)	grad_norm 0.4271 (0.3940)	mem 39782MB
[2023-07-07 13:42:08 RepVGG-A0] (main.py 282): INFO Train: [168/300][20/78]	eta 0:02:22 lr 2.591942	time 1.2430 (2.4574)	loss 2.9719 (2.9635)	grad_norm 0.4163 (0.4163)	mem 39782MB
[2023-07-07 13:42:24 RepVGG-A0] (main.py 282): INFO Train: [168/300][30/78]	eta 0:01:43 lr 2.587724	time 1.2870 (2.1617)	loss 3.0033 (2.9659)	grad_norm 0.4310 (0.4117)	mem 39782MB
[2023-07-07 13:42:41 RepVGG-A0] (main.py 282): INFO Train: [168/300][40/78]	eta 0:01:17 lr 2.583508	time 3.4523 (2.0511)	loss 2.9501 (2.9688)	grad_norm 0.3683 (0.4127)	mem 39782MB
[2023-07-07 13:42:56 RepVGG-A0] (main.py 282): INFO Train: [168/300][50/78]	eta 0:00:54 lr 2.579293	time 1.1734 (1.9455)	loss 3.0245 (2.9697)	grad_norm 0.4635 (0.4107)	mem 39782MB
[2023-07-07 13:43:11 RepVGG-A0] (main.py 282): INFO Train: [168/300][60/78]	eta 0:00:33 lr 2.575079	time 1.3838 (1.8821)	loss 2.9518 (2.9775)	grad_norm 0.4068 (0.4137)	mem 39782MB
[2023-07-07 13:43:27 RepVGG-A0] (main.py 282): INFO Train: [168/300][70/78]	eta 0:00:14 lr 2.570866	time 1.4771 (1.8418)	loss 2.9732 (2.9778)	grad_norm 0.4133 (0.4139)	mem 39782MB
[2023-07-07 13:43:38 RepVGG-A0] (main.py 291): INFO EPOCH 168 training takes 0:02:21
[2023-07-07 13:43:59 RepVGG-A0] (main.py 282): INFO Train: [169/300][0/78]	eta 0:27:02 lr 2.567497	time 20.8055 (20.8055)	loss 2.8740 (2.8740)	grad_norm 0.3882 (0.3882)	mem 39782MB
[2023-07-07 13:44:15 RepVGG-A0] (main.py 282): INFO Train: [169/300][10/78]	eta 0:03:47 lr 2.563286	time 1.1731 (3.3491)	loss 3.0403 (2.9271)	grad_norm 0.4695 (0.4336)	mem 39782MB
[2023-07-07 13:44:29 RepVGG-A0] (main.py 282): INFO Train: [169/300][20/78]	eta 0:02:19 lr 2.559076	time 1.1714 (2.3982)	loss 2.9650 (2.9288)	grad_norm 0.4118 (0.4210)	mem 39782MB
[2023-07-07 13:44:44 RepVGG-A0] (main.py 282): INFO Train: [169/300][30/78]	eta 0:01:41 lr 2.554867	time 1.1286 (2.1224)	loss 3.0063 (2.9403)	grad_norm 0.4428 (0.4221)	mem 39782MB
[2023-07-07 13:45:02 RepVGG-A0] (main.py 282): INFO Train: [169/300][40/78]	eta 0:01:17 lr 2.550660	time 3.9535 (2.0415)	loss 2.9847 (2.9412)	grad_norm 0.4374 (0.4156)	mem 39782MB
[2023-07-07 13:45:18 RepVGG-A0] (main.py 282): INFO Train: [169/300][50/78]	eta 0:00:54 lr 2.546454	time 1.1740 (1.9531)	loss 3.0624 (2.9482)	grad_norm 0.3932 (0.4165)	mem 39782MB
[2023-07-07 13:45:32 RepVGG-A0] (main.py 282): INFO Train: [169/300][60/78]	eta 0:00:33 lr 2.542249	time 1.1963 (1.8662)	loss 3.0021 (2.9559)	grad_norm 0.4186 (0.4186)	mem 39782MB
[2023-07-07 13:45:47 RepVGG-A0] (main.py 282): INFO Train: [169/300][70/78]	eta 0:00:14 lr 2.538045	time 1.3265 (1.8163)	loss 3.0225 (2.9539)	grad_norm 0.3849 (0.4143)	mem 39782MB
[2023-07-07 13:45:59 RepVGG-A0] (main.py 291): INFO EPOCH 169 training takes 0:02:20
[2023-07-07 13:46:20 RepVGG-A0] (main.py 282): INFO Train: [170/300][0/78]	eta 0:27:40 lr 2.534683	time 21.2872 (21.2872)	loss 3.0217 (3.0217)	grad_norm 0.4632 (0.4632)	mem 39782MB
[2023-07-07 13:46:35 RepVGG-A0] (main.py 282): INFO Train: [170/300][10/78]	eta 0:03:39 lr 2.530481	time 1.1731 (3.2213)	loss 2.9714 (2.9528)	grad_norm 0.4123 (0.4232)	mem 39782MB
[2023-07-07 13:46:49 RepVGG-A0] (main.py 282): INFO Train: [170/300][20/78]	eta 0:02:18 lr 2.526280	time 1.1749 (2.3877)	loss 2.9041 (2.9521)	grad_norm 0.3891 (0.4195)	mem 39782MB
[2023-07-07 13:47:05 RepVGG-A0] (main.py 282): INFO Train: [170/300][30/78]	eta 0:01:42 lr 2.522081	time 1.3269 (2.1288)	loss 2.8566 (2.9446)	grad_norm 0.3868 (0.4124)	mem 39782MB
[2023-07-07 13:47:24 RepVGG-A0] (main.py 282): INFO Train: [170/300][40/78]	eta 0:01:18 lr 2.517883	time 4.1089 (2.0565)	loss 3.0040 (2.9416)	grad_norm 0.4497 (0.4109)	mem 39782MB
[2023-07-07 13:47:38 RepVGG-A0] (main.py 282): INFO Train: [170/300][50/78]	eta 0:00:54 lr 2.513686	time 1.1896 (1.9312)	loss 2.9970 (2.9497)	grad_norm 0.4956 (0.4200)	mem 39782MB
[2023-07-07 13:47:52 RepVGG-A0] (main.py 282): INFO Train: [170/300][60/78]	eta 0:00:33 lr 2.509491	time 1.1870 (1.8545)	loss 2.9493 (2.9547)	grad_norm 0.3695 (0.4194)	mem 39782MB
[2023-07-07 13:48:07 RepVGG-A0] (main.py 282): INFO Train: [170/300][70/78]	eta 0:00:14 lr 2.505296	time 1.2637 (1.8048)	loss 2.9583 (2.9539)	grad_norm 0.4598 (0.4178)	mem 39782MB
[2023-07-07 13:48:19 RepVGG-A0] (main.py 291): INFO EPOCH 170 training takes 0:02:19
[2023-07-07 13:48:41 RepVGG-A0] (main.py 282): INFO Train: [171/300][0/78]	eta 0:28:52 lr 2.501942	time 22.2160 (22.2160)	loss 2.8739 (2.8739)	grad_norm 0.4047 (0.4047)	mem 39782MB
[2023-07-07 13:48:56 RepVGG-A0] (main.py 282): INFO Train: [171/300][10/78]	eta 0:03:46 lr 2.497750	time 1.1721 (3.3330)	loss 2.8664 (2.9158)	grad_norm 0.4071 (0.4257)	mem 39782MB
[2023-07-07 13:49:10 RepVGG-A0] (main.py 282): INFO Train: [171/300][20/78]	eta 0:02:20 lr 2.493559	time 1.1735 (2.4155)	loss 2.8705 (2.9080)	grad_norm 0.4124 (0.4168)	mem 39782MB
[2023-07-07 13:49:26 RepVGG-A0] (main.py 282): INFO Train: [171/300][30/78]	eta 0:01:44 lr 2.489369	time 1.4086 (2.1689)	loss 2.8788 (2.9151)	grad_norm 0.4142 (0.4192)	mem 39782MB
[2023-07-07 13:49:45 RepVGG-A0] (main.py 282): INFO Train: [171/300][40/78]	eta 0:01:19 lr 2.485181	time 3.3710 (2.1031)	loss 2.9313 (2.9244)	grad_norm 0.4302 (0.4287)	mem 39782MB
[2023-07-07 13:50:00 RepVGG-A0] (main.py 282): INFO Train: [171/300][50/78]	eta 0:00:55 lr 2.480994	time 1.1746 (1.9757)	loss 2.9637 (2.9285)	grad_norm 0.4170 (0.4232)	mem 39782MB
[2023-07-07 13:50:15 RepVGG-A0] (main.py 282): INFO Train: [171/300][60/78]	eta 0:00:34 lr 2.476808	time 1.4143 (1.9066)	loss 2.9310 (2.9291)	grad_norm 0.4056 (0.4211)	mem 39782MB
[2023-07-07 13:50:31 RepVGG-A0] (main.py 282): INFO Train: [171/300][70/78]	eta 0:00:14 lr 2.472624	time 1.3803 (1.8510)	loss 2.9365 (2.9310)	grad_norm 0.3904 (0.4189)	mem 39782MB
[2023-07-07 13:50:42 RepVGG-A0] (main.py 291): INFO EPOCH 171 training takes 0:02:22
[2023-07-07 13:51:02 RepVGG-A0] (main.py 282): INFO Train: [172/300][0/78]	eta 0:26:08 lr 2.469277	time 20.1118 (20.1118)	loss 2.9357 (2.9357)	grad_norm 0.4223 (0.4223)	mem 39782MB
[2023-07-07 13:51:18 RepVGG-A0] (main.py 282): INFO Train: [172/300][10/78]	eta 0:03:45 lr 2.465095	time 1.1895 (3.3225)	loss 2.8590 (2.8850)	grad_norm 0.3867 (0.4099)	mem 39782MB
[2023-07-07 13:51:32 RepVGG-A0] (main.py 282): INFO Train: [172/300][20/78]	eta 0:02:18 lr 2.460914	time 1.1736 (2.3958)	loss 2.9127 (2.8948)	grad_norm 0.4396 (0.4193)	mem 39782MB
[2023-07-07 13:51:47 RepVGG-A0] (main.py 282): INFO Train: [172/300][30/78]	eta 0:01:41 lr 2.456735	time 1.3315 (2.1224)	loss 3.0181 (2.9073)	grad_norm 0.4349 (0.4197)	mem 39782MB
[2023-07-07 13:52:04 RepVGG-A0] (main.py 282): INFO Train: [172/300][40/78]	eta 0:01:16 lr 2.452557	time 1.9100 (2.0015)	loss 2.9518 (2.9106)	grad_norm 0.4100 (0.4195)	mem 39782MB
[2023-07-07 13:52:19 RepVGG-A0] (main.py 282): INFO Train: [172/300][50/78]	eta 0:00:53 lr 2.448380	time 1.6145 (1.8993)	loss 3.0142 (2.9132)	grad_norm 0.4344 (0.4189)	mem 39782MB
[2023-07-07 13:52:35 RepVGG-A0] (main.py 282): INFO Train: [172/300][60/78]	eta 0:00:33 lr 2.444205	time 1.3521 (1.8545)	loss 2.9440 (2.9138)	grad_norm 0.3808 (0.4183)	mem 39782MB
[2023-07-07 13:52:50 RepVGG-A0] (main.py 282): INFO Train: [172/300][70/78]	eta 0:00:14 lr 2.440031	time 1.3011 (1.8089)	loss 2.8950 (2.9158)	grad_norm 0.5303 (0.4188)	mem 39782MB
[2023-07-07 13:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 172 training takes 0:02:20
[2023-07-07 13:53:23 RepVGG-A0] (main.py 282): INFO Train: [173/300][0/78]	eta 0:26:57 lr 2.436693	time 20.7365 (20.7365)	loss 3.1386 (3.1386)	grad_norm 0.5914 (0.5914)	mem 39782MB
[2023-07-07 13:53:37 RepVGG-A0] (main.py 282): INFO Train: [173/300][10/78]	eta 0:03:40 lr 2.432521	time 1.1727 (3.2442)	loss 2.8575 (3.0375)	grad_norm 0.3664 (0.4833)	mem 39782MB
[2023-07-07 13:53:52 RepVGG-A0] (main.py 282): INFO Train: [173/300][20/78]	eta 0:02:18 lr 2.428351	time 1.2077 (2.3893)	loss 2.8789 (2.9658)	grad_norm 0.3851 (0.4326)	mem 39782MB
[2023-07-07 13:54:07 RepVGG-A0] (main.py 282): INFO Train: [173/300][30/78]	eta 0:01:41 lr 2.424183	time 1.1383 (2.1087)	loss 2.8076 (2.9444)	grad_norm 0.3749 (0.4145)	mem 39782MB
[2023-07-07 13:54:24 RepVGG-A0] (main.py 282): INFO Train: [173/300][40/78]	eta 0:01:16 lr 2.420015	time 3.7683 (2.0168)	loss 2.7997 (2.9346)	grad_norm 0.3728 (0.4113)	mem 39782MB
[2023-07-07 13:54:41 RepVGG-A0] (main.py 282): INFO Train: [173/300][50/78]	eta 0:00:54 lr 2.415849	time 1.3014 (1.9371)	loss 2.9018 (2.9224)	grad_norm 0.3827 (0.4085)	mem 39782MB
[2023-07-07 13:54:56 RepVGG-A0] (main.py 282): INFO Train: [173/300][60/78]	eta 0:00:33 lr 2.411685	time 1.1686 (1.8651)	loss 2.9471 (2.9228)	grad_norm 0.4212 (0.4086)	mem 39782MB
[2023-07-07 13:55:11 RepVGG-A0] (main.py 282): INFO Train: [173/300][70/78]	eta 0:00:14 lr 2.407522	time 1.1735 (1.8156)	loss 2.9275 (2.9189)	grad_norm 0.3730 (0.4077)	mem 39782MB
[2023-07-07 13:55:22 RepVGG-A0] (main.py 291): INFO EPOCH 173 training takes 0:02:20
[2023-07-07 13:55:45 RepVGG-A0] (main.py 282): INFO Train: [174/300][0/78]	eta 0:28:54 lr 2.404192	time 22.2362 (22.2362)	loss 2.8954 (2.8954)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 13:55:59 RepVGG-A0] (main.py 282): INFO Train: [174/300][10/78]	eta 0:03:44 lr 2.400032	time 1.1720 (3.2943)	loss 2.8285 (2.9059)	grad_norm 0.3906 (0.4351)	mem 39782MB
[2023-07-07 13:56:13 RepVGG-A0] (main.py 282): INFO Train: [174/300][20/78]	eta 0:02:19 lr 2.395873	time 1.1914 (2.4094)	loss 2.9235 (2.9016)	grad_norm 0.4054 (0.4213)	mem 39782MB
[2023-07-07 13:56:29 RepVGG-A0] (main.py 282): INFO Train: [174/300][30/78]	eta 0:01:42 lr 2.391715	time 1.6257 (2.1327)	loss 2.9150 (2.9021)	grad_norm 0.4346 (0.4207)	mem 39782MB
[2023-07-07 13:56:46 RepVGG-A0] (main.py 282): INFO Train: [174/300][40/78]	eta 0:01:17 lr 2.387559	time 3.8218 (2.0413)	loss 2.8672 (2.9087)	grad_norm 0.4119 (0.4222)	mem 39782MB
[2023-07-07 13:57:01 RepVGG-A0] (main.py 282): INFO Train: [174/300][50/78]	eta 0:00:54 lr 2.383404	time 1.1891 (1.9408)	loss 2.8644 (2.9118)	grad_norm 0.3976 (0.4227)	mem 39782MB
[2023-07-07 13:57:17 RepVGG-A0] (main.py 282): INFO Train: [174/300][60/78]	eta 0:00:33 lr 2.379251	time 1.2056 (1.8763)	loss 2.8940 (2.9096)	grad_norm 0.3892 (0.4201)	mem 39782MB
[2023-07-07 13:57:32 RepVGG-A0] (main.py 282): INFO Train: [174/300][70/78]	eta 0:00:14 lr 2.375099	time 1.2020 (1.8261)	loss 2.9348 (2.9141)	grad_norm 0.4304 (0.4233)	mem 39782MB
[2023-07-07 13:57:44 RepVGG-A0] (main.py 291): INFO EPOCH 174 training takes 0:02:21
[2023-07-07 13:58:06 RepVGG-A0] (main.py 282): INFO Train: [175/300][0/78]	eta 0:28:54 lr 2.371779	time 22.2368 (22.2368)	loss 2.8764 (2.8764)	grad_norm 0.4550 (0.4550)	mem 39782MB
[2023-07-07 13:58:20 RepVGG-A0] (main.py 282): INFO Train: [175/300][10/78]	eta 0:03:46 lr 2.367630	time 1.1748 (3.3268)	loss 2.8703 (2.8670)	grad_norm 0.3782 (0.4255)	mem 39782MB
[2023-07-07 13:58:34 RepVGG-A0] (main.py 282): INFO Train: [175/300][20/78]	eta 0:02:18 lr 2.363482	time 1.1731 (2.3958)	loss 2.9342 (2.8609)	grad_norm 0.4397 (0.4166)	mem 39782MB
[2023-07-07 13:58:50 RepVGG-A0] (main.py 282): INFO Train: [175/300][30/78]	eta 0:01:42 lr 2.359336	time 1.1490 (2.1348)	loss 2.8593 (2.8745)	grad_norm 0.3908 (0.4234)	mem 39782MB
[2023-07-07 13:59:08 RepVGG-A0] (main.py 282): INFO Train: [175/300][40/78]	eta 0:01:18 lr 2.355192	time 3.6345 (2.0608)	loss 2.8959 (2.8769)	grad_norm 0.4323 (0.4225)	mem 39782MB
[2023-07-07 13:59:23 RepVGG-A0] (main.py 282): INFO Train: [175/300][50/78]	eta 0:00:54 lr 2.351049	time 1.1741 (1.9527)	loss 2.9491 (2.8963)	grad_norm 0.4569 (0.4365)	mem 39782MB
[2023-07-07 13:59:38 RepVGG-A0] (main.py 282): INFO Train: [175/300][60/78]	eta 0:00:33 lr 2.346907	time 1.2938 (1.8796)	loss 2.9824 (2.8979)	grad_norm 0.4288 (0.4316)	mem 39782MB
[2023-07-07 13:59:52 RepVGG-A0] (main.py 282): INFO Train: [175/300][70/78]	eta 0:00:14 lr 2.342767	time 1.5596 (1.8150)	loss 2.9140 (2.8989)	grad_norm 0.4479 (0.4276)	mem 39782MB
[2023-07-07 14:00:04 RepVGG-A0] (main.py 291): INFO EPOCH 175 training takes 0:02:20
[2023-07-07 14:00:26 RepVGG-A0] (main.py 282): INFO Train: [176/300][0/78]	eta 0:28:41 lr 2.339457	time 22.0755 (22.0755)	loss 2.8790 (2.8790)	grad_norm 0.4049 (0.4049)	mem 39782MB
[2023-07-07 14:00:40 RepVGG-A0] (main.py 282): INFO Train: [176/300][10/78]	eta 0:03:41 lr 2.335319	time 1.1722 (3.2552)	loss 2.8235 (2.8518)	grad_norm 0.4052 (0.4060)	mem 39782MB
[2023-07-07 14:00:54 RepVGG-A0] (main.py 282): INFO Train: [176/300][20/78]	eta 0:02:19 lr 2.331184	time 1.1910 (2.3972)	loss 2.8791 (2.8537)	grad_norm 0.3774 (0.4057)	mem 39782MB
[2023-07-07 14:01:11 RepVGG-A0] (main.py 282): INFO Train: [176/300][30/78]	eta 0:01:43 lr 2.327050	time 1.4099 (2.1459)	loss 2.8669 (2.8662)	grad_norm 0.4550 (0.4164)	mem 39782MB
[2023-07-07 14:01:28 RepVGG-A0] (main.py 282): INFO Train: [176/300][40/78]	eta 0:01:17 lr 2.322917	time 3.6992 (2.0473)	loss 2.9005 (2.8728)	grad_norm 0.4153 (0.4206)	mem 39782MB
[2023-07-07 14:01:44 RepVGG-A0] (main.py 282): INFO Train: [176/300][50/78]	eta 0:00:54 lr 2.318786	time 1.2353 (1.9489)	loss 2.8756 (2.8805)	grad_norm 0.4460 (0.4203)	mem 39782MB
[2023-07-07 14:01:59 RepVGG-A0] (main.py 282): INFO Train: [176/300][60/78]	eta 0:00:33 lr 2.314657	time 1.1796 (1.8804)	loss 2.8787 (2.8829)	grad_norm 0.4125 (0.4201)	mem 39782MB
[2023-07-07 14:02:14 RepVGG-A0] (main.py 282): INFO Train: [176/300][70/78]	eta 0:00:14 lr 2.310529	time 1.4507 (1.8281)	loss 3.0215 (2.8851)	grad_norm 0.4762 (0.4207)	mem 39782MB
[2023-07-07 14:02:25 RepVGG-A0] (main.py 291): INFO EPOCH 176 training takes 0:02:20
[2023-07-07 14:02:47 RepVGG-A0] (main.py 282): INFO Train: [177/300][0/78]	eta 0:28:23 lr 2.307228	time 21.8419 (21.8419)	loss 2.8606 (2.8606)	grad_norm 0.4294 (0.4294)	mem 39782MB
[2023-07-07 14:03:03 RepVGG-A0] (main.py 282): INFO Train: [177/300][10/78]	eta 0:03:52 lr 2.303104	time 1.1715 (3.4157)	loss 2.8287 (2.8676)	grad_norm 0.4109 (0.4347)	mem 39782MB
[2023-07-07 14:03:17 RepVGG-A0] (main.py 282): INFO Train: [177/300][20/78]	eta 0:02:24 lr 2.298980	time 1.1769 (2.4840)	loss 2.8915 (2.8651)	grad_norm 0.4054 (0.4214)	mem 39782MB
[2023-07-07 14:03:32 RepVGG-A0] (main.py 282): INFO Train: [177/300][30/78]	eta 0:01:44 lr 2.294859	time 1.5955 (2.1724)	loss 2.8940 (2.8579)	grad_norm 0.4534 (0.4241)	mem 39782MB
[2023-07-07 14:03:51 RepVGG-A0] (main.py 282): INFO Train: [177/300][40/78]	eta 0:01:19 lr 2.290739	time 3.6480 (2.0868)	loss 2.8719 (2.8631)	grad_norm 0.4210 (0.4281)	mem 39782MB
[2023-07-07 14:04:05 RepVGG-A0] (main.py 282): INFO Train: [177/300][50/78]	eta 0:00:55 lr 2.286621	time 1.1838 (1.9692)	loss 2.9257 (2.8687)	grad_norm 0.4044 (0.4290)	mem 39782MB
[2023-07-07 14:04:20 RepVGG-A0] (main.py 282): INFO Train: [177/300][60/78]	eta 0:00:33 lr 2.282504	time 1.1750 (1.8805)	loss 2.9300 (2.8709)	grad_norm 0.4053 (0.4258)	mem 39782MB
[2023-07-07 14:04:36 RepVGG-A0] (main.py 282): INFO Train: [177/300][70/78]	eta 0:00:14 lr 2.278389	time 1.1650 (1.8403)	loss 2.9404 (2.8738)	grad_norm 0.4117 (0.4240)	mem 39782MB
[2023-07-07 14:04:48 RepVGG-A0] (main.py 291): INFO EPOCH 177 training takes 0:02:22
[2023-07-07 14:05:08 RepVGG-A0] (main.py 282): INFO Train: [178/300][0/78]	eta 0:26:36 lr 2.275098	time 20.4717 (20.4717)	loss 2.8712 (2.8712)	grad_norm 0.5030 (0.5030)	mem 39782MB
[2023-07-07 14:05:23 RepVGG-A0] (main.py 282): INFO Train: [178/300][10/78]	eta 0:03:40 lr 2.270986	time 1.1723 (3.2383)	loss 2.8508 (2.9026)	grad_norm 0.4013 (0.4872)	mem 39782MB
[2023-07-07 14:05:39 RepVGG-A0] (main.py 282): INFO Train: [178/300][20/78]	eta 0:02:21 lr 2.266876	time 1.4311 (2.4333)	loss 2.8355 (2.8785)	grad_norm 0.4032 (0.4468)	mem 39782MB
[2023-07-07 14:05:54 RepVGG-A0] (main.py 282): INFO Train: [178/300][30/78]	eta 0:01:42 lr 2.262767	time 1.3382 (2.1374)	loss 2.9066 (2.8756)	grad_norm 0.5090 (0.4396)	mem 39782MB
[2023-07-07 14:06:12 RepVGG-A0] (main.py 282): INFO Train: [178/300][40/78]	eta 0:01:18 lr 2.258660	time 3.1703 (2.0585)	loss 2.9182 (2.8748)	grad_norm 0.3990 (0.4328)	mem 39782MB
[2023-07-07 14:06:27 RepVGG-A0] (main.py 282): INFO Train: [178/300][50/78]	eta 0:00:54 lr 2.254555	time 1.1713 (1.9437)	loss 2.8213 (2.8734)	grad_norm 0.4083 (0.4322)	mem 39782MB
[2023-07-07 14:06:42 RepVGG-A0] (main.py 282): INFO Train: [178/300][60/78]	eta 0:00:33 lr 2.250452	time 1.2938 (1.8746)	loss 2.8361 (2.8685)	grad_norm 0.4020 (0.4271)	mem 39782MB
[2023-07-07 14:06:57 RepVGG-A0] (main.py 282): INFO Train: [178/300][70/78]	eta 0:00:14 lr 2.246350	time 1.1714 (1.8228)	loss 2.9094 (2.8690)	grad_norm 0.4972 (0.4286)	mem 39782MB
[2023-07-07 14:07:09 RepVGG-A0] (main.py 291): INFO EPOCH 178 training takes 0:02:20
[2023-07-07 14:07:31 RepVGG-A0] (main.py 282): INFO Train: [179/300][0/78]	eta 0:29:37 lr 2.243069	time 22.7871 (22.7871)	loss 2.7717 (2.7717)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 14:07:45 RepVGG-A0] (main.py 282): INFO Train: [179/300][10/78]	eta 0:03:45 lr 2.238971	time 1.1720 (3.3175)	loss 2.7930 (2.8043)	grad_norm 0.4358 (0.4013)	mem 39782MB
[2023-07-07 14:08:00 RepVGG-A0] (main.py 282): INFO Train: [179/300][20/78]	eta 0:02:22 lr 2.234874	time 1.2398 (2.4642)	loss 2.8299 (2.8156)	grad_norm 0.4070 (0.4127)	mem 39782MB
[2023-07-07 14:08:15 RepVGG-A0] (main.py 282): INFO Train: [179/300][30/78]	eta 0:01:43 lr 2.230778	time 1.2871 (2.1504)	loss 2.8455 (2.8239)	grad_norm 0.3977 (0.4138)	mem 39782MB
[2023-07-07 14:08:33 RepVGG-A0] (main.py 282): INFO Train: [179/300][40/78]	eta 0:01:17 lr 2.226685	time 1.4424 (2.0480)	loss 2.8984 (2.8322)	grad_norm 0.4566 (0.4153)	mem 39782MB
[2023-07-07 14:08:48 RepVGG-A0] (main.py 282): INFO Train: [179/300][50/78]	eta 0:00:54 lr 2.222593	time 1.1740 (1.9509)	loss 2.9046 (2.8454)	grad_norm 0.4202 (0.4243)	mem 39782MB
[2023-07-07 14:09:03 RepVGG-A0] (main.py 282): INFO Train: [179/300][60/78]	eta 0:00:33 lr 2.218503	time 1.1928 (1.8788)	loss 2.8639 (2.8488)	grad_norm 0.4486 (0.4242)	mem 39782MB
[2023-07-07 14:09:18 RepVGG-A0] (main.py 282): INFO Train: [179/300][70/78]	eta 0:00:14 lr 2.214415	time 1.2414 (1.8251)	loss 2.7352 (2.8532)	grad_norm 0.4134 (0.4272)	mem 39782MB
[2023-07-07 14:09:30 RepVGG-A0] (main.py 291): INFO EPOCH 179 training takes 0:02:21
[2023-07-07 14:09:52 RepVGG-A0] (main.py 282): INFO Train: [180/300][0/78]	eta 0:28:54 lr 2.211146	time 22.2328 (22.2328)	loss 2.8327 (2.8327)	grad_norm 0.4234 (0.4234)	mem 39782MB
[2023-07-07 14:10:06 RepVGG-A0] (main.py 282): INFO Train: [180/300][10/78]	eta 0:03:43 lr 2.207061	time 1.1736 (3.2797)	loss 2.8042 (2.8281)	grad_norm 0.4227 (0.4185)	mem 39782MB
[2023-07-07 14:10:21 RepVGG-A0] (main.py 282): INFO Train: [180/300][20/78]	eta 0:02:21 lr 2.202977	time 1.1780 (2.4415)	loss 2.8338 (2.8257)	grad_norm 0.4307 (0.4238)	mem 39782MB
[2023-07-07 14:10:37 RepVGG-A0] (main.py 282): INFO Train: [180/300][30/78]	eta 0:01:44 lr 2.198896	time 1.5639 (2.1754)	loss 2.8552 (2.8493)	grad_norm 0.4013 (0.4360)	mem 39782MB
[2023-07-07 14:10:55 RepVGG-A0] (main.py 282): INFO Train: [180/300][40/78]	eta 0:01:18 lr 2.194816	time 3.4077 (2.0667)	loss 2.8822 (2.8517)	grad_norm 0.4398 (0.4329)	mem 39782MB
[2023-07-07 14:11:09 RepVGG-A0] (main.py 282): INFO Train: [180/300][50/78]	eta 0:00:54 lr 2.190738	time 1.1733 (1.9486)	loss 2.9205 (2.8533)	grad_norm 0.4570 (0.4285)	mem 39782MB
[2023-07-07 14:11:25 RepVGG-A0] (main.py 282): INFO Train: [180/300][60/78]	eta 0:00:33 lr 2.186662	time 1.4741 (1.8884)	loss 2.8784 (2.8573)	grad_norm 0.4141 (0.4297)	mem 39782MB
[2023-07-07 14:11:38 RepVGG-A0] (main.py 282): INFO Train: [180/300][70/78]	eta 0:00:14 lr 2.182588	time 1.1763 (1.8087)	loss 2.8947 (2.8609)	grad_norm 0.4716 (0.4313)	mem 39782MB
[2023-07-07 14:11:51 RepVGG-A0] (main.py 291): INFO EPOCH 180 training takes 0:02:20
[2023-07-07 14:12:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.618 (17.618)	Loss 2.2331 (2.2331)	Acc@1 51.160 (51.160)	Acc@5 75.751 (75.751)	Mem 39782MB
[2023-07-07 14:12:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 51.752 Acc@5 76.092
[2023-07-07 14:12:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 180: 51.752%
[2023-07-07 14:12:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 51.75%
[2023-07-07 14:12:30 RepVGG-A0] (main.py 282): INFO Train: [181/300][0/78]	eta 0:27:12 lr 2.179330	time 20.9261 (20.9261)	loss 2.8228 (2.8228)	grad_norm 0.4137 (0.4137)	mem 39782MB
[2023-07-07 14:12:47 RepVGG-A0] (main.py 282): INFO Train: [181/300][10/78]	eta 0:03:50 lr 2.175259	time 1.1707 (3.3924)	loss 2.7742 (2.8111)	grad_norm 0.3866 (0.4094)	mem 39782MB
[2023-07-07 14:13:01 RepVGG-A0] (main.py 282): INFO Train: [181/300][20/78]	eta 0:02:23 lr 2.171190	time 1.4249 (2.4772)	loss 2.8249 (2.8106)	grad_norm 0.4492 (0.4071)	mem 39782MB
[2023-07-07 14:13:17 RepVGG-A0] (main.py 282): INFO Train: [181/300][30/78]	eta 0:01:44 lr 2.167123	time 1.6133 (2.1706)	loss 2.8824 (2.8309)	grad_norm 0.4161 (0.4194)	mem 39782MB
[2023-07-07 14:13:34 RepVGG-A0] (main.py 282): INFO Train: [181/300][40/78]	eta 0:01:18 lr 2.163058	time 4.2182 (2.0634)	loss 2.8729 (2.8324)	grad_norm 0.4424 (0.4200)	mem 39782MB
[2023-07-07 14:13:49 RepVGG-A0] (main.py 282): INFO Train: [181/300][50/78]	eta 0:00:54 lr 2.158994	time 1.1741 (1.9535)	loss 2.8797 (2.8356)	grad_norm 0.4372 (0.4223)	mem 39782MB
[2023-07-07 14:14:03 RepVGG-A0] (main.py 282): INFO Train: [181/300][60/78]	eta 0:00:33 lr 2.154933	time 1.1732 (1.8717)	loss 2.8876 (2.8397)	grad_norm 0.4500 (0.4270)	mem 39782MB
[2023-07-07 14:14:19 RepVGG-A0] (main.py 282): INFO Train: [181/300][70/78]	eta 0:00:14 lr 2.150873	time 1.1724 (1.8326)	loss 2.8160 (2.8410)	grad_norm 0.4354 (0.4248)	mem 39782MB
[2023-07-07 14:14:30 RepVGG-A0] (main.py 291): INFO EPOCH 181 training takes 0:02:20
[2023-07-07 14:14:51 RepVGG-A0] (main.py 282): INFO Train: [182/300][0/78]	eta 0:27:10 lr 2.147627	time 20.9101 (20.9101)	loss 2.8189 (2.8189)	grad_norm 0.4604 (0.4604)	mem 39782MB
[2023-07-07 14:15:05 RepVGG-A0] (main.py 282): INFO Train: [182/300][10/78]	eta 0:03:37 lr 2.143570	time 1.1754 (3.1942)	loss 2.7648 (2.7969)	grad_norm 0.3832 (0.4279)	mem 39782MB
[2023-07-07 14:15:20 RepVGG-A0] (main.py 282): INFO Train: [182/300][20/78]	eta 0:02:17 lr 2.139516	time 1.1723 (2.3721)	loss 2.8685 (2.8098)	grad_norm 0.4696 (0.4289)	mem 39782MB
[2023-07-07 14:15:35 RepVGG-A0] (main.py 282): INFO Train: [182/300][30/78]	eta 0:01:40 lr 2.135464	time 1.3783 (2.0958)	loss 2.8748 (2.8413)	grad_norm 0.4038 (0.4527)	mem 39782MB
[2023-07-07 14:15:53 RepVGG-A0] (main.py 282): INFO Train: [182/300][40/78]	eta 0:01:17 lr 2.131413	time 4.4089 (2.0317)	loss 2.8822 (2.8387)	grad_norm 0.4073 (0.4402)	mem 39782MB
[2023-07-07 14:16:08 RepVGG-A0] (main.py 282): INFO Train: [182/300][50/78]	eta 0:00:54 lr 2.127364	time 1.1732 (1.9312)	loss 2.7834 (2.8395)	grad_norm 0.3986 (0.4338)	mem 39782MB
[2023-07-07 14:16:23 RepVGG-A0] (main.py 282): INFO Train: [182/300][60/78]	eta 0:00:33 lr 2.123318	time 1.1825 (1.8565)	loss 2.9036 (2.8395)	grad_norm 0.4175 (0.4315)	mem 39782MB
[2023-07-07 14:16:39 RepVGG-A0] (main.py 282): INFO Train: [182/300][70/78]	eta 0:00:14 lr 2.119273	time 1.1796 (1.8146)	loss 2.9307 (2.8425)	grad_norm 0.5108 (0.4387)	mem 39782MB
[2023-07-07 14:16:50 RepVGG-A0] (main.py 291): INFO EPOCH 182 training takes 0:02:20
[2023-07-07 14:17:12 RepVGG-A0] (main.py 282): INFO Train: [183/300][0/78]	eta 0:28:27 lr 2.116039	time 21.8971 (21.8971)	loss 2.8600 (2.8600)	grad_norm 0.4088 (0.4088)	mem 39782MB
[2023-07-07 14:17:27 RepVGG-A0] (main.py 282): INFO Train: [183/300][10/78]	eta 0:03:48 lr 2.111997	time 1.1725 (3.3641)	loss 2.7181 (2.7997)	grad_norm 0.4117 (0.4263)	mem 39782MB
[2023-07-07 14:17:41 RepVGG-A0] (main.py 282): INFO Train: [183/300][20/78]	eta 0:02:21 lr 2.107958	time 1.1749 (2.4337)	loss 2.8696 (2.8032)	grad_norm 0.4094 (0.4277)	mem 39782MB
[2023-07-07 14:17:58 RepVGG-A0] (main.py 282): INFO Train: [183/300][30/78]	eta 0:01:44 lr 2.103921	time 1.7533 (2.1735)	loss 2.7941 (2.8043)	grad_norm 0.4136 (0.4238)	mem 39782MB
[2023-07-07 14:18:15 RepVGG-A0] (main.py 282): INFO Train: [183/300][40/78]	eta 0:01:18 lr 2.099886	time 3.9872 (2.0555)	loss 2.8651 (2.8130)	grad_norm 0.4417 (0.4279)	mem 39782MB
[2023-07-07 14:18:30 RepVGG-A0] (main.py 282): INFO Train: [183/300][50/78]	eta 0:00:54 lr 2.095852	time 1.1749 (1.9469)	loss 2.8286 (2.8180)	grad_norm 0.4075 (0.4246)	mem 39782MB
[2023-07-07 14:18:44 RepVGG-A0] (main.py 282): INFO Train: [183/300][60/78]	eta 0:00:33 lr 2.091821	time 1.3822 (1.8707)	loss 2.8584 (2.8253)	grad_norm 0.3917 (0.4247)	mem 39782MB
[2023-07-07 14:19:00 RepVGG-A0] (main.py 282): INFO Train: [183/300][70/78]	eta 0:00:14 lr 2.087791	time 1.2046 (1.8230)	loss 2.8865 (2.8283)	grad_norm 0.4519 (0.4292)	mem 39782MB
[2023-07-07 14:19:11 RepVGG-A0] (main.py 291): INFO EPOCH 183 training takes 0:02:20
[2023-07-07 14:19:33 RepVGG-A0] (main.py 282): INFO Train: [184/300][0/78]	eta 0:28:44 lr 2.084569	time 22.1076 (22.1076)	loss 2.7765 (2.7765)	grad_norm 0.4164 (0.4164)	mem 39782MB
[2023-07-07 14:19:48 RepVGG-A0] (main.py 282): INFO Train: [184/300][10/78]	eta 0:03:52 lr 2.080544	time 1.1716 (3.4141)	loss 2.7928 (2.8065)	grad_norm 0.4092 (0.4290)	mem 39782MB
[2023-07-07 14:20:04 RepVGG-A0] (main.py 282): INFO Train: [184/300][20/78]	eta 0:02:26 lr 2.076520	time 1.4621 (2.5187)	loss 2.8359 (2.8182)	grad_norm 0.4272 (0.4374)	mem 39782MB
[2023-07-07 14:20:19 RepVGG-A0] (main.py 282): INFO Train: [184/300][30/78]	eta 0:01:45 lr 2.072498	time 1.6700 (2.1917)	loss 2.8801 (2.8203)	grad_norm 0.4715 (0.4347)	mem 39782MB
[2023-07-07 14:20:34 RepVGG-A0] (main.py 282): INFO Train: [184/300][40/78]	eta 0:01:16 lr 2.068479	time 1.8310 (2.0206)	loss 2.7404 (2.8233)	grad_norm 0.4266 (0.4359)	mem 39782MB
[2023-07-07 14:20:52 RepVGG-A0] (main.py 282): INFO Train: [184/300][50/78]	eta 0:00:55 lr 2.064461	time 1.3128 (1.9768)	loss 2.8192 (2.8214)	grad_norm 0.4441 (0.4355)	mem 39782MB
[2023-07-07 14:21:06 RepVGG-A0] (main.py 282): INFO Train: [184/300][60/78]	eta 0:00:34 lr 2.060445	time 1.2975 (1.8946)	loss 2.8125 (2.8235)	grad_norm 0.4380 (0.4349)	mem 39782MB
[2023-07-07 14:21:21 RepVGG-A0] (main.py 282): INFO Train: [184/300][70/78]	eta 0:00:14 lr 2.056432	time 1.2145 (1.8281)	loss 2.8384 (2.8265)	grad_norm 0.4162 (0.4350)	mem 39782MB
[2023-07-07 14:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 184 training takes 0:02:21
[2023-07-07 14:21:55 RepVGG-A0] (main.py 282): INFO Train: [185/300][0/78]	eta 0:29:02 lr 2.053223	time 22.3353 (22.3353)	loss 2.7801 (2.7801)	grad_norm 0.4285 (0.4285)	mem 39782MB
[2023-07-07 14:22:10 RepVGG-A0] (main.py 282): INFO Train: [185/300][10/78]	eta 0:03:49 lr 2.049213	time 1.1714 (3.3806)	loss 2.8124 (2.8018)	grad_norm 0.4397 (0.4510)	mem 39782MB
[2023-07-07 14:22:25 RepVGG-A0] (main.py 282): INFO Train: [185/300][20/78]	eta 0:02:24 lr 2.045205	time 1.2081 (2.4880)	loss 2.8541 (2.8035)	grad_norm 0.4867 (0.4514)	mem 39782MB
[2023-07-07 14:22:40 RepVGG-A0] (main.py 282): INFO Train: [185/300][30/78]	eta 0:01:43 lr 2.041199	time 1.3721 (2.1528)	loss 2.8282 (2.8029)	grad_norm 0.4233 (0.4425)	mem 39782MB
[2023-07-07 14:22:59 RepVGG-A0] (main.py 282): INFO Train: [185/300][40/78]	eta 0:01:19 lr 2.037196	time 4.5893 (2.0955)	loss 2.7643 (2.8075)	grad_norm 0.4123 (0.4435)	mem 39782MB
[2023-07-07 14:23:14 RepVGG-A0] (main.py 282): INFO Train: [185/300][50/78]	eta 0:00:55 lr 2.033194	time 1.3838 (1.9791)	loss 2.7714 (2.8130)	grad_norm 0.4245 (0.4378)	mem 39782MB
[2023-07-07 14:23:29 RepVGG-A0] (main.py 282): INFO Train: [185/300][60/78]	eta 0:00:34 lr 2.029195	time 1.1759 (1.9094)	loss 2.8332 (2.8157)	grad_norm 0.4865 (0.4370)	mem 39782MB
[2023-07-07 14:23:45 RepVGG-A0] (main.py 282): INFO Train: [185/300][70/78]	eta 0:00:14 lr 2.025198	time 1.4297 (1.8593)	loss 2.9407 (2.8279)	grad_norm 0.5153 (0.4496)	mem 39782MB
[2023-07-07 14:23:56 RepVGG-A0] (main.py 291): INFO EPOCH 185 training takes 0:02:22
[2023-07-07 14:24:16 RepVGG-A0] (main.py 282): INFO Train: [186/300][0/78]	eta 0:26:38 lr 2.022001	time 20.4894 (20.4894)	loss 2.7749 (2.7749)	grad_norm 0.3953 (0.3953)	mem 39782MB
[2023-07-07 14:24:32 RepVGG-A0] (main.py 282): INFO Train: [186/300][10/78]	eta 0:03:46 lr 2.018008	time 1.1727 (3.3315)	loss 2.7901 (2.7917)	grad_norm 0.4386 (0.4102)	mem 39782MB
[2023-07-07 14:24:46 RepVGG-A0] (main.py 282): INFO Train: [186/300][20/78]	eta 0:02:19 lr 2.014017	time 1.1720 (2.4121)	loss 2.8072 (2.7969)	grad_norm 0.4457 (0.4197)	mem 39782MB
[2023-07-07 14:25:01 RepVGG-A0] (main.py 282): INFO Train: [186/300][30/78]	eta 0:01:41 lr 2.010028	time 1.4111 (2.1137)	loss 2.8075 (2.7972)	grad_norm 0.4208 (0.4273)	mem 39782MB
[2023-07-07 14:25:19 RepVGG-A0] (main.py 282): INFO Train: [186/300][40/78]	eta 0:01:17 lr 2.006040	time 3.1824 (2.0399)	loss 2.8035 (2.8016)	grad_norm 0.3876 (0.4283)	mem 39782MB
[2023-07-07 14:25:35 RepVGG-A0] (main.py 282): INFO Train: [186/300][50/78]	eta 0:00:54 lr 2.002056	time 1.1715 (1.9459)	loss 2.8245 (2.8020)	grad_norm 0.4566 (0.4273)	mem 39782MB
[2023-07-07 14:25:50 RepVGG-A0] (main.py 282): INFO Train: [186/300][60/78]	eta 0:00:33 lr 1.998073	time 1.4390 (1.8745)	loss 2.8608 (2.8084)	grad_norm 0.4367 (0.4297)	mem 39782MB
[2023-07-07 14:26:04 RepVGG-A0] (main.py 282): INFO Train: [186/300][70/78]	eta 0:00:14 lr 1.994092	time 1.1714 (1.8137)	loss 2.8557 (2.8097)	grad_norm 0.4443 (0.4279)	mem 39782MB
[2023-07-07 14:26:16 RepVGG-A0] (main.py 291): INFO EPOCH 186 training takes 0:02:20
[2023-07-07 14:26:38 RepVGG-A0] (main.py 282): INFO Train: [187/300][0/78]	eta 0:28:30 lr 1.990909	time 21.9312 (21.9312)	loss 2.7114 (2.7114)	grad_norm 0.4073 (0.4073)	mem 39782MB
[2023-07-07 14:26:53 RepVGG-A0] (main.py 282): INFO Train: [187/300][10/78]	eta 0:03:46 lr 1.986933	time 1.1928 (3.3295)	loss 2.8416 (2.7752)	grad_norm 0.5060 (0.4395)	mem 39782MB
[2023-07-07 14:27:08 RepVGG-A0] (main.py 282): INFO Train: [187/300][20/78]	eta 0:02:23 lr 1.982958	time 1.1804 (2.4743)	loss 2.7635 (2.7816)	grad_norm 0.4179 (0.4472)	mem 39782MB
[2023-07-07 14:27:24 RepVGG-A0] (main.py 282): INFO Train: [187/300][30/78]	eta 0:01:44 lr 1.978986	time 1.4191 (2.1801)	loss 2.7879 (2.7851)	grad_norm 0.4245 (0.4434)	mem 39782MB
[2023-07-07 14:27:41 RepVGG-A0] (main.py 282): INFO Train: [187/300][40/78]	eta 0:01:18 lr 1.975016	time 2.1001 (2.0694)	loss 2.7688 (2.7816)	grad_norm 0.4820 (0.4404)	mem 39782MB
[2023-07-07 14:27:56 RepVGG-A0] (main.py 282): INFO Train: [187/300][50/78]	eta 0:00:54 lr 1.971048	time 1.2671 (1.9559)	loss 2.8389 (2.7874)	grad_norm 0.4164 (0.4371)	mem 39782MB
[2023-07-07 14:28:11 RepVGG-A0] (main.py 282): INFO Train: [187/300][60/78]	eta 0:00:33 lr 1.967083	time 1.2879 (1.8803)	loss 2.8165 (2.7910)	grad_norm 0.4245 (0.4376)	mem 39782MB
[2023-07-07 14:28:26 RepVGG-A0] (main.py 282): INFO Train: [187/300][70/78]	eta 0:00:14 lr 1.963119	time 1.3025 (1.8308)	loss 2.8028 (2.7933)	grad_norm 0.3970 (0.4364)	mem 39782MB
[2023-07-07 14:28:38 RepVGG-A0] (main.py 291): INFO EPOCH 187 training takes 0:02:21
[2023-07-07 14:28:59 RepVGG-A0] (main.py 282): INFO Train: [188/300][0/78]	eta 0:27:24 lr 1.959950	time 21.0832 (21.0832)	loss 2.7805 (2.7805)	grad_norm 0.4687 (0.4687)	mem 39782MB
[2023-07-07 14:29:14 RepVGG-A0] (main.py 282): INFO Train: [188/300][10/78]	eta 0:03:40 lr 1.955991	time 1.1913 (3.2436)	loss 2.7913 (2.7913)	grad_norm 0.5163 (0.4936)	mem 39782MB
[2023-07-07 14:29:28 RepVGG-A0] (main.py 282): INFO Train: [188/300][20/78]	eta 0:02:18 lr 1.952034	time 1.1720 (2.3882)	loss 2.8438 (2.7897)	grad_norm 0.4126 (0.4590)	mem 39782MB
[2023-07-07 14:29:44 RepVGG-A0] (main.py 282): INFO Train: [188/300][30/78]	eta 0:01:41 lr 1.948079	time 1.3221 (2.1184)	loss 2.8117 (2.7920)	grad_norm 0.4578 (0.4553)	mem 39782MB
[2023-07-07 14:30:01 RepVGG-A0] (main.py 282): INFO Train: [188/300][40/78]	eta 0:01:16 lr 1.944126	time 2.5088 (2.0176)	loss 2.7603 (2.7908)	grad_norm 0.4701 (0.4472)	mem 39782MB
[2023-07-07 14:30:16 RepVGG-A0] (main.py 282): INFO Train: [188/300][50/78]	eta 0:00:53 lr 1.940176	time 1.1914 (1.9219)	loss 2.8262 (2.7963)	grad_norm 0.4409 (0.4484)	mem 39782MB
[2023-07-07 14:30:31 RepVGG-A0] (main.py 282): INFO Train: [188/300][60/78]	eta 0:00:33 lr 1.936228	time 1.3670 (1.8568)	loss 2.8254 (2.7976)	grad_norm 0.4234 (0.4458)	mem 39782MB
[2023-07-07 14:30:46 RepVGG-A0] (main.py 282): INFO Train: [188/300][70/78]	eta 0:00:14 lr 1.932282	time 1.1718 (1.8050)	loss 2.8837 (2.8000)	grad_norm 0.4376 (0.4440)	mem 39782MB
[2023-07-07 14:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 188 training takes 0:02:19
[2023-07-07 14:31:19 RepVGG-A0] (main.py 282): INFO Train: [189/300][0/78]	eta 0:27:34 lr 1.929127	time 21.2145 (21.2145)	loss 2.8023 (2.8023)	grad_norm 0.4253 (0.4253)	mem 39782MB
[2023-07-07 14:31:34 RepVGG-A0] (main.py 282): INFO Train: [189/300][10/78]	eta 0:03:46 lr 1.925185	time 1.1917 (3.3328)	loss 2.7363 (2.7696)	grad_norm 0.4329 (0.4367)	mem 39782MB
[2023-07-07 14:31:48 RepVGG-A0] (main.py 282): INFO Train: [189/300][20/78]	eta 0:02:20 lr 1.921246	time 1.2045 (2.4142)	loss 2.8197 (2.7849)	grad_norm 0.5442 (0.4628)	mem 39782MB
[2023-07-07 14:32:04 RepVGG-A0] (main.py 282): INFO Train: [189/300][30/78]	eta 0:01:42 lr 1.917309	time 1.1291 (2.1411)	loss 2.8799 (2.8052)	grad_norm 0.4085 (0.4646)	mem 39782MB
[2023-07-07 14:32:21 RepVGG-A0] (main.py 282): INFO Train: [189/300][40/78]	eta 0:01:17 lr 1.913374	time 3.5601 (2.0415)	loss 2.8226 (2.8098)	grad_norm 0.4250 (0.4580)	mem 39782MB
[2023-07-07 14:32:37 RepVGG-A0] (main.py 282): INFO Train: [189/300][50/78]	eta 0:00:54 lr 1.909441	time 1.2194 (1.9428)	loss 2.8462 (2.8060)	grad_norm 0.5137 (0.4555)	mem 39782MB
[2023-07-07 14:32:52 RepVGG-A0] (main.py 282): INFO Train: [189/300][60/78]	eta 0:00:33 lr 1.905511	time 1.2045 (1.8674)	loss 2.8155 (2.8061)	grad_norm 0.4503 (0.4533)	mem 39782MB
[2023-07-07 14:33:07 RepVGG-A0] (main.py 282): INFO Train: [189/300][70/78]	eta 0:00:14 lr 1.901583	time 1.4267 (1.8251)	loss 2.7623 (2.8031)	grad_norm 0.3960 (0.4496)	mem 39782MB
[2023-07-07 14:33:19 RepVGG-A0] (main.py 291): INFO EPOCH 189 training takes 0:02:21
[2023-07-07 14:33:41 RepVGG-A0] (main.py 282): INFO Train: [190/300][0/78]	eta 0:28:51 lr 1.898443	time 22.1950 (22.1950)	loss 2.7051 (2.7051)	grad_norm 0.4072 (0.4072)	mem 39782MB
[2023-07-07 14:33:56 RepVGG-A0] (main.py 282): INFO Train: [190/300][10/78]	eta 0:03:46 lr 1.894519	time 1.1715 (3.3370)	loss 2.7020 (2.7205)	grad_norm 0.4427 (0.4193)	mem 39782MB
[2023-07-07 14:34:10 RepVGG-A0] (main.py 282): INFO Train: [190/300][20/78]	eta 0:02:20 lr 1.890598	time 1.1716 (2.4142)	loss 2.8002 (2.7437)	grad_norm 0.4369 (0.4279)	mem 39782MB
[2023-07-07 14:34:25 RepVGG-A0] (main.py 282): INFO Train: [190/300][30/78]	eta 0:01:41 lr 1.886679	time 1.2542 (2.1246)	loss 2.7843 (2.7524)	grad_norm 0.4388 (0.4329)	mem 39782MB
[2023-07-07 14:34:43 RepVGG-A0] (main.py 282): INFO Train: [190/300][40/78]	eta 0:01:17 lr 1.882763	time 2.6423 (2.0463)	loss 2.9179 (2.7609)	grad_norm 0.4305 (0.4336)	mem 39782MB
[2023-07-07 14:34:59 RepVGG-A0] (main.py 282): INFO Train: [190/300][50/78]	eta 0:00:54 lr 1.878848	time 1.1711 (1.9555)	loss 2.8975 (2.7692)	grad_norm 0.4950 (0.4375)	mem 39782MB
[2023-07-07 14:35:14 RepVGG-A0] (main.py 282): INFO Train: [190/300][60/78]	eta 0:00:33 lr 1.874937	time 1.1869 (1.8817)	loss 2.7920 (2.7771)	grad_norm 0.4458 (0.4381)	mem 39782MB
[2023-07-07 14:35:29 RepVGG-A0] (main.py 282): INFO Train: [190/300][70/78]	eta 0:00:14 lr 1.871027	time 1.1765 (1.8247)	loss 2.7649 (2.7795)	grad_norm 0.4468 (0.4383)	mem 39782MB
[2023-07-07 14:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 190 training takes 0:02:21
[2023-07-07 14:36:02 RepVGG-A0] (main.py 282): INFO Train: [191/300][0/78]	eta 0:28:00 lr 1.867901	time 21.5425 (21.5425)	loss 2.7536 (2.7536)	grad_norm 0.4486 (0.4486)	mem 39782MB
[2023-07-07 14:36:17 RepVGG-A0] (main.py 282): INFO Train: [191/300][10/78]	eta 0:03:48 lr 1.863996	time 1.1721 (3.3532)	loss 2.7687 (2.7795)	grad_norm 0.4554 (0.4545)	mem 39782MB
[2023-07-07 14:36:33 RepVGG-A0] (main.py 282): INFO Train: [191/300][20/78]	eta 0:02:23 lr 1.860094	time 1.1822 (2.4798)	loss 2.6871 (2.7686)	grad_norm 0.4229 (0.4408)	mem 39782MB
[2023-07-07 14:36:48 RepVGG-A0] (main.py 282): INFO Train: [191/300][30/78]	eta 0:01:45 lr 1.856194	time 1.5594 (2.1914)	loss 2.8034 (2.7672)	grad_norm 0.4214 (0.4470)	mem 39782MB
[2023-07-07 14:37:06 RepVGG-A0] (main.py 282): INFO Train: [191/300][40/78]	eta 0:01:19 lr 1.852296	time 3.1636 (2.0942)	loss 2.7281 (2.7650)	grad_norm 0.4349 (0.4468)	mem 39782MB
[2023-07-07 14:37:21 RepVGG-A0] (main.py 282): INFO Train: [191/300][50/78]	eta 0:00:55 lr 1.848400	time 1.1738 (1.9687)	loss 2.8212 (2.7687)	grad_norm 0.4610 (0.4467)	mem 39782MB
[2023-07-07 14:37:36 RepVGG-A0] (main.py 282): INFO Train: [191/300][60/78]	eta 0:00:34 lr 1.844507	time 1.2500 (1.9023)	loss 2.8388 (2.7675)	grad_norm 0.4316 (0.4449)	mem 39782MB
[2023-07-07 14:37:51 RepVGG-A0] (main.py 282): INFO Train: [191/300][70/78]	eta 0:00:14 lr 1.840617	time 1.4168 (1.8437)	loss 2.7749 (2.7678)	grad_norm 0.4229 (0.4425)	mem 39782MB
[2023-07-07 14:38:03 RepVGG-A0] (main.py 291): INFO EPOCH 191 training takes 0:02:22
[2023-07-07 14:38:25 RepVGG-A0] (main.py 282): INFO Train: [192/300][0/78]	eta 0:28:27 lr 1.837506	time 21.8959 (21.8959)	loss 2.6835 (2.6835)	grad_norm 0.4034 (0.4034)	mem 39782MB
[2023-07-07 14:38:39 RepVGG-A0] (main.py 282): INFO Train: [192/300][10/78]	eta 0:03:42 lr 1.833620	time 1.1722 (3.2731)	loss 2.8083 (2.7553)	grad_norm 0.5598 (0.4831)	mem 39782MB
[2023-07-07 14:38:53 RepVGG-A0] (main.py 282): INFO Train: [192/300][20/78]	eta 0:02:18 lr 1.829737	time 1.1727 (2.3819)	loss 2.7303 (2.7712)	grad_norm 0.4680 (0.4719)	mem 39782MB
[2023-07-07 14:39:08 RepVGG-A0] (main.py 282): INFO Train: [192/300][30/78]	eta 0:01:40 lr 1.825855	time 1.5198 (2.0856)	loss 2.7505 (2.7675)	grad_norm 0.4811 (0.4643)	mem 39782MB
[2023-07-07 14:39:27 RepVGG-A0] (main.py 282): INFO Train: [192/300][40/78]	eta 0:01:17 lr 1.821977	time 3.3874 (2.0371)	loss 2.7569 (2.7676)	grad_norm 0.4207 (0.4582)	mem 39782MB
[2023-07-07 14:39:42 RepVGG-A0] (main.py 282): INFO Train: [192/300][50/78]	eta 0:00:54 lr 1.818101	time 1.1723 (1.9351)	loss 2.7550 (2.7649)	grad_norm 0.4156 (0.4537)	mem 39782MB
[2023-07-07 14:39:57 RepVGG-A0] (main.py 282): INFO Train: [192/300][60/78]	eta 0:00:33 lr 1.814227	time 1.3102 (1.8673)	loss 2.7120 (2.7586)	grad_norm 0.4297 (0.4495)	mem 39782MB
[2023-07-07 14:40:12 RepVGG-A0] (main.py 282): INFO Train: [192/300][70/78]	eta 0:00:14 lr 1.810356	time 1.3584 (1.8168)	loss 2.7696 (2.7580)	grad_norm 0.4640 (0.4472)	mem 39782MB
[2023-07-07 14:40:23 RepVGG-A0] (main.py 291): INFO EPOCH 192 training takes 0:02:20
[2023-07-07 14:40:46 RepVGG-A0] (main.py 282): INFO Train: [193/300][0/78]	eta 0:29:19 lr 1.807260	time 22.5581 (22.5581)	loss 2.7291 (2.7291)	grad_norm 0.4036 (0.4036)	mem 39782MB
[2023-07-07 14:41:00 RepVGG-A0] (main.py 282): INFO Train: [193/300][10/78]	eta 0:03:48 lr 1.803394	time 1.1710 (3.3670)	loss 2.6925 (2.7259)	grad_norm 0.4517 (0.4502)	mem 39782MB
[2023-07-07 14:41:14 RepVGG-A0] (main.py 282): INFO Train: [193/300][20/78]	eta 0:02:20 lr 1.799530	time 1.1733 (2.4294)	loss 2.8107 (2.7414)	grad_norm 0.4116 (0.4525)	mem 39782MB
[2023-07-07 14:41:29 RepVGG-A0] (main.py 282): INFO Train: [193/300][30/78]	eta 0:01:41 lr 1.795668	time 1.1851 (2.1189)	loss 2.7897 (2.7512)	grad_norm 0.4694 (0.4457)	mem 39782MB
[2023-07-07 14:41:47 RepVGG-A0] (main.py 282): INFO Train: [193/300][40/78]	eta 0:01:18 lr 1.791809	time 3.8687 (2.0527)	loss 2.8351 (2.7582)	grad_norm 0.4968 (0.4518)	mem 39782MB
[2023-07-07 14:42:03 RepVGG-A0] (main.py 282): INFO Train: [193/300][50/78]	eta 0:00:54 lr 1.787952	time 1.1762 (1.9493)	loss 2.6976 (2.7596)	grad_norm 0.4137 (0.4515)	mem 39782MB
[2023-07-07 14:42:18 RepVGG-A0] (main.py 282): INFO Train: [193/300][60/78]	eta 0:00:33 lr 1.784098	time 1.2182 (1.8871)	loss 2.7541 (2.7620)	grad_norm 0.4364 (0.4494)	mem 39782MB
[2023-07-07 14:42:33 RepVGG-A0] (main.py 282): INFO Train: [193/300][70/78]	eta 0:00:14 lr 1.780247	time 1.1715 (1.8207)	loss 2.7360 (2.7652)	grad_norm 0.4380 (0.4486)	mem 39782MB
[2023-07-07 14:42:44 RepVGG-A0] (main.py 291): INFO EPOCH 193 training takes 0:02:20
[2023-07-07 14:43:04 RepVGG-A0] (main.py 282): INFO Train: [194/300][0/78]	eta 0:26:37 lr 1.777167	time 20.4810 (20.4810)	loss 2.6787 (2.6787)	grad_norm 0.4310 (0.4310)	mem 39782MB
[2023-07-07 14:43:20 RepVGG-A0] (main.py 282): INFO Train: [194/300][10/78]	eta 0:03:44 lr 1.773321	time 1.1712 (3.2995)	loss 2.6991 (2.7119)	grad_norm 0.4425 (0.4408)	mem 39782MB
[2023-07-07 14:43:35 RepVGG-A0] (main.py 282): INFO Train: [194/300][20/78]	eta 0:02:22 lr 1.769476	time 1.2360 (2.4498)	loss 2.7320 (2.7169)	grad_norm 0.4360 (0.4388)	mem 39782MB
[2023-07-07 14:43:51 RepVGG-A0] (main.py 282): INFO Train: [194/300][30/78]	eta 0:01:43 lr 1.765635	time 1.2954 (2.1559)	loss 2.7239 (2.7301)	grad_norm 0.4448 (0.4482)	mem 39782MB
[2023-07-07 14:44:10 RepVGG-A0] (main.py 282): INFO Train: [194/300][40/78]	eta 0:01:19 lr 1.761795	time 4.1285 (2.0955)	loss 2.7865 (2.7479)	grad_norm 0.4704 (0.4508)	mem 39782MB
[2023-07-07 14:44:24 RepVGG-A0] (main.py 282): INFO Train: [194/300][50/78]	eta 0:00:54 lr 1.757959	time 1.1914 (1.9586)	loss 2.7784 (2.7517)	grad_norm 0.4269 (0.4521)	mem 39782MB
[2023-07-07 14:44:40 RepVGG-A0] (main.py 282): INFO Train: [194/300][60/78]	eta 0:00:34 lr 1.754125	time 1.3968 (1.9105)	loss 2.7502 (2.7547)	grad_norm 0.4041 (0.4469)	mem 39782MB
[2023-07-07 14:44:55 RepVGG-A0] (main.py 282): INFO Train: [194/300][70/78]	eta 0:00:14 lr 1.750294	time 1.4049 (1.8403)	loss 2.7781 (2.7617)	grad_norm 0.4861 (0.4503)	mem 39782MB
[2023-07-07 14:45:06 RepVGG-A0] (main.py 291): INFO EPOCH 194 training takes 0:02:22
[2023-07-07 14:45:28 RepVGG-A0] (main.py 282): INFO Train: [195/300][0/78]	eta 0:28:36 lr 1.747230	time 22.0022 (22.0022)	loss 2.7422 (2.7422)	grad_norm 0.4089 (0.4089)	mem 39782MB
[2023-07-07 14:45:43 RepVGG-A0] (main.py 282): INFO Train: [195/300][10/78]	eta 0:03:45 lr 1.743404	time 1.1746 (3.3174)	loss 2.7248 (2.7264)	grad_norm 0.4321 (0.4382)	mem 39782MB
[2023-07-07 14:45:57 RepVGG-A0] (main.py 282): INFO Train: [195/300][20/78]	eta 0:02:20 lr 1.739580	time 1.1719 (2.4235)	loss 2.7915 (2.7284)	grad_norm 0.4999 (0.4435)	mem 39782MB
[2023-07-07 14:46:13 RepVGG-A0] (main.py 282): INFO Train: [195/300][30/78]	eta 0:01:42 lr 1.735758	time 1.2761 (2.1450)	loss 2.7104 (2.7247)	grad_norm 0.3932 (0.4407)	mem 39782MB
[2023-07-07 14:46:31 RepVGG-A0] (main.py 282): INFO Train: [195/300][40/78]	eta 0:01:18 lr 1.731940	time 3.8526 (2.0681)	loss 2.7409 (2.7282)	grad_norm 0.4674 (0.4386)	mem 39782MB
[2023-07-07 14:46:46 RepVGG-A0] (main.py 282): INFO Train: [195/300][50/78]	eta 0:00:54 lr 1.728124	time 1.1741 (1.9571)	loss 2.7811 (2.7377)	grad_norm 0.4913 (0.4462)	mem 39782MB
[2023-07-07 14:47:01 RepVGG-A0] (main.py 282): INFO Train: [195/300][60/78]	eta 0:00:33 lr 1.724310	time 1.1780 (1.8826)	loss 2.7843 (2.7382)	grad_norm 0.4378 (0.4458)	mem 39782MB
[2023-07-07 14:47:16 RepVGG-A0] (main.py 282): INFO Train: [195/300][70/78]	eta 0:00:14 lr 1.720499	time 1.2331 (1.8303)	loss 2.8477 (2.7422)	grad_norm 0.4418 (0.4459)	mem 39782MB
[2023-07-07 14:47:28 RepVGG-A0] (main.py 291): INFO EPOCH 195 training takes 0:02:21
[2023-07-07 14:47:49 RepVGG-A0] (main.py 282): INFO Train: [196/300][0/78]	eta 0:27:45 lr 1.717453	time 21.3524 (21.3524)	loss 2.6868 (2.6868)	grad_norm 0.4320 (0.4320)	mem 39782MB
[2023-07-07 14:48:04 RepVGG-A0] (main.py 282): INFO Train: [196/300][10/78]	eta 0:03:41 lr 1.713647	time 1.1722 (3.2586)	loss 2.7405 (2.7045)	grad_norm 0.4881 (0.4478)	mem 39782MB
[2023-07-07 14:48:18 RepVGG-A0] (main.py 282): INFO Train: [196/300][20/78]	eta 0:02:18 lr 1.709843	time 1.1732 (2.3809)	loss 2.7381 (2.7074)	grad_norm 0.4865 (0.4532)	mem 39782MB
[2023-07-07 14:48:34 RepVGG-A0] (main.py 282): INFO Train: [196/300][30/78]	eta 0:01:42 lr 1.706043	time 1.1561 (2.1349)	loss 2.7856 (2.7143)	grad_norm 0.4468 (0.4531)	mem 39782MB
[2023-07-07 14:48:52 RepVGG-A0] (main.py 282): INFO Train: [196/300][40/78]	eta 0:01:17 lr 1.702245	time 3.8621 (2.0483)	loss 2.8156 (2.7275)	grad_norm 0.4458 (0.4542)	mem 39782MB
[2023-07-07 14:49:07 RepVGG-A0] (main.py 282): INFO Train: [196/300][50/78]	eta 0:00:54 lr 1.698450	time 1.1724 (1.9405)	loss 2.7998 (2.7304)	grad_norm 0.4323 (0.4534)	mem 39782MB
[2023-07-07 14:49:22 RepVGG-A0] (main.py 282): INFO Train: [196/300][60/78]	eta 0:00:33 lr 1.694657	time 1.3287 (1.8700)	loss 2.7731 (2.7326)	grad_norm 0.4516 (0.4499)	mem 39782MB
[2023-07-07 14:49:38 RepVGG-A0] (main.py 282): INFO Train: [196/300][70/78]	eta 0:00:14 lr 1.690867	time 1.1710 (1.8341)	loss 2.8390 (2.7367)	grad_norm 0.4302 (0.4485)	mem 39782MB
[2023-07-07 14:49:49 RepVGG-A0] (main.py 291): INFO EPOCH 196 training takes 0:02:21
[2023-07-07 14:50:11 RepVGG-A0] (main.py 282): INFO Train: [197/300][0/78]	eta 0:28:32 lr 1.687838	time 21.9534 (21.9534)	loss 2.7313 (2.7313)	grad_norm 0.4770 (0.4770)	mem 39782MB
[2023-07-07 14:50:26 RepVGG-A0] (main.py 282): INFO Train: [197/300][10/78]	eta 0:03:48 lr 1.684053	time 1.1707 (3.3575)	loss 2.7238 (2.6923)	grad_norm 0.4498 (0.4401)	mem 39782MB
[2023-07-07 14:50:41 RepVGG-A0] (main.py 282): INFO Train: [197/300][20/78]	eta 0:02:23 lr 1.680271	time 1.2946 (2.4664)	loss 2.6606 (2.7099)	grad_norm 0.4524 (0.4523)	mem 39782MB
[2023-07-07 14:50:56 RepVGG-A0] (main.py 282): INFO Train: [197/300][30/78]	eta 0:01:43 lr 1.676491	time 1.2715 (2.1525)	loss 2.7834 (2.7253)	grad_norm 0.4815 (0.4515)	mem 39782MB
[2023-07-07 14:51:14 RepVGG-A0] (main.py 282): INFO Train: [197/300][40/78]	eta 0:01:18 lr 1.672714	time 3.5700 (2.0641)	loss 2.8035 (2.7362)	grad_norm 0.4727 (0.4603)	mem 39782MB
[2023-07-07 14:51:29 RepVGG-A0] (main.py 282): INFO Train: [197/300][50/78]	eta 0:00:54 lr 1.668941	time 1.1733 (1.9586)	loss 2.8045 (2.7387)	grad_norm 0.4550 (0.4557)	mem 39782MB
[2023-07-07 14:51:45 RepVGG-A0] (main.py 282): INFO Train: [197/300][60/78]	eta 0:00:34 lr 1.665169	time 1.3055 (1.8955)	loss 2.7805 (2.7462)	grad_norm 0.4759 (0.4596)	mem 39782MB
[2023-07-07 14:52:00 RepVGG-A0] (main.py 282): INFO Train: [197/300][70/78]	eta 0:00:14 lr 1.661401	time 1.4714 (1.8444)	loss 2.7354 (2.7480)	grad_norm 0.4191 (0.4553)	mem 39782MB
[2023-07-07 14:52:13 RepVGG-A0] (main.py 291): INFO EPOCH 197 training takes 0:02:23
[2023-07-07 14:52:34 RepVGG-A0] (main.py 282): INFO Train: [198/300][0/78]	eta 0:27:31 lr 1.658388	time 21.1754 (21.1754)	loss 2.7015 (2.7015)	grad_norm 0.4569 (0.4569)	mem 39782MB
[2023-07-07 14:52:50 RepVGG-A0] (main.py 282): INFO Train: [198/300][10/78]	eta 0:03:49 lr 1.654625	time 1.1734 (3.3792)	loss 2.7630 (2.7203)	grad_norm 0.4549 (0.4517)	mem 39782MB
[2023-07-07 14:53:05 RepVGG-A0] (main.py 282): INFO Train: [198/300][20/78]	eta 0:02:23 lr 1.650864	time 1.3122 (2.4674)	loss 2.7478 (2.7205)	grad_norm 0.4598 (0.4501)	mem 39782MB
[2023-07-07 14:53:19 RepVGG-A0] (main.py 282): INFO Train: [198/300][30/78]	eta 0:01:43 lr 1.647106	time 1.2553 (2.1491)	loss 2.7337 (2.7193)	grad_norm 0.4697 (0.4514)	mem 39782MB
[2023-07-07 14:53:39 RepVGG-A0] (main.py 282): INFO Train: [198/300][40/78]	eta 0:01:19 lr 1.643351	time 2.9834 (2.0934)	loss 2.7766 (2.7269)	grad_norm 0.4484 (0.4539)	mem 39782MB
[2023-07-07 14:53:53 RepVGG-A0] (main.py 282): INFO Train: [198/300][50/78]	eta 0:00:55 lr 1.639599	time 1.2776 (1.9737)	loss 2.7324 (2.7323)	grad_norm 0.4767 (0.4527)	mem 39782MB
[2023-07-07 14:54:08 RepVGG-A0] (main.py 282): INFO Train: [198/300][60/78]	eta 0:00:33 lr 1.635850	time 1.2168 (1.8829)	loss 2.7963 (2.7347)	grad_norm 0.4818 (0.4556)	mem 39782MB
[2023-07-07 14:54:23 RepVGG-A0] (main.py 282): INFO Train: [198/300][70/78]	eta 0:00:14 lr 1.632103	time 1.2888 (1.8413)	loss 2.7912 (2.7353)	grad_norm 0.4412 (0.4538)	mem 39782MB
[2023-07-07 14:54:36 RepVGG-A0] (main.py 291): INFO EPOCH 198 training takes 0:02:22
[2023-07-07 14:54:55 RepVGG-A0] (main.py 282): INFO Train: [199/300][0/78]	eta 0:25:34 lr 1.629108	time 19.6769 (19.6769)	loss 2.7389 (2.7389)	grad_norm 0.5080 (0.5080)	mem 39782MB
[2023-07-07 14:55:11 RepVGG-A0] (main.py 282): INFO Train: [199/300][10/78]	eta 0:03:39 lr 1.625367	time 1.1927 (3.2280)	loss 2.7088 (2.6713)	grad_norm 0.4871 (0.4536)	mem 39782MB
[2023-07-07 14:55:25 RepVGG-A0] (main.py 282): INFO Train: [199/300][20/78]	eta 0:02:17 lr 1.621628	time 1.1751 (2.3662)	loss 2.6376 (2.6914)	grad_norm 0.4320 (0.4726)	mem 39782MB
[2023-07-07 14:55:41 RepVGG-A0] (main.py 282): INFO Train: [199/300][30/78]	eta 0:01:41 lr 1.617892	time 1.5139 (2.1054)	loss 2.7080 (2.7000)	grad_norm 0.4160 (0.4564)	mem 39782MB
[2023-07-07 14:55:57 RepVGG-A0] (main.py 282): INFO Train: [199/300][40/78]	eta 0:01:15 lr 1.614159	time 2.3368 (1.9850)	loss 2.7504 (2.7078)	grad_norm 0.4930 (0.4578)	mem 39782MB
[2023-07-07 14:56:13 RepVGG-A0] (main.py 282): INFO Train: [199/300][50/78]	eta 0:00:53 lr 1.610429	time 1.3414 (1.9060)	loss 2.7123 (2.7115)	grad_norm 0.4328 (0.4530)	mem 39782MB
[2023-07-07 14:56:28 RepVGG-A0] (main.py 282): INFO Train: [199/300][60/78]	eta 0:00:33 lr 1.606702	time 1.2087 (1.8430)	loss 2.6874 (2.7176)	grad_norm 0.4593 (0.4521)	mem 39782MB
[2023-07-07 14:56:43 RepVGG-A0] (main.py 282): INFO Train: [199/300][70/78]	eta 0:00:14 lr 1.602977	time 1.1714 (1.7943)	loss 2.7779 (2.7183)	grad_norm 0.4478 (0.4521)	mem 39782MB
[2023-07-07 14:56:55 RepVGG-A0] (main.py 291): INFO EPOCH 199 training takes 0:02:19
[2023-07-07 14:57:17 RepVGG-A0] (main.py 282): INFO Train: [200/300][0/78]	eta 0:28:22 lr 1.600000	time 21.8260 (21.8260)	loss 2.6772 (2.6772)	grad_norm 0.4235 (0.4235)	mem 39782MB
[2023-07-07 14:57:32 RepVGG-A0] (main.py 282): INFO Train: [200/300][10/78]	eta 0:03:48 lr 1.596281	time 1.1717 (3.3619)	loss 2.7024 (2.6889)	grad_norm 0.4494 (0.4678)	mem 39782MB
[2023-07-07 14:57:46 RepVGG-A0] (main.py 282): INFO Train: [200/300][20/78]	eta 0:02:21 lr 1.592565	time 1.2063 (2.4380)	loss 2.7219 (2.6985)	grad_norm 0.4626 (0.4614)	mem 39782MB
[2023-07-07 14:58:02 RepVGG-A0] (main.py 282): INFO Train: [200/300][30/78]	eta 0:01:43 lr 1.588851	time 1.3453 (2.1606)	loss 2.6764 (2.7009)	grad_norm 0.4165 (0.4536)	mem 39782MB
[2023-07-07 14:58:19 RepVGG-A0] (main.py 282): INFO Train: [200/300][40/78]	eta 0:01:18 lr 1.585141	time 3.9342 (2.0561)	loss 2.7223 (2.7029)	grad_norm 0.4453 (0.4541)	mem 39782MB
[2023-07-07 14:58:35 RepVGG-A0] (main.py 282): INFO Train: [200/300][50/78]	eta 0:00:54 lr 1.581433	time 1.1931 (1.9616)	loss 2.7548 (2.7087)	grad_norm 0.4563 (0.4536)	mem 39782MB
[2023-07-07 14:58:50 RepVGG-A0] (main.py 282): INFO Train: [200/300][60/78]	eta 0:00:34 lr 1.577728	time 1.1766 (1.8907)	loss 2.7603 (2.7113)	grad_norm 0.4873 (0.4545)	mem 39782MB
[2023-07-07 14:59:06 RepVGG-A0] (main.py 282): INFO Train: [200/300][70/78]	eta 0:00:14 lr 1.574027	time 1.4596 (1.8449)	loss 2.7540 (2.7134)	grad_norm 0.4348 (0.4551)	mem 39782MB
[2023-07-07 14:59:17 RepVGG-A0] (main.py 291): INFO EPOCH 200 training takes 0:02:22
[2023-07-07 14:59:34 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.565 (17.565)	Loss 2.1103 (2.1103)	Acc@1 54.468 (54.468)	Acc@5 78.546 (78.546)	Mem 39782MB
[2023-07-07 14:59:35 RepVGG-A0] (main.py 342): INFO  * Acc@1 54.550 Acc@5 78.434
[2023-07-07 14:59:35 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 200: 54.550%
[2023-07-07 14:59:35 RepVGG-A0] (main.py 172): INFO Max accuracy: 54.55%
[2023-07-07 14:59:58 RepVGG-A0] (main.py 282): INFO Train: [201/300][0/78]	eta 0:29:11 lr 1.571067	time 22.4537 (22.4537)	loss 2.7462 (2.7462)	grad_norm 0.4643 (0.4643)	mem 39782MB
[2023-07-07 15:00:12 RepVGG-A0] (main.py 282): INFO Train: [201/300][10/78]	eta 0:03:48 lr 1.567371	time 1.1723 (3.3658)	loss 2.7340 (2.7008)	grad_norm 0.4720 (0.4569)	mem 39782MB
[2023-07-07 15:00:27 RepVGG-A0] (main.py 282): INFO Train: [201/300][20/78]	eta 0:02:21 lr 1.563678	time 1.2381 (2.4418)	loss 2.6791 (2.6931)	grad_norm 0.4784 (0.4527)	mem 39782MB
[2023-07-07 15:00:42 RepVGG-A0] (main.py 282): INFO Train: [201/300][30/78]	eta 0:01:42 lr 1.559987	time 1.1776 (2.1354)	loss 2.7674 (2.6970)	grad_norm 0.4531 (0.4595)	mem 39782MB
[2023-07-07 15:01:00 RepVGG-A0] (main.py 282): INFO Train: [201/300][40/78]	eta 0:01:18 lr 1.556299	time 4.4163 (2.0622)	loss 2.7357 (2.7039)	grad_norm 0.4294 (0.4565)	mem 39782MB
[2023-07-07 15:01:15 RepVGG-A0] (main.py 282): INFO Train: [201/300][50/78]	eta 0:00:54 lr 1.552615	time 1.1719 (1.9453)	loss 2.8222 (2.7033)	grad_norm 0.4932 (0.4562)	mem 39782MB
[2023-07-07 15:01:30 RepVGG-A0] (main.py 282): INFO Train: [201/300][60/78]	eta 0:00:33 lr 1.548933	time 1.4004 (1.8833)	loss 2.7099 (2.7105)	grad_norm 0.4492 (0.4645)	mem 39782MB
[2023-07-07 15:01:45 RepVGG-A0] (main.py 282): INFO Train: [201/300][70/78]	eta 0:00:14 lr 1.545254	time 1.1712 (1.8253)	loss 2.7361 (2.7120)	grad_norm 0.4466 (0.4634)	mem 39782MB
[2023-07-07 15:01:57 RepVGG-A0] (main.py 291): INFO EPOCH 201 training takes 0:02:21
[2023-07-07 15:02:19 RepVGG-A0] (main.py 282): INFO Train: [202/300][0/78]	eta 0:28:06 lr 1.542314	time 21.6250 (21.6250)	loss 2.6081 (2.6081)	grad_norm 0.4479 (0.4479)	mem 39782MB
[2023-07-07 15:02:33 RepVGG-A0] (main.py 282): INFO Train: [202/300][10/78]	eta 0:03:44 lr 1.538640	time 1.1704 (3.2951)	loss 2.7337 (2.6763)	grad_norm 0.4152 (0.4501)	mem 39782MB
[2023-07-07 15:02:48 RepVGG-A0] (main.py 282): INFO Train: [202/300][20/78]	eta 0:02:22 lr 1.534970	time 1.1276 (2.4563)	loss 2.7094 (2.6853)	grad_norm 0.4604 (0.4558)	mem 39782MB
[2023-07-07 15:03:03 RepVGG-A0] (main.py 282): INFO Train: [202/300][30/78]	eta 0:01:42 lr 1.531303	time 1.1825 (2.1359)	loss 2.7169 (2.6865)	grad_norm 0.4561 (0.4486)	mem 39782MB
[2023-07-07 15:03:22 RepVGG-A0] (main.py 282): INFO Train: [202/300][40/78]	eta 0:01:18 lr 1.527638	time 3.8706 (2.0705)	loss 2.7587 (2.6948)	grad_norm 0.5535 (0.4623)	mem 39782MB
[2023-07-07 15:03:36 RepVGG-A0] (main.py 282): INFO Train: [202/300][50/78]	eta 0:00:54 lr 1.523977	time 1.1619 (1.9491)	loss 2.6702 (2.6980)	grad_norm 0.4480 (0.4585)	mem 39782MB
[2023-07-07 15:03:52 RepVGG-A0] (main.py 282): INFO Train: [202/300][60/78]	eta 0:00:33 lr 1.520319	time 1.1780 (1.8822)	loss 2.7053 (2.6986)	grad_norm 0.4488 (0.4556)	mem 39782MB
[2023-07-07 15:04:06 RepVGG-A0] (main.py 282): INFO Train: [202/300][70/78]	eta 0:00:14 lr 1.516663	time 1.4009 (1.8223)	loss 2.6825 (2.7011)	grad_norm 0.4678 (0.4571)	mem 39782MB
[2023-07-07 15:04:18 RepVGG-A0] (main.py 291): INFO EPOCH 202 training takes 0:02:20
[2023-07-07 15:04:39 RepVGG-A0] (main.py 282): INFO Train: [203/300][0/78]	eta 0:27:45 lr 1.513741	time 21.3555 (21.3555)	loss 2.6325 (2.6325)	grad_norm 0.4610 (0.4610)	mem 39782MB
[2023-07-07 15:04:54 RepVGG-A0] (main.py 282): INFO Train: [203/300][10/78]	eta 0:03:43 lr 1.510092	time 1.1719 (3.2820)	loss 2.6816 (2.6525)	grad_norm 0.4398 (0.4600)	mem 39782MB
[2023-07-07 15:05:09 RepVGG-A0] (main.py 282): INFO Train: [203/300][20/78]	eta 0:02:22 lr 1.506445	time 1.2418 (2.4509)	loss 2.6551 (2.6586)	grad_norm 0.4564 (0.4558)	mem 39782MB
[2023-07-07 15:05:24 RepVGG-A0] (main.py 282): INFO Train: [203/300][30/78]	eta 0:01:42 lr 1.502801	time 1.3463 (2.1355)	loss 2.6348 (2.6666)	grad_norm 0.4566 (0.4520)	mem 39782MB
[2023-07-07 15:05:41 RepVGG-A0] (main.py 282): INFO Train: [203/300][40/78]	eta 0:01:17 lr 1.499161	time 1.7721 (2.0314)	loss 2.7105 (2.6776)	grad_norm 0.4678 (0.4598)	mem 39782MB
[2023-07-07 15:05:56 RepVGG-A0] (main.py 282): INFO Train: [203/300][50/78]	eta 0:00:54 lr 1.495523	time 1.1718 (1.9353)	loss 2.7292 (2.6851)	grad_norm 0.4720 (0.4575)	mem 39782MB
[2023-07-07 15:06:11 RepVGG-A0] (main.py 282): INFO Train: [203/300][60/78]	eta 0:00:33 lr 1.491889	time 1.2672 (1.8615)	loss 2.6704 (2.6883)	grad_norm 0.4767 (0.4594)	mem 39782MB
[2023-07-07 15:06:26 RepVGG-A0] (main.py 282): INFO Train: [203/300][70/78]	eta 0:00:14 lr 1.488257	time 1.5380 (1.8110)	loss 2.7152 (2.6898)	grad_norm 0.4470 (0.4568)	mem 39782MB
[2023-07-07 15:06:38 RepVGG-A0] (main.py 291): INFO EPOCH 203 training takes 0:02:20
[2023-07-07 15:06:58 RepVGG-A0] (main.py 282): INFO Train: [204/300][0/78]	eta 0:26:16 lr 1.485354	time 20.2153 (20.2153)	loss 2.7290 (2.7290)	grad_norm 0.4325 (0.4325)	mem 39782MB
[2023-07-07 15:07:13 RepVGG-A0] (main.py 282): INFO Train: [204/300][10/78]	eta 0:03:37 lr 1.481728	time 1.1720 (3.2045)	loss 2.7045 (2.6771)	grad_norm 0.4687 (0.4776)	mem 39782MB
[2023-07-07 15:07:29 RepVGG-A0] (main.py 282): INFO Train: [204/300][20/78]	eta 0:02:20 lr 1.478106	time 1.1764 (2.4182)	loss 2.6434 (2.6700)	grad_norm 0.4837 (0.4665)	mem 39782MB
[2023-07-07 15:07:45 RepVGG-A0] (main.py 282): INFO Train: [204/300][30/78]	eta 0:01:43 lr 1.474486	time 1.7260 (2.1562)	loss 2.6273 (2.6789)	grad_norm 0.4788 (0.4724)	mem 39782MB
[2023-07-07 15:08:02 RepVGG-A0] (main.py 282): INFO Train: [204/300][40/78]	eta 0:01:18 lr 1.470869	time 2.3124 (2.0578)	loss 2.7083 (2.6801)	grad_norm 0.4729 (0.4648)	mem 39782MB
[2023-07-07 15:08:17 RepVGG-A0] (main.py 282): INFO Train: [204/300][50/78]	eta 0:00:54 lr 1.467256	time 1.1733 (1.9427)	loss 2.7134 (2.6860)	grad_norm 0.4387 (0.4709)	mem 39782MB
[2023-07-07 15:08:33 RepVGG-A0] (main.py 282): INFO Train: [204/300][60/78]	eta 0:00:33 lr 1.463646	time 1.1875 (1.8801)	loss 2.6914 (2.6889)	grad_norm 0.4452 (0.4674)	mem 39782MB
[2023-07-07 15:08:47 RepVGG-A0] (main.py 282): INFO Train: [204/300][70/78]	eta 0:00:14 lr 1.460039	time 1.1921 (1.8162)	loss 2.8127 (2.6934)	grad_norm 0.5104 (0.4689)	mem 39782MB
[2023-07-07 15:08:59 RepVGG-A0] (main.py 291): INFO EPOCH 204 training takes 0:02:20
[2023-07-07 15:09:19 RepVGG-A0] (main.py 282): INFO Train: [205/300][0/78]	eta 0:25:33 lr 1.457155	time 19.6557 (19.6557)	loss 2.6381 (2.6381)	grad_norm 0.4268 (0.4268)	mem 39782MB
[2023-07-07 15:09:35 RepVGG-A0] (main.py 282): INFO Train: [205/300][10/78]	eta 0:03:41 lr 1.453554	time 1.1722 (3.2582)	loss 2.7252 (2.6630)	grad_norm 0.5214 (0.4603)	mem 39782MB
[2023-07-07 15:09:51 RepVGG-A0] (main.py 282): INFO Train: [205/300][20/78]	eta 0:02:23 lr 1.449955	time 1.2861 (2.4766)	loss 2.6519 (2.6550)	grad_norm 0.4474 (0.4633)	mem 39782MB
[2023-07-07 15:10:07 RepVGG-A0] (main.py 282): INFO Train: [205/300][30/78]	eta 0:01:44 lr 1.446360	time 1.7994 (2.1761)	loss 2.5902 (2.6588)	grad_norm 0.4202 (0.4566)	mem 39782MB
[2023-07-07 15:10:23 RepVGG-A0] (main.py 282): INFO Train: [205/300][40/78]	eta 0:01:17 lr 1.442768	time 1.9142 (2.0485)	loss 2.7107 (2.6575)	grad_norm 0.4638 (0.4551)	mem 39782MB
[2023-07-07 15:10:38 RepVGG-A0] (main.py 282): INFO Train: [205/300][50/78]	eta 0:00:54 lr 1.439179	time 1.1737 (1.9351)	loss 2.6194 (2.6614)	grad_norm 0.4931 (0.4569)	mem 39782MB
[2023-07-07 15:10:53 RepVGG-A0] (main.py 282): INFO Train: [205/300][60/78]	eta 0:00:33 lr 1.435593	time 1.1904 (1.8631)	loss 2.7218 (2.6679)	grad_norm 0.4572 (0.4584)	mem 39782MB
[2023-07-07 15:11:10 RepVGG-A0] (main.py 282): INFO Train: [205/300][70/78]	eta 0:00:14 lr 1.432011	time 1.2290 (1.8380)	loss 2.7021 (2.6726)	grad_norm 0.4536 (0.4589)	mem 39782MB
[2023-07-07 15:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 205 training takes 0:02:21
[2023-07-07 15:11:42 RepVGG-A0] (main.py 282): INFO Train: [206/300][0/78]	eta 0:28:27 lr 1.429147	time 21.8886 (21.8886)	loss 2.5973 (2.5973)	grad_norm 0.4490 (0.4490)	mem 39782MB
[2023-07-07 15:11:58 RepVGG-A0] (main.py 282): INFO Train: [206/300][10/78]	eta 0:03:50 lr 1.425570	time 1.2047 (3.3908)	loss 2.6606 (2.6647)	grad_norm 0.5078 (0.4835)	mem 39782MB
[2023-07-07 15:12:13 RepVGG-A0] (main.py 282): INFO Train: [206/300][20/78]	eta 0:02:24 lr 1.421997	time 1.2861 (2.4851)	loss 2.6262 (2.6639)	grad_norm 0.4207 (0.4753)	mem 39782MB
[2023-07-07 15:12:28 RepVGG-A0] (main.py 282): INFO Train: [206/300][30/78]	eta 0:01:45 lr 1.418426	time 1.5492 (2.1883)	loss 2.7456 (2.6709)	grad_norm 0.4883 (0.4718)	mem 39782MB
[2023-07-07 15:12:48 RepVGG-A0] (main.py 282): INFO Train: [206/300][40/78]	eta 0:01:20 lr 1.414859	time 2.8361 (2.1242)	loss 2.6428 (2.6695)	grad_norm 0.4709 (0.4731)	mem 39782MB
[2023-07-07 15:13:03 RepVGG-A0] (main.py 282): INFO Train: [206/300][50/78]	eta 0:00:56 lr 1.411295	time 1.1715 (2.0033)	loss 2.7539 (2.6704)	grad_norm 0.4930 (0.4689)	mem 39782MB
[2023-07-07 15:13:18 RepVGG-A0] (main.py 282): INFO Train: [206/300][60/78]	eta 0:00:34 lr 1.407734	time 1.1406 (1.9338)	loss 2.6636 (2.6744)	grad_norm 0.4478 (0.4682)	mem 39782MB
[2023-07-07 15:13:33 RepVGG-A0] (main.py 282): INFO Train: [206/300][70/78]	eta 0:00:14 lr 1.404177	time 1.3109 (1.8719)	loss 2.6996 (2.6769)	grad_norm 0.5127 (0.4701)	mem 39782MB
[2023-07-07 15:13:45 RepVGG-A0] (main.py 291): INFO EPOCH 206 training takes 0:02:24
[2023-07-07 15:14:07 RepVGG-A0] (main.py 282): INFO Train: [207/300][0/78]	eta 0:28:38 lr 1.401333	time 22.0324 (22.0324)	loss 2.6368 (2.6368)	grad_norm 0.4561 (0.4561)	mem 39782MB
[2023-07-07 15:14:22 RepVGG-A0] (main.py 282): INFO Train: [207/300][10/78]	eta 0:03:48 lr 1.397782	time 1.1968 (3.3576)	loss 2.6501 (2.6256)	grad_norm 0.4834 (0.4459)	mem 39782MB
[2023-07-07 15:14:36 RepVGG-A0] (main.py 282): INFO Train: [207/300][20/78]	eta 0:02:21 lr 1.394233	time 1.1844 (2.4318)	loss 2.7111 (2.6559)	grad_norm 0.4360 (0.4585)	mem 39782MB
[2023-07-07 15:14:51 RepVGG-A0] (main.py 282): INFO Train: [207/300][30/78]	eta 0:01:42 lr 1.390688	time 1.6392 (2.1347)	loss 2.6754 (2.6521)	grad_norm 0.4687 (0.4598)	mem 39782MB
[2023-07-07 15:15:10 RepVGG-A0] (main.py 282): INFO Train: [207/300][40/78]	eta 0:01:18 lr 1.387146	time 3.2703 (2.0610)	loss 2.6506 (2.6535)	grad_norm 0.4621 (0.4605)	mem 39782MB
[2023-07-07 15:15:25 RepVGG-A0] (main.py 282): INFO Train: [207/300][50/78]	eta 0:00:54 lr 1.383607	time 1.1717 (1.9553)	loss 2.6957 (2.6581)	grad_norm 0.4694 (0.4593)	mem 39782MB
[2023-07-07 15:15:39 RepVGG-A0] (main.py 282): INFO Train: [207/300][60/78]	eta 0:00:33 lr 1.380072	time 1.1786 (1.8732)	loss 2.7084 (2.6630)	grad_norm 0.4483 (0.4621)	mem 39782MB
[2023-07-07 15:15:55 RepVGG-A0] (main.py 282): INFO Train: [207/300][70/78]	eta 0:00:14 lr 1.376540	time 1.4367 (1.8259)	loss 2.6775 (2.6640)	grad_norm 0.5273 (0.4610)	mem 39782MB
[2023-07-07 15:16:06 RepVGG-A0] (main.py 291): INFO EPOCH 207 training takes 0:02:20
[2023-07-07 15:16:27 RepVGG-A0] (main.py 282): INFO Train: [208/300][0/78]	eta 0:27:29 lr 1.373717	time 21.1426 (21.1426)	loss 2.6527 (2.6527)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:16:42 RepVGG-A0] (main.py 282): INFO Train: [208/300][10/78]	eta 0:03:40 lr 1.370190	time 1.1725 (3.2412)	loss 2.6099 (2.6374)	grad_norm 0.4304 (0.4576)	mem 39782MB
[2023-07-07 15:16:56 RepVGG-A0] (main.py 282): INFO Train: [208/300][20/78]	eta 0:02:17 lr 1.366668	time 1.1722 (2.3774)	loss 2.6971 (2.6506)	grad_norm 0.5722 (0.4871)	mem 39782MB
[2023-07-07 15:17:10 RepVGG-A0] (main.py 282): INFO Train: [208/300][30/78]	eta 0:01:39 lr 1.363148	time 1.1276 (2.0702)	loss 2.6764 (2.6662)	grad_norm 0.4372 (0.4908)	mem 39782MB
[2023-07-07 15:17:30 RepVGG-A0] (main.py 282): INFO Train: [208/300][40/78]	eta 0:01:17 lr 1.359632	time 5.2371 (2.0447)	loss 2.6108 (2.6655)	grad_norm 0.4529 (0.4803)	mem 39782MB
[2023-07-07 15:17:45 RepVGG-A0] (main.py 282): INFO Train: [208/300][50/78]	eta 0:00:54 lr 1.356119	time 1.1739 (1.9394)	loss 2.6963 (2.6668)	grad_norm 0.4589 (0.4742)	mem 39782MB
[2023-07-07 15:18:00 RepVGG-A0] (main.py 282): INFO Train: [208/300][60/78]	eta 0:00:33 lr 1.352609	time 1.3848 (1.8746)	loss 2.6617 (2.6678)	grad_norm 0.5027 (0.4740)	mem 39782MB
[2023-07-07 15:18:15 RepVGG-A0] (main.py 282): INFO Train: [208/300][70/78]	eta 0:00:14 lr 1.349103	time 1.1273 (1.8158)	loss 2.6388 (2.6657)	grad_norm 0.4364 (0.4734)	mem 39782MB
[2023-07-07 15:18:27 RepVGG-A0] (main.py 291): INFO EPOCH 208 training takes 0:02:20
[2023-07-07 15:18:48 RepVGG-A0] (main.py 282): INFO Train: [209/300][0/78]	eta 0:27:57 lr 1.346300	time 21.5083 (21.5083)	loss 2.6156 (2.6156)	grad_norm 0.4722 (0.4722)	mem 39782MB
[2023-07-07 15:19:04 RepVGG-A0] (main.py 282): INFO Train: [209/300][10/78]	eta 0:03:51 lr 1.342800	time 1.1729 (3.4028)	loss 2.6739 (2.6281)	grad_norm 0.4505 (0.4658)	mem 39782MB
[2023-07-07 15:19:19 RepVGG-A0] (main.py 282): INFO Train: [209/300][20/78]	eta 0:02:24 lr 1.339303	time 1.4117 (2.4961)	loss 2.7041 (2.6237)	grad_norm 0.4839 (0.4602)	mem 39782MB
[2023-07-07 15:19:35 RepVGG-A0] (main.py 282): INFO Train: [209/300][30/78]	eta 0:01:45 lr 1.335809	time 1.4530 (2.1929)	loss 2.6888 (2.6281)	grad_norm 0.4522 (0.4636)	mem 39782MB
[2023-07-07 15:19:53 RepVGG-A0] (main.py 282): INFO Train: [209/300][40/78]	eta 0:01:19 lr 1.332319	time 4.2609 (2.0979)	loss 2.6904 (2.6386)	grad_norm 0.4650 (0.4680)	mem 39782MB
[2023-07-07 15:20:07 RepVGG-A0] (main.py 282): INFO Train: [209/300][50/78]	eta 0:00:55 lr 1.328832	time 1.1755 (1.9691)	loss 2.5733 (2.6412)	grad_norm 0.4505 (0.4659)	mem 39782MB
[2023-07-07 15:20:23 RepVGG-A0] (main.py 282): INFO Train: [209/300][60/78]	eta 0:00:34 lr 1.325349	time 1.1279 (1.8991)	loss 2.6790 (2.6481)	grad_norm 0.4856 (0.4687)	mem 39782MB
[2023-07-07 15:20:38 RepVGG-A0] (main.py 282): INFO Train: [209/300][70/78]	eta 0:00:14 lr 1.321869	time 1.2961 (1.8460)	loss 2.5360 (2.6472)	grad_norm 0.4369 (0.4675)	mem 39782MB
[2023-07-07 15:20:49 RepVGG-A0] (main.py 291): INFO EPOCH 209 training takes 0:02:22
[2023-07-07 15:21:10 RepVGG-A0] (main.py 282): INFO Train: [210/300][0/78]	eta 0:27:24 lr 1.319087	time 21.0852 (21.0852)	loss 2.6432 (2.6432)	grad_norm 0.4836 (0.4836)	mem 39782MB
[2023-07-07 15:21:24 RepVGG-A0] (main.py 282): INFO Train: [210/300][10/78]	eta 0:03:35 lr 1.315613	time 1.1728 (3.1726)	loss 2.5964 (2.6284)	grad_norm 0.4594 (0.4600)	mem 39782MB
[2023-07-07 15:21:38 RepVGG-A0] (main.py 282): INFO Train: [210/300][20/78]	eta 0:02:16 lr 1.312143	time 1.1730 (2.3456)	loss 2.7135 (2.6302)	grad_norm 0.4737 (0.4724)	mem 39782MB
[2023-07-07 15:21:54 RepVGG-A0] (main.py 282): INFO Train: [210/300][30/78]	eta 0:01:39 lr 1.308675	time 1.3694 (2.0805)	loss 2.6762 (2.6351)	grad_norm 0.4746 (0.4716)	mem 39782MB
[2023-07-07 15:22:11 RepVGG-A0] (main.py 282): INFO Train: [210/300][40/78]	eta 0:01:15 lr 1.305212	time 3.0039 (1.9924)	loss 2.7133 (2.6418)	grad_norm 0.4621 (0.4693)	mem 39782MB
[2023-07-07 15:22:27 RepVGG-A0] (main.py 282): INFO Train: [210/300][50/78]	eta 0:00:53 lr 1.301751	time 1.1985 (1.9115)	loss 2.6508 (2.6433)	grad_norm 0.4663 (0.4668)	mem 39782MB
[2023-07-07 15:22:42 RepVGG-A0] (main.py 282): INFO Train: [210/300][60/78]	eta 0:00:33 lr 1.298294	time 1.1745 (1.8530)	loss 2.6584 (2.6438)	grad_norm 0.4484 (0.4675)	mem 39782MB
[2023-07-07 15:22:57 RepVGG-A0] (main.py 282): INFO Train: [210/300][70/78]	eta 0:00:14 lr 1.294841	time 1.2110 (1.8043)	loss 2.7393 (2.6471)	grad_norm 0.5262 (0.4707)	mem 39782MB
[2023-07-07 15:23:10 RepVGG-A0] (main.py 291): INFO EPOCH 210 training takes 0:02:20
[2023-07-07 15:23:31 RepVGG-A0] (main.py 282): INFO Train: [211/300][0/78]	eta 0:27:41 lr 1.292080	time 21.3031 (21.3031)	loss 2.6325 (2.6325)	grad_norm 0.4356 (0.4356)	mem 39782MB
[2023-07-07 15:23:46 RepVGG-A0] (main.py 282): INFO Train: [211/300][10/78]	eta 0:03:41 lr 1.288633	time 1.1727 (3.2594)	loss 2.6313 (2.6290)	grad_norm 0.4630 (0.4541)	mem 39782MB
[2023-07-07 15:24:00 RepVGG-A0] (main.py 282): INFO Train: [211/300][20/78]	eta 0:02:18 lr 1.285189	time 1.1723 (2.3922)	loss 2.6759 (2.6314)	grad_norm 0.4485 (0.4595)	mem 39782MB
[2023-07-07 15:24:15 RepVGG-A0] (main.py 282): INFO Train: [211/300][30/78]	eta 0:01:41 lr 1.281749	time 1.3112 (2.1099)	loss 2.6284 (2.6349)	grad_norm 0.4985 (0.4621)	mem 39782MB
[2023-07-07 15:24:33 RepVGG-A0] (main.py 282): INFO Train: [211/300][40/78]	eta 0:01:17 lr 1.278312	time 4.6694 (2.0389)	loss 2.5976 (2.6377)	grad_norm 0.4584 (0.4635)	mem 39782MB
[2023-07-07 15:24:48 RepVGG-A0] (main.py 282): INFO Train: [211/300][50/78]	eta 0:00:53 lr 1.274878	time 1.1905 (1.9245)	loss 2.6540 (2.6414)	grad_norm 0.5000 (0.4648)	mem 39782MB
[2023-07-07 15:25:03 RepVGG-A0] (main.py 282): INFO Train: [211/300][60/78]	eta 0:00:33 lr 1.271448	time 1.1957 (1.8608)	loss 2.6448 (2.6415)	grad_norm 0.4516 (0.4671)	mem 39782MB
[2023-07-07 15:25:18 RepVGG-A0] (main.py 282): INFO Train: [211/300][70/78]	eta 0:00:14 lr 1.268022	time 1.2135 (1.8065)	loss 2.6468 (2.6444)	grad_norm 0.5160 (0.4688)	mem 39782MB
[2023-07-07 15:25:30 RepVGG-A0] (main.py 291): INFO EPOCH 211 training takes 0:02:20
[2023-07-07 15:25:52 RepVGG-A0] (main.py 282): INFO Train: [212/300][0/78]	eta 0:28:19 lr 1.265283	time 21.7881 (21.7881)	loss 2.6630 (2.6630)	grad_norm 0.4468 (0.4468)	mem 39782MB
[2023-07-07 15:26:06 RepVGG-A0] (main.py 282): INFO Train: [212/300][10/78]	eta 0:03:41 lr 1.261863	time 1.1730 (3.2516)	loss 2.6029 (2.6012)	grad_norm 0.4791 (0.4590)	mem 39782MB
[2023-07-07 15:26:21 RepVGG-A0] (main.py 282): INFO Train: [212/300][20/78]	eta 0:02:20 lr 1.258446	time 1.2858 (2.4168)	loss 2.6121 (2.6096)	grad_norm 0.4377 (0.4671)	mem 39782MB
[2023-07-07 15:26:36 RepVGG-A0] (main.py 282): INFO Train: [212/300][30/78]	eta 0:01:41 lr 1.255032	time 1.1281 (2.1196)	loss 2.6485 (2.6118)	grad_norm 0.4815 (0.4687)	mem 39782MB
[2023-07-07 15:26:54 RepVGG-A0] (main.py 282): INFO Train: [212/300][40/78]	eta 0:01:17 lr 1.251623	time 4.0891 (2.0517)	loss 2.6075 (2.6151)	grad_norm 0.4764 (0.4668)	mem 39782MB
[2023-07-07 15:27:09 RepVGG-A0] (main.py 282): INFO Train: [212/300][50/78]	eta 0:00:54 lr 1.248216	time 1.1715 (1.9372)	loss 2.6139 (2.6191)	grad_norm 0.4431 (0.4696)	mem 39782MB
[2023-07-07 15:27:25 RepVGG-A0] (main.py 282): INFO Train: [212/300][60/78]	eta 0:00:33 lr 1.244814	time 1.1319 (1.8801)	loss 2.6468 (2.6223)	grad_norm 0.4883 (0.4686)	mem 39782MB
[2023-07-07 15:27:39 RepVGG-A0] (main.py 282): INFO Train: [212/300][70/78]	eta 0:00:14 lr 1.241414	time 1.1749 (1.8087)	loss 2.6293 (2.6230)	grad_norm 0.4819 (0.4687)	mem 39782MB
[2023-07-07 15:27:52 RepVGG-A0] (main.py 291): INFO EPOCH 212 training takes 0:02:21
[2023-07-07 15:28:12 RepVGG-A0] (main.py 282): INFO Train: [213/300][0/78]	eta 0:26:58 lr 1.238697	time 20.7438 (20.7438)	loss 2.5989 (2.5989)	grad_norm 0.4698 (0.4698)	mem 39782MB
[2023-07-07 15:28:27 RepVGG-A0] (main.py 282): INFO Train: [213/300][10/78]	eta 0:03:36 lr 1.235305	time 1.1693 (3.1852)	loss 2.6604 (2.6124)	grad_norm 0.4888 (0.4668)	mem 39782MB
[2023-07-07 15:28:42 RepVGG-A0] (main.py 282): INFO Train: [213/300][20/78]	eta 0:02:17 lr 1.231915	time 1.1785 (2.3788)	loss 2.6045 (2.6150)	grad_norm 0.4763 (0.4782)	mem 39782MB
[2023-07-07 15:28:56 RepVGG-A0] (main.py 282): INFO Train: [213/300][30/78]	eta 0:01:40 lr 1.228529	time 1.3010 (2.0945)	loss 2.6258 (2.6179)	grad_norm 0.4601 (0.4699)	mem 39782MB
[2023-07-07 15:29:15 RepVGG-A0] (main.py 282): INFO Train: [213/300][40/78]	eta 0:01:16 lr 1.225147	time 4.1874 (2.0252)	loss 2.6412 (2.6203)	grad_norm 0.5136 (0.4774)	mem 39782MB
[2023-07-07 15:29:30 RepVGG-A0] (main.py 282): INFO Train: [213/300][50/78]	eta 0:00:53 lr 1.221768	time 1.1939 (1.9254)	loss 2.5960 (2.6214)	grad_norm 0.4761 (0.4741)	mem 39782MB
[2023-07-07 15:29:45 RepVGG-A0] (main.py 282): INFO Train: [213/300][60/78]	eta 0:00:33 lr 1.218393	time 1.1810 (1.8636)	loss 2.6330 (2.6235)	grad_norm 0.5029 (0.4761)	mem 39782MB
[2023-07-07 15:30:01 RepVGG-A0] (main.py 282): INFO Train: [213/300][70/78]	eta 0:00:14 lr 1.215022	time 1.3142 (1.8250)	loss 2.6749 (2.6277)	grad_norm 0.4545 (0.4756)	mem 39782MB
[2023-07-07 15:30:13 RepVGG-A0] (main.py 291): INFO EPOCH 213 training takes 0:02:21
[2023-07-07 15:30:33 RepVGG-A0] (main.py 282): INFO Train: [214/300][0/78]	eta 0:25:26 lr 1.212327	time 19.5683 (19.5683)	loss 2.5578 (2.5578)	grad_norm 0.4605 (0.4605)	mem 39782MB
[2023-07-07 15:30:49 RepVGG-A0] (main.py 282): INFO Train: [214/300][10/78]	eta 0:03:40 lr 1.208962	time 1.1712 (3.2476)	loss 2.6141 (2.5897)	grad_norm 0.4649 (0.4605)	mem 39782MB
[2023-07-07 15:31:05 RepVGG-A0] (main.py 282): INFO Train: [214/300][20/78]	eta 0:02:24 lr 1.205600	time 1.2995 (2.4838)	loss 2.6250 (2.6000)	grad_norm 0.5483 (0.4681)	mem 39782MB
[2023-07-07 15:31:19 RepVGG-A0] (main.py 282): INFO Train: [214/300][30/78]	eta 0:01:42 lr 1.202243	time 1.1855 (2.1401)	loss 2.6117 (2.6096)	grad_norm 0.4734 (0.4799)	mem 39782MB
[2023-07-07 15:31:37 RepVGG-A0] (main.py 282): INFO Train: [214/300][40/78]	eta 0:01:17 lr 1.198888	time 3.6339 (2.0522)	loss 2.6468 (2.6160)	grad_norm 0.4667 (0.4781)	mem 39782MB
[2023-07-07 15:31:52 RepVGG-A0] (main.py 282): INFO Train: [214/300][50/78]	eta 0:00:54 lr 1.195538	time 1.1949 (1.9402)	loss 2.6698 (2.6174)	grad_norm 0.4861 (0.4744)	mem 39782MB
[2023-07-07 15:32:07 RepVGG-A0] (main.py 282): INFO Train: [214/300][60/78]	eta 0:00:33 lr 1.192190	time 1.1660 (1.8688)	loss 2.6297 (2.6231)	grad_norm 0.4660 (0.4822)	mem 39782MB
[2023-07-07 15:32:23 RepVGG-A0] (main.py 282): INFO Train: [214/300][70/78]	eta 0:00:14 lr 1.188847	time 1.1300 (1.8314)	loss 2.6527 (2.6256)	grad_norm 0.4832 (0.4792)	mem 39782MB
[2023-07-07 15:32:33 RepVGG-A0] (main.py 291): INFO EPOCH 214 training takes 0:02:20
[2023-07-07 15:32:55 RepVGG-A0] (main.py 282): INFO Train: [215/300][0/78]	eta 0:27:44 lr 1.186175	time 21.3434 (21.3434)	loss 2.6166 (2.6166)	grad_norm 0.4838 (0.4838)	mem 39782MB
[2023-07-07 15:33:09 RepVGG-A0] (main.py 282): INFO Train: [215/300][10/78]	eta 0:03:40 lr 1.182838	time 1.1732 (3.2476)	loss 2.5566 (2.5902)	grad_norm 0.4760 (0.4567)	mem 39782MB
[2023-07-07 15:33:25 RepVGG-A0] (main.py 282): INFO Train: [215/300][20/78]	eta 0:02:23 lr 1.179504	time 1.1731 (2.4680)	loss 2.6278 (2.5869)	grad_norm 0.5156 (0.4638)	mem 39782MB
[2023-07-07 15:33:42 RepVGG-A0] (main.py 282): INFO Train: [215/300][30/78]	eta 0:01:45 lr 1.176175	time 1.5054 (2.1962)	loss 2.6262 (2.5999)	grad_norm 0.4806 (0.4775)	mem 39782MB
[2023-07-07 15:33:59 RepVGG-A0] (main.py 282): INFO Train: [215/300][40/78]	eta 0:01:19 lr 1.172849	time 3.6816 (2.0836)	loss 2.6443 (2.6016)	grad_norm 0.4640 (0.4733)	mem 39782MB
[2023-07-07 15:34:14 RepVGG-A0] (main.py 282): INFO Train: [215/300][50/78]	eta 0:00:55 lr 1.169526	time 1.1725 (1.9792)	loss 2.6203 (2.6074)	grad_norm 0.5113 (0.4762)	mem 39782MB
[2023-07-07 15:34:29 RepVGG-A0] (main.py 282): INFO Train: [215/300][60/78]	eta 0:00:34 lr 1.166208	time 1.1778 (1.8924)	loss 2.5985 (2.6108)	grad_norm 0.4671 (0.4752)	mem 39782MB
[2023-07-07 15:34:44 RepVGG-A0] (main.py 282): INFO Train: [215/300][70/78]	eta 0:00:14 lr 1.162893	time 1.1776 (1.8392)	loss 2.6137 (2.6152)	grad_norm 0.4564 (0.4789)	mem 39782MB
[2023-07-07 15:34:55 RepVGG-A0] (main.py 291): INFO EPOCH 215 training takes 0:02:22
[2023-07-07 15:35:17 RepVGG-A0] (main.py 282): INFO Train: [216/300][0/78]	eta 0:27:27 lr 1.160243	time 21.1266 (21.1266)	loss 2.5729 (2.5729)	grad_norm 0.5179 (0.5179)	mem 39782MB
[2023-07-07 15:35:33 RepVGG-A0] (main.py 282): INFO Train: [216/300][10/78]	eta 0:03:51 lr 1.156935	time 1.1718 (3.4062)	loss 2.5738 (2.5770)	grad_norm 0.4784 (0.4752)	mem 39782MB
[2023-07-07 15:35:47 RepVGG-A0] (main.py 282): INFO Train: [216/300][20/78]	eta 0:02:22 lr 1.153630	time 1.1748 (2.4610)	loss 2.6108 (2.5847)	grad_norm 0.4568 (0.4693)	mem 39782MB
[2023-07-07 15:36:03 RepVGG-A0] (main.py 282): INFO Train: [216/300][30/78]	eta 0:01:44 lr 1.150329	time 1.2777 (2.1754)	loss 2.5941 (2.5952)	grad_norm 0.5016 (0.4759)	mem 39782MB
[2023-07-07 15:36:21 RepVGG-A0] (main.py 282): INFO Train: [216/300][40/78]	eta 0:01:18 lr 1.147032	time 4.3343 (2.0750)	loss 2.5871 (2.5991)	grad_norm 0.4737 (0.4743)	mem 39782MB
[2023-07-07 15:36:36 RepVGG-A0] (main.py 282): INFO Train: [216/300][50/78]	eta 0:00:55 lr 1.143738	time 1.2269 (1.9677)	loss 2.6531 (2.6070)	grad_norm 0.5457 (0.4820)	mem 39782MB
[2023-07-07 15:36:51 RepVGG-A0] (main.py 282): INFO Train: [216/300][60/78]	eta 0:00:34 lr 1.140448	time 1.1968 (1.8922)	loss 2.6387 (2.6098)	grad_norm 0.4538 (0.4853)	mem 39782MB
[2023-07-07 15:37:06 RepVGG-A0] (main.py 282): INFO Train: [216/300][70/78]	eta 0:00:14 lr 1.137162	time 1.4525 (1.8440)	loss 2.5850 (2.6091)	grad_norm 0.4704 (0.4836)	mem 39782MB
[2023-07-07 15:37:17 RepVGG-A0] (main.py 291): INFO EPOCH 216 training takes 0:02:21
[2023-07-07 15:37:38 RepVGG-A0] (main.py 282): INFO Train: [217/300][0/78]	eta 0:28:18 lr 1.134535	time 21.7724 (21.7724)	loss 2.5235 (2.5235)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:37:52 RepVGG-A0] (main.py 282): INFO Train: [217/300][10/78]	eta 0:03:40 lr 1.131256	time 1.1707 (3.2394)	loss 2.5266 (2.5611)	grad_norm 0.4741 (0.4763)	mem 39782MB
[2023-07-07 15:38:07 RepVGG-A0] (main.py 282): INFO Train: [217/300][20/78]	eta 0:02:19 lr 1.127980	time 1.1751 (2.4055)	loss 2.5697 (2.5727)	grad_norm 0.4497 (0.4682)	mem 39782MB
[2023-07-07 15:38:22 RepVGG-A0] (main.py 282): INFO Train: [217/300][30/78]	eta 0:01:41 lr 1.124708	time 1.1928 (2.1114)	loss 2.5662 (2.5816)	grad_norm 0.4814 (0.4721)	mem 39782MB
[2023-07-07 15:38:40 RepVGG-A0] (main.py 282): INFO Train: [217/300][40/78]	eta 0:01:17 lr 1.121440	time 4.2439 (2.0399)	loss 2.6068 (2.5867)	grad_norm 0.4837 (0.4768)	mem 39782MB
[2023-07-07 15:38:55 RepVGG-A0] (main.py 282): INFO Train: [217/300][50/78]	eta 0:00:54 lr 1.118175	time 1.2764 (1.9345)	loss 2.6318 (2.5938)	grad_norm 0.4781 (0.4750)	mem 39782MB
[2023-07-07 15:39:10 RepVGG-A0] (main.py 282): INFO Train: [217/300][60/78]	eta 0:00:33 lr 1.114914	time 1.2017 (1.8563)	loss 2.5875 (2.5962)	grad_norm 0.5024 (0.4758)	mem 39782MB
[2023-07-07 15:39:26 RepVGG-A0] (main.py 282): INFO Train: [217/300][70/78]	eta 0:00:14 lr 1.111657	time 1.2913 (1.8181)	loss 2.5990 (2.5999)	grad_norm 0.4819 (0.4764)	mem 39782MB
[2023-07-07 15:39:37 RepVGG-A0] (main.py 291): INFO EPOCH 217 training takes 0:02:20
[2023-07-07 15:39:59 RepVGG-A0] (main.py 282): INFO Train: [218/300][0/78]	eta 0:29:01 lr 1.109054	time 22.3230 (22.3230)	loss 2.5743 (2.5743)	grad_norm 0.4891 (0.4891)	mem 39782MB
[2023-07-07 15:40:15 RepVGG-A0] (main.py 282): INFO Train: [218/300][10/78]	eta 0:03:54 lr 1.105804	time 1.3437 (3.4553)	loss 2.6161 (2.5592)	grad_norm 0.5280 (0.4843)	mem 39782MB
[2023-07-07 15:40:30 RepVGG-A0] (main.py 282): INFO Train: [218/300][20/78]	eta 0:02:25 lr 1.102557	time 1.1737 (2.5103)	loss 2.5994 (2.5733)	grad_norm 0.4757 (0.4871)	mem 39782MB
[2023-07-07 15:40:45 RepVGG-A0] (main.py 282): INFO Train: [218/300][30/78]	eta 0:01:45 lr 1.099314	time 1.3203 (2.1888)	loss 2.6021 (2.5821)	grad_norm 0.4633 (0.4888)	mem 39782MB
[2023-07-07 15:41:03 RepVGG-A0] (main.py 282): INFO Train: [218/300][40/78]	eta 0:01:19 lr 1.096075	time 3.2563 (2.0990)	loss 2.6342 (2.5830)	grad_norm 0.4775 (0.4850)	mem 39782MB
[2023-07-07 15:41:18 RepVGG-A0] (main.py 282): INFO Train: [218/300][50/78]	eta 0:00:55 lr 1.092840	time 1.1759 (1.9740)	loss 2.5657 (2.5898)	grad_norm 0.4559 (0.4835)	mem 39782MB
[2023-07-07 15:41:33 RepVGG-A0] (main.py 282): INFO Train: [218/300][60/78]	eta 0:00:34 lr 1.089609	time 1.2678 (1.9028)	loss 2.5801 (2.5887)	grad_norm 0.4809 (0.4809)	mem 39782MB
[2023-07-07 15:41:48 RepVGG-A0] (main.py 282): INFO Train: [218/300][70/78]	eta 0:00:14 lr 1.086381	time 1.2691 (1.8477)	loss 2.6520 (2.5931)	grad_norm 0.5080 (0.4838)	mem 39782MB
[2023-07-07 15:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 218 training takes 0:02:22
[2023-07-07 15:42:22 RepVGG-A0] (main.py 282): INFO Train: [219/300][0/78]	eta 0:28:00 lr 1.083802	time 21.5476 (21.5476)	loss 2.5723 (2.5723)	grad_norm 0.4598 (0.4598)	mem 39782MB
[2023-07-07 15:42:36 RepVGG-A0] (main.py 282): INFO Train: [219/300][10/78]	eta 0:03:44 lr 1.080581	time 1.1723 (3.2983)	loss 2.5507 (2.5542)	grad_norm 0.5098 (0.4698)	mem 39782MB
[2023-07-07 15:42:51 RepVGG-A0] (main.py 282): INFO Train: [219/300][20/78]	eta 0:02:20 lr 1.077364	time 1.4762 (2.4304)	loss 2.5788 (2.5702)	grad_norm 0.5126 (0.4855)	mem 39782MB
[2023-07-07 15:43:07 RepVGG-A0] (main.py 282): INFO Train: [219/300][30/78]	eta 0:01:43 lr 1.074151	time 1.5620 (2.1588)	loss 2.5709 (2.5768)	grad_norm 0.4718 (0.4858)	mem 39782MB
[2023-07-07 15:43:24 RepVGG-A0] (main.py 282): INFO Train: [219/300][40/78]	eta 0:01:18 lr 1.070942	time 2.3594 (2.0569)	loss 2.5553 (2.5770)	grad_norm 0.4710 (0.4841)	mem 39782MB
[2023-07-07 15:43:39 RepVGG-A0] (main.py 282): INFO Train: [219/300][50/78]	eta 0:00:54 lr 1.067737	time 1.1941 (1.9482)	loss 2.6180 (2.5810)	grad_norm 0.5241 (0.4860)	mem 39782MB
[2023-07-07 15:43:53 RepVGG-A0] (main.py 282): INFO Train: [219/300][60/78]	eta 0:00:33 lr 1.064535	time 1.1773 (1.8569)	loss 2.6619 (2.5890)	grad_norm 0.4939 (0.4877)	mem 39782MB
[2023-07-07 15:44:09 RepVGG-A0] (main.py 282): INFO Train: [219/300][70/78]	eta 0:00:14 lr 1.061337	time 1.2640 (1.8103)	loss 2.5534 (2.5878)	grad_norm 0.4977 (0.4861)	mem 39782MB
[2023-07-07 15:44:20 RepVGG-A0] (main.py 291): INFO EPOCH 219 training takes 0:02:20
[2023-07-07 15:44:41 RepVGG-A0] (main.py 282): INFO Train: [220/300][0/78]	eta 0:27:30 lr 1.058782	time 21.1587 (21.1587)	loss 2.5689 (2.5689)	grad_norm 0.4640 (0.4640)	mem 39782MB
[2023-07-07 15:44:56 RepVGG-A0] (main.py 282): INFO Train: [220/300][10/78]	eta 0:03:39 lr 1.055591	time 1.1708 (3.2273)	loss 2.5663 (2.5493)	grad_norm 0.4841 (0.4878)	mem 39782MB
[2023-07-07 15:45:10 RepVGG-A0] (main.py 282): INFO Train: [220/300][20/78]	eta 0:02:18 lr 1.052404	time 1.1738 (2.3874)	loss 2.5841 (2.5568)	grad_norm 0.4704 (0.5001)	mem 39782MB
[2023-07-07 15:45:26 RepVGG-A0] (main.py 282): INFO Train: [220/300][30/78]	eta 0:01:41 lr 1.049221	time 1.3499 (2.1223)	loss 2.5669 (2.5647)	grad_norm 0.4838 (0.4927)	mem 39782MB
[2023-07-07 15:45:44 RepVGG-A0] (main.py 282): INFO Train: [220/300][40/78]	eta 0:01:17 lr 1.046042	time 4.3594 (2.0513)	loss 2.6631 (2.5715)	grad_norm 0.4764 (0.4889)	mem 39782MB
[2023-07-07 15:45:59 RepVGG-A0] (main.py 282): INFO Train: [220/300][50/78]	eta 0:00:54 lr 1.042867	time 1.1722 (1.9432)	loss 2.6068 (2.5779)	grad_norm 0.4897 (0.4882)	mem 39782MB
[2023-07-07 15:46:15 RepVGG-A0] (main.py 282): INFO Train: [220/300][60/78]	eta 0:00:33 lr 1.039696	time 1.4200 (1.8742)	loss 2.5700 (2.5808)	grad_norm 0.4994 (0.4913)	mem 39782MB
[2023-07-07 15:46:30 RepVGG-A0] (main.py 282): INFO Train: [220/300][70/78]	eta 0:00:14 lr 1.036528	time 1.3932 (1.8260)	loss 2.5796 (2.5806)	grad_norm 0.4628 (0.4894)	mem 39782MB
[2023-07-07 15:46:41 RepVGG-A0] (main.py 291): INFO EPOCH 220 training takes 0:02:20
[2023-07-07 15:46:58 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.985 (16.985)	Loss 1.8846 (1.8846)	Acc@1 60.229 (60.229)	Acc@5 82.672 (82.672)	Mem 39782MB
[2023-07-07 15:46:59 RepVGG-A0] (main.py 342): INFO  * Acc@1 60.430 Acc@5 82.872
[2023-07-07 15:46:59 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 220: 60.430%
[2023-07-07 15:46:59 RepVGG-A0] (main.py 172): INFO Max accuracy: 60.43%
[2023-07-07 15:47:20 RepVGG-A0] (main.py 282): INFO Train: [221/300][0/78]	eta 0:26:29 lr 1.033997	time 20.3720 (20.3720)	loss 2.5350 (2.5350)	grad_norm 0.4686 (0.4686)	mem 39782MB
[2023-07-07 15:47:35 RepVGG-A0] (main.py 282): INFO Train: [221/300][10/78]	eta 0:03:40 lr 1.030836	time 1.1929 (3.2420)	loss 2.5846 (2.5559)	grad_norm 0.5104 (0.5007)	mem 39782MB
[2023-07-07 15:47:51 RepVGG-A0] (main.py 282): INFO Train: [221/300][20/78]	eta 0:02:22 lr 1.027680	time 1.4022 (2.4513)	loss 2.5306 (2.5629)	grad_norm 0.4605 (0.4899)	mem 39782MB
[2023-07-07 15:48:07 RepVGG-A0] (main.py 282): INFO Train: [221/300][30/78]	eta 0:01:45 lr 1.024527	time 2.1381 (2.1936)	loss 2.6048 (2.5610)	grad_norm 0.5106 (0.4890)	mem 39782MB
[2023-07-07 15:48:24 RepVGG-A0] (main.py 282): INFO Train: [221/300][40/78]	eta 0:01:18 lr 1.021379	time 3.6720 (2.0659)	loss 2.5120 (2.5637)	grad_norm 0.4713 (0.4880)	mem 39782MB
[2023-07-07 15:48:39 RepVGG-A0] (main.py 282): INFO Train: [221/300][50/78]	eta 0:00:54 lr 1.018234	time 1.3348 (1.9596)	loss 2.5958 (2.5672)	grad_norm 0.5240 (0.4871)	mem 39782MB
[2023-07-07 15:48:54 RepVGG-A0] (main.py 282): INFO Train: [221/300][60/78]	eta 0:00:33 lr 1.015093	time 1.1802 (1.8851)	loss 2.6190 (2.5730)	grad_norm 0.4760 (0.4858)	mem 39782MB
[2023-07-07 15:49:10 RepVGG-A0] (main.py 282): INFO Train: [221/300][70/78]	eta 0:00:14 lr 1.011956	time 1.4151 (1.8466)	loss 2.5831 (2.5753)	grad_norm 0.5042 (0.4868)	mem 39782MB
[2023-07-07 15:49:23 RepVGG-A0] (main.py 291): INFO EPOCH 221 training takes 0:02:23
[2023-07-07 15:49:45 RepVGG-A0] (main.py 282): INFO Train: [222/300][0/78]	eta 0:29:41 lr 1.009449	time 22.8376 (22.8376)	loss 2.6220 (2.6220)	grad_norm 0.4914 (0.4914)	mem 39782MB
[2023-07-07 15:50:00 RepVGG-A0] (main.py 282): INFO Train: [222/300][10/78]	eta 0:03:52 lr 1.006319	time 1.1722 (3.4216)	loss 2.4593 (2.5301)	grad_norm 0.4525 (0.4776)	mem 39782MB
[2023-07-07 15:50:14 RepVGG-A0] (main.py 282): INFO Train: [222/300][20/78]	eta 0:02:21 lr 1.003194	time 1.1735 (2.4442)	loss 2.5137 (2.5468)	grad_norm 0.4798 (0.4826)	mem 39782MB
[2023-07-07 15:50:28 RepVGG-A0] (main.py 282): INFO Train: [222/300][30/78]	eta 0:01:41 lr 1.000072	time 1.2500 (2.1240)	loss 2.5217 (2.5506)	grad_norm 0.4730 (0.4815)	mem 39782MB
[2023-07-07 15:50:46 RepVGG-A0] (main.py 282): INFO Train: [222/300][40/78]	eta 0:01:17 lr 0.996954	time 3.2639 (2.0364)	loss 2.5776 (2.5588)	grad_norm 0.5011 (0.4845)	mem 39782MB
[2023-07-07 15:51:01 RepVGG-A0] (main.py 282): INFO Train: [222/300][50/78]	eta 0:00:54 lr 0.993840	time 1.4800 (1.9379)	loss 2.6282 (2.5624)	grad_norm 0.4818 (0.4836)	mem 39782MB
[2023-07-07 15:51:17 RepVGG-A0] (main.py 282): INFO Train: [222/300][60/78]	eta 0:00:33 lr 0.990730	time 1.1757 (1.8810)	loss 2.5806 (2.5645)	grad_norm 0.4855 (0.4862)	mem 39782MB
[2023-07-07 15:51:32 RepVGG-A0] (main.py 282): INFO Train: [222/300][70/78]	eta 0:00:14 lr 0.987624	time 1.3422 (1.8246)	loss 2.5720 (2.5668)	grad_norm 0.4788 (0.4853)	mem 39782MB
[2023-07-07 15:51:44 RepVGG-A0] (main.py 291): INFO EPOCH 222 training takes 0:02:21
[2023-07-07 15:52:07 RepVGG-A0] (main.py 282): INFO Train: [223/300][0/78]	eta 0:29:35 lr 0.985142	time 22.7600 (22.7600)	loss 2.5261 (2.5261)	grad_norm 0.4824 (0.4824)	mem 39782MB
[2023-07-07 15:52:22 RepVGG-A0] (main.py 282): INFO Train: [223/300][10/78]	eta 0:03:53 lr 0.982043	time 1.1947 (3.4330)	loss 2.5845 (2.5510)	grad_norm 0.5013 (0.4981)	mem 39782MB
[2023-07-07 15:52:35 RepVGG-A0] (main.py 282): INFO Train: [223/300][20/78]	eta 0:02:22 lr 0.978948	time 1.1732 (2.4508)	loss 2.5954 (2.5593)	grad_norm 0.4780 (0.5029)	mem 39782MB
[2023-07-07 15:52:52 RepVGG-A0] (main.py 282): INFO Train: [223/300][30/78]	eta 0:01:45 lr 0.975857	time 1.5373 (2.2068)	loss 2.4888 (2.5514)	grad_norm 0.4752 (0.4952)	mem 39782MB
[2023-07-07 15:53:09 RepVGG-A0] (main.py 282): INFO Train: [223/300][40/78]	eta 0:01:19 lr 0.972771	time 2.8176 (2.0791)	loss 2.6126 (2.5592)	grad_norm 0.4764 (0.4953)	mem 39782MB
[2023-07-07 15:53:24 RepVGG-A0] (main.py 282): INFO Train: [223/300][50/78]	eta 0:00:54 lr 0.969688	time 1.1733 (1.9641)	loss 2.5535 (2.5600)	grad_norm 0.4945 (0.4948)	mem 39782MB
[2023-07-07 15:53:39 RepVGG-A0] (main.py 282): INFO Train: [223/300][60/78]	eta 0:00:34 lr 0.966609	time 1.2877 (1.8899)	loss 2.6077 (2.5640)	grad_norm 0.4734 (0.4932)	mem 39782MB
[2023-07-07 15:53:55 RepVGG-A0] (main.py 282): INFO Train: [223/300][70/78]	eta 0:00:14 lr 0.963534	time 1.3962 (1.8415)	loss 2.6259 (2.5677)	grad_norm 0.4944 (0.4923)	mem 39782MB
[2023-07-07 15:54:06 RepVGG-A0] (main.py 291): INFO EPOCH 223 training takes 0:02:22
[2023-07-07 15:54:27 RepVGG-A0] (main.py 282): INFO Train: [224/300][0/78]	eta 0:27:28 lr 0.961077	time 21.1333 (21.1333)	loss 2.5058 (2.5058)	grad_norm 0.4953 (0.4953)	mem 39782MB
[2023-07-07 15:54:41 RepVGG-A0] (main.py 282): INFO Train: [224/300][10/78]	eta 0:03:37 lr 0.958010	time 1.1709 (3.1981)	loss 2.5588 (2.5395)	grad_norm 0.4578 (0.5028)	mem 39782MB
[2023-07-07 15:54:57 RepVGG-A0] (main.py 282): INFO Train: [224/300][20/78]	eta 0:02:20 lr 0.954946	time 1.1930 (2.4265)	loss 2.6362 (2.5399)	grad_norm 0.4992 (0.5000)	mem 39782MB
[2023-07-07 15:55:12 RepVGG-A0] (main.py 282): INFO Train: [224/300][30/78]	eta 0:01:42 lr 0.951887	time 1.4245 (2.1281)	loss 2.4925 (2.5377)	grad_norm 0.4729 (0.4954)	mem 39782MB
[2023-07-07 15:55:31 RepVGG-A0] (main.py 282): INFO Train: [224/300][40/78]	eta 0:01:18 lr 0.948832	time 3.0992 (2.0721)	loss 2.4892 (2.5388)	grad_norm 0.5102 (0.4970)	mem 39782MB
[2023-07-07 15:55:46 RepVGG-A0] (main.py 282): INFO Train: [224/300][50/78]	eta 0:00:54 lr 0.945780	time 1.2081 (1.9581)	loss 2.5897 (2.5425)	grad_norm 0.4963 (0.4969)	mem 39782MB
[2023-07-07 15:56:01 RepVGG-A0] (main.py 282): INFO Train: [224/300][60/78]	eta 0:00:33 lr 0.942733	time 1.4524 (1.8814)	loss 2.5298 (2.5481)	grad_norm 0.4766 (0.4956)	mem 39782MB
[2023-07-07 15:56:16 RepVGG-A0] (main.py 282): INFO Train: [224/300][70/78]	eta 0:00:14 lr 0.939690	time 1.6730 (1.8370)	loss 2.5196 (2.5519)	grad_norm 0.4975 (0.4972)	mem 39782MB
[2023-07-07 15:56:28 RepVGG-A0] (main.py 291): INFO EPOCH 224 training takes 0:02:21
[2023-07-07 15:56:50 RepVGG-A0] (main.py 282): INFO Train: [225/300][0/78]	eta 0:28:30 lr 0.937258	time 21.9252 (21.9252)	loss 2.4888 (2.4888)	grad_norm 0.5075 (0.5075)	mem 39782MB
[2023-07-07 15:57:04 RepVGG-A0] (main.py 282): INFO Train: [225/300][10/78]	eta 0:03:43 lr 0.934222	time 1.1713 (3.2895)	loss 2.4860 (2.5382)	grad_norm 0.4895 (0.4909)	mem 39782MB
[2023-07-07 15:57:18 RepVGG-A0] (main.py 282): INFO Train: [225/300][20/78]	eta 0:02:19 lr 0.931191	time 1.1721 (2.4041)	loss 2.5355 (2.5375)	grad_norm 0.4810 (0.4851)	mem 39782MB
[2023-07-07 15:57:34 RepVGG-A0] (main.py 282): INFO Train: [225/300][30/78]	eta 0:01:43 lr 0.928163	time 1.8304 (2.1497)	loss 2.5426 (2.5394)	grad_norm 0.4985 (0.4874)	mem 39782MB
[2023-07-07 15:57:51 RepVGG-A0] (main.py 282): INFO Train: [225/300][40/78]	eta 0:01:16 lr 0.925140	time 3.0404 (2.0224)	loss 2.5641 (2.5444)	grad_norm 0.5378 (0.4909)	mem 39782MB
[2023-07-07 15:58:07 RepVGG-A0] (main.py 282): INFO Train: [225/300][50/78]	eta 0:00:54 lr 0.922120	time 1.2169 (1.9400)	loss 2.5271 (2.5460)	grad_norm 0.4918 (0.4955)	mem 39782MB
[2023-07-07 15:58:23 RepVGG-A0] (main.py 282): INFO Train: [225/300][60/78]	eta 0:00:33 lr 0.919105	time 1.2507 (1.8822)	loss 2.5881 (2.5492)	grad_norm 0.4952 (0.4940)	mem 39782MB
[2023-07-07 15:58:38 RepVGG-A0] (main.py 282): INFO Train: [225/300][70/78]	eta 0:00:14 lr 0.916093	time 1.2994 (1.8303)	loss 2.6289 (2.5529)	grad_norm 0.5021 (0.4925)	mem 39782MB
[2023-07-07 15:58:50 RepVGG-A0] (main.py 291): INFO EPOCH 225 training takes 0:02:21
[2023-07-07 15:59:10 RepVGG-A0] (main.py 282): INFO Train: [226/300][0/78]	eta 0:26:55 lr 0.913687	time 20.7057 (20.7057)	loss 2.5287 (2.5287)	grad_norm 0.4776 (0.4776)	mem 39782MB
[2023-07-07 15:59:27 RepVGG-A0] (main.py 282): INFO Train: [226/300][10/78]	eta 0:03:49 lr 0.910684	time 1.1704 (3.3821)	loss 2.5845 (2.5124)	grad_norm 0.4954 (0.4838)	mem 39782MB
[2023-07-07 15:59:42 RepVGG-A0] (main.py 282): INFO Train: [226/300][20/78]	eta 0:02:24 lr 0.907684	time 1.2332 (2.4933)	loss 2.5993 (2.5168)	grad_norm 0.4981 (0.4960)	mem 39782MB
[2023-07-07 15:59:56 RepVGG-A0] (main.py 282): INFO Train: [226/300][30/78]	eta 0:01:43 lr 0.904688	time 1.5194 (2.1573)	loss 2.5046 (2.5224)	grad_norm 0.4910 (0.4935)	mem 39782MB
[2023-07-07 16:00:14 RepVGG-A0] (main.py 282): INFO Train: [226/300][40/78]	eta 0:01:18 lr 0.901697	time 2.2680 (2.0602)	loss 2.5803 (2.5289)	grad_norm 0.5053 (0.4947)	mem 39782MB
[2023-07-07 16:00:29 RepVGG-A0] (main.py 282): INFO Train: [226/300][50/78]	eta 0:00:54 lr 0.898710	time 1.1962 (1.9521)	loss 2.5219 (2.5314)	grad_norm 0.5148 (0.4937)	mem 39782MB
[2023-07-07 16:00:45 RepVGG-A0] (main.py 282): INFO Train: [226/300][60/78]	eta 0:00:33 lr 0.895726	time 1.1779 (1.8853)	loss 2.5392 (2.5380)	grad_norm 0.5291 (0.4971)	mem 39782MB
[2023-07-07 16:00:59 RepVGG-A0] (main.py 282): INFO Train: [226/300][70/78]	eta 0:00:14 lr 0.892747	time 1.2774 (1.8260)	loss 2.5633 (2.5406)	grad_norm 0.5015 (0.4992)	mem 39782MB
[2023-07-07 16:01:11 RepVGG-A0] (main.py 291): INFO EPOCH 226 training takes 0:02:21
[2023-07-07 16:01:33 RepVGG-A0] (main.py 282): INFO Train: [227/300][0/78]	eta 0:28:21 lr 0.890367	time 21.8091 (21.8091)	loss 2.4808 (2.4808)	grad_norm 0.4839 (0.4839)	mem 39782MB
[2023-07-07 16:01:47 RepVGG-A0] (main.py 282): INFO Train: [227/300][10/78]	eta 0:03:43 lr 0.887396	time 1.1722 (3.2795)	loss 2.5717 (2.5163)	grad_norm 0.5000 (0.4859)	mem 39782MB
[2023-07-07 16:02:02 RepVGG-A0] (main.py 282): INFO Train: [227/300][20/78]	eta 0:02:21 lr 0.884428	time 1.2434 (2.4327)	loss 2.5367 (2.5236)	grad_norm 0.5048 (0.4904)	mem 39782MB
[2023-07-07 16:02:18 RepVGG-A0] (main.py 282): INFO Train: [227/300][30/78]	eta 0:01:43 lr 0.881465	time 1.1331 (2.1572)	loss 2.4444 (2.5267)	grad_norm 0.5313 (0.4920)	mem 39782MB
[2023-07-07 16:02:35 RepVGG-A0] (main.py 282): INFO Train: [227/300][40/78]	eta 0:01:17 lr 0.878506	time 3.8017 (2.0390)	loss 2.5487 (2.5323)	grad_norm 0.4835 (0.4962)	mem 39782MB
[2023-07-07 16:02:51 RepVGG-A0] (main.py 282): INFO Train: [227/300][50/78]	eta 0:00:54 lr 0.875552	time 1.1744 (1.9575)	loss 2.6093 (2.5307)	grad_norm 0.5101 (0.4968)	mem 39782MB
[2023-07-07 16:03:06 RepVGG-A0] (main.py 282): INFO Train: [227/300][60/78]	eta 0:00:33 lr 0.872601	time 1.2928 (1.8848)	loss 2.5412 (2.5358)	grad_norm 0.5010 (0.4974)	mem 39782MB
[2023-07-07 16:03:21 RepVGG-A0] (main.py 282): INFO Train: [227/300][70/78]	eta 0:00:14 lr 0.869654	time 1.2899 (1.8325)	loss 2.4979 (2.5364)	grad_norm 0.4780 (0.4987)	mem 39782MB
[2023-07-07 16:03:31 RepVGG-A0] (main.py 291): INFO EPOCH 227 training takes 0:02:20
[2023-07-07 16:03:52 RepVGG-A0] (main.py 282): INFO Train: [228/300][0/78]	eta 0:26:24 lr 0.867300	time 20.3193 (20.3193)	loss 2.5255 (2.5255)	grad_norm 0.4888 (0.4888)	mem 39782MB
[2023-07-07 16:04:06 RepVGG-A0] (main.py 282): INFO Train: [228/300][10/78]	eta 0:03:36 lr 0.864362	time 1.1904 (3.1818)	loss 2.4856 (2.4995)	grad_norm 0.5211 (0.5037)	mem 39782MB
[2023-07-07 16:04:21 RepVGG-A0] (main.py 282): INFO Train: [228/300][20/78]	eta 0:02:18 lr 0.861427	time 1.1726 (2.3835)	loss 2.4663 (2.5090)	grad_norm 0.4989 (0.4966)	mem 39782MB
[2023-07-07 16:04:38 RepVGG-A0] (main.py 282): INFO Train: [228/300][30/78]	eta 0:01:42 lr 0.858496	time 1.4576 (2.1374)	loss 2.4984 (2.5078)	grad_norm 0.4733 (0.4940)	mem 39782MB
[2023-07-07 16:04:55 RepVGG-A0] (main.py 282): INFO Train: [228/300][40/78]	eta 0:01:17 lr 0.855570	time 2.9813 (2.0361)	loss 2.5733 (2.5156)	grad_norm 0.5176 (0.4957)	mem 39782MB
[2023-07-07 16:05:10 RepVGG-A0] (main.py 282): INFO Train: [228/300][50/78]	eta 0:00:53 lr 0.852648	time 1.1879 (1.9271)	loss 2.5651 (2.5230)	grad_norm 0.4996 (0.5002)	mem 39782MB
[2023-07-07 16:05:25 RepVGG-A0] (main.py 282): INFO Train: [228/300][60/78]	eta 0:00:33 lr 0.849731	time 1.2221 (1.8600)	loss 2.5407 (2.5215)	grad_norm 0.4959 (0.4983)	mem 39782MB
[2023-07-07 16:05:40 RepVGG-A0] (main.py 282): INFO Train: [228/300][70/78]	eta 0:00:14 lr 0.846817	time 1.1798 (1.8094)	loss 2.5890 (2.5236)	grad_norm 0.5037 (0.4973)	mem 39782MB
[2023-07-07 16:05:51 RepVGG-A0] (main.py 291): INFO EPOCH 228 training takes 0:02:19
[2023-07-07 16:06:13 RepVGG-A0] (main.py 282): INFO Train: [229/300][0/78]	eta 0:28:39 lr 0.844489	time 22.0511 (22.0511)	loss 2.5134 (2.5134)	grad_norm 0.4955 (0.4955)	mem 39782MB
[2023-07-07 16:06:28 RepVGG-A0] (main.py 282): INFO Train: [229/300][10/78]	eta 0:03:45 lr 0.841583	time 1.1734 (3.3234)	loss 2.5201 (2.4952)	grad_norm 0.4885 (0.4975)	mem 39782MB
[2023-07-07 16:06:42 RepVGG-A0] (main.py 282): INFO Train: [229/300][20/78]	eta 0:02:20 lr 0.838682	time 1.1921 (2.4287)	loss 2.6184 (2.5084)	grad_norm 0.5325 (0.5072)	mem 39782MB
[2023-07-07 16:06:58 RepVGG-A0] (main.py 282): INFO Train: [229/300][30/78]	eta 0:01:42 lr 0.835784	time 1.2235 (2.1408)	loss 2.5527 (2.5223)	grad_norm 0.4963 (0.5021)	mem 39782MB
[2023-07-07 16:07:16 RepVGG-A0] (main.py 282): INFO Train: [229/300][40/78]	eta 0:01:18 lr 0.832891	time 3.0516 (2.0664)	loss 2.4755 (2.5183)	grad_norm 0.5258 (0.5019)	mem 39782MB
[2023-07-07 16:07:31 RepVGG-A0] (main.py 282): INFO Train: [229/300][50/78]	eta 0:00:54 lr 0.830003	time 1.1739 (1.9574)	loss 2.5132 (2.5218)	grad_norm 0.5343 (0.5030)	mem 39782MB
[2023-07-07 16:07:46 RepVGG-A0] (main.py 282): INFO Train: [229/300][60/78]	eta 0:00:33 lr 0.827118	time 1.1785 (1.8829)	loss 2.5498 (2.5245)	grad_norm 0.4989 (0.5037)	mem 39782MB
[2023-07-07 16:08:02 RepVGG-A0] (main.py 282): INFO Train: [229/300][70/78]	eta 0:00:14 lr 0.824238	time 1.5281 (1.8353)	loss 2.5550 (2.5264)	grad_norm 0.5166 (0.5035)	mem 39782MB
[2023-07-07 16:08:13 RepVGG-A0] (main.py 291): INFO EPOCH 229 training takes 0:02:21
[2023-07-07 16:08:34 RepVGG-A0] (main.py 282): INFO Train: [230/300][0/78]	eta 0:28:12 lr 0.821937	time 21.7004 (21.7004)	loss 2.5178 (2.5178)	grad_norm 0.4908 (0.4908)	mem 39782MB
[2023-07-07 16:08:49 RepVGG-A0] (main.py 282): INFO Train: [230/300][10/78]	eta 0:03:46 lr 0.819064	time 1.1719 (3.3327)	loss 2.5392 (2.5037)	grad_norm 0.5070 (0.4987)	mem 39782MB
[2023-07-07 16:09:05 RepVGG-A0] (main.py 282): INFO Train: [230/300][20/78]	eta 0:02:24 lr 0.816196	time 1.2202 (2.4983)	loss 2.5291 (2.5126)	grad_norm 0.4918 (0.5001)	mem 39782MB
[2023-07-07 16:09:19 RepVGG-A0] (main.py 282): INFO Train: [230/300][30/78]	eta 0:01:42 lr 0.813332	time 1.5198 (2.1423)	loss 2.4957 (2.5144)	grad_norm 0.4943 (0.5026)	mem 39782MB
[2023-07-07 16:09:36 RepVGG-A0] (main.py 282): INFO Train: [230/300][40/78]	eta 0:01:17 lr 0.810472	time 3.3131 (2.0381)	loss 2.5333 (2.5139)	grad_norm 0.4874 (0.5005)	mem 39782MB
[2023-07-07 16:09:52 RepVGG-A0] (main.py 282): INFO Train: [230/300][50/78]	eta 0:00:54 lr 0.807617	time 1.1725 (1.9509)	loss 2.5440 (2.5194)	grad_norm 0.5224 (0.5003)	mem 39782MB
[2023-07-07 16:10:07 RepVGG-A0] (main.py 282): INFO Train: [230/300][60/78]	eta 0:00:33 lr 0.804766	time 1.1280 (1.8775)	loss 2.5769 (2.5245)	grad_norm 0.5131 (0.5037)	mem 39782MB
[2023-07-07 16:10:22 RepVGG-A0] (main.py 282): INFO Train: [230/300][70/78]	eta 0:00:14 lr 0.801919	time 1.1314 (1.8260)	loss 2.5230 (2.5250)	grad_norm 0.4890 (0.5033)	mem 39782MB
[2023-07-07 16:10:34 RepVGG-A0] (main.py 291): INFO EPOCH 230 training takes 0:02:20
[2023-07-07 16:10:55 RepVGG-A0] (main.py 282): INFO Train: [231/300][0/78]	eta 0:28:27 lr 0.799645	time 21.8872 (21.8872)	loss 2.5200 (2.5200)	grad_norm 0.4890 (0.4890)	mem 39782MB
[2023-07-07 16:11:09 RepVGG-A0] (main.py 282): INFO Train: [231/300][10/78]	eta 0:03:41 lr 0.796806	time 1.1707 (3.2588)	loss 2.4820 (2.4876)	grad_norm 0.5044 (0.4964)	mem 39782MB
[2023-07-07 16:11:25 RepVGG-A0] (main.py 282): INFO Train: [231/300][20/78]	eta 0:02:20 lr 0.793971	time 1.2362 (2.4297)	loss 2.5207 (2.4964)	grad_norm 0.5226 (0.5073)	mem 39782MB
[2023-07-07 16:11:40 RepVGG-A0] (main.py 282): INFO Train: [231/300][30/78]	eta 0:01:43 lr 0.791141	time 1.1583 (2.1507)	loss 2.5513 (2.4999)	grad_norm 0.4892 (0.5057)	mem 39782MB
[2023-07-07 16:11:58 RepVGG-A0] (main.py 282): INFO Train: [231/300][40/78]	eta 0:01:18 lr 0.788315	time 3.4267 (2.0698)	loss 2.5239 (2.4997)	grad_norm 0.4973 (0.5028)	mem 39782MB
[2023-07-07 16:12:13 RepVGG-A0] (main.py 282): INFO Train: [231/300][50/78]	eta 0:00:54 lr 0.785493	time 1.1723 (1.9579)	loss 2.4641 (2.5045)	grad_norm 0.5195 (0.5043)	mem 39782MB
[2023-07-07 16:12:28 RepVGG-A0] (main.py 282): INFO Train: [231/300][60/78]	eta 0:00:33 lr 0.782676	time 1.2663 (1.8772)	loss 2.5424 (2.5061)	grad_norm 0.5058 (0.5039)	mem 39782MB
[2023-07-07 16:12:44 RepVGG-A0] (main.py 282): INFO Train: [231/300][70/78]	eta 0:00:14 lr 0.779863	time 1.4117 (1.8339)	loss 2.5311 (2.5091)	grad_norm 0.4934 (0.5065)	mem 39782MB
[2023-07-07 16:12:55 RepVGG-A0] (main.py 291): INFO EPOCH 231 training takes 0:02:21
[2023-07-07 16:13:17 RepVGG-A0] (main.py 282): INFO Train: [232/300][0/78]	eta 0:28:03 lr 0.777616	time 21.5848 (21.5848)	loss 2.4144 (2.4144)	grad_norm 0.5016 (0.5016)	mem 39782MB
[2023-07-07 16:13:31 RepVGG-A0] (main.py 282): INFO Train: [232/300][10/78]	eta 0:03:44 lr 0.774811	time 1.1710 (3.3053)	loss 2.4747 (2.4716)	grad_norm 0.5215 (0.5087)	mem 39782MB
[2023-07-07 16:13:46 RepVGG-A0] (main.py 282): INFO Train: [232/300][20/78]	eta 0:02:21 lr 0.772010	time 1.1768 (2.4389)	loss 2.4825 (2.4779)	grad_norm 0.5125 (0.5089)	mem 39782MB
[2023-07-07 16:14:00 RepVGG-A0] (main.py 282): INFO Train: [232/300][30/78]	eta 0:01:40 lr 0.769214	time 1.3479 (2.0967)	loss 2.5613 (2.4895)	grad_norm 0.5037 (0.5062)	mem 39782MB
[2023-07-07 16:14:20 RepVGG-A0] (main.py 282): INFO Train: [232/300][40/78]	eta 0:01:18 lr 0.766422	time 4.0187 (2.0635)	loss 2.5415 (2.4979)	grad_norm 0.5148 (0.5051)	mem 39782MB
[2023-07-07 16:14:35 RepVGG-A0] (main.py 282): INFO Train: [232/300][50/78]	eta 0:00:54 lr 0.763634	time 1.2503 (1.9536)	loss 2.5436 (2.5035)	grad_norm 0.4926 (0.5051)	mem 39782MB
[2023-07-07 16:14:51 RepVGG-A0] (main.py 282): INFO Train: [232/300][60/78]	eta 0:00:34 lr 0.760851	time 1.2124 (1.8956)	loss 2.5682 (2.5064)	grad_norm 0.5255 (0.5054)	mem 39782MB
[2023-07-07 16:15:04 RepVGG-A0] (main.py 282): INFO Train: [232/300][70/78]	eta 0:00:14 lr 0.758073	time 1.4083 (1.8153)	loss 2.4667 (2.5082)	grad_norm 0.5199 (0.5059)	mem 39782MB
[2023-07-07 16:15:16 RepVGG-A0] (main.py 291): INFO EPOCH 232 training takes 0:02:21
[2023-07-07 16:15:38 RepVGG-A0] (main.py 282): INFO Train: [233/300][0/78]	eta 0:28:11 lr 0.755853	time 21.6890 (21.6890)	loss 2.4850 (2.4850)	grad_norm 0.4861 (0.4861)	mem 39782MB
[2023-07-07 16:15:52 RepVGG-A0] (main.py 282): INFO Train: [233/300][10/78]	eta 0:03:43 lr 0.753082	time 1.1727 (3.2824)	loss 2.5110 (2.4794)	grad_norm 0.5264 (0.5047)	mem 39782MB
[2023-07-07 16:16:07 RepVGG-A0] (main.py 282): INFO Train: [233/300][20/78]	eta 0:02:19 lr 0.750316	time 1.1767 (2.4093)	loss 2.4631 (2.4774)	grad_norm 0.5059 (0.5057)	mem 39782MB
[2023-07-07 16:16:23 RepVGG-A0] (main.py 282): INFO Train: [233/300][30/78]	eta 0:01:43 lr 0.747554	time 1.2966 (2.1467)	loss 2.4213 (2.4826)	grad_norm 0.5195 (0.5117)	mem 39782MB
[2023-07-07 16:16:40 RepVGG-A0] (main.py 282): INFO Train: [233/300][40/78]	eta 0:01:17 lr 0.744796	time 3.4336 (2.0307)	loss 2.5040 (2.4824)	grad_norm 0.4857 (0.5098)	mem 39782MB
[2023-07-07 16:16:55 RepVGG-A0] (main.py 282): INFO Train: [233/300][50/78]	eta 0:00:53 lr 0.742043	time 1.1738 (1.9267)	loss 2.5188 (2.4865)	grad_norm 0.5036 (0.5124)	mem 39782MB
[2023-07-07 16:17:10 RepVGG-A0] (main.py 282): INFO Train: [233/300][60/78]	eta 0:00:33 lr 0.739294	time 1.6248 (1.8666)	loss 2.4372 (2.4914)	grad_norm 0.4957 (0.5112)	mem 39782MB
[2023-07-07 16:17:25 RepVGG-A0] (main.py 282): INFO Train: [233/300][70/78]	eta 0:00:14 lr 0.736550	time 1.1960 (1.8103)	loss 2.5690 (2.4943)	grad_norm 0.5257 (0.5134)	mem 39782MB
[2023-07-07 16:17:37 RepVGG-A0] (main.py 291): INFO EPOCH 233 training takes 0:02:20
[2023-07-07 16:18:00 RepVGG-A0] (main.py 282): INFO Train: [234/300][0/78]	eta 0:29:11 lr 0.734358	time 22.4545 (22.4545)	loss 2.4051 (2.4051)	grad_norm 0.5111 (0.5111)	mem 39782MB
[2023-07-07 16:18:14 RepVGG-A0] (main.py 282): INFO Train: [234/300][10/78]	eta 0:03:48 lr 0.731621	time 1.1725 (3.3660)	loss 2.5204 (2.4886)	grad_norm 0.5129 (0.5066)	mem 39782MB
[2023-07-07 16:18:29 RepVGG-A0] (main.py 282): INFO Train: [234/300][20/78]	eta 0:02:23 lr 0.728890	time 1.1493 (2.4699)	loss 2.4513 (2.4781)	grad_norm 0.5179 (0.5055)	mem 39782MB
[2023-07-07 16:18:44 RepVGG-A0] (main.py 282): INFO Train: [234/300][30/78]	eta 0:01:42 lr 0.726162	time 1.2143 (2.1427)	loss 2.5027 (2.4793)	grad_norm 0.5414 (0.5103)	mem 39782MB
[2023-07-07 16:19:02 RepVGG-A0] (main.py 282): INFO Train: [234/300][40/78]	eta 0:01:18 lr 0.723439	time 3.9385 (2.0670)	loss 2.5043 (2.4838)	grad_norm 0.5134 (0.5097)	mem 39782MB
[2023-07-07 16:19:18 RepVGG-A0] (main.py 282): INFO Train: [234/300][50/78]	eta 0:00:55 lr 0.720721	time 1.1735 (1.9767)	loss 2.4964 (2.4894)	grad_norm 0.4892 (0.5068)	mem 39782MB
[2023-07-07 16:19:32 RepVGG-A0] (main.py 282): INFO Train: [234/300][60/78]	eta 0:00:33 lr 0.718007	time 1.1878 (1.8782)	loss 2.4702 (2.4925)	grad_norm 0.5074 (0.5100)	mem 39782MB
[2023-07-07 16:19:48 RepVGG-A0] (main.py 282): INFO Train: [234/300][70/78]	eta 0:00:14 lr 0.715297	time 1.3332 (1.8463)	loss 2.5065 (2.4939)	grad_norm 0.5236 (0.5097)	mem 39782MB
[2023-07-07 16:19:59 RepVGG-A0] (main.py 291): INFO EPOCH 234 training takes 0:02:22
[2023-07-07 16:20:21 RepVGG-A0] (main.py 282): INFO Train: [235/300][0/78]	eta 0:27:48 lr 0.713133	time 21.3898 (21.3898)	loss 2.4609 (2.4609)	grad_norm 0.5096 (0.5096)	mem 39782MB
[2023-07-07 16:20:35 RepVGG-A0] (main.py 282): INFO Train: [235/300][10/78]	eta 0:03:43 lr 0.710431	time 1.1735 (3.2920)	loss 2.4729 (2.4595)	grad_norm 0.5333 (0.5153)	mem 39782MB
[2023-07-07 16:20:51 RepVGG-A0] (main.py 282): INFO Train: [235/300][20/78]	eta 0:02:21 lr 0.707735	time 1.1774 (2.4464)	loss 2.4507 (2.4675)	grad_norm 0.5101 (0.5163)	mem 39782MB
[2023-07-07 16:21:06 RepVGG-A0] (main.py 282): INFO Train: [235/300][30/78]	eta 0:01:43 lr 0.705042	time 1.2189 (2.1653)	loss 2.5112 (2.4719)	grad_norm 0.4835 (0.5139)	mem 39782MB
[2023-07-07 16:21:24 RepVGG-A0] (main.py 282): INFO Train: [235/300][40/78]	eta 0:01:18 lr 0.702354	time 3.9990 (2.0754)	loss 2.4506 (2.4697)	grad_norm 0.5222 (0.5125)	mem 39782MB
[2023-07-07 16:21:39 RepVGG-A0] (main.py 282): INFO Train: [235/300][50/78]	eta 0:00:54 lr 0.699671	time 1.1743 (1.9616)	loss 2.4784 (2.4733)	grad_norm 0.5040 (0.5119)	mem 39782MB
[2023-07-07 16:21:54 RepVGG-A0] (main.py 282): INFO Train: [235/300][60/78]	eta 0:00:34 lr 0.696992	time 1.2936 (1.8890)	loss 2.5561 (2.4781)	grad_norm 0.5282 (0.5113)	mem 39782MB
[2023-07-07 16:22:10 RepVGG-A0] (main.py 282): INFO Train: [235/300][70/78]	eta 0:00:14 lr 0.694317	time 1.1753 (1.8390)	loss 2.4801 (2.4793)	grad_norm 0.5023 (0.5132)	mem 39782MB
[2023-07-07 16:22:21 RepVGG-A0] (main.py 291): INFO EPOCH 235 training takes 0:02:22
[2023-07-07 16:22:43 RepVGG-A0] (main.py 282): INFO Train: [236/300][0/78]	eta 0:28:11 lr 0.692181	time 21.6803 (21.6803)	loss 2.4939 (2.4939)	grad_norm 0.5067 (0.5067)	mem 39782MB
[2023-07-07 16:22:58 RepVGG-A0] (main.py 282): INFO Train: [236/300][10/78]	eta 0:03:44 lr 0.689515	time 1.1740 (3.3087)	loss 2.4515 (2.4766)	grad_norm 0.5149 (0.5207)	mem 39782MB
[2023-07-07 16:23:12 RepVGG-A0] (main.py 282): INFO Train: [236/300][20/78]	eta 0:02:19 lr 0.686853	time 1.1730 (2.4128)	loss 2.4583 (2.4688)	grad_norm 0.5042 (0.5174)	mem 39782MB
[2023-07-07 16:23:28 RepVGG-A0] (main.py 282): INFO Train: [236/300][30/78]	eta 0:01:42 lr 0.684196	time 1.5130 (2.1446)	loss 2.4822 (2.4750)	grad_norm 0.5256 (0.5191)	mem 39782MB
[2023-07-07 16:23:45 RepVGG-A0] (main.py 282): INFO Train: [236/300][40/78]	eta 0:01:17 lr 0.681543	time 3.1310 (2.0494)	loss 2.5409 (2.4763)	grad_norm 0.5654 (0.5184)	mem 39782MB
[2023-07-07 16:24:00 RepVGG-A0] (main.py 282): INFO Train: [236/300][50/78]	eta 0:00:54 lr 0.678895	time 1.1730 (1.9387)	loss 2.4983 (2.4802)	grad_norm 0.5100 (0.5184)	mem 39782MB
[2023-07-07 16:24:15 RepVGG-A0] (main.py 282): INFO Train: [236/300][60/78]	eta 0:00:33 lr 0.676251	time 1.1863 (1.8683)	loss 2.5194 (2.4837)	grad_norm 0.5365 (0.5205)	mem 39782MB
[2023-07-07 16:24:31 RepVGG-A0] (main.py 282): INFO Train: [236/300][70/78]	eta 0:00:14 lr 0.673612	time 1.4895 (1.8244)	loss 2.5248 (2.4851)	grad_norm 0.5180 (0.5196)	mem 39782MB
[2023-07-07 16:24:43 RepVGG-A0] (main.py 291): INFO EPOCH 236 training takes 0:02:21
[2023-07-07 16:25:04 RepVGG-A0] (main.py 282): INFO Train: [237/300][0/78]	eta 0:27:26 lr 0.671504	time 21.1036 (21.1036)	loss 2.4098 (2.4098)	grad_norm 0.5018 (0.5018)	mem 39782MB
[2023-07-07 16:25:21 RepVGG-A0] (main.py 282): INFO Train: [237/300][10/78]	eta 0:03:51 lr 0.668873	time 1.1705 (3.4009)	loss 2.3976 (2.4333)	grad_norm 0.5053 (0.5123)	mem 39782MB
[2023-07-07 16:25:35 RepVGG-A0] (main.py 282): INFO Train: [237/300][20/78]	eta 0:02:24 lr 0.666247	time 1.2080 (2.4846)	loss 2.4904 (2.4448)	grad_norm 0.4952 (0.5129)	mem 39782MB
[2023-07-07 16:25:51 RepVGG-A0] (main.py 282): INFO Train: [237/300][30/78]	eta 0:01:44 lr 0.663625	time 1.5868 (2.1800)	loss 2.5183 (2.4538)	grad_norm 0.5083 (0.5118)	mem 39782MB
[2023-07-07 16:26:09 RepVGG-A0] (main.py 282): INFO Train: [237/300][40/78]	eta 0:01:19 lr 0.661008	time 2.7686 (2.0901)	loss 2.5016 (2.4590)	grad_norm 0.5057 (0.5110)	mem 39782MB
[2023-07-07 16:26:24 RepVGG-A0] (main.py 282): INFO Train: [237/300][50/78]	eta 0:00:55 lr 0.658395	time 1.1755 (1.9749)	loss 2.5021 (2.4606)	grad_norm 0.5189 (0.5121)	mem 39782MB
[2023-07-07 16:26:39 RepVGG-A0] (main.py 282): INFO Train: [237/300][60/78]	eta 0:00:34 lr 0.655787	time 1.2918 (1.9043)	loss 2.5106 (2.4656)	grad_norm 0.5117 (0.5155)	mem 39782MB
[2023-07-07 16:26:54 RepVGG-A0] (main.py 282): INFO Train: [237/300][70/78]	eta 0:00:14 lr 0.653184	time 1.2005 (1.8422)	loss 2.4451 (2.4701)	grad_norm 0.4989 (0.5149)	mem 39782MB
[2023-07-07 16:27:07 RepVGG-A0] (main.py 291): INFO EPOCH 237 training takes 0:02:23
[2023-07-07 16:27:27 RepVGG-A0] (main.py 282): INFO Train: [238/300][0/78]	eta 0:26:55 lr 0.651104	time 20.7161 (20.7161)	loss 2.4727 (2.4727)	grad_norm 0.5201 (0.5201)	mem 39782MB
[2023-07-07 16:27:43 RepVGG-A0] (main.py 282): INFO Train: [238/300][10/78]	eta 0:03:48 lr 0.648509	time 1.1714 (3.3609)	loss 2.4287 (2.4421)	grad_norm 0.5409 (0.5316)	mem 39782MB
[2023-07-07 16:27:58 RepVGG-A0] (main.py 282): INFO Train: [238/300][20/78]	eta 0:02:21 lr 0.645919	time 1.2399 (2.4336)	loss 2.5186 (2.4502)	grad_norm 0.5059 (0.5210)	mem 39782MB
[2023-07-07 16:28:12 RepVGG-A0] (main.py 282): INFO Train: [238/300][30/78]	eta 0:01:41 lr 0.643333	time 1.1770 (2.1243)	loss 2.4948 (2.4540)	grad_norm 0.5094 (0.5194)	mem 39782MB
[2023-07-07 16:28:29 RepVGG-A0] (main.py 282): INFO Train: [238/300][40/78]	eta 0:01:16 lr 0.640751	time 1.9351 (2.0217)	loss 2.5081 (2.4588)	grad_norm 0.5411 (0.5217)	mem 39782MB
[2023-07-07 16:28:46 RepVGG-A0] (main.py 282): INFO Train: [238/300][50/78]	eta 0:00:54 lr 0.638174	time 1.1825 (1.9447)	loss 2.5237 (2.4644)	grad_norm 0.5207 (0.5190)	mem 39782MB
[2023-07-07 16:29:01 RepVGG-A0] (main.py 282): INFO Train: [238/300][60/78]	eta 0:00:33 lr 0.635602	time 1.1736 (1.8772)	loss 2.5219 (2.4672)	grad_norm 0.5533 (0.5213)	mem 39782MB
[2023-07-07 16:29:17 RepVGG-A0] (main.py 282): INFO Train: [238/300][70/78]	eta 0:00:14 lr 0.633035	time 1.2556 (1.8417)	loss 2.4633 (2.4714)	grad_norm 0.5158 (0.5216)	mem 39782MB
[2023-07-07 16:29:31 RepVGG-A0] (main.py 291): INFO EPOCH 238 training takes 0:02:24
[2023-07-07 16:29:50 RepVGG-A0] (main.py 282): INFO Train: [239/300][0/78]	eta 0:25:37 lr 0.630984	time 19.7167 (19.7167)	loss 2.5144 (2.5144)	grad_norm 0.5044 (0.5044)	mem 39782MB
[2023-07-07 16:30:08 RepVGG-A0] (main.py 282): INFO Train: [239/300][10/78]	eta 0:03:49 lr 0.628425	time 1.1720 (3.3815)	loss 2.4030 (2.4261)	grad_norm 0.5167 (0.5076)	mem 39782MB
[2023-07-07 16:30:22 RepVGG-A0] (main.py 282): INFO Train: [239/300][20/78]	eta 0:02:22 lr 0.625870	time 1.1723 (2.4560)	loss 2.4348 (2.4369)	grad_norm 0.5082 (0.5065)	mem 39782MB
[2023-07-07 16:30:37 RepVGG-A0] (main.py 282): INFO Train: [239/300][30/78]	eta 0:01:43 lr 0.623320	time 1.4729 (2.1502)	loss 2.4709 (2.4420)	grad_norm 0.5131 (0.5116)	mem 39782MB
[2023-07-07 16:30:53 RepVGG-A0] (main.py 282): INFO Train: [239/300][40/78]	eta 0:01:16 lr 0.620775	time 2.4592 (2.0025)	loss 2.4154 (2.4399)	grad_norm 0.5239 (0.5122)	mem 39782MB
[2023-07-07 16:31:09 RepVGG-A0] (main.py 282): INFO Train: [239/300][50/78]	eta 0:00:53 lr 0.618235	time 1.1950 (1.9266)	loss 2.4860 (2.4453)	grad_norm 0.5131 (0.5181)	mem 39782MB
[2023-07-07 16:31:24 RepVGG-A0] (main.py 282): INFO Train: [239/300][60/78]	eta 0:00:33 lr 0.615699	time 1.1747 (1.8616)	loss 2.4857 (2.4506)	grad_norm 0.5130 (0.5182)	mem 39782MB
[2023-07-07 16:31:39 RepVGG-A0] (main.py 282): INFO Train: [239/300][70/78]	eta 0:00:14 lr 0.613167	time 1.2011 (1.8130)	loss 2.5097 (2.4556)	grad_norm 0.5155 (0.5188)	mem 39782MB
[2023-07-07 16:31:52 RepVGG-A0] (main.py 291): INFO EPOCH 239 training takes 0:02:21
[2023-07-07 16:32:13 RepVGG-A0] (main.py 282): INFO Train: [240/300][0/78]	eta 0:27:42 lr 0.611146	time 21.3123 (21.3123)	loss 2.4300 (2.4300)	grad_norm 0.5347 (0.5347)	mem 39782MB
[2023-07-07 16:32:27 RepVGG-A0] (main.py 282): INFO Train: [240/300][10/78]	eta 0:03:39 lr 0.608623	time 1.1911 (3.2291)	loss 2.4421 (2.4360)	grad_norm 0.5065 (0.5107)	mem 39782MB
[2023-07-07 16:32:42 RepVGG-A0] (main.py 282): INFO Train: [240/300][20/78]	eta 0:02:17 lr 0.606104	time 1.1930 (2.3682)	loss 2.4506 (2.4360)	grad_norm 0.5195 (0.5150)	mem 39782MB
[2023-07-07 16:32:57 RepVGG-A0] (main.py 282): INFO Train: [240/300][30/78]	eta 0:01:40 lr 0.603591	time 1.1743 (2.0862)	loss 2.4652 (2.4439)	grad_norm 0.5357 (0.5225)	mem 39782MB
[2023-07-07 16:33:15 RepVGG-A0] (main.py 282): INFO Train: [240/300][40/78]	eta 0:01:16 lr 0.601082	time 3.5579 (2.0199)	loss 2.4111 (2.4373)	grad_norm 0.5102 (0.5195)	mem 39782MB
[2023-07-07 16:33:30 RepVGG-A0] (main.py 282): INFO Train: [240/300][50/78]	eta 0:00:53 lr 0.598578	time 1.1719 (1.9231)	loss 2.4749 (2.4426)	grad_norm 0.5417 (0.5226)	mem 39782MB
[2023-07-07 16:33:45 RepVGG-A0] (main.py 282): INFO Train: [240/300][60/78]	eta 0:00:33 lr 0.596078	time 1.2590 (1.8557)	loss 2.4258 (2.4453)	grad_norm 0.5251 (0.5232)	mem 39782MB
[2023-07-07 16:34:01 RepVGG-A0] (main.py 282): INFO Train: [240/300][70/78]	eta 0:00:14 lr 0.593584	time 1.1843 (1.8120)	loss 2.4731 (2.4472)	grad_norm 0.5203 (0.5220)	mem 39782MB
[2023-07-07 16:34:12 RepVGG-A0] (main.py 291): INFO EPOCH 240 training takes 0:02:20
[2023-07-07 16:34:29 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.485 (17.485)	Loss 1.6567 (1.6567)	Acc@1 63.867 (63.867)	Acc@5 85.229 (85.229)	Mem 39782MB
[2023-07-07 16:34:31 RepVGG-A0] (main.py 342): INFO  * Acc@1 63.708 Acc@5 85.256
[2023-07-07 16:34:31 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 240: 63.708%
[2023-07-07 16:34:31 RepVGG-A0] (main.py 172): INFO Max accuracy: 63.71%
[2023-07-07 16:34:53 RepVGG-A0] (main.py 282): INFO Train: [241/300][0/78]	eta 0:28:59 lr 0.591591	time 22.3028 (22.3028)	loss 2.3991 (2.3991)	grad_norm 0.5200 (0.5200)	mem 39782MB
[2023-07-07 16:35:09 RepVGG-A0] (main.py 282): INFO Train: [241/300][10/78]	eta 0:03:55 lr 0.589105	time 1.1932 (3.4607)	loss 2.4675 (2.4214)	grad_norm 0.5386 (0.5268)	mem 39782MB
[2023-07-07 16:35:23 RepVGG-A0] (main.py 282): INFO Train: [241/300][20/78]	eta 0:02:24 lr 0.586623	time 1.2899 (2.4832)	loss 2.3876 (2.4326)	grad_norm 0.5181 (0.5230)	mem 39782MB
[2023-07-07 16:35:38 RepVGG-A0] (main.py 282): INFO Train: [241/300][30/78]	eta 0:01:44 lr 0.584146	time 1.7311 (2.1802)	loss 2.4445 (2.4380)	grad_norm 0.5373 (0.5264)	mem 39782MB
[2023-07-07 16:35:56 RepVGG-A0] (main.py 282): INFO Train: [241/300][40/78]	eta 0:01:18 lr 0.581674	time 3.0719 (2.0766)	loss 2.4639 (2.4387)	grad_norm 0.5300 (0.5295)	mem 39782MB
[2023-07-07 16:36:11 RepVGG-A0] (main.py 282): INFO Train: [241/300][50/78]	eta 0:00:54 lr 0.579206	time 1.1803 (1.9630)	loss 2.4554 (2.4399)	grad_norm 0.5122 (0.5267)	mem 39782MB
[2023-07-07 16:36:26 RepVGG-A0] (main.py 282): INFO Train: [241/300][60/78]	eta 0:00:34 lr 0.576744	time 1.3063 (1.8923)	loss 2.4613 (2.4443)	grad_norm 0.5366 (0.5284)	mem 39782MB
[2023-07-07 16:36:41 RepVGG-A0] (main.py 282): INFO Train: [241/300][70/78]	eta 0:00:14 lr 0.574286	time 1.2562 (1.8383)	loss 2.4555 (2.4476)	grad_norm 0.5246 (0.5284)	mem 39782MB
[2023-07-07 16:36:53 RepVGG-A0] (main.py 291): INFO EPOCH 241 training takes 0:02:22
[2023-07-07 16:37:15 RepVGG-A0] (main.py 282): INFO Train: [242/300][0/78]	eta 0:29:03 lr 0.572323	time 22.3510 (22.3510)	loss 2.4111 (2.4111)	grad_norm 0.4983 (0.4983)	mem 39782MB
[2023-07-07 16:37:30 RepVGG-A0] (main.py 282): INFO Train: [242/300][10/78]	eta 0:03:48 lr 0.569873	time 1.1714 (3.3665)	loss 2.4073 (2.4218)	grad_norm 0.5256 (0.5114)	mem 39782MB
[2023-07-07 16:37:45 RepVGG-A0] (main.py 282): INFO Train: [242/300][20/78]	eta 0:02:24 lr 0.567428	time 1.1818 (2.4989)	loss 2.4587 (2.4225)	grad_norm 0.5348 (0.5161)	mem 39782MB
[2023-07-07 16:38:00 RepVGG-A0] (main.py 282): INFO Train: [242/300][30/78]	eta 0:01:43 lr 0.564988	time 1.1863 (2.1593)	loss 2.4717 (2.4222)	grad_norm 0.5473 (0.5234)	mem 39782MB
[2023-07-07 16:38:17 RepVGG-A0] (main.py 282): INFO Train: [242/300][40/78]	eta 0:01:18 lr 0.562553	time 2.9800 (2.0632)	loss 2.4829 (2.4285)	grad_norm 0.5147 (0.5238)	mem 39782MB
[2023-07-07 16:38:33 RepVGG-A0] (main.py 282): INFO Train: [242/300][50/78]	eta 0:00:54 lr 0.560122	time 1.1261 (1.9549)	loss 2.4341 (2.4336)	grad_norm 0.5428 (0.5256)	mem 39782MB
[2023-07-07 16:38:47 RepVGG-A0] (main.py 282): INFO Train: [242/300][60/78]	eta 0:00:33 lr 0.557697	time 1.1722 (1.8782)	loss 2.4697 (2.4360)	grad_norm 0.5336 (0.5258)	mem 39782MB
[2023-07-07 16:39:03 RepVGG-A0] (main.py 282): INFO Train: [242/300][70/78]	eta 0:00:14 lr 0.555276	time 1.3419 (1.8270)	loss 2.4894 (2.4381)	grad_norm 0.5259 (0.5274)	mem 39782MB
[2023-07-07 16:39:15 RepVGG-A0] (main.py 291): INFO EPOCH 242 training takes 0:02:21
[2023-07-07 16:39:37 RepVGG-A0] (main.py 282): INFO Train: [243/300][0/78]	eta 0:28:57 lr 0.553342	time 22.2704 (22.2704)	loss 2.3625 (2.3625)	grad_norm 0.5264 (0.5264)	mem 39782MB
[2023-07-07 16:39:51 RepVGG-A0] (main.py 282): INFO Train: [243/300][10/78]	eta 0:03:45 lr 0.550930	time 1.1728 (3.3212)	loss 2.4440 (2.4023)	grad_norm 0.5474 (0.5210)	mem 39782MB
[2023-07-07 16:40:06 RepVGG-A0] (main.py 282): INFO Train: [243/300][20/78]	eta 0:02:21 lr 0.548522	time 1.1726 (2.4445)	loss 2.3988 (2.4118)	grad_norm 0.5586 (0.5246)	mem 39782MB
[2023-07-07 16:40:21 RepVGG-A0] (main.py 282): INFO Train: [243/300][30/78]	eta 0:01:42 lr 0.546119	time 1.3512 (2.1450)	loss 2.3972 (2.4148)	grad_norm 0.5263 (0.5280)	mem 39782MB
[2023-07-07 16:40:39 RepVGG-A0] (main.py 282): INFO Train: [243/300][40/78]	eta 0:01:18 lr 0.543721	time 4.4361 (2.0692)	loss 2.4385 (2.4178)	grad_norm 0.5355 (0.5277)	mem 39782MB
[2023-07-07 16:40:54 RepVGG-A0] (main.py 282): INFO Train: [243/300][50/78]	eta 0:00:54 lr 0.541328	time 1.1928 (1.9483)	loss 2.4245 (2.4199)	grad_norm 0.5468 (0.5269)	mem 39782MB
[2023-07-07 16:41:09 RepVGG-A0] (main.py 282): INFO Train: [243/300][60/78]	eta 0:00:33 lr 0.538939	time 1.1922 (1.8796)	loss 2.4258 (2.4216)	grad_norm 0.5250 (0.5287)	mem 39782MB
[2023-07-07 16:41:25 RepVGG-A0] (main.py 282): INFO Train: [243/300][70/78]	eta 0:00:14 lr 0.536556	time 1.2558 (1.8328)	loss 2.4525 (2.4260)	grad_norm 0.5215 (0.5294)	mem 39782MB
[2023-07-07 16:41:36 RepVGG-A0] (main.py 291): INFO EPOCH 243 training takes 0:02:21
[2023-07-07 16:41:58 RepVGG-A0] (main.py 282): INFO Train: [244/300][0/78]	eta 0:28:03 lr 0.534652	time 21.5876 (21.5876)	loss 2.4279 (2.4279)	grad_norm 0.5363 (0.5363)	mem 39782MB
[2023-07-07 16:42:12 RepVGG-A0] (main.py 282): INFO Train: [244/300][10/78]	eta 0:03:41 lr 0.532277	time 1.1730 (3.2614)	loss 2.4443 (2.4113)	grad_norm 0.5216 (0.5318)	mem 39782MB
[2023-07-07 16:42:27 RepVGG-A0] (main.py 282): INFO Train: [244/300][20/78]	eta 0:02:20 lr 0.529907	time 1.3115 (2.4146)	loss 2.3885 (2.4172)	grad_norm 0.5616 (0.5337)	mem 39782MB
[2023-07-07 16:42:43 RepVGG-A0] (main.py 282): INFO Train: [244/300][30/78]	eta 0:01:42 lr 0.527541	time 1.3501 (2.1442)	loss 2.4344 (2.4151)	grad_norm 0.5230 (0.5312)	mem 39782MB
[2023-07-07 16:43:01 RepVGG-A0] (main.py 282): INFO Train: [244/300][40/78]	eta 0:01:18 lr 0.525181	time 3.3162 (2.0571)	loss 2.4714 (2.4211)	grad_norm 0.5274 (0.5338)	mem 39782MB
[2023-07-07 16:43:17 RepVGG-A0] (main.py 282): INFO Train: [244/300][50/78]	eta 0:00:55 lr 0.522825	time 1.7227 (1.9743)	loss 2.4107 (2.4227)	grad_norm 0.5291 (0.5338)	mem 39782MB
[2023-07-07 16:43:32 RepVGG-A0] (main.py 282): INFO Train: [244/300][60/78]	eta 0:00:34 lr 0.520474	time 1.4265 (1.9002)	loss 2.4053 (2.4230)	grad_norm 0.5210 (0.5318)	mem 39782MB
[2023-07-07 16:43:47 RepVGG-A0] (main.py 282): INFO Train: [244/300][70/78]	eta 0:00:14 lr 0.518128	time 1.2084 (1.8429)	loss 2.4382 (2.4268)	grad_norm 0.5280 (0.5313)	mem 39782MB
[2023-07-07 16:43:58 RepVGG-A0] (main.py 291): INFO EPOCH 244 training takes 0:02:22
[2023-07-07 16:44:20 RepVGG-A0] (main.py 282): INFO Train: [245/300][0/78]	eta 0:27:49 lr 0.516254	time 21.4017 (21.4017)	loss 2.4421 (2.4421)	grad_norm 0.5272 (0.5272)	mem 39782MB
[2023-07-07 16:44:35 RepVGG-A0] (main.py 282): INFO Train: [245/300][10/78]	eta 0:03:46 lr 0.513917	time 1.1718 (3.3367)	loss 2.4456 (2.3837)	grad_norm 0.5456 (0.5333)	mem 39782MB
[2023-07-07 16:44:49 RepVGG-A0] (main.py 282): INFO Train: [245/300][20/78]	eta 0:02:20 lr 0.511584	time 1.1741 (2.4238)	loss 2.4780 (2.4058)	grad_norm 0.5279 (0.5315)	mem 39782MB
[2023-07-07 16:45:05 RepVGG-A0] (main.py 282): INFO Train: [245/300][30/78]	eta 0:01:43 lr 0.509256	time 1.2483 (2.1476)	loss 2.4096 (2.4132)	grad_norm 0.5196 (0.5296)	mem 39782MB
[2023-07-07 16:45:24 RepVGG-A0] (main.py 282): INFO Train: [245/300][40/78]	eta 0:01:19 lr 0.506933	time 4.9933 (2.0877)	loss 2.4292 (2.4169)	grad_norm 0.5629 (0.5344)	mem 39782MB
[2023-07-07 16:45:38 RepVGG-A0] (main.py 282): INFO Train: [245/300][50/78]	eta 0:00:54 lr 0.504615	time 1.1832 (1.9569)	loss 2.4156 (2.4192)	grad_norm 0.5365 (0.5367)	mem 39782MB
[2023-07-07 16:45:54 RepVGG-A0] (main.py 282): INFO Train: [245/300][60/78]	eta 0:00:34 lr 0.502302	time 1.3723 (1.8905)	loss 2.4195 (2.4175)	grad_norm 0.5408 (0.5354)	mem 39782MB
[2023-07-07 16:46:09 RepVGG-A0] (main.py 282): INFO Train: [245/300][70/78]	eta 0:00:14 lr 0.499994	time 1.4146 (1.8434)	loss 2.4393 (2.4212)	grad_norm 0.5221 (0.5342)	mem 39782MB
[2023-07-07 16:46:20 RepVGG-A0] (main.py 291): INFO EPOCH 245 training takes 0:02:21
[2023-07-07 16:46:40 RepVGG-A0] (main.py 282): INFO Train: [246/300][0/78]	eta 0:27:03 lr 0.498151	time 20.8192 (20.8192)	loss 2.4084 (2.4084)	grad_norm 0.5154 (0.5154)	mem 39782MB
[2023-07-07 16:46:56 RepVGG-A0] (main.py 282): INFO Train: [246/300][10/78]	eta 0:03:42 lr 0.495851	time 1.1741 (3.2678)	loss 2.4017 (2.4027)	grad_norm 0.5220 (0.5350)	mem 39782MB
[2023-07-07 16:47:10 RepVGG-A0] (main.py 282): INFO Train: [246/300][20/78]	eta 0:02:19 lr 0.493556	time 1.1737 (2.4049)	loss 2.4431 (2.4105)	grad_norm 0.5343 (0.5351)	mem 39782MB
[2023-07-07 16:47:25 RepVGG-A0] (main.py 282): INFO Train: [246/300][30/78]	eta 0:01:41 lr 0.491267	time 1.5486 (2.1120)	loss 2.4662 (2.4109)	grad_norm 0.5511 (0.5362)	mem 39782MB
[2023-07-07 16:47:44 RepVGG-A0] (main.py 282): INFO Train: [246/300][40/78]	eta 0:01:17 lr 0.488982	time 4.3059 (2.0503)	loss 2.3732 (2.4154)	grad_norm 0.5395 (0.5391)	mem 39782MB
[2023-07-07 16:47:59 RepVGG-A0] (main.py 282): INFO Train: [246/300][50/78]	eta 0:00:54 lr 0.486702	time 1.2813 (1.9471)	loss 2.4227 (2.4178)	grad_norm 0.5357 (0.5385)	mem 39782MB
[2023-07-07 16:48:14 RepVGG-A0] (main.py 282): INFO Train: [246/300][60/78]	eta 0:00:33 lr 0.484426	time 1.2992 (1.8740)	loss 2.4073 (2.4177)	grad_norm 0.5322 (0.5378)	mem 39782MB
[2023-07-07 16:48:30 RepVGG-A0] (main.py 282): INFO Train: [246/300][70/78]	eta 0:00:14 lr 0.482156	time 1.2745 (1.8330)	loss 2.4450 (2.4212)	grad_norm 0.5437 (0.5383)	mem 39782MB
[2023-07-07 16:48:42 RepVGG-A0] (main.py 291): INFO EPOCH 246 training takes 0:02:22
[2023-07-07 16:49:04 RepVGG-A0] (main.py 282): INFO Train: [247/300][0/78]	eta 0:28:01 lr 0.480343	time 21.5633 (21.5633)	loss 2.4026 (2.4026)	grad_norm 0.5318 (0.5318)	mem 39782MB
[2023-07-07 16:49:19 RepVGG-A0] (main.py 282): INFO Train: [247/300][10/78]	eta 0:03:46 lr 0.478082	time 1.1736 (3.3250)	loss 2.3178 (2.3869)	grad_norm 0.5305 (0.5308)	mem 39782MB
[2023-07-07 16:49:33 RepVGG-A0] (main.py 282): INFO Train: [247/300][20/78]	eta 0:02:20 lr 0.475825	time 1.1275 (2.4285)	loss 2.4506 (2.3981)	grad_norm 0.5342 (0.5354)	mem 39782MB
[2023-07-07 16:49:49 RepVGG-A0] (main.py 282): INFO Train: [247/300][30/78]	eta 0:01:42 lr 0.473574	time 1.4976 (2.1452)	loss 2.4100 (2.4006)	grad_norm 0.5426 (0.5353)	mem 39782MB
[2023-07-07 16:50:06 RepVGG-A0] (main.py 282): INFO Train: [247/300][40/78]	eta 0:01:17 lr 0.471327	time 3.2123 (2.0435)	loss 2.4649 (2.4037)	grad_norm 0.5285 (0.5371)	mem 39782MB
[2023-07-07 16:50:21 RepVGG-A0] (main.py 282): INFO Train: [247/300][50/78]	eta 0:00:54 lr 0.469085	time 1.1283 (1.9359)	loss 2.3756 (2.4035)	grad_norm 0.5415 (0.5373)	mem 39782MB
[2023-07-07 16:50:36 RepVGG-A0] (main.py 282): INFO Train: [247/300][60/78]	eta 0:00:33 lr 0.466848	time 1.2427 (1.8740)	loss 2.4501 (2.4042)	grad_norm 0.5326 (0.5376)	mem 39782MB
[2023-07-07 16:50:52 RepVGG-A0] (main.py 282): INFO Train: [247/300][70/78]	eta 0:00:14 lr 0.464616	time 1.2172 (1.8230)	loss 2.4068 (2.4077)	grad_norm 0.5408 (0.5387)	mem 39782MB
[2023-07-07 16:51:03 RepVGG-A0] (main.py 291): INFO EPOCH 247 training takes 0:02:21
[2023-07-07 16:51:25 RepVGG-A0] (main.py 282): INFO Train: [248/300][0/78]	eta 0:28:19 lr 0.462834	time 21.7935 (21.7935)	loss 2.3658 (2.3658)	grad_norm 0.5286 (0.5286)	mem 39782MB
[2023-07-07 16:51:40 RepVGG-A0] (main.py 282): INFO Train: [248/300][10/78]	eta 0:03:48 lr 0.460611	time 1.1717 (3.3659)	loss 2.3524 (2.3758)	grad_norm 0.5408 (0.5415)	mem 39782MB
[2023-07-07 16:51:56 RepVGG-A0] (main.py 282): INFO Train: [248/300][20/78]	eta 0:02:24 lr 0.458393	time 1.4041 (2.4829)	loss 2.4158 (2.3832)	grad_norm 0.5374 (0.5391)	mem 39782MB
[2023-07-07 16:52:10 RepVGG-A0] (main.py 282): INFO Train: [248/300][30/78]	eta 0:01:43 lr 0.456180	time 1.3318 (2.1531)	loss 2.3566 (2.3808)	grad_norm 0.5345 (0.5420)	mem 39782MB
[2023-07-07 16:52:28 RepVGG-A0] (main.py 282): INFO Train: [248/300][40/78]	eta 0:01:18 lr 0.453972	time 3.6980 (2.0686)	loss 2.4556 (2.3822)	grad_norm 0.5308 (0.5417)	mem 39782MB
[2023-07-07 16:52:44 RepVGG-A0] (main.py 282): INFO Train: [248/300][50/78]	eta 0:00:54 lr 0.451768	time 1.1723 (1.9621)	loss 2.4086 (2.3875)	grad_norm 0.5242 (0.5407)	mem 39782MB
[2023-07-07 16:52:59 RepVGG-A0] (main.py 282): INFO Train: [248/300][60/78]	eta 0:00:34 lr 0.449570	time 1.2926 (1.8956)	loss 2.4667 (2.3943)	grad_norm 0.5247 (0.5394)	mem 39782MB
[2023-07-07 16:53:14 RepVGG-A0] (main.py 282): INFO Train: [248/300][70/78]	eta 0:00:14 lr 0.447377	time 1.3865 (1.8362)	loss 2.4404 (2.3937)	grad_norm 0.5516 (0.5400)	mem 39782MB
[2023-07-07 16:53:25 RepVGG-A0] (main.py 291): INFO EPOCH 248 training takes 0:02:21
[2023-07-07 16:53:47 RepVGG-A0] (main.py 282): INFO Train: [249/300][0/78]	eta 0:28:25 lr 0.445626	time 21.8690 (21.8690)	loss 2.3641 (2.3641)	grad_norm 0.5415 (0.5415)	mem 39782MB
[2023-07-07 16:54:03 RepVGG-A0] (main.py 282): INFO Train: [249/300][10/78]	eta 0:03:53 lr 0.443441	time 1.1707 (3.4368)	loss 2.4164 (2.3955)	grad_norm 0.5613 (0.5463)	mem 39782MB
[2023-07-07 16:54:19 RepVGG-A0] (main.py 282): INFO Train: [249/300][20/78]	eta 0:02:26 lr 0.441262	time 1.1886 (2.5342)	loss 2.3321 (2.3895)	grad_norm 0.5299 (0.5436)	mem 39782MB
[2023-07-07 16:54:33 RepVGG-A0] (main.py 282): INFO Train: [249/300][30/78]	eta 0:01:44 lr 0.439087	time 1.2432 (2.1769)	loss 2.3749 (2.3820)	grad_norm 0.5466 (0.5423)	mem 39782MB
[2023-07-07 16:54:52 RepVGG-A0] (main.py 282): INFO Train: [249/300][40/78]	eta 0:01:20 lr 0.436918	time 3.0090 (2.1120)	loss 2.4507 (2.3873)	grad_norm 0.5560 (0.5440)	mem 39782MB
[2023-07-07 16:55:07 RepVGG-A0] (main.py 282): INFO Train: [249/300][50/78]	eta 0:00:55 lr 0.434753	time 1.2526 (1.9935)	loss 2.3750 (2.3908)	grad_norm 0.5436 (0.5435)	mem 39782MB
[2023-07-07 16:55:23 RepVGG-A0] (main.py 282): INFO Train: [249/300][60/78]	eta 0:00:34 lr 0.432593	time 1.2957 (1.9239)	loss 2.3803 (2.3912)	grad_norm 0.5453 (0.5442)	mem 39782MB
[2023-07-07 16:55:37 RepVGG-A0] (main.py 282): INFO Train: [249/300][70/78]	eta 0:00:14 lr 0.430439	time 1.4856 (1.8620)	loss 2.4147 (2.3959)	grad_norm 0.5415 (0.5455)	mem 39782MB
[2023-07-07 16:55:49 RepVGG-A0] (main.py 291): INFO EPOCH 249 training takes 0:02:23
[2023-07-07 16:56:12 RepVGG-A0] (main.py 282): INFO Train: [250/300][0/78]	eta 0:29:04 lr 0.428719	time 22.3625 (22.3625)	loss 2.3721 (2.3721)	grad_norm 0.5473 (0.5473)	mem 39782MB
[2023-07-07 16:56:25 RepVGG-A0] (main.py 282): INFO Train: [250/300][10/78]	eta 0:03:43 lr 0.426573	time 1.1722 (3.2817)	loss 2.3609 (2.3830)	grad_norm 0.5381 (0.5453)	mem 39782MB
[2023-07-07 16:56:41 RepVGG-A0] (main.py 282): INFO Train: [250/300][20/78]	eta 0:02:24 lr 0.424433	time 1.3253 (2.4876)	loss 2.3909 (2.3846)	grad_norm 0.5433 (0.5451)	mem 39782MB
[2023-07-07 16:56:56 RepVGG-A0] (main.py 282): INFO Train: [250/300][30/78]	eta 0:01:43 lr 0.422297	time 1.8163 (2.1559)	loss 2.3840 (2.3864)	grad_norm 0.5434 (0.5436)	mem 39782MB
[2023-07-07 16:57:13 RepVGG-A0] (main.py 282): INFO Train: [250/300][40/78]	eta 0:01:18 lr 0.420166	time 3.8390 (2.0550)	loss 2.3963 (2.3838)	grad_norm 0.5405 (0.5441)	mem 39782MB
[2023-07-07 16:57:28 RepVGG-A0] (main.py 282): INFO Train: [250/300][50/78]	eta 0:00:54 lr 0.418041	time 1.2923 (1.9432)	loss 2.3932 (2.3897)	grad_norm 0.5372 (0.5442)	mem 39782MB
[2023-07-07 16:57:44 RepVGG-A0] (main.py 282): INFO Train: [250/300][60/78]	eta 0:00:33 lr 0.415920	time 1.1742 (1.8743)	loss 2.4254 (2.3904)	grad_norm 0.5433 (0.5445)	mem 39782MB
[2023-07-07 16:57:59 RepVGG-A0] (main.py 282): INFO Train: [250/300][70/78]	eta 0:00:14 lr 0.413805	time 1.7486 (1.8267)	loss 2.4274 (2.3921)	grad_norm 0.5415 (0.5441)	mem 39782MB
[2023-07-07 16:58:10 RepVGG-A0] (main.py 291): INFO EPOCH 250 training takes 0:02:21
[2023-07-07 16:58:33 RepVGG-A0] (main.py 282): INFO Train: [251/300][0/78]	eta 0:29:26 lr 0.412116	time 22.6533 (22.6533)	loss 2.3760 (2.3760)	grad_norm 0.5354 (0.5354)	mem 39782MB
[2023-07-07 16:58:47 RepVGG-A0] (main.py 282): INFO Train: [251/300][10/78]	eta 0:03:47 lr 0.410009	time 1.1723 (3.3475)	loss 2.3910 (2.3669)	grad_norm 0.5519 (0.5437)	mem 39782MB
[2023-07-07 16:59:03 RepVGG-A0] (main.py 282): INFO Train: [251/300][20/78]	eta 0:02:25 lr 0.407908	time 1.1957 (2.5079)	loss 2.3844 (2.3613)	grad_norm 0.5602 (0.5462)	mem 39782MB
[2023-07-07 16:59:17 RepVGG-A0] (main.py 282): INFO Train: [251/300][30/78]	eta 0:01:44 lr 0.405811	time 1.3669 (2.1705)	loss 2.3653 (2.3673)	grad_norm 0.5405 (0.5464)	mem 39782MB
[2023-07-07 16:59:35 RepVGG-A0] (main.py 282): INFO Train: [251/300][40/78]	eta 0:01:18 lr 0.403720	time 3.7377 (2.0592)	loss 2.4165 (2.3727)	grad_norm 0.5541 (0.5469)	mem 39782MB
[2023-07-07 16:59:50 RepVGG-A0] (main.py 282): INFO Train: [251/300][50/78]	eta 0:00:54 lr 0.401634	time 1.2720 (1.9583)	loss 2.4010 (2.3731)	grad_norm 0.5494 (0.5473)	mem 39782MB
[2023-07-07 17:00:06 RepVGG-A0] (main.py 282): INFO Train: [251/300][60/78]	eta 0:00:34 lr 0.399552	time 1.4455 (1.8949)	loss 2.3578 (2.3742)	grad_norm 0.5450 (0.5477)	mem 39782MB
[2023-07-07 17:00:21 RepVGG-A0] (main.py 282): INFO Train: [251/300][70/78]	eta 0:00:14 lr 0.397476	time 1.4789 (1.8361)	loss 2.3231 (2.3741)	grad_norm 0.5406 (0.5481)	mem 39782MB
[2023-07-07 17:00:32 RepVGG-A0] (main.py 291): INFO EPOCH 251 training takes 0:02:21
[2023-07-07 17:00:54 RepVGG-A0] (main.py 282): INFO Train: [252/300][0/78]	eta 0:28:33 lr 0.395819	time 21.9623 (21.9623)	loss 2.3456 (2.3456)	grad_norm 0.5385 (0.5385)	mem 39782MB
[2023-07-07 17:01:10 RepVGG-A0] (main.py 282): INFO Train: [252/300][10/78]	eta 0:03:55 lr 0.393751	time 1.1738 (3.4588)	loss 2.4136 (2.3792)	grad_norm 0.5492 (0.5555)	mem 39782MB
[2023-07-07 17:01:26 RepVGG-A0] (main.py 282): INFO Train: [252/300][20/78]	eta 0:02:27 lr 0.391689	time 1.3140 (2.5471)	loss 2.3688 (2.3707)	grad_norm 0.5463 (0.5476)	mem 39782MB
[2023-07-07 17:01:41 RepVGG-A0] (main.py 282): INFO Train: [252/300][30/78]	eta 0:01:46 lr 0.389632	time 1.1274 (2.2221)	loss 2.4164 (2.3675)	grad_norm 0.5640 (0.5487)	mem 39782MB
[2023-07-07 17:01:58 RepVGG-A0] (main.py 282): INFO Train: [252/300][40/78]	eta 0:01:19 lr 0.387580	time 2.8270 (2.1008)	loss 2.4040 (2.3678)	grad_norm 0.5449 (0.5482)	mem 39782MB
[2023-07-07 17:02:14 RepVGG-A0] (main.py 282): INFO Train: [252/300][50/78]	eta 0:00:55 lr 0.385533	time 1.1923 (1.9908)	loss 2.3848 (2.3676)	grad_norm 0.5438 (0.5501)	mem 39782MB
[2023-07-07 17:02:29 RepVGG-A0] (main.py 282): INFO Train: [252/300][60/78]	eta 0:00:34 lr 0.383491	time 1.4803 (1.9165)	loss 2.3967 (2.3709)	grad_norm 0.5508 (0.5500)	mem 39782MB
[2023-07-07 17:02:44 RepVGG-A0] (main.py 282): INFO Train: [252/300][70/78]	eta 0:00:14 lr 0.381455	time 1.3767 (1.8609)	loss 2.3835 (2.3727)	grad_norm 0.5554 (0.5510)	mem 39782MB
[2023-07-07 17:02:56 RepVGG-A0] (main.py 291): INFO EPOCH 252 training takes 0:02:23
[2023-07-07 17:03:18 RepVGG-A0] (main.py 282): INFO Train: [253/300][0/78]	eta 0:28:49 lr 0.379829	time 22.1722 (22.1722)	loss 2.3010 (2.3010)	grad_norm 0.5560 (0.5560)	mem 39782MB
[2023-07-07 17:03:33 RepVGG-A0] (main.py 282): INFO Train: [253/300][10/78]	eta 0:03:51 lr 0.377801	time 1.1914 (3.4013)	loss 2.2713 (2.3211)	grad_norm 0.5352 (0.5418)	mem 39782MB
[2023-07-07 17:03:48 RepVGG-A0] (main.py 282): INFO Train: [253/300][20/78]	eta 0:02:23 lr 0.375779	time 1.1755 (2.4777)	loss 2.3195 (2.3275)	grad_norm 0.5387 (0.5432)	mem 39782MB
[2023-07-07 17:04:04 RepVGG-A0] (main.py 282): INFO Train: [253/300][30/78]	eta 0:01:45 lr 0.373761	time 1.8229 (2.1988)	loss 2.3221 (2.3389)	grad_norm 0.5472 (0.5463)	mem 39782MB
[2023-07-07 17:04:22 RepVGG-A0] (main.py 282): INFO Train: [253/300][40/78]	eta 0:01:20 lr 0.371749	time 3.0396 (2.1060)	loss 2.3006 (2.3465)	grad_norm 0.5497 (0.5491)	mem 39782MB
[2023-07-07 17:04:36 RepVGG-A0] (main.py 282): INFO Train: [253/300][50/78]	eta 0:00:55 lr 0.369742	time 1.1725 (1.9713)	loss 2.3943 (2.3545)	grad_norm 0.5633 (0.5515)	mem 39782MB
[2023-07-07 17:04:53 RepVGG-A0] (main.py 282): INFO Train: [253/300][60/78]	eta 0:00:34 lr 0.367740	time 1.6160 (1.9135)	loss 2.3862 (2.3565)	grad_norm 0.5622 (0.5516)	mem 39782MB
[2023-07-07 17:05:07 RepVGG-A0] (main.py 282): INFO Train: [253/300][70/78]	eta 0:00:14 lr 0.365743	time 1.5757 (1.8501)	loss 2.4036 (2.3589)	grad_norm 0.5523 (0.5535)	mem 39782MB
[2023-07-07 17:05:19 RepVGG-A0] (main.py 291): INFO EPOCH 253 training takes 0:02:23
[2023-07-07 17:05:40 RepVGG-A0] (main.py 282): INFO Train: [254/300][0/78]	eta 0:27:31 lr 0.364149	time 21.1686 (21.1686)	loss 2.3383 (2.3383)	grad_norm 0.5703 (0.5703)	mem 39782MB
[2023-07-07 17:05:55 RepVGG-A0] (main.py 282): INFO Train: [254/300][10/78]	eta 0:03:46 lr 0.362161	time 1.1730 (3.3304)	loss 2.3361 (2.3413)	grad_norm 0.5651 (0.5628)	mem 39782MB
[2023-07-07 17:06:11 RepVGG-A0] (main.py 282): INFO Train: [254/300][20/78]	eta 0:02:22 lr 0.360178	time 1.3005 (2.4630)	loss 2.3867 (2.3468)	grad_norm 0.5542 (0.5571)	mem 39782MB
[2023-07-07 17:06:26 RepVGG-A0] (main.py 282): INFO Train: [254/300][30/78]	eta 0:01:44 lr 0.358200	time 1.1265 (2.1714)	loss 2.3434 (2.3512)	grad_norm 0.5460 (0.5571)	mem 39782MB
[2023-07-07 17:06:44 RepVGG-A0] (main.py 282): INFO Train: [254/300][40/78]	eta 0:01:19 lr 0.356228	time 3.2245 (2.0793)	loss 2.3695 (2.3542)	grad_norm 0.5505 (0.5565)	mem 39782MB
[2023-07-07 17:06:58 RepVGG-A0] (main.py 282): INFO Train: [254/300][50/78]	eta 0:00:54 lr 0.354260	time 1.2004 (1.9497)	loss 2.4127 (2.3584)	grad_norm 0.5571 (0.5577)	mem 39782MB
[2023-07-07 17:07:13 RepVGG-A0] (main.py 282): INFO Train: [254/300][60/78]	eta 0:00:33 lr 0.352298	time 1.3049 (1.8756)	loss 2.4190 (2.3620)	grad_norm 0.5771 (0.5577)	mem 39782MB
[2023-07-07 17:07:28 RepVGG-A0] (main.py 282): INFO Train: [254/300][70/78]	eta 0:00:14 lr 0.350341	time 1.1763 (1.8206)	loss 2.4040 (2.3632)	grad_norm 0.5646 (0.5588)	mem 39782MB
[2023-07-07 17:07:40 RepVGG-A0] (main.py 291): INFO EPOCH 254 training takes 0:02:21
[2023-07-07 17:08:02 RepVGG-A0] (main.py 282): INFO Train: [255/300][0/78]	eta 0:28:08 lr 0.348779	time 21.6508 (21.6508)	loss 2.3325 (2.3325)	grad_norm 0.5669 (0.5669)	mem 39782MB
[2023-07-07 17:08:16 RepVGG-A0] (main.py 282): INFO Train: [255/300][10/78]	eta 0:03:40 lr 0.346831	time 1.1711 (3.2357)	loss 2.3465 (2.3255)	grad_norm 0.5479 (0.5538)	mem 39782MB
[2023-07-07 17:08:30 RepVGG-A0] (main.py 282): INFO Train: [255/300][20/78]	eta 0:02:18 lr 0.344889	time 1.1906 (2.3891)	loss 2.3460 (2.3312)	grad_norm 0.5469 (0.5539)	mem 39782MB
[2023-07-07 17:08:47 RepVGG-A0] (main.py 282): INFO Train: [255/300][30/78]	eta 0:01:43 lr 0.342951	time 1.4417 (2.1469)	loss 2.3643 (2.3375)	grad_norm 0.5710 (0.5572)	mem 39782MB
[2023-07-07 17:09:05 RepVGG-A0] (main.py 282): INFO Train: [255/300][40/78]	eta 0:01:19 lr 0.341019	time 3.2788 (2.0821)	loss 2.3315 (2.3441)	grad_norm 0.5662 (0.5588)	mem 39782MB
[2023-07-07 17:09:20 RepVGG-A0] (main.py 282): INFO Train: [255/300][50/78]	eta 0:00:55 lr 0.339091	time 1.3035 (1.9683)	loss 2.3627 (2.3481)	grad_norm 0.5755 (0.5597)	mem 39782MB
[2023-07-07 17:09:35 RepVGG-A0] (main.py 282): INFO Train: [255/300][60/78]	eta 0:00:34 lr 0.337169	time 1.2190 (1.8921)	loss 2.3705 (2.3526)	grad_norm 0.5575 (0.5600)	mem 39782MB
[2023-07-07 17:09:51 RepVGG-A0] (main.py 282): INFO Train: [255/300][70/78]	eta 0:00:14 lr 0.335252	time 1.4480 (1.8451)	loss 2.3691 (2.3534)	grad_norm 0.5533 (0.5602)	mem 39782MB
[2023-07-07 17:10:01 RepVGG-A0] (main.py 291): INFO EPOCH 255 training takes 0:02:21
[2023-07-07 17:10:23 RepVGG-A0] (main.py 282): INFO Train: [256/300][0/78]	eta 0:28:10 lr 0.333722	time 21.6674 (21.6674)	loss 2.3489 (2.3489)	grad_norm 0.5691 (0.5691)	mem 39782MB
[2023-07-07 17:10:38 RepVGG-A0] (main.py 282): INFO Train: [256/300][10/78]	eta 0:03:44 lr 0.331815	time 1.1722 (3.2957)	loss 2.2994 (2.3273)	grad_norm 0.5738 (0.5588)	mem 39782MB
[2023-07-07 17:10:53 RepVGG-A0] (main.py 282): INFO Train: [256/300][20/78]	eta 0:02:22 lr 0.329912	time 1.2184 (2.4558)	loss 2.3350 (2.3362)	grad_norm 0.5591 (0.5602)	mem 39782MB
[2023-07-07 17:11:08 RepVGG-A0] (main.py 282): INFO Train: [256/300][30/78]	eta 0:01:43 lr 0.328015	time 1.6195 (2.1571)	loss 2.4175 (2.3434)	grad_norm 0.5674 (0.5626)	mem 39782MB
[2023-07-07 17:11:26 RepVGG-A0] (main.py 282): INFO Train: [256/300][40/78]	eta 0:01:18 lr 0.326123	time 2.8722 (2.0579)	loss 2.3209 (2.3422)	grad_norm 0.5526 (0.5633)	mem 39782MB
[2023-07-07 17:11:41 RepVGG-A0] (main.py 282): INFO Train: [256/300][50/78]	eta 0:00:54 lr 0.324236	time 1.1731 (1.9460)	loss 2.4041 (2.3446)	grad_norm 0.5577 (0.5630)	mem 39782MB
[2023-07-07 17:11:56 RepVGG-A0] (main.py 282): INFO Train: [256/300][60/78]	eta 0:00:33 lr 0.322354	time 1.1912 (1.8816)	loss 2.3046 (2.3434)	grad_norm 0.5718 (0.5624)	mem 39782MB
[2023-07-07 17:12:12 RepVGG-A0] (main.py 282): INFO Train: [256/300][70/78]	eta 0:00:14 lr 0.320477	time 1.3094 (1.8335)	loss 2.3534 (2.3434)	grad_norm 0.5744 (0.5625)	mem 39782MB
[2023-07-07 17:12:23 RepVGG-A0] (main.py 291): INFO EPOCH 256 training takes 0:02:21
[2023-07-07 17:12:44 RepVGG-A0] (main.py 282): INFO Train: [257/300][0/78]	eta 0:27:50 lr 0.318980	time 21.4112 (21.4112)	loss 2.3203 (2.3203)	grad_norm 0.5496 (0.5496)	mem 39782MB
[2023-07-07 17:13:00 RepVGG-A0] (main.py 282): INFO Train: [257/300][10/78]	eta 0:03:52 lr 0.317113	time 1.1725 (3.4233)	loss 2.3213 (2.3294)	grad_norm 0.5543 (0.5601)	mem 39782MB
[2023-07-07 17:13:15 RepVGG-A0] (main.py 282): INFO Train: [257/300][20/78]	eta 0:02:25 lr 0.315251	time 1.3530 (2.5047)	loss 2.2924 (2.3372)	grad_norm 0.5422 (0.5634)	mem 39782MB
[2023-07-07 17:13:30 RepVGG-A0] (main.py 282): INFO Train: [257/300][30/78]	eta 0:01:44 lr 0.313394	time 1.3214 (2.1832)	loss 2.3166 (2.3339)	grad_norm 0.5773 (0.5651)	mem 39782MB
[2023-07-07 17:13:49 RepVGG-A0] (main.py 282): INFO Train: [257/300][40/78]	eta 0:01:19 lr 0.311542	time 2.3595 (2.0968)	loss 2.3338 (2.3317)	grad_norm 0.5564 (0.5640)	mem 39782MB
[2023-07-07 17:14:04 RepVGG-A0] (main.py 282): INFO Train: [257/300][50/78]	eta 0:00:55 lr 0.309696	time 1.1743 (1.9967)	loss 2.2899 (2.3324)	grad_norm 0.5823 (0.5645)	mem 39782MB
[2023-07-07 17:14:20 RepVGG-A0] (main.py 282): INFO Train: [257/300][60/78]	eta 0:00:34 lr 0.307854	time 1.1270 (1.9217)	loss 2.2986 (2.3338)	grad_norm 0.5753 (0.5650)	mem 39782MB
[2023-07-07 17:14:35 RepVGG-A0] (main.py 282): INFO Train: [257/300][70/78]	eta 0:00:14 lr 0.306018	time 1.1594 (1.8670)	loss 2.3412 (2.3359)	grad_norm 0.5710 (0.5652)	mem 39782MB
[2023-07-07 17:14:46 RepVGG-A0] (main.py 291): INFO EPOCH 257 training takes 0:02:23
[2023-07-07 17:15:07 RepVGG-A0] (main.py 282): INFO Train: [258/300][0/78]	eta 0:28:13 lr 0.304553	time 21.7153 (21.7153)	loss 2.3046 (2.3046)	grad_norm 0.5610 (0.5610)	mem 39782MB
[2023-07-07 17:15:23 RepVGG-A0] (main.py 282): INFO Train: [258/300][10/78]	eta 0:03:47 lr 0.302727	time 1.1709 (3.3492)	loss 2.3005 (2.3156)	grad_norm 0.5682 (0.5617)	mem 39782MB
[2023-07-07 17:15:38 RepVGG-A0] (main.py 282): INFO Train: [258/300][20/78]	eta 0:02:23 lr 0.300905	time 1.3107 (2.4770)	loss 2.2965 (2.3203)	grad_norm 0.5610 (0.5649)	mem 39782MB
[2023-07-07 17:15:53 RepVGG-A0] (main.py 282): INFO Train: [258/300][30/78]	eta 0:01:44 lr 0.299089	time 1.2360 (2.1731)	loss 2.3163 (2.3229)	grad_norm 0.5888 (0.5667)	mem 39782MB
[2023-07-07 17:16:11 RepVGG-A0] (main.py 282): INFO Train: [258/300][40/78]	eta 0:01:19 lr 0.297278	time 3.7355 (2.0851)	loss 2.3631 (2.3214)	grad_norm 0.5585 (0.5660)	mem 39782MB
[2023-07-07 17:16:26 RepVGG-A0] (main.py 282): INFO Train: [258/300][50/78]	eta 0:00:55 lr 0.295473	time 1.1730 (1.9651)	loss 2.3767 (2.3264)	grad_norm 0.5721 (0.5666)	mem 39782MB
[2023-07-07 17:16:41 RepVGG-A0] (main.py 282): INFO Train: [258/300][60/78]	eta 0:00:34 lr 0.293672	time 1.3471 (1.8902)	loss 2.3101 (2.3283)	grad_norm 0.5658 (0.5671)	mem 39782MB
[2023-07-07 17:16:56 RepVGG-A0] (main.py 282): INFO Train: [258/300][70/78]	eta 0:00:14 lr 0.291877	time 1.2896 (1.8365)	loss 2.3431 (2.3318)	grad_norm 0.5701 (0.5676)	mem 39782MB
[2023-07-07 17:17:08 RepVGG-A0] (main.py 291): INFO EPOCH 258 training takes 0:02:21
[2023-07-07 17:17:30 RepVGG-A0] (main.py 282): INFO Train: [259/300][0/78]	eta 0:28:37 lr 0.290444	time 22.0173 (22.0173)	loss 2.2957 (2.2957)	grad_norm 0.5662 (0.5662)	mem 39782MB
[2023-07-07 17:17:45 RepVGG-A0] (main.py 282): INFO Train: [259/300][10/78]	eta 0:03:47 lr 0.288659	time 1.1707 (3.3480)	loss 2.2793 (2.2990)	grad_norm 0.5638 (0.5631)	mem 39782MB
[2023-07-07 17:18:00 RepVGG-A0] (main.py 282): INFO Train: [259/300][20/78]	eta 0:02:24 lr 0.286878	time 1.2818 (2.4908)	loss 2.2796 (2.3131)	grad_norm 0.5729 (0.5700)	mem 39782MB
[2023-07-07 17:18:14 RepVGG-A0] (main.py 282): INFO Train: [259/300][30/78]	eta 0:01:42 lr 0.285103	time 1.2038 (2.1255)	loss 2.3105 (2.3176)	grad_norm 0.5809 (0.5702)	mem 39782MB
[2023-07-07 17:18:32 RepVGG-A0] (main.py 282): INFO Train: [259/300][40/78]	eta 0:01:18 lr 0.283333	time 3.4319 (2.0663)	loss 2.3259 (2.3187)	grad_norm 0.5714 (0.5703)	mem 39782MB
[2023-07-07 17:18:47 RepVGG-A0] (main.py 282): INFO Train: [259/300][50/78]	eta 0:00:54 lr 0.281568	time 1.1714 (1.9411)	loss 2.3264 (2.3209)	grad_norm 0.5831 (0.5699)	mem 39782MB
[2023-07-07 17:19:02 RepVGG-A0] (main.py 282): INFO Train: [259/300][60/78]	eta 0:00:33 lr 0.279808	time 1.3234 (1.8761)	loss 2.3725 (2.3242)	grad_norm 0.5977 (0.5710)	mem 39782MB
[2023-07-07 17:19:18 RepVGG-A0] (main.py 282): INFO Train: [259/300][70/78]	eta 0:00:14 lr 0.278054	time 1.7353 (1.8297)	loss 2.2678 (2.3240)	grad_norm 0.5771 (0.5717)	mem 39782MB
[2023-07-07 17:19:30 RepVGG-A0] (main.py 291): INFO EPOCH 259 training takes 0:02:21
[2023-07-07 17:19:51 RepVGG-A0] (main.py 282): INFO Train: [260/300][0/78]	eta 0:27:26 lr 0.276655	time 21.1124 (21.1124)	loss 2.2547 (2.2547)	grad_norm 0.5650 (0.5650)	mem 39782MB
[2023-07-07 17:20:06 RepVGG-A0] (main.py 282): INFO Train: [260/300][10/78]	eta 0:03:43 lr 0.274910	time 1.1716 (3.2836)	loss 2.2938 (2.3109)	grad_norm 0.5658 (0.5689)	mem 39782MB
[2023-07-07 17:20:20 RepVGG-A0] (main.py 282): INFO Train: [260/300][20/78]	eta 0:02:19 lr 0.273170	time 1.3331 (2.4070)	loss 2.2775 (2.3181)	grad_norm 0.5763 (0.5697)	mem 39782MB
[2023-07-07 17:20:35 RepVGG-A0] (main.py 282): INFO Train: [260/300][30/78]	eta 0:01:40 lr 0.271436	time 1.1537 (2.1013)	loss 2.2940 (2.3221)	grad_norm 0.5676 (0.5700)	mem 39782MB
[2023-07-07 17:20:53 RepVGG-A0] (main.py 282): INFO Train: [260/300][40/78]	eta 0:01:17 lr 0.269707	time 3.6004 (2.0320)	loss 2.3382 (2.3215)	grad_norm 0.5700 (0.5724)	mem 39782MB
[2023-07-07 17:21:08 RepVGG-A0] (main.py 282): INFO Train: [260/300][50/78]	eta 0:00:54 lr 0.267983	time 1.3094 (1.9361)	loss 2.3635 (2.3213)	grad_norm 0.5723 (0.5737)	mem 39782MB
[2023-07-07 17:21:23 RepVGG-A0] (main.py 282): INFO Train: [260/300][60/78]	eta 0:00:33 lr 0.266265	time 1.2081 (1.8624)	loss 2.3437 (2.3211)	grad_norm 0.5727 (0.5749)	mem 39782MB
[2023-07-07 17:21:38 RepVGG-A0] (main.py 282): INFO Train: [260/300][70/78]	eta 0:00:14 lr 0.264552	time 1.2720 (1.8149)	loss 2.4088 (2.3222)	grad_norm 0.5777 (0.5755)	mem 39782MB
[2023-07-07 17:21:51 RepVGG-A0] (main.py 291): INFO EPOCH 260 training takes 0:02:20
[2023-07-07 17:22:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.958 (16.958)	Loss 1.4969 (1.4969)	Acc@1 67.114 (67.114)	Acc@5 87.482 (87.482)	Mem 39782MB
[2023-07-07 17:22:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 67.272 Acc@5 87.486
[2023-07-07 17:22:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 260: 67.272%
[2023-07-07 17:22:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 67.27%
[2023-07-07 17:22:30 RepVGG-A0] (main.py 282): INFO Train: [261/300][0/78]	eta 0:27:43 lr 0.263185	time 21.3206 (21.3206)	loss 2.3040 (2.3040)	grad_norm 0.5742 (0.5742)	mem 39782MB
[2023-07-07 17:22:46 RepVGG-A0] (main.py 282): INFO Train: [261/300][10/78]	eta 0:03:47 lr 0.261482	time 1.1711 (3.3491)	loss 2.2865 (2.2954)	grad_norm 0.5759 (0.5737)	mem 39782MB
[2023-07-07 17:23:00 RepVGG-A0] (main.py 282): INFO Train: [261/300][20/78]	eta 0:02:21 lr 0.259783	time 1.1754 (2.4392)	loss 2.3231 (2.2983)	grad_norm 0.5811 (0.5762)	mem 39782MB
[2023-07-07 17:23:14 RepVGG-A0] (main.py 282): INFO Train: [261/300][30/78]	eta 0:01:41 lr 0.258090	time 1.2566 (2.1153)	loss 2.4138 (2.3021)	grad_norm 0.5711 (0.5770)	mem 39782MB
[2023-07-07 17:23:32 RepVGG-A0] (main.py 282): INFO Train: [261/300][40/78]	eta 0:01:17 lr 0.256403	time 2.0846 (2.0344)	loss 2.3211 (2.3048)	grad_norm 0.5813 (0.5768)	mem 39782MB
[2023-07-07 17:23:48 RepVGG-A0] (main.py 282): INFO Train: [261/300][50/78]	eta 0:00:54 lr 0.254720	time 1.1720 (1.9458)	loss 2.3472 (2.3059)	grad_norm 0.5722 (0.5772)	mem 39782MB
[2023-07-07 17:24:03 RepVGG-A0] (main.py 282): INFO Train: [261/300][60/78]	eta 0:00:33 lr 0.253043	time 1.1938 (1.8650)	loss 2.3212 (2.3090)	grad_norm 0.5751 (0.5766)	mem 39782MB
[2023-07-07 17:24:18 RepVGG-A0] (main.py 282): INFO Train: [261/300][70/78]	eta 0:00:14 lr 0.251371	time 1.3468 (1.8218)	loss 2.3731 (2.3120)	grad_norm 0.5704 (0.5782)	mem 39782MB
[2023-07-07 17:24:30 RepVGG-A0] (main.py 291): INFO EPOCH 261 training takes 0:02:21
[2023-07-07 17:24:52 RepVGG-A0] (main.py 282): INFO Train: [262/300][0/78]	eta 0:28:14 lr 0.250038	time 21.7181 (21.7181)	loss 2.3080 (2.3080)	grad_norm 0.5803 (0.5803)	mem 39782MB
[2023-07-07 17:25:07 RepVGG-A0] (main.py 282): INFO Train: [262/300][10/78]	eta 0:03:44 lr 0.248376	time 1.1907 (3.3014)	loss 2.2840 (2.2894)	grad_norm 0.5728 (0.5734)	mem 39782MB
[2023-07-07 17:25:22 RepVGG-A0] (main.py 282): INFO Train: [262/300][20/78]	eta 0:02:21 lr 0.246719	time 1.1746 (2.4417)	loss 2.3827 (2.2903)	grad_norm 0.5873 (0.5748)	mem 39782MB
[2023-07-07 17:25:38 RepVGG-A0] (main.py 282): INFO Train: [262/300][30/78]	eta 0:01:44 lr 0.245067	time 1.4589 (2.1764)	loss 2.3281 (2.2901)	grad_norm 0.5979 (0.5759)	mem 39782MB
[2023-07-07 17:25:56 RepVGG-A0] (main.py 282): INFO Train: [262/300][40/78]	eta 0:01:18 lr 0.243421	time 3.6380 (2.0770)	loss 2.3319 (2.2930)	grad_norm 0.5793 (0.5774)	mem 39782MB
[2023-07-07 17:26:10 RepVGG-A0] (main.py 282): INFO Train: [262/300][50/78]	eta 0:00:54 lr 0.241780	time 1.1723 (1.9607)	loss 2.3014 (2.2958)	grad_norm 0.5810 (0.5782)	mem 39782MB
[2023-07-07 17:26:26 RepVGG-A0] (main.py 282): INFO Train: [262/300][60/78]	eta 0:00:34 lr 0.240145	time 1.4817 (1.8920)	loss 2.3382 (2.2987)	grad_norm 0.5828 (0.5782)	mem 39782MB
[2023-07-07 17:26:41 RepVGG-A0] (main.py 282): INFO Train: [262/300][70/78]	eta 0:00:14 lr 0.238514	time 1.5169 (1.8344)	loss 2.3714 (2.3023)	grad_norm 0.5824 (0.5790)	mem 39782MB
[2023-07-07 17:26:52 RepVGG-A0] (main.py 291): INFO EPOCH 262 training takes 0:02:21
[2023-07-07 17:27:13 RepVGG-A0] (main.py 282): INFO Train: [263/300][0/78]	eta 0:27:16 lr 0.237214	time 20.9839 (20.9839)	loss 2.2802 (2.2802)	grad_norm 0.6101 (0.6101)	mem 39782MB
[2023-07-07 17:27:28 RepVGG-A0] (main.py 282): INFO Train: [263/300][10/78]	eta 0:03:39 lr 0.235594	time 1.1725 (3.2240)	loss 2.2532 (2.2906)	grad_norm 0.5813 (0.6169)	mem 39782MB
[2023-07-07 17:27:43 RepVGG-A0] (main.py 282): INFO Train: [263/300][20/78]	eta 0:02:20 lr 0.233978	time 1.2783 (2.4258)	loss 2.2514 (2.2906)	grad_norm 0.5791 (0.5982)	mem 39782MB
[2023-07-07 17:28:05 RepVGG-A0] (main.py 282): INFO Train: [263/300][30/78]	eta 0:01:51 lr 0.232368	time 1.1712 (2.3287)	loss 2.2801 (2.2926)	grad_norm 0.5789 (0.5924)	mem 39782MB
[2023-07-07 17:28:21 RepVGG-A0] (main.py 282): INFO Train: [263/300][40/78]	eta 0:01:21 lr 0.230764	time 1.1749 (2.1521)	loss 2.3147 (2.2959)	grad_norm 0.5843 (0.5906)	mem 39782MB
[2023-07-07 17:28:36 RepVGG-A0] (main.py 282): INFO Train: [263/300][50/78]	eta 0:00:57 lr 0.229165	time 1.1780 (2.0363)	loss 2.3103 (2.2959)	grad_norm 0.5638 (0.5889)	mem 39782MB
[2023-07-07 17:28:51 RepVGG-A0] (main.py 282): INFO Train: [263/300][60/78]	eta 0:00:35 lr 0.227571	time 1.2580 (1.9451)	loss 2.3074 (2.2993)	grad_norm 0.5914 (0.5885)	mem 39782MB
[2023-07-07 17:29:06 RepVGG-A0] (main.py 282): INFO Train: [263/300][70/78]	eta 0:00:15 lr 0.225982	time 1.2249 (1.8804)	loss 2.2816 (2.2993)	grad_norm 0.5738 (0.5882)	mem 39782MB
[2023-07-07 17:29:17 RepVGG-A0] (main.py 291): INFO EPOCH 263 training takes 0:02:24
[2023-07-07 17:29:37 RepVGG-A0] (main.py 282): INFO Train: [264/300][0/78]	eta 0:26:51 lr 0.224715	time 20.6645 (20.6645)	loss 2.2557 (2.2557)	grad_norm 0.5828 (0.5828)	mem 39782MB
[2023-07-07 17:29:53 RepVGG-A0] (main.py 282): INFO Train: [264/300][10/78]	eta 0:03:41 lr 0.223136	time 1.1714 (3.2584)	loss 2.2653 (2.2877)	grad_norm 0.5700 (0.5851)	mem 39782MB
[2023-07-07 17:30:07 RepVGG-A0] (main.py 282): INFO Train: [264/300][20/78]	eta 0:02:19 lr 0.221563	time 1.1729 (2.4047)	loss 2.4038 (2.2930)	grad_norm 0.5929 (0.5869)	mem 39782MB
[2023-07-07 17:30:23 RepVGG-A0] (main.py 282): INFO Train: [264/300][30/78]	eta 0:01:41 lr 0.219995	time 1.2756 (2.1207)	loss 2.2461 (2.2919)	grad_norm 0.6009 (0.5866)	mem 39782MB
[2023-07-07 17:30:40 RepVGG-A0] (main.py 282): INFO Train: [264/300][40/78]	eta 0:01:17 lr 0.218432	time 3.1567 (2.0290)	loss 2.3134 (2.2957)	grad_norm 0.5828 (0.5865)	mem 39782MB
[2023-07-07 17:30:55 RepVGG-A0] (main.py 282): INFO Train: [264/300][50/78]	eta 0:00:54 lr 0.216875	time 1.1733 (1.9338)	loss 2.3095 (2.2962)	grad_norm 0.5860 (0.5859)	mem 39782MB
[2023-07-07 17:31:11 RepVGG-A0] (main.py 282): INFO Train: [264/300][60/78]	eta 0:00:33 lr 0.215323	time 1.7962 (1.8797)	loss 2.3026 (2.2985)	grad_norm 0.5947 (0.5869)	mem 39782MB
[2023-07-07 17:31:26 RepVGG-A0] (main.py 282): INFO Train: [264/300][70/78]	eta 0:00:14 lr 0.213776	time 1.2514 (1.8156)	loss 2.3335 (2.2973)	grad_norm 0.5859 (0.5867)	mem 39782MB
[2023-07-07 17:31:38 RepVGG-A0] (main.py 291): INFO EPOCH 264 training takes 0:02:20
[2023-07-07 17:32:00 RepVGG-A0] (main.py 282): INFO Train: [265/300][0/78]	eta 0:28:31 lr 0.212543	time 21.9409 (21.9409)	loss 2.3042 (2.3042)	grad_norm 0.5911 (0.5911)	mem 39782MB
[2023-07-07 17:32:15 RepVGG-A0] (main.py 282): INFO Train: [265/300][10/78]	eta 0:03:48 lr 0.211006	time 1.1918 (3.3665)	loss 2.3049 (2.2855)	grad_norm 0.5899 (0.5860)	mem 39782MB
[2023-07-07 17:32:30 RepVGG-A0] (main.py 282): INFO Train: [265/300][20/78]	eta 0:02:23 lr 0.209474	time 1.2382 (2.4702)	loss 2.2930 (2.2779)	grad_norm 0.5889 (0.5902)	mem 39782MB
[2023-07-07 17:32:44 RepVGG-A0] (main.py 282): INFO Train: [265/300][30/78]	eta 0:01:43 lr 0.207948	time 1.2397 (2.1515)	loss 2.2874 (2.2785)	grad_norm 0.5842 (0.5901)	mem 39782MB
[2023-07-07 17:33:02 RepVGG-A0] (main.py 282): INFO Train: [265/300][40/78]	eta 0:01:18 lr 0.206427	time 3.7179 (2.0644)	loss 2.3098 (2.2771)	grad_norm 0.6056 (0.5899)	mem 39782MB
[2023-07-07 17:33:17 RepVGG-A0] (main.py 282): INFO Train: [265/300][50/78]	eta 0:00:54 lr 0.204912	time 1.1723 (1.9490)	loss 2.3307 (2.2831)	grad_norm 0.5949 (0.5911)	mem 39782MB
[2023-07-07 17:33:32 RepVGG-A0] (main.py 282): INFO Train: [265/300][60/78]	eta 0:00:33 lr 0.203402	time 1.1783 (1.8814)	loss 2.2527 (2.2842)	grad_norm 0.5862 (0.5911)	mem 39782MB
[2023-07-07 17:33:48 RepVGG-A0] (main.py 282): INFO Train: [265/300][70/78]	eta 0:00:14 lr 0.201897	time 1.3212 (1.8412)	loss 2.2884 (2.2831)	grad_norm 0.5918 (0.5905)	mem 39782MB
[2023-07-07 17:33:59 RepVGG-A0] (main.py 291): INFO EPOCH 265 training takes 0:02:21
[2023-07-07 17:34:21 RepVGG-A0] (main.py 282): INFO Train: [266/300][0/78]	eta 0:28:20 lr 0.200698	time 21.7970 (21.7970)	loss 2.2219 (2.2219)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 17:34:36 RepVGG-A0] (main.py 282): INFO Train: [266/300][10/78]	eta 0:03:47 lr 0.199203	time 1.1730 (3.3499)	loss 2.2761 (2.2539)	grad_norm 0.5801 (0.5881)	mem 39782MB
[2023-07-07 17:34:51 RepVGG-A0] (main.py 282): INFO Train: [266/300][20/78]	eta 0:02:23 lr 0.197713	time 1.2879 (2.4673)	loss 2.2440 (2.2589)	grad_norm 0.5976 (0.5885)	mem 39782MB
[2023-07-07 17:35:06 RepVGG-A0] (main.py 282): INFO Train: [266/300][30/78]	eta 0:01:44 lr 0.196229	time 1.3624 (2.1680)	loss 2.2712 (2.2691)	grad_norm 0.5975 (0.5891)	mem 39782MB
[2023-07-07 17:35:23 RepVGG-A0] (main.py 282): INFO Train: [266/300][40/78]	eta 0:01:17 lr 0.194751	time 2.5915 (2.0456)	loss 2.2948 (2.2717)	grad_norm 0.5995 (0.5908)	mem 39782MB
[2023-07-07 17:35:39 RepVGG-A0] (main.py 282): INFO Train: [266/300][50/78]	eta 0:00:54 lr 0.193278	time 1.1727 (1.9523)	loss 2.2744 (2.2745)	grad_norm 0.5956 (0.5913)	mem 39782MB
[2023-07-07 17:35:54 RepVGG-A0] (main.py 282): INFO Train: [266/300][60/78]	eta 0:00:33 lr 0.191810	time 1.2013 (1.8737)	loss 2.2412 (2.2735)	grad_norm 0.5952 (0.5922)	mem 39782MB
[2023-07-07 17:36:09 RepVGG-A0] (main.py 282): INFO Train: [266/300][70/78]	eta 0:00:14 lr 0.190348	time 1.3400 (1.8243)	loss 2.2706 (2.2763)	grad_norm 0.6125 (0.5929)	mem 39782MB
[2023-07-07 17:36:21 RepVGG-A0] (main.py 291): INFO EPOCH 266 training takes 0:02:21
[2023-07-07 17:36:41 RepVGG-A0] (main.py 282): INFO Train: [267/300][0/78]	eta 0:26:02 lr 0.189182	time 20.0330 (20.0330)	loss 2.2134 (2.2134)	grad_norm 0.5900 (0.5900)	mem 39782MB
[2023-07-07 17:36:56 RepVGG-A0] (main.py 282): INFO Train: [267/300][10/78]	eta 0:03:34 lr 0.187729	time 1.1896 (3.1562)	loss 2.2414 (2.2469)	grad_norm 0.5996 (0.5898)	mem 39782MB
[2023-07-07 17:37:12 RepVGG-A0] (main.py 282): INFO Train: [267/300][20/78]	eta 0:02:21 lr 0.186282	time 1.1283 (2.4350)	loss 2.2543 (2.2497)	grad_norm 0.6010 (0.5914)	mem 39782MB
[2023-07-07 17:37:27 RepVGG-A0] (main.py 282): INFO Train: [267/300][30/78]	eta 0:01:42 lr 0.184840	time 1.6656 (2.1343)	loss 2.2365 (2.2594)	grad_norm 0.5988 (0.5931)	mem 39782MB
[2023-07-07 17:37:43 RepVGG-A0] (main.py 282): INFO Train: [267/300][40/78]	eta 0:01:16 lr 0.183404	time 3.3883 (2.0007)	loss 2.2909 (2.2606)	grad_norm 0.5921 (0.5955)	mem 39782MB
[2023-07-07 17:37:58 RepVGG-A0] (main.py 282): INFO Train: [267/300][50/78]	eta 0:00:53 lr 0.181973	time 1.3426 (1.9048)	loss 2.3305 (2.2618)	grad_norm 0.6023 (0.5957)	mem 39782MB
[2023-07-07 17:38:13 RepVGG-A0] (main.py 282): INFO Train: [267/300][60/78]	eta 0:00:33 lr 0.180548	time 1.3037 (1.8398)	loss 2.2286 (2.2636)	grad_norm 0.6014 (0.5958)	mem 39782MB
[2023-07-07 17:38:28 RepVGG-A0] (main.py 282): INFO Train: [267/300][70/78]	eta 0:00:14 lr 0.179128	time 1.3650 (1.7905)	loss 2.2932 (2.2654)	grad_norm 0.6048 (0.5967)	mem 39782MB
[2023-07-07 17:38:40 RepVGG-A0] (main.py 291): INFO EPOCH 267 training takes 0:02:18
[2023-07-07 17:39:01 RepVGG-A0] (main.py 282): INFO Train: [268/300][0/78]	eta 0:27:11 lr 0.177996	time 20.9192 (20.9192)	loss 2.2690 (2.2690)	grad_norm 0.5898 (0.5898)	mem 39782MB
[2023-07-07 17:39:16 RepVGG-A0] (main.py 282): INFO Train: [268/300][10/78]	eta 0:03:41 lr 0.176585	time 1.1681 (3.2632)	loss 2.2784 (2.2468)	grad_norm 0.5931 (0.5918)	mem 39782MB
[2023-07-07 17:39:31 RepVGG-A0] (main.py 282): INFO Train: [268/300][20/78]	eta 0:02:21 lr 0.175181	time 1.2105 (2.4476)	loss 2.2841 (2.2551)	grad_norm 0.5965 (0.5918)	mem 39782MB
[2023-07-07 17:39:46 RepVGG-A0] (main.py 282): INFO Train: [268/300][30/78]	eta 0:01:42 lr 0.173782	time 1.3602 (2.1332)	loss 2.2719 (2.2565)	grad_norm 0.5863 (0.5934)	mem 39782MB
[2023-07-07 17:40:03 RepVGG-A0] (main.py 282): INFO Train: [268/300][40/78]	eta 0:01:17 lr 0.172388	time 3.2252 (2.0406)	loss 2.3227 (2.2622)	grad_norm 0.5968 (0.5946)	mem 39782MB
[2023-07-07 17:40:19 RepVGG-A0] (main.py 282): INFO Train: [268/300][50/78]	eta 0:00:54 lr 0.170999	time 1.1721 (1.9436)	loss 2.2625 (2.2638)	grad_norm 0.5996 (0.5957)	mem 39782MB
[2023-07-07 17:40:34 RepVGG-A0] (main.py 282): INFO Train: [268/300][60/78]	eta 0:00:33 lr 0.169617	time 1.1825 (1.8736)	loss 2.3020 (2.2661)	grad_norm 0.5948 (0.5972)	mem 39782MB
[2023-07-07 17:40:49 RepVGG-A0] (main.py 282): INFO Train: [268/300][70/78]	eta 0:00:14 lr 0.168239	time 1.2746 (1.8166)	loss 2.2723 (2.2680)	grad_norm 0.6081 (0.5977)	mem 39782MB
[2023-07-07 17:41:00 RepVGG-A0] (main.py 291): INFO EPOCH 268 training takes 0:02:20
[2023-07-07 17:41:21 RepVGG-A0] (main.py 282): INFO Train: [269/300][0/78]	eta 0:27:26 lr 0.167141	time 21.1120 (21.1120)	loss 2.2072 (2.2072)	grad_norm 0.5896 (0.5896)	mem 39782MB
[2023-07-07 17:41:36 RepVGG-A0] (main.py 282): INFO Train: [269/300][10/78]	eta 0:03:43 lr 0.165774	time 1.1751 (3.2895)	loss 2.2568 (2.2346)	grad_norm 0.6026 (0.5946)	mem 39782MB
[2023-07-07 17:41:52 RepVGG-A0] (main.py 282): INFO Train: [269/300][20/78]	eta 0:02:22 lr 0.164411	time 1.4269 (2.4528)	loss 2.2867 (2.2483)	grad_norm 0.6027 (0.5969)	mem 39782MB
[2023-07-07 17:42:07 RepVGG-A0] (main.py 282): INFO Train: [269/300][30/78]	eta 0:01:43 lr 0.163055	time 1.5384 (2.1535)	loss 2.2794 (2.2527)	grad_norm 0.5956 (0.5978)	mem 39782MB
[2023-07-07 17:42:26 RepVGG-A0] (main.py 282): INFO Train: [269/300][40/78]	eta 0:01:19 lr 0.161704	time 3.2628 (2.0811)	loss 2.2815 (2.2580)	grad_norm 0.6046 (0.5996)	mem 39782MB
[2023-07-07 17:42:40 RepVGG-A0] (main.py 282): INFO Train: [269/300][50/78]	eta 0:00:54 lr 0.160358	time 1.1772 (1.9601)	loss 2.2585 (2.2608)	grad_norm 0.5963 (0.6004)	mem 39782MB
[2023-07-07 17:42:55 RepVGG-A0] (main.py 282): INFO Train: [269/300][60/78]	eta 0:00:33 lr 0.159018	time 1.1758 (1.8876)	loss 2.2829 (2.2616)	grad_norm 0.6096 (0.6003)	mem 39782MB
[2023-07-07 17:43:10 RepVGG-A0] (main.py 282): INFO Train: [269/300][70/78]	eta 0:00:14 lr 0.157683	time 1.1275 (1.8310)	loss 2.2902 (2.2643)	grad_norm 0.5994 (0.6009)	mem 39782MB
[2023-07-07 17:43:21 RepVGG-A0] (main.py 291): INFO EPOCH 269 training takes 0:02:21
[2023-07-07 17:43:43 RepVGG-A0] (main.py 282): INFO Train: [270/300][0/78]	eta 0:28:46 lr 0.156619	time 22.1399 (22.1399)	loss 2.2402 (2.2402)	grad_norm 0.6002 (0.6002)	mem 39782MB
[2023-07-07 17:43:58 RepVGG-A0] (main.py 282): INFO Train: [270/300][10/78]	eta 0:03:49 lr 0.155294	time 1.1733 (3.3808)	loss 2.2005 (2.2513)	grad_norm 0.5950 (0.6043)	mem 39782MB
[2023-07-07 17:44:14 RepVGG-A0] (main.py 282): INFO Train: [270/300][20/78]	eta 0:02:24 lr 0.153975	time 1.1390 (2.4880)	loss 2.2576 (2.2477)	grad_norm 0.5992 (0.6035)	mem 39782MB
[2023-07-07 17:44:28 RepVGG-A0] (main.py 282): INFO Train: [270/300][30/78]	eta 0:01:44 lr 0.152661	time 1.1294 (2.1670)	loss 2.1664 (2.2432)	grad_norm 0.6050 (0.6041)	mem 39782MB
[2023-07-07 17:44:46 RepVGG-A0] (main.py 282): INFO Train: [270/300][40/78]	eta 0:01:18 lr 0.151353	time 3.0716 (2.0644)	loss 2.2966 (2.2462)	grad_norm 0.6112 (0.6051)	mem 39782MB
[2023-07-07 17:45:01 RepVGG-A0] (main.py 282): INFO Train: [270/300][50/78]	eta 0:00:54 lr 0.150050	time 1.3934 (1.9572)	loss 2.2768 (2.2501)	grad_norm 0.6031 (0.6053)	mem 39782MB
[2023-07-07 17:45:16 RepVGG-A0] (main.py 282): INFO Train: [270/300][60/78]	eta 0:00:33 lr 0.148752	time 1.4023 (1.8815)	loss 2.2869 (2.2517)	grad_norm 0.6040 (0.6058)	mem 39782MB
[2023-07-07 17:45:31 RepVGG-A0] (main.py 282): INFO Train: [270/300][70/78]	eta 0:00:14 lr 0.147460	time 1.2463 (1.8265)	loss 2.2689 (2.2514)	grad_norm 0.6121 (0.6065)	mem 39782MB
[2023-07-07 17:45:42 RepVGG-A0] (main.py 291): INFO EPOCH 270 training takes 0:02:21
[2023-07-07 17:46:02 RepVGG-A0] (main.py 282): INFO Train: [271/300][0/78]	eta 0:25:36 lr 0.146431	time 19.6990 (19.6990)	loss 2.2697 (2.2697)	grad_norm 0.6115 (0.6115)	mem 39782MB
[2023-07-07 17:46:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][10/78]	eta 0:03:49 lr 0.145149	time 1.1713 (3.3778)	loss 2.2362 (2.2270)	grad_norm 0.5993 (0.6003)	mem 39782MB
[2023-07-07 17:46:33 RepVGG-A0] (main.py 282): INFO Train: [271/300][20/78]	eta 0:02:20 lr 0.143872	time 1.2180 (2.4194)	loss 2.2211 (2.2329)	grad_norm 0.5962 (0.6028)	mem 39782MB
[2023-07-07 17:46:48 RepVGG-A0] (main.py 282): INFO Train: [271/300][30/78]	eta 0:01:41 lr 0.142602	time 1.1942 (2.1043)	loss 2.2150 (2.2356)	grad_norm 0.6090 (0.6048)	mem 39782MB
[2023-07-07 17:47:05 RepVGG-A0] (main.py 282): INFO Train: [271/300][40/78]	eta 0:01:16 lr 0.141336	time 3.3187 (2.0123)	loss 2.2809 (2.2419)	grad_norm 0.6036 (0.6051)	mem 39782MB
[2023-07-07 17:47:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][50/78]	eta 0:00:53 lr 0.140076	time 1.1808 (1.9120)	loss 2.3249 (2.2434)	grad_norm 0.6162 (0.6058)	mem 39782MB
[2023-07-07 17:47:36 RepVGG-A0] (main.py 282): INFO Train: [271/300][60/78]	eta 0:00:33 lr 0.138822	time 1.2511 (1.8528)	loss 2.2590 (2.2453)	grad_norm 0.6106 (0.6069)	mem 39782MB
[2023-07-07 17:47:50 RepVGG-A0] (main.py 282): INFO Train: [271/300][70/78]	eta 0:00:14 lr 0.137573	time 1.4684 (1.8007)	loss 2.2250 (2.2452)	grad_norm 0.6113 (0.6073)	mem 39782MB
[2023-07-07 17:48:02 RepVGG-A0] (main.py 291): INFO EPOCH 271 training takes 0:02:19
[2023-07-07 17:48:24 RepVGG-A0] (main.py 282): INFO Train: [272/300][0/78]	eta 0:28:37 lr 0.136578	time 22.0208 (22.0208)	loss 2.1933 (2.1933)	grad_norm 0.6081 (0.6081)	mem 39782MB
[2023-07-07 17:48:39 RepVGG-A0] (main.py 282): INFO Train: [272/300][10/78]	eta 0:03:46 lr 0.135339	time 1.1725 (3.3299)	loss 2.2268 (2.2472)	grad_norm 0.6057 (0.6103)	mem 39782MB
[2023-07-07 17:48:53 RepVGG-A0] (main.py 282): INFO Train: [272/300][20/78]	eta 0:02:21 lr 0.134105	time 1.1819 (2.4388)	loss 2.2296 (2.2440)	grad_norm 0.6070 (0.6112)	mem 39782MB
[2023-07-07 17:49:08 RepVGG-A0] (main.py 282): INFO Train: [272/300][30/78]	eta 0:01:42 lr 0.132877	time 1.5495 (2.1281)	loss 2.2694 (2.2427)	grad_norm 0.6172 (0.6116)	mem 39782MB
[2023-07-07 17:49:25 RepVGG-A0] (main.py 282): INFO Train: [272/300][40/78]	eta 0:01:17 lr 0.131655	time 3.9513 (2.0285)	loss 2.1640 (2.2395)	grad_norm 0.6209 (0.6121)	mem 39782MB
[2023-07-07 17:49:41 RepVGG-A0] (main.py 282): INFO Train: [272/300][50/78]	eta 0:00:54 lr 0.130438	time 1.1863 (1.9332)	loss 2.2693 (2.2379)	grad_norm 0.6034 (0.6133)	mem 39782MB
[2023-07-07 17:49:56 RepVGG-A0] (main.py 282): INFO Train: [272/300][60/78]	eta 0:00:33 lr 0.129227	time 1.1764 (1.8665)	loss 2.2464 (2.2417)	grad_norm 0.6289 (0.6136)	mem 39782MB
[2023-07-07 17:50:12 RepVGG-A0] (main.py 282): INFO Train: [272/300][70/78]	eta 0:00:14 lr 0.128021	time 1.3441 (1.8265)	loss 2.2774 (2.2431)	grad_norm 0.6133 (0.6140)	mem 39782MB
[2023-07-07 17:50:24 RepVGG-A0] (main.py 291): INFO EPOCH 272 training takes 0:02:21
[2023-07-07 17:50:45 RepVGG-A0] (main.py 282): INFO Train: [273/300][0/78]	eta 0:27:05 lr 0.127060	time 20.8360 (20.8360)	loss 2.2077 (2.2077)	grad_norm 0.6025 (0.6025)	mem 39782MB
[2023-07-07 17:51:01 RepVGG-A0] (main.py 282): INFO Train: [273/300][10/78]	eta 0:03:51 lr 0.125864	time 1.1724 (3.4030)	loss 2.2138 (2.2163)	grad_norm 0.6136 (0.6100)	mem 39782MB
[2023-07-07 17:51:17 RepVGG-A0] (main.py 282): INFO Train: [273/300][20/78]	eta 0:02:27 lr 0.124674	time 1.1284 (2.5396)	loss 2.1858 (2.2246)	grad_norm 0.6155 (0.6130)	mem 39782MB
[2023-07-07 17:51:33 RepVGG-A0] (main.py 282): INFO Train: [273/300][30/78]	eta 0:01:46 lr 0.123489	time 1.3863 (2.2223)	loss 2.2223 (2.2280)	grad_norm 0.6181 (0.6123)	mem 39782MB
[2023-07-07 17:51:50 RepVGG-A0] (main.py 282): INFO Train: [273/300][40/78]	eta 0:01:19 lr 0.122310	time 2.4960 (2.1029)	loss 2.2470 (2.2259)	grad_norm 0.6127 (0.6129)	mem 39782MB
[2023-07-07 17:52:05 RepVGG-A0] (main.py 282): INFO Train: [273/300][50/78]	eta 0:00:55 lr 0.121136	time 1.1921 (1.9925)	loss 2.2400 (2.2299)	grad_norm 0.6200 (0.6141)	mem 39782MB
[2023-07-07 17:52:20 RepVGG-A0] (main.py 282): INFO Train: [273/300][60/78]	eta 0:00:34 lr 0.119968	time 1.1743 (1.9061)	loss 2.2412 (2.2306)	grad_norm 0.6246 (0.6147)	mem 39782MB
[2023-07-07 17:52:35 RepVGG-A0] (main.py 282): INFO Train: [273/300][70/78]	eta 0:00:14 lr 0.118806	time 1.1265 (1.8492)	loss 2.2642 (2.2325)	grad_norm 0.6233 (0.6163)	mem 39782MB
[2023-07-07 17:52:46 RepVGG-A0] (main.py 291): INFO EPOCH 273 training takes 0:02:22
[2023-07-07 17:53:07 RepVGG-A0] (main.py 282): INFO Train: [274/300][0/78]	eta 0:26:31 lr 0.117880	time 20.3991 (20.3991)	loss 2.1352 (2.1352)	grad_norm 0.6061 (0.6061)	mem 39782MB
[2023-07-07 17:53:22 RepVGG-A0] (main.py 282): INFO Train: [274/300][10/78]	eta 0:03:39 lr 0.116727	time 1.1902 (3.2256)	loss 2.2339 (2.2222)	grad_norm 0.6169 (0.6088)	mem 39782MB
[2023-07-07 17:53:37 RepVGG-A0] (main.py 282): INFO Train: [274/300][20/78]	eta 0:02:20 lr 0.115580	time 1.1901 (2.4166)	loss 2.2244 (2.2253)	grad_norm 0.6198 (0.6120)	mem 39782MB
[2023-07-07 17:53:52 RepVGG-A0] (main.py 282): INFO Train: [274/300][30/78]	eta 0:01:41 lr 0.114439	time 1.4347 (2.1211)	loss 2.2597 (2.2221)	grad_norm 0.6142 (0.6141)	mem 39782MB
[2023-07-07 17:54:11 RepVGG-A0] (main.py 282): INFO Train: [274/300][40/78]	eta 0:01:18 lr 0.113303	time 3.5654 (2.0561)	loss 2.2346 (2.2229)	grad_norm 0.6123 (0.6146)	mem 39782MB
[2023-07-07 17:54:26 RepVGG-A0] (main.py 282): INFO Train: [274/300][50/78]	eta 0:00:54 lr 0.112173	time 1.2026 (1.9450)	loss 2.2641 (2.2230)	grad_norm 0.6258 (0.6161)	mem 39782MB
[2023-07-07 17:54:40 RepVGG-A0] (main.py 282): INFO Train: [274/300][60/78]	eta 0:00:33 lr 0.111048	time 1.4783 (1.8704)	loss 2.2723 (2.2245)	grad_norm 0.6216 (0.6162)	mem 39782MB
[2023-07-07 17:54:55 RepVGG-A0] (main.py 282): INFO Train: [274/300][70/78]	eta 0:00:14 lr 0.109929	time 1.2322 (1.8113)	loss 2.2314 (2.2273)	grad_norm 0.6171 (0.6171)	mem 39782MB
[2023-07-07 17:55:07 RepVGG-A0] (main.py 291): INFO EPOCH 274 training takes 0:02:20
[2023-07-07 17:55:28 RepVGG-A0] (main.py 282): INFO Train: [275/300][0/78]	eta 0:27:08 lr 0.109037	time 20.8809 (20.8809)	loss 2.2237 (2.2237)	grad_norm 0.6124 (0.6124)	mem 39782MB
[2023-07-07 17:55:43 RepVGG-A0] (main.py 282): INFO Train: [275/300][10/78]	eta 0:03:41 lr 0.107928	time 1.1714 (3.2560)	loss 2.2020 (2.2176)	grad_norm 0.6142 (0.6143)	mem 39782MB
[2023-07-07 17:55:57 RepVGG-A0] (main.py 282): INFO Train: [275/300][20/78]	eta 0:02:19 lr 0.106825	time 1.1717 (2.3998)	loss 2.2195 (2.2203)	grad_norm 0.6073 (0.6151)	mem 39782MB
[2023-07-07 17:56:13 RepVGG-A0] (main.py 282): INFO Train: [275/300][30/78]	eta 0:01:41 lr 0.105727	time 1.1382 (2.1232)	loss 2.2467 (2.2210)	grad_norm 0.6171 (0.6158)	mem 39782MB
[2023-07-07 17:56:30 RepVGG-A0] (main.py 282): INFO Train: [275/300][40/78]	eta 0:01:17 lr 0.104634	time 3.3880 (2.0311)	loss 2.2531 (2.2201)	grad_norm 0.6200 (0.6171)	mem 39782MB
[2023-07-07 17:56:45 RepVGG-A0] (main.py 282): INFO Train: [275/300][50/78]	eta 0:00:53 lr 0.103547	time 1.1718 (1.9203)	loss 2.2219 (2.2221)	grad_norm 0.6284 (0.6182)	mem 39782MB
[2023-07-07 17:57:00 RepVGG-A0] (main.py 282): INFO Train: [275/300][60/78]	eta 0:00:33 lr 0.102466	time 1.1274 (1.8565)	loss 2.2170 (2.2217)	grad_norm 0.6174 (0.6187)	mem 39782MB
[2023-07-07 17:57:15 RepVGG-A0] (main.py 282): INFO Train: [275/300][70/78]	eta 0:00:14 lr 0.101390	time 1.1721 (1.8055)	loss 2.2083 (2.2227)	grad_norm 0.6305 (0.6191)	mem 39782MB
[2023-07-07 17:57:26 RepVGG-A0] (main.py 291): INFO EPOCH 275 training takes 0:02:19
[2023-07-07 17:57:49 RepVGG-A0] (main.py 282): INFO Train: [276/300][0/78]	eta 0:29:15 lr 0.100534	time 22.5021 (22.5021)	loss 2.2616 (2.2616)	grad_norm 0.6158 (0.6158)	mem 39782MB
[2023-07-07 17:58:03 RepVGG-A0] (main.py 282): INFO Train: [276/300][10/78]	eta 0:03:42 lr 0.099468	time 1.1924 (3.2773)	loss 2.1532 (2.2020)	grad_norm 0.6254 (0.6183)	mem 39782MB
[2023-07-07 17:58:17 RepVGG-A0] (main.py 282): INFO Train: [276/300][20/78]	eta 0:02:18 lr 0.098408	time 1.1729 (2.3903)	loss 2.2395 (2.2136)	grad_norm 0.6192 (0.6210)	mem 39782MB
[2023-07-07 17:58:33 RepVGG-A0] (main.py 282): INFO Train: [276/300][30/78]	eta 0:01:43 lr 0.097354	time 1.1525 (2.1484)	loss 2.1685 (2.2202)	grad_norm 0.6238 (0.6215)	mem 39782MB
[2023-07-07 17:58:50 RepVGG-A0] (main.py 282): INFO Train: [276/300][40/78]	eta 0:01:17 lr 0.096305	time 3.4807 (2.0483)	loss 2.2472 (2.2200)	grad_norm 0.6140 (0.6213)	mem 39782MB
[2023-07-07 17:59:06 RepVGG-A0] (main.py 282): INFO Train: [276/300][50/78]	eta 0:00:54 lr 0.095262	time 1.1754 (1.9425)	loss 2.1787 (2.2219)	grad_norm 0.6189 (0.6214)	mem 39782MB
[2023-07-07 17:59:22 RepVGG-A0] (main.py 282): INFO Train: [276/300][60/78]	eta 0:00:34 lr 0.094224	time 1.2097 (1.8927)	loss 2.2556 (2.2244)	grad_norm 0.6191 (0.6219)	mem 39782MB
[2023-07-07 17:59:37 RepVGG-A0] (main.py 282): INFO Train: [276/300][70/78]	eta 0:00:14 lr 0.093192	time 1.2105 (1.8323)	loss 2.2278 (2.2271)	grad_norm 0.6211 (0.6219)	mem 39782MB
[2023-07-07 17:59:49 RepVGG-A0] (main.py 291): INFO EPOCH 276 training takes 0:02:22
[2023-07-07 18:00:11 RepVGG-A0] (main.py 282): INFO Train: [277/300][0/78]	eta 0:28:01 lr 0.092370	time 21.5514 (21.5514)	loss 2.1395 (2.1395)	grad_norm 0.6191 (0.6191)	mem 39782MB
[2023-07-07 18:00:25 RepVGG-A0] (main.py 282): INFO Train: [277/300][10/78]	eta 0:03:44 lr 0.091348	time 1.1722 (3.2963)	loss 2.1923 (2.2109)	grad_norm 0.6192 (0.6209)	mem 39782MB
[2023-07-07 18:00:41 RepVGG-A0] (main.py 282): INFO Train: [277/300][20/78]	eta 0:02:23 lr 0.090332	time 1.1763 (2.4690)	loss 2.2245 (2.2120)	grad_norm 0.6143 (0.6234)	mem 39782MB
[2023-07-07 18:00:56 RepVGG-A0] (main.py 282): INFO Train: [277/300][30/78]	eta 0:01:43 lr 0.089321	time 1.3794 (2.1523)	loss 2.2156 (2.2108)	grad_norm 0.6254 (0.6242)	mem 39782MB
[2023-07-07 18:01:13 RepVGG-A0] (main.py 282): INFO Train: [277/300][40/78]	eta 0:01:18 lr 0.088316	time 1.9381 (2.0537)	loss 2.2115 (2.2084)	grad_norm 0.6309 (0.6240)	mem 39782MB
[2023-07-07 18:01:29 RepVGG-A0] (main.py 282): INFO Train: [277/300][50/78]	eta 0:00:54 lr 0.087316	time 1.1709 (1.9598)	loss 2.1747 (2.2093)	grad_norm 0.6257 (0.6247)	mem 39782MB
[2023-07-07 18:01:44 RepVGG-A0] (main.py 282): INFO Train: [277/300][60/78]	eta 0:00:33 lr 0.086322	time 1.2033 (1.8869)	loss 2.1952 (2.2080)	grad_norm 0.6303 (0.6249)	mem 39782MB
[2023-07-07 18:01:59 RepVGG-A0] (main.py 282): INFO Train: [277/300][70/78]	eta 0:00:14 lr 0.085334	time 1.1741 (1.8296)	loss 2.1542 (2.2076)	grad_norm 0.6297 (0.6249)	mem 39782MB
[2023-07-07 18:02:11 RepVGG-A0] (main.py 291): INFO EPOCH 277 training takes 0:02:21
[2023-07-07 18:02:31 RepVGG-A0] (main.py 282): INFO Train: [278/300][0/78]	eta 0:26:21 lr 0.084548	time 20.2715 (20.2715)	loss 2.1961 (2.1961)	grad_norm 0.6245 (0.6245)	mem 39782MB
[2023-07-07 18:02:47 RepVGG-A0] (main.py 282): INFO Train: [278/300][10/78]	eta 0:03:41 lr 0.083569	time 1.1725 (3.2604)	loss 2.1746 (2.1864)	grad_norm 0.6288 (0.6279)	mem 39782MB
[2023-07-07 18:03:01 RepVGG-A0] (main.py 282): INFO Train: [278/300][20/78]	eta 0:02:18 lr 0.082597	time 1.1275 (2.3901)	loss 2.1510 (2.1896)	grad_norm 0.6294 (0.6258)	mem 39782MB
[2023-07-07 18:03:17 RepVGG-A0] (main.py 282): INFO Train: [278/300][30/78]	eta 0:01:42 lr 0.081630	time 1.7450 (2.1458)	loss 2.2404 (2.1995)	grad_norm 0.6267 (0.6270)	mem 39782MB
[2023-07-07 18:03:34 RepVGG-A0] (main.py 282): INFO Train: [278/300][40/78]	eta 0:01:16 lr 0.080668	time 3.3192 (2.0236)	loss 2.1619 (2.2014)	grad_norm 0.6280 (0.6274)	mem 39782MB
[2023-07-07 18:03:49 RepVGG-A0] (main.py 282): INFO Train: [278/300][50/78]	eta 0:00:53 lr 0.079713	time 1.1734 (1.9211)	loss 2.2232 (2.2016)	grad_norm 0.6328 (0.6273)	mem 39782MB
[2023-07-07 18:04:05 RepVGG-A0] (main.py 282): INFO Train: [278/300][60/78]	eta 0:00:33 lr 0.078762	time 1.4888 (1.8800)	loss 2.1655 (2.1990)	grad_norm 0.6323 (0.6273)	mem 39782MB
[2023-07-07 18:04:20 RepVGG-A0] (main.py 282): INFO Train: [278/300][70/78]	eta 0:00:14 lr 0.077818	time 1.1813 (1.8194)	loss 2.1868 (2.1982)	grad_norm 0.6310 (0.6271)	mem 39782MB
[2023-07-07 18:04:32 RepVGG-A0] (main.py 291): INFO EPOCH 278 training takes 0:02:21
[2023-07-07 18:04:54 RepVGG-A0] (main.py 282): INFO Train: [279/300][0/78]	eta 0:29:03 lr 0.077066	time 22.3531 (22.3531)	loss 2.1991 (2.1991)	grad_norm 0.6333 (0.6333)	mem 39782MB
[2023-07-07 18:05:08 RepVGG-A0] (main.py 282): INFO Train: [279/300][10/78]	eta 0:03:44 lr 0.076132	time 1.1817 (3.3076)	loss 2.2333 (2.1647)	grad_norm 0.6290 (0.6256)	mem 39782MB
[2023-07-07 18:05:22 RepVGG-A0] (main.py 282): INFO Train: [279/300][20/78]	eta 0:02:18 lr 0.075203	time 1.1712 (2.3943)	loss 2.1851 (2.1764)	grad_norm 0.6231 (0.6288)	mem 39782MB
[2023-07-07 18:05:38 RepVGG-A0] (main.py 282): INFO Train: [279/300][30/78]	eta 0:01:41 lr 0.074280	time 1.2592 (2.1220)	loss 2.2309 (2.1816)	grad_norm 0.6293 (0.6302)	mem 39782MB
[2023-07-07 18:05:55 RepVGG-A0] (main.py 282): INFO Train: [279/300][40/78]	eta 0:01:17 lr 0.073363	time 3.3051 (2.0375)	loss 2.1956 (2.1865)	grad_norm 0.6336 (0.6288)	mem 39782MB
[2023-07-07 18:06:11 RepVGG-A0] (main.py 282): INFO Train: [279/300][50/78]	eta 0:00:54 lr 0.072451	time 1.1723 (1.9333)	loss 2.1726 (2.1901)	grad_norm 0.6366 (0.6295)	mem 39782MB
[2023-07-07 18:06:26 RepVGG-A0] (main.py 282): INFO Train: [279/300][60/78]	eta 0:00:33 lr 0.071545	time 1.1803 (1.8618)	loss 2.2419 (2.1940)	grad_norm 0.6231 (0.6301)	mem 39782MB
[2023-07-07 18:06:40 RepVGG-A0] (main.py 282): INFO Train: [279/300][70/78]	eta 0:00:14 lr 0.070644	time 1.2227 (1.8103)	loss 2.1922 (2.1969)	grad_norm 0.6338 (0.6305)	mem 39782MB
[2023-07-07 18:06:52 RepVGG-A0] (main.py 291): INFO EPOCH 279 training takes 0:02:20
[2023-07-07 18:07:14 RepVGG-A0] (main.py 282): INFO Train: [280/300][0/78]	eta 0:28:32 lr 0.069928	time 21.9544 (21.9544)	loss 2.1964 (2.1964)	grad_norm 0.6307 (0.6307)	mem 39782MB
[2023-07-07 18:07:29 RepVGG-A0] (main.py 282): INFO Train: [280/300][10/78]	eta 0:03:46 lr 0.069037	time 1.1912 (3.3313)	loss 2.1753 (2.1882)	grad_norm 0.6386 (0.6312)	mem 39782MB
[2023-07-07 18:07:44 RepVGG-A0] (main.py 282): INFO Train: [280/300][20/78]	eta 0:02:22 lr 0.068153	time 1.3519 (2.4620)	loss 2.1930 (2.1876)	grad_norm 0.6311 (0.6313)	mem 39782MB
[2023-07-07 18:07:58 RepVGG-A0] (main.py 282): INFO Train: [280/300][30/78]	eta 0:01:41 lr 0.067273	time 1.1897 (2.1211)	loss 2.2772 (2.1944)	grad_norm 0.6304 (0.6313)	mem 39782MB
[2023-07-07 18:08:17 RepVGG-A0] (main.py 282): INFO Train: [280/300][40/78]	eta 0:01:19 lr 0.066400	time 5.1073 (2.0811)	loss 2.1771 (2.1973)	grad_norm 0.6321 (0.6312)	mem 39782MB
[2023-07-07 18:08:32 RepVGG-A0] (main.py 282): INFO Train: [280/300][50/78]	eta 0:00:54 lr 0.065532	time 1.1906 (1.9619)	loss 2.1433 (2.1978)	grad_norm 0.6427 (0.6314)	mem 39782MB
[2023-07-07 18:08:47 RepVGG-A0] (main.py 282): INFO Train: [280/300][60/78]	eta 0:00:34 lr 0.064670	time 1.3227 (1.8895)	loss 2.1799 (2.1991)	grad_norm 0.6401 (0.6316)	mem 39782MB
[2023-07-07 18:09:03 RepVGG-A0] (main.py 282): INFO Train: [280/300][70/78]	eta 0:00:14 lr 0.063813	time 1.1789 (1.8366)	loss 2.2052 (2.2013)	grad_norm 0.6405 (0.6322)	mem 39782MB
[2023-07-07 18:09:14 RepVGG-A0] (main.py 291): INFO EPOCH 280 training takes 0:02:22
[2023-07-07 18:09:32 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.638 (17.638)	Loss 1.3635 (1.3635)	Acc@1 69.037 (69.037)	Acc@5 88.812 (88.812)	Mem 39782MB
[2023-07-07 18:09:33 RepVGG-A0] (main.py 342): INFO  * Acc@1 69.638 Acc@5 88.854
[2023-07-07 18:09:33 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 280: 69.638%
[2023-07-07 18:09:33 RepVGG-A0] (main.py 172): INFO Max accuracy: 69.64%
[2023-07-07 18:09:52 RepVGG-A0] (main.py 282): INFO Train: [281/300][0/78]	eta 0:24:19 lr 0.063132	time 18.7143 (18.7143)	loss 2.1701 (2.1701)	grad_norm 0.6216 (0.6216)	mem 39782MB
[2023-07-07 18:10:08 RepVGG-A0] (main.py 282): INFO Train: [281/300][10/78]	eta 0:03:36 lr 0.062286	time 1.1718 (3.1886)	loss 2.2389 (2.1709)	grad_norm 0.6274 (0.6287)	mem 39782MB
[2023-07-07 18:10:24 RepVGG-A0] (main.py 282): INFO Train: [281/300][20/78]	eta 0:02:20 lr 0.061445	time 1.3056 (2.4281)	loss 2.1615 (2.1814)	grad_norm 0.6191 (0.6288)	mem 39782MB
[2023-07-07 18:10:39 RepVGG-A0] (main.py 282): INFO Train: [281/300][30/78]	eta 0:01:42 lr 0.060610	time 1.3023 (2.1308)	loss 2.1843 (2.1840)	grad_norm 0.6321 (0.6304)	mem 39782MB
[2023-07-07 18:10:58 RepVGG-A0] (main.py 282): INFO Train: [281/300][40/78]	eta 0:01:18 lr 0.059781	time 2.8761 (2.0576)	loss 2.1592 (2.1866)	grad_norm 0.6289 (0.6306)	mem 39782MB
[2023-07-07 18:11:12 RepVGG-A0] (main.py 282): INFO Train: [281/300][50/78]	eta 0:00:54 lr 0.058957	time 1.1726 (1.9380)	loss 2.1879 (2.1911)	grad_norm 0.6314 (0.6313)	mem 39782MB
[2023-07-07 18:11:28 RepVGG-A0] (main.py 282): INFO Train: [281/300][60/78]	eta 0:00:33 lr 0.058139	time 1.1785 (1.8741)	loss 2.1690 (2.1911)	grad_norm 0.6353 (0.6314)	mem 39782MB
[2023-07-07 18:11:43 RepVGG-A0] (main.py 282): INFO Train: [281/300][70/78]	eta 0:00:14 lr 0.057327	time 1.1723 (1.8294)	loss 2.1746 (2.1908)	grad_norm 0.6258 (0.6322)	mem 39782MB
[2023-07-07 18:11:54 RepVGG-A0] (main.py 291): INFO EPOCH 281 training takes 0:02:21
[2023-07-07 18:12:15 RepVGG-A0] (main.py 282): INFO Train: [282/300][0/78]	eta 0:27:31 lr 0.056681	time 21.1686 (21.1686)	loss 2.1906 (2.1906)	grad_norm 0.6240 (0.6240)	mem 39782MB
[2023-07-07 18:12:32 RepVGG-A0] (main.py 282): INFO Train: [282/300][10/78]	eta 0:03:51 lr 0.055879	time 1.1715 (3.4027)	loss 2.1948 (2.1969)	grad_norm 0.6307 (0.6304)	mem 39782MB
[2023-07-07 18:12:47 RepVGG-A0] (main.py 282): INFO Train: [282/300][20/78]	eta 0:02:24 lr 0.055082	time 1.6360 (2.4975)	loss 2.2096 (2.1932)	grad_norm 0.6330 (0.6300)	mem 39782MB
[2023-07-07 18:13:02 RepVGG-A0] (main.py 282): INFO Train: [282/300][30/78]	eta 0:01:44 lr 0.054291	time 1.1292 (2.1699)	loss 2.1907 (2.1895)	grad_norm 0.6427 (0.6300)	mem 39782MB
[2023-07-07 18:13:20 RepVGG-A0] (main.py 282): INFO Train: [282/300][40/78]	eta 0:01:19 lr 0.053506	time 4.4598 (2.0929)	loss 2.1539 (2.1893)	grad_norm 0.6304 (0.6312)	mem 39782MB
[2023-07-07 18:13:34 RepVGG-A0] (main.py 282): INFO Train: [282/300][50/78]	eta 0:00:54 lr 0.052727	time 1.1733 (1.9640)	loss 2.1650 (2.1891)	grad_norm 0.6291 (0.6317)	mem 39782MB
[2023-07-07 18:13:50 RepVGG-A0] (main.py 282): INFO Train: [282/300][60/78]	eta 0:00:34 lr 0.051953	time 1.4132 (1.8979)	loss 2.1850 (2.1896)	grad_norm 0.6489 (0.6326)	mem 39782MB
[2023-07-07 18:14:05 RepVGG-A0] (main.py 282): INFO Train: [282/300][70/78]	eta 0:00:14 lr 0.051185	time 1.3552 (1.8413)	loss 2.1961 (2.1876)	grad_norm 0.6391 (0.6338)	mem 39782MB
[2023-07-07 18:14:16 RepVGG-A0] (main.py 291): INFO EPOCH 282 training takes 0:02:21
[2023-07-07 18:14:35 RepVGG-A0] (main.py 282): INFO Train: [283/300][0/78]	eta 0:23:56 lr 0.050574	time 18.4186 (18.4186)	loss 2.1877 (2.1877)	grad_norm 0.6352 (0.6352)	mem 39782MB
[2023-07-07 18:14:52 RepVGG-A0] (main.py 282): INFO Train: [283/300][10/78]	eta 0:03:42 lr 0.049816	time 1.1720 (3.2776)	loss 2.1622 (2.1751)	grad_norm 0.6357 (0.6315)	mem 39782MB
[2023-07-07 18:15:07 RepVGG-A0] (main.py 282): INFO Train: [283/300][20/78]	eta 0:02:20 lr 0.049064	time 1.3344 (2.4218)	loss 2.2134 (2.1738)	grad_norm 0.6375 (0.6325)	mem 39782MB
[2023-07-07 18:15:22 RepVGG-A0] (main.py 282): INFO Train: [283/300][30/78]	eta 0:01:41 lr 0.048317	time 1.5053 (2.1072)	loss 2.1375 (2.1774)	grad_norm 0.6477 (0.6340)	mem 39782MB
[2023-07-07 18:15:40 RepVGG-A0] (main.py 282): INFO Train: [283/300][40/78]	eta 0:01:17 lr 0.047576	time 4.6606 (2.0438)	loss 2.1588 (2.1739)	grad_norm 0.6324 (0.6340)	mem 39782MB
[2023-07-07 18:15:54 RepVGG-A0] (main.py 282): INFO Train: [283/300][50/78]	eta 0:00:53 lr 0.046841	time 1.1741 (1.9236)	loss 2.1449 (2.1762)	grad_norm 0.6307 (0.6344)	mem 39782MB
[2023-07-07 18:16:09 RepVGG-A0] (main.py 282): INFO Train: [283/300][60/78]	eta 0:00:33 lr 0.046112	time 1.1728 (1.8538)	loss 2.1924 (2.1794)	grad_norm 0.6432 (0.6346)	mem 39782MB
[2023-07-07 18:16:25 RepVGG-A0] (main.py 282): INFO Train: [283/300][70/78]	eta 0:00:14 lr 0.045388	time 1.2019 (1.8153)	loss 2.2057 (2.1790)	grad_norm 0.6443 (0.6353)	mem 39782MB
[2023-07-07 18:16:37 RepVGG-A0] (main.py 291): INFO EPOCH 283 training takes 0:02:20
[2023-07-07 18:16:59 RepVGG-A0] (main.py 282): INFO Train: [284/300][0/78]	eta 0:28:39 lr 0.044813	time 22.0388 (22.0388)	loss 2.1688 (2.1688)	grad_norm 0.6296 (0.6296)	mem 39782MB
[2023-07-07 18:17:13 RepVGG-A0] (main.py 282): INFO Train: [284/300][10/78]	eta 0:03:43 lr 0.044099	time 1.1938 (3.2866)	loss 2.1265 (2.1518)	grad_norm 0.6321 (0.6322)	mem 39782MB
[2023-07-07 18:17:28 RepVGG-A0] (main.py 282): INFO Train: [284/300][20/78]	eta 0:02:20 lr 0.043391	time 1.1788 (2.4298)	loss 2.2001 (2.1553)	grad_norm 0.6344 (0.6327)	mem 39782MB
[2023-07-07 18:17:42 RepVGG-A0] (main.py 282): INFO Train: [284/300][30/78]	eta 0:01:41 lr 0.042689	time 1.2109 (2.1148)	loss 2.1915 (2.1680)	grad_norm 0.6331 (0.6334)	mem 39782MB
[2023-07-07 18:18:01 RepVGG-A0] (main.py 282): INFO Train: [284/300][40/78]	eta 0:01:18 lr 0.041992	time 4.2730 (2.0542)	loss 2.2084 (2.1719)	grad_norm 0.6395 (0.6343)	mem 39782MB
[2023-07-07 18:18:16 RepVGG-A0] (main.py 282): INFO Train: [284/300][50/78]	eta 0:00:54 lr 0.041301	time 1.1737 (1.9589)	loss 2.1923 (2.1723)	grad_norm 0.6439 (0.6352)	mem 39782MB
[2023-07-07 18:18:31 RepVGG-A0] (main.py 282): INFO Train: [284/300][60/78]	eta 0:00:33 lr 0.040616	time 1.1959 (1.8696)	loss 2.2250 (2.1729)	grad_norm 0.6367 (0.6358)	mem 39782MB
[2023-07-07 18:18:45 RepVGG-A0] (main.py 282): INFO Train: [284/300][70/78]	eta 0:00:14 lr 0.039937	time 1.1881 (1.8100)	loss 2.1098 (2.1714)	grad_norm 0.6448 (0.6363)	mem 39782MB
[2023-07-07 18:18:57 RepVGG-A0] (main.py 291): INFO EPOCH 284 training takes 0:02:20
[2023-07-07 18:19:19 RepVGG-A0] (main.py 282): INFO Train: [285/300][0/78]	eta 0:28:19 lr 0.039397	time 21.7856 (21.7856)	loss 2.2449 (2.2449)	grad_norm 0.6319 (0.6319)	mem 39782MB
[2023-07-07 18:19:33 RepVGG-A0] (main.py 282): INFO Train: [285/300][10/78]	eta 0:03:41 lr 0.038728	time 1.1718 (3.2549)	loss 2.1724 (2.1844)	grad_norm 0.6371 (0.6377)	mem 39782MB
[2023-07-07 18:19:48 RepVGG-A0] (main.py 282): INFO Train: [285/300][20/78]	eta 0:02:20 lr 0.038065	time 1.1748 (2.4209)	loss 2.2304 (2.1758)	grad_norm 0.6384 (0.6370)	mem 39782MB
[2023-07-07 18:20:03 RepVGG-A0] (main.py 282): INFO Train: [285/300][30/78]	eta 0:01:42 lr 0.037407	time 1.1828 (2.1296)	loss 2.1780 (2.1748)	grad_norm 0.6332 (0.6374)	mem 39782MB
[2023-07-07 18:20:22 RepVGG-A0] (main.py 282): INFO Train: [285/300][40/78]	eta 0:01:18 lr 0.036755	time 2.9029 (2.0585)	loss 2.2148 (2.1707)	grad_norm 0.6368 (0.6371)	mem 39782MB
[2023-07-07 18:20:37 RepVGG-A0] (main.py 282): INFO Train: [285/300][50/78]	eta 0:00:54 lr 0.036108	time 1.2446 (1.9616)	loss 2.1688 (2.1706)	grad_norm 0.6503 (0.6375)	mem 39782MB
[2023-07-07 18:20:52 RepVGG-A0] (main.py 282): INFO Train: [285/300][60/78]	eta 0:00:33 lr 0.035467	time 1.6255 (1.8855)	loss 2.1271 (2.1725)	grad_norm 0.6346 (0.6379)	mem 39782MB
[2023-07-07 18:21:08 RepVGG-A0] (main.py 282): INFO Train: [285/300][70/78]	eta 0:00:14 lr 0.034832	time 1.3962 (1.8356)	loss 2.1315 (2.1748)	grad_norm 0.6494 (0.6384)	mem 39782MB
[2023-07-07 18:21:19 RepVGG-A0] (main.py 291): INFO EPOCH 285 training takes 0:02:21
[2023-07-07 18:21:40 RepVGG-A0] (main.py 282): INFO Train: [286/300][0/78]	eta 0:28:08 lr 0.034329	time 21.6428 (21.6428)	loss 2.1324 (2.1324)	grad_norm 0.6346 (0.6346)	mem 39782MB
[2023-07-07 18:21:55 RepVGG-A0] (main.py 282): INFO Train: [286/300][10/78]	eta 0:03:46 lr 0.033704	time 1.1724 (3.3237)	loss 2.1990 (2.1598)	grad_norm 0.6388 (0.6375)	mem 39782MB
[2023-07-07 18:22:11 RepVGG-A0] (main.py 282): INFO Train: [286/300][20/78]	eta 0:02:23 lr 0.033085	time 1.2445 (2.4770)	loss 2.2022 (2.1688)	grad_norm 0.6456 (0.6377)	mem 39782MB
[2023-07-07 18:22:27 RepVGG-A0] (main.py 282): INFO Train: [286/300][30/78]	eta 0:01:45 lr 0.032471	time 1.4669 (2.1877)	loss 2.2501 (2.1684)	grad_norm 0.6315 (0.6382)	mem 39782MB
[2023-07-07 18:22:43 RepVGG-A0] (main.py 282): INFO Train: [286/300][40/78]	eta 0:01:18 lr 0.031864	time 3.2778 (2.0641)	loss 2.1124 (2.1669)	grad_norm 0.6351 (0.6383)	mem 39782MB
[2023-07-07 18:22:58 RepVGG-A0] (main.py 282): INFO Train: [286/300][50/78]	eta 0:00:54 lr 0.031262	time 1.1725 (1.9544)	loss 2.1639 (2.1649)	grad_norm 0.6456 (0.6389)	mem 39782MB
[2023-07-07 18:23:14 RepVGG-A0] (main.py 282): INFO Train: [286/300][60/78]	eta 0:00:33 lr 0.030666	time 1.1785 (1.8854)	loss 2.2083 (2.1649)	grad_norm 0.6461 (0.6393)	mem 39782MB
[2023-07-07 18:23:29 RepVGG-A0] (main.py 282): INFO Train: [286/300][70/78]	eta 0:00:14 lr 0.030075	time 1.3030 (1.8372)	loss 2.1423 (2.1658)	grad_norm 0.6385 (0.6391)	mem 39782MB
[2023-07-07 18:23:41 RepVGG-A0] (main.py 291): INFO EPOCH 286 training takes 0:02:22
[2023-07-07 18:24:02 RepVGG-A0] (main.py 282): INFO Train: [287/300][0/78]	eta 0:27:41 lr 0.029607	time 21.3039 (21.3039)	loss 2.1179 (2.1179)	grad_norm 0.6271 (0.6271)	mem 39782MB
[2023-07-07 18:24:16 RepVGG-A0] (main.py 282): INFO Train: [287/300][10/78]	eta 0:03:35 lr 0.029027	time 1.1719 (3.1687)	loss 2.1597 (2.1514)	grad_norm 0.6414 (0.6348)	mem 39782MB
[2023-07-07 18:24:30 RepVGG-A0] (main.py 282): INFO Train: [287/300][20/78]	eta 0:02:16 lr 0.028452	time 1.1743 (2.3539)	loss 2.1640 (2.1551)	grad_norm 0.6405 (0.6372)	mem 39782MB
[2023-07-07 18:24:47 RepVGG-A0] (main.py 282): INFO Train: [287/300][30/78]	eta 0:01:42 lr 0.027883	time 1.3344 (2.1433)	loss 2.1540 (2.1601)	grad_norm 0.6416 (0.6386)	mem 39782MB
[2023-07-07 18:25:04 RepVGG-A0] (main.py 282): INFO Train: [287/300][40/78]	eta 0:01:17 lr 0.027320	time 4.3709 (2.0284)	loss 2.1754 (2.1626)	grad_norm 0.6366 (0.6384)	mem 39782MB
[2023-07-07 18:25:19 RepVGG-A0] (main.py 282): INFO Train: [287/300][50/78]	eta 0:00:53 lr 0.026763	time 1.1732 (1.9241)	loss 2.2027 (2.1616)	grad_norm 0.6437 (0.6379)	mem 39782MB
[2023-07-07 18:25:34 RepVGG-A0] (main.py 282): INFO Train: [287/300][60/78]	eta 0:00:33 lr 0.026211	time 1.3533 (1.8577)	loss 2.1462 (2.1625)	grad_norm 0.6364 (0.6377)	mem 39782MB
[2023-07-07 18:25:49 RepVGG-A0] (main.py 282): INFO Train: [287/300][70/78]	eta 0:00:14 lr 0.025666	time 1.2330 (1.8098)	loss 2.2057 (2.1643)	grad_norm 0.6396 (0.6378)	mem 39782MB
[2023-07-07 18:26:02 RepVGG-A0] (main.py 291): INFO EPOCH 287 training takes 0:02:20
[2023-07-07 18:26:23 RepVGG-A0] (main.py 282): INFO Train: [288/300][0/78]	eta 0:28:10 lr 0.025233	time 21.6737 (21.6737)	loss 2.0993 (2.0993)	grad_norm 0.6299 (0.6299)	mem 39782MB
[2023-07-07 18:26:39 RepVGG-A0] (main.py 282): INFO Train: [288/300][10/78]	eta 0:03:49 lr 0.024697	time 1.1893 (3.3747)	loss 2.1253 (2.1432)	grad_norm 0.6283 (0.6344)	mem 39782MB
[2023-07-07 18:26:53 RepVGG-A0] (main.py 282): INFO Train: [288/300][20/78]	eta 0:02:22 lr 0.024167	time 1.1787 (2.4544)	loss 2.0950 (2.1496)	grad_norm 0.6313 (0.6354)	mem 39782MB
[2023-07-07 18:27:09 RepVGG-A0] (main.py 282): INFO Train: [288/300][30/78]	eta 0:01:43 lr 0.023643	time 1.4538 (2.1551)	loss 2.1407 (2.1556)	grad_norm 0.6364 (0.6366)	mem 39782MB
[2023-07-07 18:27:26 RepVGG-A0] (main.py 282): INFO Train: [288/300][40/78]	eta 0:01:18 lr 0.023125	time 3.7321 (2.0582)	loss 2.1986 (2.1542)	grad_norm 0.6396 (0.6369)	mem 39782MB
[2023-07-07 18:27:41 RepVGG-A0] (main.py 282): INFO Train: [288/300][50/78]	eta 0:00:54 lr 0.022612	time 1.1738 (1.9564)	loss 2.1654 (2.1581)	grad_norm 0.6432 (0.6380)	mem 39782MB
[2023-07-07 18:27:57 RepVGG-A0] (main.py 282): INFO Train: [288/300][60/78]	eta 0:00:34 lr 0.022105	time 1.1994 (1.8893)	loss 2.1478 (2.1590)	grad_norm 0.6505 (0.6383)	mem 39782MB
[2023-07-07 18:28:13 RepVGG-A0] (main.py 282): INFO Train: [288/300][70/78]	eta 0:00:14 lr 0.021604	time 1.3257 (1.8461)	loss 2.1222 (2.1586)	grad_norm 0.6443 (0.6382)	mem 39782MB
[2023-07-07 18:28:23 RepVGG-A0] (main.py 291): INFO EPOCH 288 training takes 0:02:21
[2023-07-07 18:28:45 RepVGG-A0] (main.py 282): INFO Train: [289/300][0/78]	eta 0:28:22 lr 0.021207	time 21.8206 (21.8206)	loss 2.1554 (2.1554)	grad_norm 0.6301 (0.6301)	mem 39782MB
[2023-07-07 18:28:59 RepVGG-A0] (main.py 282): INFO Train: [289/300][10/78]	eta 0:03:43 lr 0.020716	time 1.1730 (3.2818)	loss 2.1953 (2.1613)	grad_norm 0.6348 (0.6334)	mem 39782MB
[2023-07-07 18:29:14 RepVGG-A0] (main.py 282): INFO Train: [289/300][20/78]	eta 0:02:18 lr 0.020231	time 1.1715 (2.3933)	loss 2.1118 (2.1598)	grad_norm 0.6334 (0.6342)	mem 39782MB
[2023-07-07 18:29:29 RepVGG-A0] (main.py 282): INFO Train: [289/300][30/78]	eta 0:01:41 lr 0.019752	time 1.2092 (2.1188)	loss 2.1551 (2.1581)	grad_norm 0.6473 (0.6355)	mem 39782MB
[2023-07-07 18:29:47 RepVGG-A0] (main.py 282): INFO Train: [289/300][40/78]	eta 0:01:17 lr 0.019278	time 3.2527 (2.0313)	loss 2.2200 (2.1564)	grad_norm 0.6360 (0.6361)	mem 39782MB
[2023-07-07 18:30:02 RepVGG-A0] (main.py 282): INFO Train: [289/300][50/78]	eta 0:00:54 lr 0.018810	time 1.1732 (1.9330)	loss 2.1010 (2.1563)	grad_norm 0.6379 (0.6367)	mem 39782MB
[2023-07-07 18:30:17 RepVGG-A0] (main.py 282): INFO Train: [289/300][60/78]	eta 0:00:33 lr 0.018348	time 1.3205 (1.8651)	loss 2.1829 (2.1569)	grad_norm 0.6434 (0.6373)	mem 39782MB
[2023-07-07 18:30:32 RepVGG-A0] (main.py 282): INFO Train: [289/300][70/78]	eta 0:00:14 lr 0.017891	time 1.4833 (1.8117)	loss 2.1957 (2.1592)	grad_norm 0.6380 (0.6376)	mem 39782MB
[2023-07-07 18:30:44 RepVGG-A0] (main.py 291): INFO EPOCH 289 training takes 0:02:20
[2023-07-07 18:31:05 RepVGG-A0] (main.py 282): INFO Train: [290/300][0/78]	eta 0:27:57 lr 0.017530	time 21.5123 (21.5123)	loss 2.1946 (2.1946)	grad_norm 0.6331 (0.6331)	mem 39782MB
[2023-07-07 18:31:20 RepVGG-A0] (main.py 282): INFO Train: [290/300][10/78]	eta 0:03:45 lr 0.017084	time 1.1714 (3.3235)	loss 2.1494 (2.1425)	grad_norm 0.6345 (0.6371)	mem 39782MB
[2023-07-07 18:31:36 RepVGG-A0] (main.py 282): INFO Train: [290/300][20/78]	eta 0:02:23 lr 0.016643	time 1.1746 (2.4767)	loss 2.1449 (2.1395)	grad_norm 0.6403 (0.6375)	mem 39782MB
[2023-07-07 18:31:51 RepVGG-A0] (main.py 282): INFO Train: [290/300][30/78]	eta 0:01:43 lr 0.016209	time 1.3983 (2.1616)	loss 2.1788 (2.1448)	grad_norm 0.6392 (0.6381)	mem 39782MB
[2023-07-07 18:32:09 RepVGG-A0] (main.py 282): INFO Train: [290/300][40/78]	eta 0:01:19 lr 0.015780	time 4.0303 (2.0829)	loss 2.1260 (2.1499)	grad_norm 0.6362 (0.6382)	mem 39782MB
[2023-07-07 18:32:24 RepVGG-A0] (main.py 282): INFO Train: [290/300][50/78]	eta 0:00:55 lr 0.015356	time 1.1401 (1.9675)	loss 2.1492 (2.1517)	grad_norm 0.6442 (0.6385)	mem 39782MB
[2023-07-07 18:32:39 RepVGG-A0] (main.py 282): INFO Train: [290/300][60/78]	eta 0:00:33 lr 0.014939	time 1.3573 (1.8880)	loss 2.2110 (2.1511)	grad_norm 0.6374 (0.6388)	mem 39782MB
[2023-07-07 18:32:55 RepVGG-A0] (main.py 282): INFO Train: [290/300][70/78]	eta 0:00:14 lr 0.014527	time 1.5364 (1.8416)	loss 2.1477 (2.1527)	grad_norm 0.6340 (0.6390)	mem 39782MB
[2023-07-07 18:33:06 RepVGG-A0] (main.py 291): INFO EPOCH 290 training takes 0:02:21
[2023-07-07 18:33:23 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.729 (17.729)	Loss 1.3477 (1.3477)	Acc@1 70.551 (70.551)	Acc@5 89.075 (89.075)	Mem 39782MB
[2023-07-07 18:33:24 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.714 Acc@5 89.520
[2023-07-07 18:33:24 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 290: 70.714%
[2023-07-07 18:33:24 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:33:46 RepVGG-A0] (main.py 282): INFO Train: [291/300][0/78]	eta 0:27:50 lr 0.014202	time 21.4181 (21.4181)	loss 2.0824 (2.0824)	grad_norm 0.6434 (0.6434)	mem 39782MB
[2023-07-07 18:34:01 RepVGG-A0] (main.py 282): INFO Train: [291/300][10/78]	eta 0:03:48 lr 0.013800	time 1.1914 (3.3632)	loss 2.2348 (2.1394)	grad_norm 0.6438 (0.6372)	mem 39782MB
[2023-07-07 18:34:15 RepVGG-A0] (main.py 282): INFO Train: [291/300][20/78]	eta 0:02:20 lr 0.013405	time 1.1730 (2.4190)	loss 2.1732 (2.1405)	grad_norm 0.6340 (0.6360)	mem 39782MB
[2023-07-07 18:34:30 RepVGG-A0] (main.py 282): INFO Train: [291/300][30/78]	eta 0:01:41 lr 0.013015	time 1.3645 (2.1075)	loss 2.1263 (2.1505)	grad_norm 0.6422 (0.6367)	mem 39782MB
[2023-07-07 18:34:48 RepVGG-A0] (main.py 282): INFO Train: [291/300][40/78]	eta 0:01:17 lr 0.012630	time 3.3677 (2.0322)	loss 2.1932 (2.1564)	grad_norm 0.6372 (0.6366)	mem 39782MB
[2023-07-07 18:35:03 RepVGG-A0] (main.py 282): INFO Train: [291/300][50/78]	eta 0:00:53 lr 0.012252	time 1.1276 (1.9230)	loss 2.1244 (2.1520)	grad_norm 0.6398 (0.6368)	mem 39782MB
[2023-07-07 18:35:17 RepVGG-A0] (main.py 282): INFO Train: [291/300][60/78]	eta 0:00:33 lr 0.011879	time 1.1765 (1.8419)	loss 2.1230 (2.1503)	grad_norm 0.6288 (0.6369)	mem 39782MB
[2023-07-07 18:35:31 RepVGG-A0] (main.py 282): INFO Train: [291/300][70/78]	eta 0:00:14 lr 0.011512	time 1.1918 (1.7885)	loss 2.1892 (2.1509)	grad_norm 0.6503 (0.6372)	mem 39782MB
[2023-07-07 18:35:44 RepVGG-A0] (main.py 291): INFO EPOCH 291 training takes 0:02:19
[2023-07-07 18:36:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.302 (17.302)	Loss 1.3313 (1.3313)	Acc@1 70.636 (70.636)	Acc@5 89.459 (89.459)	Mem 39782MB
[2023-07-07 18:36:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.680 Acc@5 89.592
[2023-07-07 18:36:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 291: 70.680%
[2023-07-07 18:36:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:36:25 RepVGG-A0] (main.py 282): INFO Train: [292/300][0/78]	eta 0:28:57 lr 0.011223	time 22.2786 (22.2786)	loss 2.1226 (2.1226)	grad_norm 0.6248 (0.6248)	mem 39782MB
[2023-07-07 18:36:39 RepVGG-A0] (main.py 282): INFO Train: [292/300][10/78]	eta 0:03:47 lr 0.010866	time 1.1997 (3.3421)	loss 2.1332 (2.1431)	grad_norm 0.6354 (0.6333)	mem 39782MB
[2023-07-07 18:36:52 RepVGG-A0] (main.py 282): INFO Train: [292/300][20/78]	eta 0:02:17 lr 0.010515	time 1.1731 (2.3662)	loss 2.1610 (2.1429)	grad_norm 0.6346 (0.6351)	mem 39782MB
[2023-07-07 18:37:09 RepVGG-A0] (main.py 282): INFO Train: [292/300][30/78]	eta 0:01:43 lr 0.010170	time 1.6083 (2.1478)	loss 2.1791 (2.1386)	grad_norm 0.6324 (0.6356)	mem 39782MB
[2023-07-07 18:37:24 RepVGG-A0] (main.py 282): INFO Train: [292/300][40/78]	eta 0:01:15 lr 0.009831	time 1.3022 (1.9916)	loss 2.1462 (2.1339)	grad_norm 0.6360 (0.6356)	mem 39782MB
[2023-07-07 18:37:42 RepVGG-A0] (main.py 282): INFO Train: [292/300][50/78]	eta 0:00:54 lr 0.009497	time 1.3736 (1.9539)	loss 2.1361 (2.1399)	grad_norm 0.6320 (0.6359)	mem 39782MB
[2023-07-07 18:37:57 RepVGG-A0] (main.py 282): INFO Train: [292/300][60/78]	eta 0:00:33 lr 0.009169	time 1.3276 (1.8785)	loss 2.1173 (2.1403)	grad_norm 0.6324 (0.6360)	mem 39782MB
[2023-07-07 18:38:12 RepVGG-A0] (main.py 282): INFO Train: [292/300][70/78]	eta 0:00:14 lr 0.008847	time 1.2792 (1.8273)	loss 2.1438 (2.1413)	grad_norm 0.6374 (0.6361)	mem 39782MB
[2023-07-07 18:38:24 RepVGG-A0] (main.py 291): INFO EPOCH 292 training takes 0:02:21
[2023-07-07 18:38:41 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.243 (17.243)	Loss 1.3228 (1.3228)	Acc@1 70.398 (70.398)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:38:42 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.696 Acc@5 89.542
[2023-07-07 18:38:42 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 292: 70.696%
[2023-07-07 18:38:42 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:39:04 RepVGG-A0] (main.py 282): INFO Train: [293/300][0/78]	eta 0:28:24 lr 0.008594	time 21.8548 (21.8548)	loss 2.1774 (2.1774)	grad_norm 0.6353 (0.6353)	mem 39782MB
[2023-07-07 18:39:19 RepVGG-A0] (main.py 282): INFO Train: [293/300][10/78]	eta 0:03:46 lr 0.008282	time 1.1716 (3.3340)	loss 2.0886 (2.1470)	grad_norm 0.6343 (0.6344)	mem 39782MB
[2023-07-07 18:39:34 RepVGG-A0] (main.py 282): INFO Train: [293/300][20/78]	eta 0:02:22 lr 0.007976	time 1.2621 (2.4585)	loss 2.1540 (2.1432)	grad_norm 0.6426 (0.6347)	mem 39782MB
[2023-07-07 18:39:48 RepVGG-A0] (main.py 282): INFO Train: [293/300][30/78]	eta 0:01:42 lr 0.007676	time 1.4400 (2.1313)	loss 2.1363 (2.1427)	grad_norm 0.6335 (0.6353)	mem 39782MB
[2023-07-07 18:40:06 RepVGG-A0] (main.py 282): INFO Train: [293/300][40/78]	eta 0:01:17 lr 0.007381	time 3.1014 (2.0445)	loss 2.0833 (2.1415)	grad_norm 0.6293 (0.6353)	mem 39782MB
[2023-07-07 18:40:21 RepVGG-A0] (main.py 282): INFO Train: [293/300][50/78]	eta 0:00:54 lr 0.007092	time 1.1728 (1.9332)	loss 2.1352 (2.1407)	grad_norm 0.6350 (0.6354)	mem 39782MB
[2023-07-07 18:40:37 RepVGG-A0] (main.py 282): INFO Train: [293/300][60/78]	eta 0:00:33 lr 0.006809	time 1.3676 (1.8754)	loss 2.1204 (2.1376)	grad_norm 0.6328 (0.6346)	mem 39782MB
[2023-07-07 18:40:51 RepVGG-A0] (main.py 282): INFO Train: [293/300][70/78]	eta 0:00:14 lr 0.006532	time 1.4240 (1.8197)	loss 2.0828 (2.1357)	grad_norm 0.6330 (0.6345)	mem 39782MB
[2023-07-07 18:41:04 RepVGG-A0] (main.py 291): INFO EPOCH 293 training takes 0:02:21
[2023-07-07 18:41:21 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.201 (17.201)	Loss 1.3155 (1.3155)	Acc@1 70.862 (70.862)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:41:22 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.908 Acc@5 89.588
[2023-07-07 18:41:22 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 293: 70.908%
[2023-07-07 18:41:22 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:41:45 RepVGG-A0] (main.py 282): INFO Train: [294/300][0/78]	eta 0:29:26 lr 0.006314	time 22.6520 (22.6520)	loss 2.1597 (2.1597)	grad_norm 0.6317 (0.6317)	mem 39782MB
[2023-07-07 18:41:59 RepVGG-A0] (main.py 282): INFO Train: [294/300][10/78]	eta 0:03:49 lr 0.006048	time 1.1711 (3.3744)	loss 2.1226 (2.1375)	grad_norm 0.6324 (0.6331)	mem 39782MB
[2023-07-07 18:42:13 RepVGG-A0] (main.py 282): INFO Train: [294/300][20/78]	eta 0:02:21 lr 0.005786	time 1.1733 (2.4355)	loss 2.1495 (2.1386)	grad_norm 0.6389 (0.6340)	mem 39782MB
[2023-07-07 18:42:29 RepVGG-A0] (main.py 282): INFO Train: [294/300][30/78]	eta 0:01:42 lr 0.005531	time 1.1930 (2.1450)	loss 2.1732 (2.1408)	grad_norm 0.6441 (0.6348)	mem 39782MB
[2023-07-07 18:42:47 RepVGG-A0] (main.py 282): INFO Train: [294/300][40/78]	eta 0:01:18 lr 0.005281	time 3.9552 (2.0729)	loss 2.1908 (2.1415)	grad_norm 0.6303 (0.6342)	mem 39782MB
[2023-07-07 18:43:01 RepVGG-A0] (main.py 282): INFO Train: [294/300][50/78]	eta 0:00:54 lr 0.005038	time 1.1723 (1.9489)	loss 2.1498 (2.1418)	grad_norm 0.6358 (0.6345)	mem 39782MB
[2023-07-07 18:43:16 RepVGG-A0] (main.py 282): INFO Train: [294/300][60/78]	eta 0:00:33 lr 0.004800	time 1.3457 (1.8746)	loss 2.2040 (2.1411)	grad_norm 0.6295 (0.6341)	mem 39782MB
[2023-07-07 18:43:32 RepVGG-A0] (main.py 282): INFO Train: [294/300][70/78]	eta 0:00:14 lr 0.004567	time 1.3542 (1.8285)	loss 2.0964 (2.1410)	grad_norm 0.6185 (0.6338)	mem 39782MB
[2023-07-07 18:43:43 RepVGG-A0] (main.py 291): INFO EPOCH 294 training takes 0:02:20
[2023-07-07 18:44:00 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.480 (17.480)	Loss 1.3250 (1.3250)	Acc@1 70.532 (70.532)	Acc@5 89.752 (89.752)	Mem 39782MB
[2023-07-07 18:44:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.842 Acc@5 89.598
[2023-07-07 18:44:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 294: 70.842%
[2023-07-07 18:44:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:44:23 RepVGG-A0] (main.py 282): INFO Train: [295/300][0/78]	eta 0:27:19 lr 0.004385	time 21.0168 (21.0168)	loss 2.1260 (2.1260)	grad_norm 0.6282 (0.6282)	mem 39782MB
[2023-07-07 18:44:38 RepVGG-A0] (main.py 282): INFO Train: [295/300][10/78]	eta 0:03:42 lr 0.004164	time 1.1701 (3.2759)	loss 2.1483 (2.1224)	grad_norm 0.6271 (0.6331)	mem 39782MB
[2023-07-07 18:44:52 RepVGG-A0] (main.py 282): INFO Train: [295/300][20/78]	eta 0:02:18 lr 0.003947	time 1.1725 (2.3957)	loss 2.1639 (2.1371)	grad_norm 0.6318 (0.6325)	mem 39782MB
[2023-07-07 18:45:07 RepVGG-A0] (main.py 282): INFO Train: [295/300][30/78]	eta 0:01:41 lr 0.003737	time 1.3295 (2.1184)	loss 2.1638 (2.1433)	grad_norm 0.6297 (0.6330)	mem 39782MB
[2023-07-07 18:45:25 RepVGG-A0] (main.py 282): INFO Train: [295/300][40/78]	eta 0:01:17 lr 0.003532	time 3.2288 (2.0296)	loss 2.2110 (2.1452)	grad_norm 0.6445 (0.6335)	mem 39782MB
[2023-07-07 18:45:40 RepVGG-A0] (main.py 282): INFO Train: [295/300][50/78]	eta 0:00:54 lr 0.003333	time 1.1739 (1.9341)	loss 2.1079 (2.1436)	grad_norm 0.6327 (0.6334)	mem 39782MB
[2023-07-07 18:45:55 RepVGG-A0] (main.py 282): INFO Train: [295/300][60/78]	eta 0:00:33 lr 0.003140	time 1.3530 (1.8630)	loss 2.1638 (2.1427)	grad_norm 0.6386 (0.6334)	mem 39782MB
[2023-07-07 18:46:10 RepVGG-A0] (main.py 282): INFO Train: [295/300][70/78]	eta 0:00:14 lr 0.002953	time 1.1265 (1.8038)	loss 2.1338 (2.1423)	grad_norm 0.6326 (0.6333)	mem 39782MB
[2023-07-07 18:46:22 RepVGG-A0] (main.py 291): INFO EPOCH 295 training takes 0:02:20
[2023-07-07 18:46:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.253 (17.253)	Loss 1.3213 (1.3213)	Acc@1 70.807 (70.807)	Acc@5 89.526 (89.526)	Mem 39782MB
[2023-07-07 18:46:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.834 Acc@5 89.672
[2023-07-07 18:46:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 295: 70.834%
[2023-07-07 18:46:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:47:03 RepVGG-A0] (main.py 282): INFO Train: [296/300][0/78]	eta 0:29:09 lr 0.002807	time 22.4328 (22.4328)	loss 2.1783 (2.1783)	grad_norm 0.6409 (0.6409)	mem 39782MB
[2023-07-07 18:47:18 RepVGG-A0] (main.py 282): INFO Train: [296/300][10/78]	eta 0:03:48 lr 0.002630	time 1.1732 (3.3669)	loss 2.1835 (2.1467)	grad_norm 0.6360 (0.6313)	mem 39782MB
[2023-07-07 18:47:32 RepVGG-A0] (main.py 282): INFO Train: [296/300][20/78]	eta 0:02:21 lr 0.002459	time 1.1955 (2.4435)	loss 2.1135 (2.1486)	grad_norm 0.6263 (0.6316)	mem 39782MB
[2023-07-07 18:47:48 RepVGG-A0] (main.py 282): INFO Train: [296/300][30/78]	eta 0:01:44 lr 0.002293	time 1.9622 (2.1872)	loss 2.0826 (2.1445)	grad_norm 0.6213 (0.6309)	mem 39782MB
[2023-07-07 18:48:05 RepVGG-A0] (main.py 282): INFO Train: [296/300][40/78]	eta 0:01:17 lr 0.002133	time 3.6854 (2.0472)	loss 2.1334 (2.1387)	grad_norm 0.6220 (0.6305)	mem 39782MB
[2023-07-07 18:48:20 RepVGG-A0] (main.py 282): INFO Train: [296/300][50/78]	eta 0:00:54 lr 0.001979	time 1.1724 (1.9424)	loss 2.1323 (2.1368)	grad_norm 0.6307 (0.6305)	mem 39782MB
[2023-07-07 18:48:35 RepVGG-A0] (main.py 282): INFO Train: [296/300][60/78]	eta 0:00:33 lr 0.001831	time 1.3942 (1.8814)	loss 2.1564 (2.1372)	grad_norm 0.6358 (0.6309)	mem 39782MB
[2023-07-07 18:48:51 RepVGG-A0] (main.py 282): INFO Train: [296/300][70/78]	eta 0:00:14 lr 0.001689	time 1.7929 (1.8418)	loss 2.1388 (2.1370)	grad_norm 0.6276 (0.6312)	mem 39782MB
[2023-07-07 18:49:02 RepVGG-A0] (main.py 291): INFO EPOCH 296 training takes 0:02:21
[2023-07-07 18:49:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.545 (17.545)	Loss 1.3167 (1.3167)	Acc@1 70.837 (70.837)	Acc@5 89.807 (89.807)	Mem 39782MB
[2023-07-07 18:49:21 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.906 Acc@5 89.658
[2023-07-07 18:49:21 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 296: 70.906%
[2023-07-07 18:49:21 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:49:41 RepVGG-A0] (main.py 282): INFO Train: [297/300][0/78]	eta 0:26:57 lr 0.001579	time 20.7385 (20.7385)	loss 2.1197 (2.1197)	grad_norm 0.6238 (0.6238)	mem 39782MB
[2023-07-07 18:49:57 RepVGG-A0] (main.py 282): INFO Train: [297/300][10/78]	eta 0:03:42 lr 0.001447	time 1.1721 (3.2723)	loss 2.1246 (2.1355)	grad_norm 0.6274 (0.6294)	mem 39782MB
[2023-07-07 18:50:12 RepVGG-A0] (main.py 282): INFO Train: [297/300][20/78]	eta 0:02:20 lr 0.001321	time 1.1745 (2.4295)	loss 2.1815 (2.1480)	grad_norm 0.6337 (0.6296)	mem 39782MB
[2023-07-07 18:50:27 RepVGG-A0] (main.py 282): INFO Train: [297/300][30/78]	eta 0:01:42 lr 0.001200	time 1.3825 (2.1404)	loss 2.1454 (2.1475)	grad_norm 0.6343 (0.6302)	mem 39782MB
[2023-07-07 18:50:44 RepVGG-A0] (main.py 282): INFO Train: [297/300][40/78]	eta 0:01:17 lr 0.001085	time 3.6899 (2.0381)	loss 2.1025 (2.1437)	grad_norm 0.6336 (0.6305)	mem 39782MB
[2023-07-07 18:51:00 RepVGG-A0] (main.py 282): INFO Train: [297/300][50/78]	eta 0:00:54 lr 0.000976	time 1.1894 (1.9419)	loss 2.1530 (2.1438)	grad_norm 0.6287 (0.6300)	mem 39782MB
[2023-07-07 18:51:15 RepVGG-A0] (main.py 282): INFO Train: [297/300][60/78]	eta 0:00:33 lr 0.000873	time 1.3405 (1.8697)	loss 2.1608 (2.1455)	grad_norm 0.6384 (0.6298)	mem 39782MB
[2023-07-07 18:51:31 RepVGG-A0] (main.py 282): INFO Train: [297/300][70/78]	eta 0:00:14 lr 0.000776	time 1.2782 (1.8381)	loss 2.1180 (2.1443)	grad_norm 0.6278 (0.6301)	mem 39782MB
[2023-07-07 18:51:42 RepVGG-A0] (main.py 291): INFO EPOCH 297 training takes 0:02:21
[2023-07-07 18:51:59 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.027 (17.027)	Loss 1.3204 (1.3204)	Acc@1 70.703 (70.703)	Acc@5 89.709 (89.709)	Mem 39782MB
[2023-07-07 18:52:01 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.910 Acc@5 89.666
[2023-07-07 18:52:01 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 297: 70.910%
[2023-07-07 18:52:01 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:52:24 RepVGG-A0] (main.py 282): INFO Train: [298/300][0/78]	eta 0:29:17 lr 0.000702	time 22.5360 (22.5360)	loss 2.1364 (2.1364)	grad_norm 0.6243 (0.6243)	mem 39782MB
[2023-07-07 18:52:37 RepVGG-A0] (main.py 282): INFO Train: [298/300][10/78]	eta 0:03:44 lr 0.000615	time 1.1745 (3.2966)	loss 2.1551 (2.1323)	grad_norm 0.6289 (0.6289)	mem 39782MB
[2023-07-07 18:52:52 RepVGG-A0] (main.py 282): INFO Train: [298/300][20/78]	eta 0:02:20 lr 0.000533	time 1.4684 (2.4301)	loss 2.1861 (2.1439)	grad_norm 0.6324 (0.6287)	mem 39782MB
[2023-07-07 18:53:07 RepVGG-A0] (main.py 282): INFO Train: [298/300][30/78]	eta 0:01:42 lr 0.000458	time 1.2023 (2.1342)	loss 2.1423 (2.1454)	grad_norm 0.6304 (0.6298)	mem 39782MB
[2023-07-07 18:53:26 RepVGG-A0] (main.py 282): INFO Train: [298/300][40/78]	eta 0:01:18 lr 0.000388	time 3.9276 (2.0757)	loss 2.1452 (2.1450)	grad_norm 0.6381 (0.6295)	mem 39782MB
[2023-07-07 18:53:41 RepVGG-A0] (main.py 282): INFO Train: [298/300][50/78]	eta 0:00:55 lr 0.000324	time 1.2629 (1.9666)	loss 2.2054 (2.1433)	grad_norm 0.6352 (0.6292)	mem 39782MB
[2023-07-07 18:53:56 RepVGG-A0] (main.py 282): INFO Train: [298/300][60/78]	eta 0:00:33 lr 0.000266	time 1.2127 (1.8835)	loss 2.1195 (2.1379)	grad_norm 0.6251 (0.6291)	mem 39782MB
[2023-07-07 18:54:11 RepVGG-A0] (main.py 282): INFO Train: [298/300][70/78]	eta 0:00:14 lr 0.000213	time 1.3948 (1.8315)	loss 2.1295 (2.1392)	grad_norm 0.6323 (0.6295)	mem 39782MB
[2023-07-07 18:54:23 RepVGG-A0] (main.py 291): INFO EPOCH 298 training takes 0:02:21
[2023-07-07 18:54:40 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.101 (17.101)	Loss 1.3234 (1.3234)	Acc@1 70.844 (70.844)	Acc@5 89.368 (89.368)	Mem 39782MB
[2023-07-07 18:54:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.926 Acc@5 89.596
[2023-07-07 18:54:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 298: 70.926%
[2023-07-07 18:54:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:55:02 RepVGG-A0] (main.py 282): INFO Train: [299/300][0/78]	eta 0:27:05 lr 0.000175	time 20.8375 (20.8375)	loss 2.1426 (2.1426)	grad_norm 0.6278 (0.6278)	mem 39782MB
[2023-07-07 18:55:18 RepVGG-A0] (main.py 282): INFO Train: [299/300][10/78]	eta 0:03:45 lr 0.000133	time 1.1724 (3.3196)	loss 2.1268 (2.1367)	grad_norm 0.6257 (0.6300)	mem 39782MB
[2023-07-07 18:55:33 RepVGG-A0] (main.py 282): INFO Train: [299/300][20/78]	eta 0:02:21 lr 0.000097	time 1.1942 (2.4471)	loss 2.1740 (2.1444)	grad_norm 0.6276 (0.6300)	mem 39782MB
[2023-07-07 18:55:48 RepVGG-A0] (main.py 282): INFO Train: [299/300][30/78]	eta 0:01:43 lr 0.000066	time 1.4359 (2.1570)	loss 2.1934 (2.1427)	grad_norm 0.6263 (0.6297)	mem 39782MB
[2023-07-07 18:56:06 RepVGG-A0] (main.py 282): INFO Train: [299/300][40/78]	eta 0:01:18 lr 0.000042	time 2.8448 (2.0577)	loss 2.1340 (2.1379)	grad_norm 0.6283 (0.6291)	mem 39782MB
[2023-07-07 18:56:21 RepVGG-A0] (main.py 282): INFO Train: [299/300][50/78]	eta 0:00:54 lr 0.000023	time 1.1734 (1.9426)	loss 2.1390 (2.1358)	grad_norm 0.6304 (0.6295)	mem 39782MB
[2023-07-07 18:56:35 RepVGG-A0] (main.py 282): INFO Train: [299/300][60/78]	eta 0:00:33 lr 0.000009	time 1.1722 (1.8612)	loss 2.1305 (2.1348)	grad_norm 0.6289 (0.6294)	mem 39782MB
[2023-07-07 18:56:50 RepVGG-A0] (main.py 282): INFO Train: [299/300][70/78]	eta 0:00:14 lr 0.000002	time 1.3911 (1.8173)	loss 2.1636 (2.1355)	grad_norm 0.6317 (0.6294)	mem 39782MB
[2023-07-07 18:57:02 RepVGG-A0] (main.py 291): INFO EPOCH 299 training takes 0:02:20
[2023-07-07 18:57:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.016 (17.016)	Loss 1.3233 (1.3233)	Acc@1 70.471 (70.471)	Acc@5 89.478 (89.478)	Mem 39782MB
[2023-07-07 18:57:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.892 Acc@5 89.628
[2023-07-07 18:57:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 299: 70.892%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 194): INFO Training time 11:54:08
