[2023-07-07 06:57:03 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 7
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 06:57:06 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 06:57:06 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 06:57:07 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 06:57:07 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 06:58:00 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 1:08:48 lr 0.000000	time 52.9338 (52.9338)	loss 6.9410 (6.9410)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 06:58:12 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:06:41 lr 0.164103	time 1.2074 (5.9082)	loss 6.8737 (6.9127)	grad_norm 0.3863 (0.4375)	mem 39782MB
[2023-07-07 06:58:25 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:36 lr 0.328205	time 1.2967 (3.7246)	loss 6.8288 (6.8824)	grad_norm 0.6087 (0.4656)	mem 39782MB
[2023-07-07 06:58:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:22 lr 0.492308	time 1.3581 (2.9725)	loss 6.6805 (6.8429)	grad_norm 0.3451 (0.4584)	mem 39782MB
[2023-07-07 06:58:52 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:37 lr 0.656410	time 1.3054 (2.5742)	loss 6.6049 (6.8025)	grad_norm 0.2875 (0.4779)	mem 39782MB
[2023-07-07 06:59:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:06 lr 0.820513	time 2.1815 (2.3620)	loss 6.5671 (6.7546)	grad_norm 0.4756 (0.4584)	mem 39782MB
[2023-07-07 06:59:24 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:40 lr 0.984615	time 1.9468 (2.2506)	loss 6.5322 (6.7181)	grad_norm 0.2836 (0.4587)	mem 39782MB
[2023-07-07 06:59:39 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:17 lr 1.148718	time 1.1560 (2.1491)	loss 6.4120 (6.6867)	grad_norm 0.2158 (0.4426)	mem 39782MB
[2023-07-07 06:59:50 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:43
[2023-07-07 07:01:01 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 4096
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 4096
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 7
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 12.8
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:01:05 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:01:05 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:01:05 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:01:05 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:09 RepVGG-A0] (main.py 422): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 2048
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /root/datasets/imagenet/
  IMG_SIZE: 224
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 2048
  TEST_SIZE: 224
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 7
MODEL:
  ARCH: RepVGG-A0
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: /cosmos/youmin/QARepVGG/first_try/RepVGG-A0/train_from_scratch
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: train_from_scratch
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 6.4
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: true
  WARMUP_EPOCHS: 5
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-07-07 07:03:12 RepVGG-A0] (main.py 84): INFO Creating model:RepVGG-A0
[2023-07-07 07:03:12 RepVGG-A0] (main.py 89): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (rbr_dense): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (rbr_1x1): Sequential(
      (conv): Conv2d(3, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
    )
    (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_identity): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (rbr_whbn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (rbr_dense): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (rbr_1x1): Sequential(
        (conv): Conv2d(192, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (rbr_whbn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1280, out_features=1000, bias=True)
)
[2023-07-07 07:03:12 RepVGG-A0] (main.py 106): INFO number of params: 9103304
[2023-07-07 07:03:12 RepVGG-A0] (main.py 155): INFO Start training
[2023-07-07 07:03:55 RepVGG-A0] (main.py 282): INFO Train: [0/300][0/78]	eta 0:56:13 lr 0.000000	time 43.2479 (43.2479)	loss 6.9410 (6.9410)	grad_norm 0.4532 (0.4532)	mem 39782MB
[2023-07-07 07:04:07 RepVGG-A0] (main.py 282): INFO Train: [0/300][10/78]	eta 0:05:41 lr 0.164103	time 1.1696 (5.0183)	loss 6.8727 (6.9129)	grad_norm 0.3837 (0.4372)	mem 39782MB
[2023-07-07 07:04:20 RepVGG-A0] (main.py 282): INFO Train: [0/300][20/78]	eta 0:03:06 lr 0.328205	time 1.1720 (3.2159)	loss 6.8045 (6.8786)	grad_norm 0.6673 (0.4541)	mem 39782MB
[2023-07-07 07:04:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][30/78]	eta 0:02:04 lr 0.492308	time 1.1722 (2.5842)	loss 6.7150 (6.8464)	grad_norm 0.3204 (0.5029)	mem 39782MB
[2023-07-07 07:04:45 RepVGG-A0] (main.py 282): INFO Train: [0/300][40/78]	eta 0:01:26 lr 0.656410	time 1.1721 (2.2744)	loss 6.6039 (6.8003)	grad_norm 0.2427 (0.4866)	mem 39782MB
[2023-07-07 07:05:02 RepVGG-A0] (main.py 282): INFO Train: [0/300][50/78]	eta 0:01:00 lr 0.820513	time 2.4285 (2.1500)	loss 6.5320 (6.7567)	grad_norm 0.2072 (0.4704)	mem 39782MB
[2023-07-07 07:05:17 RepVGG-A0] (main.py 282): INFO Train: [0/300][60/78]	eta 0:00:36 lr 0.984615	time 1.4081 (2.0432)	loss 6.4556 (6.7121)	grad_norm 0.3638 (0.4523)	mem 39782MB
[2023-07-07 07:05:32 RepVGG-A0] (main.py 282): INFO Train: [0/300][70/78]	eta 0:00:15 lr 1.148718	time 1.1740 (1.9721)	loss 6.3620 (6.6710)	grad_norm 0.2930 (0.4425)	mem 39782MB
[2023-07-07 07:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 0 training takes 0:02:32
[2023-07-07 07:06:02 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.530 (17.530)	Loss 8.4176 (8.4176)	Acc@1 0.433 (0.433)	Acc@5 1.807 (1.807)	Mem 39782MB
[2023-07-07 07:06:04 RepVGG-A0] (main.py 342): INFO  * Acc@1 0.438 Acc@5 1.750
[2023-07-07 07:06:04 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 0: 0.438%
[2023-07-07 07:06:04 RepVGG-A0] (main.py 172): INFO Max accuracy: 0.44%
[2023-07-07 07:06:25 RepVGG-A0] (main.py 282): INFO Train: [1/300][0/78]	eta 0:27:44 lr 1.280000	time 21.3409 (21.3409)	loss 6.4175 (6.4175)	grad_norm 0.3022 (0.3022)	mem 39782MB
[2023-07-07 07:06:39 RepVGG-A0] (main.py 282): INFO Train: [1/300][10/78]	eta 0:03:36 lr 1.444103	time 1.1710 (3.1877)	loss 6.2801 (6.3308)	grad_norm 0.2858 (0.3078)	mem 39782MB
[2023-07-07 07:06:53 RepVGG-A0] (main.py 282): INFO Train: [1/300][20/78]	eta 0:02:15 lr 1.608205	time 1.1956 (2.3412)	loss 6.2977 (6.3001)	grad_norm 0.3848 (0.3558)	mem 39782MB
[2023-07-07 07:07:09 RepVGG-A0] (main.py 282): INFO Train: [1/300][30/78]	eta 0:01:39 lr 1.772308	time 1.3068 (2.0821)	loss 6.1750 (6.2695)	grad_norm 0.3921 (0.3527)	mem 39782MB
[2023-07-07 07:07:28 RepVGG-A0] (main.py 282): INFO Train: [1/300][40/78]	eta 0:01:17 lr 1.936410	time 4.3363 (2.0525)	loss 6.0961 (6.2390)	grad_norm 0.3742 (0.3538)	mem 39782MB
[2023-07-07 07:07:44 RepVGG-A0] (main.py 282): INFO Train: [1/300][50/78]	eta 0:00:54 lr 2.100513	time 1.1698 (1.9513)	loss 6.1492 (6.2127)	grad_norm 0.5806 (0.3590)	mem 39782MB
[2023-07-07 07:07:59 RepVGG-A0] (main.py 282): INFO Train: [1/300][60/78]	eta 0:00:33 lr 2.264615	time 1.3215 (1.8780)	loss 6.0572 (6.1891)	grad_norm 0.4412 (0.3583)	mem 39782MB
[2023-07-07 07:08:14 RepVGG-A0] (main.py 282): INFO Train: [1/300][70/78]	eta 0:00:14 lr 2.428718	time 1.3964 (1.8334)	loss 5.9474 (6.1596)	grad_norm 0.4348 (0.3595)	mem 39782MB
[2023-07-07 07:08:25 RepVGG-A0] (main.py 291): INFO EPOCH 1 training takes 0:02:21
[2023-07-07 07:08:47 RepVGG-A0] (main.py 282): INFO Train: [2/300][0/78]	eta 0:28:02 lr 2.560000	time 21.5711 (21.5711)	loss 5.7935 (5.7935)	grad_norm 0.3089 (0.3089)	mem 39782MB
[2023-07-07 07:09:01 RepVGG-A0] (main.py 282): INFO Train: [2/300][10/78]	eta 0:03:39 lr 2.724103	time 1.1884 (3.2273)	loss 5.8069 (5.8712)	grad_norm 0.3208 (0.3754)	mem 39782MB
[2023-07-07 07:09:16 RepVGG-A0] (main.py 282): INFO Train: [2/300][20/78]	eta 0:02:19 lr 2.888205	time 1.1726 (2.3988)	loss 5.8612 (5.8554)	grad_norm 0.5859 (0.3874)	mem 39782MB
[2023-07-07 07:09:31 RepVGG-A0] (main.py 282): INFO Train: [2/300][30/78]	eta 0:01:41 lr 3.052308	time 1.3605 (2.1124)	loss 5.8284 (5.8764)	grad_norm 0.3534 (0.3930)	mem 39782MB
[2023-07-07 07:09:49 RepVGG-A0] (main.py 282): INFO Train: [2/300][40/78]	eta 0:01:17 lr 3.216410	time 3.5433 (2.0272)	loss 5.6493 (5.8547)	grad_norm 0.2448 (0.3795)	mem 39782MB
[2023-07-07 07:10:04 RepVGG-A0] (main.py 282): INFO Train: [2/300][50/78]	eta 0:00:54 lr 3.380513	time 1.3505 (1.9303)	loss 5.6007 (5.8203)	grad_norm 0.2856 (0.3737)	mem 39782MB
[2023-07-07 07:10:20 RepVGG-A0] (main.py 282): INFO Train: [2/300][60/78]	eta 0:00:33 lr 3.544615	time 1.3078 (1.8746)	loss 5.6070 (5.7867)	grad_norm 0.3870 (0.3667)	mem 39782MB
[2023-07-07 07:10:35 RepVGG-A0] (main.py 282): INFO Train: [2/300][70/78]	eta 0:00:14 lr 3.708718	time 1.3852 (1.8208)	loss 5.4769 (5.7632)	grad_norm 0.2952 (0.3666)	mem 39782MB
[2023-07-07 07:10:47 RepVGG-A0] (main.py 291): INFO EPOCH 2 training takes 0:02:21
[2023-07-07 07:11:07 RepVGG-A0] (main.py 282): INFO Train: [3/300][0/78]	eta 0:26:33 lr 3.840000	time 20.4243 (20.4243)	loss 5.5129 (5.5129)	grad_norm 0.4211 (0.4211)	mem 39782MB
[2023-07-07 07:11:22 RepVGG-A0] (main.py 282): INFO Train: [3/300][10/78]	eta 0:03:35 lr 4.004103	time 1.1899 (3.1754)	loss 5.5814 (5.7004)	grad_norm 0.3348 (0.4536)	mem 39782MB
[2023-07-07 07:11:37 RepVGG-A0] (main.py 282): INFO Train: [3/300][20/78]	eta 0:02:18 lr 4.168205	time 1.1711 (2.3833)	loss 5.5343 (5.6420)	grad_norm 0.2892 (0.3932)	mem 39782MB
[2023-07-07 07:11:52 RepVGG-A0] (main.py 282): INFO Train: [3/300][30/78]	eta 0:01:41 lr 4.332308	time 2.0470 (2.1205)	loss 5.5118 (5.5762)	grad_norm 0.4183 (0.3690)	mem 39782MB
[2023-07-07 07:12:09 RepVGG-A0] (main.py 282): INFO Train: [3/300][40/78]	eta 0:01:16 lr 4.496410	time 3.7355 (2.0094)	loss 5.3820 (5.5213)	grad_norm 0.4425 (0.3594)	mem 39782MB
[2023-07-07 07:12:24 RepVGG-A0] (main.py 282): INFO Train: [3/300][50/78]	eta 0:00:53 lr 4.660513	time 1.1726 (1.8992)	loss 5.3994 (5.5140)	grad_norm 0.3540 (0.3620)	mem 39782MB
[2023-07-07 07:12:39 RepVGG-A0] (main.py 282): INFO Train: [3/300][60/78]	eta 0:00:33 lr 4.824615	time 1.1741 (1.8374)	loss 5.3165 (5.4761)	grad_norm 0.3398 (0.3547)	mem 39782MB
[2023-07-07 07:12:53 RepVGG-A0] (main.py 282): INFO Train: [3/300][70/78]	eta 0:00:14 lr 4.988718	time 1.2704 (1.7815)	loss 5.1191 (5.4388)	grad_norm 0.3245 (0.3490)	mem 39782MB
[2023-07-07 07:13:05 RepVGG-A0] (main.py 291): INFO EPOCH 3 training takes 0:02:18
[2023-07-07 07:13:26 RepVGG-A0] (main.py 282): INFO Train: [4/300][0/78]	eta 0:27:05 lr 5.120000	time 20.8414 (20.8414)	loss 5.0564 (5.0564)	grad_norm 0.3194 (0.3194)	mem 39782MB
[2023-07-07 07:13:40 RepVGG-A0] (main.py 282): INFO Train: [4/300][10/78]	eta 0:03:38 lr 5.284103	time 1.1939 (3.2131)	loss 5.2924 (5.2471)	grad_norm 0.3480 (0.3871)	mem 39782MB
[2023-07-07 07:13:55 RepVGG-A0] (main.py 282): INFO Train: [4/300][20/78]	eta 0:02:17 lr 5.448205	time 1.1724 (2.3751)	loss 5.1015 (5.2119)	grad_norm 0.3079 (0.3590)	mem 39782MB
[2023-07-07 07:14:10 RepVGG-A0] (main.py 282): INFO Train: [4/300][30/78]	eta 0:01:40 lr 5.612308	time 1.2658 (2.0920)	loss 5.1198 (5.1726)	grad_norm 0.4055 (0.3539)	mem 39782MB
[2023-07-07 07:14:28 RepVGG-A0] (main.py 282): INFO Train: [4/300][40/78]	eta 0:01:16 lr 5.776410	time 4.7256 (2.0262)	loss 5.1092 (5.2021)	grad_norm 0.2796 (0.3646)	mem 39782MB
[2023-07-07 07:14:44 RepVGG-A0] (main.py 282): INFO Train: [4/300][50/78]	eta 0:00:54 lr 5.940513	time 1.3374 (1.9301)	loss 5.1225 (5.1977)	grad_norm 0.2789 (0.3640)	mem 39782MB
[2023-07-07 07:14:59 RepVGG-A0] (main.py 282): INFO Train: [4/300][60/78]	eta 0:00:33 lr 6.104615	time 1.1747 (1.8591)	loss 5.0068 (5.1636)	grad_norm 0.4101 (0.3544)	mem 39782MB
[2023-07-07 07:15:14 RepVGG-A0] (main.py 282): INFO Train: [4/300][70/78]	eta 0:00:14 lr 6.268718	time 1.2920 (1.8151)	loss 4.8888 (5.1327)	grad_norm 0.3424 (0.3485)	mem 39782MB
[2023-07-07 07:15:26 RepVGG-A0] (main.py 291): INFO EPOCH 4 training takes 0:02:20
[2023-07-07 07:15:47 RepVGG-A0] (main.py 282): INFO Train: [5/300][0/78]	eta 0:27:49 lr 6.395615	time 21.3994 (21.3994)	loss 4.9994 (4.9994)	grad_norm 0.3501 (0.3501)	mem 39782MB
[2023-07-07 07:16:03 RepVGG-A0] (main.py 282): INFO Train: [5/300][10/78]	eta 0:03:48 lr 6.395387	time 1.1737 (3.3608)	loss 4.8068 (4.9072)	grad_norm 0.3121 (0.3207)	mem 39782MB
[2023-07-07 07:16:17 RepVGG-A0] (main.py 282): INFO Train: [5/300][20/78]	eta 0:02:20 lr 6.395153	time 1.2856 (2.4275)	loss 4.7085 (4.8608)	grad_norm 0.3066 (0.3194)	mem 39782MB
[2023-07-07 07:16:33 RepVGG-A0] (main.py 282): INFO Train: [5/300][30/78]	eta 0:01:43 lr 6.394914	time 1.2215 (2.1606)	loss 4.7888 (4.8392)	grad_norm 0.3153 (0.3274)	mem 39782MB
[2023-07-07 07:16:50 RepVGG-A0] (main.py 282): INFO Train: [5/300][40/78]	eta 0:01:18 lr 6.394669	time 3.6889 (2.0562)	loss 4.7571 (4.8270)	grad_norm 0.4065 (0.3341)	mem 39782MB
[2023-07-07 07:17:05 RepVGG-A0] (main.py 282): INFO Train: [5/300][50/78]	eta 0:00:54 lr 6.394418	time 1.1715 (1.9395)	loss 4.6881 (4.8201)	grad_norm 0.3186 (0.3363)	mem 39782MB
[2023-07-07 07:17:20 RepVGG-A0] (main.py 282): INFO Train: [5/300][60/78]	eta 0:00:33 lr 6.394162	time 1.1399 (1.8659)	loss 4.6606 (4.8039)	grad_norm 0.2947 (0.3370)	mem 39782MB
[2023-07-07 07:17:35 RepVGG-A0] (main.py 282): INFO Train: [5/300][70/78]	eta 0:00:14 lr 6.393899	time 1.3458 (1.8185)	loss 4.7976 (4.7904)	grad_norm 0.3928 (0.3394)	mem 39782MB
[2023-07-07 07:17:47 RepVGG-A0] (main.py 291): INFO EPOCH 5 training takes 0:02:21
[2023-07-07 07:18:09 RepVGG-A0] (main.py 282): INFO Train: [6/300][0/78]	eta 0:28:29 lr 6.393686	time 21.9126 (21.9126)	loss 4.5676 (4.5676)	grad_norm 0.3199 (0.3199)	mem 39782MB
[2023-07-07 07:18:24 RepVGG-A0] (main.py 282): INFO Train: [6/300][10/78]	eta 0:03:47 lr 6.393413	time 1.1707 (3.3467)	loss 4.6762 (4.5935)	grad_norm 0.3654 (0.3503)	mem 39782MB
[2023-07-07 07:18:38 RepVGG-A0] (main.py 282): INFO Train: [6/300][20/78]	eta 0:02:21 lr 6.393134	time 1.1962 (2.4432)	loss 4.6103 (4.5692)	grad_norm 0.4356 (0.3452)	mem 39782MB
[2023-07-07 07:18:53 RepVGG-A0] (main.py 282): INFO Train: [6/300][30/78]	eta 0:01:41 lr 6.392850	time 1.1295 (2.1214)	loss 4.7284 (4.6752)	grad_norm 0.3324 (0.3829)	mem 39782MB
[2023-07-07 07:19:11 RepVGG-A0] (main.py 282): INFO Train: [6/300][40/78]	eta 0:01:17 lr 6.392560	time 3.0300 (2.0418)	loss 4.6555 (4.6575)	grad_norm 0.3424 (0.3618)	mem 39782MB
[2023-07-07 07:19:27 RepVGG-A0] (main.py 282): INFO Train: [6/300][50/78]	eta 0:00:54 lr 6.392265	time 1.1711 (1.9521)	loss 4.4753 (4.6302)	grad_norm 0.2716 (0.3537)	mem 39782MB
[2023-07-07 07:19:42 RepVGG-A0] (main.py 282): INFO Train: [6/300][60/78]	eta 0:00:33 lr 6.391963	time 1.1944 (1.8816)	loss 4.5657 (4.6027)	grad_norm 0.4000 (0.3523)	mem 39782MB
[2023-07-07 07:19:57 RepVGG-A0] (main.py 282): INFO Train: [6/300][70/78]	eta 0:00:14 lr 6.391656	time 1.2037 (1.8296)	loss 4.3720 (4.5806)	grad_norm 0.3288 (0.3490)	mem 39782MB
[2023-07-07 07:20:09 RepVGG-A0] (main.py 291): INFO EPOCH 6 training takes 0:02:22
[2023-07-07 07:20:31 RepVGG-A0] (main.py 282): INFO Train: [7/300][0/78]	eta 0:27:50 lr 6.391406	time 21.4183 (21.4183)	loss 4.8628 (4.8628)	grad_norm 0.6078 (0.6078)	mem 39782MB
[2023-07-07 07:20:45 RepVGG-A0] (main.py 282): INFO Train: [7/300][10/78]	eta 0:03:39 lr 6.391089	time 1.1715 (3.2244)	loss 5.0475 (5.2194)	grad_norm 0.3224 (0.5314)	mem 39782MB
[2023-07-07 07:20:59 RepVGG-A0] (main.py 282): INFO Train: [7/300][20/78]	eta 0:02:18 lr 6.390766	time 1.1720 (2.3803)	loss 4.5625 (5.0006)	grad_norm 0.2351 (0.4205)	mem 39782MB
[2023-07-07 07:21:14 RepVGG-A0] (main.py 282): INFO Train: [7/300][30/78]	eta 0:01:41 lr 6.390437	time 1.2039 (2.1043)	loss 4.3732 (4.8624)	grad_norm 0.2142 (0.3827)	mem 39782MB
[2023-07-07 07:21:34 RepVGG-A0] (main.py 282): INFO Train: [7/300][40/78]	eta 0:01:18 lr 6.390102	time 3.8793 (2.0571)	loss 4.3599 (4.7409)	grad_norm 0.3031 (0.3593)	mem 39782MB
[2023-07-07 07:21:50 RepVGG-A0] (main.py 282): INFO Train: [7/300][50/78]	eta 0:00:55 lr 6.389761	time 1.2674 (1.9705)	loss 4.4511 (4.6681)	grad_norm 0.3885 (0.3520)	mem 39782MB
[2023-07-07 07:22:05 RepVGG-A0] (main.py 282): INFO Train: [7/300][60/78]	eta 0:00:34 lr 6.389415	time 1.2995 (1.8966)	loss 4.2528 (4.6134)	grad_norm 0.2802 (0.3473)	mem 39782MB
[2023-07-07 07:22:20 RepVGG-A0] (main.py 282): INFO Train: [7/300][70/78]	eta 0:00:14 lr 6.389063	time 1.1764 (1.8380)	loss 4.4029 (4.5770)	grad_norm 0.3772 (0.3502)	mem 39782MB
[2023-07-07 07:22:31 RepVGG-A0] (main.py 291): INFO EPOCH 7 training takes 0:02:21
[2023-07-07 07:22:53 RepVGG-A0] (main.py 282): INFO Train: [8/300][0/78]	eta 0:28:12 lr 6.388777	time 21.6988 (21.6988)	loss 4.2877 (4.2877)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 07:23:06 RepVGG-A0] (main.py 282): INFO Train: [8/300][10/78]	eta 0:03:36 lr 6.388415	time 1.1709 (3.1853)	loss 4.1751 (4.2452)	grad_norm 0.3247 (0.3365)	mem 39782MB
[2023-07-07 07:23:20 RepVGG-A0] (main.py 282): INFO Train: [8/300][20/78]	eta 0:02:16 lr 6.388047	time 1.1907 (2.3449)	loss 4.3209 (4.2767)	grad_norm 0.3676 (0.3602)	mem 39782MB
[2023-07-07 07:23:35 RepVGG-A0] (main.py 282): INFO Train: [8/300][30/78]	eta 0:01:39 lr 6.387673	time 1.1365 (2.0784)	loss 4.2721 (4.2680)	grad_norm 0.3572 (0.3583)	mem 39782MB
[2023-07-07 07:23:54 RepVGG-A0] (main.py 282): INFO Train: [8/300][40/78]	eta 0:01:16 lr 6.387293	time 4.2412 (2.0160)	loss 4.0840 (4.2408)	grad_norm 0.3285 (0.3522)	mem 39782MB
[2023-07-07 07:24:09 RepVGG-A0] (main.py 282): INFO Train: [8/300][50/78]	eta 0:00:53 lr 6.386908	time 1.1727 (1.9172)	loss 4.1152 (4.2337)	grad_norm 0.3480 (0.3560)	mem 39782MB
[2023-07-07 07:24:23 RepVGG-A0] (main.py 282): INFO Train: [8/300][60/78]	eta 0:00:33 lr 6.386517	time 1.2017 (1.8414)	loss 4.0578 (4.2202)	grad_norm 0.3056 (0.3526)	mem 39782MB
[2023-07-07 07:24:39 RepVGG-A0] (main.py 282): INFO Train: [8/300][70/78]	eta 0:00:14 lr 6.386120	time 1.2958 (1.8042)	loss 4.6913 (4.2420)	grad_norm 0.5369 (0.3675)	mem 39782MB
[2023-07-07 07:24:51 RepVGG-A0] (main.py 291): INFO EPOCH 8 training takes 0:02:20
[2023-07-07 07:25:13 RepVGG-A0] (main.py 282): INFO Train: [9/300][0/78]	eta 0:28:39 lr 6.385798	time 22.0423 (22.0423)	loss 4.5626 (4.5626)	grad_norm 0.3629 (0.3629)	mem 39782MB
[2023-07-07 07:25:27 RepVGG-A0] (main.py 282): INFO Train: [9/300][10/78]	eta 0:03:40 lr 6.385391	time 1.1704 (3.2464)	loss 4.1043 (4.2938)	grad_norm 0.2382 (0.2936)	mem 39782MB
[2023-07-07 07:25:43 RepVGG-A0] (main.py 282): INFO Train: [9/300][20/78]	eta 0:02:21 lr 6.384978	time 1.1814 (2.4463)	loss 4.1148 (4.2250)	grad_norm 0.3011 (0.2995)	mem 39782MB
[2023-07-07 07:25:57 RepVGG-A0] (main.py 282): INFO Train: [9/300][30/78]	eta 0:01:42 lr 6.384560	time 1.4070 (2.1268)	loss 3.9352 (4.1828)	grad_norm 0.2605 (0.3031)	mem 39782MB
[2023-07-07 07:26:14 RepVGG-A0] (main.py 282): INFO Train: [9/300][40/78]	eta 0:01:16 lr 6.384135	time 2.7170 (2.0224)	loss 4.0245 (4.1574)	grad_norm 0.3226 (0.3117)	mem 39782MB
[2023-07-07 07:26:30 RepVGG-A0] (main.py 282): INFO Train: [9/300][50/78]	eta 0:00:54 lr 6.383705	time 1.1749 (1.9360)	loss 4.4033 (4.1672)	grad_norm 0.4367 (0.3327)	mem 39782MB
[2023-07-07 07:26:45 RepVGG-A0] (main.py 282): INFO Train: [9/300][60/78]	eta 0:00:33 lr 6.383269	time 1.1776 (1.8655)	loss 4.1049 (4.1536)	grad_norm 0.3265 (0.3286)	mem 39782MB
[2023-07-07 07:27:00 RepVGG-A0] (main.py 282): INFO Train: [9/300][70/78]	eta 0:00:14 lr 6.382827	time 1.3996 (1.8115)	loss 3.9915 (4.1315)	grad_norm 0.3517 (0.3280)	mem 39782MB
[2023-07-07 07:27:11 RepVGG-A0] (main.py 291): INFO EPOCH 9 training takes 0:02:19
[2023-07-07 07:27:32 RepVGG-A0] (main.py 282): INFO Train: [10/300][0/78]	eta 0:27:10 lr 6.382470	time 20.9102 (20.9102)	loss 4.3033 (4.3033)	grad_norm 0.4651 (0.4651)	mem 39782MB
[2023-07-07 07:27:47 RepVGG-A0] (main.py 282): INFO Train: [10/300][10/78]	eta 0:03:40 lr 6.382018	time 1.1708 (3.2446)	loss 3.9509 (4.0862)	grad_norm 0.3140 (0.3522)	mem 39782MB
[2023-07-07 07:28:02 RepVGG-A0] (main.py 282): INFO Train: [10/300][20/78]	eta 0:02:20 lr 6.381560	time 1.2089 (2.4153)	loss 4.0714 (4.0512)	grad_norm 0.3932 (0.3513)	mem 39782MB
[2023-07-07 07:28:16 RepVGG-A0] (main.py 282): INFO Train: [10/300][30/78]	eta 0:01:41 lr 6.381097	time 1.2667 (2.1120)	loss 4.2179 (4.0226)	grad_norm 0.4598 (0.3468)	mem 39782MB
[2023-07-07 07:28:34 RepVGG-A0] (main.py 282): INFO Train: [10/300][40/78]	eta 0:01:17 lr 6.380628	time 3.6807 (2.0355)	loss 3.9921 (4.0378)	grad_norm 0.3532 (0.3555)	mem 39782MB
[2023-07-07 07:28:50 RepVGG-A0] (main.py 282): INFO Train: [10/300][50/78]	eta 0:00:54 lr 6.380153	time 1.1734 (1.9415)	loss 4.0047 (4.0333)	grad_norm 0.3167 (0.3534)	mem 39782MB
[2023-07-07 07:29:05 RepVGG-A0] (main.py 282): INFO Train: [10/300][60/78]	eta 0:00:33 lr 6.379672	time 1.1813 (1.8760)	loss 4.0153 (4.0222)	grad_norm 0.3627 (0.3533)	mem 39782MB
[2023-07-07 07:29:21 RepVGG-A0] (main.py 282): INFO Train: [10/300][70/78]	eta 0:00:14 lr 6.379186	time 1.3854 (1.8348)	loss 3.8692 (4.0130)	grad_norm 0.3247 (0.3522)	mem 39782MB
[2023-07-07 07:29:33 RepVGG-A0] (main.py 291): INFO EPOCH 10 training takes 0:02:21
[2023-07-07 07:29:55 RepVGG-A0] (main.py 282): INFO Train: [11/300][0/78]	eta 0:28:45 lr 6.378793	time 22.1279 (22.1279)	loss 4.3243 (4.3243)	grad_norm 0.4965 (0.4965)	mem 39782MB
[2023-07-07 07:30:09 RepVGG-A0] (main.py 282): INFO Train: [11/300][10/78]	eta 0:03:45 lr 6.378296	time 1.1910 (3.3203)	loss 4.5735 (4.6172)	grad_norm 0.4137 (0.5417)	mem 39782MB
[2023-07-07 07:30:24 RepVGG-A0] (main.py 282): INFO Train: [11/300][20/78]	eta 0:02:20 lr 6.377794	time 1.2711 (2.4161)	loss 3.9549 (4.4196)	grad_norm 0.2363 (0.4263)	mem 39782MB
[2023-07-07 07:30:39 RepVGG-A0] (main.py 282): INFO Train: [11/300][30/78]	eta 0:01:43 lr 6.377286	time 1.3725 (2.1460)	loss 3.8950 (4.2835)	grad_norm 0.2683 (0.3847)	mem 39782MB
[2023-07-07 07:30:57 RepVGG-A0] (main.py 282): INFO Train: [11/300][40/78]	eta 0:01:18 lr 6.376772	time 3.5698 (2.0601)	loss 3.9102 (4.1897)	grad_norm 0.3163 (0.3636)	mem 39782MB
[2023-07-07 07:31:12 RepVGG-A0] (main.py 282): INFO Train: [11/300][50/78]	eta 0:00:54 lr 6.376252	time 1.1711 (1.9446)	loss 3.8875 (4.1227)	grad_norm 0.3426 (0.3517)	mem 39782MB
[2023-07-07 07:31:28 RepVGG-A0] (main.py 282): INFO Train: [11/300][60/78]	eta 0:00:33 lr 6.375727	time 1.2870 (1.8831)	loss 3.8402 (4.1005)	grad_norm 0.3005 (0.3552)	mem 39782MB
[2023-07-07 07:31:42 RepVGG-A0] (main.py 282): INFO Train: [11/300][70/78]	eta 0:00:14 lr 6.375196	time 1.3163 (1.8250)	loss 4.2426 (4.0844)	grad_norm 0.5178 (0.3610)	mem 39782MB
[2023-07-07 07:31:54 RepVGG-A0] (main.py 291): INFO EPOCH 11 training takes 0:02:21
[2023-07-07 07:32:16 RepVGG-A0] (main.py 282): INFO Train: [12/300][0/78]	eta 0:28:08 lr 6.374767	time 21.6461 (21.6461)	loss 4.0045 (4.0045)	grad_norm 0.3421 (0.3421)	mem 39782MB
[2023-07-07 07:32:30 RepVGG-A0] (main.py 282): INFO Train: [12/300][10/78]	eta 0:03:43 lr 6.374226	time 1.1712 (3.2810)	loss 3.9091 (3.8718)	grad_norm 0.3571 (0.3158)	mem 39782MB
[2023-07-07 07:32:45 RepVGG-A0] (main.py 282): INFO Train: [12/300][20/78]	eta 0:02:20 lr 6.373679	time 1.2070 (2.4253)	loss 3.8771 (3.8714)	grad_norm 0.3231 (0.3243)	mem 39782MB
[2023-07-07 07:33:00 RepVGG-A0] (main.py 282): INFO Train: [12/300][30/78]	eta 0:01:42 lr 6.373126	time 1.2203 (2.1411)	loss 4.0895 (3.8768)	grad_norm 0.4718 (0.3424)	mem 39782MB
[2023-07-07 07:33:18 RepVGG-A0] (main.py 282): INFO Train: [12/300][40/78]	eta 0:01:17 lr 6.372567	time 2.7644 (2.0364)	loss 3.8020 (3.8934)	grad_norm 0.2953 (0.3434)	mem 39782MB
[2023-07-07 07:33:33 RepVGG-A0] (main.py 282): INFO Train: [12/300][50/78]	eta 0:00:54 lr 6.372003	time 1.1735 (1.9365)	loss 3.9145 (3.8843)	grad_norm 0.3674 (0.3439)	mem 39782MB
[2023-07-07 07:33:49 RepVGG-A0] (main.py 282): INFO Train: [12/300][60/78]	eta 0:00:33 lr 6.371433	time 1.4120 (1.8824)	loss 3.9452 (3.8781)	grad_norm 0.3711 (0.3458)	mem 39782MB
[2023-07-07 07:34:03 RepVGG-A0] (main.py 282): INFO Train: [12/300][70/78]	eta 0:00:14 lr 6.370858	time 1.4768 (1.8186)	loss 4.2037 (3.8835)	grad_norm 0.5503 (0.3526)	mem 39782MB
[2023-07-07 07:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 12 training takes 0:02:20
[2023-07-07 07:34:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][0/78]	eta 0:28:26 lr 6.370393	time 21.8780 (21.8780)	loss 4.4674 (4.4674)	grad_norm 0.5121 (0.5121)	mem 39782MB
[2023-07-07 07:34:50 RepVGG-A0] (main.py 282): INFO Train: [13/300][10/78]	eta 0:03:42 lr 6.369807	time 1.1694 (3.2707)	loss 4.0633 (4.2611)	grad_norm 0.3029 (0.3710)	mem 39782MB
[2023-07-07 07:35:05 RepVGG-A0] (main.py 282): INFO Train: [13/300][20/78]	eta 0:02:18 lr 6.369216	time 1.1727 (2.3956)	loss 3.8143 (4.0843)	grad_norm 0.2852 (0.3273)	mem 39782MB
[2023-07-07 07:35:19 RepVGG-A0] (main.py 282): INFO Train: [13/300][30/78]	eta 0:01:40 lr 6.368618	time 1.2975 (2.0942)	loss 3.8893 (4.0051)	grad_norm 0.3547 (0.3255)	mem 39782MB
[2023-07-07 07:35:36 RepVGG-A0] (main.py 282): INFO Train: [13/300][40/78]	eta 0:01:15 lr 6.368015	time 3.1595 (1.9967)	loss 3.7835 (3.9539)	grad_norm 0.3138 (0.3253)	mem 39782MB
[2023-07-07 07:35:52 RepVGG-A0] (main.py 282): INFO Train: [13/300][50/78]	eta 0:00:53 lr 6.367406	time 1.3427 (1.9135)	loss 4.1381 (3.9428)	grad_norm 0.4586 (0.3365)	mem 39782MB
[2023-07-07 07:36:07 RepVGG-A0] (main.py 282): INFO Train: [13/300][60/78]	eta 0:00:33 lr 6.366792	time 1.1728 (1.8426)	loss 3.7757 (3.9269)	grad_norm 0.3021 (0.3360)	mem 39782MB
[2023-07-07 07:36:22 RepVGG-A0] (main.py 282): INFO Train: [13/300][70/78]	eta 0:00:14 lr 6.366172	time 1.3697 (1.7998)	loss 3.8047 (3.9011)	grad_norm 0.3652 (0.3343)	mem 39782MB
[2023-07-07 07:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 13 training takes 0:02:19
[2023-07-07 07:36:55 RepVGG-A0] (main.py 282): INFO Train: [14/300][0/78]	eta 0:27:02 lr 6.365671	time 20.8003 (20.8003)	loss 3.8906 (3.8906)	grad_norm 0.3951 (0.3951)	mem 39782MB
[2023-07-07 07:37:10 RepVGG-A0] (main.py 282): INFO Train: [14/300][10/78]	eta 0:03:42 lr 6.365041	time 1.1720 (3.2746)	loss 3.6377 (3.7760)	grad_norm 0.3136 (0.3536)	mem 39782MB
[2023-07-07 07:37:25 RepVGG-A0] (main.py 282): INFO Train: [14/300][20/78]	eta 0:02:20 lr 6.364405	time 1.1737 (2.4233)	loss 3.7157 (3.7500)	grad_norm 0.3702 (0.3490)	mem 39782MB
[2023-07-07 07:37:40 RepVGG-A0] (main.py 282): INFO Train: [14/300][30/78]	eta 0:01:42 lr 6.363763	time 1.6710 (2.1412)	loss 3.9004 (3.7703)	grad_norm 0.3959 (0.3608)	mem 39782MB
[2023-07-07 07:37:59 RepVGG-A0] (main.py 282): INFO Train: [14/300][40/78]	eta 0:01:18 lr 6.363115	time 4.2058 (2.0610)	loss 3.7546 (3.7743)	grad_norm 0.3423 (0.3600)	mem 39782MB
[2023-07-07 07:38:14 RepVGG-A0] (main.py 282): INFO Train: [14/300][50/78]	eta 0:00:54 lr 6.362462	time 1.2449 (1.9519)	loss 3.8126 (3.7702)	grad_norm 0.3715 (0.3569)	mem 39782MB
[2023-07-07 07:38:29 RepVGG-A0] (main.py 282): INFO Train: [14/300][60/78]	eta 0:00:33 lr 6.361803	time 1.1812 (1.8779)	loss 4.3976 (3.8335)	grad_norm 0.5011 (0.3816)	mem 39782MB
[2023-07-07 07:38:44 RepVGG-A0] (main.py 282): INFO Train: [14/300][70/78]	eta 0:00:14 lr 6.361139	time 1.3116 (1.8297)	loss 3.8003 (3.8706)	grad_norm 0.2397 (0.3792)	mem 39782MB
[2023-07-07 07:38:56 RepVGG-A0] (main.py 291): INFO EPOCH 14 training takes 0:02:21
[2023-07-07 07:39:16 RepVGG-A0] (main.py 282): INFO Train: [15/300][0/78]	eta 0:25:59 lr 6.360603	time 19.9894 (19.9894)	loss 3.6437 (3.6437)	grad_norm 0.2818 (0.2818)	mem 39782MB
[2023-07-07 07:39:32 RepVGG-A0] (main.py 282): INFO Train: [15/300][10/78]	eta 0:03:46 lr 6.359928	time 1.1725 (3.3238)	loss 3.6426 (3.7376)	grad_norm 0.2760 (0.3218)	mem 39782MB
[2023-07-07 07:39:46 RepVGG-A0] (main.py 282): INFO Train: [15/300][20/78]	eta 0:02:20 lr 6.359247	time 1.1939 (2.4207)	loss 3.7460 (3.7183)	grad_norm 0.3307 (0.3248)	mem 39782MB
[2023-07-07 07:40:01 RepVGG-A0] (main.py 282): INFO Train: [15/300][30/78]	eta 0:01:41 lr 6.358561	time 1.1913 (2.1249)	loss 3.7163 (3.7017)	grad_norm 0.3374 (0.3216)	mem 39782MB
[2023-07-07 07:40:20 RepVGG-A0] (main.py 282): INFO Train: [15/300][40/78]	eta 0:01:18 lr 6.357869	time 3.6053 (2.0547)	loss 3.7735 (3.7124)	grad_norm 0.3651 (0.3323)	mem 39782MB
[2023-07-07 07:40:35 RepVGG-A0] (main.py 282): INFO Train: [15/300][50/78]	eta 0:00:54 lr 6.357171	time 1.1729 (1.9417)	loss 4.3714 (3.7565)	grad_norm 0.6949 (0.3576)	mem 39782MB
[2023-07-07 07:40:50 RepVGG-A0] (main.py 282): INFO Train: [15/300][60/78]	eta 0:00:33 lr 6.356468	time 1.3152 (1.8712)	loss 5.2350 (4.0275)	grad_norm 0.4850 (0.4067)	mem 39782MB
[2023-07-07 07:41:05 RepVGG-A0] (main.py 282): INFO Train: [15/300][70/78]	eta 0:00:14 lr 6.355759	time 1.2066 (1.8179)	loss 4.4283 (4.1321)	grad_norm 0.2292 (0.3932)	mem 39782MB
[2023-07-07 07:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 15 training takes 0:02:21
[2023-07-07 07:41:37 RepVGG-A0] (main.py 282): INFO Train: [16/300][0/78]	eta 0:25:53 lr 6.355187	time 19.9168 (19.9168)	loss 4.2265 (4.2265)	grad_norm 0.2985 (0.2985)	mem 39782MB
[2023-07-07 07:41:53 RepVGG-A0] (main.py 282): INFO Train: [16/300][10/78]	eta 0:03:43 lr 6.354468	time 1.1708 (3.2810)	loss 3.9346 (4.0447)	grad_norm 0.2392 (0.2544)	mem 39782MB
[2023-07-07 07:42:07 RepVGG-A0] (main.py 282): INFO Train: [16/300][20/78]	eta 0:02:19 lr 6.353743	time 1.1717 (2.4002)	loss 3.9292 (3.9917)	grad_norm 0.3623 (0.2789)	mem 39782MB
[2023-07-07 07:42:23 RepVGG-A0] (main.py 282): INFO Train: [16/300][30/78]	eta 0:01:41 lr 6.353012	time 1.3754 (2.1205)	loss 3.7464 (3.9645)	grad_norm 0.2343 (0.2871)	mem 39782MB
[2023-07-07 07:42:40 RepVGG-A0] (main.py 282): INFO Train: [16/300][40/78]	eta 0:01:17 lr 6.352276	time 3.6250 (2.0368)	loss 3.9977 (3.9385)	grad_norm 0.4042 (0.2984)	mem 39782MB
[2023-07-07 07:42:55 RepVGG-A0] (main.py 282): INFO Train: [16/300][50/78]	eta 0:00:54 lr 6.351534	time 1.1723 (1.9314)	loss 3.7787 (3.9106)	grad_norm 0.3138 (0.2998)	mem 39782MB
[2023-07-07 07:43:11 RepVGG-A0] (main.py 282): INFO Train: [16/300][60/78]	eta 0:00:33 lr 6.350786	time 1.2657 (1.8747)	loss 4.0153 (3.8997)	grad_norm 0.4180 (0.3114)	mem 39782MB
[2023-07-07 07:43:26 RepVGG-A0] (main.py 282): INFO Train: [16/300][70/78]	eta 0:00:14 lr 6.350033	time 1.1783 (1.8205)	loss 3.8283 (3.8902)	grad_norm 0.3425 (0.3142)	mem 39782MB
[2023-07-07 07:43:38 RepVGG-A0] (main.py 291): INFO EPOCH 16 training takes 0:02:20
[2023-07-07 07:43:58 RepVGG-A0] (main.py 282): INFO Train: [17/300][0/78]	eta 0:26:49 lr 6.349426	time 20.6399 (20.6399)	loss 3.6134 (3.6134)	grad_norm 0.3172 (0.3172)	mem 39782MB
[2023-07-07 07:44:14 RepVGG-A0] (main.py 282): INFO Train: [17/300][10/78]	eta 0:03:43 lr 6.348662	time 1.1694 (3.2915)	loss 3.8158 (3.7375)	grad_norm 0.3768 (0.3612)	mem 39782MB
[2023-07-07 07:44:29 RepVGG-A0] (main.py 282): INFO Train: [17/300][20/78]	eta 0:02:21 lr 6.347893	time 1.1777 (2.4390)	loss 3.6787 (3.7317)	grad_norm 0.3442 (0.3521)	mem 39782MB
[2023-07-07 07:44:44 RepVGG-A0] (main.py 282): INFO Train: [17/300][30/78]	eta 0:01:42 lr 6.347118	time 1.3092 (2.1416)	loss 3.8309 (3.7394)	grad_norm 0.3819 (0.3557)	mem 39782MB
[2023-07-07 07:45:02 RepVGG-A0] (main.py 282): INFO Train: [17/300][40/78]	eta 0:01:18 lr 6.346337	time 3.9571 (2.0591)	loss 3.7528 (3.7391)	grad_norm 0.3219 (0.3521)	mem 39782MB
[2023-07-07 07:45:18 RepVGG-A0] (main.py 282): INFO Train: [17/300][50/78]	eta 0:00:54 lr 6.345551	time 1.2818 (1.9642)	loss 3.9344 (3.7528)	grad_norm 0.4348 (0.3601)	mem 39782MB
[2023-07-07 07:45:32 RepVGG-A0] (main.py 282): INFO Train: [17/300][60/78]	eta 0:00:33 lr 6.344759	time 1.1805 (1.8794)	loss 3.6612 (3.7669)	grad_norm 0.2790 (0.3611)	mem 39782MB
[2023-07-07 07:45:47 RepVGG-A0] (main.py 282): INFO Train: [17/300][70/78]	eta 0:00:14 lr 6.343961	time 1.2303 (1.8262)	loss 3.6350 (3.7553)	grad_norm 0.3194 (0.3548)	mem 39782MB
[2023-07-07 07:46:00 RepVGG-A0] (main.py 291): INFO EPOCH 17 training takes 0:02:22
[2023-07-07 07:46:22 RepVGG-A0] (main.py 282): INFO Train: [18/300][0/78]	eta 0:27:38 lr 6.343319	time 21.2645 (21.2645)	loss 6.2398 (6.2398)	grad_norm 1.0156 (1.0156)	mem 39782MB
[2023-07-07 07:46:36 RepVGG-A0] (main.py 282): INFO Train: [18/300][10/78]	eta 0:03:42 lr 6.342511	time 1.1915 (3.2760)	loss 5.4875 (5.8388)	grad_norm 0.4270 (0.5488)	mem 39782MB
[2023-07-07 07:46:51 RepVGG-A0] (main.py 282): INFO Train: [18/300][20/78]	eta 0:02:19 lr 6.341698	time 1.2986 (2.4076)	loss 4.7507 (5.4250)	grad_norm 0.3467 (0.4279)	mem 39782MB
[2023-07-07 07:47:06 RepVGG-A0] (main.py 282): INFO Train: [18/300][30/78]	eta 0:01:41 lr 6.340879	time 1.2962 (2.1064)	loss 4.4240 (5.1658)	grad_norm 0.2444 (0.3872)	mem 39782MB
[2023-07-07 07:47:24 RepVGG-A0] (main.py 282): INFO Train: [18/300][40/78]	eta 0:01:17 lr 6.340054	time 4.2980 (2.0477)	loss 4.2786 (4.9506)	grad_norm 0.3201 (0.3564)	mem 39782MB
[2023-07-07 07:47:40 RepVGG-A0] (main.py 282): INFO Train: [18/300][50/78]	eta 0:00:54 lr 6.339223	time 1.2221 (1.9453)	loss 4.0870 (4.7990)	grad_norm 0.2617 (0.3466)	mem 39782MB
[2023-07-07 07:47:55 RepVGG-A0] (main.py 282): INFO Train: [18/300][60/78]	eta 0:00:33 lr 6.338387	time 1.3001 (1.8812)	loss 4.0547 (4.6778)	grad_norm 0.3505 (0.3408)	mem 39782MB
[2023-07-07 07:48:11 RepVGG-A0] (main.py 282): INFO Train: [18/300][70/78]	eta 0:00:14 lr 6.337545	time 1.4931 (1.8410)	loss 4.0413 (4.5819)	grad_norm 0.3598 (0.3366)	mem 39782MB
[2023-07-07 07:48:22 RepVGG-A0] (main.py 291): INFO EPOCH 18 training takes 0:02:21
[2023-07-07 07:48:43 RepVGG-A0] (main.py 282): INFO Train: [19/300][0/78]	eta 0:27:28 lr 6.336868	time 21.1353 (21.1353)	loss 3.8839 (3.8839)	grad_norm 0.3231 (0.3231)	mem 39782MB
[2023-07-07 07:48:57 RepVGG-A0] (main.py 282): INFO Train: [19/300][10/78]	eta 0:03:36 lr 6.336016	time 1.1728 (3.1850)	loss 3.9508 (3.9083)	grad_norm 0.3505 (0.3401)	mem 39782MB
[2023-07-07 07:49:13 RepVGG-A0] (main.py 282): INFO Train: [19/300][20/78]	eta 0:02:19 lr 6.335158	time 1.3085 (2.3999)	loss 3.8897 (3.9043)	grad_norm 0.3872 (0.3436)	mem 39782MB
[2023-07-07 07:49:27 RepVGG-A0] (main.py 282): INFO Train: [19/300][30/78]	eta 0:01:39 lr 6.334295	time 1.1912 (2.0824)	loss 3.7673 (3.9068)	grad_norm 0.3336 (0.3445)	mem 39782MB
[2023-07-07 07:49:44 RepVGG-A0] (main.py 282): INFO Train: [19/300][40/78]	eta 0:01:16 lr 6.333426	time 4.1319 (2.0064)	loss 3.9889 (3.8879)	grad_norm 0.4114 (0.3415)	mem 39782MB
[2023-07-07 07:50:00 RepVGG-A0] (main.py 282): INFO Train: [19/300][50/78]	eta 0:00:53 lr 6.332551	time 1.1739 (1.9089)	loss 3.7390 (3.8767)	grad_norm 0.3259 (0.3416)	mem 39782MB
[2023-07-07 07:50:14 RepVGG-A0] (main.py 282): INFO Train: [19/300][60/78]	eta 0:00:33 lr 6.331671	time 1.1928 (1.8412)	loss 3.9306 (3.8678)	grad_norm 0.3858 (0.3434)	mem 39782MB
[2023-07-07 07:50:30 RepVGG-A0] (main.py 282): INFO Train: [19/300][70/78]	eta 0:00:14 lr 6.330785	time 1.3505 (1.8000)	loss 4.0535 (3.8682)	grad_norm 0.4791 (0.3495)	mem 39782MB
[2023-07-07 07:50:41 RepVGG-A0] (main.py 291): INFO EPOCH 19 training takes 0:02:19
[2023-07-07 07:51:03 RepVGG-A0] (main.py 282): INFO Train: [20/300][0/78]	eta 0:28:11 lr 6.330072	time 21.6890 (21.6890)	loss 3.7154 (3.7154)	grad_norm 0.2921 (0.2921)	mem 39782MB
[2023-07-07 07:51:17 RepVGG-A0] (main.py 282): INFO Train: [20/300][10/78]	eta 0:03:42 lr 6.329176	time 1.1779 (3.2738)	loss 4.1822 (3.8597)	grad_norm 0.4776 (0.3881)	mem 39782MB
[2023-07-07 07:51:33 RepVGG-A0] (main.py 282): INFO Train: [20/300][20/78]	eta 0:02:22 lr 6.328275	time 1.1743 (2.4570)	loss 3.8048 (3.8667)	grad_norm 0.3171 (0.3670)	mem 39782MB
[2023-07-07 07:51:48 RepVGG-A0] (main.py 282): INFO Train: [20/300][30/78]	eta 0:01:43 lr 6.327367	time 1.3924 (2.1640)	loss 3.8482 (3.8744)	grad_norm 0.3293 (0.3753)	mem 39782MB
[2023-07-07 07:52:06 RepVGG-A0] (main.py 282): INFO Train: [20/300][40/78]	eta 0:01:18 lr 6.326454	time 3.8261 (2.0670)	loss 3.7650 (3.8358)	grad_norm 0.3773 (0.3609)	mem 39782MB
[2023-07-07 07:52:21 RepVGG-A0] (main.py 282): INFO Train: [20/300][50/78]	eta 0:00:54 lr 6.325536	time 1.1923 (1.9514)	loss 3.5441 (3.8057)	grad_norm 0.2934 (0.3514)	mem 39782MB
[2023-07-07 07:52:36 RepVGG-A0] (main.py 282): INFO Train: [20/300][60/78]	eta 0:00:33 lr 6.324611	time 1.3648 (1.8821)	loss 4.0153 (3.8042)	grad_norm 0.4276 (0.3578)	mem 39782MB
[2023-07-07 07:52:51 RepVGG-A0] (main.py 282): INFO Train: [20/300][70/78]	eta 0:00:14 lr 6.323682	time 1.1828 (1.8270)	loss 3.7293 (3.8054)	grad_norm 0.3177 (0.3581)	mem 39782MB
[2023-07-07 07:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 20 training takes 0:02:20
[2023-07-07 07:53:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.623 (17.623)	Loss 3.2837 (3.2837)	Acc@1 32.971 (32.971)	Acc@5 57.623 (57.623)	Mem 39782MB
[2023-07-07 07:53:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 32.742 Acc@5 57.506
[2023-07-07 07:53:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 20: 32.742%
[2023-07-07 07:53:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 07:53:42 RepVGG-A0] (main.py 282): INFO Train: [21/300][0/78]	eta 0:27:35 lr 6.322934	time 21.2191 (21.2191)	loss 3.6910 (3.6910)	grad_norm 0.3284 (0.3284)	mem 39782MB
[2023-07-07 07:53:57 RepVGG-A0] (main.py 282): INFO Train: [21/300][10/78]	eta 0:03:45 lr 6.321994	time 1.1721 (3.3124)	loss 3.8877 (3.7255)	grad_norm 0.4108 (0.3748)	mem 39782MB
[2023-07-07 07:54:12 RepVGG-A0] (main.py 282): INFO Train: [21/300][20/78]	eta 0:02:21 lr 6.321048	time 1.2892 (2.4384)	loss 3.7020 (3.7393)	grad_norm 0.3869 (0.3783)	mem 39782MB
[2023-07-07 07:54:27 RepVGG-A0] (main.py 282): INFO Train: [21/300][30/78]	eta 0:01:42 lr 6.320097	time 1.1749 (2.1395)	loss 3.5875 (3.7312)	grad_norm 0.3176 (0.3678)	mem 39782MB
[2023-07-07 07:54:44 RepVGG-A0] (main.py 282): INFO Train: [21/300][40/78]	eta 0:01:17 lr 6.319140	time 3.2057 (2.0436)	loss 3.7002 (3.7106)	grad_norm 0.4025 (0.3611)	mem 39782MB
[2023-07-07 07:54:59 RepVGG-A0] (main.py 282): INFO Train: [21/300][50/78]	eta 0:00:54 lr 6.318177	time 1.1746 (1.9411)	loss 3.5830 (3.7055)	grad_norm 0.3152 (0.3574)	mem 39782MB
[2023-07-07 07:55:15 RepVGG-A0] (main.py 282): INFO Train: [21/300][60/78]	eta 0:00:33 lr 6.317209	time 1.1871 (1.8724)	loss 3.6742 (3.7037)	grad_norm 0.3534 (0.3590)	mem 39782MB
[2023-07-07 07:55:30 RepVGG-A0] (main.py 282): INFO Train: [21/300][70/78]	eta 0:00:14 lr 6.316236	time 1.4066 (1.8233)	loss 3.8340 (3.7087)	grad_norm 0.4265 (0.3649)	mem 39782MB
[2023-07-07 07:55:42 RepVGG-A0] (main.py 291): INFO EPOCH 21 training takes 0:02:21
[2023-07-07 07:56:03 RepVGG-A0] (main.py 282): INFO Train: [22/300][0/78]	eta 0:28:00 lr 6.315452	time 21.5417 (21.5417)	loss 4.4624 (4.4624)	grad_norm 0.5225 (0.5225)	mem 39782MB
[2023-07-07 07:56:18 RepVGG-A0] (main.py 282): INFO Train: [22/300][10/78]	eta 0:03:43 lr 6.314469	time 1.1949 (3.2832)	loss 3.8606 (4.0939)	grad_norm 0.3035 (0.3728)	mem 39782MB
[2023-07-07 07:56:32 RepVGG-A0] (main.py 282): INFO Train: [22/300][20/78]	eta 0:02:19 lr 6.313479	time 1.1741 (2.4031)	loss 3.6778 (3.9155)	grad_norm 0.2631 (0.3263)	mem 39782MB
[2023-07-07 07:56:48 RepVGG-A0] (main.py 282): INFO Train: [22/300][30/78]	eta 0:01:43 lr 6.312484	time 1.1833 (2.1486)	loss 3.6210 (3.8253)	grad_norm 0.3040 (0.3154)	mem 39782MB
[2023-07-07 07:57:06 RepVGG-A0] (main.py 282): INFO Train: [22/300][40/78]	eta 0:01:17 lr 6.311483	time 3.8913 (2.0508)	loss 3.6412 (3.7771)	grad_norm 0.3168 (0.3164)	mem 39782MB
[2023-07-07 07:57:20 RepVGG-A0] (main.py 282): INFO Train: [22/300][50/78]	eta 0:00:54 lr 6.310477	time 1.1293 (1.9381)	loss 3.7067 (3.7557)	grad_norm 0.3499 (0.3246)	mem 39782MB
[2023-07-07 07:57:35 RepVGG-A0] (main.py 282): INFO Train: [22/300][60/78]	eta 0:00:33 lr 6.309465	time 1.1722 (1.8634)	loss 3.6337 (3.7324)	grad_norm 0.3477 (0.3247)	mem 39782MB
[2023-07-07 07:57:50 RepVGG-A0] (main.py 282): INFO Train: [22/300][70/78]	eta 0:00:14 lr 6.308448	time 1.1753 (1.8155)	loss 3.6419 (3.7212)	grad_norm 0.3597 (0.3286)	mem 39782MB
[2023-07-07 07:58:03 RepVGG-A0] (main.py 291): INFO EPOCH 22 training takes 0:02:21
[2023-07-07 07:58:24 RepVGG-A0] (main.py 282): INFO Train: [23/300][0/78]	eta 0:27:24 lr 6.307630	time 21.0818 (21.0818)	loss 3.4685 (3.4685)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 07:58:39 RepVGG-A0] (main.py 282): INFO Train: [23/300][10/78]	eta 0:03:41 lr 6.306602	time 1.1707 (3.2532)	loss 3.5689 (3.6093)	grad_norm 0.3604 (0.3686)	mem 39782MB
[2023-07-07 07:58:54 RepVGG-A0] (main.py 282): INFO Train: [23/300][20/78]	eta 0:02:22 lr 6.305569	time 1.3802 (2.4501)	loss 3.6114 (3.6152)	grad_norm 0.3414 (0.3583)	mem 39782MB
[2023-07-07 07:59:09 RepVGG-A0] (main.py 282): INFO Train: [23/300][30/78]	eta 0:01:42 lr 6.304530	time 1.3658 (2.1369)	loss 3.5687 (3.6137)	grad_norm 0.3500 (0.3585)	mem 39782MB
[2023-07-07 07:59:27 RepVGG-A0] (main.py 282): INFO Train: [23/300][40/78]	eta 0:01:18 lr 6.303486	time 3.5108 (2.0540)	loss 3.6108 (3.6182)	grad_norm 0.3400 (0.3606)	mem 39782MB
[2023-07-07 07:59:42 RepVGG-A0] (main.py 282): INFO Train: [23/300][50/78]	eta 0:00:54 lr 6.302436	time 1.3580 (1.9485)	loss 3.5814 (3.6114)	grad_norm 0.3568 (0.3566)	mem 39782MB
[2023-07-07 07:59:57 RepVGG-A0] (main.py 282): INFO Train: [23/300][60/78]	eta 0:00:33 lr 6.301380	time 1.1804 (1.8771)	loss 3.6135 (3.6180)	grad_norm 0.3734 (0.3597)	mem 39782MB
[2023-07-07 08:00:13 RepVGG-A0] (main.py 282): INFO Train: [23/300][70/78]	eta 0:00:14 lr 6.300319	time 1.1292 (1.8291)	loss 3.6602 (3.6139)	grad_norm 0.3992 (0.3592)	mem 39782MB
[2023-07-07 08:00:24 RepVGG-A0] (main.py 291): INFO EPOCH 23 training takes 0:02:20
[2023-07-07 08:00:46 RepVGG-A0] (main.py 282): INFO Train: [24/300][0/78]	eta 0:28:25 lr 6.299466	time 21.8711 (21.8711)	loss 3.6344 (3.6344)	grad_norm 0.3645 (0.3645)	mem 39782MB
[2023-07-07 08:00:59 RepVGG-A0] (main.py 282): INFO Train: [24/300][10/78]	eta 0:03:40 lr 6.298395	time 1.1732 (3.2396)	loss 3.5245 (3.5216)	grad_norm 0.3359 (0.3254)	mem 39782MB
[2023-07-07 08:01:14 RepVGG-A0] (main.py 282): INFO Train: [24/300][20/78]	eta 0:02:18 lr 6.297318	time 1.1719 (2.3921)	loss 4.4663 (3.6679)	grad_norm 0.7927 (0.4109)	mem 39782MB
[2023-07-07 08:01:29 RepVGG-A0] (main.py 282): INFO Train: [24/300][30/78]	eta 0:01:41 lr 6.296236	time 1.2955 (2.1043)	loss 5.5447 (4.3645)	grad_norm 0.3807 (0.4860)	mem 39782MB
[2023-07-07 08:01:47 RepVGG-A0] (main.py 282): INFO Train: [24/300][40/78]	eta 0:01:16 lr 6.295148	time 3.2318 (2.0254)	loss 4.7818 (4.5705)	grad_norm 0.2415 (0.4467)	mem 39782MB
[2023-07-07 08:02:02 RepVGG-A0] (main.py 282): INFO Train: [24/300][50/78]	eta 0:00:53 lr 6.294054	time 1.1900 (1.9177)	loss 4.4753 (4.5875)	grad_norm 0.2658 (0.4163)	mem 39782MB
[2023-07-07 08:02:17 RepVGG-A0] (main.py 282): INFO Train: [24/300][60/78]	eta 0:00:33 lr 6.292955	time 1.2693 (1.8512)	loss 4.3630 (4.5474)	grad_norm 0.3431 (0.3977)	mem 39782MB
[2023-07-07 08:02:32 RepVGG-A0] (main.py 282): INFO Train: [24/300][70/78]	eta 0:00:14 lr 6.291850	time 1.1704 (1.8006)	loss 4.2704 (4.4930)	grad_norm 0.4236 (0.3862)	mem 39782MB
[2023-07-07 08:02:44 RepVGG-A0] (main.py 291): INFO EPOCH 24 training takes 0:02:19
[2023-07-07 08:03:04 RepVGG-A0] (main.py 282): INFO Train: [25/300][0/78]	eta 0:26:29 lr 6.290963	time 20.3725 (20.3725)	loss 3.9907 (3.9907)	grad_norm 0.2841 (0.2841)	mem 39782MB
[2023-07-07 08:03:21 RepVGG-A0] (main.py 282): INFO Train: [25/300][10/78]	eta 0:03:49 lr 6.289848	time 1.1734 (3.3721)	loss 3.9881 (3.9744)	grad_norm 0.3544 (0.3094)	mem 39782MB
[2023-07-07 08:03:35 RepVGG-A0] (main.py 282): INFO Train: [25/300][20/78]	eta 0:02:21 lr 6.288728	time 1.1857 (2.4376)	loss 3.8662 (3.9334)	grad_norm 0.2953 (0.3101)	mem 39782MB
[2023-07-07 08:03:50 RepVGG-A0] (main.py 282): INFO Train: [25/300][30/78]	eta 0:01:42 lr 6.287602	time 1.1297 (2.1350)	loss 3.8506 (3.9074)	grad_norm 0.3473 (0.3172)	mem 39782MB
[2023-07-07 08:04:07 RepVGG-A0] (main.py 282): INFO Train: [25/300][40/78]	eta 0:01:17 lr 6.286470	time 4.1373 (2.0390)	loss 3.8721 (3.9111)	grad_norm 0.3601 (0.3316)	mem 39782MB
[2023-07-07 08:04:22 RepVGG-A0] (main.py 282): INFO Train: [25/300][50/78]	eta 0:00:54 lr 6.285333	time 1.1737 (1.9390)	loss 3.8315 (3.8928)	grad_norm 0.3959 (0.3312)	mem 39782MB
[2023-07-07 08:04:38 RepVGG-A0] (main.py 282): INFO Train: [25/300][60/78]	eta 0:00:33 lr 6.284191	time 1.4614 (1.8780)	loss 3.7478 (3.8759)	grad_norm 0.3242 (0.3322)	mem 39782MB
[2023-07-07 08:04:54 RepVGG-A0] (main.py 282): INFO Train: [25/300][70/78]	eta 0:00:14 lr 6.283043	time 1.1281 (1.8301)	loss 3.9121 (3.8628)	grad_norm 0.4574 (0.3368)	mem 39782MB
[2023-07-07 08:05:06 RepVGG-A0] (main.py 291): INFO EPOCH 25 training takes 0:02:21
[2023-07-07 08:05:27 RepVGG-A0] (main.py 282): INFO Train: [26/300][0/78]	eta 0:27:36 lr 6.282120	time 21.2313 (21.2313)	loss 3.7392 (3.7392)	grad_norm 0.3104 (0.3104)	mem 39782MB
[2023-07-07 08:05:42 RepVGG-A0] (main.py 282): INFO Train: [26/300][10/78]	eta 0:03:44 lr 6.280962	time 1.1727 (3.3072)	loss 4.3313 (3.8068)	grad_norm 0.7122 (0.4144)	mem 39782MB
[2023-07-07 08:05:56 RepVGG-A0] (main.py 282): INFO Train: [26/300][20/78]	eta 0:02:19 lr 6.279798	time 1.4256 (2.4101)	loss 4.8313 (4.3950)	grad_norm 0.3648 (0.5107)	mem 39782MB
[2023-07-07 08:06:11 RepVGG-A0] (main.py 282): INFO Train: [26/300][30/78]	eta 0:01:42 lr 6.278629	time 1.5325 (2.1267)	loss 4.2230 (4.3820)	grad_norm 0.3739 (0.4444)	mem 39782MB
[2023-07-07 08:06:30 RepVGG-A0] (main.py 282): INFO Train: [26/300][40/78]	eta 0:01:18 lr 6.277454	time 4.5106 (2.0549)	loss 3.9516 (4.3167)	grad_norm 0.2316 (0.4091)	mem 39782MB
[2023-07-07 08:06:45 RepVGG-A0] (main.py 282): INFO Train: [26/300][50/78]	eta 0:00:54 lr 6.276274	time 1.1737 (1.9419)	loss 3.8305 (4.2321)	grad_norm 0.2624 (0.3826)	mem 39782MB
[2023-07-07 08:07:00 RepVGG-A0] (main.py 282): INFO Train: [26/300][60/78]	eta 0:00:33 lr 6.275088	time 1.1802 (1.8746)	loss 3.7621 (4.1515)	grad_norm 0.3173 (0.3659)	mem 39782MB
[2023-07-07 08:07:14 RepVGG-A0] (main.py 282): INFO Train: [26/300][70/78]	eta 0:00:14 lr 6.273897	time 1.1711 (1.8133)	loss 3.7263 (4.0903)	grad_norm 0.3091 (0.3571)	mem 39782MB
[2023-07-07 08:07:26 RepVGG-A0] (main.py 291): INFO EPOCH 26 training takes 0:02:20
[2023-07-07 08:07:48 RepVGG-A0] (main.py 282): INFO Train: [27/300][0/78]	eta 0:27:56 lr 6.272940	time 21.4946 (21.4946)	loss 3.6989 (3.6989)	grad_norm 0.3342 (0.3342)	mem 39782MB
[2023-07-07 08:08:03 RepVGG-A0] (main.py 282): INFO Train: [27/300][10/78]	eta 0:03:44 lr 6.271738	time 1.1702 (3.3001)	loss 3.7929 (3.7221)	grad_norm 0.3630 (0.3613)	mem 39782MB
[2023-07-07 08:08:17 RepVGG-A0] (main.py 282): INFO Train: [27/300][20/78]	eta 0:02:21 lr 6.270532	time 1.1776 (2.4317)	loss 3.8064 (3.7335)	grad_norm 0.3418 (0.3543)	mem 39782MB
[2023-07-07 08:08:32 RepVGG-A0] (main.py 282): INFO Train: [27/300][30/78]	eta 0:01:41 lr 6.269319	time 1.2656 (2.1226)	loss 3.6340 (3.6986)	grad_norm 0.3159 (0.3384)	mem 39782MB
[2023-07-07 08:08:50 RepVGG-A0] (main.py 282): INFO Train: [27/300][40/78]	eta 0:01:17 lr 6.268101	time 3.0214 (2.0470)	loss 4.0521 (3.7102)	grad_norm 0.5404 (0.3534)	mem 39782MB
[2023-07-07 08:09:05 RepVGG-A0] (main.py 282): INFO Train: [27/300][50/78]	eta 0:00:54 lr 6.266878	time 1.1709 (1.9347)	loss 4.0340 (3.8127)	grad_norm 0.3163 (0.3780)	mem 39782MB
[2023-07-07 08:09:20 RepVGG-A0] (main.py 282): INFO Train: [27/300][60/78]	eta 0:00:33 lr 6.265649	time 1.1762 (1.8619)	loss 3.5768 (3.8071)	grad_norm 0.2731 (0.3623)	mem 39782MB
[2023-07-07 08:09:35 RepVGG-A0] (main.py 282): INFO Train: [27/300][70/78]	eta 0:00:14 lr 6.264414	time 1.1733 (1.8131)	loss 3.6027 (3.7792)	grad_norm 0.3163 (0.3513)	mem 39782MB
[2023-07-07 08:09:47 RepVGG-A0] (main.py 291): INFO EPOCH 27 training takes 0:02:20
[2023-07-07 08:10:09 RepVGG-A0] (main.py 282): INFO Train: [28/300][0/78]	eta 0:28:15 lr 6.263422	time 21.7410 (21.7410)	loss 3.6210 (3.6210)	grad_norm 0.3019 (0.3019)	mem 39782MB
[2023-07-07 08:10:24 RepVGG-A0] (main.py 282): INFO Train: [28/300][10/78]	eta 0:03:48 lr 6.262178	time 1.1716 (3.3619)	loss 3.5792 (3.5644)	grad_norm 0.3147 (0.2939)	mem 39782MB
[2023-07-07 08:10:38 RepVGG-A0] (main.py 282): INFO Train: [28/300][20/78]	eta 0:02:21 lr 6.260928	time 1.1743 (2.4371)	loss 3.5860 (3.5811)	grad_norm 0.3378 (0.3093)	mem 39782MB
[2023-07-07 08:10:53 RepVGG-A0] (main.py 282): INFO Train: [28/300][30/78]	eta 0:01:41 lr 6.259672	time 1.4630 (2.1224)	loss 3.7627 (3.6173)	grad_norm 0.3801 (0.3378)	mem 39782MB
[2023-07-07 08:11:11 RepVGG-A0] (main.py 282): INFO Train: [28/300][40/78]	eta 0:01:17 lr 6.258411	time 3.3651 (2.0435)	loss 3.5484 (3.6238)	grad_norm 0.3011 (0.3368)	mem 39782MB
[2023-07-07 08:11:26 RepVGG-A0] (main.py 282): INFO Train: [28/300][50/78]	eta 0:00:54 lr 6.257145	time 1.1711 (1.9391)	loss 3.7227 (3.6219)	grad_norm 0.3926 (0.3398)	mem 39782MB
[2023-07-07 08:11:41 RepVGG-A0] (main.py 282): INFO Train: [28/300][60/78]	eta 0:00:33 lr 6.255873	time 1.1403 (1.8636)	loss 3.6272 (3.6335)	grad_norm 0.3168 (0.3440)	mem 39782MB
[2023-07-07 08:11:56 RepVGG-A0] (main.py 282): INFO Train: [28/300][70/78]	eta 0:00:14 lr 6.254595	time 1.1944 (1.8180)	loss 3.4983 (3.6243)	grad_norm 0.3334 (0.3408)	mem 39782MB
[2023-07-07 08:12:09 RepVGG-A0] (main.py 291): INFO EPOCH 28 training takes 0:02:21
[2023-07-07 08:12:31 RepVGG-A0] (main.py 282): INFO Train: [29/300][0/78]	eta 0:28:42 lr 6.253569	time 22.0781 (22.0781)	loss 3.6141 (3.6141)	grad_norm 0.3577 (0.3577)	mem 39782MB
[2023-07-07 08:12:45 RepVGG-A0] (main.py 282): INFO Train: [29/300][10/78]	eta 0:03:45 lr 6.252282	time 1.1717 (3.3193)	loss 6.1045 (4.6341)	grad_norm 0.7011 (0.6846)	mem 39782MB
[2023-07-07 08:13:00 RepVGG-A0] (main.py 282): INFO Train: [29/300][20/78]	eta 0:02:20 lr 6.250989	time 1.4454 (2.4305)	loss 5.0168 (5.0521)	grad_norm 0.3091 (0.5526)	mem 39782MB
[2023-07-07 08:13:15 RepVGG-A0] (main.py 282): INFO Train: [29/300][30/78]	eta 0:01:41 lr 6.249690	time 1.2506 (2.1182)	loss 4.5447 (4.9484)	grad_norm 0.3007 (0.4655)	mem 39782MB
[2023-07-07 08:13:33 RepVGG-A0] (main.py 282): INFO Train: [29/300][40/78]	eta 0:01:18 lr 6.248386	time 4.2226 (2.0559)	loss 4.1643 (4.7990)	grad_norm 0.2924 (0.4179)	mem 39782MB
[2023-07-07 08:13:48 RepVGG-A0] (main.py 282): INFO Train: [29/300][50/78]	eta 0:00:54 lr 6.247077	time 1.1750 (1.9466)	loss 4.0872 (4.6673)	grad_norm 0.3205 (0.3931)	mem 39782MB
[2023-07-07 08:14:04 RepVGG-A0] (main.py 282): INFO Train: [29/300][60/78]	eta 0:00:33 lr 6.245762	time 1.2833 (1.8843)	loss 3.9483 (4.5621)	grad_norm 0.3041 (0.3779)	mem 39782MB
[2023-07-07 08:14:18 RepVGG-A0] (main.py 282): INFO Train: [29/300][70/78]	eta 0:00:14 lr 6.244441	time 1.2749 (1.8198)	loss 3.8829 (4.4784)	grad_norm 0.2823 (0.3697)	mem 39782MB
[2023-07-07 08:14:31 RepVGG-A0] (main.py 291): INFO EPOCH 29 training takes 0:02:21
[2023-07-07 08:14:51 RepVGG-A0] (main.py 282): INFO Train: [30/300][0/78]	eta 0:27:09 lr 6.243381	time 20.8879 (20.8879)	loss 3.7136 (3.7136)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 08:15:06 RepVGG-A0] (main.py 282): INFO Train: [30/300][10/78]	eta 0:03:38 lr 6.242051	time 1.1700 (3.2164)	loss 3.8445 (3.8606)	grad_norm 0.3725 (0.3390)	mem 39782MB
[2023-07-07 08:15:20 RepVGG-A0] (main.py 282): INFO Train: [30/300][20/78]	eta 0:02:17 lr 6.240715	time 1.1904 (2.3768)	loss 3.8322 (3.8393)	grad_norm 0.3284 (0.3372)	mem 39782MB
[2023-07-07 08:15:35 RepVGG-A0] (main.py 282): INFO Train: [30/300][30/78]	eta 0:01:39 lr 6.239373	time 1.3745 (2.0728)	loss 3.7189 (3.8192)	grad_norm 0.3047 (0.3383)	mem 39782MB
[2023-07-07 08:15:53 RepVGG-A0] (main.py 282): INFO Train: [30/300][40/78]	eta 0:01:16 lr 6.238027	time 5.2583 (2.0209)	loss 3.8315 (3.8029)	grad_norm 0.3972 (0.3407)	mem 39782MB
[2023-07-07 08:16:08 RepVGG-A0] (main.py 282): INFO Train: [30/300][50/78]	eta 0:00:53 lr 6.236674	time 1.1734 (1.9155)	loss 3.6541 (3.7946)	grad_norm 0.3080 (0.3382)	mem 39782MB
[2023-07-07 08:16:24 RepVGG-A0] (main.py 282): INFO Train: [30/300][60/78]	eta 0:00:33 lr 6.235317	time 1.2832 (1.8644)	loss 3.7359 (3.7931)	grad_norm 0.3292 (0.3433)	mem 39782MB
[2023-07-07 08:16:38 RepVGG-A0] (main.py 282): INFO Train: [30/300][70/78]	eta 0:00:14 lr 6.233953	time 1.1320 (1.8012)	loss 3.9999 (3.7892)	grad_norm 0.4951 (0.3462)	mem 39782MB
[2023-07-07 08:16:50 RepVGG-A0] (main.py 291): INFO EPOCH 30 training takes 0:02:19
[2023-07-07 08:17:12 RepVGG-A0] (main.py 282): INFO Train: [31/300][0/78]	eta 0:28:28 lr 6.232859	time 21.9041 (21.9041)	loss 5.3088 (5.3088)	grad_norm 0.5897 (0.5897)	mem 39782MB
[2023-07-07 08:17:27 RepVGG-A0] (main.py 282): INFO Train: [31/300][10/78]	eta 0:03:50 lr 6.231486	time 1.1716 (3.3859)	loss 4.2237 (4.6527)	grad_norm 0.2788 (0.3600)	mem 39782MB
[2023-07-07 08:17:42 RepVGG-A0] (main.py 282): INFO Train: [31/300][20/78]	eta 0:02:23 lr 6.230107	time 1.3029 (2.4676)	loss 3.9927 (4.3991)	grad_norm 0.3201 (0.3397)	mem 39782MB
[2023-07-07 08:17:58 RepVGG-A0] (main.py 282): INFO Train: [31/300][30/78]	eta 0:01:44 lr 6.228723	time 1.2927 (2.1769)	loss 3.8104 (4.2174)	grad_norm 0.2599 (0.3074)	mem 39782MB
[2023-07-07 08:18:15 RepVGG-A0] (main.py 282): INFO Train: [31/300][40/78]	eta 0:01:18 lr 6.227334	time 3.1906 (2.0733)	loss 3.6962 (4.1012)	grad_norm 0.3200 (0.2997)	mem 39782MB
[2023-07-07 08:18:30 RepVGG-A0] (main.py 282): INFO Train: [31/300][50/78]	eta 0:00:54 lr 6.225939	time 1.2188 (1.9603)	loss 3.7652 (4.0410)	grad_norm 0.3230 (0.3059)	mem 39782MB
[2023-07-07 08:18:45 RepVGG-A0] (main.py 282): INFO Train: [31/300][60/78]	eta 0:00:33 lr 6.224539	time 1.1786 (1.8832)	loss 3.8190 (3.9841)	grad_norm 0.3415 (0.3073)	mem 39782MB
[2023-07-07 08:19:00 RepVGG-A0] (main.py 282): INFO Train: [31/300][70/78]	eta 0:00:14 lr 6.223133	time 1.2260 (1.8348)	loss 3.6617 (3.9416)	grad_norm 0.3307 (0.3094)	mem 39782MB
[2023-07-07 08:19:12 RepVGG-A0] (main.py 291): INFO EPOCH 31 training takes 0:02:21
[2023-07-07 08:19:32 RepVGG-A0] (main.py 282): INFO Train: [32/300][0/78]	eta 0:26:42 lr 6.222004	time 20.5423 (20.5423)	loss 3.6108 (3.6108)	grad_norm 0.3058 (0.3058)	mem 39782MB
[2023-07-07 08:19:46 RepVGG-A0] (main.py 282): INFO Train: [32/300][10/78]	eta 0:03:32 lr 6.220589	time 1.1710 (3.1309)	loss 3.7281 (3.7254)	grad_norm 0.3673 (0.3759)	mem 39782MB
[2023-07-07 08:20:02 RepVGG-A0] (main.py 282): INFO Train: [32/300][20/78]	eta 0:02:18 lr 6.219168	time 1.1723 (2.3838)	loss 3.5251 (3.6974)	grad_norm 0.2875 (0.3475)	mem 39782MB
[2023-07-07 08:20:17 RepVGG-A0] (main.py 282): INFO Train: [32/300][30/78]	eta 0:01:41 lr 6.217741	time 1.1997 (2.1151)	loss 3.5418 (3.6724)	grad_norm 0.3112 (0.3431)	mem 39782MB
[2023-07-07 08:20:35 RepVGG-A0] (main.py 282): INFO Train: [32/300][40/78]	eta 0:01:17 lr 6.216309	time 4.7980 (2.0408)	loss 3.8247 (3.6739)	grad_norm 0.4289 (0.3510)	mem 39782MB
[2023-07-07 08:20:50 RepVGG-A0] (main.py 282): INFO Train: [32/300][50/78]	eta 0:00:54 lr 6.214872	time 1.1735 (1.9340)	loss 3.7586 (3.6764)	grad_norm 0.4604 (0.3518)	mem 39782MB
[2023-07-07 08:21:05 RepVGG-A0] (main.py 282): INFO Train: [32/300][60/78]	eta 0:00:33 lr 6.213429	time 1.2602 (1.8665)	loss 3.6135 (3.6886)	grad_norm 0.3088 (0.3563)	mem 39782MB
[2023-07-07 08:21:20 RepVGG-A0] (main.py 282): INFO Train: [32/300][70/78]	eta 0:00:14 lr 6.211981	time 1.3091 (1.8128)	loss 3.5816 (3.6702)	grad_norm 0.3149 (0.3469)	mem 39782MB
[2023-07-07 08:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 32 training takes 0:02:20
[2023-07-07 08:21:54 RepVGG-A0] (main.py 282): INFO Train: [33/300][0/78]	eta 0:27:58 lr 6.210818	time 21.5170 (21.5170)	loss 4.0676 (4.0676)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 08:22:09 RepVGG-A0] (main.py 282): INFO Train: [33/300][10/78]	eta 0:03:45 lr 6.209360	time 1.1726 (3.3135)	loss 5.5350 (4.9070)	grad_norm 0.5298 (0.7022)	mem 39782MB
[2023-07-07 08:22:24 RepVGG-A0] (main.py 282): INFO Train: [33/300][20/78]	eta 0:02:21 lr 6.207897	time 1.1783 (2.4418)	loss 4.4440 (4.8482)	grad_norm 0.2923 (0.5366)	mem 39782MB
[2023-07-07 08:22:39 RepVGG-A0] (main.py 282): INFO Train: [33/300][30/78]	eta 0:01:43 lr 6.206428	time 1.3440 (2.1569)	loss 3.9190 (4.6203)	grad_norm 0.2446 (0.4461)	mem 39782MB
[2023-07-07 08:22:57 RepVGG-A0] (main.py 282): INFO Train: [33/300][40/78]	eta 0:01:18 lr 6.204954	time 3.3726 (2.0635)	loss 3.9857 (4.4632)	grad_norm 0.3565 (0.4098)	mem 39782MB
[2023-07-07 08:23:12 RepVGG-A0] (main.py 282): INFO Train: [33/300][50/78]	eta 0:00:54 lr 6.203474	time 1.2393 (1.9550)	loss 3.7173 (4.3355)	grad_norm 0.2677 (0.3821)	mem 39782MB
[2023-07-07 08:23:27 RepVGG-A0] (main.py 282): INFO Train: [33/300][60/78]	eta 0:00:33 lr 6.201989	time 1.2558 (1.8776)	loss 3.6838 (4.2384)	grad_norm 0.3083 (0.3665)	mem 39782MB
[2023-07-07 08:23:42 RepVGG-A0] (main.py 282): INFO Train: [33/300][70/78]	eta 0:00:14 lr 6.200499	time 1.3682 (1.8299)	loss 3.6918 (4.1690)	grad_norm 0.3201 (0.3605)	mem 39782MB
[2023-07-07 08:23:54 RepVGG-A0] (main.py 291): INFO EPOCH 33 training takes 0:02:21
[2023-07-07 08:24:16 RepVGG-A0] (main.py 282): INFO Train: [34/300][0/78]	eta 0:29:21 lr 6.199302	time 22.5831 (22.5831)	loss 3.5206 (3.5206)	grad_norm 0.2979 (0.2979)	mem 39782MB
[2023-07-07 08:24:31 RepVGG-A0] (main.py 282): INFO Train: [34/300][10/78]	eta 0:03:49 lr 6.197802	time 1.1731 (3.3789)	loss 3.6300 (3.6235)	grad_norm 0.3314 (0.3289)	mem 39782MB
[2023-07-07 08:24:46 RepVGG-A0] (main.py 282): INFO Train: [34/300][20/78]	eta 0:02:23 lr 6.196296	time 1.4702 (2.4767)	loss 3.8385 (3.6951)	grad_norm 0.4196 (0.3657)	mem 39782MB
[2023-07-07 08:25:00 RepVGG-A0] (main.py 282): INFO Train: [34/300][30/78]	eta 0:01:43 lr 6.194785	time 1.1792 (2.1481)	loss 3.6542 (3.6841)	grad_norm 0.3606 (0.3504)	mem 39782MB
[2023-07-07 08:25:17 RepVGG-A0] (main.py 282): INFO Train: [34/300][40/78]	eta 0:01:17 lr 6.193269	time 3.3730 (2.0357)	loss 3.7511 (3.6750)	grad_norm 0.3824 (0.3458)	mem 39782MB
[2023-07-07 08:25:32 RepVGG-A0] (main.py 282): INFO Train: [34/300][50/78]	eta 0:00:54 lr 6.191747	time 1.1778 (1.9331)	loss 3.5639 (3.6667)	grad_norm 0.3597 (0.3452)	mem 39782MB
[2023-07-07 08:25:47 RepVGG-A0] (main.py 282): INFO Train: [34/300][60/78]	eta 0:00:33 lr 6.190220	time 1.3145 (1.8593)	loss 3.6012 (3.6618)	grad_norm 0.3250 (0.3445)	mem 39782MB
[2023-07-07 08:26:02 RepVGG-A0] (main.py 282): INFO Train: [34/300][70/78]	eta 0:00:14 lr 6.188687	time 1.1732 (1.8016)	loss 3.7291 (3.6551)	grad_norm 0.4421 (0.3453)	mem 39782MB
[2023-07-07 08:26:14 RepVGG-A0] (main.py 291): INFO EPOCH 34 training takes 0:02:20
[2023-07-07 08:26:35 RepVGG-A0] (main.py 282): INFO Train: [35/300][0/78]	eta 0:27:26 lr 6.187457	time 21.1091 (21.1091)	loss 3.5790 (3.5790)	grad_norm 0.3010 (0.3010)	mem 39782MB
[2023-07-07 08:26:51 RepVGG-A0] (main.py 282): INFO Train: [35/300][10/78]	eta 0:03:47 lr 6.185915	time 1.1703 (3.3417)	loss 3.7068 (3.5885)	grad_norm 0.4171 (0.3401)	mem 39782MB
[2023-07-07 08:27:06 RepVGG-A0] (main.py 282): INFO Train: [35/300][20/78]	eta 0:02:22 lr 6.184367	time 1.2298 (2.4550)	loss 3.5150 (3.5946)	grad_norm 0.3161 (0.3442)	mem 39782MB
[2023-07-07 08:27:20 RepVGG-A0] (main.py 282): INFO Train: [35/300][30/78]	eta 0:01:42 lr 6.182814	time 1.1583 (2.1359)	loss 3.6157 (3.5836)	grad_norm 0.3487 (0.3416)	mem 39782MB
[2023-07-07 08:27:39 RepVGG-A0] (main.py 282): INFO Train: [35/300][40/78]	eta 0:01:18 lr 6.181256	time 3.2788 (2.0625)	loss 3.6411 (3.5799)	grad_norm 0.3401 (0.3428)	mem 39782MB
[2023-07-07 08:27:54 RepVGG-A0] (main.py 282): INFO Train: [35/300][50/78]	eta 0:00:54 lr 6.179692	time 1.2027 (1.9516)	loss 3.4631 (3.5822)	grad_norm 0.2910 (0.3484)	mem 39782MB
[2023-07-07 08:28:10 RepVGG-A0] (main.py 282): INFO Train: [35/300][60/78]	eta 0:00:34 lr 6.178123	time 1.1718 (1.9006)	loss 3.6476 (3.5750)	grad_norm 0.4451 (0.3473)	mem 39782MB
[2023-07-07 08:28:24 RepVGG-A0] (main.py 282): INFO Train: [35/300][70/78]	eta 0:00:14 lr 6.176548	time 1.3229 (1.8247)	loss 6.0156 (3.7917)	grad_norm 0.6339 (0.4042)	mem 39782MB
[2023-07-07 08:28:36 RepVGG-A0] (main.py 291): INFO EPOCH 35 training takes 0:02:22
[2023-07-07 08:28:57 RepVGG-A0] (main.py 282): INFO Train: [36/300][0/78]	eta 0:27:32 lr 6.175285	time 21.1904 (21.1904)	loss 5.1530 (5.1530)	grad_norm 0.3020 (0.3020)	mem 39782MB
[2023-07-07 08:29:13 RepVGG-A0] (main.py 282): INFO Train: [36/300][10/78]	eta 0:03:49 lr 6.173701	time 1.1730 (3.3732)	loss 4.4158 (4.8099)	grad_norm 0.2546 (0.2981)	mem 39782MB
[2023-07-07 08:29:29 RepVGG-A0] (main.py 282): INFO Train: [36/300][20/78]	eta 0:02:25 lr 6.172111	time 1.1805 (2.5073)	loss 4.1363 (4.5907)	grad_norm 0.2571 (0.2900)	mem 39782MB
[2023-07-07 08:29:45 RepVGG-A0] (main.py 282): INFO Train: [36/300][30/78]	eta 0:01:46 lr 6.170516	time 1.5581 (2.2110)	loss 4.1167 (4.4611)	grad_norm 0.2667 (0.2970)	mem 39782MB
[2023-07-07 08:30:02 RepVGG-A0] (main.py 282): INFO Train: [36/300][40/78]	eta 0:01:19 lr 6.168916	time 2.6601 (2.0949)	loss 3.9984 (4.3531)	grad_norm 0.2985 (0.2937)	mem 39782MB
[2023-07-07 08:30:17 RepVGG-A0] (main.py 282): INFO Train: [36/300][50/78]	eta 0:00:55 lr 6.167310	time 1.1715 (1.9845)	loss 3.8400 (4.2717)	grad_norm 0.2791 (0.2976)	mem 39782MB
[2023-07-07 08:30:32 RepVGG-A0] (main.py 282): INFO Train: [36/300][60/78]	eta 0:00:34 lr 6.165699	time 1.1752 (1.8948)	loss 3.7550 (4.2025)	grad_norm 0.2899 (0.3001)	mem 39782MB
[2023-07-07 08:30:47 RepVGG-A0] (main.py 282): INFO Train: [36/300][70/78]	eta 0:00:14 lr 6.164083	time 1.5069 (1.8480)	loss 3.9428 (4.1573)	grad_norm 0.3755 (0.3072)	mem 39782MB
[2023-07-07 08:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 36 training takes 0:02:21
[2023-07-07 08:31:20 RepVGG-A0] (main.py 282): INFO Train: [37/300][0/78]	eta 0:27:45 lr 6.162786	time 21.3494 (21.3494)	loss 3.6369 (3.6369)	grad_norm 0.2641 (0.2641)	mem 39782MB
[2023-07-07 08:31:35 RepVGG-A0] (main.py 282): INFO Train: [37/300][10/78]	eta 0:03:49 lr 6.161160	time 1.1716 (3.3805)	loss 4.1524 (3.8720)	grad_norm 0.5285 (0.3896)	mem 39782MB
[2023-07-07 08:31:51 RepVGG-A0] (main.py 282): INFO Train: [37/300][20/78]	eta 0:02:24 lr 6.159529	time 1.2106 (2.4905)	loss 3.7640 (3.8594)	grad_norm 0.2866 (0.3609)	mem 39782MB
[2023-07-07 08:32:06 RepVGG-A0] (main.py 282): INFO Train: [37/300][30/78]	eta 0:01:44 lr 6.157892	time 1.5138 (2.1770)	loss 3.6823 (3.8079)	grad_norm 0.3098 (0.3445)	mem 39782MB
[2023-07-07 08:32:24 RepVGG-A0] (main.py 282): INFO Train: [37/300][40/78]	eta 0:01:19 lr 6.156250	time 3.7522 (2.0806)	loss 3.9968 (3.8014)	grad_norm 0.4558 (0.3483)	mem 39782MB
[2023-07-07 08:32:38 RepVGG-A0] (main.py 282): INFO Train: [37/300][50/78]	eta 0:00:54 lr 6.154603	time 1.1766 (1.9639)	loss 3.7482 (3.7810)	grad_norm 0.3601 (0.3421)	mem 39782MB
[2023-07-07 08:32:54 RepVGG-A0] (main.py 282): INFO Train: [37/300][60/78]	eta 0:00:34 lr 6.152950	time 1.1765 (1.8951)	loss 3.6767 (3.7724)	grad_norm 0.2920 (0.3431)	mem 39782MB
[2023-07-07 08:33:09 RepVGG-A0] (main.py 282): INFO Train: [37/300][70/78]	eta 0:00:14 lr 6.151292	time 1.1285 (1.8456)	loss 3.6645 (3.7516)	grad_norm 0.3624 (0.3397)	mem 39782MB
[2023-07-07 08:33:21 RepVGG-A0] (main.py 291): INFO EPOCH 37 training takes 0:02:22
[2023-07-07 08:33:41 RepVGG-A0] (main.py 282): INFO Train: [38/300][0/78]	eta 0:26:20 lr 6.149962	time 20.2674 (20.2674)	loss 4.0416 (4.0416)	grad_norm 0.4791 (0.4791)	mem 39782MB
[2023-07-07 08:33:55 RepVGG-A0] (main.py 282): INFO Train: [38/300][10/78]	eta 0:03:34 lr 6.148295	time 1.1954 (3.1526)	loss 3.6973 (3.8408)	grad_norm 0.3382 (0.3775)	mem 39782MB
[2023-07-07 08:34:11 RepVGG-A0] (main.py 282): INFO Train: [38/300][20/78]	eta 0:02:17 lr 6.146622	time 1.1712 (2.3765)	loss 3.6625 (3.8384)	grad_norm 0.3023 (0.3812)	mem 39782MB
[2023-07-07 08:34:27 RepVGG-A0] (main.py 282): INFO Train: [38/300][30/78]	eta 0:01:42 lr 6.144944	time 1.4000 (2.1288)	loss 3.6304 (3.7591)	grad_norm 0.3173 (0.3514)	mem 39782MB
[2023-07-07 08:34:44 RepVGG-A0] (main.py 282): INFO Train: [38/300][40/78]	eta 0:01:17 lr 6.143260	time 2.6378 (2.0435)	loss 3.7118 (3.7204)	grad_norm 0.4193 (0.3488)	mem 39782MB
[2023-07-07 08:35:00 RepVGG-A0] (main.py 282): INFO Train: [38/300][50/78]	eta 0:00:54 lr 6.141571	time 1.1736 (1.9398)	loss 3.4917 (3.7168)	grad_norm 0.2784 (0.3514)	mem 39782MB
[2023-07-07 08:35:14 RepVGG-A0] (main.py 282): INFO Train: [38/300][60/78]	eta 0:00:33 lr 6.139877	time 1.2936 (1.8574)	loss 3.7452 (3.6937)	grad_norm 0.4043 (0.3475)	mem 39782MB
[2023-07-07 08:35:29 RepVGG-A0] (main.py 282): INFO Train: [38/300][70/78]	eta 0:00:14 lr 6.138178	time 1.2993 (1.8020)	loss 3.5028 (3.6839)	grad_norm 0.3260 (0.3473)	mem 39782MB
[2023-07-07 08:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 38 training takes 0:02:19
[2023-07-07 08:36:00 RepVGG-A0] (main.py 282): INFO Train: [39/300][0/78]	eta 0:25:53 lr 6.136815	time 19.9210 (19.9210)	loss 3.4836 (3.4836)	grad_norm 0.3211 (0.3211)	mem 39782MB
[2023-07-07 08:36:16 RepVGG-A0] (main.py 282): INFO Train: [39/300][10/78]	eta 0:03:42 lr 6.135106	time 1.1708 (3.2763)	loss 4.0391 (3.6977)	grad_norm 0.5231 (0.4356)	mem 39782MB
[2023-07-07 08:36:32 RepVGG-A0] (main.py 282): INFO Train: [39/300][20/78]	eta 0:02:21 lr 6.133392	time 1.1799 (2.4416)	loss 3.5839 (3.7357)	grad_norm 0.2831 (0.4031)	mem 39782MB
[2023-07-07 08:36:47 RepVGG-A0] (main.py 282): INFO Train: [39/300][30/78]	eta 0:01:43 lr 6.131672	time 1.2324 (2.1506)	loss 3.5588 (3.6720)	grad_norm 0.3069 (0.3710)	mem 39782MB
[2023-07-07 08:37:05 RepVGG-A0] (main.py 282): INFO Train: [39/300][40/78]	eta 0:01:18 lr 6.129948	time 3.7478 (2.0640)	loss 3.6565 (3.6497)	grad_norm 0.3971 (0.3680)	mem 39782MB
[2023-07-07 08:37:20 RepVGG-A0] (main.py 282): INFO Train: [39/300][50/78]	eta 0:00:54 lr 6.128218	time 1.2055 (1.9579)	loss 3.5048 (3.6239)	grad_norm 0.3044 (0.3579)	mem 39782MB
[2023-07-07 08:37:35 RepVGG-A0] (main.py 282): INFO Train: [39/300][60/78]	eta 0:00:33 lr 6.126482	time 1.2489 (1.8849)	loss 3.6811 (3.6140)	grad_norm 0.4063 (0.3590)	mem 39782MB
[2023-07-07 08:37:50 RepVGG-A0] (main.py 282): INFO Train: [39/300][70/78]	eta 0:00:14 lr 6.124742	time 1.2415 (1.8267)	loss 5.9486 (3.7849)	grad_norm 0.7251 (0.4069)	mem 39782MB
[2023-07-07 08:38:02 RepVGG-A0] (main.py 291): INFO EPOCH 39 training takes 0:02:21
[2023-07-07 08:38:24 RepVGG-A0] (main.py 282): INFO Train: [40/300][0/78]	eta 0:28:17 lr 6.123345	time 21.7648 (21.7648)	loss 4.9819 (4.9819)	grad_norm 0.3385 (0.3385)	mem 39782MB
[2023-07-07 08:38:38 RepVGG-A0] (main.py 282): INFO Train: [40/300][10/78]	eta 0:03:44 lr 6.121595	time 1.1907 (3.3012)	loss 4.4096 (4.7580)	grad_norm 0.2171 (0.3292)	mem 39782MB
[2023-07-07 08:38:54 RepVGG-A0] (main.py 282): INFO Train: [40/300][20/78]	eta 0:02:23 lr 6.119840	time 1.4242 (2.4781)	loss 4.2009 (4.4997)	grad_norm 0.2960 (0.2941)	mem 39782MB
[2023-07-07 08:39:09 RepVGG-A0] (main.py 282): INFO Train: [40/300][30/78]	eta 0:01:43 lr 6.118080	time 1.1868 (2.1512)	loss 4.0533 (4.3518)	grad_norm 0.3498 (0.2936)	mem 39782MB
[2023-07-07 08:39:26 RepVGG-A0] (main.py 282): INFO Train: [40/300][40/78]	eta 0:01:18 lr 6.116314	time 4.4250 (2.0599)	loss 3.8007 (4.2424)	grad_norm 0.2709 (0.2886)	mem 39782MB
[2023-07-07 08:39:42 RepVGG-A0] (main.py 282): INFO Train: [40/300][50/78]	eta 0:00:54 lr 6.114543	time 1.1722 (1.9546)	loss 3.9658 (4.1666)	grad_norm 0.3507 (0.2931)	mem 39782MB
[2023-07-07 08:39:56 RepVGG-A0] (main.py 282): INFO Train: [40/300][60/78]	eta 0:00:33 lr 6.112766	time 1.3948 (1.8647)	loss 3.7267 (4.1094)	grad_norm 0.2797 (0.2978)	mem 39782MB
[2023-07-07 08:40:11 RepVGG-A0] (main.py 282): INFO Train: [40/300][70/78]	eta 0:00:14 lr 6.110985	time 1.1742 (1.8160)	loss 3.9470 (4.0676)	grad_norm 0.4053 (0.3037)	mem 39782MB
[2023-07-07 08:40:23 RepVGG-A0] (main.py 291): INFO EPOCH 40 training takes 0:02:20
[2023-07-07 08:40:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 16.990 (16.990)	Loss 3.4978 (3.4978)	Acc@1 30.176 (30.176)	Acc@5 54.333 (54.333)	Mem 39782MB
[2023-07-07 08:40:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 30.152 Acc@5 53.964
[2023-07-07 08:40:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 40: 30.152%
[2023-07-07 08:40:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 08:41:03 RepVGG-A0] (main.py 282): INFO Train: [41/300][0/78]	eta 0:28:11 lr 6.109556	time 21.6812 (21.6812)	loss 3.7145 (3.7145)	grad_norm 0.2828 (0.2828)	mem 39782MB
[2023-07-07 08:41:17 RepVGG-A0] (main.py 282): INFO Train: [41/300][10/78]	eta 0:03:43 lr 6.107765	time 1.1723 (3.2850)	loss 3.7515 (3.6917)	grad_norm 0.3373 (0.3208)	mem 39782MB
[2023-07-07 08:41:33 RepVGG-A0] (main.py 282): INFO Train: [41/300][20/78]	eta 0:02:23 lr 6.105968	time 1.1801 (2.4683)	loss 3.6104 (3.6619)	grad_norm 0.3243 (0.3212)	mem 39782MB
[2023-07-07 08:41:47 RepVGG-A0] (main.py 282): INFO Train: [41/300][30/78]	eta 0:01:42 lr 6.104167	time 1.3070 (2.1308)	loss 3.7247 (3.6985)	grad_norm 0.3527 (0.3398)	mem 39782MB
[2023-07-07 08:42:06 RepVGG-A0] (main.py 282): INFO Train: [41/300][40/78]	eta 0:01:18 lr 6.102360	time 4.7852 (2.0702)	loss 4.8237 (3.7951)	grad_norm 0.7509 (0.3882)	mem 39782MB
[2023-07-07 08:42:21 RepVGG-A0] (main.py 282): INFO Train: [41/300][50/78]	eta 0:00:54 lr 6.100548	time 1.1852 (1.9565)	loss 4.1277 (3.9404)	grad_norm 0.2980 (0.4007)	mem 39782MB
[2023-07-07 08:42:36 RepVGG-A0] (main.py 282): INFO Train: [41/300][60/78]	eta 0:00:33 lr 6.098731	time 1.3002 (1.8797)	loss 3.7863 (3.9384)	grad_norm 0.2564 (0.3769)	mem 39782MB
[2023-07-07 08:42:51 RepVGG-A0] (main.py 282): INFO Train: [41/300][70/78]	eta 0:00:14 lr 6.096908	time 1.1794 (1.8243)	loss 3.7676 (3.9192)	grad_norm 0.2968 (0.3665)	mem 39782MB
[2023-07-07 08:43:03 RepVGG-A0] (main.py 291): INFO EPOCH 41 training takes 0:02:21
[2023-07-07 08:43:23 RepVGG-A0] (main.py 282): INFO Train: [42/300][0/78]	eta 0:26:16 lr 6.095447	time 20.2078 (20.2078)	loss 3.5684 (3.5684)	grad_norm 0.2683 (0.2683)	mem 39782MB
[2023-07-07 08:43:39 RepVGG-A0] (main.py 282): INFO Train: [42/300][10/78]	eta 0:03:45 lr 6.093615	time 1.1701 (3.3110)	loss 3.6564 (3.6187)	grad_norm 0.3046 (0.3101)	mem 39782MB
[2023-07-07 08:43:54 RepVGG-A0] (main.py 282): INFO Train: [42/300][20/78]	eta 0:02:22 lr 6.091778	time 1.1810 (2.4533)	loss 3.6445 (3.6339)	grad_norm 0.3314 (0.3194)	mem 39782MB
[2023-07-07 08:44:10 RepVGG-A0] (main.py 282): INFO Train: [42/300][30/78]	eta 0:01:43 lr 6.089935	time 1.9353 (2.1620)	loss 3.7008 (3.6297)	grad_norm 0.3844 (0.3224)	mem 39782MB
[2023-07-07 08:44:27 RepVGG-A0] (main.py 282): INFO Train: [42/300][40/78]	eta 0:01:18 lr 6.088088	time 2.8608 (2.0634)	loss 3.6472 (3.6336)	grad_norm 0.3619 (0.3305)	mem 39782MB
[2023-07-07 08:44:43 RepVGG-A0] (main.py 282): INFO Train: [42/300][50/78]	eta 0:00:54 lr 6.086235	time 1.1754 (1.9584)	loss 3.6245 (3.6317)	grad_norm 0.3298 (0.3319)	mem 39782MB
[2023-07-07 08:44:58 RepVGG-A0] (main.py 282): INFO Train: [42/300][60/78]	eta 0:00:34 lr 6.084377	time 1.3370 (1.8953)	loss 3.5930 (3.6223)	grad_norm 0.3289 (0.3301)	mem 39782MB
[2023-07-07 08:45:13 RepVGG-A0] (main.py 282): INFO Train: [42/300][70/78]	eta 0:00:14 lr 6.082514	time 1.4081 (1.8321)	loss 5.4014 (3.7456)	grad_norm 0.6171 (0.3765)	mem 39782MB
[2023-07-07 08:45:25 RepVGG-A0] (main.py 291): INFO EPOCH 42 training takes 0:02:22
[2023-07-07 08:45:48 RepVGG-A0] (main.py 282): INFO Train: [43/300][0/78]	eta 0:29:59 lr 6.081020	time 23.0714 (23.0714)	loss 4.4556 (4.4556)	grad_norm 0.2995 (0.2995)	mem 39782MB
[2023-07-07 08:46:03 RepVGG-A0] (main.py 282): INFO Train: [43/300][10/78]	eta 0:03:54 lr 6.079148	time 1.1723 (3.4535)	loss 4.1515 (4.1829)	grad_norm 0.3257 (0.2908)	mem 39782MB
[2023-07-07 08:46:19 RepVGG-A0] (main.py 282): INFO Train: [43/300][20/78]	eta 0:02:30 lr 6.077270	time 1.1720 (2.5884)	loss 3.8370 (4.0476)	grad_norm 0.2543 (0.2742)	mem 39782MB
[2023-07-07 08:46:34 RepVGG-A0] (main.py 282): INFO Train: [43/300][30/78]	eta 0:01:46 lr 6.075387	time 1.2000 (2.2144)	loss 3.7527 (3.9768)	grad_norm 0.2847 (0.2890)	mem 39782MB
[2023-07-07 08:46:52 RepVGG-A0] (main.py 282): INFO Train: [43/300][40/78]	eta 0:01:20 lr 6.073499	time 4.2343 (2.1301)	loss 3.5949 (3.8982)	grad_norm 0.2838 (0.2848)	mem 39782MB
[2023-07-07 08:47:07 RepVGG-A0] (main.py 282): INFO Train: [43/300][50/78]	eta 0:00:55 lr 6.071606	time 1.1745 (1.9980)	loss 3.7061 (3.8451)	grad_norm 0.3253 (0.2884)	mem 39782MB
[2023-07-07 08:47:24 RepVGG-A0] (main.py 282): INFO Train: [43/300][60/78]	eta 0:00:34 lr 6.069708	time 1.3964 (1.9440)	loss 3.6639 (3.8132)	grad_norm 0.3038 (0.2949)	mem 39782MB
[2023-07-07 08:47:40 RepVGG-A0] (main.py 282): INFO Train: [43/300][70/78]	eta 0:00:15 lr 6.067804	time 1.3225 (1.8970)	loss 3.6969 (3.7832)	grad_norm 0.3611 (0.2987)	mem 39782MB
[2023-07-07 08:47:50 RepVGG-A0] (main.py 291): INFO EPOCH 43 training takes 0:02:24
[2023-07-07 08:48:14 RepVGG-A0] (main.py 282): INFO Train: [44/300][0/78]	eta 0:31:00 lr 6.066278	time 23.8504 (23.8504)	loss 3.5771 (3.5771)	grad_norm 0.2954 (0.2954)	mem 39782MB
[2023-07-07 08:48:29 RepVGG-A0] (main.py 282): INFO Train: [44/300][10/78]	eta 0:03:59 lr 6.064365	time 1.1992 (3.5257)	loss 3.6885 (3.6417)	grad_norm 0.4345 (0.3724)	mem 39782MB
[2023-07-07 08:48:42 RepVGG-A0] (main.py 282): INFO Train: [44/300][20/78]	eta 0:02:25 lr 6.062447	time 1.1734 (2.5099)	loss 3.5494 (3.6471)	grad_norm 0.2973 (0.3572)	mem 39782MB
[2023-07-07 08:48:59 RepVGG-A0] (main.py 282): INFO Train: [44/300][30/78]	eta 0:01:47 lr 6.060524	time 1.5015 (2.2344)	loss 3.6133 (3.6147)	grad_norm 0.3415 (0.3459)	mem 39782MB
[2023-07-07 08:49:17 RepVGG-A0] (main.py 282): INFO Train: [44/300][40/78]	eta 0:01:20 lr 6.058595	time 2.6882 (2.1249)	loss 3.5408 (3.6126)	grad_norm 0.3129 (0.3475)	mem 39782MB
[2023-07-07 08:49:32 RepVGG-A0] (main.py 282): INFO Train: [44/300][50/78]	eta 0:00:56 lr 6.056662	time 1.1766 (2.0110)	loss 3.6718 (3.5982)	grad_norm 0.3771 (0.3424)	mem 39782MB
[2023-07-07 08:49:47 RepVGG-A0] (main.py 282): INFO Train: [44/300][60/78]	eta 0:00:34 lr 6.054723	time 1.1774 (1.9253)	loss 6.1110 (3.8388)	grad_norm 0.5306 (0.4077)	mem 39782MB
[2023-07-07 08:50:02 RepVGG-A0] (main.py 282): INFO Train: [44/300][70/78]	eta 0:00:14 lr 6.052780	time 1.4157 (1.8631)	loss 5.0074 (4.0714)	grad_norm 0.2979 (0.4005)	mem 39782MB
[2023-07-07 08:50:14 RepVGG-A0] (main.py 291): INFO EPOCH 44 training takes 0:02:24
[2023-07-07 08:50:34 RepVGG-A0] (main.py 282): INFO Train: [45/300][0/78]	eta 0:26:19 lr 6.051221	time 20.2468 (20.2468)	loss 4.8655 (4.8655)	grad_norm 0.4593 (0.4593)	mem 39782MB
[2023-07-07 08:50:49 RepVGG-A0] (main.py 282): INFO Train: [45/300][10/78]	eta 0:03:37 lr 6.049268	time 1.1714 (3.1969)	loss 4.2090 (4.4920)	grad_norm 0.2622 (0.2962)	mem 39782MB
[2023-07-07 08:51:03 RepVGG-A0] (main.py 282): INFO Train: [45/300][20/78]	eta 0:02:15 lr 6.047310	time 1.1898 (2.3434)	loss 4.1325 (4.3335)	grad_norm 0.3535 (0.3022)	mem 39782MB
[2023-07-07 08:51:18 RepVGG-A0] (main.py 282): INFO Train: [45/300][30/78]	eta 0:01:39 lr 6.045346	time 1.3303 (2.0714)	loss 4.0018 (4.2302)	grad_norm 0.3194 (0.2951)	mem 39782MB
[2023-07-07 08:51:37 RepVGG-A0] (main.py 282): INFO Train: [45/300][40/78]	eta 0:01:16 lr 6.043378	time 4.4185 (2.0131)	loss 3.8367 (4.1648)	grad_norm 0.2758 (0.3002)	mem 39782MB
[2023-07-07 08:51:51 RepVGG-A0] (main.py 282): INFO Train: [45/300][50/78]	eta 0:00:53 lr 6.041405	time 1.1706 (1.9057)	loss 3.8494 (4.1091)	grad_norm 0.3430 (0.3055)	mem 39782MB
[2023-07-07 08:52:07 RepVGG-A0] (main.py 282): INFO Train: [45/300][60/78]	eta 0:00:33 lr 6.039426	time 1.1297 (1.8478)	loss 4.2961 (4.0768)	grad_norm 0.6054 (0.3205)	mem 39782MB
[2023-07-07 08:52:22 RepVGG-A0] (main.py 282): INFO Train: [45/300][70/78]	eta 0:00:14 lr 6.037442	time 1.2327 (1.8016)	loss 3.9933 (4.1113)	grad_norm 0.2760 (0.3360)	mem 39782MB
[2023-07-07 08:52:34 RepVGG-A0] (main.py 291): INFO EPOCH 45 training takes 0:02:19
[2023-07-07 08:52:55 RepVGG-A0] (main.py 282): INFO Train: [46/300][0/78]	eta 0:26:50 lr 6.035851	time 20.6450 (20.6450)	loss 3.7938 (3.7938)	grad_norm 0.2596 (0.2596)	mem 39782MB
[2023-07-07 08:53:10 RepVGG-A0] (main.py 282): INFO Train: [46/300][10/78]	eta 0:03:44 lr 6.033858	time 1.1724 (3.3081)	loss 3.6691 (3.7518)	grad_norm 0.3166 (0.2873)	mem 39782MB
[2023-07-07 08:53:26 RepVGG-A0] (main.py 282): INFO Train: [46/300][20/78]	eta 0:02:22 lr 6.031860	time 1.3011 (2.4532)	loss 3.6961 (3.7384)	grad_norm 0.2918 (0.3043)	mem 39782MB
[2023-07-07 08:53:42 RepVGG-A0] (main.py 282): INFO Train: [46/300][30/78]	eta 0:01:45 lr 6.029857	time 1.8113 (2.2009)	loss 3.7862 (3.7313)	grad_norm 0.3898 (0.3162)	mem 39782MB
[2023-07-07 08:54:00 RepVGG-A0] (main.py 282): INFO Train: [46/300][40/78]	eta 0:01:19 lr 6.027849	time 3.4986 (2.0854)	loss 3.6986 (3.7230)	grad_norm 0.3323 (0.3213)	mem 39782MB
[2023-07-07 08:54:14 RepVGG-A0] (main.py 282): INFO Train: [46/300][50/78]	eta 0:00:54 lr 6.025836	time 1.1736 (1.9643)	loss 3.7017 (3.7156)	grad_norm 0.3697 (0.3247)	mem 39782MB
[2023-07-07 08:54:29 RepVGG-A0] (main.py 282): INFO Train: [46/300][60/78]	eta 0:00:33 lr 6.023817	time 1.3029 (1.8802)	loss 3.7196 (3.7301)	grad_norm 0.3131 (0.3347)	mem 39782MB
[2023-07-07 08:54:45 RepVGG-A0] (main.py 282): INFO Train: [46/300][70/78]	eta 0:00:14 lr 6.021794	time 1.3331 (1.8411)	loss 3.8160 (3.7282)	grad_norm 0.4250 (0.3374)	mem 39782MB
[2023-07-07 08:54:56 RepVGG-A0] (main.py 291): INFO EPOCH 46 training takes 0:02:22
[2023-07-07 08:55:19 RepVGG-A0] (main.py 282): INFO Train: [47/300][0/78]	eta 0:28:50 lr 6.020171	time 22.1826 (22.1826)	loss 3.5696 (3.5696)	grad_norm 0.2796 (0.2796)	mem 39782MB
[2023-07-07 08:55:32 RepVGG-A0] (main.py 282): INFO Train: [47/300][10/78]	eta 0:03:39 lr 6.018138	time 1.1892 (3.2308)	loss 3.6336 (3.6185)	grad_norm 0.3517 (0.3406)	mem 39782MB
[2023-07-07 08:55:48 RepVGG-A0] (main.py 282): INFO Train: [47/300][20/78]	eta 0:02:22 lr 6.016101	time 1.1843 (2.4502)	loss 3.6413 (3.6233)	grad_norm 0.3655 (0.3468)	mem 39782MB
[2023-07-07 08:56:02 RepVGG-A0] (main.py 282): INFO Train: [47/300][30/78]	eta 0:01:41 lr 6.014058	time 1.3229 (2.1168)	loss 3.9027 (3.6393)	grad_norm 0.5037 (0.3573)	mem 39782MB
[2023-07-07 08:56:20 RepVGG-A0] (main.py 282): INFO Train: [47/300][40/78]	eta 0:01:17 lr 6.012010	time 3.8285 (2.0351)	loss 3.7270 (3.7235)	grad_norm 0.2925 (0.3810)	mem 39782MB
[2023-07-07 08:56:34 RepVGG-A0] (main.py 282): INFO Train: [47/300][50/78]	eta 0:00:53 lr 6.009957	time 1.1711 (1.9169)	loss 3.7273 (3.7099)	grad_norm 0.4113 (0.3637)	mem 39782MB
[2023-07-07 08:56:50 RepVGG-A0] (main.py 282): INFO Train: [47/300][60/78]	eta 0:00:33 lr 6.007899	time 1.4480 (1.8556)	loss 3.4670 (3.7014)	grad_norm 0.2575 (0.3587)	mem 39782MB
[2023-07-07 08:57:04 RepVGG-A0] (main.py 282): INFO Train: [47/300][70/78]	eta 0:00:14 lr 6.005836	time 1.3453 (1.8019)	loss 3.6096 (3.6861)	grad_norm 0.3760 (0.3543)	mem 39782MB
[2023-07-07 08:57:16 RepVGG-A0] (main.py 291): INFO EPOCH 47 training takes 0:02:19
[2023-07-07 08:57:37 RepVGG-A0] (main.py 282): INFO Train: [48/300][0/78]	eta 0:27:23 lr 6.004181	time 21.0642 (21.0642)	loss 3.4423 (3.4423)	grad_norm 0.3321 (0.3321)	mem 39782MB
[2023-07-07 08:57:52 RepVGG-A0] (main.py 282): INFO Train: [48/300][10/78]	eta 0:03:41 lr 6.002109	time 1.1723 (3.2564)	loss 3.6079 (3.5644)	grad_norm 0.3679 (0.3627)	mem 39782MB
[2023-07-07 08:58:07 RepVGG-A0] (main.py 282): INFO Train: [48/300][20/78]	eta 0:02:20 lr 6.000032	time 1.1741 (2.4251)	loss 3.6025 (3.5761)	grad_norm 0.3330 (0.3525)	mem 39782MB
[2023-07-07 08:58:22 RepVGG-A0] (main.py 282): INFO Train: [48/300][30/78]	eta 0:01:42 lr 5.997950	time 1.5749 (2.1316)	loss 3.5148 (3.5634)	grad_norm 0.3271 (0.3473)	mem 39782MB
[2023-07-07 08:58:41 RepVGG-A0] (main.py 282): INFO Train: [48/300][40/78]	eta 0:01:18 lr 5.995862	time 3.7594 (2.0711)	loss 6.1225 (3.6987)	grad_norm 1.0851 (0.4075)	mem 39782MB
[2023-07-07 08:58:55 RepVGG-A0] (main.py 282): INFO Train: [48/300][50/78]	eta 0:00:54 lr 5.993770	time 1.1719 (1.9392)	loss 5.4030 (4.1445)	grad_norm 0.3712 (0.4201)	mem 39782MB
[2023-07-07 08:59:11 RepVGG-A0] (main.py 282): INFO Train: [48/300][60/78]	eta 0:00:33 lr 5.991672	time 1.4007 (1.8775)	loss 4.6384 (4.2844)	grad_norm 0.2745 (0.4012)	mem 39782MB
[2023-07-07 08:59:26 RepVGG-A0] (main.py 282): INFO Train: [48/300][70/78]	eta 0:00:14 lr 5.989570	time 1.2258 (1.8232)	loss 4.3213 (4.3142)	grad_norm 0.2977 (0.3865)	mem 39782MB
[2023-07-07 08:59:37 RepVGG-A0] (main.py 291): INFO EPOCH 48 training takes 0:02:20
[2023-07-07 08:59:58 RepVGG-A0] (main.py 282): INFO Train: [49/300][0/78]	eta 0:27:27 lr 5.987884	time 21.1170 (21.1170)	loss 4.1322 (4.1322)	grad_norm 0.3038 (0.3038)	mem 39782MB
[2023-07-07 09:00:13 RepVGG-A0] (main.py 282): INFO Train: [49/300][10/78]	eta 0:03:41 lr 5.985773	time 1.1733 (3.2609)	loss 4.1376 (4.0728)	grad_norm 0.4388 (0.3053)	mem 39782MB
[2023-07-07 09:00:28 RepVGG-A0] (main.py 282): INFO Train: [49/300][20/78]	eta 0:02:21 lr 5.983656	time 1.2306 (2.4391)	loss 3.9502 (4.0989)	grad_norm 0.2403 (0.3206)	mem 39782MB
[2023-07-07 09:00:44 RepVGG-A0] (main.py 282): INFO Train: [49/300][30/78]	eta 0:01:43 lr 5.981535	time 1.3693 (2.1561)	loss 3.9387 (4.0293)	grad_norm 0.3422 (0.3050)	mem 39782MB
[2023-07-07 09:01:02 RepVGG-A0] (main.py 282): INFO Train: [49/300][40/78]	eta 0:01:19 lr 5.979408	time 2.6063 (2.0798)	loss 3.9272 (3.9855)	grad_norm 0.3663 (0.3073)	mem 39782MB
[2023-07-07 09:01:17 RepVGG-A0] (main.py 282): INFO Train: [49/300][50/78]	eta 0:00:54 lr 5.977276	time 1.1299 (1.9615)	loss 3.7437 (3.9472)	grad_norm 0.2899 (0.3088)	mem 39782MB
[2023-07-07 09:01:32 RepVGG-A0] (main.py 282): INFO Train: [49/300][60/78]	eta 0:00:34 lr 5.975140	time 1.2973 (1.8895)	loss 3.8995 (3.9232)	grad_norm 0.4693 (0.3180)	mem 39782MB
[2023-07-07 09:01:47 RepVGG-A0] (main.py 282): INFO Train: [49/300][70/78]	eta 0:00:14 lr 5.972998	time 1.1789 (1.8232)	loss 4.0035 (3.9620)	grad_norm 0.3394 (0.3382)	mem 39782MB
[2023-07-07 09:01:59 RepVGG-A0] (main.py 291): INFO EPOCH 49 training takes 0:02:21
[2023-07-07 09:02:20 RepVGG-A0] (main.py 282): INFO Train: [50/300][0/78]	eta 0:26:55 lr 5.971281	time 20.7157 (20.7157)	loss 3.7558 (3.7558)	grad_norm 0.2950 (0.2950)	mem 39782MB
[2023-07-07 09:02:35 RepVGG-A0] (main.py 282): INFO Train: [50/300][10/78]	eta 0:03:42 lr 5.969131	time 1.1927 (3.2724)	loss 3.6921 (3.7002)	grad_norm 0.2737 (0.2964)	mem 39782MB
[2023-07-07 09:02:50 RepVGG-A0] (main.py 282): INFO Train: [50/300][20/78]	eta 0:02:21 lr 5.966975	time 1.1933 (2.4338)	loss 3.8223 (3.6957)	grad_norm 0.3660 (0.3141)	mem 39782MB
[2023-07-07 09:03:06 RepVGG-A0] (main.py 282): INFO Train: [50/300][30/78]	eta 0:01:43 lr 5.964815	time 1.4922 (2.1618)	loss 3.7176 (3.7029)	grad_norm 0.3405 (0.3242)	mem 39782MB
[2023-07-07 09:03:23 RepVGG-A0] (main.py 282): INFO Train: [50/300][40/78]	eta 0:01:18 lr 5.962649	time 2.6992 (2.0538)	loss 3.6058 (3.6846)	grad_norm 0.3403 (0.3205)	mem 39782MB
[2023-07-07 09:03:37 RepVGG-A0] (main.py 282): INFO Train: [50/300][50/78]	eta 0:00:53 lr 5.960478	time 1.1921 (1.9216)	loss 3.7661 (3.7144)	grad_norm 0.3356 (0.3412)	mem 39782MB
[2023-07-07 09:03:53 RepVGG-A0] (main.py 282): INFO Train: [50/300][60/78]	eta 0:00:33 lr 5.958303	time 1.1981 (1.8674)	loss 3.6555 (3.7012)	grad_norm 0.3280 (0.3350)	mem 39782MB
[2023-07-07 09:04:07 RepVGG-A0] (main.py 282): INFO Train: [50/300][70/78]	eta 0:00:14 lr 5.956122	time 1.3610 (1.8052)	loss 3.5622 (3.6945)	grad_norm 0.3263 (0.3350)	mem 39782MB
[2023-07-07 09:04:19 RepVGG-A0] (main.py 291): INFO EPOCH 50 training takes 0:02:20
[2023-07-07 09:04:40 RepVGG-A0] (main.py 282): INFO Train: [51/300][0/78]	eta 0:26:51 lr 5.954374	time 20.6553 (20.6553)	loss 3.6441 (3.6441)	grad_norm 0.3777 (0.3777)	mem 39782MB
[2023-07-07 09:04:54 RepVGG-A0] (main.py 282): INFO Train: [51/300][10/78]	eta 0:03:36 lr 5.952185	time 1.1721 (3.1903)	loss 3.6295 (3.6677)	grad_norm 0.3116 (0.3741)	mem 39782MB
[2023-07-07 09:05:09 RepVGG-A0] (main.py 282): INFO Train: [51/300][20/78]	eta 0:02:18 lr 5.949991	time 1.1756 (2.3943)	loss 3.5870 (3.6442)	grad_norm 0.3179 (0.3613)	mem 39782MB
[2023-07-07 09:05:25 RepVGG-A0] (main.py 282): INFO Train: [51/300][30/78]	eta 0:01:41 lr 5.947791	time 1.1935 (2.1150)	loss 3.5994 (3.6248)	grad_norm 0.3729 (0.3550)	mem 39782MB
[2023-07-07 09:05:43 RepVGG-A0] (main.py 282): INFO Train: [51/300][40/78]	eta 0:01:17 lr 5.945587	time 3.8996 (2.0390)	loss 3.5805 (3.6231)	grad_norm 0.3457 (0.3568)	mem 39782MB
[2023-07-07 09:05:57 RepVGG-A0] (main.py 282): INFO Train: [51/300][50/78]	eta 0:00:53 lr 5.943378	time 1.1733 (1.9280)	loss 3.5130 (3.6180)	grad_norm 0.3412 (0.3562)	mem 39782MB
[2023-07-07 09:06:13 RepVGG-A0] (main.py 282): INFO Train: [51/300][60/78]	eta 0:00:33 lr 5.941164	time 1.6274 (1.8645)	loss 6.0795 (3.8053)	grad_norm 0.5566 (0.4047)	mem 39782MB
[2023-07-07 09:06:27 RepVGG-A0] (main.py 282): INFO Train: [51/300][70/78]	eta 0:00:14 lr 5.938944	time 1.2583 (1.8027)	loss 5.2089 (4.0805)	grad_norm 0.2728 (0.4118)	mem 39782MB
[2023-07-07 09:06:39 RepVGG-A0] (main.py 291): INFO EPOCH 51 training takes 0:02:19
[2023-07-07 09:07:00 RepVGG-A0] (main.py 282): INFO Train: [52/300][0/78]	eta 0:27:28 lr 5.937166	time 21.1333 (21.1333)	loss 4.7100 (4.7100)	grad_norm 0.3029 (0.3029)	mem 39782MB
[2023-07-07 09:07:15 RepVGG-A0] (main.py 282): INFO Train: [52/300][10/78]	eta 0:03:42 lr 5.934938	time 1.1723 (3.2703)	loss 4.3257 (4.5026)	grad_norm 0.3327 (0.2876)	mem 39782MB
[2023-07-07 09:07:29 RepVGG-A0] (main.py 282): INFO Train: [52/300][20/78]	eta 0:02:18 lr 5.932705	time 1.1730 (2.3928)	loss 4.2245 (4.3782)	grad_norm 0.3075 (0.2900)	mem 39782MB
[2023-07-07 09:07:45 RepVGG-A0] (main.py 282): INFO Train: [52/300][30/78]	eta 0:01:41 lr 5.930467	time 1.6135 (2.1221)	loss 4.0353 (4.2869)	grad_norm 0.2978 (0.2967)	mem 39782MB
[2023-07-07 09:08:03 RepVGG-A0] (main.py 282): INFO Train: [52/300][40/78]	eta 0:01:17 lr 5.928224	time 3.5339 (2.0460)	loss 3.9572 (4.2161)	grad_norm 0.2919 (0.2976)	mem 39782MB
[2023-07-07 09:08:18 RepVGG-A0] (main.py 282): INFO Train: [52/300][50/78]	eta 0:00:54 lr 5.925976	time 1.1757 (1.9445)	loss 3.9247 (4.1532)	grad_norm 0.3220 (0.2993)	mem 39782MB
[2023-07-07 09:08:33 RepVGG-A0] (main.py 282): INFO Train: [52/300][60/78]	eta 0:00:33 lr 5.923724	time 1.2386 (1.8759)	loss 3.9441 (4.1158)	grad_norm 0.3542 (0.3089)	mem 39782MB
[2023-07-07 09:08:48 RepVGG-A0] (main.py 282): INFO Train: [52/300][70/78]	eta 0:00:14 lr 5.921466	time 1.1815 (1.8168)	loss 4.4732 (4.0854)	grad_norm 0.7432 (0.3164)	mem 39782MB
[2023-07-07 09:09:01 RepVGG-A0] (main.py 291): INFO EPOCH 52 training takes 0:02:21
[2023-07-07 09:09:21 RepVGG-A0] (main.py 282): INFO Train: [53/300][0/78]	eta 0:25:57 lr 5.919657	time 19.9726 (19.9726)	loss 5.1831 (5.1831)	grad_norm 0.4777 (0.4777)	mem 39782MB
[2023-07-07 09:09:36 RepVGG-A0] (main.py 282): INFO Train: [53/300][10/78]	eta 0:03:39 lr 5.917390	time 1.1707 (3.2306)	loss 4.1867 (4.4992)	grad_norm 0.3043 (0.3298)	mem 39782MB
[2023-07-07 09:09:50 RepVGG-A0] (main.py 282): INFO Train: [53/300][20/78]	eta 0:02:17 lr 5.915119	time 1.1709 (2.3650)	loss 3.9154 (4.3027)	grad_norm 0.2308 (0.3019)	mem 39782MB
[2023-07-07 09:10:06 RepVGG-A0] (main.py 282): INFO Train: [53/300][30/78]	eta 0:01:40 lr 5.912843	time 1.2219 (2.0917)	loss 3.9735 (4.1741)	grad_norm 0.3032 (0.2942)	mem 39782MB
[2023-07-07 09:10:24 RepVGG-A0] (main.py 282): INFO Train: [53/300][40/78]	eta 0:01:16 lr 5.910562	time 3.7812 (2.0212)	loss 3.8370 (4.0817)	grad_norm 0.2973 (0.2907)	mem 39782MB
[2023-07-07 09:10:39 RepVGG-A0] (main.py 282): INFO Train: [53/300][50/78]	eta 0:00:53 lr 5.908276	time 1.1757 (1.9226)	loss 3.7631 (4.0263)	grad_norm 0.3332 (0.2959)	mem 39782MB
[2023-07-07 09:10:54 RepVGG-A0] (main.py 282): INFO Train: [53/300][60/78]	eta 0:00:33 lr 5.905985	time 1.2764 (1.8504)	loss 3.7129 (3.9934)	grad_norm 0.2992 (0.3058)	mem 39782MB
[2023-07-07 09:11:08 RepVGG-A0] (main.py 282): INFO Train: [53/300][70/78]	eta 0:00:14 lr 5.903689	time 1.2126 (1.7970)	loss 3.7415 (3.9552)	grad_norm 0.3184 (0.3045)	mem 39782MB
[2023-07-07 09:11:20 RepVGG-A0] (main.py 291): INFO EPOCH 53 training takes 0:02:19
[2023-07-07 09:11:41 RepVGG-A0] (main.py 282): INFO Train: [54/300][0/78]	eta 0:27:09 lr 5.901849	time 20.8912 (20.8912)	loss 3.8013 (3.8013)	grad_norm 0.4143 (0.4143)	mem 39782MB
[2023-07-07 09:11:57 RepVGG-A0] (main.py 282): INFO Train: [54/300][10/78]	eta 0:03:47 lr 5.899545	time 1.1716 (3.3504)	loss 3.7819 (3.9357)	grad_norm 0.2811 (0.4191)	mem 39782MB
[2023-07-07 09:12:12 RepVGG-A0] (main.py 282): INFO Train: [54/300][20/78]	eta 0:02:23 lr 5.897236	time 1.1857 (2.4689)	loss 3.7023 (3.8101)	grad_norm 0.3360 (0.3612)	mem 39782MB
[2023-07-07 09:12:28 RepVGG-A0] (main.py 282): INFO Train: [54/300][30/78]	eta 0:01:44 lr 5.894921	time 1.3379 (2.1835)	loss 3.7909 (3.7788)	grad_norm 0.3742 (0.3560)	mem 39782MB
[2023-07-07 09:12:45 RepVGG-A0] (main.py 282): INFO Train: [54/300][40/78]	eta 0:01:19 lr 5.892602	time 2.8559 (2.0818)	loss 3.6540 (3.7485)	grad_norm 0.3055 (0.3458)	mem 39782MB
[2023-07-07 09:13:00 RepVGG-A0] (main.py 282): INFO Train: [54/300][50/78]	eta 0:00:54 lr 5.890278	time 1.1725 (1.9642)	loss 3.6803 (3.7340)	grad_norm 0.3613 (0.3470)	mem 39782MB
[2023-07-07 09:13:16 RepVGG-A0] (main.py 282): INFO Train: [54/300][60/78]	eta 0:00:34 lr 5.887950	time 1.3277 (1.8980)	loss 4.1606 (3.7340)	grad_norm 0.5986 (0.3528)	mem 39782MB
[2023-07-07 09:13:31 RepVGG-A0] (main.py 282): INFO Train: [54/300][70/78]	eta 0:00:14 lr 5.885616	time 1.3117 (1.8419)	loss 3.7920 (3.7837)	grad_norm 0.2966 (0.3676)	mem 39782MB
[2023-07-07 09:13:42 RepVGG-A0] (main.py 291): INFO EPOCH 54 training takes 0:02:22
[2023-07-07 09:14:04 RepVGG-A0] (main.py 282): INFO Train: [55/300][0/78]	eta 0:28:58 lr 5.883746	time 22.2935 (22.2935)	loss 3.5938 (3.5938)	grad_norm 0.3142 (0.3142)	mem 39782MB
[2023-07-07 09:14:18 RepVGG-A0] (main.py 282): INFO Train: [55/300][10/78]	eta 0:03:44 lr 5.881404	time 1.1711 (3.2993)	loss 3.5359 (3.6462)	grad_norm 0.2664 (0.3141)	mem 39782MB
[2023-07-07 09:14:32 RepVGG-A0] (main.py 282): INFO Train: [55/300][20/78]	eta 0:02:18 lr 5.879056	time 1.1899 (2.3933)	loss 3.6805 (3.6281)	grad_norm 0.3742 (0.3193)	mem 39782MB
[2023-07-07 09:14:48 RepVGG-A0] (main.py 282): INFO Train: [55/300][30/78]	eta 0:01:41 lr 5.876704	time 1.5999 (2.1245)	loss 3.6404 (3.6279)	grad_norm 0.3462 (0.3244)	mem 39782MB
[2023-07-07 09:15:05 RepVGG-A0] (main.py 282): INFO Train: [55/300][40/78]	eta 0:01:16 lr 5.874348	time 3.7317 (2.0182)	loss 3.6862 (3.6206)	grad_norm 0.4316 (0.3270)	mem 39782MB
[2023-07-07 09:15:22 RepVGG-A0] (main.py 282): INFO Train: [55/300][50/78]	eta 0:00:54 lr 5.871986	time 1.1726 (1.9529)	loss 3.6217 (3.6259)	grad_norm 0.3439 (0.3371)	mem 39782MB
[2023-07-07 09:15:37 RepVGG-A0] (main.py 282): INFO Train: [55/300][60/78]	eta 0:00:33 lr 5.869620	time 1.3275 (1.8830)	loss 3.5402 (3.6215)	grad_norm 0.3490 (0.3377)	mem 39782MB
[2023-07-07 09:15:52 RepVGG-A0] (main.py 282): INFO Train: [55/300][70/78]	eta 0:00:14 lr 5.867248	time 1.3631 (1.8279)	loss 4.1844 (3.6681)	grad_norm 0.5416 (0.3622)	mem 39782MB
[2023-07-07 09:16:03 RepVGG-A0] (main.py 291): INFO EPOCH 55 training takes 0:02:20
[2023-07-07 09:16:24 RepVGG-A0] (main.py 282): INFO Train: [56/300][0/78]	eta 0:27:25 lr 5.865348	time 21.1016 (21.1016)	loss 3.5918 (3.5918)	grad_norm 0.2869 (0.2869)	mem 39782MB
[2023-07-07 09:16:40 RepVGG-A0] (main.py 282): INFO Train: [56/300][10/78]	eta 0:03:47 lr 5.862968	time 1.1714 (3.3515)	loss 3.6275 (3.5780)	grad_norm 0.2982 (0.2909)	mem 39782MB
[2023-07-07 09:16:54 RepVGG-A0] (main.py 282): INFO Train: [56/300][20/78]	eta 0:02:21 lr 5.860583	time 1.4242 (2.4417)	loss 3.5802 (3.5727)	grad_norm 0.3235 (0.3030)	mem 39782MB
[2023-07-07 09:17:10 RepVGG-A0] (main.py 282): INFO Train: [56/300][30/78]	eta 0:01:43 lr 5.858194	time 1.3621 (2.1504)	loss 3.5433 (3.5574)	grad_norm 0.3312 (0.3073)	mem 39782MB
[2023-07-07 09:17:27 RepVGG-A0] (main.py 282): INFO Train: [56/300][40/78]	eta 0:01:17 lr 5.855800	time 2.8778 (2.0525)	loss 3.5901 (3.5578)	grad_norm 0.3846 (0.3146)	mem 39782MB
[2023-07-07 09:17:43 RepVGG-A0] (main.py 282): INFO Train: [56/300][50/78]	eta 0:00:54 lr 5.853401	time 1.1732 (1.9531)	loss 4.2889 (3.6266)	grad_norm 0.6707 (0.3569)	mem 39782MB
[2023-07-07 09:17:59 RepVGG-A0] (main.py 282): INFO Train: [56/300][60/78]	eta 0:00:34 lr 5.850997	time 1.4346 (1.8966)	loss 3.8084 (3.7167)	grad_norm 0.2702 (0.3711)	mem 39782MB
[2023-07-07 09:18:14 RepVGG-A0] (main.py 282): INFO Train: [56/300][70/78]	eta 0:00:14 lr 5.848588	time 1.2409 (1.8390)	loss 3.7793 (3.7159)	grad_norm 0.3020 (0.3574)	mem 39782MB
[2023-07-07 09:18:25 RepVGG-A0] (main.py 291): INFO EPOCH 56 training takes 0:02:21
[2023-07-07 09:18:46 RepVGG-A0] (main.py 282): INFO Train: [57/300][0/78]	eta 0:27:53 lr 5.846658	time 21.4611 (21.4611)	loss 3.4556 (3.4556)	grad_norm 0.2411 (0.2411)	mem 39782MB
[2023-07-07 09:19:00 RepVGG-A0] (main.py 282): INFO Train: [57/300][10/78]	eta 0:03:36 lr 5.844241	time 1.1745 (3.1874)	loss 3.5334 (3.4731)	grad_norm 0.3036 (0.2740)	mem 39782MB
[2023-07-07 09:19:15 RepVGG-A0] (main.py 282): INFO Train: [57/300][20/78]	eta 0:02:18 lr 5.841819	time 1.1919 (2.3896)	loss 3.6260 (3.5044)	grad_norm 0.3639 (0.3037)	mem 39782MB
[2023-07-07 09:19:31 RepVGG-A0] (main.py 282): INFO Train: [57/300][30/78]	eta 0:01:42 lr 5.839392	time 1.4899 (2.1358)	loss 3.5134 (3.5206)	grad_norm 0.3151 (0.3156)	mem 39782MB
[2023-07-07 09:19:48 RepVGG-A0] (main.py 282): INFO Train: [57/300][40/78]	eta 0:01:17 lr 5.836960	time 2.2331 (2.0353)	loss 3.5685 (3.5152)	grad_norm 0.3532 (0.3159)	mem 39782MB
[2023-07-07 09:20:03 RepVGG-A0] (main.py 282): INFO Train: [57/300][50/78]	eta 0:00:54 lr 5.834524	time 1.1722 (1.9337)	loss 3.4588 (3.5199)	grad_norm 0.3171 (0.3222)	mem 39782MB
[2023-07-07 09:20:19 RepVGG-A0] (main.py 282): INFO Train: [57/300][60/78]	eta 0:00:33 lr 5.832083	time 1.2712 (1.8689)	loss 3.6518 (3.5339)	grad_norm 0.4287 (0.3322)	mem 39782MB
[2023-07-07 09:20:35 RepVGG-A0] (main.py 282): INFO Train: [57/300][70/78]	eta 0:00:14 lr 5.829637	time 1.4240 (1.8335)	loss 3.5807 (3.5467)	grad_norm 0.3394 (0.3365)	mem 39782MB
[2023-07-07 09:20:46 RepVGG-A0] (main.py 291): INFO EPOCH 57 training takes 0:02:21
[2023-07-07 09:21:07 RepVGG-A0] (main.py 282): INFO Train: [58/300][0/78]	eta 0:28:08 lr 5.827677	time 21.6499 (21.6499)	loss 3.5252 (3.5252)	grad_norm 0.3257 (0.3257)	mem 39782MB
[2023-07-07 09:21:22 RepVGG-A0] (main.py 282): INFO Train: [58/300][10/78]	eta 0:03:41 lr 5.825223	time 1.2015 (3.2645)	loss 3.5415 (3.4982)	grad_norm 0.4379 (0.3458)	mem 39782MB
[2023-07-07 09:21:37 RepVGG-A0] (main.py 282): INFO Train: [58/300][20/78]	eta 0:02:21 lr 5.822764	time 1.2404 (2.4408)	loss 5.7298 (4.0169)	grad_norm 0.8552 (0.5332)	mem 39782MB
[2023-07-07 09:21:51 RepVGG-A0] (main.py 282): INFO Train: [58/300][30/78]	eta 0:01:41 lr 5.820300	time 1.5833 (2.1231)	loss 4.2640 (4.2801)	grad_norm 0.2507 (0.4912)	mem 39782MB
[2023-07-07 09:22:09 RepVGG-A0] (main.py 282): INFO Train: [58/300][40/78]	eta 0:01:17 lr 5.817832	time 4.0953 (2.0419)	loss 3.8599 (4.2426)	grad_norm 0.2199 (0.4393)	mem 39782MB
[2023-07-07 09:22:24 RepVGG-A0] (main.py 282): INFO Train: [58/300][50/78]	eta 0:00:54 lr 5.815359	time 1.1723 (1.9353)	loss 3.8534 (4.1710)	grad_norm 0.2943 (0.4105)	mem 39782MB
[2023-07-07 09:22:40 RepVGG-A0] (main.py 282): INFO Train: [58/300][60/78]	eta 0:00:33 lr 5.812881	time 1.2326 (1.8781)	loss 3.6598 (4.0960)	grad_norm 0.2548 (0.3863)	mem 39782MB
[2023-07-07 09:22:56 RepVGG-A0] (main.py 282): INFO Train: [58/300][70/78]	eta 0:00:14 lr 5.810398	time 1.3273 (1.8301)	loss 3.5012 (4.0317)	grad_norm 0.2529 (0.3735)	mem 39782MB
[2023-07-07 09:23:07 RepVGG-A0] (main.py 291): INFO EPOCH 58 training takes 0:02:21
[2023-07-07 09:23:27 RepVGG-A0] (main.py 282): INFO Train: [59/300][0/78]	eta 0:26:27 lr 5.808409	time 20.3475 (20.3475)	loss 3.7108 (3.7108)	grad_norm 0.4193 (0.4193)	mem 39782MB
[2023-07-07 09:23:43 RepVGG-A0] (main.py 282): INFO Train: [59/300][10/78]	eta 0:03:40 lr 5.805918	time 1.1921 (3.2421)	loss 3.5066 (3.5797)	grad_norm 0.2791 (0.3217)	mem 39782MB
[2023-07-07 09:23:58 RepVGG-A0] (main.py 282): INFO Train: [59/300][20/78]	eta 0:02:21 lr 5.803422	time 1.1743 (2.4345)	loss 3.6042 (3.5813)	grad_norm 0.3507 (0.3272)	mem 39782MB
[2023-07-07 09:24:14 RepVGG-A0] (main.py 282): INFO Train: [59/300][30/78]	eta 0:01:43 lr 5.800922	time 1.5215 (2.1648)	loss 3.4761 (3.5928)	grad_norm 0.2843 (0.3336)	mem 39782MB
[2023-07-07 09:24:32 RepVGG-A0] (main.py 282): INFO Train: [59/300][40/78]	eta 0:01:19 lr 5.798417	time 3.4245 (2.0872)	loss 3.5045 (3.5837)	grad_norm 0.3075 (0.3316)	mem 39782MB
[2023-07-07 09:24:47 RepVGG-A0] (main.py 282): INFO Train: [59/300][50/78]	eta 0:00:55 lr 5.795907	time 1.1753 (1.9711)	loss 3.5615 (3.5796)	grad_norm 0.3520 (0.3340)	mem 39782MB
[2023-07-07 09:25:02 RepVGG-A0] (main.py 282): INFO Train: [59/300][60/78]	eta 0:00:34 lr 5.793392	time 1.2416 (1.8937)	loss 3.5471 (3.5785)	grad_norm 0.3667 (0.3382)	mem 39782MB
[2023-07-07 09:25:18 RepVGG-A0] (main.py 282): INFO Train: [59/300][70/78]	eta 0:00:14 lr 5.790873	time 1.1923 (1.8525)	loss 3.4160 (3.5747)	grad_norm 0.2880 (0.3382)	mem 39782MB
[2023-07-07 09:25:29 RepVGG-A0] (main.py 291): INFO EPOCH 59 training takes 0:02:22
[2023-07-07 09:25:51 RepVGG-A0] (main.py 282): INFO Train: [60/300][0/78]	eta 0:28:30 lr 5.788854	time 21.9297 (21.9297)	loss 3.5127 (3.5127)	grad_norm 0.3800 (0.3800)	mem 39782MB
[2023-07-07 09:26:05 RepVGG-A0] (main.py 282): INFO Train: [60/300][10/78]	eta 0:03:41 lr 5.786327	time 1.1740 (3.2573)	loss 3.8670 (3.7574)	grad_norm 0.4371 (0.4711)	mem 39782MB
[2023-07-07 09:26:20 RepVGG-A0] (main.py 282): INFO Train: [60/300][20/78]	eta 0:02:19 lr 5.783795	time 1.1729 (2.4087)	loss 3.5336 (3.6628)	grad_norm 0.3213 (0.3947)	mem 39782MB
[2023-07-07 09:26:35 RepVGG-A0] (main.py 282): INFO Train: [60/300][30/78]	eta 0:01:41 lr 5.781258	time 1.1853 (2.1121)	loss 3.4368 (3.6058)	grad_norm 0.2783 (0.3676)	mem 39782MB
[2023-07-07 09:26:54 RepVGG-A0] (main.py 282): INFO Train: [60/300][40/78]	eta 0:01:18 lr 5.778716	time 4.3655 (2.0579)	loss 3.5585 (3.5761)	grad_norm 0.3812 (0.3604)	mem 39782MB
[2023-07-07 09:27:09 RepVGG-A0] (main.py 282): INFO Train: [60/300][50/78]	eta 0:00:54 lr 5.776170	time 1.3149 (1.9490)	loss 3.5425 (3.5925)	grad_norm 0.3176 (0.3683)	mem 39782MB
[2023-07-07 09:27:23 RepVGG-A0] (main.py 282): INFO Train: [60/300][60/78]	eta 0:00:33 lr 5.773619	time 1.1778 (1.8626)	loss 3.4509 (3.5747)	grad_norm 0.3014 (0.3571)	mem 39782MB
[2023-07-07 09:27:38 RepVGG-A0] (main.py 282): INFO Train: [60/300][70/78]	eta 0:00:14 lr 5.771064	time 1.3956 (1.8170)	loss 4.6611 (3.6252)	grad_norm 0.9074 (0.3854)	mem 39782MB
[2023-07-07 09:27:50 RepVGG-A0] (main.py 291): INFO EPOCH 60 training takes 0:02:21
[2023-07-07 09:28:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.402 (17.402)	Loss 9.5352 (9.5352)	Acc@1 1.117 (1.117)	Acc@5 4.065 (4.065)	Mem 39782MB
[2023-07-07 09:28:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 1.154 Acc@5 3.944
[2023-07-07 09:28:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 60: 1.154%
[2023-07-07 09:28:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 09:28:31 RepVGG-A0] (main.py 282): INFO Train: [61/300][0/78]	eta 0:28:33 lr 5.769016	time 21.9644 (21.9644)	loss 4.4185 (4.4185)	grad_norm 0.3837 (0.3837)	mem 39782MB
[2023-07-07 09:28:48 RepVGG-A0] (main.py 282): INFO Train: [61/300][10/78]	eta 0:04:00 lr 5.766452	time 1.1751 (3.5340)	loss 3.8298 (4.0821)	grad_norm 0.2932 (0.3212)	mem 39782MB
[2023-07-07 09:29:02 RepVGG-A0] (main.py 282): INFO Train: [61/300][20/78]	eta 0:02:26 lr 5.763884	time 1.1737 (2.5235)	loss 3.6596 (3.9174)	grad_norm 0.2410 (0.3010)	mem 39782MB
[2023-07-07 09:29:17 RepVGG-A0] (main.py 282): INFO Train: [61/300][30/78]	eta 0:01:44 lr 5.761311	time 1.1730 (2.1844)	loss 3.5477 (3.8116)	grad_norm 0.2852 (0.2923)	mem 39782MB
[2023-07-07 09:29:34 RepVGG-A0] (main.py 282): INFO Train: [61/300][40/78]	eta 0:01:18 lr 5.758733	time 3.3027 (2.0758)	loss 3.5702 (3.7369)	grad_norm 0.3038 (0.2913)	mem 39782MB
[2023-07-07 09:29:49 RepVGG-A0] (main.py 282): INFO Train: [61/300][50/78]	eta 0:00:54 lr 5.756151	time 1.2168 (1.9580)	loss 3.4163 (3.6891)	grad_norm 0.3334 (0.2957)	mem 39782MB
[2023-07-07 09:30:04 RepVGG-A0] (main.py 282): INFO Train: [61/300][60/78]	eta 0:00:34 lr 5.753564	time 1.2117 (1.8925)	loss 3.4564 (3.6519)	grad_norm 0.2989 (0.2962)	mem 39782MB
[2023-07-07 09:30:20 RepVGG-A0] (main.py 282): INFO Train: [61/300][70/78]	eta 0:00:14 lr 5.750972	time 1.4407 (1.8485)	loss 3.5942 (3.6362)	grad_norm 0.4232 (0.3059)	mem 39782MB
[2023-07-07 09:30:31 RepVGG-A0] (main.py 291): INFO EPOCH 61 training takes 0:02:22
[2023-07-07 09:30:52 RepVGG-A0] (main.py 282): INFO Train: [62/300][0/78]	eta 0:26:49 lr 5.748896	time 20.6379 (20.6379)	loss 3.4876 (3.4876)	grad_norm 0.3303 (0.3303)	mem 39782MB
[2023-07-07 09:31:06 RepVGG-A0] (main.py 282): INFO Train: [62/300][10/78]	eta 0:03:31 lr 5.746296	time 1.1721 (3.1133)	loss 3.4261 (3.4233)	grad_norm 0.3172 (0.3186)	mem 39782MB
[2023-07-07 09:31:21 RepVGG-A0] (main.py 282): INFO Train: [62/300][20/78]	eta 0:02:17 lr 5.743692	time 1.2808 (2.3721)	loss 3.5084 (3.4317)	grad_norm 0.3536 (0.3274)	mem 39782MB
[2023-07-07 09:31:37 RepVGG-A0] (main.py 282): INFO Train: [62/300][30/78]	eta 0:01:41 lr 5.741083	time 1.3890 (2.1187)	loss 3.6301 (3.4680)	grad_norm 0.4112 (0.3466)	mem 39782MB
[2023-07-07 09:31:55 RepVGG-A0] (main.py 282): INFO Train: [62/300][40/78]	eta 0:01:17 lr 5.738469	time 3.6165 (2.0274)	loss 3.7289 (3.5543)	grad_norm 0.3568 (0.3771)	mem 39782MB
[2023-07-07 09:32:10 RepVGG-A0] (main.py 282): INFO Train: [62/300][50/78]	eta 0:00:53 lr 5.735851	time 1.1720 (1.9274)	loss 3.4514 (3.5457)	grad_norm 0.2826 (0.3600)	mem 39782MB
[2023-07-07 09:32:25 RepVGG-A0] (main.py 282): INFO Train: [62/300][60/78]	eta 0:00:33 lr 5.733228	time 1.1412 (1.8583)	loss 3.5076 (3.5355)	grad_norm 0.3257 (0.3530)	mem 39782MB
[2023-07-07 09:32:40 RepVGG-A0] (main.py 282): INFO Train: [62/300][70/78]	eta 0:00:14 lr 5.730601	time 1.2891 (1.8069)	loss 3.4964 (3.5262)	grad_norm 0.3370 (0.3522)	mem 39782MB
[2023-07-07 09:32:52 RepVGG-A0] (main.py 291): INFO EPOCH 62 training takes 0:02:20
[2023-07-07 09:33:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][0/78]	eta 0:28:32 lr 5.728496	time 21.9584 (21.9584)	loss 3.4153 (3.4153)	grad_norm 0.3240 (0.3240)	mem 39782MB
[2023-07-07 09:33:28 RepVGG-A0] (main.py 282): INFO Train: [63/300][10/78]	eta 0:03:41 lr 5.725861	time 1.1736 (3.2635)	loss 3.4301 (3.3948)	grad_norm 0.4217 (0.3436)	mem 39782MB
[2023-07-07 09:33:42 RepVGG-A0] (main.py 282): INFO Train: [63/300][20/78]	eta 0:02:18 lr 5.723221	time 1.2870 (2.3818)	loss 5.1587 (3.8983)	grad_norm 0.7453 (0.5193)	mem 39782MB
[2023-07-07 09:33:57 RepVGG-A0] (main.py 282): INFO Train: [63/300][30/78]	eta 0:01:40 lr 5.720576	time 1.4787 (2.0956)	loss 4.1814 (4.1525)	grad_norm 0.2767 (0.4875)	mem 39782MB
[2023-07-07 09:34:14 RepVGG-A0] (main.py 282): INFO Train: [63/300][40/78]	eta 0:01:15 lr 5.717927	time 3.0404 (1.9997)	loss 3.8237 (4.1041)	grad_norm 0.2881 (0.4358)	mem 39782MB
[2023-07-07 09:34:29 RepVGG-A0] (main.py 282): INFO Train: [63/300][50/78]	eta 0:00:53 lr 5.715273	time 1.3423 (1.9182)	loss 3.6916 (4.0313)	grad_norm 0.3010 (0.4041)	mem 39782MB
[2023-07-07 09:34:45 RepVGG-A0] (main.py 282): INFO Train: [63/300][60/78]	eta 0:00:33 lr 5.712615	time 1.1728 (1.8543)	loss 3.5893 (3.9623)	grad_norm 0.2600 (0.3830)	mem 39782MB
[2023-07-07 09:35:00 RepVGG-A0] (main.py 282): INFO Train: [63/300][70/78]	eta 0:00:14 lr 5.709952	time 1.3302 (1.8123)	loss 3.4956 (3.9028)	grad_norm 0.3287 (0.3677)	mem 39782MB
[2023-07-07 09:35:12 RepVGG-A0] (main.py 291): INFO EPOCH 63 training takes 0:02:20
[2023-07-07 09:35:33 RepVGG-A0] (main.py 282): INFO Train: [64/300][0/78]	eta 0:27:51 lr 5.707819	time 21.4262 (21.4262)	loss 3.5431 (3.5431)	grad_norm 0.3458 (0.3458)	mem 39782MB
[2023-07-07 09:35:49 RepVGG-A0] (main.py 282): INFO Train: [64/300][10/78]	eta 0:03:49 lr 5.705148	time 1.1696 (3.3787)	loss 3.3823 (3.4813)	grad_norm 0.2726 (0.3107)	mem 39782MB
[2023-07-07 09:36:04 RepVGG-A0] (main.py 282): INFO Train: [64/300][20/78]	eta 0:02:25 lr 5.702473	time 1.1980 (2.5114)	loss 3.6720 (3.4833)	grad_norm 0.4396 (0.3233)	mem 39782MB
[2023-07-07 09:36:20 RepVGG-A0] (main.py 282): INFO Train: [64/300][30/78]	eta 0:01:45 lr 5.699793	time 1.6070 (2.1962)	loss 3.4669 (3.5157)	grad_norm 0.2986 (0.3359)	mem 39782MB
[2023-07-07 09:36:38 RepVGG-A0] (main.py 282): INFO Train: [64/300][40/78]	eta 0:01:19 lr 5.697109	time 2.1216 (2.0944)	loss 3.5325 (3.5055)	grad_norm 0.3475 (0.3318)	mem 39782MB
[2023-07-07 09:36:53 RepVGG-A0] (main.py 282): INFO Train: [64/300][50/78]	eta 0:00:55 lr 5.694420	time 1.1762 (1.9850)	loss 3.4202 (3.4888)	grad_norm 0.3971 (0.3264)	mem 39782MB
[2023-07-07 09:37:07 RepVGG-A0] (main.py 282): INFO Train: [64/300][60/78]	eta 0:00:34 lr 5.691726	time 1.1736 (1.8921)	loss 3.5596 (3.5147)	grad_norm 0.3464 (0.3421)	mem 39782MB
[2023-07-07 09:37:22 RepVGG-A0] (main.py 282): INFO Train: [64/300][70/78]	eta 0:00:14 lr 5.689029	time 1.2905 (1.8352)	loss 3.4479 (3.5111)	grad_norm 0.3460 (0.3384)	mem 39782MB
[2023-07-07 09:37:34 RepVGG-A0] (main.py 291): INFO EPOCH 64 training takes 0:02:22
[2023-07-07 09:37:55 RepVGG-A0] (main.py 282): INFO Train: [65/300][0/78]	eta 0:27:25 lr 5.686867	time 21.0912 (21.0912)	loss 3.4227 (3.4227)	grad_norm 0.3390 (0.3390)	mem 39782MB
[2023-07-07 09:38:09 RepVGG-A0] (main.py 282): INFO Train: [65/300][10/78]	eta 0:03:38 lr 5.684161	time 1.1737 (3.2184)	loss 3.4328 (3.4542)	grad_norm 0.3396 (0.3593)	mem 39782MB
[2023-07-07 09:38:25 RepVGG-A0] (main.py 282): INFO Train: [65/300][20/78]	eta 0:02:21 lr 5.681451	time 1.1858 (2.4465)	loss 3.5148 (3.4289)	grad_norm 0.3700 (0.3420)	mem 39782MB
[2023-07-07 09:38:41 RepVGG-A0] (main.py 282): INFO Train: [65/300][30/78]	eta 0:01:43 lr 5.678736	time 1.6749 (2.1563)	loss 3.5329 (3.4509)	grad_norm 0.3616 (0.3542)	mem 39782MB
[2023-07-07 09:38:58 RepVGG-A0] (main.py 282): INFO Train: [65/300][40/78]	eta 0:01:17 lr 5.676017	time 3.4901 (2.0502)	loss 3.5469 (3.4501)	grad_norm 0.4233 (0.3501)	mem 39782MB
[2023-07-07 09:39:13 RepVGG-A0] (main.py 282): INFO Train: [65/300][50/78]	eta 0:00:54 lr 5.673293	time 1.1742 (1.9455)	loss 4.7437 (3.6213)	grad_norm 0.6230 (0.4151)	mem 39782MB
[2023-07-07 09:39:28 RepVGG-A0] (main.py 282): INFO Train: [65/300][60/78]	eta 0:00:33 lr 5.670564	time 1.2102 (1.8705)	loss 4.1593 (3.7918)	grad_norm 0.3560 (0.4301)	mem 39782MB
[2023-07-07 09:39:43 RepVGG-A0] (main.py 282): INFO Train: [65/300][70/78]	eta 0:00:14 lr 5.667832	time 1.2435 (1.8158)	loss 3.8463 (3.8123)	grad_norm 0.3073 (0.4077)	mem 39782MB
[2023-07-07 09:39:55 RepVGG-A0] (main.py 291): INFO EPOCH 65 training takes 0:02:21
[2023-07-07 09:40:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][0/78]	eta 0:26:59 lr 5.665642	time 20.7621 (20.7621)	loss 3.6337 (3.6337)	grad_norm 0.2577 (0.2577)	mem 39782MB
[2023-07-07 09:40:30 RepVGG-A0] (main.py 282): INFO Train: [66/300][10/78]	eta 0:03:33 lr 5.662902	time 1.1930 (3.1387)	loss 3.4923 (3.5631)	grad_norm 0.2528 (0.2668)	mem 39782MB
[2023-07-07 09:40:44 RepVGG-A0] (main.py 282): INFO Train: [66/300][20/78]	eta 0:02:14 lr 5.660156	time 1.1918 (2.3204)	loss 3.4588 (3.5261)	grad_norm 0.2966 (0.2720)	mem 39782MB
[2023-07-07 09:40:59 RepVGG-A0] (main.py 282): INFO Train: [66/300][30/78]	eta 0:01:38 lr 5.657407	time 1.3111 (2.0477)	loss 3.5297 (3.5175)	grad_norm 0.3068 (0.2793)	mem 39782MB
[2023-07-07 09:41:16 RepVGG-A0] (main.py 282): INFO Train: [66/300][40/78]	eta 0:01:14 lr 5.654653	time 3.5825 (1.9704)	loss 3.4545 (3.5090)	grad_norm 0.2734 (0.2895)	mem 39782MB
[2023-07-07 09:41:32 RepVGG-A0] (main.py 282): INFO Train: [66/300][50/78]	eta 0:00:52 lr 5.651894	time 2.1485 (1.8918)	loss 3.5002 (3.4989)	grad_norm 0.3489 (0.2950)	mem 39782MB
[2023-07-07 09:41:47 RepVGG-A0] (main.py 282): INFO Train: [66/300][60/78]	eta 0:00:32 lr 5.649132	time 1.3057 (1.8290)	loss 5.2156 (3.6620)	grad_norm 0.5786 (0.3609)	mem 39782MB
[2023-07-07 09:42:02 RepVGG-A0] (main.py 282): INFO Train: [66/300][70/78]	eta 0:00:14 lr 5.646364	time 1.2623 (1.7903)	loss 4.3412 (3.8182)	grad_norm 0.3216 (0.3730)	mem 39782MB
[2023-07-07 09:42:15 RepVGG-A0] (main.py 291): INFO EPOCH 66 training takes 0:02:19
[2023-07-07 09:42:36 RepVGG-A0] (main.py 282): INFO Train: [67/300][0/78]	eta 0:27:46 lr 5.644147	time 21.3673 (21.3673)	loss 3.9564 (3.9564)	grad_norm 0.2578 (0.2578)	mem 39782MB
[2023-07-07 09:42:50 RepVGG-A0] (main.py 282): INFO Train: [67/300][10/78]	eta 0:03:40 lr 5.641372	time 1.1929 (3.2478)	loss 3.7591 (3.8534)	grad_norm 0.2625 (0.2836)	mem 39782MB
[2023-07-07 09:43:04 RepVGG-A0] (main.py 282): INFO Train: [67/300][20/78]	eta 0:02:16 lr 5.638592	time 1.1720 (2.3578)	loss 3.6575 (3.7751)	grad_norm 0.2765 (0.2761)	mem 39782MB
[2023-07-07 09:43:19 RepVGG-A0] (main.py 282): INFO Train: [67/300][30/78]	eta 0:01:40 lr 5.635808	time 1.4440 (2.0834)	loss 3.5705 (3.7173)	grad_norm 0.2977 (0.2811)	mem 39782MB
[2023-07-07 09:43:37 RepVGG-A0] (main.py 282): INFO Train: [67/300][40/78]	eta 0:01:16 lr 5.633020	time 3.3309 (2.0138)	loss 3.5164 (3.7044)	grad_norm 0.2655 (0.2931)	mem 39782MB
[2023-07-07 09:43:53 RepVGG-A0] (main.py 282): INFO Train: [67/300][50/78]	eta 0:00:53 lr 5.630227	time 1.1725 (1.9277)	loss 3.6202 (3.6749)	grad_norm 0.3324 (0.2952)	mem 39782MB
[2023-07-07 09:44:07 RepVGG-A0] (main.py 282): INFO Train: [67/300][60/78]	eta 0:00:33 lr 5.627430	time 1.3099 (1.8502)	loss 3.6669 (3.6547)	grad_norm 0.3992 (0.3004)	mem 39782MB
[2023-07-07 09:44:23 RepVGG-A0] (main.py 282): INFO Train: [67/300][70/78]	eta 0:00:14 lr 5.624629	time 1.6433 (1.8110)	loss 3.6583 (3.6502)	grad_norm 0.3790 (0.3068)	mem 39782MB
[2023-07-07 09:44:35 RepVGG-A0] (main.py 291): INFO EPOCH 67 training takes 0:02:20
[2023-07-07 09:44:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][0/78]	eta 0:27:49 lr 5.622384	time 21.4047 (21.4047)	loss 3.4626 (3.4626)	grad_norm 0.2924 (0.2924)	mem 39782MB
[2023-07-07 09:45:10 RepVGG-A0] (main.py 282): INFO Train: [68/300][10/78]	eta 0:03:36 lr 5.619575	time 1.1708 (3.1829)	loss 3.5322 (3.5251)	grad_norm 0.3247 (0.3421)	mem 39782MB
[2023-07-07 09:45:25 RepVGG-A0] (main.py 282): INFO Train: [68/300][20/78]	eta 0:02:18 lr 5.616761	time 1.1739 (2.3907)	loss 3.4931 (3.5095)	grad_norm 0.3365 (0.3351)	mem 39782MB
[2023-07-07 09:45:40 RepVGG-A0] (main.py 282): INFO Train: [68/300][30/78]	eta 0:01:41 lr 5.613943	time 1.4619 (2.1129)	loss 3.5766 (3.5158)	grad_norm 0.3669 (0.3429)	mem 39782MB
[2023-07-07 09:45:56 RepVGG-A0] (main.py 282): INFO Train: [68/300][40/78]	eta 0:01:15 lr 5.611120	time 2.0916 (1.9896)	loss 3.5308 (3.5184)	grad_norm 0.3171 (0.3462)	mem 39782MB
[2023-07-07 09:46:13 RepVGG-A0] (main.py 282): INFO Train: [68/300][50/78]	eta 0:00:54 lr 5.608294	time 1.1733 (1.9332)	loss 3.5248 (3.5172)	grad_norm 0.3760 (0.3501)	mem 39782MB
[2023-07-07 09:46:29 RepVGG-A0] (main.py 282): INFO Train: [68/300][60/78]	eta 0:00:33 lr 5.605462	time 1.5112 (1.8673)	loss 3.5357 (3.5241)	grad_norm 0.3654 (0.3540)	mem 39782MB
[2023-07-07 09:46:44 RepVGG-A0] (main.py 282): INFO Train: [68/300][70/78]	eta 0:00:14 lr 5.602627	time 1.1782 (1.8182)	loss 3.5355 (3.5184)	grad_norm 0.3921 (0.3495)	mem 39782MB
[2023-07-07 09:46:56 RepVGG-A0] (main.py 291): INFO EPOCH 68 training takes 0:02:20
[2023-07-07 09:47:17 RepVGG-A0] (main.py 282): INFO Train: [69/300][0/78]	eta 0:28:13 lr 5.600355	time 21.7140 (21.7140)	loss 3.5421 (3.5421)	grad_norm 0.4097 (0.4097)	mem 39782MB
[2023-07-07 09:47:32 RepVGG-A0] (main.py 282): INFO Train: [69/300][10/78]	eta 0:03:45 lr 5.597512	time 1.1706 (3.3094)	loss 3.4392 (3.5386)	grad_norm 0.3140 (0.3957)	mem 39782MB
[2023-07-07 09:47:46 RepVGG-A0] (main.py 282): INFO Train: [69/300][20/78]	eta 0:02:19 lr 5.594665	time 1.2091 (2.4117)	loss 3.4100 (3.4998)	grad_norm 0.3201 (0.3725)	mem 39782MB
[2023-07-07 09:48:02 RepVGG-A0] (main.py 282): INFO Train: [69/300][30/78]	eta 0:01:42 lr 5.591813	time 1.3217 (2.1321)	loss 3.4211 (3.4719)	grad_norm 0.3596 (0.3596)	mem 39782MB
[2023-07-07 09:48:20 RepVGG-A0] (main.py 282): INFO Train: [69/300][40/78]	eta 0:01:17 lr 5.588956	time 3.8669 (2.0503)	loss 3.6880 (3.4743)	grad_norm 0.4635 (0.3623)	mem 39782MB
[2023-07-07 09:48:35 RepVGG-A0] (main.py 282): INFO Train: [69/300][50/78]	eta 0:00:54 lr 5.586096	time 1.1727 (1.9505)	loss 6.1683 (3.7841)	grad_norm 0.6966 (0.4551)	mem 39782MB
[2023-07-07 09:48:50 RepVGG-A0] (main.py 282): INFO Train: [69/300][60/78]	eta 0:00:33 lr 5.583231	time 1.2097 (1.8722)	loss 4.9864 (4.0751)	grad_norm 0.3042 (0.4439)	mem 39782MB
[2023-07-07 09:49:05 RepVGG-A0] (main.py 282): INFO Train: [69/300][70/78]	eta 0:00:14 lr 5.580362	time 1.1930 (1.8220)	loss 4.4739 (4.1613)	grad_norm 0.3020 (0.4236)	mem 39782MB
[2023-07-07 09:49:17 RepVGG-A0] (main.py 291): INFO EPOCH 69 training takes 0:02:21
[2023-07-07 09:49:39 RepVGG-A0] (main.py 282): INFO Train: [70/300][0/78]	eta 0:28:36 lr 5.578063	time 22.0039 (22.0039)	loss 4.0726 (4.0726)	grad_norm 0.2419 (0.2419)	mem 39782MB
[2023-07-07 09:49:53 RepVGG-A0] (main.py 282): INFO Train: [70/300][10/78]	eta 0:03:41 lr 5.575187	time 1.1708 (3.2612)	loss 4.0047 (4.0703)	grad_norm 0.3224 (0.2928)	mem 39782MB
[2023-07-07 09:50:09 RepVGG-A0] (main.py 282): INFO Train: [70/300][20/78]	eta 0:02:22 lr 5.572305	time 1.3418 (2.4604)	loss 3.7103 (3.9986)	grad_norm 0.2858 (0.2949)	mem 39782MB
[2023-07-07 09:50:24 RepVGG-A0] (main.py 282): INFO Train: [70/300][30/78]	eta 0:01:44 lr 5.569420	time 1.3269 (2.1742)	loss 3.7131 (3.9259)	grad_norm 0.2641 (0.2913)	mem 39782MB
[2023-07-07 09:50:41 RepVGG-A0] (main.py 282): INFO Train: [70/300][40/78]	eta 0:01:18 lr 5.566530	time 3.0248 (2.0600)	loss 3.7473 (3.8897)	grad_norm 0.3403 (0.3055)	mem 39782MB
[2023-07-07 09:50:56 RepVGG-A0] (main.py 282): INFO Train: [70/300][50/78]	eta 0:00:54 lr 5.563636	time 1.1753 (1.9406)	loss 3.6192 (3.8520)	grad_norm 0.2810 (0.3034)	mem 39782MB
[2023-07-07 09:51:11 RepVGG-A0] (main.py 282): INFO Train: [70/300][60/78]	eta 0:00:33 lr 5.560738	time 1.3068 (1.8711)	loss 3.9393 (3.8329)	grad_norm 0.4148 (0.3113)	mem 39782MB
[2023-07-07 09:51:25 RepVGG-A0] (main.py 282): INFO Train: [70/300][70/78]	eta 0:00:14 lr 5.557836	time 1.5708 (1.8046)	loss 3.6074 (3.8166)	grad_norm 0.2909 (0.3134)	mem 39782MB
[2023-07-07 09:51:36 RepVGG-A0] (main.py 291): INFO EPOCH 70 training takes 0:02:19
[2023-07-07 09:51:58 RepVGG-A0] (main.py 282): INFO Train: [71/300][0/78]	eta 0:28:21 lr 5.555511	time 21.8199 (21.8199)	loss 3.5391 (3.5391)	grad_norm 0.2949 (0.2949)	mem 39782MB
[2023-07-07 09:52:12 RepVGG-A0] (main.py 282): INFO Train: [71/300][10/78]	eta 0:03:42 lr 5.552601	time 1.1735 (3.2670)	loss 3.5823 (3.6568)	grad_norm 0.2917 (0.3733)	mem 39782MB
[2023-07-07 09:52:26 RepVGG-A0] (main.py 282): INFO Train: [71/300][20/78]	eta 0:02:17 lr 5.549686	time 1.1732 (2.3634)	loss 3.4849 (3.6014)	grad_norm 0.2888 (0.3414)	mem 39782MB
[2023-07-07 09:52:42 RepVGG-A0] (main.py 282): INFO Train: [71/300][30/78]	eta 0:01:41 lr 5.546768	time 1.1288 (2.1080)	loss 3.6145 (3.6009)	grad_norm 0.3619 (0.3468)	mem 39782MB
[2023-07-07 09:53:00 RepVGG-A0] (main.py 282): INFO Train: [71/300][40/78]	eta 0:01:17 lr 5.543845	time 4.2994 (2.0361)	loss 3.6001 (3.5876)	grad_norm 0.3471 (0.3410)	mem 39782MB
[2023-07-07 09:53:15 RepVGG-A0] (main.py 282): INFO Train: [71/300][50/78]	eta 0:00:53 lr 5.540918	time 1.1705 (1.9244)	loss 3.7173 (3.6505)	grad_norm 0.3041 (0.3686)	mem 39782MB
[2023-07-07 09:53:29 RepVGG-A0] (main.py 282): INFO Train: [71/300][60/78]	eta 0:00:33 lr 5.537986	time 1.2291 (1.8530)	loss 3.7017 (3.6459)	grad_norm 0.3630 (0.3598)	mem 39782MB
[2023-07-07 09:53:45 RepVGG-A0] (main.py 282): INFO Train: [71/300][70/78]	eta 0:00:14 lr 5.535051	time 1.2867 (1.8041)	loss 3.5679 (3.6280)	grad_norm 0.3185 (0.3501)	mem 39782MB
[2023-07-07 09:53:56 RepVGG-A0] (main.py 291): INFO EPOCH 71 training takes 0:02:20
[2023-07-07 09:54:18 RepVGG-A0] (main.py 282): INFO Train: [72/300][0/78]	eta 0:28:04 lr 5.532700	time 21.6024 (21.6024)	loss 3.4326 (3.4326)	grad_norm 0.2911 (0.2911)	mem 39782MB
[2023-07-07 09:54:32 RepVGG-A0] (main.py 282): INFO Train: [72/300][10/78]	eta 0:03:42 lr 5.529757	time 1.1727 (3.2678)	loss 3.4038 (3.4629)	grad_norm 0.3112 (0.3135)	mem 39782MB
[2023-07-07 09:54:48 RepVGG-A0] (main.py 282): INFO Train: [72/300][20/78]	eta 0:02:22 lr 5.526809	time 1.2340 (2.4512)	loss 3.4863 (3.5235)	grad_norm 0.3500 (0.3556)	mem 39782MB
[2023-07-07 09:55:04 RepVGG-A0] (main.py 282): INFO Train: [72/300][30/78]	eta 0:01:44 lr 5.523858	time 1.7230 (2.1723)	loss 3.4091 (3.5142)	grad_norm 0.3324 (0.3452)	mem 39782MB
[2023-07-07 09:55:21 RepVGG-A0] (main.py 282): INFO Train: [72/300][40/78]	eta 0:01:18 lr 5.520902	time 4.1351 (2.0559)	loss 3.4763 (3.5138)	grad_norm 0.3531 (0.3500)	mem 39782MB
[2023-07-07 09:55:36 RepVGG-A0] (main.py 282): INFO Train: [72/300][50/78]	eta 0:00:54 lr 5.517942	time 1.1718 (1.9455)	loss 3.4621 (3.5006)	grad_norm 0.3320 (0.3453)	mem 39782MB
[2023-07-07 09:55:50 RepVGG-A0] (main.py 282): INFO Train: [72/300][60/78]	eta 0:00:33 lr 5.514978	time 1.3340 (1.8670)	loss 3.5410 (3.4995)	grad_norm 0.4239 (0.3478)	mem 39782MB
[2023-07-07 09:56:06 RepVGG-A0] (main.py 282): INFO Train: [72/300][70/78]	eta 0:00:14 lr 5.512010	time 1.2445 (1.8215)	loss 5.5307 (3.6431)	grad_norm 0.8740 (0.4036)	mem 39782MB
[2023-07-07 09:56:18 RepVGG-A0] (main.py 291): INFO EPOCH 72 training takes 0:02:21
[2023-07-07 09:56:39 RepVGG-A0] (main.py 282): INFO Train: [73/300][0/78]	eta 0:28:13 lr 5.509633	time 21.7102 (21.7102)	loss 4.6905 (4.6905)	grad_norm 0.3197 (0.3197)	mem 39782MB
[2023-07-07 09:56:54 RepVGG-A0] (main.py 282): INFO Train: [73/300][10/78]	eta 0:03:44 lr 5.506657	time 1.1888 (3.3082)	loss 4.0563 (4.3773)	grad_norm 0.2373 (0.2861)	mem 39782MB
[2023-07-07 09:57:09 RepVGG-A0] (main.py 282): INFO Train: [73/300][20/78]	eta 0:02:20 lr 5.503677	time 1.1728 (2.4297)	loss 3.8464 (4.2289)	grad_norm 0.2448 (0.3022)	mem 39782MB
[2023-07-07 09:57:24 RepVGG-A0] (main.py 282): INFO Train: [73/300][30/78]	eta 0:01:42 lr 5.500693	time 1.2438 (2.1311)	loss 3.7619 (4.0935)	grad_norm 0.2543 (0.2828)	mem 39782MB
[2023-07-07 09:57:42 RepVGG-A0] (main.py 282): INFO Train: [73/300][40/78]	eta 0:01:18 lr 5.497705	time 3.8227 (2.0551)	loss 3.6254 (3.9986)	grad_norm 0.2672 (0.2799)	mem 39782MB
[2023-07-07 09:57:57 RepVGG-A0] (main.py 282): INFO Train: [73/300][50/78]	eta 0:00:54 lr 5.494713	time 1.1708 (1.9432)	loss 3.6277 (3.9215)	grad_norm 0.3221 (0.2826)	mem 39782MB
[2023-07-07 09:58:11 RepVGG-A0] (main.py 282): INFO Train: [73/300][60/78]	eta 0:00:33 lr 5.491716	time 1.1799 (1.8645)	loss 3.5610 (3.8725)	grad_norm 0.2941 (0.2880)	mem 39782MB
[2023-07-07 09:58:26 RepVGG-A0] (main.py 282): INFO Train: [73/300][70/78]	eta 0:00:14 lr 5.488716	time 1.1703 (1.8096)	loss 3.6163 (3.8304)	grad_norm 0.3572 (0.2900)	mem 39782MB
[2023-07-07 09:58:38 RepVGG-A0] (main.py 291): INFO EPOCH 73 training takes 0:02:20
[2023-07-07 09:59:00 RepVGG-A0] (main.py 282): INFO Train: [74/300][0/78]	eta 0:27:50 lr 5.486313	time 21.4142 (21.4142)	loss 3.5565 (3.5565)	grad_norm 0.3862 (0.3862)	mem 39782MB
[2023-07-07 09:59:15 RepVGG-A0] (main.py 282): INFO Train: [74/300][10/78]	eta 0:03:47 lr 5.483305	time 1.1712 (3.3522)	loss 3.4499 (3.5583)	grad_norm 0.2935 (0.3335)	mem 39782MB
[2023-07-07 09:59:30 RepVGG-A0] (main.py 282): INFO Train: [74/300][20/78]	eta 0:02:22 lr 5.480293	time 1.1755 (2.4563)	loss 3.6079 (3.5334)	grad_norm 0.3946 (0.3368)	mem 39782MB
[2023-07-07 09:59:46 RepVGG-A0] (main.py 282): INFO Train: [74/300][30/78]	eta 0:01:44 lr 5.477276	time 1.2342 (2.1722)	loss 3.4448 (3.5366)	grad_norm 0.2881 (0.3353)	mem 39782MB
[2023-07-07 10:00:04 RepVGG-A0] (main.py 282): INFO Train: [74/300][40/78]	eta 0:01:19 lr 5.474256	time 4.0086 (2.0867)	loss 3.4804 (3.5279)	grad_norm 0.3264 (0.3352)	mem 39782MB
[2023-07-07 10:00:18 RepVGG-A0] (main.py 282): INFO Train: [74/300][50/78]	eta 0:00:54 lr 5.471232	time 1.1740 (1.9588)	loss 3.5421 (3.5231)	grad_norm 0.3907 (0.3412)	mem 39782MB
[2023-07-07 10:00:34 RepVGG-A0] (main.py 282): INFO Train: [74/300][60/78]	eta 0:00:33 lr 5.468203	time 1.2793 (1.8865)	loss 3.5536 (3.5261)	grad_norm 0.3227 (0.3421)	mem 39782MB
[2023-07-07 10:00:50 RepVGG-A0] (main.py 282): INFO Train: [74/300][70/78]	eta 0:00:14 lr 5.465171	time 1.3094 (1.8505)	loss 3.6673 (3.5298)	grad_norm 0.4644 (0.3466)	mem 39782MB
[2023-07-07 10:01:01 RepVGG-A0] (main.py 291): INFO EPOCH 74 training takes 0:02:22
[2023-07-07 10:01:22 RepVGG-A0] (main.py 282): INFO Train: [75/300][0/78]	eta 0:26:53 lr 5.462742	time 20.6804 (20.6804)	loss 3.4238 (3.4238)	grad_norm 0.3282 (0.3282)	mem 39782MB
[2023-07-07 10:01:36 RepVGG-A0] (main.py 282): INFO Train: [75/300][10/78]	eta 0:03:38 lr 5.459702	time 1.1697 (3.2132)	loss 3.5363 (3.4885)	grad_norm 0.3977 (0.3616)	mem 39782MB
[2023-07-07 10:01:51 RepVGG-A0] (main.py 282): INFO Train: [75/300][20/78]	eta 0:02:17 lr 5.456658	time 1.1707 (2.3764)	loss 3.4678 (3.4607)	grad_norm 0.3402 (0.3409)	mem 39782MB
[2023-07-07 10:02:07 RepVGG-A0] (main.py 282): INFO Train: [75/300][30/78]	eta 0:01:41 lr 5.453610	time 1.2860 (2.1102)	loss 3.5991 (3.4970)	grad_norm 0.4109 (0.3673)	mem 39782MB
[2023-07-07 10:02:24 RepVGG-A0] (main.py 282): INFO Train: [75/300][40/78]	eta 0:01:16 lr 5.450558	time 2.4664 (2.0177)	loss 3.4083 (3.4935)	grad_norm 0.2769 (0.3562)	mem 39782MB
[2023-07-07 10:02:41 RepVGG-A0] (main.py 282): INFO Train: [75/300][50/78]	eta 0:00:55 lr 5.447501	time 1.2967 (1.9658)	loss 3.4099 (3.4854)	grad_norm 0.3503 (0.3551)	mem 39782MB
[2023-07-07 10:02:57 RepVGG-A0] (main.py 282): INFO Train: [75/300][60/78]	eta 0:00:34 lr 5.444441	time 1.1432 (1.8948)	loss 3.4086 (3.4710)	grad_norm 0.3656 (0.3504)	mem 39782MB
[2023-07-07 10:03:12 RepVGG-A0] (main.py 282): INFO Train: [75/300][70/78]	eta 0:00:14 lr 5.441377	time 1.1718 (1.8437)	loss 3.5768 (3.5037)	grad_norm 0.3341 (0.3662)	mem 39782MB
[2023-07-07 10:03:23 RepVGG-A0] (main.py 291): INFO EPOCH 75 training takes 0:02:21
[2023-07-07 10:03:44 RepVGG-A0] (main.py 282): INFO Train: [76/300][0/78]	eta 0:27:41 lr 5.438923	time 21.2956 (21.2956)	loss 3.3751 (3.3751)	grad_norm 0.2974 (0.2974)	mem 39782MB
[2023-07-07 10:04:01 RepVGG-A0] (main.py 282): INFO Train: [76/300][10/78]	eta 0:03:52 lr 5.435851	time 1.1970 (3.4182)	loss 3.4477 (3.4093)	grad_norm 0.3213 (0.3309)	mem 39782MB
[2023-07-07 10:04:15 RepVGG-A0] (main.py 282): INFO Train: [76/300][20/78]	eta 0:02:22 lr 5.432776	time 1.3123 (2.4539)	loss 3.3998 (3.4006)	grad_norm 0.3448 (0.3281)	mem 39782MB
[2023-07-07 10:04:30 RepVGG-A0] (main.py 282): INFO Train: [76/300][30/78]	eta 0:01:43 lr 5.429696	time 1.2644 (2.1544)	loss 3.5500 (3.4407)	grad_norm 0.4127 (0.3527)	mem 39782MB
[2023-07-07 10:04:47 RepVGG-A0] (main.py 282): INFO Train: [76/300][40/78]	eta 0:01:18 lr 5.426612	time 3.6097 (2.0587)	loss 3.2908 (3.4334)	grad_norm 0.3175 (0.3496)	mem 39782MB
[2023-07-07 10:05:02 RepVGG-A0] (main.py 282): INFO Train: [76/300][50/78]	eta 0:00:54 lr 5.423525	time 1.1731 (1.9433)	loss 3.4733 (3.4347)	grad_norm 0.3627 (0.3508)	mem 39782MB
[2023-07-07 10:05:18 RepVGG-A0] (main.py 282): INFO Train: [76/300][60/78]	eta 0:00:33 lr 5.420433	time 1.1851 (1.8797)	loss 3.4105 (3.4324)	grad_norm 0.3779 (0.3503)	mem 39782MB
[2023-07-07 10:05:32 RepVGG-A0] (main.py 282): INFO Train: [76/300][70/78]	eta 0:00:14 lr 5.417338	time 1.1812 (1.8173)	loss 5.4137 (3.5133)	grad_norm 1.0900 (0.3931)	mem 39782MB
[2023-07-07 10:05:44 RepVGG-A0] (main.py 291): INFO EPOCH 76 training takes 0:02:20
[2023-07-07 10:06:06 RepVGG-A0] (main.py 282): INFO Train: [77/300][0/78]	eta 0:28:56 lr 5.414858	time 22.2584 (22.2584)	loss 5.2042 (5.2042)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 10:06:20 RepVGG-A0] (main.py 282): INFO Train: [77/300][10/78]	eta 0:03:41 lr 5.411755	time 1.1718 (3.2566)	loss 4.5173 (4.8160)	grad_norm 0.3152 (0.3642)	mem 39782MB
[2023-07-07 10:06:34 RepVGG-A0] (main.py 282): INFO Train: [77/300][20/78]	eta 0:02:18 lr 5.408649	time 1.1914 (2.3806)	loss 4.1032 (4.5021)	grad_norm 0.2650 (0.3186)	mem 39782MB
[2023-07-07 10:06:50 RepVGG-A0] (main.py 282): INFO Train: [77/300][30/78]	eta 0:01:41 lr 5.405538	time 1.2477 (2.1249)	loss 3.9798 (4.3239)	grad_norm 0.3430 (0.3121)	mem 39782MB
[2023-07-07 10:07:08 RepVGG-A0] (main.py 282): INFO Train: [77/300][40/78]	eta 0:01:18 lr 5.402423	time 4.3098 (2.0599)	loss 3.7810 (4.1934)	grad_norm 0.3259 (0.3036)	mem 39782MB
[2023-07-07 10:07:23 RepVGG-A0] (main.py 282): INFO Train: [77/300][50/78]	eta 0:00:54 lr 5.399304	time 1.1732 (1.9344)	loss 3.6530 (4.1039)	grad_norm 0.3076 (0.3064)	mem 39782MB
[2023-07-07 10:07:39 RepVGG-A0] (main.py 282): INFO Train: [77/300][60/78]	eta 0:00:33 lr 5.396182	time 1.1959 (1.8795)	loss 3.6731 (4.0283)	grad_norm 0.3446 (0.3027)	mem 39782MB
[2023-07-07 10:07:54 RepVGG-A0] (main.py 282): INFO Train: [77/300][70/78]	eta 0:00:14 lr 5.393055	time 1.3757 (1.8306)	loss 3.5631 (3.9762)	grad_norm 0.2742 (0.3071)	mem 39782MB
[2023-07-07 10:08:06 RepVGG-A0] (main.py 291): INFO EPOCH 77 training takes 0:02:21
[2023-07-07 10:08:27 RepVGG-A0] (main.py 282): INFO Train: [78/300][0/78]	eta 0:28:15 lr 5.390551	time 21.7339 (21.7339)	loss 3.4931 (3.4931)	grad_norm 0.3382 (0.3382)	mem 39782MB
[2023-07-07 10:08:42 RepVGG-A0] (main.py 282): INFO Train: [78/300][10/78]	eta 0:03:43 lr 5.387417	time 1.1714 (3.2851)	loss 3.4694 (3.5501)	grad_norm 0.2988 (0.3343)	mem 39782MB
[2023-07-07 10:08:57 RepVGG-A0] (main.py 282): INFO Train: [78/300][20/78]	eta 0:02:21 lr 5.384279	time 1.2000 (2.4396)	loss 3.6486 (3.5641)	grad_norm 0.3817 (0.3522)	mem 39782MB
[2023-07-07 10:09:11 RepVGG-A0] (main.py 282): INFO Train: [78/300][30/78]	eta 0:01:41 lr 5.381138	time 1.3346 (2.1196)	loss 3.5341 (3.5461)	grad_norm 0.3380 (0.3396)	mem 39782MB
[2023-07-07 10:09:30 RepVGG-A0] (main.py 282): INFO Train: [78/300][40/78]	eta 0:01:18 lr 5.377992	time 3.3255 (2.0590)	loss 3.5867 (3.5378)	grad_norm 0.3562 (0.3401)	mem 39782MB
[2023-07-07 10:09:46 RepVGG-A0] (main.py 282): INFO Train: [78/300][50/78]	eta 0:00:54 lr 5.374843	time 1.1742 (1.9602)	loss 3.5661 (3.5395)	grad_norm 0.3894 (0.3455)	mem 39782MB
[2023-07-07 10:10:01 RepVGG-A0] (main.py 282): INFO Train: [78/300][60/78]	eta 0:00:33 lr 5.371689	time 1.3332 (1.8851)	loss 3.4927 (3.5346)	grad_norm 0.3290 (0.3454)	mem 39782MB
[2023-07-07 10:10:15 RepVGG-A0] (main.py 282): INFO Train: [78/300][70/78]	eta 0:00:14 lr 5.368532	time 1.1792 (1.8250)	loss 3.7614 (3.5335)	grad_norm 0.5386 (0.3483)	mem 39782MB
[2023-07-07 10:10:27 RepVGG-A0] (main.py 291): INFO EPOCH 78 training takes 0:02:21
[2023-07-07 10:10:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][0/78]	eta 0:28:32 lr 5.366003	time 21.9597 (21.9597)	loss 3.7192 (3.7192)	grad_norm 0.3883 (0.3883)	mem 39782MB
[2023-07-07 10:11:03 RepVGG-A0] (main.py 282): INFO Train: [79/300][10/78]	eta 0:03:42 lr 5.362839	time 1.1701 (3.2688)	loss 3.4214 (3.5570)	grad_norm 0.2665 (0.3224)	mem 39782MB
[2023-07-07 10:11:17 RepVGG-A0] (main.py 282): INFO Train: [79/300][20/78]	eta 0:02:16 lr 5.359670	time 1.1898 (2.3560)	loss 3.4521 (3.4935)	grad_norm 0.3262 (0.3080)	mem 39782MB
[2023-07-07 10:11:32 RepVGG-A0] (main.py 282): INFO Train: [79/300][30/78]	eta 0:01:40 lr 5.356498	time 1.1808 (2.0901)	loss 3.4157 (3.4904)	grad_norm 0.3432 (0.3223)	mem 39782MB
[2023-07-07 10:11:49 RepVGG-A0] (main.py 282): INFO Train: [79/300][40/78]	eta 0:01:15 lr 5.353322	time 1.9115 (1.9987)	loss 3.2808 (3.4835)	grad_norm 0.3033 (0.3284)	mem 39782MB
[2023-07-07 10:12:05 RepVGG-A0] (main.py 282): INFO Train: [79/300][50/78]	eta 0:00:53 lr 5.350142	time 1.1284 (1.9200)	loss 3.4790 (3.4797)	grad_norm 0.3717 (0.3329)	mem 39782MB
[2023-07-07 10:12:21 RepVGG-A0] (main.py 282): INFO Train: [79/300][60/78]	eta 0:00:33 lr 5.346959	time 1.2224 (1.8643)	loss 3.4685 (3.4694)	grad_norm 0.3667 (0.3314)	mem 39782MB
[2023-07-07 10:12:36 RepVGG-A0] (main.py 282): INFO Train: [79/300][70/78]	eta 0:00:14 lr 5.343771	time 1.3366 (1.8187)	loss 4.0492 (3.5092)	grad_norm 0.7083 (0.3583)	mem 39782MB
[2023-07-07 10:12:47 RepVGG-A0] (main.py 291): INFO EPOCH 79 training takes 0:02:20
[2023-07-07 10:13:08 RepVGG-A0] (main.py 282): INFO Train: [80/300][0/78]	eta 0:26:14 lr 5.341218	time 20.1922 (20.1922)	loss 3.7838 (3.7838)	grad_norm 0.3243 (0.3243)	mem 39782MB
[2023-07-07 10:13:22 RepVGG-A0] (main.py 282): INFO Train: [80/300][10/78]	eta 0:03:36 lr 5.338023	time 1.1896 (3.1846)	loss 3.5252 (3.5844)	grad_norm 0.2977 (0.2853)	mem 39782MB
[2023-07-07 10:13:38 RepVGG-A0] (main.py 282): INFO Train: [80/300][20/78]	eta 0:02:19 lr 5.334825	time 1.1834 (2.4034)	loss 3.4535 (3.5252)	grad_norm 0.3072 (0.2960)	mem 39782MB
[2023-07-07 10:13:54 RepVGG-A0] (main.py 282): INFO Train: [80/300][30/78]	eta 0:01:42 lr 5.331623	time 1.6588 (2.1363)	loss 3.3761 (3.4747)	grad_norm 0.2722 (0.2921)	mem 39782MB
[2023-07-07 10:14:11 RepVGG-A0] (main.py 282): INFO Train: [80/300][40/78]	eta 0:01:17 lr 5.328416	time 4.3343 (2.0506)	loss 3.4416 (3.4469)	grad_norm 0.3658 (0.2937)	mem 39782MB
[2023-07-07 10:14:27 RepVGG-A0] (main.py 282): INFO Train: [80/300][50/78]	eta 0:00:54 lr 5.325206	time 1.1723 (1.9434)	loss 3.4599 (3.4533)	grad_norm 0.3275 (0.3082)	mem 39782MB
[2023-07-07 10:14:41 RepVGG-A0] (main.py 282): INFO Train: [80/300][60/78]	eta 0:00:33 lr 5.321993	time 1.2726 (1.8671)	loss 3.6742 (3.4429)	grad_norm 0.4813 (0.3119)	mem 39782MB
[2023-07-07 10:14:56 RepVGG-A0] (main.py 282): INFO Train: [80/300][70/78]	eta 0:00:14 lr 5.318775	time 1.3817 (1.8159)	loss 4.7123 (3.6002)	grad_norm 0.5154 (0.3707)	mem 39782MB
[2023-07-07 10:15:08 RepVGG-A0] (main.py 291): INFO EPOCH 80 training takes 0:02:20
[2023-07-07 10:15:25 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.043 (17.043)	Loss 5.1657 (5.1657)	Acc@1 11.731 (11.731)	Acc@5 27.191 (27.191)	Mem 39782MB
[2023-07-07 10:15:26 RepVGG-A0] (main.py 342): INFO  * Acc@1 11.640 Acc@5 26.608
[2023-07-07 10:15:26 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 80: 11.640%
[2023-07-07 10:15:26 RepVGG-A0] (main.py 172): INFO Max accuracy: 32.74%
[2023-07-07 10:15:46 RepVGG-A0] (main.py 282): INFO Train: [81/300][0/78]	eta 0:25:28 lr 5.316198	time 19.5911 (19.5911)	loss 3.9074 (3.9074)	grad_norm 0.2790 (0.2790)	mem 39782MB
[2023-07-07 10:16:01 RepVGG-A0] (main.py 282): INFO Train: [81/300][10/78]	eta 0:03:37 lr 5.312973	time 1.1701 (3.1995)	loss 3.6011 (3.7334)	grad_norm 0.2627 (0.2694)	mem 39782MB
[2023-07-07 10:16:16 RepVGG-A0] (main.py 282): INFO Train: [81/300][20/78]	eta 0:02:16 lr 5.309745	time 1.1913 (2.3591)	loss 3.4800 (3.6553)	grad_norm 0.2382 (0.2740)	mem 39782MB
[2023-07-07 10:16:31 RepVGG-A0] (main.py 282): INFO Train: [81/300][30/78]	eta 0:01:40 lr 5.306513	time 1.4751 (2.0957)	loss 3.3844 (3.5898)	grad_norm 0.2845 (0.2751)	mem 39782MB
[2023-07-07 10:16:49 RepVGG-A0] (main.py 282): INFO Train: [81/300][40/78]	eta 0:01:16 lr 5.303277	time 2.5275 (2.0211)	loss 3.3503 (3.5419)	grad_norm 0.2972 (0.2759)	mem 39782MB
[2023-07-07 10:17:06 RepVGG-A0] (main.py 282): INFO Train: [81/300][50/78]	eta 0:00:54 lr 5.300037	time 2.6879 (1.9525)	loss 3.3656 (3.5172)	grad_norm 0.3083 (0.2858)	mem 39782MB
[2023-07-07 10:17:21 RepVGG-A0] (main.py 282): INFO Train: [81/300][60/78]	eta 0:00:33 lr 5.296794	time 1.1972 (1.8747)	loss 3.4123 (3.4955)	grad_norm 0.3078 (0.2882)	mem 39782MB
[2023-07-07 10:17:36 RepVGG-A0] (main.py 282): INFO Train: [81/300][70/78]	eta 0:00:14 lr 5.293546	time 1.1708 (1.8232)	loss 3.3502 (3.4825)	grad_norm 0.3443 (0.2952)	mem 39782MB
[2023-07-07 10:17:48 RepVGG-A0] (main.py 291): INFO EPOCH 81 training takes 0:02:21
[2023-07-07 10:18:08 RepVGG-A0] (main.py 282): INFO Train: [82/300][0/78]	eta 0:26:41 lr 5.290946	time 20.5350 (20.5350)	loss 3.3147 (3.3147)	grad_norm 0.3601 (0.3601)	mem 39782MB
[2023-07-07 10:18:23 RepVGG-A0] (main.py 282): INFO Train: [82/300][10/78]	eta 0:03:37 lr 5.287692	time 1.1724 (3.1974)	loss 3.3028 (3.3615)	grad_norm 0.2981 (0.3495)	mem 39782MB
[2023-07-07 10:18:38 RepVGG-A0] (main.py 282): INFO Train: [82/300][20/78]	eta 0:02:19 lr 5.284434	time 1.1731 (2.4029)	loss 3.4113 (3.3650)	grad_norm 0.3628 (0.3463)	mem 39782MB
[2023-07-07 10:18:52 RepVGG-A0] (main.py 282): INFO Train: [82/300][30/78]	eta 0:01:39 lr 5.281172	time 1.1952 (2.0808)	loss 3.3860 (3.3648)	grad_norm 0.3732 (0.3417)	mem 39782MB
[2023-07-07 10:19:11 RepVGG-A0] (main.py 282): INFO Train: [82/300][40/78]	eta 0:01:17 lr 5.277907	time 4.1132 (2.0291)	loss 4.6170 (3.4784)	grad_norm 0.8830 (0.4006)	mem 39782MB
[2023-07-07 10:19:26 RepVGG-A0] (main.py 282): INFO Train: [82/300][50/78]	eta 0:00:53 lr 5.274638	time 1.1724 (1.9239)	loss 3.8963 (3.6319)	grad_norm 0.3246 (0.4212)	mem 39782MB
[2023-07-07 10:19:42 RepVGG-A0] (main.py 282): INFO Train: [82/300][60/78]	eta 0:00:33 lr 5.271365	time 1.3677 (1.8662)	loss 3.5491 (3.6336)	grad_norm 0.2857 (0.3992)	mem 39782MB
[2023-07-07 10:19:55 RepVGG-A0] (main.py 282): INFO Train: [82/300][70/78]	eta 0:00:14 lr 5.268089	time 1.1734 (1.7968)	loss 3.4455 (3.6155)	grad_norm 0.2560 (0.3825)	mem 39782MB
[2023-07-07 10:20:08 RepVGG-A0] (main.py 291): INFO EPOCH 82 training takes 0:02:20
[2023-07-07 10:20:29 RepVGG-A0] (main.py 282): INFO Train: [83/300][0/78]	eta 0:28:00 lr 5.265465	time 21.5485 (21.5485)	loss 3.4931 (3.4931)	grad_norm 0.3216 (0.3216)	mem 39782MB
[2023-07-07 10:20:44 RepVGG-A0] (main.py 282): INFO Train: [83/300][10/78]	eta 0:03:42 lr 5.262181	time 1.1728 (3.2733)	loss 3.3281 (3.3670)	grad_norm 0.3384 (0.3006)	mem 39782MB
[2023-07-07 10:20:58 RepVGG-A0] (main.py 282): INFO Train: [83/300][20/78]	eta 0:02:18 lr 5.258894	time 1.1736 (2.3935)	loss 3.4453 (3.3710)	grad_norm 0.3841 (0.3199)	mem 39782MB
[2023-07-07 10:21:14 RepVGG-A0] (main.py 282): INFO Train: [83/300][30/78]	eta 0:01:42 lr 5.255604	time 1.1877 (2.1255)	loss 3.3588 (3.3824)	grad_norm 0.3160 (0.3292)	mem 39782MB
[2023-07-07 10:21:32 RepVGG-A0] (main.py 282): INFO Train: [83/300][40/78]	eta 0:01:18 lr 5.252309	time 4.2960 (2.0624)	loss 3.3773 (3.3666)	grad_norm 0.3920 (0.3250)	mem 39782MB
[2023-07-07 10:21:46 RepVGG-A0] (main.py 282): INFO Train: [83/300][50/78]	eta 0:00:54 lr 5.249011	time 1.1909 (1.9286)	loss 3.4724 (3.3717)	grad_norm 0.3291 (0.3297)	mem 39782MB
[2023-07-07 10:22:02 RepVGG-A0] (main.py 282): INFO Train: [83/300][60/78]	eta 0:00:33 lr 5.245709	time 1.3591 (1.8680)	loss 3.3909 (3.3741)	grad_norm 0.3200 (0.3347)	mem 39782MB
[2023-07-07 10:22:16 RepVGG-A0] (main.py 282): INFO Train: [83/300][70/78]	eta 0:00:14 lr 5.242404	time 1.4177 (1.8121)	loss 3.4392 (3.3719)	grad_norm 0.3974 (0.3345)	mem 39782MB
[2023-07-07 10:22:28 RepVGG-A0] (main.py 291): INFO EPOCH 83 training takes 0:02:20
[2023-07-07 10:22:49 RepVGG-A0] (main.py 282): INFO Train: [84/300][0/78]	eta 0:27:31 lr 5.239757	time 21.1756 (21.1756)	loss 3.6490 (3.6490)	grad_norm 0.5047 (0.5047)	mem 39782MB
[2023-07-07 10:23:03 RepVGG-A0] (main.py 282): INFO Train: [84/300][10/78]	eta 0:03:37 lr 5.236445	time 1.1711 (3.2020)	loss 3.3717 (3.4268)	grad_norm 0.2995 (0.3506)	mem 39782MB
[2023-07-07 10:23:18 RepVGG-A0] (main.py 282): INFO Train: [84/300][20/78]	eta 0:02:19 lr 5.233129	time 1.1722 (2.3996)	loss 3.3197 (3.4002)	grad_norm 0.3304 (0.3447)	mem 39782MB
[2023-07-07 10:23:33 RepVGG-A0] (main.py 282): INFO Train: [84/300][30/78]	eta 0:01:41 lr 5.229809	time 1.5010 (2.1160)	loss 3.4780 (3.3982)	grad_norm 0.4088 (0.3489)	mem 39782MB
[2023-07-07 10:23:51 RepVGG-A0] (main.py 282): INFO Train: [84/300][40/78]	eta 0:01:17 lr 5.226486	time 4.7004 (2.0389)	loss 3.2833 (3.3875)	grad_norm 0.3027 (0.3448)	mem 39782MB
[2023-07-07 10:24:06 RepVGG-A0] (main.py 282): INFO Train: [84/300][50/78]	eta 0:00:53 lr 5.223160	time 1.1720 (1.9240)	loss 3.4252 (3.3840)	grad_norm 0.3730 (0.3488)	mem 39782MB
[2023-07-07 10:24:21 RepVGG-A0] (main.py 282): INFO Train: [84/300][60/78]	eta 0:00:33 lr 5.219829	time 1.1854 (1.8563)	loss 3.4247 (3.3792)	grad_norm 0.4371 (0.3504)	mem 39782MB
[2023-07-07 10:24:36 RepVGG-A0] (main.py 282): INFO Train: [84/300][70/78]	eta 0:00:14 lr 5.216495	time 1.3598 (1.8054)	loss 3.2842 (3.3819)	grad_norm 0.2982 (0.3514)	mem 39782MB
[2023-07-07 10:24:47 RepVGG-A0] (main.py 291): INFO EPOCH 84 training takes 0:02:19
[2023-07-07 10:25:09 RepVGG-A0] (main.py 282): INFO Train: [85/300][0/78]	eta 0:28:00 lr 5.213825	time 21.5404 (21.5404)	loss 3.4240 (3.4240)	grad_norm 0.4159 (0.4159)	mem 39782MB
[2023-07-07 10:25:22 RepVGG-A0] (main.py 282): INFO Train: [85/300][10/78]	eta 0:03:37 lr 5.210485	time 1.1886 (3.1913)	loss 3.9177 (3.6336)	grad_norm 0.5796 (0.5154)	mem 39782MB
[2023-07-07 10:25:37 RepVGG-A0] (main.py 282): INFO Train: [85/300][20/78]	eta 0:02:17 lr 5.207140	time 1.1736 (2.3791)	loss 3.3390 (3.5839)	grad_norm 0.2774 (0.4386)	mem 39782MB
[2023-07-07 10:25:52 RepVGG-A0] (main.py 282): INFO Train: [85/300][30/78]	eta 0:01:40 lr 5.203793	time 1.3688 (2.0891)	loss 3.2881 (3.5005)	grad_norm 0.3069 (0.3939)	mem 39782MB
[2023-07-07 10:26:10 RepVGG-A0] (main.py 282): INFO Train: [85/300][40/78]	eta 0:01:16 lr 5.200441	time 3.6023 (2.0259)	loss 3.3799 (3.4504)	grad_norm 0.3181 (0.3711)	mem 39782MB
[2023-07-07 10:26:25 RepVGG-A0] (main.py 282): INFO Train: [85/300][50/78]	eta 0:00:53 lr 5.197086	time 1.1718 (1.9273)	loss 3.3547 (3.4241)	grad_norm 0.3898 (0.3666)	mem 39782MB
[2023-07-07 10:26:41 RepVGG-A0] (main.py 282): INFO Train: [85/300][60/78]	eta 0:00:33 lr 5.193728	time 1.1812 (1.8621)	loss 3.2813 (3.4122)	grad_norm 0.3192 (0.3636)	mem 39782MB
[2023-07-07 10:26:56 RepVGG-A0] (main.py 282): INFO Train: [85/300][70/78]	eta 0:00:14 lr 5.190365	time 1.1727 (1.8168)	loss 3.3495 (3.3989)	grad_norm 0.3511 (0.3602)	mem 39782MB
[2023-07-07 10:27:07 RepVGG-A0] (main.py 291): INFO EPOCH 85 training takes 0:02:20
[2023-07-07 10:27:28 RepVGG-A0] (main.py 282): INFO Train: [86/300][0/78]	eta 0:27:13 lr 5.187673	time 20.9371 (20.9371)	loss 3.6778 (3.6778)	grad_norm 0.5963 (0.5963)	mem 39782MB
[2023-07-07 10:27:44 RepVGG-A0] (main.py 282): INFO Train: [86/300][10/78]	eta 0:03:45 lr 5.184304	time 1.1697 (3.3213)	loss 5.3110 (4.4977)	grad_norm 0.7889 (0.7841)	mem 39782MB
[2023-07-07 10:27:59 RepVGG-A0] (main.py 282): INFO Train: [86/300][20/78]	eta 0:02:21 lr 5.180932	time 1.3189 (2.4446)	loss 4.0974 (4.5591)	grad_norm 0.2884 (0.6187)	mem 39782MB
[2023-07-07 10:28:14 RepVGG-A0] (main.py 282): INFO Train: [86/300][30/78]	eta 0:01:42 lr 5.177556	time 1.4453 (2.1363)	loss 3.8321 (4.3484)	grad_norm 0.3546 (0.5155)	mem 39782MB
[2023-07-07 10:28:33 RepVGG-A0] (main.py 282): INFO Train: [86/300][40/78]	eta 0:01:18 lr 5.174177	time 4.3427 (2.0788)	loss 3.5053 (4.1714)	grad_norm 0.2587 (0.4501)	mem 39782MB
[2023-07-07 10:28:48 RepVGG-A0] (main.py 282): INFO Train: [86/300][50/78]	eta 0:00:54 lr 5.170794	time 1.3006 (1.9638)	loss 3.4582 (4.0417)	grad_norm 0.2524 (0.4154)	mem 39782MB
[2023-07-07 10:29:03 RepVGG-A0] (main.py 282): INFO Train: [86/300][60/78]	eta 0:00:34 lr 5.167407	time 1.3244 (1.8913)	loss 3.3747 (3.9408)	grad_norm 0.2897 (0.3935)	mem 39782MB
[2023-07-07 10:29:17 RepVGG-A0] (main.py 282): INFO Train: [86/300][70/78]	eta 0:00:14 lr 5.164017	time 1.1860 (1.8210)	loss 3.3832 (3.8704)	grad_norm 0.3005 (0.3827)	mem 39782MB
[2023-07-07 10:29:29 RepVGG-A0] (main.py 291): INFO EPOCH 86 training takes 0:02:21
[2023-07-07 10:29:50 RepVGG-A0] (main.py 282): INFO Train: [87/300][0/78]	eta 0:28:00 lr 5.161303	time 21.5392 (21.5392)	loss 3.3695 (3.3695)	grad_norm 0.3264 (0.3264)	mem 39782MB
[2023-07-07 10:30:06 RepVGG-A0] (main.py 282): INFO Train: [87/300][10/78]	eta 0:03:48 lr 5.157906	time 1.1893 (3.3668)	loss 3.3291 (3.3597)	grad_norm 0.3041 (0.3253)	mem 39782MB
[2023-07-07 10:30:21 RepVGG-A0] (main.py 282): INFO Train: [87/300][20/78]	eta 0:02:23 lr 5.154506	time 1.2142 (2.4710)	loss 3.6214 (3.3693)	grad_norm 0.4556 (0.3385)	mem 39782MB
[2023-07-07 10:30:36 RepVGG-A0] (main.py 282): INFO Train: [87/300][30/78]	eta 0:01:43 lr 5.151103	time 1.1290 (2.1575)	loss 3.3823 (3.3701)	grad_norm 0.3088 (0.3321)	mem 39782MB
[2023-07-07 10:30:54 RepVGG-A0] (main.py 282): INFO Train: [87/300][40/78]	eta 0:01:18 lr 5.147696	time 4.2145 (2.0738)	loss 3.4071 (3.3658)	grad_norm 0.3761 (0.3334)	mem 39782MB
[2023-07-07 10:31:08 RepVGG-A0] (main.py 282): INFO Train: [87/300][50/78]	eta 0:00:54 lr 5.144285	time 1.1898 (1.9569)	loss 3.2760 (3.3635)	grad_norm 0.2973 (0.3326)	mem 39782MB
[2023-07-07 10:31:23 RepVGG-A0] (main.py 282): INFO Train: [87/300][60/78]	eta 0:00:33 lr 5.140871	time 1.1745 (1.8795)	loss 3.3544 (3.3777)	grad_norm 0.3193 (0.3411)	mem 39782MB
[2023-07-07 10:31:39 RepVGG-A0] (main.py 282): INFO Train: [87/300][70/78]	eta 0:00:14 lr 5.137454	time 1.2941 (1.8346)	loss 3.3800 (3.3710)	grad_norm 0.3821 (0.3391)	mem 39782MB
[2023-07-07 10:31:50 RepVGG-A0] (main.py 291): INFO EPOCH 87 training takes 0:02:21
[2023-07-07 10:32:13 RepVGG-A0] (main.py 282): INFO Train: [88/300][0/78]	eta 0:28:43 lr 5.134717	time 22.1002 (22.1002)	loss 3.4013 (3.4013)	grad_norm 0.3599 (0.3599)	mem 39782MB
[2023-07-07 10:32:28 RepVGG-A0] (main.py 282): INFO Train: [88/300][10/78]	eta 0:03:53 lr 5.131293	time 1.1891 (3.4360)	loss 3.3096 (3.3780)	grad_norm 0.3363 (0.3783)	mem 39782MB
[2023-07-07 10:32:43 RepVGG-A0] (main.py 282): INFO Train: [88/300][20/78]	eta 0:02:25 lr 5.127866	time 1.1843 (2.5063)	loss 3.2913 (3.3407)	grad_norm 0.3279 (0.3545)	mem 39782MB
[2023-07-07 10:32:58 RepVGG-A0] (main.py 282): INFO Train: [88/300][30/78]	eta 0:01:44 lr 5.124435	time 1.3846 (2.1766)	loss 3.2900 (3.3300)	grad_norm 0.3467 (0.3561)	mem 39782MB
[2023-07-07 10:33:16 RepVGG-A0] (main.py 282): INFO Train: [88/300][40/78]	eta 0:01:19 lr 5.121001	time 4.8357 (2.0928)	loss 3.4535 (3.3274)	grad_norm 0.4504 (0.3562)	mem 39782MB
[2023-07-07 10:33:30 RepVGG-A0] (main.py 282): INFO Train: [88/300][50/78]	eta 0:00:54 lr 5.117563	time 1.1747 (1.9607)	loss 5.6295 (3.6016)	grad_norm 0.5972 (0.4390)	mem 39782MB
[2023-07-07 10:33:46 RepVGG-A0] (main.py 282): INFO Train: [88/300][60/78]	eta 0:00:34 lr 5.114122	time 1.2941 (1.8950)	loss 4.5210 (3.8382)	grad_norm 0.2926 (0.4385)	mem 39782MB
[2023-07-07 10:34:01 RepVGG-A0] (main.py 282): INFO Train: [88/300][70/78]	eta 0:00:14 lr 5.110678	time 1.2920 (1.8374)	loss 4.0282 (3.8898)	grad_norm 0.2949 (0.4208)	mem 39782MB
[2023-07-07 10:34:14 RepVGG-A0] (main.py 291): INFO EPOCH 88 training takes 0:02:23
[2023-07-07 10:34:36 RepVGG-A0] (main.py 282): INFO Train: [89/300][0/78]	eta 0:28:36 lr 5.107920	time 22.0089 (22.0089)	loss 3.7189 (3.7189)	grad_norm 0.2494 (0.2494)	mem 39782MB
[2023-07-07 10:34:50 RepVGG-A0] (main.py 282): INFO Train: [89/300][10/78]	eta 0:03:46 lr 5.104469	time 1.1902 (3.3331)	loss 3.5935 (3.6820)	grad_norm 0.2979 (0.2737)	mem 39782MB
[2023-07-07 10:35:05 RepVGG-A0] (main.py 282): INFO Train: [89/300][20/78]	eta 0:02:22 lr 5.101015	time 1.4414 (2.4544)	loss 3.5706 (3.6239)	grad_norm 0.3213 (0.2793)	mem 39782MB
[2023-07-07 10:35:19 RepVGG-A0] (main.py 282): INFO Train: [89/300][30/78]	eta 0:01:41 lr 5.097557	time 1.1731 (2.1155)	loss 3.6307 (3.5930)	grad_norm 0.3384 (0.2874)	mem 39782MB
[2023-07-07 10:35:37 RepVGG-A0] (main.py 282): INFO Train: [89/300][40/78]	eta 0:01:17 lr 5.094096	time 3.2333 (2.0425)	loss 3.4057 (3.5645)	grad_norm 0.2683 (0.2941)	mem 39782MB
[2023-07-07 10:35:52 RepVGG-A0] (main.py 282): INFO Train: [89/300][50/78]	eta 0:00:54 lr 5.090631	time 1.1928 (1.9335)	loss 3.4172 (3.5395)	grad_norm 0.3317 (0.2978)	mem 39782MB
[2023-07-07 10:36:08 RepVGG-A0] (main.py 282): INFO Train: [89/300][60/78]	eta 0:00:33 lr 5.087164	time 1.1303 (1.8687)	loss 3.3452 (3.5252)	grad_norm 0.3111 (0.3032)	mem 39782MB
[2023-07-07 10:36:23 RepVGG-A0] (main.py 282): INFO Train: [89/300][70/78]	eta 0:00:14 lr 5.083692	time 1.2866 (1.8206)	loss 3.4466 (3.5141)	grad_norm 0.3837 (0.3085)	mem 39782MB
[2023-07-07 10:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 89 training takes 0:02:20
[2023-07-07 10:36:55 RepVGG-A0] (main.py 282): INFO Train: [90/300][0/78]	eta 0:27:55 lr 5.080913	time 21.4836 (21.4836)	loss 3.3873 (3.3873)	grad_norm 0.2854 (0.2854)	mem 39782MB
[2023-07-07 10:37:11 RepVGG-A0] (main.py 282): INFO Train: [90/300][10/78]	eta 0:03:49 lr 5.077435	time 1.1716 (3.3683)	loss 3.6231 (3.4901)	grad_norm 0.4454 (0.4168)	mem 39782MB
[2023-07-07 10:37:25 RepVGG-A0] (main.py 282): INFO Train: [90/300][20/78]	eta 0:02:21 lr 5.073955	time 1.1970 (2.4313)	loss 3.3195 (3.4751)	grad_norm 0.2934 (0.3839)	mem 39782MB
[2023-07-07 10:37:40 RepVGG-A0] (main.py 282): INFO Train: [90/300][30/78]	eta 0:01:42 lr 5.070470	time 1.2414 (2.1363)	loss 3.4724 (3.4480)	grad_norm 0.3416 (0.3664)	mem 39782MB
[2023-07-07 10:37:58 RepVGG-A0] (main.py 282): INFO Train: [90/300][40/78]	eta 0:01:18 lr 5.066983	time 3.2421 (2.0598)	loss 3.2981 (3.4222)	grad_norm 0.2938 (0.3541)	mem 39782MB
[2023-07-07 10:38:14 RepVGG-A0] (main.py 282): INFO Train: [90/300][50/78]	eta 0:00:54 lr 5.063492	time 1.1722 (1.9547)	loss 3.5730 (3.4152)	grad_norm 0.4873 (0.3578)	mem 39782MB
[2023-07-07 10:38:28 RepVGG-A0] (main.py 282): INFO Train: [90/300][60/78]	eta 0:00:33 lr 5.059998	time 1.2978 (1.8717)	loss 5.2193 (3.5976)	grad_norm 0.6534 (0.4244)	mem 39782MB
[2023-07-07 10:38:43 RepVGG-A0] (main.py 282): INFO Train: [90/300][70/78]	eta 0:00:14 lr 5.056500	time 1.2894 (1.8225)	loss 4.0254 (3.7151)	grad_norm 0.2893 (0.4222)	mem 39782MB
[2023-07-07 10:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 90 training takes 0:02:20
[2023-07-07 10:39:17 RepVGG-A0] (main.py 282): INFO Train: [91/300][0/78]	eta 0:28:41 lr 5.053700	time 22.0730 (22.0730)	loss 3.8096 (3.8096)	grad_norm 0.2900 (0.2900)	mem 39782MB
[2023-07-07 10:39:31 RepVGG-A0] (main.py 282): INFO Train: [91/300][10/78]	eta 0:03:42 lr 5.050196	time 1.1725 (3.2742)	loss 3.6563 (3.6634)	grad_norm 0.3048 (0.2744)	mem 39782MB
[2023-07-07 10:39:46 RepVGG-A0] (main.py 282): INFO Train: [91/300][20/78]	eta 0:02:20 lr 5.046689	time 1.3490 (2.4201)	loss 3.4256 (3.6040)	grad_norm 0.2436 (0.2787)	mem 39782MB
[2023-07-07 10:40:02 RepVGG-A0] (main.py 282): INFO Train: [91/300][30/78]	eta 0:01:44 lr 5.043179	time 1.5706 (2.1701)	loss 3.4148 (3.5523)	grad_norm 0.2710 (0.2819)	mem 39782MB
[2023-07-07 10:40:18 RepVGG-A0] (main.py 282): INFO Train: [91/300][40/78]	eta 0:01:17 lr 5.039665	time 2.6896 (2.0283)	loss 3.4212 (3.5223)	grad_norm 0.2918 (0.2888)	mem 39782MB
[2023-07-07 10:40:33 RepVGG-A0] (main.py 282): INFO Train: [91/300][50/78]	eta 0:00:53 lr 5.036148	time 1.1731 (1.9242)	loss 3.5583 (3.4997)	grad_norm 0.3607 (0.2909)	mem 39782MB
[2023-07-07 10:40:48 RepVGG-A0] (main.py 282): INFO Train: [91/300][60/78]	eta 0:00:33 lr 5.032628	time 1.1984 (1.8503)	loss 3.5715 (3.4894)	grad_norm 0.3677 (0.3011)	mem 39782MB
[2023-07-07 10:41:03 RepVGG-A0] (main.py 282): INFO Train: [91/300][70/78]	eta 0:00:14 lr 5.029105	time 1.2305 (1.8093)	loss 3.3376 (3.4694)	grad_norm 0.3018 (0.3001)	mem 39782MB
[2023-07-07 10:41:15 RepVGG-A0] (main.py 291): INFO EPOCH 91 training takes 0:02:20
[2023-07-07 10:41:36 RepVGG-A0] (main.py 282): INFO Train: [92/300][0/78]	eta 0:27:25 lr 5.026283	time 21.0930 (21.0930)	loss 3.5873 (3.5873)	grad_norm 0.4467 (0.4467)	mem 39782MB
[2023-07-07 10:41:51 RepVGG-A0] (main.py 282): INFO Train: [92/300][10/78]	eta 0:03:42 lr 5.022754	time 1.1716 (3.2687)	loss 3.3675 (3.3944)	grad_norm 0.3085 (0.3474)	mem 39782MB
[2023-07-07 10:42:05 RepVGG-A0] (main.py 282): INFO Train: [92/300][20/78]	eta 0:02:18 lr 5.019221	time 1.1725 (2.3884)	loss 3.3681 (3.3699)	grad_norm 0.3563 (0.3408)	mem 39782MB
[2023-07-07 10:42:20 RepVGG-A0] (main.py 282): INFO Train: [92/300][30/78]	eta 0:01:41 lr 5.015685	time 1.1336 (2.1042)	loss 3.4448 (3.3801)	grad_norm 0.3890 (0.3458)	mem 39782MB
[2023-07-07 10:42:38 RepVGG-A0] (main.py 282): INFO Train: [92/300][40/78]	eta 0:01:16 lr 5.012146	time 4.2076 (2.0249)	loss 3.3233 (3.3780)	grad_norm 0.3086 (0.3479)	mem 39782MB
[2023-07-07 10:42:53 RepVGG-A0] (main.py 282): INFO Train: [92/300][50/78]	eta 0:00:53 lr 5.008603	time 1.1739 (1.9234)	loss 3.4478 (3.3663)	grad_norm 0.3969 (0.3440)	mem 39782MB
[2023-07-07 10:43:08 RepVGG-A0] (main.py 282): INFO Train: [92/300][60/78]	eta 0:00:33 lr 5.005057	time 1.1569 (1.8582)	loss 3.3855 (3.3836)	grad_norm 0.3106 (0.3543)	mem 39782MB
[2023-07-07 10:43:23 RepVGG-A0] (main.py 282): INFO Train: [92/300][70/78]	eta 0:00:14 lr 5.001508	time 1.3715 (1.8086)	loss 3.3952 (3.3751)	grad_norm 0.3792 (0.3507)	mem 39782MB
[2023-07-07 10:43:35 RepVGG-A0] (main.py 291): INFO EPOCH 92 training takes 0:02:20
[2023-07-07 10:43:57 RepVGG-A0] (main.py 282): INFO Train: [93/300][0/78]	eta 0:28:37 lr 4.998667	time 22.0140 (22.0140)	loss 3.5945 (3.5945)	grad_norm 0.4690 (0.4690)	mem 39782MB
[2023-07-07 10:44:12 RepVGG-A0] (main.py 282): INFO Train: [93/300][10/78]	eta 0:03:46 lr 4.995112	time 1.1734 (3.3362)	loss 3.2962 (3.3583)	grad_norm 0.3758 (0.3627)	mem 39782MB
[2023-07-07 10:44:26 RepVGG-A0] (main.py 282): INFO Train: [93/300][20/78]	eta 0:02:18 lr 4.991554	time 1.1735 (2.3938)	loss 3.2954 (3.3268)	grad_norm 0.3243 (0.3417)	mem 39782MB
[2023-07-07 10:44:41 RepVGG-A0] (main.py 282): INFO Train: [93/300][30/78]	eta 0:01:42 lr 4.987992	time 1.4224 (2.1323)	loss 3.3428 (3.3391)	grad_norm 0.3700 (0.3540)	mem 39782MB
[2023-07-07 10:44:59 RepVGG-A0] (main.py 282): INFO Train: [93/300][40/78]	eta 0:01:17 lr 4.984428	time 3.3605 (2.0377)	loss 3.2685 (3.3288)	grad_norm 0.3630 (0.3527)	mem 39782MB
[2023-07-07 10:45:14 RepVGG-A0] (main.py 282): INFO Train: [93/300][50/78]	eta 0:00:54 lr 4.980860	time 1.1734 (1.9329)	loss 3.2925 (3.3192)	grad_norm 0.3187 (0.3509)	mem 39782MB
[2023-07-07 10:45:29 RepVGG-A0] (main.py 282): INFO Train: [93/300][60/78]	eta 0:00:33 lr 4.977289	time 1.3000 (1.8631)	loss 3.7966 (3.3521)	grad_norm 0.5721 (0.3726)	mem 39782MB
[2023-07-07 10:45:44 RepVGG-A0] (main.py 282): INFO Train: [93/300][70/78]	eta 0:00:14 lr 4.973715	time 1.3717 (1.8132)	loss 3.3752 (3.3888)	grad_norm 0.2790 (0.3798)	mem 39782MB
[2023-07-07 10:45:56 RepVGG-A0] (main.py 291): INFO EPOCH 93 training takes 0:02:20
[2023-07-07 10:46:16 RepVGG-A0] (main.py 282): INFO Train: [94/300][0/78]	eta 0:26:01 lr 4.970853	time 20.0193 (20.0193)	loss 3.2816 (3.2816)	grad_norm 0.2970 (0.2970)	mem 39782MB
[2023-07-07 10:46:33 RepVGG-A0] (main.py 282): INFO Train: [94/300][10/78]	eta 0:03:47 lr 4.967273	time 1.1716 (3.3429)	loss 3.3073 (3.2506)	grad_norm 0.3257 (0.3105)	mem 39782MB
[2023-07-07 10:46:49 RepVGG-A0] (main.py 282): INFO Train: [94/300][20/78]	eta 0:02:25 lr 4.963690	time 1.1784 (2.5052)	loss 3.2919 (3.2688)	grad_norm 0.3192 (0.3282)	mem 39782MB
[2023-07-07 10:47:05 RepVGG-A0] (main.py 282): INFO Train: [94/300][30/78]	eta 0:01:46 lr 4.960103	time 1.7178 (2.2123)	loss 3.2754 (3.2602)	grad_norm 0.3676 (0.3276)	mem 39782MB
[2023-07-07 10:47:21 RepVGG-A0] (main.py 282): INFO Train: [94/300][40/78]	eta 0:01:18 lr 4.956514	time 1.5562 (2.0736)	loss 3.3998 (3.3018)	grad_norm 0.3815 (0.3565)	mem 39782MB
[2023-07-07 10:47:36 RepVGG-A0] (main.py 282): INFO Train: [94/300][50/78]	eta 0:00:54 lr 4.952921	time 1.1940 (1.9623)	loss 3.2303 (3.3034)	grad_norm 0.3048 (0.3481)	mem 39782MB
[2023-07-07 10:47:51 RepVGG-A0] (main.py 282): INFO Train: [94/300][60/78]	eta 0:00:33 lr 4.949325	time 1.1863 (1.8830)	loss 3.2913 (3.3000)	grad_norm 0.3780 (0.3469)	mem 39782MB
[2023-07-07 10:48:06 RepVGG-A0] (main.py 282): INFO Train: [94/300][70/78]	eta 0:00:14 lr 4.945726	time 1.5347 (1.8259)	loss 3.2742 (3.2990)	grad_norm 0.3318 (0.3462)	mem 39782MB
[2023-07-07 10:48:18 RepVGG-A0] (main.py 291): INFO EPOCH 94 training takes 0:02:21
[2023-07-07 10:48:40 RepVGG-A0] (main.py 282): INFO Train: [95/300][0/78]	eta 0:28:43 lr 4.942845	time 22.0992 (22.0992)	loss 3.4173 (3.4173)	grad_norm 0.4473 (0.4473)	mem 39782MB
[2023-07-07 10:48:54 RepVGG-A0] (main.py 282): INFO Train: [95/300][10/78]	eta 0:03:44 lr 4.939240	time 1.1693 (3.3075)	loss 3.1974 (3.3333)	grad_norm 0.3206 (0.3940)	mem 39782MB
[2023-07-07 10:49:10 RepVGG-A0] (main.py 282): INFO Train: [95/300][20/78]	eta 0:02:23 lr 4.935632	time 1.4319 (2.4783)	loss 3.2778 (3.2754)	grad_norm 0.3305 (0.3543)	mem 39782MB
[2023-07-07 10:49:25 RepVGG-A0] (main.py 282): INFO Train: [95/300][30/78]	eta 0:01:44 lr 4.932022	time 1.5195 (2.1788)	loss 3.3324 (3.2924)	grad_norm 0.4079 (0.3655)	mem 39782MB
[2023-07-07 10:49:42 RepVGG-A0] (main.py 282): INFO Train: [95/300][40/78]	eta 0:01:17 lr 4.928407	time 2.3938 (2.0475)	loss 3.2188 (3.2920)	grad_norm 0.3472 (0.3665)	mem 39782MB
[2023-07-07 10:49:57 RepVGG-A0] (main.py 282): INFO Train: [95/300][50/78]	eta 0:00:54 lr 4.924790	time 1.1717 (1.9478)	loss 3.3041 (3.2896)	grad_norm 0.4050 (0.3629)	mem 39782MB
[2023-07-07 10:50:12 RepVGG-A0] (main.py 282): INFO Train: [95/300][60/78]	eta 0:00:33 lr 4.921170	time 1.3041 (1.8664)	loss 3.1790 (3.3002)	grad_norm 0.2904 (0.3676)	mem 39782MB
[2023-07-07 10:50:27 RepVGG-A0] (main.py 282): INFO Train: [95/300][70/78]	eta 0:00:14 lr 4.917547	time 1.1984 (1.8136)	loss 3.2849 (3.2948)	grad_norm 0.3459 (0.3644)	mem 39782MB
[2023-07-07 10:50:38 RepVGG-A0] (main.py 291): INFO EPOCH 95 training takes 0:02:20
[2023-07-07 10:50:59 RepVGG-A0] (main.py 282): INFO Train: [96/300][0/78]	eta 0:27:10 lr 4.914646	time 20.9038 (20.9038)	loss 3.3609 (3.3609)	grad_norm 0.4653 (0.4653)	mem 39782MB
[2023-07-07 10:51:14 RepVGG-A0] (main.py 282): INFO Train: [96/300][10/78]	eta 0:03:40 lr 4.911017	time 1.1920 (3.2452)	loss 6.3324 (4.4454)	grad_norm 0.8510 (0.8143)	mem 39782MB
[2023-07-07 10:51:29 RepVGG-A0] (main.py 282): INFO Train: [96/300][20/78]	eta 0:02:19 lr 4.907385	time 1.1715 (2.4010)	loss 5.1166 (5.0902)	grad_norm 0.2901 (0.6619)	mem 39782MB
[2023-07-07 10:51:43 RepVGG-A0] (main.py 282): INFO Train: [96/300][30/78]	eta 0:01:40 lr 4.903750	time 1.1819 (2.0926)	loss 4.4515 (5.0014)	grad_norm 0.2770 (0.5503)	mem 39782MB
[2023-07-07 10:52:02 RepVGG-A0] (main.py 282): INFO Train: [96/300][40/78]	eta 0:01:17 lr 4.900111	time 4.3167 (2.0291)	loss 4.1964 (4.8473)	grad_norm 0.2482 (0.4951)	mem 39782MB
[2023-07-07 10:52:16 RepVGG-A0] (main.py 282): INFO Train: [96/300][50/78]	eta 0:00:53 lr 4.896470	time 1.1722 (1.9159)	loss 3.8969 (4.6778)	grad_norm 0.2669 (0.4522)	mem 39782MB
[2023-07-07 10:52:31 RepVGG-A0] (main.py 282): INFO Train: [96/300][60/78]	eta 0:00:33 lr 4.892826	time 1.2319 (1.8458)	loss 3.8091 (4.5431)	grad_norm 0.3133 (0.4259)	mem 39782MB
[2023-07-07 10:52:47 RepVGG-A0] (main.py 282): INFO Train: [96/300][70/78]	eta 0:00:14 lr 4.889179	time 1.2873 (1.8050)	loss 3.7907 (4.4308)	grad_norm 0.3464 (0.4095)	mem 39782MB
[2023-07-07 10:52:58 RepVGG-A0] (main.py 291): INFO EPOCH 96 training takes 0:02:19
[2023-07-07 10:53:20 RepVGG-A0] (main.py 282): INFO Train: [97/300][0/78]	eta 0:28:42 lr 4.886259	time 22.0884 (22.0884)	loss 3.4921 (3.4921)	grad_norm 0.2730 (0.2730)	mem 39782MB
[2023-07-07 10:53:35 RepVGG-A0] (main.py 282): INFO Train: [97/300][10/78]	eta 0:03:44 lr 4.882606	time 1.1885 (3.3031)	loss 3.4797 (3.5595)	grad_norm 0.3142 (0.3169)	mem 39782MB
[2023-07-07 10:53:49 RepVGG-A0] (main.py 282): INFO Train: [97/300][20/78]	eta 0:02:19 lr 4.878950	time 1.2570 (2.4029)	loss 3.5308 (3.5571)	grad_norm 0.3494 (0.3215)	mem 39782MB
[2023-07-07 10:54:05 RepVGG-A0] (main.py 282): INFO Train: [97/300][30/78]	eta 0:01:43 lr 4.875291	time 1.6228 (2.1493)	loss 3.5256 (3.5527)	grad_norm 0.3804 (0.3323)	mem 39782MB
[2023-07-07 10:54:23 RepVGG-A0] (main.py 282): INFO Train: [97/300][40/78]	eta 0:01:18 lr 4.871629	time 3.5377 (2.0527)	loss 3.4803 (3.5399)	grad_norm 0.3200 (0.3301)	mem 39782MB
[2023-07-07 10:54:37 RepVGG-A0] (main.py 282): INFO Train: [97/300][50/78]	eta 0:00:54 lr 4.867964	time 1.1779 (1.9364)	loss 3.5336 (3.5387)	grad_norm 0.3250 (0.3386)	mem 39782MB
[2023-07-07 10:54:52 RepVGG-A0] (main.py 282): INFO Train: [97/300][60/78]	eta 0:00:33 lr 4.864296	time 1.1807 (1.8689)	loss 3.4079 (3.5244)	grad_norm 0.3264 (0.3380)	mem 39782MB
[2023-07-07 10:55:07 RepVGG-A0] (main.py 282): INFO Train: [97/300][70/78]	eta 0:00:14 lr 4.860625	time 1.1951 (1.8147)	loss 3.5487 (3.5181)	grad_norm 0.3968 (0.3426)	mem 39782MB
[2023-07-07 10:55:19 RepVGG-A0] (main.py 291): INFO EPOCH 97 training takes 0:02:20
[2023-07-07 10:55:40 RepVGG-A0] (main.py 282): INFO Train: [98/300][0/78]	eta 0:27:50 lr 4.857686	time 21.4183 (21.4183)	loss 3.3179 (3.3179)	grad_norm 0.3202 (0.3202)	mem 39782MB
[2023-07-07 10:55:54 RepVGG-A0] (main.py 282): INFO Train: [98/300][10/78]	eta 0:03:39 lr 4.854010	time 1.1911 (3.2272)	loss 3.4988 (3.4897)	grad_norm 0.3928 (0.4157)	mem 39782MB
[2023-07-07 10:56:09 RepVGG-A0] (main.py 282): INFO Train: [98/300][20/78]	eta 0:02:20 lr 4.850331	time 1.1738 (2.4157)	loss 3.3963 (3.4466)	grad_norm 0.3147 (0.3766)	mem 39782MB
[2023-07-07 10:56:24 RepVGG-A0] (main.py 282): INFO Train: [98/300][30/78]	eta 0:01:41 lr 4.846649	time 1.4315 (2.1173)	loss 3.3567 (3.4207)	grad_norm 0.3499 (0.3597)	mem 39782MB
[2023-07-07 10:56:42 RepVGG-A0] (main.py 282): INFO Train: [98/300][40/78]	eta 0:01:17 lr 4.842963	time 3.3202 (2.0456)	loss 3.4048 (3.4061)	grad_norm 0.4264 (0.3585)	mem 39782MB
[2023-07-07 10:56:57 RepVGG-A0] (main.py 282): INFO Train: [98/300][50/78]	eta 0:00:54 lr 4.839275	time 1.1713 (1.9386)	loss 3.5078 (3.4269)	grad_norm 0.3982 (0.3720)	mem 39782MB
[2023-07-07 10:57:12 RepVGG-A0] (main.py 282): INFO Train: [98/300][60/78]	eta 0:00:33 lr 4.835584	time 1.2882 (1.8671)	loss 3.3828 (3.4161)	grad_norm 0.3177 (0.3655)	mem 39782MB
[2023-07-07 10:57:28 RepVGG-A0] (main.py 282): INFO Train: [98/300][70/78]	eta 0:00:14 lr 4.831890	time 1.3527 (1.8183)	loss 3.3019 (3.4036)	grad_norm 0.3478 (0.3604)	mem 39782MB
[2023-07-07 10:57:40 RepVGG-A0] (main.py 291): INFO EPOCH 98 training takes 0:02:21
[2023-07-07 10:58:02 RepVGG-A0] (main.py 282): INFO Train: [99/300][0/78]	eta 0:28:12 lr 4.828933	time 21.6973 (21.6973)	loss 3.3504 (3.3504)	grad_norm 0.4066 (0.4066)	mem 39782MB
[2023-07-07 10:58:16 RepVGG-A0] (main.py 282): INFO Train: [99/300][10/78]	eta 0:03:40 lr 4.825233	time 1.1716 (3.2499)	loss 3.3860 (3.4310)	grad_norm 0.3805 (0.4299)	mem 39782MB
[2023-07-07 10:58:29 RepVGG-A0] (main.py 282): INFO Train: [99/300][20/78]	eta 0:02:15 lr 4.821531	time 1.1726 (2.3442)	loss 3.2694 (3.3688)	grad_norm 0.3074 (0.3755)	mem 39782MB
[2023-07-07 10:58:44 RepVGG-A0] (main.py 282): INFO Train: [99/300][30/78]	eta 0:01:39 lr 4.817826	time 1.3025 (2.0649)	loss 3.4305 (3.3595)	grad_norm 0.3995 (0.3717)	mem 39782MB
[2023-07-07 10:59:03 RepVGG-A0] (main.py 282): INFO Train: [99/300][40/78]	eta 0:01:16 lr 4.814117	time 4.3946 (2.0146)	loss 3.8905 (3.4215)	grad_norm 0.5800 (0.4067)	mem 39782MB
[2023-07-07 10:59:17 RepVGG-A0] (main.py 282): INFO Train: [99/300][50/78]	eta 0:00:53 lr 4.810406	time 1.2290 (1.9048)	loss 3.3220 (3.4407)	grad_norm 0.3095 (0.3978)	mem 39782MB
[2023-07-07 10:59:33 RepVGG-A0] (main.py 282): INFO Train: [99/300][60/78]	eta 0:00:33 lr 4.806692	time 1.3290 (1.8451)	loss 3.2516 (3.4238)	grad_norm 0.3078 (0.3838)	mem 39782MB
[2023-07-07 10:59:48 RepVGG-A0] (main.py 282): INFO Train: [99/300][70/78]	eta 0:00:14 lr 4.802976	time 1.2280 (1.7960)	loss 3.3378 (3.4066)	grad_norm 0.3218 (0.3770)	mem 39782MB
[2023-07-07 10:59:59 RepVGG-A0] (main.py 291): INFO EPOCH 99 training takes 0:02:18
[2023-07-07 11:00:20 RepVGG-A0] (main.py 282): INFO Train: [100/300][0/78]	eta 0:27:04 lr 4.800000	time 20.8226 (20.8226)	loss 3.2217 (3.2217)	grad_norm 0.3370 (0.3370)	mem 39782MB
[2023-07-07 11:00:33 RepVGG-A0] (main.py 282): INFO Train: [100/300][10/78]	eta 0:03:33 lr 4.796278	time 1.1715 (3.1335)	loss 3.3082 (3.2944)	grad_norm 0.3589 (0.3672)	mem 39782MB
[2023-07-07 11:00:48 RepVGG-A0] (main.py 282): INFO Train: [100/300][20/78]	eta 0:02:15 lr 4.792553	time 1.1720 (2.3348)	loss 3.2610 (3.2793)	grad_norm 0.3386 (0.3572)	mem 39782MB
[2023-07-07 11:01:04 RepVGG-A0] (main.py 282): INFO Train: [100/300][30/78]	eta 0:01:40 lr 4.788825	time 1.6506 (2.0923)	loss 3.2295 (3.2861)	grad_norm 0.3677 (0.3633)	mem 39782MB
[2023-07-07 11:01:21 RepVGG-A0] (main.py 282): INFO Train: [100/300][40/78]	eta 0:01:16 lr 4.785095	time 3.4431 (2.0102)	loss 3.2185 (3.2870)	grad_norm 0.3622 (0.3610)	mem 39782MB
[2023-07-07 11:01:36 RepVGG-A0] (main.py 282): INFO Train: [100/300][50/78]	eta 0:00:53 lr 4.781361	time 1.2922 (1.9047)	loss 3.2996 (3.2874)	grad_norm 0.3899 (0.3616)	mem 39782MB
[2023-07-07 11:01:51 RepVGG-A0] (main.py 282): INFO Train: [100/300][60/78]	eta 0:00:33 lr 4.777625	time 1.1934 (1.8359)	loss 3.2960 (3.2944)	grad_norm 0.3464 (0.3632)	mem 39782MB
[2023-07-07 11:02:06 RepVGG-A0] (main.py 282): INFO Train: [100/300][70/78]	eta 0:00:14 lr 4.773885	time 1.2146 (1.7931)	loss 3.3796 (3.2992)	grad_norm 0.4160 (0.3661)	mem 39782MB
[2023-07-07 11:02:18 RepVGG-A0] (main.py 291): INFO EPOCH 100 training takes 0:02:19
[2023-07-07 11:02:36 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.521 (17.521)	Loss 2.8196 (2.8196)	Acc@1 40.741 (40.741)	Acc@5 66.449 (66.449)	Mem 39782MB
[2023-07-07 11:02:37 RepVGG-A0] (main.py 342): INFO  * Acc@1 40.988 Acc@5 66.530
[2023-07-07 11:02:37 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 100: 40.988%
[2023-07-07 11:02:37 RepVGG-A0] (main.py 172): INFO Max accuracy: 40.99%
[2023-07-07 11:02:58 RepVGG-A0] (main.py 282): INFO Train: [101/300][0/78]	eta 0:27:24 lr 4.770892	time 21.0865 (21.0865)	loss 3.2201 (3.2201)	grad_norm 0.3386 (0.3386)	mem 39782MB
[2023-07-07 11:03:15 RepVGG-A0] (main.py 282): INFO Train: [101/300][10/78]	eta 0:03:57 lr 4.767148	time 1.1742 (3.4952)	loss 3.2787 (3.2423)	grad_norm 0.3965 (0.3596)	mem 39782MB
[2023-07-07 11:03:29 RepVGG-A0] (main.py 282): INFO Train: [101/300][20/78]	eta 0:02:24 lr 4.763401	time 1.1728 (2.4880)	loss 3.2556 (3.2646)	grad_norm 0.3963 (0.3756)	mem 39782MB
[2023-07-07 11:03:45 RepVGG-A0] (main.py 282): INFO Train: [101/300][30/78]	eta 0:01:45 lr 4.759651	time 1.1278 (2.1876)	loss 3.2742 (3.2748)	grad_norm 0.3679 (0.3772)	mem 39782MB
[2023-07-07 11:04:03 RepVGG-A0] (main.py 282): INFO Train: [101/300][40/78]	eta 0:01:19 lr 4.755898	time 4.3723 (2.1033)	loss 3.2192 (3.2652)	grad_norm 0.3157 (0.3655)	mem 39782MB
[2023-07-07 11:04:17 RepVGG-A0] (main.py 282): INFO Train: [101/300][50/78]	eta 0:00:55 lr 4.752142	time 1.3049 (1.9698)	loss 6.5138 (3.5002)	grad_norm 0.9319 (0.4543)	mem 39782MB
[2023-07-07 11:04:33 RepVGG-A0] (main.py 282): INFO Train: [101/300][60/78]	eta 0:00:34 lr 4.748384	time 1.1952 (1.8959)	loss 5.4842 (3.9063)	grad_norm 0.3905 (0.4563)	mem 39782MB
[2023-07-07 11:04:48 RepVGG-A0] (main.py 282): INFO Train: [101/300][70/78]	eta 0:00:14 lr 4.744623	time 1.4268 (1.8464)	loss 4.8002 (4.0785)	grad_norm 0.2919 (0.4443)	mem 39782MB
[2023-07-07 11:04:59 RepVGG-A0] (main.py 291): INFO EPOCH 101 training takes 0:02:21
[2023-07-07 11:05:20 RepVGG-A0] (main.py 282): INFO Train: [102/300][0/78]	eta 0:27:33 lr 4.741612	time 21.2034 (21.2034)	loss 4.3484 (4.3484)	grad_norm 0.2890 (0.2890)	mem 39782MB
[2023-07-07 11:05:34 RepVGG-A0] (main.py 282): INFO Train: [102/300][10/78]	eta 0:03:41 lr 4.737846	time 1.1692 (3.2530)	loss 4.2383 (4.2844)	grad_norm 0.3381 (0.3161)	mem 39782MB
[2023-07-07 11:05:49 RepVGG-A0] (main.py 282): INFO Train: [102/300][20/78]	eta 0:02:18 lr 4.734077	time 1.1708 (2.3914)	loss 3.9610 (4.1818)	grad_norm 0.3016 (0.3182)	mem 39782MB
[2023-07-07 11:06:04 RepVGG-A0] (main.py 282): INFO Train: [102/300][30/78]	eta 0:01:41 lr 4.730305	time 1.3700 (2.1196)	loss 3.9380 (4.0895)	grad_norm 0.4031 (0.3212)	mem 39782MB
[2023-07-07 11:06:23 RepVGG-A0] (main.py 282): INFO Train: [102/300][40/78]	eta 0:01:18 lr 4.726530	time 3.8071 (2.0599)	loss 3.8176 (4.0223)	grad_norm 0.3427 (0.3224)	mem 39782MB
[2023-07-07 11:06:38 RepVGG-A0] (main.py 282): INFO Train: [102/300][50/78]	eta 0:00:54 lr 4.722753	time 1.1724 (1.9431)	loss 3.7248 (3.9654)	grad_norm 0.3630 (0.3240)	mem 39782MB
[2023-07-07 11:06:53 RepVGG-A0] (main.py 282): INFO Train: [102/300][60/78]	eta 0:00:33 lr 4.718973	time 1.4496 (1.8750)	loss 3.7172 (3.9241)	grad_norm 0.3410 (0.3284)	mem 39782MB
[2023-07-07 11:07:07 RepVGG-A0] (main.py 282): INFO Train: [102/300][70/78]	eta 0:00:14 lr 4.715191	time 1.3881 (1.8138)	loss 3.5681 (3.8775)	grad_norm 0.3241 (0.3260)	mem 39782MB
[2023-07-07 11:07:19 RepVGG-A0] (main.py 291): INFO EPOCH 102 training takes 0:02:20
[2023-07-07 11:07:42 RepVGG-A0] (main.py 282): INFO Train: [103/300][0/78]	eta 0:30:03 lr 4.712162	time 23.1193 (23.1193)	loss 3.5883 (3.5883)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 11:07:58 RepVGG-A0] (main.py 282): INFO Train: [103/300][10/78]	eta 0:04:03 lr 4.708375	time 1.4902 (3.5847)	loss 3.4790 (3.5167)	grad_norm 0.3307 (0.3436)	mem 39782MB
[2023-07-07 11:08:12 RepVGG-A0] (main.py 282): INFO Train: [103/300][20/78]	eta 0:02:27 lr 4.704585	time 1.1735 (2.5517)	loss 3.5892 (3.5144)	grad_norm 0.4160 (0.3458)	mem 39782MB
[2023-07-07 11:08:28 RepVGG-A0] (main.py 282): INFO Train: [103/300][30/78]	eta 0:01:47 lr 4.700791	time 1.2668 (2.2456)	loss 3.4886 (3.5090)	grad_norm 0.3507 (0.3477)	mem 39782MB
[2023-07-07 11:08:46 RepVGG-A0] (main.py 282): INFO Train: [103/300][40/78]	eta 0:01:20 lr 4.696996	time 4.1499 (2.1212)	loss 3.5529 (3.5139)	grad_norm 0.4226 (0.3557)	mem 39782MB
[2023-07-07 11:09:02 RepVGG-A0] (main.py 282): INFO Train: [103/300][50/78]	eta 0:00:56 lr 4.693197	time 1.1427 (2.0159)	loss 3.4145 (3.5108)	grad_norm 0.3632 (0.3557)	mem 39782MB
[2023-07-07 11:09:17 RepVGG-A0] (main.py 282): INFO Train: [103/300][60/78]	eta 0:00:34 lr 4.689396	time 1.2680 (1.9319)	loss 3.4554 (3.5065)	grad_norm 0.3377 (0.3563)	mem 39782MB
[2023-07-07 11:09:31 RepVGG-A0] (main.py 282): INFO Train: [103/300][70/78]	eta 0:00:14 lr 4.685592	time 1.3414 (1.8701)	loss 3.9408 (3.5291)	grad_norm 0.6074 (0.3754)	mem 39782MB
[2023-07-07 11:09:43 RepVGG-A0] (main.py 291): INFO EPOCH 103 training takes 0:02:24
[2023-07-07 11:10:05 RepVGG-A0] (main.py 282): INFO Train: [104/300][0/78]	eta 0:28:33 lr 4.682547	time 21.9672 (21.9672)	loss 3.4944 (3.4944)	grad_norm 0.3481 (0.3481)	mem 39782MB
[2023-07-07 11:10:21 RepVGG-A0] (main.py 282): INFO Train: [104/300][10/78]	eta 0:03:50 lr 4.678739	time 1.1730 (3.3952)	loss 3.3443 (3.4364)	grad_norm 0.2905 (0.3089)	mem 39782MB
[2023-07-07 11:10:36 RepVGG-A0] (main.py 282): INFO Train: [104/300][20/78]	eta 0:02:25 lr 4.674927	time 1.3238 (2.5126)	loss 3.3601 (3.4188)	grad_norm 0.3190 (0.3227)	mem 39782MB
[2023-07-07 11:10:52 RepVGG-A0] (main.py 282): INFO Train: [104/300][30/78]	eta 0:01:45 lr 4.671113	time 1.4823 (2.2014)	loss 3.4800 (3.4044)	grad_norm 0.4319 (0.3306)	mem 39782MB
[2023-07-07 11:11:09 RepVGG-A0] (main.py 282): INFO Train: [104/300][40/78]	eta 0:01:18 lr 4.667297	time 3.5085 (2.0783)	loss 3.3868 (3.3974)	grad_norm 0.3650 (0.3313)	mem 39782MB
[2023-07-07 11:11:23 RepVGG-A0] (main.py 282): INFO Train: [104/300][50/78]	eta 0:00:54 lr 4.663478	time 1.1733 (1.9600)	loss 3.3876 (3.3949)	grad_norm 0.3621 (0.3355)	mem 39782MB
[2023-07-07 11:11:39 RepVGG-A0] (main.py 282): INFO Train: [104/300][60/78]	eta 0:00:34 lr 4.659656	time 1.1740 (1.8966)	loss 3.3903 (3.3910)	grad_norm 0.4318 (0.3407)	mem 39782MB
[2023-07-07 11:11:54 RepVGG-A0] (main.py 282): INFO Train: [104/300][70/78]	eta 0:00:14 lr 4.655831	time 1.1734 (1.8399)	loss 5.6050 (3.5221)	grad_norm 0.8881 (0.3996)	mem 39782MB
[2023-07-07 11:12:06 RepVGG-A0] (main.py 291): INFO EPOCH 104 training takes 0:02:22
[2023-07-07 11:12:26 RepVGG-A0] (main.py 282): INFO Train: [105/300][0/78]	eta 0:26:10 lr 4.652770	time 20.1400 (20.1400)	loss 4.0694 (4.0694)	grad_norm 0.3295 (0.3295)	mem 39782MB
[2023-07-07 11:12:41 RepVGG-A0] (main.py 282): INFO Train: [105/300][10/78]	eta 0:03:35 lr 4.648940	time 1.1724 (3.1702)	loss 3.7827 (3.9027)	grad_norm 0.2783 (0.2920)	mem 39782MB
[2023-07-07 11:12:55 RepVGG-A0] (main.py 282): INFO Train: [105/300][20/78]	eta 0:02:15 lr 4.645108	time 1.1714 (2.3432)	loss 3.6061 (3.7641)	grad_norm 0.2957 (0.2914)	mem 39782MB
[2023-07-07 11:13:09 RepVGG-A0] (main.py 282): INFO Train: [105/300][30/78]	eta 0:01:38 lr 4.641274	time 1.1798 (2.0522)	loss 3.4536 (3.6757)	grad_norm 0.3138 (0.2870)	mem 39782MB
[2023-07-07 11:13:28 RepVGG-A0] (main.py 282): INFO Train: [105/300][40/78]	eta 0:01:15 lr 4.637437	time 3.7988 (1.9951)	loss 3.4526 (3.6226)	grad_norm 0.3247 (0.2892)	mem 39782MB
[2023-07-07 11:13:43 RepVGG-A0] (main.py 282): INFO Train: [105/300][50/78]	eta 0:00:53 lr 4.633597	time 1.1726 (1.9113)	loss 3.3906 (3.5808)	grad_norm 0.3176 (0.2935)	mem 39782MB
[2023-07-07 11:13:58 RepVGG-A0] (main.py 282): INFO Train: [105/300][60/78]	eta 0:00:33 lr 4.629755	time 1.3808 (1.8429)	loss 3.3779 (3.5480)	grad_norm 0.3564 (0.2974)	mem 39782MB
[2023-07-07 11:14:13 RepVGG-A0] (main.py 282): INFO Train: [105/300][70/78]	eta 0:00:14 lr 4.625910	time 1.2465 (1.7869)	loss 3.4294 (3.5200)	grad_norm 0.3480 (0.3017)	mem 39782MB
[2023-07-07 11:14:25 RepVGG-A0] (main.py 291): INFO EPOCH 105 training takes 0:02:19
[2023-07-07 11:14:46 RepVGG-A0] (main.py 282): INFO Train: [106/300][0/78]	eta 0:27:26 lr 4.622833	time 21.1144 (21.1144)	loss 3.3568 (3.3568)	grad_norm 0.4038 (0.4038)	mem 39782MB
[2023-07-07 11:15:01 RepVGG-A0] (main.py 282): INFO Train: [106/300][10/78]	eta 0:03:42 lr 4.618983	time 1.1725 (3.2785)	loss 3.2640 (3.3439)	grad_norm 0.3277 (0.3555)	mem 39782MB
[2023-07-07 11:15:15 RepVGG-A0] (main.py 282): INFO Train: [106/300][20/78]	eta 0:02:18 lr 4.615131	time 1.1720 (2.3914)	loss 3.3080 (3.3300)	grad_norm 0.3653 (0.3493)	mem 39782MB
[2023-07-07 11:15:31 RepVGG-A0] (main.py 282): INFO Train: [106/300][30/78]	eta 0:01:42 lr 4.611277	time 1.4232 (2.1371)	loss 3.3053 (3.3177)	grad_norm 0.3596 (0.3467)	mem 39782MB
[2023-07-07 11:15:49 RepVGG-A0] (main.py 282): INFO Train: [106/300][40/78]	eta 0:01:17 lr 4.607420	time 4.2318 (2.0460)	loss 3.3127 (3.3178)	grad_norm 0.3452 (0.3519)	mem 39782MB
[2023-07-07 11:16:04 RepVGG-A0] (main.py 282): INFO Train: [106/300][50/78]	eta 0:00:54 lr 4.603560	time 1.1711 (1.9428)	loss 3.4144 (3.3290)	grad_norm 0.3828 (0.3579)	mem 39782MB
[2023-07-07 11:16:19 RepVGG-A0] (main.py 282): INFO Train: [106/300][60/78]	eta 0:00:33 lr 4.599698	time 1.2965 (1.8771)	loss 3.3817 (3.3311)	grad_norm 0.3683 (0.3593)	mem 39782MB
[2023-07-07 11:16:34 RepVGG-A0] (main.py 282): INFO Train: [106/300][70/78]	eta 0:00:14 lr 4.595833	time 1.1727 (1.8204)	loss 3.2999 (3.3282)	grad_norm 0.3370 (0.3559)	mem 39782MB
[2023-07-07 11:16:47 RepVGG-A0] (main.py 291): INFO EPOCH 106 training takes 0:02:21
[2023-07-07 11:17:10 RepVGG-A0] (main.py 282): INFO Train: [107/300][0/78]	eta 0:29:48 lr 4.592740	time 22.9274 (22.9274)	loss 3.5967 (3.5967)	grad_norm 0.5276 (0.5276)	mem 39782MB
[2023-07-07 11:17:25 RepVGG-A0] (main.py 282): INFO Train: [107/300][10/78]	eta 0:03:55 lr 4.588870	time 1.1772 (3.4682)	loss 3.2897 (3.4107)	grad_norm 0.3273 (0.4080)	mem 39782MB
[2023-07-07 11:17:39 RepVGG-A0] (main.py 282): INFO Train: [107/300][20/78]	eta 0:02:24 lr 4.584999	time 1.1751 (2.4967)	loss 3.3396 (3.3486)	grad_norm 0.3680 (0.3765)	mem 39782MB
[2023-07-07 11:17:54 RepVGG-A0] (main.py 282): INFO Train: [107/300][30/78]	eta 0:01:44 lr 4.581124	time 1.2149 (2.1872)	loss 3.1789 (3.3174)	grad_norm 0.2996 (0.3620)	mem 39782MB
[2023-07-07 11:18:13 RepVGG-A0] (main.py 282): INFO Train: [107/300][40/78]	eta 0:01:19 lr 4.577248	time 3.1944 (2.1048)	loss 3.5354 (3.3346)	grad_norm 0.4557 (0.3777)	mem 39782MB
[2023-07-07 11:18:28 RepVGG-A0] (main.py 282): INFO Train: [107/300][50/78]	eta 0:00:55 lr 4.573369	time 1.1720 (1.9926)	loss 3.2694 (3.3529)	grad_norm 0.3145 (0.3829)	mem 39782MB
[2023-07-07 11:18:43 RepVGG-A0] (main.py 282): INFO Train: [107/300][60/78]	eta 0:00:34 lr 4.569487	time 1.2132 (1.9060)	loss 3.2243 (3.3391)	grad_norm 0.3167 (0.3693)	mem 39782MB
[2023-07-07 11:18:58 RepVGG-A0] (main.py 282): INFO Train: [107/300][70/78]	eta 0:00:14 lr 4.565603	time 1.1935 (1.8519)	loss 3.3795 (3.3363)	grad_norm 0.3865 (0.3690)	mem 39782MB
[2023-07-07 11:19:10 RepVGG-A0] (main.py 291): INFO EPOCH 107 training takes 0:02:23
[2023-07-07 11:19:32 RepVGG-A0] (main.py 282): INFO Train: [108/300][0/78]	eta 0:28:25 lr 4.562494	time 21.8635 (21.8635)	loss 3.2993 (3.2993)	grad_norm 0.3557 (0.3557)	mem 39782MB
[2023-07-07 11:19:46 RepVGG-A0] (main.py 282): INFO Train: [108/300][10/78]	eta 0:03:45 lr 4.558605	time 1.1718 (3.3180)	loss 3.2717 (3.2832)	grad_norm 0.3630 (0.3826)	mem 39782MB
[2023-07-07 11:20:01 RepVGG-A0] (main.py 282): INFO Train: [108/300][20/78]	eta 0:02:21 lr 4.554714	time 1.1765 (2.4444)	loss 3.2322 (3.2655)	grad_norm 0.3497 (0.3675)	mem 39782MB
[2023-07-07 11:20:17 RepVGG-A0] (main.py 282): INFO Train: [108/300][30/78]	eta 0:01:44 lr 4.550821	time 1.7088 (2.1794)	loss 3.6708 (3.2949)	grad_norm 0.6360 (0.3946)	mem 39782MB
[2023-07-07 11:20:34 RepVGG-A0] (main.py 282): INFO Train: [108/300][40/78]	eta 0:01:18 lr 4.546925	time 3.5659 (2.0557)	loss 6.1369 (3.7273)	grad_norm 0.7834 (0.5315)	mem 39782MB
[2023-07-07 11:20:49 RepVGG-A0] (main.py 282): INFO Train: [108/300][50/78]	eta 0:00:54 lr 4.543027	time 1.1886 (1.9345)	loss 4.7534 (4.0199)	grad_norm 0.3638 (0.5098)	mem 39782MB
[2023-07-07 11:21:03 RepVGG-A0] (main.py 282): INFO Train: [108/300][60/78]	eta 0:00:33 lr 4.539126	time 1.1983 (1.8587)	loss 4.1695 (4.0813)	grad_norm 0.3112 (0.4736)	mem 39782MB
[2023-07-07 11:21:19 RepVGG-A0] (main.py 282): INFO Train: [108/300][70/78]	eta 0:00:14 lr 4.535223	time 1.1730 (1.8132)	loss 3.9818 (4.0770)	grad_norm 0.3120 (0.4521)	mem 39782MB
[2023-07-07 11:21:31 RepVGG-A0] (main.py 291): INFO EPOCH 108 training takes 0:02:20
[2023-07-07 11:21:52 RepVGG-A0] (main.py 282): INFO Train: [109/300][0/78]	eta 0:27:23 lr 4.532099	time 21.0661 (21.0661)	loss 3.7817 (3.7817)	grad_norm 0.3026 (0.3026)	mem 39782MB
[2023-07-07 11:22:07 RepVGG-A0] (main.py 282): INFO Train: [109/300][10/78]	eta 0:03:43 lr 4.528191	time 1.1904 (3.2876)	loss 3.5986 (3.6720)	grad_norm 0.2990 (0.2913)	mem 39782MB
[2023-07-07 11:22:22 RepVGG-A0] (main.py 282): INFO Train: [109/300][20/78]	eta 0:02:20 lr 4.524281	time 1.1740 (2.4287)	loss 3.7182 (3.6443)	grad_norm 0.3674 (0.3030)	mem 39782MB
[2023-07-07 11:22:37 RepVGG-A0] (main.py 282): INFO Train: [109/300][30/78]	eta 0:01:42 lr 4.520369	time 1.1511 (2.1444)	loss 3.6041 (3.6438)	grad_norm 0.3363 (0.3214)	mem 39782MB
[2023-07-07 11:22:55 RepVGG-A0] (main.py 282): INFO Train: [109/300][40/78]	eta 0:01:18 lr 4.516454	time 2.5731 (2.0559)	loss 3.4468 (3.6089)	grad_norm 0.2979 (0.3182)	mem 39782MB
[2023-07-07 11:23:10 RepVGG-A0] (main.py 282): INFO Train: [109/300][50/78]	eta 0:00:54 lr 4.512537	time 1.2394 (1.9412)	loss 3.4591 (3.5787)	grad_norm 0.3396 (0.3165)	mem 39782MB
[2023-07-07 11:23:25 RepVGG-A0] (main.py 282): INFO Train: [109/300][60/78]	eta 0:00:33 lr 4.508618	time 1.5570 (1.8787)	loss 3.4605 (3.5673)	grad_norm 0.3085 (0.3234)	mem 39782MB
[2023-07-07 11:23:39 RepVGG-A0] (main.py 282): INFO Train: [109/300][70/78]	eta 0:00:14 lr 4.504696	time 1.1864 (1.8112)	loss 3.4239 (3.5509)	grad_norm 0.3000 (0.3251)	mem 39782MB
[2023-07-07 11:23:52 RepVGG-A0] (main.py 291): INFO EPOCH 109 training takes 0:02:20
[2023-07-07 11:24:11 RepVGG-A0] (main.py 282): INFO Train: [110/300][0/78]	eta 0:25:47 lr 4.501557	time 19.8343 (19.8343)	loss 3.4463 (3.4463)	grad_norm 0.3769 (0.3769)	mem 39782MB
[2023-07-07 11:24:28 RepVGG-A0] (main.py 282): INFO Train: [110/300][10/78]	eta 0:03:44 lr 4.497631	time 1.1707 (3.3001)	loss 3.3882 (3.4182)	grad_norm 0.3576 (0.3923)	mem 39782MB
[2023-07-07 11:24:43 RepVGG-A0] (main.py 282): INFO Train: [110/300][20/78]	eta 0:02:23 lr 4.493703	time 1.4649 (2.4751)	loss 3.3714 (3.3934)	grad_norm 0.3262 (0.3626)	mem 39782MB
[2023-07-07 11:24:58 RepVGG-A0] (main.py 282): INFO Train: [110/300][30/78]	eta 0:01:42 lr 4.489772	time 1.1770 (2.1430)	loss 3.3345 (3.3880)	grad_norm 0.3733 (0.3650)	mem 39782MB
[2023-07-07 11:25:16 RepVGG-A0] (main.py 282): INFO Train: [110/300][40/78]	eta 0:01:18 lr 4.485839	time 2.9234 (2.0718)	loss 3.3193 (3.3824)	grad_norm 0.3394 (0.3637)	mem 39782MB
[2023-07-07 11:25:30 RepVGG-A0] (main.py 282): INFO Train: [110/300][50/78]	eta 0:00:54 lr 4.481904	time 1.1903 (1.9335)	loss 3.3422 (3.3744)	grad_norm 0.3152 (0.3632)	mem 39782MB
[2023-07-07 11:25:45 RepVGG-A0] (main.py 282): INFO Train: [110/300][60/78]	eta 0:00:33 lr 4.477967	time 1.1694 (1.8569)	loss 3.4132 (3.3746)	grad_norm 0.4600 (0.3634)	mem 39782MB
[2023-07-07 11:26:01 RepVGG-A0] (main.py 282): INFO Train: [110/300][70/78]	eta 0:00:14 lr 4.474027	time 1.7274 (1.8170)	loss 5.6913 (3.5689)	grad_norm 0.7272 (0.4327)	mem 39782MB
[2023-07-07 11:26:11 RepVGG-A0] (main.py 291): INFO EPOCH 110 training takes 0:02:19
[2023-07-07 11:26:32 RepVGG-A0] (main.py 282): INFO Train: [111/300][0/78]	eta 0:28:07 lr 4.470873	time 21.6359 (21.6359)	loss 4.4565 (4.4565)	grad_norm 0.3477 (0.3477)	mem 39782MB
[2023-07-07 11:26:47 RepVGG-A0] (main.py 282): INFO Train: [111/300][10/78]	eta 0:03:41 lr 4.466929	time 1.1719 (3.2577)	loss 3.9831 (4.2488)	grad_norm 0.2552 (0.3349)	mem 39782MB
[2023-07-07 11:27:01 RepVGG-A0] (main.py 282): INFO Train: [111/300][20/78]	eta 0:02:18 lr 4.462983	time 1.1725 (2.3923)	loss 3.7613 (4.0639)	grad_norm 0.3483 (0.3131)	mem 39782MB
[2023-07-07 11:27:17 RepVGG-A0] (main.py 282): INFO Train: [111/300][30/78]	eta 0:01:42 lr 4.459034	time 1.1612 (2.1357)	loss 3.7002 (3.9489)	grad_norm 0.3363 (0.3081)	mem 39782MB
[2023-07-07 11:27:35 RepVGG-A0] (main.py 282): INFO Train: [111/300][40/78]	eta 0:01:17 lr 4.455084	time 4.4392 (2.0465)	loss 3.5364 (3.8642)	grad_norm 0.2866 (0.3069)	mem 39782MB
[2023-07-07 11:27:49 RepVGG-A0] (main.py 282): INFO Train: [111/300][50/78]	eta 0:00:54 lr 4.451130	time 1.2993 (1.9375)	loss 3.6883 (3.8006)	grad_norm 0.4533 (0.3089)	mem 39782MB
[2023-07-07 11:28:05 RepVGG-A0] (main.py 282): INFO Train: [111/300][60/78]	eta 0:00:33 lr 4.447175	time 1.2682 (1.8696)	loss 3.4144 (3.7518)	grad_norm 0.2819 (0.3109)	mem 39782MB
[2023-07-07 11:28:20 RepVGG-A0] (main.py 282): INFO Train: [111/300][70/78]	eta 0:00:14 lr 4.443218	time 1.3228 (1.8169)	loss 3.4606 (3.7116)	grad_norm 0.3564 (0.3111)	mem 39782MB
[2023-07-07 11:28:31 RepVGG-A0] (main.py 291): INFO EPOCH 111 training takes 0:02:20
[2023-07-07 11:28:52 RepVGG-A0] (main.py 282): INFO Train: [112/300][0/78]	eta 0:26:40 lr 4.440050	time 20.5223 (20.5223)	loss 3.3302 (3.3302)	grad_norm 0.2872 (0.2872)	mem 39782MB
[2023-07-07 11:29:08 RepVGG-A0] (main.py 282): INFO Train: [112/300][10/78]	eta 0:03:44 lr 4.436088	time 1.1734 (3.3037)	loss 3.2700 (3.3688)	grad_norm 0.2874 (0.3194)	mem 39782MB
[2023-07-07 11:29:23 RepVGG-A0] (main.py 282): INFO Train: [112/300][20/78]	eta 0:02:22 lr 4.432124	time 1.2096 (2.4649)	loss 3.5721 (3.4337)	grad_norm 0.4420 (0.3740)	mem 39782MB
[2023-07-07 11:29:39 RepVGG-A0] (main.py 282): INFO Train: [112/300][30/78]	eta 0:01:45 lr 4.428158	time 2.1417 (2.1943)	loss 3.4169 (3.4257)	grad_norm 0.3504 (0.3588)	mem 39782MB
[2023-07-07 11:29:57 RepVGG-A0] (main.py 282): INFO Train: [112/300][40/78]	eta 0:01:19 lr 4.424190	time 4.6900 (2.0804)	loss 3.4092 (3.4140)	grad_norm 0.3638 (0.3531)	mem 39782MB
[2023-07-07 11:30:11 RepVGG-A0] (main.py 282): INFO Train: [112/300][50/78]	eta 0:00:54 lr 4.420220	time 1.1737 (1.9442)	loss 3.2267 (3.4072)	grad_norm 0.3132 (0.3519)	mem 39782MB
[2023-07-07 11:30:26 RepVGG-A0] (main.py 282): INFO Train: [112/300][60/78]	eta 0:00:33 lr 4.416247	time 1.3856 (1.8772)	loss 3.4864 (3.4089)	grad_norm 0.4104 (0.3566)	mem 39782MB
[2023-07-07 11:30:41 RepVGG-A0] (main.py 282): INFO Train: [112/300][70/78]	eta 0:00:14 lr 4.412272	time 1.3442 (1.8291)	loss 3.2833 (3.4011)	grad_norm 0.3236 (0.3543)	mem 39782MB
[2023-07-07 11:30:53 RepVGG-A0] (main.py 291): INFO EPOCH 112 training takes 0:02:21
[2023-07-07 11:31:15 RepVGG-A0] (main.py 282): INFO Train: [113/300][0/78]	eta 0:29:16 lr 4.409091	time 22.5238 (22.5238)	loss 3.3292 (3.3292)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:31:29 RepVGG-A0] (main.py 282): INFO Train: [113/300][10/78]	eta 0:03:45 lr 4.405112	time 1.1729 (3.3142)	loss 3.4416 (3.3317)	grad_norm 0.4377 (0.3845)	mem 39782MB
[2023-07-07 11:31:44 RepVGG-A0] (main.py 282): INFO Train: [113/300][20/78]	eta 0:02:20 lr 4.401131	time 1.1744 (2.4285)	loss 3.3226 (3.3373)	grad_norm 0.3471 (0.3794)	mem 39782MB
[2023-07-07 11:31:58 RepVGG-A0] (main.py 282): INFO Train: [113/300][30/78]	eta 0:01:41 lr 4.397148	time 1.3079 (2.1141)	loss 3.2959 (3.3282)	grad_norm 0.3474 (0.3720)	mem 39782MB
[2023-07-07 11:32:17 RepVGG-A0] (main.py 282): INFO Train: [113/300][40/78]	eta 0:01:17 lr 4.393162	time 3.3908 (2.0433)	loss 3.3532 (3.3292)	grad_norm 0.3684 (0.3746)	mem 39782MB
[2023-07-07 11:32:32 RepVGG-A0] (main.py 282): INFO Train: [113/300][50/78]	eta 0:00:54 lr 4.389175	time 1.1773 (1.9400)	loss 3.3572 (3.3256)	grad_norm 0.3695 (0.3714)	mem 39782MB
[2023-07-07 11:32:47 RepVGG-A0] (main.py 282): INFO Train: [113/300][60/78]	eta 0:00:33 lr 4.385185	time 1.4485 (1.8696)	loss 3.3409 (3.3257)	grad_norm 0.4120 (0.3745)	mem 39782MB
[2023-07-07 11:33:02 RepVGG-A0] (main.py 282): INFO Train: [113/300][70/78]	eta 0:00:14 lr 4.381193	time 1.4368 (1.8188)	loss 3.3167 (3.3290)	grad_norm 0.3438 (0.3746)	mem 39782MB
[2023-07-07 11:33:13 RepVGG-A0] (main.py 291): INFO EPOCH 113 training takes 0:02:20
[2023-07-07 11:33:34 RepVGG-A0] (main.py 282): INFO Train: [114/300][0/78]	eta 0:27:36 lr 4.377999	time 21.2346 (21.2346)	loss 3.3462 (3.3462)	grad_norm 0.4531 (0.4531)	mem 39782MB
[2023-07-07 11:33:49 RepVGG-A0] (main.py 282): INFO Train: [114/300][10/78]	eta 0:03:43 lr 4.374003	time 1.1711 (3.2826)	loss 3.2747 (3.3580)	grad_norm 0.4236 (0.4216)	mem 39782MB
[2023-07-07 11:34:05 RepVGG-A0] (main.py 282): INFO Train: [114/300][20/78]	eta 0:02:23 lr 4.370005	time 1.3648 (2.4689)	loss 3.1729 (3.3261)	grad_norm 0.3482 (0.3937)	mem 39782MB
[2023-07-07 11:34:20 RepVGG-A0] (main.py 282): INFO Train: [114/300][30/78]	eta 0:01:42 lr 4.366006	time 1.4266 (2.1401)	loss 3.1904 (3.2960)	grad_norm 0.3508 (0.3768)	mem 39782MB
[2023-07-07 11:34:37 RepVGG-A0] (main.py 282): INFO Train: [114/300][40/78]	eta 0:01:17 lr 4.362004	time 3.0136 (2.0376)	loss 3.4436 (3.2982)	grad_norm 0.5292 (0.3844)	mem 39782MB
[2023-07-07 11:34:52 RepVGG-A0] (main.py 282): INFO Train: [114/300][50/78]	eta 0:00:53 lr 4.358000	time 1.1714 (1.9284)	loss 5.7505 (3.7127)	grad_norm 0.5064 (0.4853)	mem 39782MB
[2023-07-07 11:35:07 RepVGG-A0] (main.py 282): INFO Train: [114/300][60/78]	eta 0:00:33 lr 4.353994	time 1.1874 (1.8652)	loss 4.5393 (3.9189)	grad_norm 0.3221 (0.4664)	mem 39782MB
[2023-07-07 11:35:22 RepVGG-A0] (main.py 282): INFO Train: [114/300][70/78]	eta 0:00:14 lr 4.349985	time 1.2965 (1.8087)	loss 4.0867 (3.9732)	grad_norm 0.2630 (0.4472)	mem 39782MB
[2023-07-07 11:35:33 RepVGG-A0] (main.py 291): INFO EPOCH 114 training takes 0:02:20
[2023-07-07 11:35:55 RepVGG-A0] (main.py 282): INFO Train: [115/300][0/78]	eta 0:28:16 lr 4.346777	time 21.7470 (21.7470)	loss 3.8767 (3.8767)	grad_norm 0.3248 (0.3248)	mem 39782MB
[2023-07-07 11:36:11 RepVGG-A0] (main.py 282): INFO Train: [115/300][10/78]	eta 0:03:53 lr 4.342766	time 1.1727 (3.4271)	loss 3.6313 (3.7756)	grad_norm 0.3051 (0.3070)	mem 39782MB
[2023-07-07 11:36:25 RepVGG-A0] (main.py 282): INFO Train: [115/300][20/78]	eta 0:02:23 lr 4.338752	time 1.1862 (2.4710)	loss 3.6320 (3.7265)	grad_norm 0.2789 (0.3140)	mem 39782MB
[2023-07-07 11:36:43 RepVGG-A0] (main.py 282): INFO Train: [115/300][30/78]	eta 0:01:47 lr 4.334736	time 1.7841 (2.2362)	loss 3.5060 (3.6558)	grad_norm 0.3284 (0.3023)	mem 39782MB
[2023-07-07 11:36:58 RepVGG-A0] (main.py 282): INFO Train: [115/300][40/78]	eta 0:01:18 lr 4.330718	time 4.0576 (2.0732)	loss 3.5252 (3.6350)	grad_norm 0.3425 (0.3178)	mem 39782MB
[2023-07-07 11:37:13 RepVGG-A0] (main.py 282): INFO Train: [115/300][50/78]	eta 0:00:54 lr 4.326698	time 1.1725 (1.9565)	loss 3.4260 (3.6067)	grad_norm 0.3487 (0.3182)	mem 39782MB
[2023-07-07 11:37:28 RepVGG-A0] (main.py 282): INFO Train: [115/300][60/78]	eta 0:00:33 lr 4.322675	time 1.1812 (1.8752)	loss 3.4365 (3.5819)	grad_norm 0.3808 (0.3186)	mem 39782MB
[2023-07-07 11:37:43 RepVGG-A0] (main.py 282): INFO Train: [115/300][70/78]	eta 0:00:14 lr 4.318651	time 1.1720 (1.8289)	loss 3.5163 (3.5668)	grad_norm 0.3352 (0.3265)	mem 39782MB
[2023-07-07 11:37:55 RepVGG-A0] (main.py 291): INFO EPOCH 115 training takes 0:02:21
[2023-07-07 11:38:18 RepVGG-A0] (main.py 282): INFO Train: [116/300][0/78]	eta 0:29:24 lr 4.315431	time 22.6160 (22.6160)	loss 3.3813 (3.3813)	grad_norm 0.3650 (0.3650)	mem 39782MB
[2023-07-07 11:38:32 RepVGG-A0] (main.py 282): INFO Train: [116/300][10/78]	eta 0:03:49 lr 4.311403	time 1.1741 (3.3713)	loss 3.3191 (3.3668)	grad_norm 0.3171 (0.3505)	mem 39782MB
[2023-07-07 11:38:47 RepVGG-A0] (main.py 282): INFO Train: [116/300][20/78]	eta 0:02:23 lr 4.307373	time 1.1850 (2.4782)	loss 3.3996 (3.3723)	grad_norm 0.3678 (0.3540)	mem 39782MB
[2023-07-07 11:39:03 RepVGG-A0] (main.py 282): INFO Train: [116/300][30/78]	eta 0:01:44 lr 4.303341	time 1.4427 (2.1768)	loss 3.4577 (3.3652)	grad_norm 0.4433 (0.3512)	mem 39782MB
[2023-07-07 11:39:21 RepVGG-A0] (main.py 282): INFO Train: [116/300][40/78]	eta 0:01:19 lr 4.299308	time 4.0829 (2.0840)	loss 3.3953 (3.3811)	grad_norm 0.3991 (0.3630)	mem 39782MB
[2023-07-07 11:39:35 RepVGG-A0] (main.py 282): INFO Train: [116/300][50/78]	eta 0:00:54 lr 4.295272	time 1.1728 (1.9586)	loss 3.4533 (3.3794)	grad_norm 0.4535 (0.3668)	mem 39782MB
[2023-07-07 11:39:50 RepVGG-A0] (main.py 282): INFO Train: [116/300][60/78]	eta 0:00:34 lr 4.291234	time 1.2903 (1.8905)	loss 3.3453 (3.3751)	grad_norm 0.3718 (0.3664)	mem 39782MB
[2023-07-07 11:40:06 RepVGG-A0] (main.py 282): INFO Train: [116/300][70/78]	eta 0:00:14 lr 4.287194	time 1.5323 (1.8430)	loss 3.2597 (3.3690)	grad_norm 0.3259 (0.3620)	mem 39782MB
[2023-07-07 11:40:17 RepVGG-A0] (main.py 291): INFO EPOCH 116 training takes 0:02:22
[2023-07-07 11:40:39 RepVGG-A0] (main.py 282): INFO Train: [117/300][0/78]	eta 0:28:12 lr 4.283961	time 21.6930 (21.6930)	loss 3.3384 (3.3384)	grad_norm 0.3688 (0.3688)	mem 39782MB
[2023-07-07 11:40:53 RepVGG-A0] (main.py 282): INFO Train: [117/300][10/78]	eta 0:03:41 lr 4.279918	time 1.1713 (3.2581)	loss 3.4289 (3.3295)	grad_norm 0.5023 (0.3819)	mem 39782MB
[2023-07-07 11:41:08 RepVGG-A0] (main.py 282): INFO Train: [117/300][20/78]	eta 0:02:19 lr 4.275873	time 1.1728 (2.4032)	loss 3.8907 (3.5461)	grad_norm 0.5983 (0.4939)	mem 39782MB
[2023-07-07 11:41:23 RepVGG-A0] (main.py 282): INFO Train: [117/300][30/78]	eta 0:01:41 lr 4.271826	time 1.4134 (2.1127)	loss 3.3444 (3.5494)	grad_norm 0.2836 (0.4522)	mem 39782MB
[2023-07-07 11:41:42 RepVGG-A0] (main.py 282): INFO Train: [117/300][40/78]	eta 0:01:18 lr 4.267777	time 4.6584 (2.0681)	loss 3.2329 (3.4934)	grad_norm 0.3041 (0.4120)	mem 39782MB
[2023-07-07 11:41:56 RepVGG-A0] (main.py 282): INFO Train: [117/300][50/78]	eta 0:00:54 lr 4.263726	time 1.1766 (1.9393)	loss 3.2638 (3.4522)	grad_norm 0.3454 (0.3936)	mem 39782MB
[2023-07-07 11:42:12 RepVGG-A0] (main.py 282): INFO Train: [117/300][60/78]	eta 0:00:33 lr 4.259673	time 1.2692 (1.8801)	loss 3.2424 (3.4206)	grad_norm 0.3274 (0.3820)	mem 39782MB
[2023-07-07 11:42:27 RepVGG-A0] (main.py 282): INFO Train: [117/300][70/78]	eta 0:00:14 lr 4.255618	time 1.2856 (1.8242)	loss 3.2372 (3.3992)	grad_norm 0.3250 (0.3736)	mem 39782MB
[2023-07-07 11:42:38 RepVGG-A0] (main.py 291): INFO EPOCH 117 training takes 0:02:21
[2023-07-07 11:43:00 RepVGG-A0] (main.py 282): INFO Train: [118/300][0/78]	eta 0:28:07 lr 4.252373	time 21.6312 (21.6312)	loss 3.3546 (3.3546)	grad_norm 0.4037 (0.4037)	mem 39782MB
[2023-07-07 11:43:14 RepVGG-A0] (main.py 282): INFO Train: [118/300][10/78]	eta 0:03:39 lr 4.248315	time 1.1737 (3.2348)	loss 3.2293 (3.2847)	grad_norm 0.3842 (0.3773)	mem 39782MB
[2023-07-07 11:43:29 RepVGG-A0] (main.py 282): INFO Train: [118/300][20/78]	eta 0:02:20 lr 4.244255	time 1.1734 (2.4242)	loss 3.3106 (3.2888)	grad_norm 0.4043 (0.3773)	mem 39782MB
[2023-07-07 11:43:44 RepVGG-A0] (main.py 282): INFO Train: [118/300][30/78]	eta 0:01:42 lr 4.240193	time 1.3901 (2.1275)	loss 3.2130 (3.2800)	grad_norm 0.3339 (0.3742)	mem 39782MB
[2023-07-07 11:44:02 RepVGG-A0] (main.py 282): INFO Train: [118/300][40/78]	eta 0:01:17 lr 4.236129	time 3.8869 (2.0396)	loss 3.3557 (3.2880)	grad_norm 0.4177 (0.3778)	mem 39782MB
[2023-07-07 11:44:17 RepVGG-A0] (main.py 282): INFO Train: [118/300][50/78]	eta 0:00:54 lr 4.232064	time 1.1710 (1.9406)	loss 3.3423 (3.2897)	grad_norm 0.4319 (0.3776)	mem 39782MB
[2023-07-07 11:44:32 RepVGG-A0] (main.py 282): INFO Train: [118/300][60/78]	eta 0:00:33 lr 4.227996	time 1.1309 (1.8702)	loss 3.3018 (3.2955)	grad_norm 0.3622 (0.3796)	mem 39782MB
[2023-07-07 11:44:48 RepVGG-A0] (main.py 282): INFO Train: [118/300][70/78]	eta 0:00:14 lr 4.223927	time 1.1705 (1.8204)	loss 3.1753 (3.2878)	grad_norm 0.3388 (0.3744)	mem 39782MB
[2023-07-07 11:45:00 RepVGG-A0] (main.py 291): INFO EPOCH 118 training takes 0:02:21
[2023-07-07 11:45:21 RepVGG-A0] (main.py 282): INFO Train: [119/300][0/78]	eta 0:27:44 lr 4.220670	time 21.3413 (21.3413)	loss 3.2922 (3.2922)	grad_norm 0.4124 (0.4124)	mem 39782MB
[2023-07-07 11:45:36 RepVGG-A0] (main.py 282): INFO Train: [119/300][10/78]	eta 0:03:45 lr 4.216597	time 1.1965 (3.3204)	loss 3.2864 (3.2992)	grad_norm 0.4046 (0.4327)	mem 39782MB
[2023-07-07 11:45:52 RepVGG-A0] (main.py 282): INFO Train: [119/300][20/78]	eta 0:02:24 lr 4.212523	time 1.3539 (2.4914)	loss 3.2287 (3.2755)	grad_norm 0.3663 (0.3993)	mem 39782MB
[2023-07-07 11:46:07 RepVGG-A0] (main.py 282): INFO Train: [119/300][30/78]	eta 0:01:43 lr 4.208446	time 1.5529 (2.1603)	loss 3.2549 (3.2613)	grad_norm 0.3449 (0.3821)	mem 39782MB
[2023-07-07 11:46:25 RepVGG-A0] (main.py 282): INFO Train: [119/300][40/78]	eta 0:01:19 lr 4.204368	time 3.9189 (2.0833)	loss 3.9121 (3.3100)	grad_norm 0.7106 (0.4147)	mem 39782MB
[2023-07-07 11:46:40 RepVGG-A0] (main.py 282): INFO Train: [119/300][50/78]	eta 0:00:55 lr 4.200288	time 1.1776 (1.9674)	loss 4.5169 (3.5585)	grad_norm 0.5672 (0.4931)	mem 39782MB
[2023-07-07 11:46:55 RepVGG-A0] (main.py 282): INFO Train: [119/300][60/78]	eta 0:00:33 lr 4.196206	time 1.1809 (1.8832)	loss 3.6593 (3.6149)	grad_norm 0.2740 (0.4655)	mem 39782MB
[2023-07-07 11:47:10 RepVGG-A0] (main.py 282): INFO Train: [119/300][70/78]	eta 0:00:14 lr 4.192123	time 1.3233 (1.8334)	loss 3.5328 (3.6126)	grad_norm 0.2807 (0.4434)	mem 39782MB
[2023-07-07 11:47:23 RepVGG-A0] (main.py 291): INFO EPOCH 119 training takes 0:02:22
[2023-07-07 11:47:44 RepVGG-A0] (main.py 282): INFO Train: [120/300][0/78]	eta 0:27:32 lr 4.188854	time 21.1908 (21.1908)	loss 3.3190 (3.3190)	grad_norm 0.2635 (0.2635)	mem 39782MB
[2023-07-07 11:48:00 RepVGG-A0] (main.py 282): INFO Train: [120/300][10/78]	eta 0:03:48 lr 4.184768	time 1.1879 (3.3565)	loss 3.2391 (3.2928)	grad_norm 0.2956 (0.2783)	mem 39782MB
[2023-07-07 11:48:14 RepVGG-A0] (main.py 282): INFO Train: [120/300][20/78]	eta 0:02:20 lr 4.180679	time 1.1986 (2.4229)	loss 3.3132 (3.2898)	grad_norm 0.3431 (0.2922)	mem 39782MB
[2023-07-07 11:48:29 RepVGG-A0] (main.py 282): INFO Train: [120/300][30/78]	eta 0:01:42 lr 4.176589	time 1.5626 (2.1342)	loss 3.2168 (3.2750)	grad_norm 0.2969 (0.2938)	mem 39782MB
[2023-07-07 11:48:46 RepVGG-A0] (main.py 282): INFO Train: [120/300][40/78]	eta 0:01:17 lr 4.172497	time 4.1553 (2.0386)	loss 3.2666 (3.2732)	grad_norm 0.3494 (0.3035)	mem 39782MB
[2023-07-07 11:49:02 RepVGG-A0] (main.py 282): INFO Train: [120/300][50/78]	eta 0:00:54 lr 4.168403	time 1.1892 (1.9400)	loss 3.2737 (3.2695)	grad_norm 0.3221 (0.3095)	mem 39782MB
[2023-07-07 11:49:16 RepVGG-A0] (main.py 282): INFO Train: [120/300][60/78]	eta 0:00:33 lr 4.164307	time 1.1309 (1.8639)	loss 3.1442 (3.2635)	grad_norm 0.3574 (0.3145)	mem 39782MB
[2023-07-07 11:49:31 RepVGG-A0] (main.py 282): INFO Train: [120/300][70/78]	eta 0:00:14 lr 4.160210	time 1.5754 (1.8108)	loss 3.2011 (3.2653)	grad_norm 0.3350 (0.3239)	mem 39782MB
[2023-07-07 11:49:43 RepVGG-A0] (main.py 291): INFO EPOCH 120 training takes 0:02:19
[2023-07-07 11:50:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.849 (17.849)	Loss 2.7981 (2.7981)	Acc@1 41.357 (41.357)	Acc@5 67.542 (67.542)	Mem 39782MB
[2023-07-07 11:50:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 41.654 Acc@5 67.390
[2023-07-07 11:50:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 120: 41.654%
[2023-07-07 11:50:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 11:50:24 RepVGG-A0] (main.py 282): INFO Train: [121/300][0/78]	eta 0:28:48 lr 4.156931	time 22.1665 (22.1665)	loss 3.1640 (3.1640)	grad_norm 0.3948 (0.3948)	mem 39782MB
[2023-07-07 11:50:39 RepVGG-A0] (main.py 282): INFO Train: [121/300][10/78]	eta 0:03:49 lr 4.152830	time 1.1730 (3.3793)	loss 3.1814 (3.2109)	grad_norm 0.3425 (0.3579)	mem 39782MB
[2023-07-07 11:50:54 RepVGG-A0] (main.py 282): INFO Train: [121/300][20/78]	eta 0:02:25 lr 4.148728	time 1.1795 (2.5051)	loss 3.2442 (3.2315)	grad_norm 0.4370 (0.3791)	mem 39782MB
[2023-07-07 11:51:10 RepVGG-A0] (main.py 282): INFO Train: [121/300][30/78]	eta 0:01:45 lr 4.144624	time 1.3733 (2.1928)	loss 3.2544 (3.2248)	grad_norm 0.3754 (0.3653)	mem 39782MB
[2023-07-07 11:51:28 RepVGG-A0] (main.py 282): INFO Train: [121/300][40/78]	eta 0:01:19 lr 4.140518	time 2.7940 (2.1033)	loss 3.2073 (3.2270)	grad_norm 0.3326 (0.3670)	mem 39782MB
[2023-07-07 11:51:43 RepVGG-A0] (main.py 282): INFO Train: [121/300][50/78]	eta 0:00:55 lr 4.136411	time 1.2893 (1.9879)	loss 3.2801 (3.2243)	grad_norm 0.3987 (0.3655)	mem 39782MB
[2023-07-07 11:51:58 RepVGG-A0] (main.py 282): INFO Train: [121/300][60/78]	eta 0:00:34 lr 4.132302	time 1.1734 (1.9019)	loss 3.2300 (3.2327)	grad_norm 0.3280 (0.3717)	mem 39782MB
[2023-07-07 11:52:12 RepVGG-A0] (main.py 282): INFO Train: [121/300][70/78]	eta 0:00:14 lr 4.128191	time 1.1722 (1.8311)	loss 3.3038 (3.2296)	grad_norm 0.4218 (0.3689)	mem 39782MB
[2023-07-07 11:52:23 RepVGG-A0] (main.py 291): INFO EPOCH 121 training takes 0:02:21
[2023-07-07 11:52:43 RepVGG-A0] (main.py 282): INFO Train: [122/300][0/78]	eta 0:26:36 lr 4.124902	time 20.4623 (20.4623)	loss 3.1722 (3.1722)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 11:52:59 RepVGG-A0] (main.py 282): INFO Train: [122/300][10/78]	eta 0:03:40 lr 4.120788	time 1.1681 (3.2416)	loss 3.2369 (3.2413)	grad_norm 0.3633 (0.4267)	mem 39782MB
[2023-07-07 11:53:15 RepVGG-A0] (main.py 282): INFO Train: [122/300][20/78]	eta 0:02:22 lr 4.116673	time 1.1807 (2.4537)	loss 3.2558 (3.2150)	grad_norm 0.3262 (0.3902)	mem 39782MB
[2023-07-07 11:53:29 RepVGG-A0] (main.py 282): INFO Train: [122/300][30/78]	eta 0:01:42 lr 4.112556	time 1.2290 (2.1330)	loss 3.2584 (3.2036)	grad_norm 0.4414 (0.3851)	mem 39782MB
[2023-07-07 11:53:49 RepVGG-A0] (main.py 282): INFO Train: [122/300][40/78]	eta 0:01:19 lr 4.108437	time 5.4850 (2.0886)	loss 3.1658 (3.2060)	grad_norm 0.3652 (0.3833)	mem 39782MB
[2023-07-07 11:54:03 RepVGG-A0] (main.py 282): INFO Train: [122/300][50/78]	eta 0:00:55 lr 4.104317	time 1.1755 (1.9692)	loss 3.3056 (3.2047)	grad_norm 0.4328 (0.3792)	mem 39782MB
[2023-07-07 11:54:19 RepVGG-A0] (main.py 282): INFO Train: [122/300][60/78]	eta 0:00:34 lr 4.100195	time 1.2578 (1.9088)	loss 3.2508 (3.2101)	grad_norm 0.3409 (0.3807)	mem 39782MB
[2023-07-07 11:54:34 RepVGG-A0] (main.py 282): INFO Train: [122/300][70/78]	eta 0:00:14 lr 4.096072	time 1.2104 (1.8520)	loss 3.3706 (3.2136)	grad_norm 0.4102 (0.3791)	mem 39782MB
[2023-07-07 11:54:45 RepVGG-A0] (main.py 291): INFO EPOCH 122 training takes 0:02:21
[2023-07-07 11:55:06 RepVGG-A0] (main.py 282): INFO Train: [123/300][0/78]	eta 0:27:59 lr 4.092772	time 21.5339 (21.5339)	loss 3.3069 (3.3069)	grad_norm 0.4251 (0.4251)	mem 39782MB
[2023-07-07 11:55:21 RepVGG-A0] (main.py 282): INFO Train: [123/300][10/78]	eta 0:03:44 lr 4.088645	time 1.1929 (3.2949)	loss 3.1233 (3.2516)	grad_norm 0.3225 (0.4078)	mem 39782MB
[2023-07-07 11:55:36 RepVGG-A0] (main.py 282): INFO Train: [123/300][20/78]	eta 0:02:21 lr 4.084517	time 1.1731 (2.4404)	loss 3.2000 (3.2119)	grad_norm 0.3635 (0.3850)	mem 39782MB
[2023-07-07 11:55:51 RepVGG-A0] (main.py 282): INFO Train: [123/300][30/78]	eta 0:01:42 lr 4.080388	time 1.4649 (2.1252)	loss 3.7202 (3.2288)	grad_norm 0.7181 (0.4055)	mem 39782MB
[2023-07-07 11:56:09 RepVGG-A0] (main.py 282): INFO Train: [123/300][40/78]	eta 0:01:17 lr 4.076256	time 4.0422 (2.0454)	loss 5.6348 (3.8085)	grad_norm 0.5610 (0.5285)	mem 39782MB
[2023-07-07 11:56:24 RepVGG-A0] (main.py 282): INFO Train: [123/300][50/78]	eta 0:00:54 lr 4.072124	time 1.1723 (1.9330)	loss 4.5326 (4.0037)	grad_norm 0.3829 (0.4949)	mem 39782MB
[2023-07-07 11:56:38 RepVGG-A0] (main.py 282): INFO Train: [123/300][60/78]	eta 0:00:33 lr 4.067989	time 1.1779 (1.8511)	loss 3.9338 (4.0382)	grad_norm 0.2804 (0.4687)	mem 39782MB
[2023-07-07 11:56:53 RepVGG-A0] (main.py 282): INFO Train: [123/300][70/78]	eta 0:00:14 lr 4.063853	time 1.4072 (1.8012)	loss 3.7386 (4.0138)	grad_norm 0.2780 (0.4430)	mem 39782MB
[2023-07-07 11:57:05 RepVGG-A0] (main.py 291): INFO EPOCH 123 training takes 0:02:19
[2023-07-07 11:57:26 RepVGG-A0] (main.py 282): INFO Train: [124/300][0/78]	eta 0:27:21 lr 4.060543	time 21.0410 (21.0410)	loss 3.7206 (3.7206)	grad_norm 0.3113 (0.3113)	mem 39782MB
[2023-07-07 11:57:40 RepVGG-A0] (main.py 282): INFO Train: [124/300][10/78]	eta 0:03:38 lr 4.056405	time 1.1701 (3.2143)	loss 3.4981 (3.6094)	grad_norm 0.2768 (0.3000)	mem 39782MB
[2023-07-07 11:57:55 RepVGG-A0] (main.py 282): INFO Train: [124/300][20/78]	eta 0:02:18 lr 4.052264	time 1.1717 (2.3962)	loss 3.4311 (3.5601)	grad_norm 0.3314 (0.3120)	mem 39782MB
[2023-07-07 11:58:11 RepVGG-A0] (main.py 282): INFO Train: [124/300][30/78]	eta 0:01:43 lr 4.048123	time 1.2752 (2.1503)	loss 3.4056 (3.5256)	grad_norm 0.3085 (0.3089)	mem 39782MB
[2023-07-07 11:58:29 RepVGG-A0] (main.py 282): INFO Train: [124/300][40/78]	eta 0:01:18 lr 4.043979	time 2.6759 (2.0582)	loss 3.4320 (3.5173)	grad_norm 0.3648 (0.3243)	mem 39782MB
[2023-07-07 11:58:45 RepVGG-A0] (main.py 282): INFO Train: [124/300][50/78]	eta 0:00:54 lr 4.039835	time 1.1774 (1.9613)	loss 3.3625 (3.4920)	grad_norm 0.3472 (0.3260)	mem 39782MB
[2023-07-07 11:58:59 RepVGG-A0] (main.py 282): INFO Train: [124/300][60/78]	eta 0:00:33 lr 4.035688	time 1.4493 (1.8800)	loss 3.4484 (3.4823)	grad_norm 0.3672 (0.3340)	mem 39782MB
[2023-07-07 11:59:15 RepVGG-A0] (main.py 282): INFO Train: [124/300][70/78]	eta 0:00:14 lr 4.031540	time 1.1928 (1.8308)	loss 3.3731 (3.4660)	grad_norm 0.3971 (0.3335)	mem 39782MB
[2023-07-07 11:59:26 RepVGG-A0] (main.py 291): INFO EPOCH 124 training takes 0:02:21
[2023-07-07 11:59:46 RepVGG-A0] (main.py 282): INFO Train: [125/300][0/78]	eta 0:26:28 lr 4.028221	time 20.3712 (20.3712)	loss 3.4592 (3.4592)	grad_norm 0.4339 (0.4339)	mem 39782MB
[2023-07-07 12:00:00 RepVGG-A0] (main.py 282): INFO Train: [125/300][10/78]	eta 0:03:33 lr 4.024070	time 1.1712 (3.1425)	loss 3.3368 (3.3308)	grad_norm 0.4142 (0.3486)	mem 39782MB
[2023-07-07 12:00:15 RepVGG-A0] (main.py 282): INFO Train: [125/300][20/78]	eta 0:02:15 lr 4.019918	time 1.1720 (2.3440)	loss 3.4038 (3.3452)	grad_norm 0.3500 (0.3644)	mem 39782MB
[2023-07-07 12:00:30 RepVGG-A0] (main.py 282): INFO Train: [125/300][30/78]	eta 0:01:39 lr 4.015765	time 1.3337 (2.0830)	loss 3.3047 (3.3229)	grad_norm 0.3681 (0.3536)	mem 39782MB
[2023-07-07 12:00:49 RepVGG-A0] (main.py 282): INFO Train: [125/300][40/78]	eta 0:01:16 lr 4.011610	time 4.1768 (2.0199)	loss 3.2655 (3.3292)	grad_norm 0.3332 (0.3625)	mem 39782MB
[2023-07-07 12:01:03 RepVGG-A0] (main.py 282): INFO Train: [125/300][50/78]	eta 0:00:53 lr 4.007453	time 1.1746 (1.9169)	loss 3.3272 (3.3226)	grad_norm 0.3658 (0.3631)	mem 39782MB
[2023-07-07 12:01:18 RepVGG-A0] (main.py 282): INFO Train: [125/300][60/78]	eta 0:00:33 lr 4.003296	time 1.1750 (1.8433)	loss 3.3272 (3.3184)	grad_norm 0.4948 (0.3656)	mem 39782MB
[2023-07-07 12:01:34 RepVGG-A0] (main.py 282): INFO Train: [125/300][70/78]	eta 0:00:14 lr 3.999136	time 1.1296 (1.8047)	loss 3.2554 (3.3218)	grad_norm 0.3758 (0.3696)	mem 39782MB
[2023-07-07 12:01:46 RepVGG-A0] (main.py 291): INFO EPOCH 125 training takes 0:02:19
[2023-07-07 12:02:09 RepVGG-A0] (main.py 282): INFO Train: [126/300][0/78]	eta 0:29:48 lr 3.995808	time 22.9306 (22.9306)	loss 3.2056 (3.2056)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 12:02:23 RepVGG-A0] (main.py 282): INFO Train: [126/300][10/78]	eta 0:03:47 lr 3.991646	time 1.1726 (3.3517)	loss 3.2693 (3.2293)	grad_norm 0.4313 (0.3699)	mem 39782MB
[2023-07-07 12:02:36 RepVGG-A0] (main.py 282): INFO Train: [126/300][20/78]	eta 0:02:19 lr 3.987482	time 1.2349 (2.4093)	loss 4.1885 (3.4812)	grad_norm 0.7351 (0.5165)	mem 39782MB
[2023-07-07 12:02:51 RepVGG-A0] (main.py 282): INFO Train: [126/300][30/78]	eta 0:01:40 lr 3.983318	time 1.1748 (2.0981)	loss 3.5437 (3.5898)	grad_norm 0.2850 (0.4961)	mem 39782MB
[2023-07-07 12:03:10 RepVGG-A0] (main.py 282): INFO Train: [126/300][40/78]	eta 0:01:17 lr 3.979151	time 4.5601 (2.0493)	loss 3.3748 (3.5454)	grad_norm 0.2782 (0.4436)	mem 39782MB
[2023-07-07 12:03:24 RepVGG-A0] (main.py 282): INFO Train: [126/300][50/78]	eta 0:00:54 lr 3.974984	time 1.1717 (1.9331)	loss 3.3134 (3.5004)	grad_norm 0.3118 (0.4131)	mem 39782MB
[2023-07-07 12:03:40 RepVGG-A0] (main.py 282): INFO Train: [126/300][60/78]	eta 0:00:33 lr 3.970815	time 1.1403 (1.8723)	loss 3.1719 (3.4573)	grad_norm 0.2914 (0.3957)	mem 39782MB
[2023-07-07 12:03:55 RepVGG-A0] (main.py 282): INFO Train: [126/300][70/78]	eta 0:00:14 lr 3.966644	time 1.3347 (1.8236)	loss 3.2165 (3.4242)	grad_norm 0.3286 (0.3824)	mem 39782MB
[2023-07-07 12:04:07 RepVGG-A0] (main.py 291): INFO EPOCH 126 training takes 0:02:21
[2023-07-07 12:04:28 RepVGG-A0] (main.py 282): INFO Train: [127/300][0/78]	eta 0:26:38 lr 3.963307	time 20.4881 (20.4881)	loss 3.1713 (3.1713)	grad_norm 0.3726 (0.3726)	mem 39782MB
[2023-07-07 12:04:42 RepVGG-A0] (main.py 282): INFO Train: [127/300][10/78]	eta 0:03:37 lr 3.959134	time 1.3352 (3.1975)	loss 3.0544 (3.1726)	grad_norm 0.2905 (0.3446)	mem 39782MB
[2023-07-07 12:04:59 RepVGG-A0] (main.py 282): INFO Train: [127/300][20/78]	eta 0:02:24 lr 3.954960	time 1.4450 (2.4921)	loss 3.2982 (3.2054)	grad_norm 0.4340 (0.3657)	mem 39782MB
[2023-07-07 12:05:15 RepVGG-A0] (main.py 282): INFO Train: [127/300][30/78]	eta 0:01:44 lr 3.950784	time 1.2705 (2.1819)	loss 3.1961 (3.2129)	grad_norm 0.3447 (0.3619)	mem 39782MB
[2023-07-07 12:05:32 RepVGG-A0] (main.py 282): INFO Train: [127/300][40/78]	eta 0:01:18 lr 3.946607	time 1.6185 (2.0653)	loss 3.1733 (3.2037)	grad_norm 0.3421 (0.3549)	mem 39782MB
[2023-07-07 12:05:46 RepVGG-A0] (main.py 282): INFO Train: [127/300][50/78]	eta 0:00:54 lr 3.942429	time 1.1914 (1.9306)	loss 3.2042 (3.2057)	grad_norm 0.3641 (0.3589)	mem 39782MB
[2023-07-07 12:06:01 RepVGG-A0] (main.py 282): INFO Train: [127/300][60/78]	eta 0:00:33 lr 3.938249	time 1.1754 (1.8650)	loss 3.2327 (3.2088)	grad_norm 0.3602 (0.3625)	mem 39782MB
[2023-07-07 12:06:16 RepVGG-A0] (main.py 282): INFO Train: [127/300][70/78]	eta 0:00:14 lr 3.934069	time 1.5596 (1.8157)	loss 3.1589 (3.2088)	grad_norm 0.3669 (0.3619)	mem 39782MB
[2023-07-07 12:06:27 RepVGG-A0] (main.py 291): INFO EPOCH 127 training takes 0:02:19
[2023-07-07 12:06:47 RepVGG-A0] (main.py 282): INFO Train: [128/300][0/78]	eta 0:26:38 lr 3.930723	time 20.4891 (20.4891)	loss 3.2741 (3.2741)	grad_norm 0.4096 (0.4096)	mem 39782MB
[2023-07-07 12:07:02 RepVGG-A0] (main.py 282): INFO Train: [128/300][10/78]	eta 0:03:37 lr 3.926539	time 1.1707 (3.2002)	loss 3.3603 (3.1962)	grad_norm 0.5200 (0.3976)	mem 39782MB
[2023-07-07 12:07:17 RepVGG-A0] (main.py 282): INFO Train: [128/300][20/78]	eta 0:02:18 lr 3.922355	time 1.1736 (2.3812)	loss 3.2413 (3.2432)	grad_norm 0.3907 (0.4163)	mem 39782MB
[2023-07-07 12:07:32 RepVGG-A0] (main.py 282): INFO Train: [128/300][30/78]	eta 0:01:41 lr 3.918169	time 1.4326 (2.1079)	loss 3.2288 (3.2261)	grad_norm 0.3474 (0.3936)	mem 39782MB
[2023-07-07 12:07:49 RepVGG-A0] (main.py 282): INFO Train: [128/300][40/78]	eta 0:01:16 lr 3.913982	time 1.9665 (2.0100)	loss 3.1733 (3.2137)	grad_norm 0.3579 (0.3849)	mem 39782MB
[2023-07-07 12:08:04 RepVGG-A0] (main.py 282): INFO Train: [128/300][50/78]	eta 0:00:53 lr 3.909793	time 1.1709 (1.9096)	loss 3.4341 (3.2447)	grad_norm 0.5066 (0.4082)	mem 39782MB
[2023-07-07 12:08:20 RepVGG-A0] (main.py 282): INFO Train: [128/300][60/78]	eta 0:00:33 lr 3.905603	time 1.3142 (1.8504)	loss 3.2979 (3.2592)	grad_norm 0.3325 (0.4079)	mem 39782MB
[2023-07-07 12:08:35 RepVGG-A0] (main.py 282): INFO Train: [128/300][70/78]	eta 0:00:14 lr 3.901412	time 1.3195 (1.7986)	loss 3.2454 (3.2503)	grad_norm 0.3498 (0.3960)	mem 39782MB
[2023-07-07 12:08:46 RepVGG-A0] (main.py 291): INFO EPOCH 128 training takes 0:02:19
[2023-07-07 12:09:07 RepVGG-A0] (main.py 282): INFO Train: [129/300][0/78]	eta 0:26:49 lr 3.898058	time 20.6333 (20.6333)	loss 3.0592 (3.0592)	grad_norm 0.3332 (0.3332)	mem 39782MB
[2023-07-07 12:09:22 RepVGG-A0] (main.py 282): INFO Train: [129/300][10/78]	eta 0:03:43 lr 3.893865	time 1.1732 (3.2927)	loss 3.1720 (3.1155)	grad_norm 0.3821 (0.3543)	mem 39782MB
[2023-07-07 12:09:37 RepVGG-A0] (main.py 282): INFO Train: [129/300][20/78]	eta 0:02:20 lr 3.889670	time 1.3167 (2.4291)	loss 3.0212 (3.1146)	grad_norm 0.3358 (0.3566)	mem 39782MB
[2023-07-07 12:09:53 RepVGG-A0] (main.py 282): INFO Train: [129/300][30/78]	eta 0:01:43 lr 3.885475	time 1.6347 (2.1587)	loss 3.1857 (3.1265)	grad_norm 0.3979 (0.3596)	mem 39782MB
[2023-07-07 12:10:11 RepVGG-A0] (main.py 282): INFO Train: [129/300][40/78]	eta 0:01:18 lr 3.881277	time 4.1504 (2.0722)	loss 3.4003 (3.1933)	grad_norm 0.4657 (0.3996)	mem 39782MB
[2023-07-07 12:10:26 RepVGG-A0] (main.py 282): INFO Train: [129/300][50/78]	eta 0:00:55 lr 3.877079	time 1.2950 (1.9653)	loss 3.1000 (3.2024)	grad_norm 0.3066 (0.3906)	mem 39782MB
[2023-07-07 12:10:41 RepVGG-A0] (main.py 282): INFO Train: [129/300][60/78]	eta 0:00:33 lr 3.872880	time 1.1821 (1.8758)	loss 3.1332 (3.1947)	grad_norm 0.3338 (0.3834)	mem 39782MB
[2023-07-07 12:10:56 RepVGG-A0] (main.py 282): INFO Train: [129/300][70/78]	eta 0:00:14 lr 3.868679	time 1.4161 (1.8244)	loss 3.2767 (3.1955)	grad_norm 0.3892 (0.3804)	mem 39782MB
[2023-07-07 12:11:07 RepVGG-A0] (main.py 291): INFO EPOCH 129 training takes 0:02:20
[2023-07-07 12:11:28 RepVGG-A0] (main.py 282): INFO Train: [130/300][0/78]	eta 0:26:57 lr 3.865317	time 20.7436 (20.7436)	loss 3.1619 (3.1619)	grad_norm 0.3896 (0.3896)	mem 39782MB
[2023-07-07 12:11:43 RepVGG-A0] (main.py 282): INFO Train: [130/300][10/78]	eta 0:03:42 lr 3.861114	time 1.1896 (3.2792)	loss 3.1673 (3.1364)	grad_norm 0.4363 (0.3777)	mem 39782MB
[2023-07-07 12:11:58 RepVGG-A0] (main.py 282): INFO Train: [130/300][20/78]	eta 0:02:21 lr 3.856910	time 1.1782 (2.4315)	loss 3.1884 (3.1564)	grad_norm 0.3774 (0.3877)	mem 39782MB
[2023-07-07 12:12:14 RepVGG-A0] (main.py 282): INFO Train: [130/300][30/78]	eta 0:01:43 lr 3.852705	time 1.3913 (2.1542)	loss 3.2043 (3.1822)	grad_norm 0.3818 (0.4039)	mem 39782MB
[2023-07-07 12:12:31 RepVGG-A0] (main.py 282): INFO Train: [130/300][40/78]	eta 0:01:18 lr 3.848499	time 3.3851 (2.0597)	loss 3.0590 (3.1682)	grad_norm 0.3226 (0.3881)	mem 39782MB
[2023-07-07 12:12:46 RepVGG-A0] (main.py 282): INFO Train: [130/300][50/78]	eta 0:00:54 lr 3.844291	time 1.1735 (1.9454)	loss 3.1072 (3.1668)	grad_norm 0.3681 (0.3855)	mem 39782MB
[2023-07-07 12:13:00 RepVGG-A0] (main.py 282): INFO Train: [130/300][60/78]	eta 0:00:33 lr 3.840082	time 1.1310 (1.8541)	loss 3.2322 (3.1682)	grad_norm 0.4122 (0.3846)	mem 39782MB
[2023-07-07 12:13:16 RepVGG-A0] (main.py 282): INFO Train: [130/300][70/78]	eta 0:00:14 lr 3.835872	time 1.2108 (1.8093)	loss 3.2364 (3.1719)	grad_norm 0.4715 (0.3867)	mem 39782MB
[2023-07-07 12:13:27 RepVGG-A0] (main.py 291): INFO EPOCH 130 training takes 0:02:20
[2023-07-07 12:13:49 RepVGG-A0] (main.py 282): INFO Train: [131/300][0/78]	eta 0:28:27 lr 3.832503	time 21.8952 (21.8952)	loss 3.2087 (3.2087)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 12:14:04 RepVGG-A0] (main.py 282): INFO Train: [131/300][10/78]	eta 0:03:48 lr 3.828291	time 1.1712 (3.3542)	loss 3.0459 (3.1643)	grad_norm 0.3330 (0.3943)	mem 39782MB
[2023-07-07 12:14:18 RepVGG-A0] (main.py 282): INFO Train: [131/300][20/78]	eta 0:02:21 lr 3.824078	time 1.1723 (2.4358)	loss 3.0720 (3.1310)	grad_norm 0.3571 (0.3748)	mem 39782MB
[2023-07-07 12:14:34 RepVGG-A0] (main.py 282): INFO Train: [131/300][30/78]	eta 0:01:43 lr 3.819864	time 1.3208 (2.1549)	loss 3.2173 (3.1364)	grad_norm 0.4180 (0.3766)	mem 39782MB
[2023-07-07 12:14:52 RepVGG-A0] (main.py 282): INFO Train: [131/300][40/78]	eta 0:01:18 lr 3.815649	time 4.0261 (2.0751)	loss 3.1713 (3.1457)	grad_norm 0.4111 (0.3874)	mem 39782MB
[2023-07-07 12:15:07 RepVGG-A0] (main.py 282): INFO Train: [131/300][50/78]	eta 0:00:54 lr 3.811432	time 1.1728 (1.9527)	loss 3.1089 (3.1432)	grad_norm 0.3226 (0.3814)	mem 39782MB
[2023-07-07 12:15:22 RepVGG-A0] (main.py 282): INFO Train: [131/300][60/78]	eta 0:00:33 lr 3.807215	time 1.4027 (1.8808)	loss 3.1305 (3.1479)	grad_norm 0.4056 (0.3848)	mem 39782MB
[2023-07-07 12:15:36 RepVGG-A0] (main.py 282): INFO Train: [131/300][70/78]	eta 0:00:14 lr 3.802996	time 1.3423 (1.8165)	loss 3.1343 (3.1535)	grad_norm 0.3524 (0.3884)	mem 39782MB
[2023-07-07 12:15:48 RepVGG-A0] (main.py 291): INFO EPOCH 131 training takes 0:02:21
[2023-07-07 12:16:10 RepVGG-A0] (main.py 282): INFO Train: [132/300][0/78]	eta 0:27:44 lr 3.799620	time 21.3442 (21.3442)	loss 3.0846 (3.0846)	grad_norm 0.3986 (0.3986)	mem 39782MB
[2023-07-07 12:16:25 RepVGG-A0] (main.py 282): INFO Train: [132/300][10/78]	eta 0:03:48 lr 3.795400	time 1.1738 (3.3646)	loss 3.1402 (3.1229)	grad_norm 0.3565 (0.3877)	mem 39782MB
[2023-07-07 12:16:41 RepVGG-A0] (main.py 282): INFO Train: [132/300][20/78]	eta 0:02:24 lr 3.791178	time 1.1761 (2.4882)	loss 3.1804 (3.1080)	grad_norm 0.4164 (0.3764)	mem 39782MB
[2023-07-07 12:16:56 RepVGG-A0] (main.py 282): INFO Train: [132/300][30/78]	eta 0:01:44 lr 3.786955	time 1.3819 (2.1872)	loss 3.2486 (3.1412)	grad_norm 0.4345 (0.3963)	mem 39782MB
[2023-07-07 12:17:14 RepVGG-A0] (main.py 282): INFO Train: [132/300][40/78]	eta 0:01:19 lr 3.782731	time 4.0698 (2.0925)	loss 3.1771 (3.1438)	grad_norm 0.3607 (0.3917)	mem 39782MB
[2023-07-07 12:17:30 RepVGG-A0] (main.py 282): INFO Train: [132/300][50/78]	eta 0:00:55 lr 3.778506	time 1.1746 (1.9850)	loss 3.1019 (3.1462)	grad_norm 0.3569 (0.3917)	mem 39782MB
[2023-07-07 12:17:45 RepVGG-A0] (main.py 282): INFO Train: [132/300][60/78]	eta 0:00:34 lr 3.774280	time 1.4255 (1.9126)	loss 3.2249 (3.1447)	grad_norm 0.4383 (0.3900)	mem 39782MB
[2023-07-07 12:18:01 RepVGG-A0] (main.py 282): INFO Train: [132/300][70/78]	eta 0:00:14 lr 3.770053	time 1.1828 (1.8717)	loss 3.0703 (3.1450)	grad_norm 0.3495 (0.3890)	mem 39782MB
[2023-07-07 12:18:13 RepVGG-A0] (main.py 291): INFO EPOCH 132 training takes 0:02:24
[2023-07-07 12:18:35 RepVGG-A0] (main.py 282): INFO Train: [133/300][0/78]	eta 0:27:45 lr 3.766671	time 21.3588 (21.3588)	loss 3.1537 (3.1537)	grad_norm 0.4493 (0.4493)	mem 39782MB
[2023-07-07 12:18:50 RepVGG-A0] (main.py 282): INFO Train: [133/300][10/78]	eta 0:03:49 lr 3.762442	time 1.1875 (3.3753)	loss 3.1054 (3.1568)	grad_norm 0.3868 (0.4279)	mem 39782MB
[2023-07-07 12:19:04 RepVGG-A0] (main.py 282): INFO Train: [133/300][20/78]	eta 0:02:21 lr 3.758213	time 1.2624 (2.4426)	loss 3.0822 (3.1270)	grad_norm 0.3395 (0.3970)	mem 39782MB
[2023-07-07 12:19:20 RepVGG-A0] (main.py 282): INFO Train: [133/300][30/78]	eta 0:01:44 lr 3.753982	time 1.3210 (2.1696)	loss 3.2479 (3.1304)	grad_norm 0.5089 (0.3999)	mem 39782MB
[2023-07-07 12:19:38 RepVGG-A0] (main.py 282): INFO Train: [133/300][40/78]	eta 0:01:19 lr 3.749750	time 2.9819 (2.0796)	loss 3.3194 (3.1671)	grad_norm 0.4644 (0.4221)	mem 39782MB
[2023-07-07 12:19:53 RepVGG-A0] (main.py 282): INFO Train: [133/300][50/78]	eta 0:00:54 lr 3.745517	time 1.1757 (1.9628)	loss 3.1726 (3.1719)	grad_norm 0.3405 (0.4122)	mem 39782MB
[2023-07-07 12:20:08 RepVGG-A0] (main.py 282): INFO Train: [133/300][60/78]	eta 0:00:34 lr 3.741283	time 1.2081 (1.8891)	loss 3.0323 (3.1582)	grad_norm 0.3420 (0.4020)	mem 39782MB
[2023-07-07 12:20:24 RepVGG-A0] (main.py 282): INFO Train: [133/300][70/78]	eta 0:00:14 lr 3.737049	time 1.3134 (1.8398)	loss 3.1945 (3.1522)	grad_norm 0.3681 (0.3957)	mem 39782MB
[2023-07-07 12:20:35 RepVGG-A0] (main.py 291): INFO EPOCH 133 training takes 0:02:21
[2023-07-07 12:20:56 RepVGG-A0] (main.py 282): INFO Train: [134/300][0/78]	eta 0:27:50 lr 3.733660	time 21.4134 (21.4134)	loss 3.0950 (3.0950)	grad_norm 0.4067 (0.4067)	mem 39782MB
[2023-07-07 12:21:10 RepVGG-A0] (main.py 282): INFO Train: [134/300][10/78]	eta 0:03:33 lr 3.729423	time 1.1940 (3.1465)	loss 3.1117 (3.0721)	grad_norm 0.3856 (0.3913)	mem 39782MB
[2023-07-07 12:21:24 RepVGG-A0] (main.py 282): INFO Train: [134/300][20/78]	eta 0:02:15 lr 3.725186	time 1.1729 (2.3388)	loss 3.1085 (3.0830)	grad_norm 0.3655 (0.3833)	mem 39782MB
[2023-07-07 12:21:39 RepVGG-A0] (main.py 282): INFO Train: [134/300][30/78]	eta 0:01:38 lr 3.720948	time 1.1727 (2.0550)	loss 3.0939 (3.0830)	grad_norm 0.3957 (0.3810)	mem 39782MB
[2023-07-07 12:21:58 RepVGG-A0] (main.py 282): INFO Train: [134/300][40/78]	eta 0:01:16 lr 3.716708	time 4.2210 (2.0211)	loss 3.1545 (3.0921)	grad_norm 0.4246 (0.3872)	mem 39782MB
[2023-07-07 12:22:13 RepVGG-A0] (main.py 282): INFO Train: [134/300][50/78]	eta 0:00:53 lr 3.712468	time 1.1933 (1.9197)	loss 3.0897 (3.1036)	grad_norm 0.3637 (0.3909)	mem 39782MB
[2023-07-07 12:22:27 RepVGG-A0] (main.py 282): INFO Train: [134/300][60/78]	eta 0:00:33 lr 3.708227	time 1.1738 (1.8426)	loss 3.1368 (3.1025)	grad_norm 0.3580 (0.3857)	mem 39782MB
[2023-07-07 12:22:42 RepVGG-A0] (main.py 282): INFO Train: [134/300][70/78]	eta 0:00:14 lr 3.703985	time 1.2106 (1.7934)	loss 3.2191 (3.1055)	grad_norm 0.4400 (0.3887)	mem 39782MB
[2023-07-07 12:22:56 RepVGG-A0] (main.py 291): INFO EPOCH 134 training takes 0:02:20
[2023-07-07 12:23:17 RepVGG-A0] (main.py 282): INFO Train: [135/300][0/78]	eta 0:27:33 lr 3.700590	time 21.2048 (21.2048)	loss 3.1299 (3.1299)	grad_norm 0.3975 (0.3975)	mem 39782MB
[2023-07-07 12:23:31 RepVGG-A0] (main.py 282): INFO Train: [135/300][10/78]	eta 0:03:37 lr 3.696347	time 1.1713 (3.2002)	loss 2.9952 (3.0640)	grad_norm 0.3464 (0.3517)	mem 39782MB
[2023-07-07 12:23:46 RepVGG-A0] (main.py 282): INFO Train: [135/300][20/78]	eta 0:02:20 lr 3.692102	time 1.1721 (2.4198)	loss 3.3092 (3.1193)	grad_norm 0.5393 (0.4071)	mem 39782MB
[2023-07-07 12:24:02 RepVGG-A0] (main.py 282): INFO Train: [135/300][30/78]	eta 0:01:42 lr 3.687856	time 1.4710 (2.1328)	loss 3.1070 (3.1348)	grad_norm 0.3365 (0.4024)	mem 39782MB
[2023-07-07 12:24:20 RepVGG-A0] (main.py 282): INFO Train: [135/300][40/78]	eta 0:01:17 lr 3.683610	time 3.6073 (2.0500)	loss 3.0863 (3.1183)	grad_norm 0.3426 (0.3885)	mem 39782MB
[2023-07-07 12:24:35 RepVGG-A0] (main.py 282): INFO Train: [135/300][50/78]	eta 0:00:54 lr 3.679363	time 1.1724 (1.9418)	loss 3.0615 (3.1124)	grad_norm 0.3445 (0.3864)	mem 39782MB
[2023-07-07 12:24:50 RepVGG-A0] (main.py 282): INFO Train: [135/300][60/78]	eta 0:00:33 lr 3.675115	time 1.1732 (1.8666)	loss 3.0436 (3.1042)	grad_norm 0.3513 (0.3794)	mem 39782MB
[2023-07-07 12:25:04 RepVGG-A0] (main.py 282): INFO Train: [135/300][70/78]	eta 0:00:14 lr 3.670866	time 1.1896 (1.8131)	loss 3.2469 (3.1143)	grad_norm 0.4666 (0.3906)	mem 39782MB
[2023-07-07 12:25:16 RepVGG-A0] (main.py 291): INFO EPOCH 135 training takes 0:02:20
[2023-07-07 12:25:38 RepVGG-A0] (main.py 282): INFO Train: [136/300][0/78]	eta 0:28:26 lr 3.667466	time 21.8734 (21.8734)	loss 3.1102 (3.1102)	grad_norm 0.3493 (0.3493)	mem 39782MB
[2023-07-07 12:25:53 RepVGG-A0] (main.py 282): INFO Train: [136/300][10/78]	eta 0:03:47 lr 3.663215	time 1.1991 (3.3503)	loss 3.0935 (3.0543)	grad_norm 0.3979 (0.3630)	mem 39782MB
[2023-07-07 12:26:08 RepVGG-A0] (main.py 282): INFO Train: [136/300][20/78]	eta 0:02:22 lr 3.658964	time 1.4517 (2.4648)	loss 3.0486 (3.0632)	grad_norm 0.3678 (0.3712)	mem 39782MB
[2023-07-07 12:26:23 RepVGG-A0] (main.py 282): INFO Train: [136/300][30/78]	eta 0:01:43 lr 3.654712	time 1.2740 (2.1595)	loss 3.0512 (3.0760)	grad_norm 0.3802 (0.3806)	mem 39782MB
[2023-07-07 12:26:41 RepVGG-A0] (main.py 282): INFO Train: [136/300][40/78]	eta 0:01:18 lr 3.650459	time 3.0456 (2.0622)	loss 3.0939 (3.0768)	grad_norm 0.3895 (0.3786)	mem 39782MB
[2023-07-07 12:26:56 RepVGG-A0] (main.py 282): INFO Train: [136/300][50/78]	eta 0:00:54 lr 3.646205	time 1.2349 (1.9564)	loss 3.2450 (3.0914)	grad_norm 0.4674 (0.3877)	mem 39782MB
[2023-07-07 12:27:11 RepVGG-A0] (main.py 282): INFO Train: [136/300][60/78]	eta 0:00:33 lr 3.641950	time 1.1320 (1.8691)	loss 3.1234 (3.0993)	grad_norm 0.3659 (0.3899)	mem 39782MB
[2023-07-07 12:27:26 RepVGG-A0] (main.py 282): INFO Train: [136/300][70/78]	eta 0:00:14 lr 3.637695	time 1.2962 (1.8236)	loss 3.1219 (3.0960)	grad_norm 0.3520 (0.3849)	mem 39782MB
[2023-07-07 12:27:37 RepVGG-A0] (main.py 291): INFO EPOCH 136 training takes 0:02:20
[2023-07-07 12:27:59 RepVGG-A0] (main.py 282): INFO Train: [137/300][0/78]	eta 0:28:05 lr 3.634290	time 21.6127 (21.6127)	loss 3.0797 (3.0797)	grad_norm 0.3797 (0.3797)	mem 39782MB
[2023-07-07 12:28:14 RepVGG-A0] (main.py 282): INFO Train: [137/300][10/78]	eta 0:03:44 lr 3.630033	time 1.1726 (3.3074)	loss 3.1916 (3.1139)	grad_norm 0.4715 (0.4509)	mem 39782MB
[2023-07-07 12:28:28 RepVGG-A0] (main.py 282): INFO Train: [137/300][20/78]	eta 0:02:20 lr 3.625775	time 1.1721 (2.4147)	loss 3.1100 (3.1104)	grad_norm 0.4067 (0.4225)	mem 39782MB
[2023-07-07 12:28:45 RepVGG-A0] (main.py 282): INFO Train: [137/300][30/78]	eta 0:01:44 lr 3.621517	time 1.5742 (2.1841)	loss 2.9993 (3.0867)	grad_norm 0.3459 (0.3985)	mem 39782MB
[2023-07-07 12:29:02 RepVGG-A0] (main.py 282): INFO Train: [137/300][40/78]	eta 0:01:18 lr 3.617258	time 3.0729 (2.0583)	loss 3.0257 (3.0869)	grad_norm 0.3950 (0.3992)	mem 39782MB
[2023-07-07 12:29:16 RepVGG-A0] (main.py 282): INFO Train: [137/300][50/78]	eta 0:00:54 lr 3.612998	time 1.1728 (1.9416)	loss 3.1833 (3.0942)	grad_norm 0.4106 (0.4028)	mem 39782MB
[2023-07-07 12:29:32 RepVGG-A0] (main.py 282): INFO Train: [137/300][60/78]	eta 0:00:33 lr 3.608737	time 1.3472 (1.8720)	loss 3.0749 (3.0947)	grad_norm 0.3766 (0.3988)	mem 39782MB
[2023-07-07 12:29:48 RepVGG-A0] (main.py 282): INFO Train: [137/300][70/78]	eta 0:00:14 lr 3.604476	time 1.5674 (1.8430)	loss 3.0873 (3.0916)	grad_norm 0.3647 (0.3944)	mem 39782MB
[2023-07-07 12:29:59 RepVGG-A0] (main.py 291): INFO EPOCH 137 training takes 0:02:21
[2023-07-07 12:30:20 RepVGG-A0] (main.py 282): INFO Train: [138/300][0/78]	eta 0:27:47 lr 3.601066	time 21.3723 (21.3723)	loss 3.0496 (3.0496)	grad_norm 0.3662 (0.3662)	mem 39782MB
[2023-07-07 12:30:35 RepVGG-A0] (main.py 282): INFO Train: [138/300][10/78]	eta 0:03:44 lr 3.596804	time 1.1725 (3.2997)	loss 3.1770 (3.1272)	grad_norm 0.4469 (0.4457)	mem 39782MB
[2023-07-07 12:30:50 RepVGG-A0] (main.py 282): INFO Train: [138/300][20/78]	eta 0:02:21 lr 3.592540	time 1.1711 (2.4373)	loss 3.1235 (3.1042)	grad_norm 0.3703 (0.4149)	mem 39782MB
[2023-07-07 12:31:05 RepVGG-A0] (main.py 282): INFO Train: [138/300][30/78]	eta 0:01:42 lr 3.588276	time 1.1620 (2.1281)	loss 3.1173 (3.0867)	grad_norm 0.4117 (0.4038)	mem 39782MB
[2023-07-07 12:31:23 RepVGG-A0] (main.py 282): INFO Train: [138/300][40/78]	eta 0:01:17 lr 3.584011	time 3.8797 (2.0479)	loss 3.0108 (3.0785)	grad_norm 0.3636 (0.3978)	mem 39782MB
[2023-07-07 12:31:38 RepVGG-A0] (main.py 282): INFO Train: [138/300][50/78]	eta 0:00:54 lr 3.579746	time 1.1938 (1.9365)	loss 3.0917 (3.0775)	grad_norm 0.3665 (0.3944)	mem 39782MB
[2023-07-07 12:31:53 RepVGG-A0] (main.py 282): INFO Train: [138/300][60/78]	eta 0:00:33 lr 3.575480	time 1.2465 (1.8750)	loss 3.1999 (3.0832)	grad_norm 0.4636 (0.3988)	mem 39782MB
[2023-07-07 12:32:09 RepVGG-A0] (main.py 282): INFO Train: [138/300][70/78]	eta 0:00:14 lr 3.571213	time 1.4126 (1.8269)	loss 3.1218 (3.0996)	grad_norm 0.3824 (0.4076)	mem 39782MB
[2023-07-07 12:32:20 RepVGG-A0] (main.py 291): INFO EPOCH 138 training takes 0:02:21
[2023-07-07 12:32:41 RepVGG-A0] (main.py 282): INFO Train: [139/300][0/78]	eta 0:27:16 lr 3.567799	time 20.9818 (20.9818)	loss 2.9941 (2.9941)	grad_norm 0.3523 (0.3523)	mem 39782MB
[2023-07-07 12:32:56 RepVGG-A0] (main.py 282): INFO Train: [139/300][10/78]	eta 0:03:42 lr 3.563531	time 1.1894 (3.2793)	loss 3.0214 (3.0584)	grad_norm 0.3781 (0.3952)	mem 39782MB
[2023-07-07 12:33:12 RepVGG-A0] (main.py 282): INFO Train: [139/300][20/78]	eta 0:02:23 lr 3.559262	time 1.2273 (2.4758)	loss 3.1226 (3.0470)	grad_norm 0.4609 (0.3871)	mem 39782MB
[2023-07-07 12:33:25 RepVGG-A0] (main.py 282): INFO Train: [139/300][30/78]	eta 0:01:40 lr 3.554993	time 1.2898 (2.1035)	loss 3.0138 (3.0603)	grad_norm 0.3551 (0.3905)	mem 39782MB
[2023-07-07 12:33:43 RepVGG-A0] (main.py 282): INFO Train: [139/300][40/78]	eta 0:01:16 lr 3.550723	time 3.6506 (2.0255)	loss 3.1258 (3.0575)	grad_norm 0.4109 (0.3861)	mem 39782MB
[2023-07-07 12:33:59 RepVGG-A0] (main.py 282): INFO Train: [139/300][50/78]	eta 0:00:54 lr 3.546452	time 1.1728 (1.9404)	loss 3.0552 (3.0625)	grad_norm 0.3252 (0.3840)	mem 39782MB
[2023-07-07 12:34:14 RepVGG-A0] (main.py 282): INFO Train: [139/300][60/78]	eta 0:00:33 lr 3.542181	time 1.3203 (1.8681)	loss 3.1564 (3.0710)	grad_norm 0.4667 (0.3906)	mem 39782MB
[2023-07-07 12:34:29 RepVGG-A0] (main.py 282): INFO Train: [139/300][70/78]	eta 0:00:14 lr 3.537909	time 1.3682 (1.8182)	loss 3.0128 (3.0783)	grad_norm 0.3444 (0.3918)	mem 39782MB
[2023-07-07 12:34:41 RepVGG-A0] (main.py 291): INFO EPOCH 139 training takes 0:02:21
[2023-07-07 12:35:03 RepVGG-A0] (main.py 282): INFO Train: [140/300][0/78]	eta 0:28:53 lr 3.534491	time 22.2306 (22.2306)	loss 2.9748 (2.9748)	grad_norm 0.3325 (0.3325)	mem 39782MB
[2023-07-07 12:35:17 RepVGG-A0] (main.py 282): INFO Train: [140/300][10/78]	eta 0:03:45 lr 3.530218	time 1.1836 (3.3151)	loss 3.0727 (3.0428)	grad_norm 0.4228 (0.3946)	mem 39782MB
[2023-07-07 12:35:31 RepVGG-A0] (main.py 282): INFO Train: [140/300][20/78]	eta 0:02:17 lr 3.525945	time 1.1719 (2.3712)	loss 2.9962 (3.0372)	grad_norm 0.3781 (0.3896)	mem 39782MB
[2023-07-07 12:35:46 RepVGG-A0] (main.py 282): INFO Train: [140/300][30/78]	eta 0:01:40 lr 3.521670	time 1.4843 (2.1024)	loss 2.9545 (3.0393)	grad_norm 0.3498 (0.3859)	mem 39782MB
[2023-07-07 12:36:04 RepVGG-A0] (main.py 282): INFO Train: [140/300][40/78]	eta 0:01:16 lr 3.517396	time 3.6780 (2.0163)	loss 3.0632 (3.0525)	grad_norm 0.3589 (0.3966)	mem 39782MB
[2023-07-07 12:36:19 RepVGG-A0] (main.py 282): INFO Train: [140/300][50/78]	eta 0:00:53 lr 3.513120	time 1.1734 (1.9267)	loss 3.0915 (3.0513)	grad_norm 0.3936 (0.3909)	mem 39782MB
[2023-07-07 12:36:34 RepVGG-A0] (main.py 282): INFO Train: [140/300][60/78]	eta 0:00:33 lr 3.508845	time 1.1798 (1.8592)	loss 3.0955 (3.0515)	grad_norm 0.3913 (0.3921)	mem 39782MB
[2023-07-07 12:36:50 RepVGG-A0] (main.py 282): INFO Train: [140/300][70/78]	eta 0:00:14 lr 3.504568	time 1.4227 (1.8136)	loss 3.0710 (3.0513)	grad_norm 0.3965 (0.3920)	mem 39782MB
[2023-07-07 12:37:01 RepVGG-A0] (main.py 291): INFO EPOCH 140 training takes 0:02:20
[2023-07-07 12:37:18 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.379 (17.379)	Loss 3.0108 (3.0108)	Acc@1 38.049 (38.049)	Acc@5 64.020 (64.020)	Mem 39782MB
[2023-07-07 12:37:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 38.532 Acc@5 64.328
[2023-07-07 12:37:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 140: 38.532%
[2023-07-07 12:37:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 41.65%
[2023-07-07 12:37:40 RepVGG-A0] (main.py 282): INFO Train: [141/300][0/78]	eta 0:26:18 lr 3.501147	time 20.2389 (20.2389)	loss 3.0316 (3.0316)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 12:37:55 RepVGG-A0] (main.py 282): INFO Train: [141/300][10/78]	eta 0:03:39 lr 3.496869	time 1.1929 (3.2266)	loss 2.9607 (3.0321)	grad_norm 0.3821 (0.3968)	mem 39782MB
[2023-07-07 12:38:10 RepVGG-A0] (main.py 282): INFO Train: [141/300][20/78]	eta 0:02:19 lr 3.492591	time 1.1739 (2.4090)	loss 3.0038 (3.0363)	grad_norm 0.3761 (0.3932)	mem 39782MB
[2023-07-07 12:38:25 RepVGG-A0] (main.py 282): INFO Train: [141/300][30/78]	eta 0:01:41 lr 3.488313	time 1.2994 (2.1061)	loss 3.0481 (3.0327)	grad_norm 0.3603 (0.3842)	mem 39782MB
[2023-07-07 12:38:43 RepVGG-A0] (main.py 282): INFO Train: [141/300][40/78]	eta 0:01:17 lr 3.484034	time 2.6620 (2.0316)	loss 3.0830 (3.0425)	grad_norm 0.4305 (0.3917)	mem 39782MB
[2023-07-07 12:38:59 RepVGG-A0] (main.py 282): INFO Train: [141/300][50/78]	eta 0:00:54 lr 3.479754	time 1.2981 (1.9361)	loss 3.0139 (3.0431)	grad_norm 0.3592 (0.3885)	mem 39782MB
[2023-07-07 12:39:13 RepVGG-A0] (main.py 282): INFO Train: [141/300][60/78]	eta 0:00:33 lr 3.475474	time 1.2087 (1.8577)	loss 2.9646 (3.0519)	grad_norm 0.3673 (0.3943)	mem 39782MB
[2023-07-07 12:39:29 RepVGG-A0] (main.py 282): INFO Train: [141/300][70/78]	eta 0:00:14 lr 3.471194	time 1.3170 (1.8117)	loss 3.1646 (3.0533)	grad_norm 0.4624 (0.3934)	mem 39782MB
[2023-07-07 12:39:40 RepVGG-A0] (main.py 291): INFO EPOCH 141 training takes 0:02:20
[2023-07-07 12:40:02 RepVGG-A0] (main.py 282): INFO Train: [142/300][0/78]	eta 0:27:34 lr 3.467769	time 21.2174 (21.2174)	loss 3.0408 (3.0408)	grad_norm 0.3889 (0.3889)	mem 39782MB
[2023-07-07 12:40:16 RepVGG-A0] (main.py 282): INFO Train: [142/300][10/78]	eta 0:03:39 lr 3.463488	time 1.1715 (3.2297)	loss 2.9684 (3.0126)	grad_norm 0.3824 (0.3771)	mem 39782MB
[2023-07-07 12:40:31 RepVGG-A0] (main.py 282): INFO Train: [142/300][20/78]	eta 0:02:20 lr 3.459206	time 1.1757 (2.4253)	loss 3.0279 (3.0297)	grad_norm 0.4019 (0.3849)	mem 39782MB
[2023-07-07 12:40:46 RepVGG-A0] (main.py 282): INFO Train: [142/300][30/78]	eta 0:01:42 lr 3.454924	time 1.6384 (2.1265)	loss 3.0879 (3.0252)	grad_norm 0.4027 (0.3831)	mem 39782MB
[2023-07-07 12:41:04 RepVGG-A0] (main.py 282): INFO Train: [142/300][40/78]	eta 0:01:17 lr 3.450641	time 2.6706 (2.0329)	loss 3.2373 (3.0574)	grad_norm 0.4964 (0.4087)	mem 39782MB
[2023-07-07 12:41:18 RepVGG-A0] (main.py 282): INFO Train: [142/300][50/78]	eta 0:00:53 lr 3.446358	time 1.3409 (1.9163)	loss 3.0579 (3.0578)	grad_norm 0.3573 (0.4009)	mem 39782MB
[2023-07-07 12:41:34 RepVGG-A0] (main.py 282): INFO Train: [142/300][60/78]	eta 0:00:33 lr 3.442074	time 1.1819 (1.8546)	loss 3.0716 (3.0559)	grad_norm 0.3691 (0.3967)	mem 39782MB
[2023-07-07 12:41:49 RepVGG-A0] (main.py 282): INFO Train: [142/300][70/78]	eta 0:00:14 lr 3.437790	time 1.3759 (1.8113)	loss 3.0890 (3.0529)	grad_norm 0.4186 (0.3950)	mem 39782MB
[2023-07-07 12:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 142 training takes 0:02:19
[2023-07-07 12:42:20 RepVGG-A0] (main.py 282): INFO Train: [143/300][0/78]	eta 0:26:16 lr 3.434362	time 20.2103 (20.2103)	loss 2.9890 (2.9890)	grad_norm 0.3851 (0.3851)	mem 39782MB
[2023-07-07 12:42:39 RepVGG-A0] (main.py 282): INFO Train: [143/300][10/78]	eta 0:03:57 lr 3.430077	time 1.2689 (3.4965)	loss 3.0098 (2.9962)	grad_norm 0.4055 (0.3765)	mem 39782MB
[2023-07-07 12:42:52 RepVGG-A0] (main.py 282): INFO Train: [143/300][20/78]	eta 0:02:23 lr 3.425792	time 1.2003 (2.4693)	loss 3.1225 (3.0195)	grad_norm 0.4733 (0.3959)	mem 39782MB
[2023-07-07 12:43:06 RepVGG-A0] (main.py 282): INFO Train: [143/300][30/78]	eta 0:01:41 lr 3.421506	time 1.1825 (2.1134)	loss 3.0124 (3.0240)	grad_norm 0.3792 (0.3978)	mem 39782MB
[2023-07-07 12:43:25 RepVGG-A0] (main.py 282): INFO Train: [143/300][40/78]	eta 0:01:18 lr 3.417220	time 5.1867 (2.0603)	loss 3.0851 (3.0243)	grad_norm 0.4165 (0.3976)	mem 39782MB
[2023-07-07 12:43:40 RepVGG-A0] (main.py 282): INFO Train: [143/300][50/78]	eta 0:00:54 lr 3.412934	time 1.2413 (1.9584)	loss 3.0981 (3.0338)	grad_norm 0.3946 (0.3977)	mem 39782MB
[2023-07-07 12:43:55 RepVGG-A0] (main.py 282): INFO Train: [143/300][60/78]	eta 0:00:34 lr 3.408647	time 1.1746 (1.8895)	loss 3.0645 (3.0361)	grad_norm 0.4138 (0.3988)	mem 39782MB
[2023-07-07 12:44:10 RepVGG-A0] (main.py 282): INFO Train: [143/300][70/78]	eta 0:00:14 lr 3.404360	time 1.3117 (1.8284)	loss 3.0287 (3.0387)	grad_norm 0.4123 (0.3991)	mem 39782MB
[2023-07-07 12:44:22 RepVGG-A0] (main.py 291): INFO EPOCH 143 training takes 0:02:22
[2023-07-07 12:44:44 RepVGG-A0] (main.py 282): INFO Train: [144/300][0/78]	eta 0:27:55 lr 3.400930	time 21.4749 (21.4749)	loss 3.0102 (3.0102)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:44:58 RepVGG-A0] (main.py 282): INFO Train: [144/300][10/78]	eta 0:03:41 lr 3.396642	time 1.1717 (3.2545)	loss 3.0970 (3.0303)	grad_norm 0.4112 (0.4074)	mem 39782MB
[2023-07-07 12:45:12 RepVGG-A0] (main.py 282): INFO Train: [144/300][20/78]	eta 0:02:17 lr 3.392354	time 1.1730 (2.3626)	loss 3.0913 (3.0449)	grad_norm 0.3925 (0.4080)	mem 39782MB
[2023-07-07 12:45:27 RepVGG-A0] (main.py 282): INFO Train: [144/300][30/78]	eta 0:01:39 lr 3.388065	time 1.3767 (2.0740)	loss 3.0976 (3.0356)	grad_norm 0.3883 (0.4014)	mem 39782MB
[2023-07-07 12:45:45 RepVGG-A0] (main.py 282): INFO Train: [144/300][40/78]	eta 0:01:16 lr 3.383776	time 3.4477 (2.0256)	loss 3.0061 (3.0275)	grad_norm 0.4080 (0.3968)	mem 39782MB
[2023-07-07 12:46:01 RepVGG-A0] (main.py 282): INFO Train: [144/300][50/78]	eta 0:00:53 lr 3.379487	time 1.1736 (1.9266)	loss 3.0051 (3.0387)	grad_norm 0.3644 (0.4038)	mem 39782MB
[2023-07-07 12:46:16 RepVGG-A0] (main.py 282): INFO Train: [144/300][60/78]	eta 0:00:33 lr 3.375197	time 1.3043 (1.8601)	loss 3.1304 (3.0410)	grad_norm 0.3939 (0.4006)	mem 39782MB
[2023-07-07 12:46:31 RepVGG-A0] (main.py 282): INFO Train: [144/300][70/78]	eta 0:00:14 lr 3.370907	time 1.3932 (1.8120)	loss 3.0553 (3.0430)	grad_norm 0.4046 (0.4025)	mem 39782MB
[2023-07-07 12:46:43 RepVGG-A0] (main.py 291): INFO EPOCH 144 training takes 0:02:20
[2023-07-07 12:47:05 RepVGG-A0] (main.py 282): INFO Train: [145/300][0/78]	eta 0:28:34 lr 3.367475	time 21.9810 (21.9810)	loss 3.0376 (3.0376)	grad_norm 0.4466 (0.4466)	mem 39782MB
[2023-07-07 12:47:20 RepVGG-A0] (main.py 282): INFO Train: [145/300][10/78]	eta 0:03:47 lr 3.363185	time 1.1720 (3.3392)	loss 2.9911 (3.0212)	grad_norm 0.4192 (0.4218)	mem 39782MB
[2023-07-07 12:47:35 RepVGG-A0] (main.py 282): INFO Train: [145/300][20/78]	eta 0:02:22 lr 3.358894	time 1.1807 (2.4511)	loss 3.0440 (3.0290)	grad_norm 0.4341 (0.4198)	mem 39782MB
[2023-07-07 12:47:50 RepVGG-A0] (main.py 282): INFO Train: [145/300][30/78]	eta 0:01:42 lr 3.354603	time 1.2049 (2.1378)	loss 2.9682 (3.0197)	grad_norm 0.3616 (0.4094)	mem 39782MB
[2023-07-07 12:48:08 RepVGG-A0] (main.py 282): INFO Train: [145/300][40/78]	eta 0:01:18 lr 3.350311	time 3.8915 (2.0747)	loss 2.9658 (3.0144)	grad_norm 0.3599 (0.4018)	mem 39782MB
[2023-07-07 12:48:23 RepVGG-A0] (main.py 282): INFO Train: [145/300][50/78]	eta 0:00:54 lr 3.346020	time 1.1736 (1.9584)	loss 2.9919 (3.0205)	grad_norm 0.3457 (0.4026)	mem 39782MB
[2023-07-07 12:48:39 RepVGG-A0] (main.py 282): INFO Train: [145/300][60/78]	eta 0:00:33 lr 3.341728	time 1.2038 (1.8886)	loss 3.1034 (3.0169)	grad_norm 0.4584 (0.3997)	mem 39782MB
[2023-07-07 12:48:54 RepVGG-A0] (main.py 282): INFO Train: [145/300][70/78]	eta 0:00:14 lr 3.337436	time 1.5211 (1.8382)	loss 5.6397 (3.1024)	grad_norm 1.6408 (0.4593)	mem 39782MB
[2023-07-07 12:49:05 RepVGG-A0] (main.py 291): INFO EPOCH 145 training takes 0:02:21
[2023-07-07 12:49:27 RepVGG-A0] (main.py 282): INFO Train: [146/300][0/78]	eta 0:29:08 lr 3.334002	time 22.4220 (22.4220)	loss 5.7732 (5.7732)	grad_norm 0.4792 (0.4792)	mem 39782MB
[2023-07-07 12:49:41 RepVGG-A0] (main.py 282): INFO Train: [146/300][10/78]	eta 0:03:44 lr 3.329710	time 1.1732 (3.3051)	loss 4.8605 (5.2636)	grad_norm 0.3540 (0.4210)	mem 39782MB
[2023-07-07 12:49:56 RepVGG-A0] (main.py 282): INFO Train: [146/300][20/78]	eta 0:02:21 lr 3.325417	time 1.1740 (2.4447)	loss 4.3426 (4.9537)	grad_norm 0.3067 (0.4277)	mem 39782MB
[2023-07-07 12:50:11 RepVGG-A0] (main.py 282): INFO Train: [146/300][30/78]	eta 0:01:42 lr 3.321124	time 1.4829 (2.1384)	loss 3.9866 (4.6787)	grad_norm 0.3535 (0.3978)	mem 39782MB
[2023-07-07 12:50:28 RepVGG-A0] (main.py 282): INFO Train: [146/300][40/78]	eta 0:01:16 lr 3.316831	time 2.6101 (2.0230)	loss 3.7677 (4.4731)	grad_norm 0.3586 (0.3782)	mem 39782MB
[2023-07-07 12:50:44 RepVGG-A0] (main.py 282): INFO Train: [146/300][50/78]	eta 0:00:54 lr 3.312537	time 1.1748 (1.9439)	loss 3.6562 (4.3313)	grad_norm 0.3339 (0.3789)	mem 39782MB
[2023-07-07 12:50:59 RepVGG-A0] (main.py 282): INFO Train: [146/300][60/78]	eta 0:00:33 lr 3.308243	time 1.1957 (1.8684)	loss 3.5547 (4.2052)	grad_norm 0.3752 (0.3709)	mem 39782MB
[2023-07-07 12:51:14 RepVGG-A0] (main.py 282): INFO Train: [146/300][70/78]	eta 0:00:14 lr 3.303950	time 1.5944 (1.8209)	loss 3.5450 (4.1120)	grad_norm 0.4020 (0.3701)	mem 39782MB
[2023-07-07 12:51:26 RepVGG-A0] (main.py 291): INFO EPOCH 146 training takes 0:02:20
[2023-07-07 12:51:49 RepVGG-A0] (main.py 282): INFO Train: [147/300][0/78]	eta 0:29:48 lr 3.300514	time 22.9338 (22.9338)	loss 3.4699 (3.4699)	grad_norm 0.3848 (0.3848)	mem 39782MB
[2023-07-07 12:52:03 RepVGG-A0] (main.py 282): INFO Train: [147/300][10/78]	eta 0:03:49 lr 3.296220	time 1.1714 (3.3799)	loss 3.3187 (3.3906)	grad_norm 0.2838 (0.3664)	mem 39782MB
[2023-07-07 12:52:17 RepVGG-A0] (main.py 282): INFO Train: [147/300][20/78]	eta 0:02:22 lr 3.291926	time 1.2049 (2.4589)	loss 3.3365 (3.3603)	grad_norm 0.4730 (0.3555)	mem 39782MB
[2023-07-07 12:52:32 RepVGG-A0] (main.py 282): INFO Train: [147/300][30/78]	eta 0:01:43 lr 3.287631	time 1.5257 (2.1567)	loss 3.3382 (3.3642)	grad_norm 0.3753 (0.3671)	mem 39782MB
[2023-07-07 12:52:50 RepVGG-A0] (main.py 282): INFO Train: [147/300][40/78]	eta 0:01:18 lr 3.283337	time 3.4829 (2.0694)	loss 3.2912 (3.3469)	grad_norm 0.3578 (0.3627)	mem 39782MB
[2023-07-07 12:53:05 RepVGG-A0] (main.py 282): INFO Train: [147/300][50/78]	eta 0:00:54 lr 3.279042	time 1.1724 (1.9434)	loss 3.3062 (3.3380)	grad_norm 0.3598 (0.3630)	mem 39782MB
[2023-07-07 12:53:20 RepVGG-A0] (main.py 282): INFO Train: [147/300][60/78]	eta 0:00:33 lr 3.274747	time 1.3033 (1.8739)	loss 3.2119 (3.3288)	grad_norm 0.3440 (0.3625)	mem 39782MB
[2023-07-07 12:53:35 RepVGG-A0] (main.py 282): INFO Train: [147/300][70/78]	eta 0:00:14 lr 3.270452	time 1.3178 (1.8276)	loss 3.2550 (3.3244)	grad_norm 0.3847 (0.3696)	mem 39782MB
[2023-07-07 12:53:47 RepVGG-A0] (main.py 291): INFO EPOCH 147 training takes 0:02:21
[2023-07-07 12:54:10 RepVGG-A0] (main.py 282): INFO Train: [148/300][0/78]	eta 0:30:02 lr 3.267016	time 23.1131 (23.1131)	loss 3.1614 (3.1614)	grad_norm 0.3653 (0.3653)	mem 39782MB
[2023-07-07 12:54:24 RepVGG-A0] (main.py 282): INFO Train: [148/300][10/78]	eta 0:03:47 lr 3.262720	time 1.1736 (3.3478)	loss 3.2765 (3.2091)	grad_norm 0.3601 (0.3765)	mem 39782MB
[2023-07-07 12:54:37 RepVGG-A0] (main.py 282): INFO Train: [148/300][20/78]	eta 0:02:18 lr 3.258425	time 1.1728 (2.3902)	loss 3.2251 (3.2061)	grad_norm 0.4312 (0.3857)	mem 39782MB
[2023-07-07 12:54:53 RepVGG-A0] (main.py 282): INFO Train: [148/300][30/78]	eta 0:01:42 lr 3.254129	time 1.4502 (2.1327)	loss 3.1966 (3.2046)	grad_norm 0.3788 (0.3801)	mem 39782MB
[2023-07-07 12:55:11 RepVGG-A0] (main.py 282): INFO Train: [148/300][40/78]	eta 0:01:17 lr 3.249834	time 4.0093 (2.0524)	loss 3.1868 (3.2039)	grad_norm 0.3711 (0.3819)	mem 39782MB
[2023-07-07 12:55:26 RepVGG-A0] (main.py 282): INFO Train: [148/300][50/78]	eta 0:00:54 lr 3.245538	time 1.1739 (1.9443)	loss 3.2703 (3.2037)	grad_norm 0.4977 (0.3843)	mem 39782MB
[2023-07-07 12:55:40 RepVGG-A0] (main.py 282): INFO Train: [148/300][60/78]	eta 0:00:33 lr 3.241242	time 1.1762 (1.8620)	loss 3.2137 (3.2117)	grad_norm 0.3681 (0.3927)	mem 39782MB
[2023-07-07 12:55:56 RepVGG-A0] (main.py 282): INFO Train: [148/300][70/78]	eta 0:00:14 lr 3.236946	time 1.5517 (1.8164)	loss 3.1894 (3.2121)	grad_norm 0.3063 (0.3898)	mem 39782MB
[2023-07-07 12:56:07 RepVGG-A0] (main.py 291): INFO EPOCH 148 training takes 0:02:20
[2023-07-07 12:56:30 RepVGG-A0] (main.py 282): INFO Train: [149/300][0/78]	eta 0:29:13 lr 3.233510	time 22.4779 (22.4779)	loss 3.1824 (3.1824)	grad_norm 0.3884 (0.3884)	mem 39782MB
[2023-07-07 12:56:45 RepVGG-A0] (main.py 282): INFO Train: [149/300][10/78]	eta 0:03:49 lr 3.229214	time 1.1710 (3.3769)	loss 3.1847 (3.1269)	grad_norm 0.4202 (0.3863)	mem 39782MB
[2023-07-07 12:57:00 RepVGG-A0] (main.py 282): INFO Train: [149/300][20/78]	eta 0:02:26 lr 3.224918	time 1.1785 (2.5182)	loss 3.1039 (3.1239)	grad_norm 0.3391 (0.3832)	mem 39782MB
[2023-07-07 12:57:16 RepVGG-A0] (main.py 282): INFO Train: [149/300][30/78]	eta 0:01:46 lr 3.220622	time 1.9746 (2.2235)	loss 3.1472 (3.1403)	grad_norm 0.3770 (0.3956)	mem 39782MB
[2023-07-07 12:57:33 RepVGG-A0] (main.py 282): INFO Train: [149/300][40/78]	eta 0:01:19 lr 3.216325	time 2.9399 (2.0986)	loss 3.1519 (3.1344)	grad_norm 0.4092 (0.3872)	mem 39782MB
[2023-07-07 12:57:49 RepVGG-A0] (main.py 282): INFO Train: [149/300][50/78]	eta 0:00:55 lr 3.212029	time 1.1734 (1.9856)	loss 3.1749 (3.1368)	grad_norm 0.4082 (0.3911)	mem 39782MB
[2023-07-07 12:58:04 RepVGG-A0] (main.py 282): INFO Train: [149/300][60/78]	eta 0:00:34 lr 3.207733	time 1.1832 (1.9078)	loss 3.1048 (3.1365)	grad_norm 0.3677 (0.3913)	mem 39782MB
[2023-07-07 12:58:19 RepVGG-A0] (main.py 282): INFO Train: [149/300][70/78]	eta 0:00:14 lr 3.203437	time 1.2837 (1.8555)	loss 3.3845 (3.1425)	grad_norm 0.5420 (0.3976)	mem 39782MB
[2023-07-07 12:58:30 RepVGG-A0] (main.py 291): INFO EPOCH 149 training takes 0:02:23
[2023-07-07 12:58:53 RepVGG-A0] (main.py 282): INFO Train: [150/300][0/78]	eta 0:28:39 lr 3.200000	time 22.0407 (22.0407)	loss 3.4545 (3.4545)	grad_norm 0.5789 (0.5789)	mem 39782MB
[2023-07-07 12:59:07 RepVGG-A0] (main.py 282): INFO Train: [150/300][10/78]	eta 0:03:43 lr 3.195704	time 1.1714 (3.2895)	loss 3.1921 (3.2417)	grad_norm 0.3354 (0.3925)	mem 39782MB
[2023-07-07 12:59:22 RepVGG-A0] (main.py 282): INFO Train: [150/300][20/78]	eta 0:02:21 lr 3.191408	time 1.1746 (2.4368)	loss 3.2607 (3.1784)	grad_norm 0.4256 (0.3746)	mem 39782MB
[2023-07-07 12:59:36 RepVGG-A0] (main.py 282): INFO Train: [150/300][30/78]	eta 0:01:42 lr 3.187111	time 1.4277 (2.1273)	loss 3.1144 (3.1538)	grad_norm 0.3508 (0.3665)	mem 39782MB
[2023-07-07 12:59:54 RepVGG-A0] (main.py 282): INFO Train: [150/300][40/78]	eta 0:01:17 lr 3.182815	time 3.9122 (2.0464)	loss 3.0838 (3.1393)	grad_norm 0.3752 (0.3712)	mem 39782MB
[2023-07-07 13:00:09 RepVGG-A0] (main.py 282): INFO Train: [150/300][50/78]	eta 0:00:54 lr 3.178519	time 1.1706 (1.9387)	loss 3.0411 (3.1245)	grad_norm 0.3473 (0.3678)	mem 39782MB
[2023-07-07 13:00:24 RepVGG-A0] (main.py 282): INFO Train: [150/300][60/78]	eta 0:00:33 lr 3.174223	time 1.1813 (1.8677)	loss 3.0412 (3.1159)	grad_norm 0.3779 (0.3675)	mem 39782MB
[2023-07-07 13:00:40 RepVGG-A0] (main.py 282): INFO Train: [150/300][70/78]	eta 0:00:14 lr 3.169927	time 1.1294 (1.8193)	loss 3.1126 (3.1148)	grad_norm 0.4487 (0.3727)	mem 39782MB
[2023-07-07 13:00:51 RepVGG-A0] (main.py 291): INFO EPOCH 150 training takes 0:02:20
[2023-07-07 13:01:12 RepVGG-A0] (main.py 282): INFO Train: [151/300][0/78]	eta 0:26:11 lr 3.166490	time 20.1520 (20.1520)	loss 3.1056 (3.1056)	grad_norm 0.3840 (0.3840)	mem 39782MB
[2023-07-07 13:01:28 RepVGG-A0] (main.py 282): INFO Train: [151/300][10/78]	eta 0:03:46 lr 3.162194	time 1.1714 (3.3252)	loss 3.0844 (3.0584)	grad_norm 0.3811 (0.3730)	mem 39782MB
[2023-07-07 13:01:42 RepVGG-A0] (main.py 282): INFO Train: [151/300][20/78]	eta 0:02:20 lr 3.157899	time 1.2360 (2.4264)	loss 3.1201 (3.0596)	grad_norm 0.3919 (0.3801)	mem 39782MB
[2023-07-07 13:01:57 RepVGG-A0] (main.py 282): INFO Train: [151/300][30/78]	eta 0:01:41 lr 3.153603	time 1.4252 (2.1231)	loss 3.0721 (3.0809)	grad_norm 0.3902 (0.3928)	mem 39782MB
[2023-07-07 13:02:14 RepVGG-A0] (main.py 282): INFO Train: [151/300][40/78]	eta 0:01:16 lr 3.149307	time 3.6442 (2.0194)	loss 3.0261 (3.0770)	grad_norm 0.4150 (0.3921)	mem 39782MB
[2023-07-07 13:02:29 RepVGG-A0] (main.py 282): INFO Train: [151/300][50/78]	eta 0:00:53 lr 3.145011	time 1.1721 (1.9138)	loss 3.1571 (3.0824)	grad_norm 0.4151 (0.3928)	mem 39782MB
[2023-07-07 13:02:45 RepVGG-A0] (main.py 282): INFO Train: [151/300][60/78]	eta 0:00:33 lr 3.140716	time 1.1774 (1.8557)	loss 3.0455 (3.0901)	grad_norm 0.3924 (0.3960)	mem 39782MB
[2023-07-07 13:02:59 RepVGG-A0] (main.py 282): INFO Train: [151/300][70/78]	eta 0:00:14 lr 3.136420	time 1.1821 (1.8001)	loss 3.1509 (3.0986)	grad_norm 0.3548 (0.4000)	mem 39782MB
[2023-07-07 13:03:11 RepVGG-A0] (main.py 291): INFO EPOCH 151 training takes 0:02:19
[2023-07-07 13:03:33 RepVGG-A0] (main.py 282): INFO Train: [152/300][0/78]	eta 0:28:19 lr 3.132984	time 21.7839 (21.7839)	loss 3.0885 (3.0885)	grad_norm 0.4497 (0.4497)	mem 39782MB
[2023-07-07 13:03:48 RepVGG-A0] (main.py 282): INFO Train: [152/300][10/78]	eta 0:03:44 lr 3.128689	time 1.1948 (3.3017)	loss 3.0029 (3.0350)	grad_norm 0.3745 (0.3943)	mem 39782MB
[2023-07-07 13:04:03 RepVGG-A0] (main.py 282): INFO Train: [152/300][20/78]	eta 0:02:22 lr 3.124394	time 1.1716 (2.4533)	loss 3.0820 (3.0265)	grad_norm 0.4298 (0.3839)	mem 39782MB
[2023-07-07 13:04:18 RepVGG-A0] (main.py 282): INFO Train: [152/300][30/78]	eta 0:01:43 lr 3.120099	time 1.3782 (2.1618)	loss 2.9829 (3.0524)	grad_norm 0.3830 (0.4053)	mem 39782MB
[2023-07-07 13:04:36 RepVGG-A0] (main.py 282): INFO Train: [152/300][40/78]	eta 0:01:18 lr 3.115804	time 3.7332 (2.0659)	loss 3.1446 (3.0576)	grad_norm 0.4093 (0.4006)	mem 39782MB
[2023-07-07 13:04:51 RepVGG-A0] (main.py 282): INFO Train: [152/300][50/78]	eta 0:00:54 lr 3.111510	time 1.1918 (1.9498)	loss 3.1045 (3.0553)	grad_norm 0.3895 (0.3977)	mem 39782MB
[2023-07-07 13:05:06 RepVGG-A0] (main.py 282): INFO Train: [152/300][60/78]	eta 0:00:33 lr 3.107215	time 1.1757 (1.8793)	loss 3.1597 (3.0571)	grad_norm 0.4042 (0.3981)	mem 39782MB
[2023-07-07 13:05:21 RepVGG-A0] (main.py 282): INFO Train: [152/300][70/78]	eta 0:00:14 lr 3.102921	time 1.1764 (1.8318)	loss 3.0071 (3.0564)	grad_norm 0.3651 (0.3966)	mem 39782MB
[2023-07-07 13:05:33 RepVGG-A0] (main.py 291): INFO EPOCH 152 training takes 0:02:21
[2023-07-07 13:05:56 RepVGG-A0] (main.py 282): INFO Train: [153/300][0/78]	eta 0:29:35 lr 3.099486	time 22.7613 (22.7613)	loss 3.0125 (3.0125)	grad_norm 0.3790 (0.3790)	mem 39782MB
[2023-07-07 13:06:10 RepVGG-A0] (main.py 282): INFO Train: [153/300][10/78]	eta 0:03:50 lr 3.095192	time 1.1724 (3.3849)	loss 3.0442 (3.0277)	grad_norm 0.4287 (0.4123)	mem 39782MB
[2023-07-07 13:06:25 RepVGG-A0] (main.py 282): INFO Train: [153/300][20/78]	eta 0:02:24 lr 3.090898	time 1.3320 (2.4873)	loss 3.0451 (3.0199)	grad_norm 0.4022 (0.4028)	mem 39782MB
[2023-07-07 13:06:40 RepVGG-A0] (main.py 282): INFO Train: [153/300][30/78]	eta 0:01:43 lr 3.086604	time 1.3842 (2.1590)	loss 2.9944 (3.0298)	grad_norm 0.3835 (0.4120)	mem 39782MB
[2023-07-07 13:06:59 RepVGG-A0] (main.py 282): INFO Train: [153/300][40/78]	eta 0:01:19 lr 3.082311	time 3.3167 (2.0814)	loss 3.0887 (3.0254)	grad_norm 0.3912 (0.4003)	mem 39782MB
[2023-07-07 13:07:13 RepVGG-A0] (main.py 282): INFO Train: [153/300][50/78]	eta 0:00:55 lr 3.078018	time 1.1924 (1.9644)	loss 3.0664 (3.0300)	grad_norm 0.4246 (0.4045)	mem 39782MB
[2023-07-07 13:07:29 RepVGG-A0] (main.py 282): INFO Train: [153/300][60/78]	eta 0:00:34 lr 3.073725	time 1.2599 (1.8920)	loss 3.0133 (3.0321)	grad_norm 0.4018 (0.4046)	mem 39782MB
[2023-07-07 13:07:45 RepVGG-A0] (main.py 282): INFO Train: [153/300][70/78]	eta 0:00:14 lr 3.069432	time 1.1724 (1.8514)	loss 2.9993 (3.0288)	grad_norm 0.3880 (0.4005)	mem 39782MB
[2023-07-07 13:07:55 RepVGG-A0] (main.py 291): INFO EPOCH 153 training takes 0:02:22
[2023-07-07 13:08:18 RepVGG-A0] (main.py 282): INFO Train: [154/300][0/78]	eta 0:29:03 lr 3.065998	time 22.3528 (22.3528)	loss 2.9897 (2.9897)	grad_norm 0.4179 (0.4179)	mem 39782MB
[2023-07-07 13:08:32 RepVGG-A0] (main.py 282): INFO Train: [154/300][10/78]	eta 0:03:48 lr 3.061706	time 1.1971 (3.3642)	loss 2.9819 (3.0005)	grad_norm 0.3944 (0.4052)	mem 39782MB
[2023-07-07 13:08:47 RepVGG-A0] (main.py 282): INFO Train: [154/300][20/78]	eta 0:02:23 lr 3.057414	time 1.1868 (2.4733)	loss 3.0096 (3.0076)	grad_norm 0.3801 (0.4055)	mem 39782MB
[2023-07-07 13:09:03 RepVGG-A0] (main.py 282): INFO Train: [154/300][30/78]	eta 0:01:44 lr 3.053122	time 1.5881 (2.1772)	loss 3.0075 (3.0147)	grad_norm 0.4335 (0.4096)	mem 39782MB
[2023-07-07 13:09:21 RepVGG-A0] (main.py 282): INFO Train: [154/300][40/78]	eta 0:01:18 lr 3.048830	time 2.9882 (2.0771)	loss 3.0463 (3.0277)	grad_norm 0.3554 (0.4097)	mem 39782MB
[2023-07-07 13:09:36 RepVGG-A0] (main.py 282): INFO Train: [154/300][50/78]	eta 0:00:55 lr 3.044539	time 1.5848 (1.9672)	loss 2.9626 (3.0271)	grad_norm 0.3664 (0.4070)	mem 39782MB
[2023-07-07 13:09:51 RepVGG-A0] (main.py 282): INFO Train: [154/300][60/78]	eta 0:00:34 lr 3.040248	time 1.2044 (1.8909)	loss 3.0717 (3.0303)	grad_norm 0.4155 (0.4075)	mem 39782MB
[2023-07-07 13:10:06 RepVGG-A0] (main.py 282): INFO Train: [154/300][70/78]	eta 0:00:14 lr 3.035957	time 1.3593 (1.8408)	loss 3.0358 (3.0292)	grad_norm 0.4036 (0.4070)	mem 39782MB
[2023-07-07 13:10:18 RepVGG-A0] (main.py 291): INFO EPOCH 154 training takes 0:02:22
[2023-07-07 13:10:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][0/78]	eta 0:28:07 lr 3.032525	time 21.6379 (21.6379)	loss 2.9148 (2.9148)	grad_norm 0.3518 (0.3518)	mem 39782MB
[2023-07-07 13:10:54 RepVGG-A0] (main.py 282): INFO Train: [155/300][10/78]	eta 0:03:45 lr 3.028235	time 1.1724 (3.3150)	loss 3.7514 (3.1508)	grad_norm 1.1281 (0.5835)	mem 39782MB
[2023-07-07 13:11:08 RepVGG-A0] (main.py 282): INFO Train: [155/300][20/78]	eta 0:02:17 lr 3.023945	time 1.1716 (2.3709)	loss 5.7170 (4.3670)	grad_norm 0.5419 (0.8188)	mem 39782MB
[2023-07-07 13:11:22 RepVGG-A0] (main.py 282): INFO Train: [155/300][30/78]	eta 0:01:39 lr 3.019655	time 1.2107 (2.0719)	loss 4.5317 (4.5558)	grad_norm 0.3827 (0.6999)	mem 39782MB
[2023-07-07 13:11:40 RepVGG-A0] (main.py 282): INFO Train: [155/300][40/78]	eta 0:01:15 lr 3.015366	time 3.0118 (1.9976)	loss 4.0833 (4.4827)	grad_norm 0.3370 (0.6117)	mem 39782MB
[2023-07-07 13:11:56 RepVGG-A0] (main.py 282): INFO Train: [155/300][50/78]	eta 0:00:53 lr 3.011077	time 1.1770 (1.9161)	loss 3.8810 (4.3720)	grad_norm 0.4179 (0.5589)	mem 39782MB
[2023-07-07 13:12:11 RepVGG-A0] (main.py 282): INFO Train: [155/300][60/78]	eta 0:00:33 lr 3.006789	time 1.1787 (1.8465)	loss 3.6282 (4.2606)	grad_norm 0.2972 (0.5206)	mem 39782MB
[2023-07-07 13:12:26 RepVGG-A0] (main.py 282): INFO Train: [155/300][70/78]	eta 0:00:14 lr 3.002501	time 1.3035 (1.8071)	loss 3.4198 (4.1608)	grad_norm 0.3013 (0.4941)	mem 39782MB
[2023-07-07 13:12:38 RepVGG-A0] (main.py 291): INFO EPOCH 155 training takes 0:02:19
[2023-07-07 13:12:59 RepVGG-A0] (main.py 282): INFO Train: [156/300][0/78]	eta 0:27:22 lr 2.999070	time 21.0563 (21.0563)	loss 3.4893 (3.4893)	grad_norm 0.3452 (0.3452)	mem 39782MB
[2023-07-07 13:13:16 RepVGG-A0] (main.py 282): INFO Train: [156/300][10/78]	eta 0:03:53 lr 2.994783	time 1.1722 (3.4287)	loss 3.3637 (3.3875)	grad_norm 0.3327 (0.3296)	mem 39782MB
[2023-07-07 13:13:30 RepVGG-A0] (main.py 282): INFO Train: [156/300][20/78]	eta 0:02:24 lr 2.990496	time 1.2143 (2.4847)	loss 3.2774 (3.3684)	grad_norm 0.3448 (0.3362)	mem 39782MB
[2023-07-07 13:13:46 RepVGG-A0] (main.py 282): INFO Train: [156/300][30/78]	eta 0:01:44 lr 2.986209	time 1.4927 (2.1826)	loss 3.2759 (3.3475)	grad_norm 0.3727 (0.3414)	mem 39782MB
[2023-07-07 13:14:03 RepVGG-A0] (main.py 282): INFO Train: [156/300][40/78]	eta 0:01:18 lr 2.981922	time 3.2028 (2.0736)	loss 3.1893 (3.3367)	grad_norm 0.3332 (0.3497)	mem 39782MB
[2023-07-07 13:14:18 RepVGG-A0] (main.py 282): INFO Train: [156/300][50/78]	eta 0:00:55 lr 2.977636	time 1.1782 (1.9715)	loss 3.2287 (3.3166)	grad_norm 0.3488 (0.3481)	mem 39782MB
[2023-07-07 13:14:34 RepVGG-A0] (main.py 282): INFO Train: [156/300][60/78]	eta 0:00:34 lr 2.973351	time 1.3798 (1.9111)	loss 3.2036 (3.3056)	grad_norm 0.3679 (0.3528)	mem 39782MB
[2023-07-07 13:14:49 RepVGG-A0] (main.py 282): INFO Train: [156/300][70/78]	eta 0:00:14 lr 2.969066	time 1.3969 (1.8543)	loss 3.1694 (3.2943)	grad_norm 0.3609 (0.3550)	mem 39782MB
[2023-07-07 13:15:02 RepVGG-A0] (main.py 291): INFO EPOCH 156 training takes 0:02:23
[2023-07-07 13:15:23 RepVGG-A0] (main.py 282): INFO Train: [157/300][0/78]	eta 0:28:23 lr 2.965638	time 21.8454 (21.8454)	loss 3.1868 (3.1868)	grad_norm 0.3462 (0.3462)	mem 39782MB
[2023-07-07 13:15:38 RepVGG-A0] (main.py 282): INFO Train: [157/300][10/78]	eta 0:03:46 lr 2.961353	time 1.1725 (3.3349)	loss 3.1957 (3.1656)	grad_norm 0.3874 (0.3658)	mem 39782MB
[2023-07-07 13:15:52 RepVGG-A0] (main.py 282): INFO Train: [157/300][20/78]	eta 0:02:18 lr 2.957069	time 1.1748 (2.3854)	loss 3.1176 (3.1777)	grad_norm 0.3753 (0.3879)	mem 39782MB
[2023-07-07 13:16:09 RepVGG-A0] (main.py 282): INFO Train: [157/300][30/78]	eta 0:01:43 lr 2.952786	time 1.4503 (2.1599)	loss 3.1543 (3.1712)	grad_norm 0.3456 (0.3768)	mem 39782MB
[2023-07-07 13:16:26 RepVGG-A0] (main.py 282): INFO Train: [157/300][40/78]	eta 0:01:18 lr 2.948503	time 4.8373 (2.0630)	loss 3.2090 (3.1656)	grad_norm 0.3783 (0.3821)	mem 39782MB
[2023-07-07 13:16:41 RepVGG-A0] (main.py 282): INFO Train: [157/300][50/78]	eta 0:00:54 lr 2.944220	time 1.2475 (1.9543)	loss 3.0580 (3.1536)	grad_norm 0.4047 (0.3796)	mem 39782MB
[2023-07-07 13:16:57 RepVGG-A0] (main.py 282): INFO Train: [157/300][60/78]	eta 0:00:33 lr 2.939938	time 1.2567 (1.8862)	loss 3.1478 (3.1528)	grad_norm 0.4442 (0.3806)	mem 39782MB
[2023-07-07 13:17:10 RepVGG-A0] (main.py 282): INFO Train: [157/300][70/78]	eta 0:00:14 lr 2.935656	time 1.3759 (1.8117)	loss 3.1966 (3.1555)	grad_norm 0.3872 (0.3874)	mem 39782MB
[2023-07-07 13:17:23 RepVGG-A0] (main.py 291): INFO EPOCH 157 training takes 0:02:21
[2023-07-07 13:17:45 RepVGG-A0] (main.py 282): INFO Train: [158/300][0/78]	eta 0:28:50 lr 2.932231	time 22.1892 (22.1892)	loss 3.0976 (3.0976)	grad_norm 0.3878 (0.3878)	mem 39782MB
[2023-07-07 13:17:59 RepVGG-A0] (main.py 282): INFO Train: [158/300][10/78]	eta 0:03:46 lr 2.927950	time 1.1713 (3.3302)	loss 3.0108 (3.0383)	grad_norm 0.3798 (0.3710)	mem 39782MB
[2023-07-07 13:18:13 RepVGG-A0] (main.py 282): INFO Train: [158/300][20/78]	eta 0:02:19 lr 2.923670	time 1.1753 (2.4111)	loss 3.0271 (3.0504)	grad_norm 0.3635 (0.3752)	mem 39782MB
[2023-07-07 13:18:29 RepVGG-A0] (main.py 282): INFO Train: [158/300][30/78]	eta 0:01:42 lr 2.919390	time 1.4017 (2.1436)	loss 3.1372 (3.0648)	grad_norm 0.3642 (0.3777)	mem 39782MB
[2023-07-07 13:18:48 RepVGG-A0] (main.py 282): INFO Train: [158/300][40/78]	eta 0:01:19 lr 2.915110	time 4.1358 (2.0844)	loss 3.1394 (3.0694)	grad_norm 0.4779 (0.3854)	mem 39782MB
[2023-07-07 13:19:03 RepVGG-A0] (main.py 282): INFO Train: [158/300][50/78]	eta 0:00:55 lr 2.910831	time 1.1692 (1.9654)	loss 3.0017 (3.0775)	grad_norm 0.4053 (0.3954)	mem 39782MB
[2023-07-07 13:19:18 RepVGG-A0] (main.py 282): INFO Train: [158/300][60/78]	eta 0:00:33 lr 2.906553	time 1.1786 (1.8888)	loss 3.1317 (3.0844)	grad_norm 0.4078 (0.3960)	mem 39782MB
[2023-07-07 13:19:33 RepVGG-A0] (main.py 282): INFO Train: [158/300][70/78]	eta 0:00:14 lr 2.902275	time 1.2604 (1.8283)	loss 3.0912 (3.0860)	grad_norm 0.4382 (0.3976)	mem 39782MB
[2023-07-07 13:19:44 RepVGG-A0] (main.py 291): INFO EPOCH 158 training takes 0:02:21
[2023-07-07 13:20:07 RepVGG-A0] (main.py 282): INFO Train: [159/300][0/78]	eta 0:29:50 lr 2.898853	time 22.9502 (22.9502)	loss 3.0108 (3.0108)	grad_norm 0.3711 (0.3711)	mem 39782MB
[2023-07-07 13:20:21 RepVGG-A0] (main.py 282): INFO Train: [159/300][10/78]	eta 0:03:48 lr 2.894577	time 1.1717 (3.3558)	loss 2.9970 (3.0318)	grad_norm 0.3875 (0.3844)	mem 39782MB
[2023-07-07 13:20:35 RepVGG-A0] (main.py 282): INFO Train: [159/300][20/78]	eta 0:02:20 lr 2.890300	time 1.1989 (2.4281)	loss 3.2691 (3.0657)	grad_norm 0.5703 (0.4232)	mem 39782MB
[2023-07-07 13:20:49 RepVGG-A0] (main.py 282): INFO Train: [159/300][30/78]	eta 0:01:41 lr 2.886024	time 1.2389 (2.1111)	loss 3.1239 (3.0749)	grad_norm 0.3473 (0.4154)	mem 39782MB
[2023-07-07 13:21:08 RepVGG-A0] (main.py 282): INFO Train: [159/300][40/78]	eta 0:01:17 lr 2.881749	time 3.8824 (2.0460)	loss 3.0752 (3.0696)	grad_norm 0.4536 (0.4129)	mem 39782MB
[2023-07-07 13:21:23 RepVGG-A0] (main.py 282): INFO Train: [159/300][50/78]	eta 0:00:54 lr 2.877475	time 1.1730 (1.9431)	loss 2.9999 (3.0682)	grad_norm 0.3559 (0.4114)	mem 39782MB
[2023-07-07 13:21:39 RepVGG-A0] (main.py 282): INFO Train: [159/300][60/78]	eta 0:00:34 lr 2.873201	time 1.4547 (1.8895)	loss 3.0451 (3.0640)	grad_norm 0.3696 (0.4046)	mem 39782MB
[2023-07-07 13:21:54 RepVGG-A0] (main.py 282): INFO Train: [159/300][70/78]	eta 0:00:14 lr 2.868927	time 1.3166 (1.8346)	loss 3.1131 (3.0622)	grad_norm 0.3634 (0.4023)	mem 39782MB
[2023-07-07 13:22:06 RepVGG-A0] (main.py 291): INFO EPOCH 159 training takes 0:02:22
[2023-07-07 13:22:28 RepVGG-A0] (main.py 282): INFO Train: [160/300][0/78]	eta 0:28:48 lr 2.865509	time 22.1640 (22.1640)	loss 3.0057 (3.0057)	grad_norm 0.3670 (0.3670)	mem 39782MB
[2023-07-07 13:22:43 RepVGG-A0] (main.py 282): INFO Train: [160/300][10/78]	eta 0:03:47 lr 2.861237	time 1.1720 (3.3507)	loss 3.1562 (3.0445)	grad_norm 0.4970 (0.4653)	mem 39782MB
[2023-07-07 13:22:58 RepVGG-A0] (main.py 282): INFO Train: [160/300][20/78]	eta 0:02:23 lr 2.856965	time 1.1784 (2.4682)	loss 3.0287 (3.0268)	grad_norm 0.3629 (0.4239)	mem 39782MB
[2023-07-07 13:23:14 RepVGG-A0] (main.py 282): INFO Train: [160/300][30/78]	eta 0:01:45 lr 2.852694	time 1.8111 (2.1896)	loss 3.0248 (3.0157)	grad_norm 0.4084 (0.4091)	mem 39782MB
[2023-07-07 13:23:31 RepVGG-A0] (main.py 282): INFO Train: [160/300][40/78]	eta 0:01:18 lr 2.848423	time 3.1540 (2.0677)	loss 3.0170 (3.0224)	grad_norm 0.3805 (0.4102)	mem 39782MB
[2023-07-07 13:23:47 RepVGG-A0] (main.py 282): INFO Train: [160/300][50/78]	eta 0:00:55 lr 2.844153	time 1.1785 (1.9677)	loss 2.9829 (3.0227)	grad_norm 0.3968 (0.4078)	mem 39782MB
[2023-07-07 13:24:01 RepVGG-A0] (main.py 282): INFO Train: [160/300][60/78]	eta 0:00:33 lr 2.839884	time 1.2819 (1.8781)	loss 2.9783 (3.0253)	grad_norm 0.3754 (0.4087)	mem 39782MB
[2023-07-07 13:24:17 RepVGG-A0] (main.py 282): INFO Train: [160/300][70/78]	eta 0:00:14 lr 2.835616	time 1.4101 (1.8393)	loss 3.0339 (3.0381)	grad_norm 0.3880 (0.4187)	mem 39782MB
[2023-07-07 13:24:29 RepVGG-A0] (main.py 291): INFO EPOCH 160 training takes 0:02:22
[2023-07-07 13:24:47 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 18.228 (18.228)	Loss 2.4704 (2.4704)	Acc@1 47.650 (47.650)	Acc@5 72.766 (72.766)	Mem 39782MB
[2023-07-07 13:24:48 RepVGG-A0] (main.py 342): INFO  * Acc@1 48.562 Acc@5 72.958
[2023-07-07 13:24:48 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 160: 48.562%
[2023-07-07 13:24:48 RepVGG-A0] (main.py 172): INFO Max accuracy: 48.56%
[2023-07-07 13:25:09 RepVGG-A0] (main.py 282): INFO Train: [161/300][0/78]	eta 0:27:22 lr 2.832201	time 21.0546 (21.0546)	loss 2.9715 (2.9715)	grad_norm 0.3735 (0.3735)	mem 39782MB
[2023-07-07 13:25:26 RepVGG-A0] (main.py 282): INFO Train: [161/300][10/78]	eta 0:03:52 lr 2.827934	time 1.1719 (3.4248)	loss 2.9972 (2.9753)	grad_norm 0.4074 (0.3967)	mem 39782MB
[2023-07-07 13:25:40 RepVGG-A0] (main.py 282): INFO Train: [161/300][20/78]	eta 0:02:24 lr 2.823667	time 1.2268 (2.4913)	loss 3.0113 (2.9879)	grad_norm 0.4197 (0.4031)	mem 39782MB
[2023-07-07 13:25:55 RepVGG-A0] (main.py 282): INFO Train: [161/300][30/78]	eta 0:01:44 lr 2.819401	time 1.4183 (2.1720)	loss 2.9643 (2.9865)	grad_norm 0.3911 (0.3961)	mem 39782MB
[2023-07-07 13:26:13 RepVGG-A0] (main.py 282): INFO Train: [161/300][40/78]	eta 0:01:18 lr 2.815136	time 3.3550 (2.0604)	loss 3.0424 (2.9889)	grad_norm 0.4257 (0.3975)	mem 39782MB
[2023-07-07 13:26:28 RepVGG-A0] (main.py 282): INFO Train: [161/300][50/78]	eta 0:00:54 lr 2.810871	time 1.2949 (1.9536)	loss 3.0127 (2.9989)	grad_norm 0.4067 (0.4060)	mem 39782MB
[2023-07-07 13:26:43 RepVGG-A0] (main.py 282): INFO Train: [161/300][60/78]	eta 0:00:33 lr 2.806607	time 1.1730 (1.8776)	loss 3.0563 (3.0031)	grad_norm 0.4276 (0.4064)	mem 39782MB
[2023-07-07 13:26:58 RepVGG-A0] (main.py 282): INFO Train: [161/300][70/78]	eta 0:00:14 lr 2.802344	time 1.2442 (1.8309)	loss 3.0590 (3.0059)	grad_norm 0.3827 (0.4061)	mem 39782MB
[2023-07-07 13:27:09 RepVGG-A0] (main.py 291): INFO EPOCH 161 training takes 0:02:21
[2023-07-07 13:27:29 RepVGG-A0] (main.py 282): INFO Train: [162/300][0/78]	eta 0:26:10 lr 2.798934	time 20.1343 (20.1343)	loss 3.0214 (3.0214)	grad_norm 0.4832 (0.4832)	mem 39782MB
[2023-07-07 13:27:45 RepVGG-A0] (main.py 282): INFO Train: [162/300][10/78]	eta 0:03:38 lr 2.794672	time 1.1703 (3.2186)	loss 3.0213 (2.9790)	grad_norm 0.4627 (0.4106)	mem 39782MB
[2023-07-07 13:28:00 RepVGG-A0] (main.py 282): INFO Train: [162/300][20/78]	eta 0:02:21 lr 2.790410	time 1.3509 (2.4358)	loss 2.9988 (2.9719)	grad_norm 0.4551 (0.4074)	mem 39782MB
[2023-07-07 13:28:14 RepVGG-A0] (main.py 282): INFO Train: [162/300][30/78]	eta 0:01:40 lr 2.786150	time 1.1974 (2.0972)	loss 2.9620 (2.9785)	grad_norm 0.3686 (0.4090)	mem 39782MB
[2023-07-07 13:28:33 RepVGG-A0] (main.py 282): INFO Train: [162/300][40/78]	eta 0:01:17 lr 2.781890	time 3.7922 (2.0354)	loss 3.0857 (2.9827)	grad_norm 0.5544 (0.4113)	mem 39782MB
[2023-07-07 13:28:48 RepVGG-A0] (main.py 282): INFO Train: [162/300][50/78]	eta 0:00:54 lr 2.777631	time 1.2722 (1.9385)	loss 6.2870 (3.2330)	grad_norm 1.1968 (0.5421)	mem 39782MB
[2023-07-07 13:29:04 RepVGG-A0] (main.py 282): INFO Train: [162/300][60/78]	eta 0:00:33 lr 2.773373	time 1.1736 (1.8728)	loss 5.0131 (3.5981)	grad_norm 0.6170 (0.5680)	mem 39782MB
[2023-07-07 13:29:19 RepVGG-A0] (main.py 282): INFO Train: [162/300][70/78]	eta 0:00:14 lr 2.769116	time 1.4132 (1.8266)	loss 4.1180 (3.7085)	grad_norm 0.4402 (0.5401)	mem 39782MB
[2023-07-07 13:29:31 RepVGG-A0] (main.py 291): INFO EPOCH 162 training takes 0:02:21
[2023-07-07 13:29:53 RepVGG-A0] (main.py 282): INFO Train: [163/300][0/78]	eta 0:29:06 lr 2.765710	time 22.3918 (22.3918)	loss 3.8139 (3.8139)	grad_norm 0.3159 (0.3159)	mem 39782MB
[2023-07-07 13:30:07 RepVGG-A0] (main.py 282): INFO Train: [163/300][10/78]	eta 0:03:41 lr 2.761454	time 1.1935 (3.2555)	loss 3.6103 (3.6809)	grad_norm 0.3559 (0.3428)	mem 39782MB
[2023-07-07 13:30:21 RepVGG-A0] (main.py 282): INFO Train: [163/300][20/78]	eta 0:02:17 lr 2.757199	time 1.1728 (2.3711)	loss 3.4559 (3.6049)	grad_norm 0.3433 (0.3434)	mem 39782MB
[2023-07-07 13:30:36 RepVGG-A0] (main.py 282): INFO Train: [163/300][30/78]	eta 0:01:41 lr 2.752944	time 1.5326 (2.1081)	loss 3.3584 (3.5453)	grad_norm 0.3365 (0.3408)	mem 39782MB
[2023-07-07 13:30:54 RepVGG-A0] (main.py 282): INFO Train: [163/300][40/78]	eta 0:01:16 lr 2.748691	time 3.6561 (2.0163)	loss 3.2603 (3.4908)	grad_norm 0.3382 (0.3436)	mem 39782MB
[2023-07-07 13:31:09 RepVGG-A0] (main.py 282): INFO Train: [163/300][50/78]	eta 0:00:53 lr 2.744438	time 1.1728 (1.9279)	loss 3.2294 (3.4543)	grad_norm 0.3159 (0.3447)	mem 39782MB
[2023-07-07 13:31:24 RepVGG-A0] (main.py 282): INFO Train: [163/300][60/78]	eta 0:00:33 lr 2.740186	time 1.3223 (1.8569)	loss 3.3042 (3.4206)	grad_norm 0.4374 (0.3462)	mem 39782MB
[2023-07-07 13:31:40 RepVGG-A0] (main.py 282): INFO Train: [163/300][70/78]	eta 0:00:14 lr 2.735935	time 1.7522 (1.8150)	loss 3.1631 (3.3948)	grad_norm 0.4030 (0.3485)	mem 39782MB
[2023-07-07 13:31:51 RepVGG-A0] (main.py 291): INFO EPOCH 163 training takes 0:02:20
[2023-07-07 13:32:12 RepVGG-A0] (main.py 282): INFO Train: [164/300][0/78]	eta 0:27:05 lr 2.732534	time 20.8355 (20.8355)	loss 3.1620 (3.1620)	grad_norm 0.3957 (0.3957)	mem 39782MB
[2023-07-07 13:32:28 RepVGG-A0] (main.py 282): INFO Train: [164/300][10/78]	eta 0:03:44 lr 2.728285	time 1.1896 (3.3046)	loss 3.1576 (3.1542)	grad_norm 0.3385 (0.3550)	mem 39782MB
[2023-07-07 13:32:43 RepVGG-A0] (main.py 282): INFO Train: [164/300][20/78]	eta 0:02:22 lr 2.724036	time 1.2757 (2.4567)	loss 3.2090 (3.1392)	grad_norm 0.4180 (0.3588)	mem 39782MB
[2023-07-07 13:32:58 RepVGG-A0] (main.py 282): INFO Train: [164/300][30/78]	eta 0:01:43 lr 2.719788	time 1.3885 (2.1631)	loss 3.1256 (3.1423)	grad_norm 0.3496 (0.3657)	mem 39782MB
[2023-07-07 13:33:15 RepVGG-A0] (main.py 282): INFO Train: [164/300][40/78]	eta 0:01:17 lr 2.715541	time 2.7658 (2.0427)	loss 3.0779 (3.1341)	grad_norm 0.3559 (0.3653)	mem 39782MB
[2023-07-07 13:33:30 RepVGG-A0] (main.py 282): INFO Train: [164/300][50/78]	eta 0:00:53 lr 2.711294	time 1.1723 (1.9269)	loss 3.0959 (3.1289)	grad_norm 0.3679 (0.3675)	mem 39782MB
[2023-07-07 13:33:45 RepVGG-A0] (main.py 282): INFO Train: [164/300][60/78]	eta 0:00:33 lr 2.707049	time 1.2877 (1.8685)	loss 3.1053 (3.1341)	grad_norm 0.3913 (0.3753)	mem 39782MB
[2023-07-07 13:34:01 RepVGG-A0] (main.py 282): INFO Train: [164/300][70/78]	eta 0:00:14 lr 2.702805	time 1.3360 (1.8226)	loss 3.1438 (3.1300)	grad_norm 0.3562 (0.3726)	mem 39782MB
[2023-07-07 13:34:13 RepVGG-A0] (main.py 291): INFO EPOCH 164 training takes 0:02:21
[2023-07-07 13:34:33 RepVGG-A0] (main.py 282): INFO Train: [165/300][0/78]	eta 0:27:01 lr 2.699410	time 20.7938 (20.7938)	loss 3.0342 (3.0342)	grad_norm 0.4425 (0.4425)	mem 39782MB
[2023-07-07 13:34:48 RepVGG-A0] (main.py 282): INFO Train: [165/300][10/78]	eta 0:03:38 lr 2.695167	time 1.1725 (3.2125)	loss 3.0407 (3.0463)	grad_norm 0.3568 (0.3907)	mem 39782MB
[2023-07-07 13:35:02 RepVGG-A0] (main.py 282): INFO Train: [165/300][20/78]	eta 0:02:16 lr 2.690925	time 1.1719 (2.3586)	loss 3.0715 (3.0496)	grad_norm 0.4137 (0.3881)	mem 39782MB
[2023-07-07 13:35:18 RepVGG-A0] (main.py 282): INFO Train: [165/300][30/78]	eta 0:01:40 lr 2.686684	time 1.3207 (2.1027)	loss 3.0180 (3.0415)	grad_norm 0.3612 (0.3808)	mem 39782MB
[2023-07-07 13:35:37 RepVGG-A0] (main.py 282): INFO Train: [165/300][40/78]	eta 0:01:17 lr 2.682444	time 4.1871 (2.0468)	loss 3.2472 (3.0532)	grad_norm 0.5732 (0.3978)	mem 39782MB
[2023-07-07 13:35:51 RepVGG-A0] (main.py 282): INFO Train: [165/300][50/78]	eta 0:00:54 lr 2.678205	time 1.1531 (1.9292)	loss 3.0419 (3.0681)	grad_norm 0.3507 (0.4036)	mem 39782MB
[2023-07-07 13:36:06 RepVGG-A0] (main.py 282): INFO Train: [165/300][60/78]	eta 0:00:33 lr 2.673966	time 1.2540 (1.8650)	loss 3.0511 (3.0657)	grad_norm 0.3515 (0.3972)	mem 39782MB
[2023-07-07 13:36:22 RepVGG-A0] (main.py 282): INFO Train: [165/300][70/78]	eta 0:00:14 lr 2.669729	time 1.3323 (1.8190)	loss 3.0310 (3.0621)	grad_norm 0.3679 (0.3942)	mem 39782MB
[2023-07-07 13:36:34 RepVGG-A0] (main.py 291): INFO EPOCH 165 training takes 0:02:21
[2023-07-07 13:36:55 RepVGG-A0] (main.py 282): INFO Train: [166/300][0/78]	eta 0:27:20 lr 2.666340	time 21.0293 (21.0293)	loss 3.0028 (3.0028)	grad_norm 0.3898 (0.3898)	mem 39782MB
[2023-07-07 13:37:11 RepVGG-A0] (main.py 282): INFO Train: [166/300][10/78]	eta 0:03:49 lr 2.662104	time 1.1932 (3.3769)	loss 2.9672 (3.0199)	grad_norm 0.3915 (0.4194)	mem 39782MB
[2023-07-07 13:37:26 RepVGG-A0] (main.py 282): INFO Train: [166/300][20/78]	eta 0:02:23 lr 2.657870	time 1.1750 (2.4798)	loss 2.9487 (3.0127)	grad_norm 0.4045 (0.4189)	mem 39782MB
[2023-07-07 13:37:41 RepVGG-A0] (main.py 282): INFO Train: [166/300][30/78]	eta 0:01:43 lr 2.653636	time 1.2215 (2.1662)	loss 2.9465 (3.0087)	grad_norm 0.4185 (0.4064)	mem 39782MB
[2023-07-07 13:37:59 RepVGG-A0] (main.py 282): INFO Train: [166/300][40/78]	eta 0:01:19 lr 2.649404	time 4.1561 (2.0808)	loss 3.0193 (3.0123)	grad_norm 0.3645 (0.4017)	mem 39782MB
[2023-07-07 13:38:14 RepVGG-A0] (main.py 282): INFO Train: [166/300][50/78]	eta 0:00:55 lr 2.645172	time 1.1963 (1.9700)	loss 3.0872 (3.0130)	grad_norm 0.3789 (0.4005)	mem 39782MB
[2023-07-07 13:38:30 RepVGG-A0] (main.py 282): INFO Train: [166/300][60/78]	eta 0:00:34 lr 2.640941	time 1.4308 (1.8979)	loss 3.0147 (3.0186)	grad_norm 0.4208 (0.4027)	mem 39782MB
[2023-07-07 13:38:45 RepVGG-A0] (main.py 282): INFO Train: [166/300][70/78]	eta 0:00:14 lr 2.636712	time 1.4650 (1.8447)	loss 2.9971 (3.0171)	grad_norm 0.4131 (0.4046)	mem 39782MB
[2023-07-07 13:38:55 RepVGG-A0] (main.py 291): INFO EPOCH 166 training takes 0:02:21
[2023-07-07 13:39:17 RepVGG-A0] (main.py 282): INFO Train: [167/300][0/78]	eta 0:28:40 lr 2.633329	time 22.0577 (22.0577)	loss 3.0467 (3.0467)	grad_norm 0.4661 (0.4661)	mem 39782MB
[2023-07-07 13:39:33 RepVGG-A0] (main.py 282): INFO Train: [167/300][10/78]	eta 0:03:49 lr 2.629101	time 1.1722 (3.3691)	loss 2.9266 (2.9799)	grad_norm 0.4084 (0.4003)	mem 39782MB
[2023-07-07 13:39:47 RepVGG-A0] (main.py 282): INFO Train: [167/300][20/78]	eta 0:02:23 lr 2.624874	time 1.4292 (2.4764)	loss 2.9409 (2.9768)	grad_norm 0.4423 (0.4032)	mem 39782MB
[2023-07-07 13:40:01 RepVGG-A0] (main.py 282): INFO Train: [167/300][30/78]	eta 0:01:42 lr 2.620649	time 1.1783 (2.1256)	loss 2.9301 (2.9836)	grad_norm 0.3657 (0.4048)	mem 39782MB
[2023-07-07 13:40:20 RepVGG-A0] (main.py 282): INFO Train: [167/300][40/78]	eta 0:01:18 lr 2.616424	time 2.2850 (2.0700)	loss 2.9150 (2.9790)	grad_norm 0.3943 (0.3999)	mem 39782MB
[2023-07-07 13:40:35 RepVGG-A0] (main.py 282): INFO Train: [167/300][50/78]	eta 0:00:54 lr 2.612200	time 1.1772 (1.9527)	loss 2.9975 (2.9885)	grad_norm 0.3784 (0.4076)	mem 39782MB
[2023-07-07 13:40:50 RepVGG-A0] (main.py 282): INFO Train: [167/300][60/78]	eta 0:00:33 lr 2.607978	time 1.1882 (1.8836)	loss 3.0480 (2.9929)	grad_norm 0.4593 (0.4087)	mem 39782MB
[2023-07-07 13:41:06 RepVGG-A0] (main.py 282): INFO Train: [167/300][70/78]	eta 0:00:14 lr 2.603756	time 1.4655 (1.8377)	loss 3.0947 (2.9986)	grad_norm 0.4433 (0.4107)	mem 39782MB
[2023-07-07 13:41:17 RepVGG-A0] (main.py 291): INFO EPOCH 167 training takes 0:02:21
[2023-07-07 13:41:38 RepVGG-A0] (main.py 282): INFO Train: [168/300][0/78]	eta 0:28:04 lr 2.600380	time 21.5905 (21.5905)	loss 2.9733 (2.9733)	grad_norm 0.3901 (0.3901)	mem 39782MB
[2023-07-07 13:41:53 RepVGG-A0] (main.py 282): INFO Train: [168/300][10/78]	eta 0:03:45 lr 2.596160	time 1.1722 (3.3113)	loss 3.0093 (2.9519)	grad_norm 0.4271 (0.3940)	mem 39782MB
[2023-07-07 13:42:08 RepVGG-A0] (main.py 282): INFO Train: [168/300][20/78]	eta 0:02:22 lr 2.591942	time 1.1792 (2.4546)	loss 2.9384 (2.9669)	grad_norm 0.4163 (0.4163)	mem 39782MB
[2023-07-07 13:42:24 RepVGG-A0] (main.py 282): INFO Train: [168/300][30/78]	eta 0:01:43 lr 2.587724	time 1.1941 (2.1567)	loss 3.0228 (2.9665)	grad_norm 0.4310 (0.4117)	mem 39782MB
[2023-07-07 13:42:41 RepVGG-A0] (main.py 282): INFO Train: [168/300][40/78]	eta 0:01:17 lr 2.583508	time 3.4542 (2.0513)	loss 2.9363 (2.9688)	grad_norm 0.3683 (0.4127)	mem 39782MB
[2023-07-07 13:42:56 RepVGG-A0] (main.py 282): INFO Train: [168/300][50/78]	eta 0:00:54 lr 2.579293	time 1.1747 (1.9456)	loss 2.9882 (2.9660)	grad_norm 0.4635 (0.4107)	mem 39782MB
[2023-07-07 13:43:12 RepVGG-A0] (main.py 282): INFO Train: [168/300][60/78]	eta 0:00:33 lr 2.575079	time 1.6306 (1.8862)	loss 2.9826 (2.9747)	grad_norm 0.4068 (0.4137)	mem 39782MB
[2023-07-07 13:43:27 RepVGG-A0] (main.py 282): INFO Train: [168/300][70/78]	eta 0:00:14 lr 2.570866	time 1.1748 (1.8376)	loss 2.9671 (2.9742)	grad_norm 0.4133 (0.4139)	mem 39782MB
[2023-07-07 13:43:39 RepVGG-A0] (main.py 291): INFO EPOCH 168 training takes 0:02:21
[2023-07-07 13:43:59 RepVGG-A0] (main.py 282): INFO Train: [169/300][0/78]	eta 0:26:55 lr 2.567497	time 20.7156 (20.7156)	loss 2.9213 (2.9213)	grad_norm 0.3882 (0.3882)	mem 39782MB
[2023-07-07 13:44:15 RepVGG-A0] (main.py 282): INFO Train: [169/300][10/78]	eta 0:03:47 lr 2.563286	time 1.1737 (3.3412)	loss 2.9795 (2.9542)	grad_norm 0.4695 (0.4336)	mem 39782MB
[2023-07-07 13:44:29 RepVGG-A0] (main.py 282): INFO Train: [169/300][20/78]	eta 0:02:18 lr 2.559076	time 1.1704 (2.3939)	loss 2.9242 (2.9480)	grad_norm 0.4118 (0.4210)	mem 39782MB
[2023-07-07 13:44:44 RepVGG-A0] (main.py 282): INFO Train: [169/300][30/78]	eta 0:01:41 lr 2.554867	time 1.3219 (2.1195)	loss 2.9613 (2.9455)	grad_norm 0.4428 (0.4221)	mem 39782MB
[2023-07-07 13:45:02 RepVGG-A0] (main.py 282): INFO Train: [169/300][40/78]	eta 0:01:17 lr 2.550660	time 3.9551 (2.0394)	loss 3.0086 (2.9430)	grad_norm 0.4374 (0.4156)	mem 39782MB
[2023-07-07 13:45:18 RepVGG-A0] (main.py 282): INFO Train: [169/300][50/78]	eta 0:00:54 lr 2.546454	time 1.1739 (1.9513)	loss 2.8930 (2.9496)	grad_norm 0.3932 (0.4165)	mem 39782MB
[2023-07-07 13:45:32 RepVGG-A0] (main.py 282): INFO Train: [169/300][60/78]	eta 0:00:33 lr 2.542249	time 1.1961 (1.8648)	loss 2.9495 (2.9539)	grad_norm 0.4186 (0.4186)	mem 39782MB
[2023-07-07 13:45:48 RepVGG-A0] (main.py 282): INFO Train: [169/300][70/78]	eta 0:00:14 lr 2.538045	time 1.4266 (1.8165)	loss 2.9734 (2.9537)	grad_norm 0.3849 (0.4143)	mem 39782MB
[2023-07-07 13:45:59 RepVGG-A0] (main.py 291): INFO EPOCH 169 training takes 0:02:20
[2023-07-07 13:46:20 RepVGG-A0] (main.py 282): INFO Train: [170/300][0/78]	eta 0:27:40 lr 2.534683	time 21.2900 (21.2900)	loss 2.9509 (2.9509)	grad_norm 0.4632 (0.4632)	mem 39782MB
[2023-07-07 13:46:35 RepVGG-A0] (main.py 282): INFO Train: [170/300][10/78]	eta 0:03:39 lr 2.530481	time 1.1707 (3.2212)	loss 3.0335 (2.9412)	grad_norm 0.4123 (0.4232)	mem 39782MB
[2023-07-07 13:46:49 RepVGG-A0] (main.py 282): INFO Train: [170/300][20/78]	eta 0:02:18 lr 2.526280	time 1.1731 (2.3876)	loss 2.9755 (2.9492)	grad_norm 0.3891 (0.4195)	mem 39782MB
[2023-07-07 13:47:05 RepVGG-A0] (main.py 282): INFO Train: [170/300][30/78]	eta 0:01:42 lr 2.522081	time 1.3040 (2.1287)	loss 2.9232 (2.9403)	grad_norm 0.3868 (0.4124)	mem 39782MB
[2023-07-07 13:47:24 RepVGG-A0] (main.py 282): INFO Train: [170/300][40/78]	eta 0:01:18 lr 2.517883	time 3.9996 (2.0564)	loss 2.9053 (2.9323)	grad_norm 0.4497 (0.4109)	mem 39782MB
[2023-07-07 13:47:38 RepVGG-A0] (main.py 282): INFO Train: [170/300][50/78]	eta 0:00:54 lr 2.513686	time 1.1885 (1.9312)	loss 3.0056 (2.9482)	grad_norm 0.4956 (0.4200)	mem 39782MB
[2023-07-07 13:47:52 RepVGG-A0] (main.py 282): INFO Train: [170/300][60/78]	eta 0:00:33 lr 2.509491	time 1.1875 (1.8545)	loss 2.8867 (2.9515)	grad_norm 0.3695 (0.4194)	mem 39782MB
[2023-07-07 13:48:07 RepVGG-A0] (main.py 282): INFO Train: [170/300][70/78]	eta 0:00:14 lr 2.505296	time 1.1300 (1.8048)	loss 3.0241 (2.9524)	grad_norm 0.4598 (0.4178)	mem 39782MB
[2023-07-07 13:48:19 RepVGG-A0] (main.py 291): INFO EPOCH 170 training takes 0:02:20
[2023-07-07 13:48:41 RepVGG-A0] (main.py 282): INFO Train: [171/300][0/78]	eta 0:28:39 lr 2.501942	time 22.0397 (22.0397)	loss 2.8417 (2.8417)	grad_norm 0.4047 (0.4047)	mem 39782MB
[2023-07-07 13:48:56 RepVGG-A0] (main.py 282): INFO Train: [171/300][10/78]	eta 0:03:45 lr 2.497750	time 1.1728 (3.3171)	loss 2.9196 (2.9087)	grad_norm 0.4071 (0.4257)	mem 39782MB
[2023-07-07 13:49:10 RepVGG-A0] (main.py 282): INFO Train: [171/300][20/78]	eta 0:02:19 lr 2.493559	time 1.3008 (2.4132)	loss 2.9610 (2.9090)	grad_norm 0.4124 (0.4168)	mem 39782MB
[2023-07-07 13:49:26 RepVGG-A0] (main.py 282): INFO Train: [171/300][30/78]	eta 0:01:44 lr 2.489369	time 1.2774 (2.1677)	loss 2.9283 (2.9171)	grad_norm 0.4142 (0.4192)	mem 39782MB
[2023-07-07 13:49:45 RepVGG-A0] (main.py 282): INFO Train: [171/300][40/78]	eta 0:01:19 lr 2.485181	time 3.6405 (2.0988)	loss 2.9542 (2.9251)	grad_norm 0.4302 (0.4287)	mem 39782MB
[2023-07-07 13:50:00 RepVGG-A0] (main.py 282): INFO Train: [171/300][50/78]	eta 0:00:55 lr 2.480994	time 1.1738 (1.9722)	loss 2.8924 (2.9303)	grad_norm 0.4170 (0.4232)	mem 39782MB
[2023-07-07 13:50:15 RepVGG-A0] (main.py 282): INFO Train: [171/300][60/78]	eta 0:00:34 lr 2.476808	time 1.2737 (1.9006)	loss 2.9668 (2.9337)	grad_norm 0.4056 (0.4211)	mem 39782MB
[2023-07-07 13:50:31 RepVGG-A0] (main.py 282): INFO Train: [171/300][70/78]	eta 0:00:14 lr 2.472624	time 1.1372 (1.8485)	loss 2.8454 (2.9301)	grad_norm 0.3904 (0.4189)	mem 39782MB
[2023-07-07 13:50:42 RepVGG-A0] (main.py 291): INFO EPOCH 171 training takes 0:02:22
[2023-07-07 13:51:02 RepVGG-A0] (main.py 282): INFO Train: [172/300][0/78]	eta 0:26:09 lr 2.469277	time 20.1229 (20.1229)	loss 2.9182 (2.9182)	grad_norm 0.4223 (0.4223)	mem 39782MB
[2023-07-07 13:51:18 RepVGG-A0] (main.py 282): INFO Train: [172/300][10/78]	eta 0:03:46 lr 2.465095	time 1.1900 (3.3235)	loss 2.8045 (2.8834)	grad_norm 0.3867 (0.4099)	mem 39782MB
[2023-07-07 13:51:32 RepVGG-A0] (main.py 282): INFO Train: [172/300][20/78]	eta 0:02:18 lr 2.460914	time 1.1732 (2.3963)	loss 2.9687 (2.8906)	grad_norm 0.4396 (0.4193)	mem 39782MB
[2023-07-07 13:51:48 RepVGG-A0] (main.py 282): INFO Train: [172/300][30/78]	eta 0:01:42 lr 2.456735	time 1.4068 (2.1252)	loss 2.8849 (2.8992)	grad_norm 0.4349 (0.4197)	mem 39782MB
[2023-07-07 13:52:04 RepVGG-A0] (main.py 282): INFO Train: [172/300][40/78]	eta 0:01:16 lr 2.452557	time 2.0514 (2.0027)	loss 2.9012 (2.9081)	grad_norm 0.4100 (0.4195)	mem 39782MB
[2023-07-07 13:52:19 RepVGG-A0] (main.py 282): INFO Train: [172/300][50/78]	eta 0:00:53 lr 2.448380	time 1.6169 (1.8996)	loss 2.9312 (2.9094)	grad_norm 0.4344 (0.4189)	mem 39782MB
[2023-07-07 13:52:35 RepVGG-A0] (main.py 282): INFO Train: [172/300][60/78]	eta 0:00:33 lr 2.444205	time 1.3509 (1.8547)	loss 2.9436 (2.9153)	grad_norm 0.3808 (0.4183)	mem 39782MB
[2023-07-07 13:52:50 RepVGG-A0] (main.py 282): INFO Train: [172/300][70/78]	eta 0:00:14 lr 2.440031	time 1.3010 (1.8091)	loss 3.0466 (2.9198)	grad_norm 0.5303 (0.4188)	mem 39782MB
[2023-07-07 13:53:02 RepVGG-A0] (main.py 291): INFO EPOCH 172 training takes 0:02:20
[2023-07-07 13:53:23 RepVGG-A0] (main.py 282): INFO Train: [173/300][0/78]	eta 0:26:57 lr 2.436693	time 20.7381 (20.7381)	loss 3.0430 (3.0430)	grad_norm 0.5914 (0.5914)	mem 39782MB
[2023-07-07 13:53:37 RepVGG-A0] (main.py 282): INFO Train: [173/300][10/78]	eta 0:03:40 lr 2.432521	time 1.1725 (3.2441)	loss 2.9783 (3.0157)	grad_norm 0.3664 (0.4833)	mem 39782MB
[2023-07-07 13:53:52 RepVGG-A0] (main.py 282): INFO Train: [173/300][20/78]	eta 0:02:18 lr 2.428351	time 1.2070 (2.3892)	loss 2.9246 (2.9616)	grad_norm 0.3851 (0.4326)	mem 39782MB
[2023-07-07 13:54:07 RepVGG-A0] (main.py 282): INFO Train: [173/300][30/78]	eta 0:01:41 lr 2.424183	time 1.4283 (2.1087)	loss 2.8378 (2.9389)	grad_norm 0.3749 (0.4145)	mem 39782MB
[2023-07-07 13:54:25 RepVGG-A0] (main.py 282): INFO Train: [173/300][40/78]	eta 0:01:16 lr 2.420015	time 3.6635 (2.0217)	loss 2.9241 (2.9367)	grad_norm 0.3728 (0.4113)	mem 39782MB
[2023-07-07 13:54:41 RepVGG-A0] (main.py 282): INFO Train: [173/300][50/78]	eta 0:00:54 lr 2.415849	time 1.3054 (1.9372)	loss 2.9215 (2.9305)	grad_norm 0.3827 (0.4085)	mem 39782MB
[2023-07-07 13:54:56 RepVGG-A0] (main.py 282): INFO Train: [173/300][60/78]	eta 0:00:33 lr 2.411685	time 1.1722 (1.8651)	loss 2.9368 (2.9277)	grad_norm 0.4212 (0.4086)	mem 39782MB
[2023-07-07 13:55:11 RepVGG-A0] (main.py 282): INFO Train: [173/300][70/78]	eta 0:00:14 lr 2.407522	time 1.1733 (1.8155)	loss 2.9335 (2.9257)	grad_norm 0.3730 (0.4077)	mem 39782MB
[2023-07-07 13:55:22 RepVGG-A0] (main.py 291): INFO EPOCH 173 training takes 0:02:20
[2023-07-07 13:55:45 RepVGG-A0] (main.py 282): INFO Train: [174/300][0/78]	eta 0:29:01 lr 2.404192	time 22.3256 (22.3256)	loss 2.8847 (2.8847)	grad_norm 0.4274 (0.4274)	mem 39782MB
[2023-07-07 13:55:59 RepVGG-A0] (main.py 282): INFO Train: [174/300][10/78]	eta 0:03:44 lr 2.400032	time 1.1720 (3.3023)	loss 2.8539 (2.9037)	grad_norm 0.3906 (0.4351)	mem 39782MB
[2023-07-07 13:56:13 RepVGG-A0] (main.py 282): INFO Train: [174/300][20/78]	eta 0:02:19 lr 2.395873	time 1.1915 (2.4136)	loss 2.9032 (2.8889)	grad_norm 0.4054 (0.4213)	mem 39782MB
[2023-07-07 13:56:28 RepVGG-A0] (main.py 282): INFO Train: [174/300][30/78]	eta 0:01:42 lr 2.391715	time 1.2813 (2.1268)	loss 2.8300 (2.8886)	grad_norm 0.4346 (0.4207)	mem 39782MB
[2023-07-07 13:56:46 RepVGG-A0] (main.py 282): INFO Train: [174/300][40/78]	eta 0:01:17 lr 2.387559	time 3.8232 (2.0434)	loss 2.9217 (2.8970)	grad_norm 0.4119 (0.4222)	mem 39782MB
[2023-07-07 13:57:01 RepVGG-A0] (main.py 282): INFO Train: [174/300][50/78]	eta 0:00:54 lr 2.383404	time 1.1884 (1.9425)	loss 2.9006 (2.9017)	grad_norm 0.3976 (0.4227)	mem 39782MB
[2023-07-07 13:57:17 RepVGG-A0] (main.py 282): INFO Train: [174/300][60/78]	eta 0:00:33 lr 2.379251	time 1.2765 (1.8789)	loss 2.8988 (2.9018)	grad_norm 0.3892 (0.4201)	mem 39782MB
[2023-07-07 13:57:32 RepVGG-A0] (main.py 282): INFO Train: [174/300][70/78]	eta 0:00:14 lr 2.375099	time 1.3408 (1.8274)	loss 2.9659 (2.9044)	grad_norm 0.4304 (0.4233)	mem 39782MB
[2023-07-07 13:57:44 RepVGG-A0] (main.py 291): INFO EPOCH 174 training takes 0:02:21
[2023-07-07 13:58:06 RepVGG-A0] (main.py 282): INFO Train: [175/300][0/78]	eta 0:28:52 lr 2.371779	time 22.2054 (22.2054)	loss 2.7857 (2.7857)	grad_norm 0.4550 (0.4550)	mem 39782MB
[2023-07-07 13:58:20 RepVGG-A0] (main.py 282): INFO Train: [175/300][10/78]	eta 0:03:46 lr 2.367630	time 1.1725 (3.3238)	loss 2.8221 (2.8607)	grad_norm 0.3782 (0.4255)	mem 39782MB
[2023-07-07 13:58:34 RepVGG-A0] (main.py 282): INFO Train: [175/300][20/78]	eta 0:02:18 lr 2.363482	time 1.1739 (2.3943)	loss 2.8918 (2.8683)	grad_norm 0.4397 (0.4166)	mem 39782MB
[2023-07-07 13:58:50 RepVGG-A0] (main.py 282): INFO Train: [175/300][30/78]	eta 0:01:42 lr 2.359336	time 1.5405 (2.1338)	loss 2.9272 (2.8817)	grad_norm 0.3908 (0.4234)	mem 39782MB
[2023-07-07 13:59:08 RepVGG-A0] (main.py 282): INFO Train: [175/300][40/78]	eta 0:01:18 lr 2.355192	time 3.6387 (2.0601)	loss 2.9398 (2.8902)	grad_norm 0.4323 (0.4225)	mem 39782MB
[2023-07-07 13:59:23 RepVGG-A0] (main.py 282): INFO Train: [175/300][50/78]	eta 0:00:54 lr 2.351049	time 1.1734 (1.9521)	loss 2.9301 (2.9122)	grad_norm 0.4569 (0.4365)	mem 39782MB
[2023-07-07 13:59:38 RepVGG-A0] (main.py 282): INFO Train: [175/300][60/78]	eta 0:00:33 lr 2.346907	time 1.4328 (1.8783)	loss 2.8743 (2.9080)	grad_norm 0.4288 (0.4316)	mem 39782MB
[2023-07-07 13:59:52 RepVGG-A0] (main.py 282): INFO Train: [175/300][70/78]	eta 0:00:14 lr 2.342767	time 1.4033 (1.8124)	loss 2.9843 (2.9058)	grad_norm 0.4479 (0.4276)	mem 39782MB
[2023-07-07 14:00:04 RepVGG-A0] (main.py 291): INFO EPOCH 175 training takes 0:02:20
[2023-07-07 14:00:26 RepVGG-A0] (main.py 282): INFO Train: [176/300][0/78]	eta 0:28:44 lr 2.339457	time 22.1099 (22.1099)	loss 2.8994 (2.8994)	grad_norm 0.4049 (0.4049)	mem 39782MB
[2023-07-07 14:00:40 RepVGG-A0] (main.py 282): INFO Train: [176/300][10/78]	eta 0:03:41 lr 2.335319	time 1.1723 (3.2582)	loss 2.9086 (2.8317)	grad_norm 0.4052 (0.4060)	mem 39782MB
[2023-07-07 14:00:54 RepVGG-A0] (main.py 282): INFO Train: [176/300][20/78]	eta 0:02:19 lr 2.331184	time 1.1907 (2.3988)	loss 2.8376 (2.8456)	grad_norm 0.3774 (0.4057)	mem 39782MB
[2023-07-07 14:01:11 RepVGG-A0] (main.py 282): INFO Train: [176/300][30/78]	eta 0:01:42 lr 2.327050	time 1.2966 (2.1433)	loss 2.9623 (2.8637)	grad_norm 0.4550 (0.4164)	mem 39782MB
[2023-07-07 14:01:28 RepVGG-A0] (main.py 282): INFO Train: [176/300][40/78]	eta 0:01:17 lr 2.322917	time 3.4354 (2.0467)	loss 2.7856 (2.8744)	grad_norm 0.4153 (0.4206)	mem 39782MB
[2023-07-07 14:01:44 RepVGG-A0] (main.py 282): INFO Train: [176/300][50/78]	eta 0:00:54 lr 2.318786	time 1.2354 (1.9496)	loss 2.8932 (2.8770)	grad_norm 0.4460 (0.4203)	mem 39782MB
[2023-07-07 14:01:59 RepVGG-A0] (main.py 282): INFO Train: [176/300][60/78]	eta 0:00:33 lr 2.314657	time 1.1771 (1.8809)	loss 2.8965 (2.8785)	grad_norm 0.4125 (0.4201)	mem 39782MB
[2023-07-07 14:02:14 RepVGG-A0] (main.py 282): INFO Train: [176/300][70/78]	eta 0:00:14 lr 2.310529	time 1.5803 (1.8304)	loss 2.9565 (2.8806)	grad_norm 0.4762 (0.4207)	mem 39782MB
[2023-07-07 14:02:25 RepVGG-A0] (main.py 291): INFO EPOCH 176 training takes 0:02:20
[2023-07-07 14:02:47 RepVGG-A0] (main.py 282): INFO Train: [177/300][0/78]	eta 0:28:22 lr 2.307228	time 21.8236 (21.8236)	loss 2.8366 (2.8366)	grad_norm 0.4294 (0.4294)	mem 39782MB
[2023-07-07 14:03:03 RepVGG-A0] (main.py 282): INFO Train: [177/300][10/78]	eta 0:03:52 lr 2.303104	time 1.1719 (3.4141)	loss 2.8267 (2.8493)	grad_norm 0.4109 (0.4347)	mem 39782MB
[2023-07-07 14:03:17 RepVGG-A0] (main.py 282): INFO Train: [177/300][20/78]	eta 0:02:24 lr 2.298980	time 1.1777 (2.4832)	loss 2.8581 (2.8412)	grad_norm 0.4054 (0.4214)	mem 39782MB
[2023-07-07 14:03:32 RepVGG-A0] (main.py 282): INFO Train: [177/300][30/78]	eta 0:01:44 lr 2.294859	time 1.4941 (2.1685)	loss 2.9179 (2.8525)	grad_norm 0.4534 (0.4241)	mem 39782MB
[2023-07-07 14:03:51 RepVGG-A0] (main.py 282): INFO Train: [177/300][40/78]	eta 0:01:19 lr 2.290739	time 3.6485 (2.0863)	loss 2.8529 (2.8611)	grad_norm 0.4210 (0.4281)	mem 39782MB
[2023-07-07 14:04:05 RepVGG-A0] (main.py 282): INFO Train: [177/300][50/78]	eta 0:00:55 lr 2.286621	time 1.1825 (1.9688)	loss 2.8682 (2.8662)	grad_norm 0.4044 (0.4290)	mem 39782MB
[2023-07-07 14:04:20 RepVGG-A0] (main.py 282): INFO Train: [177/300][60/78]	eta 0:00:33 lr 2.282504	time 1.1718 (1.8802)	loss 2.8704 (2.8679)	grad_norm 0.4053 (0.4258)	mem 39782MB
[2023-07-07 14:04:36 RepVGG-A0] (main.py 282): INFO Train: [177/300][70/78]	eta 0:00:14 lr 2.278389	time 1.1515 (1.8401)	loss 2.9448 (2.8713)	grad_norm 0.4117 (0.4240)	mem 39782MB
[2023-07-07 14:04:48 RepVGG-A0] (main.py 291): INFO EPOCH 177 training takes 0:02:22
[2023-07-07 14:05:08 RepVGG-A0] (main.py 282): INFO Train: [178/300][0/78]	eta 0:26:34 lr 2.275098	time 20.4395 (20.4395)	loss 2.9213 (2.9213)	grad_norm 0.5030 (0.5030)	mem 39782MB
[2023-07-07 14:05:23 RepVGG-A0] (main.py 282): INFO Train: [178/300][10/78]	eta 0:03:40 lr 2.270986	time 1.1723 (3.2354)	loss 2.8549 (2.9129)	grad_norm 0.4013 (0.4872)	mem 39782MB
[2023-07-07 14:05:39 RepVGG-A0] (main.py 282): INFO Train: [178/300][20/78]	eta 0:02:20 lr 2.266876	time 1.1745 (2.4196)	loss 2.8578 (2.8891)	grad_norm 0.4032 (0.4468)	mem 39782MB
[2023-07-07 14:05:54 RepVGG-A0] (main.py 282): INFO Train: [178/300][30/78]	eta 0:01:42 lr 2.262767	time 1.3386 (2.1364)	loss 2.9007 (2.8790)	grad_norm 0.5090 (0.4396)	mem 39782MB
[2023-07-07 14:06:12 RepVGG-A0] (main.py 282): INFO Train: [178/300][40/78]	eta 0:01:18 lr 2.258660	time 3.1491 (2.0577)	loss 2.8684 (2.8826)	grad_norm 0.3990 (0.4328)	mem 39782MB
[2023-07-07 14:06:27 RepVGG-A0] (main.py 282): INFO Train: [178/300][50/78]	eta 0:00:54 lr 2.254555	time 1.1725 (1.9430)	loss 2.8496 (2.8807)	grad_norm 0.4083 (0.4322)	mem 39782MB
[2023-07-07 14:06:42 RepVGG-A0] (main.py 282): INFO Train: [178/300][60/78]	eta 0:00:33 lr 2.250452	time 1.2946 (1.8741)	loss 2.8107 (2.8770)	grad_norm 0.4020 (0.4271)	mem 39782MB
[2023-07-07 14:06:57 RepVGG-A0] (main.py 282): INFO Train: [178/300][70/78]	eta 0:00:14 lr 2.246350	time 1.2463 (1.8234)	loss 2.9242 (2.8773)	grad_norm 0.4972 (0.4286)	mem 39782MB
[2023-07-07 14:07:09 RepVGG-A0] (main.py 291): INFO EPOCH 178 training takes 0:02:20
[2023-07-07 14:07:31 RepVGG-A0] (main.py 282): INFO Train: [179/300][0/78]	eta 0:29:44 lr 2.243069	time 22.8793 (22.8793)	loss 2.8172 (2.8172)	grad_norm 0.4012 (0.4012)	mem 39782MB
[2023-07-07 14:07:45 RepVGG-A0] (main.py 282): INFO Train: [179/300][10/78]	eta 0:03:46 lr 2.238971	time 1.1722 (3.3259)	loss 2.8817 (2.8252)	grad_norm 0.4358 (0.4013)	mem 39782MB
[2023-07-07 14:08:00 RepVGG-A0] (main.py 282): INFO Train: [179/300][20/78]	eta 0:02:22 lr 2.234874	time 1.1725 (2.4654)	loss 2.8228 (2.8305)	grad_norm 0.4070 (0.4127)	mem 39782MB
[2023-07-07 14:08:16 RepVGG-A0] (main.py 282): INFO Train: [179/300][30/78]	eta 0:01:43 lr 2.230778	time 1.6671 (2.1656)	loss 2.9269 (2.8353)	grad_norm 0.3977 (0.4138)	mem 39782MB
[2023-07-07 14:08:33 RepVGG-A0] (main.py 282): INFO Train: [179/300][40/78]	eta 0:01:17 lr 2.226685	time 1.4428 (2.0503)	loss 2.8356 (2.8410)	grad_norm 0.4566 (0.4153)	mem 39782MB
[2023-07-07 14:08:48 RepVGG-A0] (main.py 282): INFO Train: [179/300][50/78]	eta 0:00:54 lr 2.222593	time 1.1729 (1.9527)	loss 2.8505 (2.8514)	grad_norm 0.4202 (0.4243)	mem 39782MB
[2023-07-07 14:09:03 RepVGG-A0] (main.py 282): INFO Train: [179/300][60/78]	eta 0:00:33 lr 2.218503	time 1.1925 (1.8803)	loss 2.9404 (2.8516)	grad_norm 0.4486 (0.4242)	mem 39782MB
[2023-07-07 14:09:18 RepVGG-A0] (main.py 282): INFO Train: [179/300][70/78]	eta 0:00:14 lr 2.214415	time 1.2410 (1.8264)	loss 2.8138 (2.8574)	grad_norm 0.4134 (0.4272)	mem 39782MB
[2023-07-07 14:09:30 RepVGG-A0] (main.py 291): INFO EPOCH 179 training takes 0:02:21
[2023-07-07 14:09:52 RepVGG-A0] (main.py 282): INFO Train: [180/300][0/78]	eta 0:28:50 lr 2.211146	time 22.1870 (22.1870)	loss 2.7841 (2.7841)	grad_norm 0.4234 (0.4234)	mem 39782MB
[2023-07-07 14:10:06 RepVGG-A0] (main.py 282): INFO Train: [180/300][10/78]	eta 0:03:42 lr 2.207061	time 1.1740 (3.2755)	loss 2.8478 (2.8095)	grad_norm 0.4227 (0.4185)	mem 39782MB
[2023-07-07 14:10:21 RepVGG-A0] (main.py 282): INFO Train: [180/300][20/78]	eta 0:02:21 lr 2.202977	time 1.1777 (2.4393)	loss 2.8646 (2.8230)	grad_norm 0.4307 (0.4238)	mem 39782MB
[2023-07-07 14:10:37 RepVGG-A0] (main.py 282): INFO Train: [180/300][30/78]	eta 0:01:44 lr 2.198896	time 1.9142 (2.1806)	loss 2.8291 (2.8360)	grad_norm 0.4013 (0.4360)	mem 39782MB
[2023-07-07 14:10:55 RepVGG-A0] (main.py 282): INFO Train: [180/300][40/78]	eta 0:01:18 lr 2.194816	time 3.3114 (2.0656)	loss 2.8611 (2.8398)	grad_norm 0.4398 (0.4329)	mem 39782MB
[2023-07-07 14:11:09 RepVGG-A0] (main.py 282): INFO Train: [180/300][50/78]	eta 0:00:54 lr 2.190738	time 1.1735 (1.9476)	loss 2.9059 (2.8432)	grad_norm 0.4570 (0.4285)	mem 39782MB
[2023-07-07 14:11:25 RepVGG-A0] (main.py 282): INFO Train: [180/300][60/78]	eta 0:00:33 lr 2.186662	time 1.4739 (1.8877)	loss 2.8531 (2.8502)	grad_norm 0.4141 (0.4297)	mem 39782MB
[2023-07-07 14:11:38 RepVGG-A0] (main.py 282): INFO Train: [180/300][70/78]	eta 0:00:14 lr 2.182588	time 1.1774 (1.8080)	loss 2.8761 (2.8544)	grad_norm 0.4716 (0.4313)	mem 39782MB
[2023-07-07 14:11:51 RepVGG-A0] (main.py 291): INFO EPOCH 180 training takes 0:02:20
[2023-07-07 14:12:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.633 (17.633)	Loss 2.2331 (2.2331)	Acc@1 51.160 (51.160)	Acc@5 75.751 (75.751)	Mem 39782MB
[2023-07-07 14:12:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 51.752 Acc@5 76.092
[2023-07-07 14:12:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 180: 51.752%
[2023-07-07 14:12:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 51.75%
[2023-07-07 14:12:30 RepVGG-A0] (main.py 282): INFO Train: [181/300][0/78]	eta 0:27:12 lr 2.179330	time 20.9334 (20.9334)	loss 2.8045 (2.8045)	grad_norm 0.4137 (0.4137)	mem 39782MB
[2023-07-07 14:12:47 RepVGG-A0] (main.py 282): INFO Train: [181/300][10/78]	eta 0:03:50 lr 2.175259	time 1.1720 (3.3930)	loss 2.7999 (2.8116)	grad_norm 0.3866 (0.4094)	mem 39782MB
[2023-07-07 14:13:01 RepVGG-A0] (main.py 282): INFO Train: [181/300][20/78]	eta 0:02:23 lr 2.171190	time 1.1966 (2.4666)	loss 2.8264 (2.8086)	grad_norm 0.4492 (0.4071)	mem 39782MB
[2023-07-07 14:13:16 RepVGG-A0] (main.py 282): INFO Train: [181/300][30/78]	eta 0:01:44 lr 2.167123	time 1.5214 (2.1679)	loss 2.7858 (2.8195)	grad_norm 0.4161 (0.4194)	mem 39782MB
[2023-07-07 14:13:34 RepVGG-A0] (main.py 282): INFO Train: [181/300][40/78]	eta 0:01:18 lr 2.163058	time 4.2184 (2.0636)	loss 2.8135 (2.8235)	grad_norm 0.4424 (0.4200)	mem 39782MB
[2023-07-07 14:13:49 RepVGG-A0] (main.py 282): INFO Train: [181/300][50/78]	eta 0:00:54 lr 2.158994	time 1.1743 (1.9536)	loss 2.8854 (2.8295)	grad_norm 0.4372 (0.4223)	mem 39782MB
[2023-07-07 14:14:04 RepVGG-A0] (main.py 282): INFO Train: [181/300][60/78]	eta 0:00:33 lr 2.154933	time 1.6337 (1.8794)	loss 2.8827 (2.8374)	grad_norm 0.4500 (0.4270)	mem 39782MB
[2023-07-07 14:14:19 RepVGG-A0] (main.py 282): INFO Train: [181/300][70/78]	eta 0:00:14 lr 2.150873	time 1.4372 (1.8327)	loss 2.8809 (2.8379)	grad_norm 0.4354 (0.4248)	mem 39782MB
[2023-07-07 14:14:30 RepVGG-A0] (main.py 291): INFO EPOCH 181 training takes 0:02:20
[2023-07-07 14:14:51 RepVGG-A0] (main.py 282): INFO Train: [182/300][0/78]	eta 0:27:05 lr 2.147627	time 20.8447 (20.8447)	loss 2.8082 (2.8082)	grad_norm 0.4604 (0.4604)	mem 39782MB
[2023-07-07 14:15:05 RepVGG-A0] (main.py 282): INFO Train: [182/300][10/78]	eta 0:03:36 lr 2.143570	time 1.1721 (3.1876)	loss 2.8387 (2.8275)	grad_norm 0.3832 (0.4279)	mem 39782MB
[2023-07-07 14:15:20 RepVGG-A0] (main.py 282): INFO Train: [182/300][20/78]	eta 0:02:17 lr 2.139516	time 1.1726 (2.3688)	loss 2.8415 (2.8250)	grad_norm 0.4696 (0.4289)	mem 39782MB
[2023-07-07 14:15:35 RepVGG-A0] (main.py 282): INFO Train: [182/300][30/78]	eta 0:01:40 lr 2.135464	time 1.4467 (2.0936)	loss 2.8928 (2.8555)	grad_norm 0.4038 (0.4527)	mem 39782MB
[2023-07-07 14:15:53 RepVGG-A0] (main.py 282): INFO Train: [182/300][40/78]	eta 0:01:17 lr 2.131413	time 3.8790 (2.0300)	loss 2.7809 (2.8490)	grad_norm 0.4073 (0.4402)	mem 39782MB
[2023-07-07 14:16:08 RepVGG-A0] (main.py 282): INFO Train: [182/300][50/78]	eta 0:00:54 lr 2.127364	time 1.1739 (1.9298)	loss 2.8092 (2.8468)	grad_norm 0.3986 (0.4338)	mem 39782MB
[2023-07-07 14:16:23 RepVGG-A0] (main.py 282): INFO Train: [182/300][60/78]	eta 0:00:33 lr 2.123318	time 1.1811 (1.8553)	loss 2.8204 (2.8457)	grad_norm 0.4175 (0.4315)	mem 39782MB
[2023-07-07 14:16:39 RepVGG-A0] (main.py 282): INFO Train: [182/300][70/78]	eta 0:00:14 lr 2.119273	time 1.2765 (1.8150)	loss 2.8957 (2.8520)	grad_norm 0.5108 (0.4387)	mem 39782MB
[2023-07-07 14:16:51 RepVGG-A0] (main.py 291): INFO EPOCH 182 training takes 0:02:20
[2023-07-07 14:17:12 RepVGG-A0] (main.py 282): INFO Train: [183/300][0/78]	eta 0:27:52 lr 2.116039	time 21.4369 (21.4369)	loss 2.8579 (2.8579)	grad_norm 0.4088 (0.4088)	mem 39782MB
[2023-07-07 14:17:27 RepVGG-A0] (main.py 282): INFO Train: [183/300][10/78]	eta 0:03:45 lr 2.111997	time 1.1732 (3.3226)	loss 2.8588 (2.8026)	grad_norm 0.4117 (0.4263)	mem 39782MB
[2023-07-07 14:17:41 RepVGG-A0] (main.py 282): INFO Train: [183/300][20/78]	eta 0:02:19 lr 2.107958	time 1.1741 (2.4118)	loss 2.7887 (2.8120)	grad_norm 0.4094 (0.4277)	mem 39782MB
[2023-07-07 14:17:58 RepVGG-A0] (main.py 282): INFO Train: [183/300][30/78]	eta 0:01:43 lr 2.103921	time 1.7717 (2.1593)	loss 2.9032 (2.8205)	grad_norm 0.4136 (0.4238)	mem 39782MB
[2023-07-07 14:18:15 RepVGG-A0] (main.py 282): INFO Train: [183/300][40/78]	eta 0:01:17 lr 2.099886	time 3.9877 (2.0443)	loss 2.7669 (2.8268)	grad_norm 0.4417 (0.4279)	mem 39782MB
[2023-07-07 14:18:30 RepVGG-A0] (main.py 282): INFO Train: [183/300][50/78]	eta 0:00:54 lr 2.095852	time 1.1748 (1.9380)	loss 2.7834 (2.8252)	grad_norm 0.4075 (0.4246)	mem 39782MB
[2023-07-07 14:18:44 RepVGG-A0] (main.py 282): INFO Train: [183/300][60/78]	eta 0:00:33 lr 2.091821	time 1.2906 (1.8617)	loss 2.8547 (2.8276)	grad_norm 0.3917 (0.4247)	mem 39782MB
[2023-07-07 14:19:00 RepVGG-A0] (main.py 282): INFO Train: [183/300][70/78]	eta 0:00:14 lr 2.087791	time 1.2048 (1.8165)	loss 2.8765 (2.8331)	grad_norm 0.4519 (0.4292)	mem 39782MB
[2023-07-07 14:19:11 RepVGG-A0] (main.py 291): INFO EPOCH 183 training takes 0:02:20
[2023-07-07 14:19:33 RepVGG-A0] (main.py 282): INFO Train: [184/300][0/78]	eta 0:28:35 lr 2.084569	time 21.9943 (21.9943)	loss 2.7640 (2.7640)	grad_norm 0.4164 (0.4164)	mem 39782MB
[2023-07-07 14:19:48 RepVGG-A0] (main.py 282): INFO Train: [184/300][10/78]	eta 0:03:51 lr 2.080544	time 1.1704 (3.4038)	loss 2.8145 (2.7988)	grad_norm 0.4092 (0.4290)	mem 39782MB
[2023-07-07 14:20:04 RepVGG-A0] (main.py 282): INFO Train: [184/300][20/78]	eta 0:02:25 lr 2.076520	time 1.1969 (2.5007)	loss 2.8055 (2.8017)	grad_norm 0.4272 (0.4374)	mem 39782MB
[2023-07-07 14:20:19 RepVGG-A0] (main.py 282): INFO Train: [184/300][30/78]	eta 0:01:44 lr 2.072498	time 1.4264 (2.1802)	loss 2.8903 (2.8048)	grad_norm 0.4715 (0.4347)	mem 39782MB
[2023-07-07 14:20:34 RepVGG-A0] (main.py 282): INFO Train: [184/300][40/78]	eta 0:01:16 lr 2.068479	time 2.0036 (2.0220)	loss 2.8480 (2.8153)	grad_norm 0.4266 (0.4359)	mem 39782MB
[2023-07-07 14:20:52 RepVGG-A0] (main.py 282): INFO Train: [184/300][50/78]	eta 0:00:55 lr 2.064461	time 1.3129 (1.9746)	loss 2.7842 (2.8169)	grad_norm 0.4441 (0.4355)	mem 39782MB
[2023-07-07 14:21:06 RepVGG-A0] (main.py 282): INFO Train: [184/300][60/78]	eta 0:00:34 lr 2.060445	time 1.2968 (1.8927)	loss 2.7821 (2.8200)	grad_norm 0.4380 (0.4349)	mem 39782MB
[2023-07-07 14:21:21 RepVGG-A0] (main.py 282): INFO Train: [184/300][70/78]	eta 0:00:14 lr 2.056432	time 1.2161 (1.8265)	loss 2.8506 (2.8216)	grad_norm 0.4162 (0.4350)	mem 39782MB
[2023-07-07 14:21:33 RepVGG-A0] (main.py 291): INFO EPOCH 184 training takes 0:02:21
[2023-07-07 14:21:55 RepVGG-A0] (main.py 282): INFO Train: [185/300][0/78]	eta 0:29:00 lr 2.053223	time 22.3077 (22.3077)	loss 2.7822 (2.7822)	grad_norm 0.4285 (0.4285)	mem 39782MB
[2023-07-07 14:22:10 RepVGG-A0] (main.py 282): INFO Train: [185/300][10/78]	eta 0:03:49 lr 2.049213	time 1.1717 (3.3782)	loss 2.8037 (2.8170)	grad_norm 0.4397 (0.4510)	mem 39782MB
[2023-07-07 14:22:25 RepVGG-A0] (main.py 282): INFO Train: [185/300][20/78]	eta 0:02:24 lr 2.045205	time 1.3289 (2.4925)	loss 2.8797 (2.8300)	grad_norm 0.4867 (0.4514)	mem 39782MB
[2023-07-07 14:22:40 RepVGG-A0] (main.py 282): INFO Train: [185/300][30/78]	eta 0:01:43 lr 2.041199	time 1.3615 (2.1593)	loss 2.8004 (2.8241)	grad_norm 0.4233 (0.4425)	mem 39782MB
[2023-07-07 14:22:59 RepVGG-A0] (main.py 282): INFO Train: [185/300][40/78]	eta 0:01:19 lr 2.037196	time 4.5902 (2.0948)	loss 2.8101 (2.8211)	grad_norm 0.4123 (0.4435)	mem 39782MB
[2023-07-07 14:23:14 RepVGG-A0] (main.py 282): INFO Train: [185/300][50/78]	eta 0:00:55 lr 2.033194	time 1.1979 (1.9746)	loss 2.7464 (2.8166)	grad_norm 0.4245 (0.4378)	mem 39782MB
[2023-07-07 14:23:29 RepVGG-A0] (main.py 282): INFO Train: [185/300][60/78]	eta 0:00:34 lr 2.029195	time 1.1757 (1.9090)	loss 2.9054 (2.8188)	grad_norm 0.4865 (0.4370)	mem 39782MB
[2023-07-07 14:23:45 RepVGG-A0] (main.py 282): INFO Train: [185/300][70/78]	eta 0:00:14 lr 2.025198	time 1.3391 (1.8618)	loss 2.9743 (2.8326)	grad_norm 0.5153 (0.4496)	mem 39782MB
[2023-07-07 14:23:56 RepVGG-A0] (main.py 291): INFO EPOCH 185 training takes 0:02:22
[2023-07-07 14:24:16 RepVGG-A0] (main.py 282): INFO Train: [186/300][0/78]	eta 0:26:32 lr 2.022001	time 20.4202 (20.4202)	loss 2.7603 (2.7603)	grad_norm 0.3953 (0.3953)	mem 39782MB
[2023-07-07 14:24:32 RepVGG-A0] (main.py 282): INFO Train: [186/300][10/78]	eta 0:03:46 lr 2.018008	time 1.1729 (3.3289)	loss 2.8384 (2.7779)	grad_norm 0.4386 (0.4102)	mem 39782MB
[2023-07-07 14:24:46 RepVGG-A0] (main.py 282): INFO Train: [186/300][20/78]	eta 0:02:19 lr 2.014017	time 1.1724 (2.4107)	loss 2.8159 (2.7822)	grad_norm 0.4457 (0.4197)	mem 39782MB
[2023-07-07 14:25:01 RepVGG-A0] (main.py 282): INFO Train: [186/300][30/78]	eta 0:01:41 lr 2.010028	time 1.1303 (2.1084)	loss 2.8578 (2.7925)	grad_norm 0.4208 (0.4273)	mem 39782MB
[2023-07-07 14:25:19 RepVGG-A0] (main.py 282): INFO Train: [186/300][40/78]	eta 0:01:17 lr 2.006040	time 3.1811 (2.0391)	loss 2.7633 (2.7963)	grad_norm 0.3876 (0.4283)	mem 39782MB
[2023-07-07 14:25:35 RepVGG-A0] (main.py 282): INFO Train: [186/300][50/78]	eta 0:00:54 lr 2.002056	time 1.1720 (1.9453)	loss 2.8047 (2.8026)	grad_norm 0.4566 (0.4273)	mem 39782MB
[2023-07-07 14:25:50 RepVGG-A0] (main.py 282): INFO Train: [186/300][60/78]	eta 0:00:33 lr 1.998073	time 1.2076 (1.8702)	loss 2.8340 (2.8079)	grad_norm 0.4367 (0.4297)	mem 39782MB
[2023-07-07 14:26:05 RepVGG-A0] (main.py 282): INFO Train: [186/300][70/78]	eta 0:00:14 lr 1.994092	time 1.5413 (1.8184)	loss 2.7974 (2.8085)	grad_norm 0.4443 (0.4279)	mem 39782MB
[2023-07-07 14:26:16 RepVGG-A0] (main.py 291): INFO EPOCH 186 training takes 0:02:20
[2023-07-07 14:26:38 RepVGG-A0] (main.py 282): INFO Train: [187/300][0/78]	eta 0:28:28 lr 1.990909	time 21.9059 (21.9059)	loss 2.7711 (2.7711)	grad_norm 0.4073 (0.4073)	mem 39782MB
[2023-07-07 14:26:53 RepVGG-A0] (main.py 282): INFO Train: [187/300][10/78]	eta 0:03:46 lr 1.986933	time 1.1908 (3.3276)	loss 2.8541 (2.7619)	grad_norm 0.5060 (0.4395)	mem 39782MB
[2023-07-07 14:27:08 RepVGG-A0] (main.py 282): INFO Train: [187/300][20/78]	eta 0:02:23 lr 1.982958	time 1.1827 (2.4734)	loss 2.7861 (2.7777)	grad_norm 0.4179 (0.4472)	mem 39782MB
[2023-07-07 14:27:24 RepVGG-A0] (main.py 282): INFO Train: [187/300][30/78]	eta 0:01:44 lr 1.978986	time 1.2778 (2.1794)	loss 2.7873 (2.7876)	grad_norm 0.4245 (0.4434)	mem 39782MB
[2023-07-07 14:27:41 RepVGG-A0] (main.py 282): INFO Train: [187/300][40/78]	eta 0:01:18 lr 1.975016	time 1.6563 (2.0689)	loss 2.8835 (2.7922)	grad_norm 0.4820 (0.4404)	mem 39782MB
[2023-07-07 14:27:56 RepVGG-A0] (main.py 282): INFO Train: [187/300][50/78]	eta 0:00:54 lr 1.971048	time 1.2675 (1.9555)	loss 2.7356 (2.7955)	grad_norm 0.4164 (0.4371)	mem 39782MB
[2023-07-07 14:28:11 RepVGG-A0] (main.py 282): INFO Train: [187/300][60/78]	eta 0:00:33 lr 1.967083	time 1.2880 (1.8800)	loss 2.8185 (2.8004)	grad_norm 0.4245 (0.4376)	mem 39782MB
[2023-07-07 14:28:26 RepVGG-A0] (main.py 282): INFO Train: [187/300][70/78]	eta 0:00:14 lr 1.963119	time 1.3034 (1.8305)	loss 2.7693 (2.7988)	grad_norm 0.3970 (0.4364)	mem 39782MB
[2023-07-07 14:28:38 RepVGG-A0] (main.py 291): INFO EPOCH 187 training takes 0:02:21
[2023-07-07 14:28:59 RepVGG-A0] (main.py 282): INFO Train: [188/300][0/78]	eta 0:27:24 lr 1.959950	time 21.0884 (21.0884)	loss 2.7704 (2.7704)	grad_norm 0.4687 (0.4687)	mem 39782MB
[2023-07-07 14:29:14 RepVGG-A0] (main.py 282): INFO Train: [188/300][10/78]	eta 0:03:40 lr 1.955991	time 1.1919 (3.2444)	loss 2.8087 (2.7848)	grad_norm 0.5163 (0.4936)	mem 39782MB
[2023-07-07 14:29:28 RepVGG-A0] (main.py 282): INFO Train: [188/300][20/78]	eta 0:02:18 lr 1.952034	time 1.1724 (2.3886)	loss 2.7904 (2.7852)	grad_norm 0.4126 (0.4590)	mem 39782MB
[2023-07-07 14:29:44 RepVGG-A0] (main.py 282): INFO Train: [188/300][30/78]	eta 0:01:41 lr 1.948079	time 1.1713 (2.1187)	loss 2.8276 (2.7894)	grad_norm 0.4578 (0.4553)	mem 39782MB
[2023-07-07 14:30:01 RepVGG-A0] (main.py 282): INFO Train: [188/300][40/78]	eta 0:01:16 lr 1.944126	time 2.7791 (2.0206)	loss 2.8176 (2.7838)	grad_norm 0.4701 (0.4472)	mem 39782MB
[2023-07-07 14:30:16 RepVGG-A0] (main.py 282): INFO Train: [188/300][50/78]	eta 0:00:53 lr 1.940176	time 1.1911 (1.9221)	loss 2.8083 (2.7909)	grad_norm 0.4409 (0.4484)	mem 39782MB
[2023-07-07 14:30:31 RepVGG-A0] (main.py 282): INFO Train: [188/300][60/78]	eta 0:00:33 lr 1.936228	time 1.2037 (1.8543)	loss 2.8371 (2.7926)	grad_norm 0.4234 (0.4458)	mem 39782MB
[2023-07-07 14:30:46 RepVGG-A0] (main.py 282): INFO Train: [188/300][70/78]	eta 0:00:14 lr 1.932282	time 1.1703 (1.8051)	loss 2.7957 (2.7975)	grad_norm 0.4376 (0.4440)	mem 39782MB
[2023-07-07 14:30:58 RepVGG-A0] (main.py 291): INFO EPOCH 188 training takes 0:02:19
[2023-07-07 14:31:19 RepVGG-A0] (main.py 282): INFO Train: [189/300][0/78]	eta 0:27:24 lr 1.929127	time 21.0893 (21.0893)	loss 2.7304 (2.7304)	grad_norm 0.4253 (0.4253)	mem 39782MB
[2023-07-07 14:31:34 RepVGG-A0] (main.py 282): INFO Train: [189/300][10/78]	eta 0:03:45 lr 1.925185	time 1.1922 (3.3214)	loss 2.7243 (2.7669)	grad_norm 0.4329 (0.4367)	mem 39782MB
[2023-07-07 14:31:48 RepVGG-A0] (main.py 282): INFO Train: [189/300][20/78]	eta 0:02:19 lr 1.921246	time 1.1284 (2.4082)	loss 2.8110 (2.7879)	grad_norm 0.5442 (0.4628)	mem 39782MB
[2023-07-07 14:32:04 RepVGG-A0] (main.py 282): INFO Train: [189/300][30/78]	eta 0:01:42 lr 1.917309	time 1.3406 (2.1370)	loss 2.7191 (2.8008)	grad_norm 0.4085 (0.4646)	mem 39782MB
[2023-07-07 14:32:21 RepVGG-A0] (main.py 282): INFO Train: [189/300][40/78]	eta 0:01:17 lr 1.913374	time 3.5588 (2.0384)	loss 2.7685 (2.8008)	grad_norm 0.4250 (0.4580)	mem 39782MB
[2023-07-07 14:32:37 RepVGG-A0] (main.py 282): INFO Train: [189/300][50/78]	eta 0:00:54 lr 1.909441	time 1.2179 (1.9403)	loss 2.9027 (2.8048)	grad_norm 0.5137 (0.4555)	mem 39782MB
[2023-07-07 14:32:52 RepVGG-A0] (main.py 282): INFO Train: [189/300][60/78]	eta 0:00:33 lr 1.905511	time 1.1821 (1.8651)	loss 2.8208 (2.8080)	grad_norm 0.4503 (0.4533)	mem 39782MB
[2023-07-07 14:33:07 RepVGG-A0] (main.py 282): INFO Train: [189/300][70/78]	eta 0:00:14 lr 1.901583	time 1.4250 (1.8233)	loss 2.8377 (2.8086)	grad_norm 0.3960 (0.4496)	mem 39782MB
[2023-07-07 14:33:19 RepVGG-A0] (main.py 291): INFO EPOCH 189 training takes 0:02:21
[2023-07-07 14:33:41 RepVGG-A0] (main.py 282): INFO Train: [190/300][0/78]	eta 0:28:46 lr 1.898443	time 22.1367 (22.1367)	loss 2.7273 (2.7273)	grad_norm 0.4072 (0.4072)	mem 39782MB
[2023-07-07 14:33:56 RepVGG-A0] (main.py 282): INFO Train: [190/300][10/78]	eta 0:03:46 lr 1.894519	time 1.1711 (3.3316)	loss 2.7306 (2.7488)	grad_norm 0.4427 (0.4193)	mem 39782MB
[2023-07-07 14:34:10 RepVGG-A0] (main.py 282): INFO Train: [190/300][20/78]	eta 0:02:19 lr 1.890598	time 1.1711 (2.4114)	loss 2.7550 (2.7553)	grad_norm 0.4369 (0.4279)	mem 39782MB
[2023-07-07 14:34:25 RepVGG-A0] (main.py 282): INFO Train: [190/300][30/78]	eta 0:01:41 lr 1.886679	time 1.2543 (2.1227)	loss 2.7431 (2.7602)	grad_norm 0.4388 (0.4329)	mem 39782MB
[2023-07-07 14:34:43 RepVGG-A0] (main.py 282): INFO Train: [190/300][40/78]	eta 0:01:17 lr 1.882763	time 3.1593 (2.0449)	loss 2.8538 (2.7638)	grad_norm 0.4305 (0.4336)	mem 39782MB
[2023-07-07 14:34:59 RepVGG-A0] (main.py 282): INFO Train: [190/300][50/78]	eta 0:00:54 lr 1.878848	time 1.1724 (1.9543)	loss 2.8373 (2.7728)	grad_norm 0.4950 (0.4375)	mem 39782MB
[2023-07-07 14:35:14 RepVGG-A0] (main.py 282): INFO Train: [190/300][60/78]	eta 0:00:33 lr 1.874937	time 1.3422 (1.8807)	loss 2.7917 (2.7759)	grad_norm 0.4458 (0.4381)	mem 39782MB
[2023-07-07 14:35:29 RepVGG-A0] (main.py 282): INFO Train: [190/300][70/78]	eta 0:00:14 lr 1.871027	time 1.1748 (1.8238)	loss 2.8206 (2.7779)	grad_norm 0.4468 (0.4383)	mem 39782MB
[2023-07-07 14:35:40 RepVGG-A0] (main.py 291): INFO EPOCH 190 training takes 0:02:21
[2023-07-07 14:36:02 RepVGG-A0] (main.py 282): INFO Train: [191/300][0/78]	eta 0:28:00 lr 1.867901	time 21.5443 (21.5443)	loss 2.6394 (2.6394)	grad_norm 0.4486 (0.4486)	mem 39782MB
[2023-07-07 14:36:17 RepVGG-A0] (main.py 282): INFO Train: [191/300][10/78]	eta 0:03:48 lr 1.863996	time 1.1692 (3.3533)	loss 2.7072 (2.7473)	grad_norm 0.4554 (0.4545)	mem 39782MB
[2023-07-07 14:36:33 RepVGG-A0] (main.py 282): INFO Train: [191/300][20/78]	eta 0:02:24 lr 1.860094	time 1.2942 (2.4851)	loss 2.6903 (2.7388)	grad_norm 0.4229 (0.4408)	mem 39782MB
[2023-07-07 14:36:48 RepVGG-A0] (main.py 282): INFO Train: [191/300][30/78]	eta 0:01:45 lr 1.856194	time 1.5588 (2.1915)	loss 2.8395 (2.7563)	grad_norm 0.4214 (0.4470)	mem 39782MB
[2023-07-07 14:37:06 RepVGG-A0] (main.py 282): INFO Train: [191/300][40/78]	eta 0:01:19 lr 1.852296	time 2.9766 (2.0942)	loss 2.8074 (2.7603)	grad_norm 0.4349 (0.4468)	mem 39782MB
[2023-07-07 14:37:21 RepVGG-A0] (main.py 282): INFO Train: [191/300][50/78]	eta 0:00:55 lr 1.848400	time 1.1744 (1.9687)	loss 2.8005 (2.7650)	grad_norm 0.4610 (0.4467)	mem 39782MB
[2023-07-07 14:37:36 RepVGG-A0] (main.py 282): INFO Train: [191/300][60/78]	eta 0:00:34 lr 1.844507	time 1.3886 (1.9023)	loss 2.7471 (2.7680)	grad_norm 0.4316 (0.4449)	mem 39782MB
[2023-07-07 14:37:51 RepVGG-A0] (main.py 282): INFO Train: [191/300][70/78]	eta 0:00:14 lr 1.840617	time 1.3071 (1.8422)	loss 2.8065 (2.7698)	grad_norm 0.4229 (0.4425)	mem 39782MB
[2023-07-07 14:38:03 RepVGG-A0] (main.py 291): INFO EPOCH 191 training takes 0:02:22
[2023-07-07 14:38:25 RepVGG-A0] (main.py 282): INFO Train: [192/300][0/78]	eta 0:28:30 lr 1.837506	time 21.9311 (21.9311)	loss 2.6392 (2.6392)	grad_norm 0.4034 (0.4034)	mem 39782MB
[2023-07-07 14:38:39 RepVGG-A0] (main.py 282): INFO Train: [192/300][10/78]	eta 0:03:42 lr 1.833620	time 1.1720 (3.2763)	loss 2.8657 (2.7679)	grad_norm 0.5598 (0.4831)	mem 39782MB
[2023-07-07 14:38:53 RepVGG-A0] (main.py 282): INFO Train: [192/300][20/78]	eta 0:02:18 lr 1.829737	time 1.1727 (2.3835)	loss 2.8056 (2.7826)	grad_norm 0.4680 (0.4719)	mem 39782MB
[2023-07-07 14:39:08 RepVGG-A0] (main.py 282): INFO Train: [192/300][30/78]	eta 0:01:39 lr 1.825855	time 1.4108 (2.0832)	loss 2.7851 (2.7768)	grad_norm 0.4811 (0.4643)	mem 39782MB
[2023-07-07 14:39:27 RepVGG-A0] (main.py 282): INFO Train: [192/300][40/78]	eta 0:01:17 lr 1.821977	time 3.4171 (2.0379)	loss 2.7665 (2.7791)	grad_norm 0.4207 (0.4582)	mem 39782MB
[2023-07-07 14:39:42 RepVGG-A0] (main.py 282): INFO Train: [192/300][50/78]	eta 0:00:54 lr 1.818101	time 1.1726 (1.9358)	loss 2.8015 (2.7768)	grad_norm 0.4156 (0.4537)	mem 39782MB
[2023-07-07 14:39:57 RepVGG-A0] (main.py 282): INFO Train: [192/300][60/78]	eta 0:00:33 lr 1.814227	time 1.3085 (1.8678)	loss 2.7354 (2.7744)	grad_norm 0.4297 (0.4495)	mem 39782MB
[2023-07-07 14:40:12 RepVGG-A0] (main.py 282): INFO Train: [192/300][70/78]	eta 0:00:14 lr 1.810356	time 1.1740 (1.8147)	loss 2.7779 (2.7748)	grad_norm 0.4640 (0.4472)	mem 39782MB
[2023-07-07 14:40:23 RepVGG-A0] (main.py 291): INFO EPOCH 192 training takes 0:02:20
[2023-07-07 14:40:46 RepVGG-A0] (main.py 282): INFO Train: [193/300][0/78]	eta 0:29:14 lr 1.807260	time 22.4998 (22.4998)	loss 2.6868 (2.6868)	grad_norm 0.4036 (0.4036)	mem 39782MB
[2023-07-07 14:41:00 RepVGG-A0] (main.py 282): INFO Train: [193/300][10/78]	eta 0:03:48 lr 1.803394	time 1.1711 (3.3617)	loss 2.6826 (2.7364)	grad_norm 0.4517 (0.4502)	mem 39782MB
[2023-07-07 14:41:14 RepVGG-A0] (main.py 282): INFO Train: [193/300][20/78]	eta 0:02:20 lr 1.799530	time 1.2437 (2.4300)	loss 2.7446 (2.7410)	grad_norm 0.4116 (0.4525)	mem 39782MB
[2023-07-07 14:41:29 RepVGG-A0] (main.py 282): INFO Train: [193/300][30/78]	eta 0:01:41 lr 1.795668	time 1.1854 (2.1170)	loss 2.7829 (2.7392)	grad_norm 0.4694 (0.4457)	mem 39782MB
[2023-07-07 14:41:47 RepVGG-A0] (main.py 282): INFO Train: [193/300][40/78]	eta 0:01:17 lr 1.791809	time 3.7076 (2.0473)	loss 2.8301 (2.7466)	grad_norm 0.4968 (0.4518)	mem 39782MB
[2023-07-07 14:42:03 RepVGG-A0] (main.py 282): INFO Train: [193/300][50/78]	eta 0:00:54 lr 1.787952	time 1.1766 (1.9482)	loss 2.8046 (2.7542)	grad_norm 0.4137 (0.4515)	mem 39782MB
[2023-07-07 14:42:18 RepVGG-A0] (main.py 282): INFO Train: [193/300][60/78]	eta 0:00:33 lr 1.784098	time 1.3077 (1.8876)	loss 2.7468 (2.7547)	grad_norm 0.4364 (0.4494)	mem 39782MB
[2023-07-07 14:42:33 RepVGG-A0] (main.py 282): INFO Train: [193/300][70/78]	eta 0:00:14 lr 1.780247	time 1.1711 (1.8199)	loss 2.7515 (2.7561)	grad_norm 0.4380 (0.4486)	mem 39782MB
[2023-07-07 14:42:44 RepVGG-A0] (main.py 291): INFO EPOCH 193 training takes 0:02:20
[2023-07-07 14:43:04 RepVGG-A0] (main.py 282): INFO Train: [194/300][0/78]	eta 0:26:37 lr 1.777167	time 20.4782 (20.4782)	loss 2.7321 (2.7321)	grad_norm 0.4310 (0.4310)	mem 39782MB
[2023-07-07 14:43:20 RepVGG-A0] (main.py 282): INFO Train: [194/300][10/78]	eta 0:03:44 lr 1.773321	time 1.1724 (3.2994)	loss 2.6968 (2.7109)	grad_norm 0.4425 (0.4408)	mem 39782MB
[2023-07-07 14:43:35 RepVGG-A0] (main.py 282): INFO Train: [194/300][20/78]	eta 0:02:22 lr 1.769476	time 1.2348 (2.4497)	loss 2.7594 (2.7219)	grad_norm 0.4360 (0.4388)	mem 39782MB
[2023-07-07 14:43:51 RepVGG-A0] (main.py 282): INFO Train: [194/300][30/78]	eta 0:01:43 lr 1.765635	time 1.4242 (2.1558)	loss 2.7448 (2.7387)	grad_norm 0.4448 (0.4482)	mem 39782MB
[2023-07-07 14:44:10 RepVGG-A0] (main.py 282): INFO Train: [194/300][40/78]	eta 0:01:19 lr 1.761795	time 3.7468 (2.0955)	loss 2.7949 (2.7481)	grad_norm 0.4704 (0.4508)	mem 39782MB
[2023-07-07 14:44:24 RepVGG-A0] (main.py 282): INFO Train: [194/300][50/78]	eta 0:00:54 lr 1.757959	time 1.1892 (1.9585)	loss 2.8137 (2.7509)	grad_norm 0.4269 (0.4521)	mem 39782MB
[2023-07-07 14:44:40 RepVGG-A0] (main.py 282): INFO Train: [194/300][60/78]	eta 0:00:34 lr 1.754125	time 1.3972 (1.9104)	loss 2.7999 (2.7513)	grad_norm 0.4041 (0.4469)	mem 39782MB
[2023-07-07 14:44:55 RepVGG-A0] (main.py 282): INFO Train: [194/300][70/78]	eta 0:00:14 lr 1.750294	time 1.4030 (1.8403)	loss 2.8073 (2.7550)	grad_norm 0.4861 (0.4503)	mem 39782MB
[2023-07-07 14:45:06 RepVGG-A0] (main.py 291): INFO EPOCH 194 training takes 0:02:22
[2023-07-07 14:45:28 RepVGG-A0] (main.py 282): INFO Train: [195/300][0/78]	eta 0:28:36 lr 1.747230	time 22.0075 (22.0075)	loss 2.7075 (2.7075)	grad_norm 0.4089 (0.4089)	mem 39782MB
[2023-07-07 14:45:43 RepVGG-A0] (main.py 282): INFO Train: [195/300][10/78]	eta 0:03:45 lr 1.743404	time 1.1752 (3.3176)	loss 2.7082 (2.7137)	grad_norm 0.4321 (0.4382)	mem 39782MB
[2023-07-07 14:45:57 RepVGG-A0] (main.py 282): INFO Train: [195/300][20/78]	eta 0:02:20 lr 1.739580	time 1.1700 (2.4236)	loss 2.7851 (2.7265)	grad_norm 0.4999 (0.4435)	mem 39782MB
[2023-07-07 14:46:13 RepVGG-A0] (main.py 282): INFO Train: [195/300][30/78]	eta 0:01:43 lr 1.735758	time 1.3564 (2.1508)	loss 2.6764 (2.7289)	grad_norm 0.3932 (0.4407)	mem 39782MB
[2023-07-07 14:46:31 RepVGG-A0] (main.py 282): INFO Train: [195/300][40/78]	eta 0:01:18 lr 1.731940	time 3.8521 (2.0681)	loss 2.7948 (2.7353)	grad_norm 0.4674 (0.4386)	mem 39782MB
[2023-07-07 14:46:46 RepVGG-A0] (main.py 282): INFO Train: [195/300][50/78]	eta 0:00:54 lr 1.728124	time 1.1729 (1.9571)	loss 2.7469 (2.7427)	grad_norm 0.4913 (0.4462)	mem 39782MB
[2023-07-07 14:47:01 RepVGG-A0] (main.py 282): INFO Train: [195/300][60/78]	eta 0:00:33 lr 1.724310	time 1.1791 (1.8827)	loss 2.7893 (2.7461)	grad_norm 0.4378 (0.4458)	mem 39782MB
[2023-07-07 14:47:16 RepVGG-A0] (main.py 282): INFO Train: [195/300][70/78]	eta 0:00:14 lr 1.720499	time 1.2337 (1.8303)	loss 2.8408 (2.7487)	grad_norm 0.4418 (0.4459)	mem 39782MB
[2023-07-07 14:47:28 RepVGG-A0] (main.py 291): INFO EPOCH 195 training takes 0:02:21
[2023-07-07 14:47:49 RepVGG-A0] (main.py 282): INFO Train: [196/300][0/78]	eta 0:27:33 lr 1.717453	time 21.1932 (21.1932)	loss 2.6759 (2.6759)	grad_norm 0.4320 (0.4320)	mem 39782MB
[2023-07-07 14:48:04 RepVGG-A0] (main.py 282): INFO Train: [196/300][10/78]	eta 0:03:41 lr 1.713647	time 1.1722 (3.2608)	loss 2.7250 (2.7121)	grad_norm 0.4881 (0.4478)	mem 39782MB
[2023-07-07 14:48:18 RepVGG-A0] (main.py 282): INFO Train: [196/300][20/78]	eta 0:02:18 lr 1.709843	time 1.1736 (2.3820)	loss 2.7450 (2.7229)	grad_norm 0.4865 (0.4532)	mem 39782MB
[2023-07-07 14:48:34 RepVGG-A0] (main.py 282): INFO Train: [196/300][30/78]	eta 0:01:42 lr 1.706043	time 1.3877 (2.1356)	loss 2.6900 (2.7214)	grad_norm 0.4468 (0.4531)	mem 39782MB
[2023-07-07 14:48:52 RepVGG-A0] (main.py 282): INFO Train: [196/300][40/78]	eta 0:01:17 lr 1.702245	time 3.6801 (2.0489)	loss 2.7943 (2.7238)	grad_norm 0.4458 (0.4542)	mem 39782MB
[2023-07-07 14:49:07 RepVGG-A0] (main.py 282): INFO Train: [196/300][50/78]	eta 0:00:54 lr 1.698450	time 1.1727 (1.9409)	loss 2.6850 (2.7272)	grad_norm 0.4323 (0.4534)	mem 39782MB
[2023-07-07 14:49:22 RepVGG-A0] (main.py 282): INFO Train: [196/300][60/78]	eta 0:00:33 lr 1.694657	time 1.3277 (1.8704)	loss 2.7362 (2.7292)	grad_norm 0.4516 (0.4499)	mem 39782MB
[2023-07-07 14:49:38 RepVGG-A0] (main.py 282): INFO Train: [196/300][70/78]	eta 0:00:14 lr 1.690867	time 1.1712 (1.8344)	loss 2.7144 (2.7308)	grad_norm 0.4302 (0.4485)	mem 39782MB
[2023-07-07 14:49:49 RepVGG-A0] (main.py 291): INFO EPOCH 196 training takes 0:02:21
[2023-07-07 14:50:11 RepVGG-A0] (main.py 282): INFO Train: [197/300][0/78]	eta 0:28:32 lr 1.687838	time 21.9524 (21.9524)	loss 2.6914 (2.6914)	grad_norm 0.4770 (0.4770)	mem 39782MB
[2023-07-07 14:50:26 RepVGG-A0] (main.py 282): INFO Train: [197/300][10/78]	eta 0:03:48 lr 1.684053	time 1.1716 (3.3573)	loss 2.7250 (2.7060)	grad_norm 0.4498 (0.4401)	mem 39782MB
[2023-07-07 14:50:41 RepVGG-A0] (main.py 282): INFO Train: [197/300][20/78]	eta 0:02:23 lr 1.680271	time 1.2894 (2.4661)	loss 2.7899 (2.7293)	grad_norm 0.4524 (0.4523)	mem 39782MB
[2023-07-07 14:50:56 RepVGG-A0] (main.py 282): INFO Train: [197/300][30/78]	eta 0:01:43 lr 1.676491	time 1.4494 (2.1582)	loss 2.7526 (2.7245)	grad_norm 0.4815 (0.4515)	mem 39782MB
[2023-07-07 14:51:14 RepVGG-A0] (main.py 282): INFO Train: [197/300][40/78]	eta 0:01:18 lr 1.672714	time 4.1693 (2.0641)	loss 2.7829 (2.7348)	grad_norm 0.4727 (0.4603)	mem 39782MB
[2023-07-07 14:51:29 RepVGG-A0] (main.py 282): INFO Train: [197/300][50/78]	eta 0:00:54 lr 1.668941	time 1.1733 (1.9585)	loss 2.8022 (2.7362)	grad_norm 0.4550 (0.4557)	mem 39782MB
[2023-07-07 14:51:45 RepVGG-A0] (main.py 282): INFO Train: [197/300][60/78]	eta 0:00:34 lr 1.665169	time 1.3065 (1.8955)	loss 2.7651 (2.7397)	grad_norm 0.4759 (0.4596)	mem 39782MB
[2023-07-07 14:52:00 RepVGG-A0] (main.py 282): INFO Train: [197/300][70/78]	eta 0:00:14 lr 1.661401	time 1.5133 (1.8449)	loss 2.7031 (2.7395)	grad_norm 0.4191 (0.4553)	mem 39782MB
[2023-07-07 14:52:13 RepVGG-A0] (main.py 291): INFO EPOCH 197 training takes 0:02:23
[2023-07-07 14:52:34 RepVGG-A0] (main.py 282): INFO Train: [198/300][0/78]	eta 0:27:24 lr 1.658388	time 21.0886 (21.0886)	loss 2.7216 (2.7216)	grad_norm 0.4569 (0.4569)	mem 39782MB
[2023-07-07 14:52:50 RepVGG-A0] (main.py 282): INFO Train: [198/300][10/78]	eta 0:03:49 lr 1.654625	time 1.1734 (3.3803)	loss 2.7661 (2.6992)	grad_norm 0.4549 (0.4517)	mem 39782MB
[2023-07-07 14:53:04 RepVGG-A0] (main.py 282): INFO Train: [198/300][20/78]	eta 0:02:22 lr 1.650864	time 1.1733 (2.4612)	loss 2.6631 (2.6973)	grad_norm 0.4598 (0.4501)	mem 39782MB
[2023-07-07 14:53:19 RepVGG-A0] (main.py 282): INFO Train: [198/300][30/78]	eta 0:01:43 lr 1.647106	time 1.2561 (2.1495)	loss 2.7161 (2.7081)	grad_norm 0.4697 (0.4514)	mem 39782MB
[2023-07-07 14:53:39 RepVGG-A0] (main.py 282): INFO Train: [198/300][40/78]	eta 0:01:19 lr 1.643351	time 3.0624 (2.0937)	loss 2.7317 (2.7138)	grad_norm 0.4484 (0.4539)	mem 39782MB
[2023-07-07 14:53:53 RepVGG-A0] (main.py 282): INFO Train: [198/300][50/78]	eta 0:00:55 lr 1.639599	time 1.2779 (1.9739)	loss 2.7294 (2.7175)	grad_norm 0.4767 (0.4527)	mem 39782MB
[2023-07-07 14:54:08 RepVGG-A0] (main.py 282): INFO Train: [198/300][60/78]	eta 0:00:33 lr 1.635850	time 1.2149 (1.8831)	loss 2.7415 (2.7199)	grad_norm 0.4818 (0.4556)	mem 39782MB
[2023-07-07 14:54:23 RepVGG-A0] (main.py 282): INFO Train: [198/300][70/78]	eta 0:00:14 lr 1.632103	time 1.2879 (1.8415)	loss 2.7243 (2.7186)	grad_norm 0.4412 (0.4538)	mem 39782MB
[2023-07-07 14:54:35 RepVGG-A0] (main.py 291): INFO EPOCH 198 training takes 0:02:22
[2023-07-07 14:54:55 RepVGG-A0] (main.py 282): INFO Train: [199/300][0/78]	eta 0:25:43 lr 1.629108	time 19.7859 (19.7859)	loss 2.7335 (2.7335)	grad_norm 0.5080 (0.5080)	mem 39782MB
[2023-07-07 14:55:11 RepVGG-A0] (main.py 282): INFO Train: [199/300][10/78]	eta 0:03:40 lr 1.625367	time 1.1927 (3.2379)	loss 2.6646 (2.6934)	grad_norm 0.4871 (0.4536)	mem 39782MB
[2023-07-07 14:55:25 RepVGG-A0] (main.py 282): INFO Train: [199/300][20/78]	eta 0:02:17 lr 1.621628	time 1.1745 (2.3713)	loss 2.6895 (2.7038)	grad_norm 0.4320 (0.4726)	mem 39782MB
[2023-07-07 14:55:41 RepVGG-A0] (main.py 282): INFO Train: [199/300][30/78]	eta 0:01:40 lr 1.617892	time 1.3066 (2.1022)	loss 2.6305 (2.7013)	grad_norm 0.4160 (0.4564)	mem 39782MB
[2023-07-07 14:55:57 RepVGG-A0] (main.py 282): INFO Train: [199/300][40/78]	eta 0:01:15 lr 1.614159	time 2.4154 (1.9786)	loss 2.8350 (2.7110)	grad_norm 0.4930 (0.4578)	mem 39782MB
[2023-07-07 14:56:13 RepVGG-A0] (main.py 282): INFO Train: [199/300][50/78]	eta 0:00:53 lr 1.610429	time 1.3412 (1.9081)	loss 2.7601 (2.7132)	grad_norm 0.4328 (0.4530)	mem 39782MB
[2023-07-07 14:56:28 RepVGG-A0] (main.py 282): INFO Train: [199/300][60/78]	eta 0:00:33 lr 1.606702	time 1.2082 (1.8448)	loss 2.7693 (2.7143)	grad_norm 0.4593 (0.4521)	mem 39782MB
[2023-07-07 14:56:43 RepVGG-A0] (main.py 282): INFO Train: [199/300][70/78]	eta 0:00:14 lr 1.602977	time 1.1710 (1.7959)	loss 2.7157 (2.7179)	grad_norm 0.4478 (0.4521)	mem 39782MB
[2023-07-07 14:56:55 RepVGG-A0] (main.py 291): INFO EPOCH 199 training takes 0:02:19
[2023-07-07 14:57:17 RepVGG-A0] (main.py 282): INFO Train: [200/300][0/78]	eta 0:28:30 lr 1.600000	time 21.9284 (21.9284)	loss 2.7172 (2.7172)	grad_norm 0.4235 (0.4235)	mem 39782MB
[2023-07-07 14:57:32 RepVGG-A0] (main.py 282): INFO Train: [200/300][10/78]	eta 0:03:49 lr 1.596281	time 1.1729 (3.3712)	loss 2.6530 (2.6988)	grad_norm 0.4494 (0.4678)	mem 39782MB
[2023-07-07 14:57:46 RepVGG-A0] (main.py 282): INFO Train: [200/300][20/78]	eta 0:02:21 lr 1.592565	time 1.2057 (2.4428)	loss 2.6958 (2.7026)	grad_norm 0.4626 (0.4614)	mem 39782MB
[2023-07-07 14:58:02 RepVGG-A0] (main.py 282): INFO Train: [200/300][30/78]	eta 0:01:43 lr 1.588851	time 1.3453 (2.1639)	loss 2.6887 (2.7001)	grad_norm 0.4165 (0.4536)	mem 39782MB
[2023-07-07 14:58:19 RepVGG-A0] (main.py 282): INFO Train: [200/300][40/78]	eta 0:01:17 lr 1.585141	time 3.3903 (2.0470)	loss 2.7055 (2.6972)	grad_norm 0.4453 (0.4541)	mem 39782MB
[2023-07-07 14:58:35 RepVGG-A0] (main.py 282): INFO Train: [200/300][50/78]	eta 0:00:54 lr 1.581433	time 1.1932 (1.9636)	loss 2.7040 (2.7016)	grad_norm 0.4563 (0.4536)	mem 39782MB
[2023-07-07 14:58:50 RepVGG-A0] (main.py 282): INFO Train: [200/300][60/78]	eta 0:00:34 lr 1.577728	time 1.1762 (1.8923)	loss 2.6404 (2.7015)	grad_norm 0.4873 (0.4545)	mem 39782MB
[2023-07-07 14:59:06 RepVGG-A0] (main.py 282): INFO Train: [200/300][70/78]	eta 0:00:14 lr 1.574027	time 1.1279 (1.8463)	loss 2.7085 (2.7077)	grad_norm 0.4348 (0.4551)	mem 39782MB
[2023-07-07 14:59:17 RepVGG-A0] (main.py 291): INFO EPOCH 200 training takes 0:02:22
[2023-07-07 14:59:34 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.626 (17.626)	Loss 2.1103 (2.1103)	Acc@1 54.468 (54.468)	Acc@5 78.546 (78.546)	Mem 39782MB
[2023-07-07 14:59:35 RepVGG-A0] (main.py 342): INFO  * Acc@1 54.550 Acc@5 78.434
[2023-07-07 14:59:35 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 200: 54.550%
[2023-07-07 14:59:35 RepVGG-A0] (main.py 172): INFO Max accuracy: 54.55%
[2023-07-07 14:59:58 RepVGG-A0] (main.py 282): INFO Train: [201/300][0/78]	eta 0:29:11 lr 1.571067	time 22.4505 (22.4505)	loss 2.6604 (2.6604)	grad_norm 0.4643 (0.4643)	mem 39782MB
[2023-07-07 15:00:12 RepVGG-A0] (main.py 282): INFO Train: [201/300][10/78]	eta 0:03:48 lr 1.567371	time 1.1726 (3.3654)	loss 2.7021 (2.6784)	grad_norm 0.4720 (0.4569)	mem 39782MB
[2023-07-07 15:00:27 RepVGG-A0] (main.py 282): INFO Train: [201/300][20/78]	eta 0:02:21 lr 1.563678	time 1.2357 (2.4414)	loss 2.6945 (2.6807)	grad_norm 0.4784 (0.4527)	mem 39782MB
[2023-07-07 15:00:42 RepVGG-A0] (main.py 282): INFO Train: [201/300][30/78]	eta 0:01:42 lr 1.559987	time 1.3430 (2.1352)	loss 2.6349 (2.6897)	grad_norm 0.4531 (0.4595)	mem 39782MB
[2023-07-07 15:01:00 RepVGG-A0] (main.py 282): INFO Train: [201/300][40/78]	eta 0:01:18 lr 1.556299	time 4.4161 (2.0621)	loss 2.6986 (2.6955)	grad_norm 0.4294 (0.4565)	mem 39782MB
[2023-07-07 15:01:15 RepVGG-A0] (main.py 282): INFO Train: [201/300][50/78]	eta 0:00:54 lr 1.552615	time 1.1714 (1.9452)	loss 2.8180 (2.6966)	grad_norm 0.4932 (0.4562)	mem 39782MB
[2023-07-07 15:01:30 RepVGG-A0] (main.py 282): INFO Train: [201/300][60/78]	eta 0:00:33 lr 1.548933	time 1.4877 (1.8847)	loss 2.6922 (2.7064)	grad_norm 0.4492 (0.4645)	mem 39782MB
[2023-07-07 15:01:45 RepVGG-A0] (main.py 282): INFO Train: [201/300][70/78]	eta 0:00:14 lr 1.545254	time 1.1718 (1.8252)	loss 2.7542 (2.7101)	grad_norm 0.4466 (0.4634)	mem 39782MB
[2023-07-07 15:01:57 RepVGG-A0] (main.py 291): INFO EPOCH 201 training takes 0:02:21
[2023-07-07 15:02:19 RepVGG-A0] (main.py 282): INFO Train: [202/300][0/78]	eta 0:28:05 lr 1.542314	time 21.6052 (21.6052)	loss 2.7220 (2.7220)	grad_norm 0.4479 (0.4479)	mem 39782MB
[2023-07-07 15:02:33 RepVGG-A0] (main.py 282): INFO Train: [202/300][10/78]	eta 0:03:43 lr 1.538640	time 1.1719 (3.2932)	loss 2.6976 (2.6771)	grad_norm 0.4152 (0.4501)	mem 39782MB
[2023-07-07 15:02:49 RepVGG-A0] (main.py 282): INFO Train: [202/300][20/78]	eta 0:02:22 lr 1.534970	time 1.4610 (2.4630)	loss 2.6772 (2.6772)	grad_norm 0.4604 (0.4558)	mem 39782MB
[2023-07-07 15:03:03 RepVGG-A0] (main.py 282): INFO Train: [202/300][30/78]	eta 0:01:42 lr 1.531303	time 1.4191 (2.1428)	loss 2.6920 (2.6784)	grad_norm 0.4561 (0.4486)	mem 39782MB
[2023-07-07 15:03:22 RepVGG-A0] (main.py 282): INFO Train: [202/300][40/78]	eta 0:01:18 lr 1.527638	time 3.8713 (2.0700)	loss 2.8209 (2.6898)	grad_norm 0.5535 (0.4623)	mem 39782MB
[2023-07-07 15:03:36 RepVGG-A0] (main.py 282): INFO Train: [202/300][50/78]	eta 0:00:54 lr 1.523977	time 1.3926 (1.9529)	loss 2.7872 (2.6934)	grad_norm 0.4480 (0.4585)	mem 39782MB
[2023-07-07 15:03:52 RepVGG-A0] (main.py 282): INFO Train: [202/300][60/78]	eta 0:00:33 lr 1.520319	time 1.1775 (1.8819)	loss 2.6327 (2.6919)	grad_norm 0.4488 (0.4556)	mem 39782MB
[2023-07-07 15:04:07 RepVGG-A0] (main.py 282): INFO Train: [202/300][70/78]	eta 0:00:14 lr 1.516663	time 1.6447 (1.8255)	loss 2.7141 (2.6947)	grad_norm 0.4678 (0.4571)	mem 39782MB
[2023-07-07 15:04:18 RepVGG-A0] (main.py 291): INFO EPOCH 202 training takes 0:02:20
[2023-07-07 15:04:39 RepVGG-A0] (main.py 282): INFO Train: [203/300][0/78]	eta 0:27:35 lr 1.513741	time 21.2201 (21.2201)	loss 2.6507 (2.6507)	grad_norm 0.4610 (0.4610)	mem 39782MB
[2023-07-07 15:04:54 RepVGG-A0] (main.py 282): INFO Train: [203/300][10/78]	eta 0:03:42 lr 1.510092	time 1.1720 (3.2698)	loss 2.6850 (2.6683)	grad_norm 0.4398 (0.4600)	mem 39782MB
[2023-07-07 15:05:09 RepVGG-A0] (main.py 282): INFO Train: [203/300][20/78]	eta 0:02:21 lr 1.506445	time 1.2408 (2.4444)	loss 2.6929 (2.6775)	grad_norm 0.4564 (0.4558)	mem 39782MB
[2023-07-07 15:05:24 RepVGG-A0] (main.py 282): INFO Train: [203/300][30/78]	eta 0:01:42 lr 1.502801	time 1.3463 (2.1311)	loss 2.7966 (2.6850)	grad_norm 0.4566 (0.4520)	mem 39782MB
[2023-07-07 15:05:41 RepVGG-A0] (main.py 282): INFO Train: [203/300][40/78]	eta 0:01:17 lr 1.499161	time 1.9038 (2.0282)	loss 2.7115 (2.6937)	grad_norm 0.4678 (0.4598)	mem 39782MB
[2023-07-07 15:05:56 RepVGG-A0] (main.py 282): INFO Train: [203/300][50/78]	eta 0:00:54 lr 1.495523	time 1.1726 (1.9327)	loss 2.6751 (2.6916)	grad_norm 0.4720 (0.4575)	mem 39782MB
[2023-07-07 15:06:11 RepVGG-A0] (main.py 282): INFO Train: [203/300][60/78]	eta 0:00:33 lr 1.491889	time 1.2681 (1.8593)	loss 2.6838 (2.6913)	grad_norm 0.4767 (0.4594)	mem 39782MB
[2023-07-07 15:06:26 RepVGG-A0] (main.py 282): INFO Train: [203/300][70/78]	eta 0:00:14 lr 1.488257	time 1.3803 (1.8069)	loss 2.7344 (2.6939)	grad_norm 0.4470 (0.4568)	mem 39782MB
[2023-07-07 15:06:38 RepVGG-A0] (main.py 291): INFO EPOCH 203 training takes 0:02:20
[2023-07-07 15:06:58 RepVGG-A0] (main.py 282): INFO Train: [204/300][0/78]	eta 0:26:07 lr 1.485354	time 20.1021 (20.1021)	loss 2.6584 (2.6584)	grad_norm 0.4325 (0.4325)	mem 39782MB
[2023-07-07 15:07:13 RepVGG-A0] (main.py 282): INFO Train: [204/300][10/78]	eta 0:03:37 lr 1.481728	time 1.1719 (3.1941)	loss 2.7041 (2.6766)	grad_norm 0.4687 (0.4776)	mem 39782MB
[2023-07-07 15:07:29 RepVGG-A0] (main.py 282): INFO Train: [204/300][20/78]	eta 0:02:19 lr 1.478106	time 1.1756 (2.4127)	loss 2.6757 (2.6836)	grad_norm 0.4837 (0.4665)	mem 39782MB
[2023-07-07 15:07:45 RepVGG-A0] (main.py 282): INFO Train: [204/300][30/78]	eta 0:01:42 lr 1.474486	time 1.4069 (2.1422)	loss 2.6959 (2.6893)	grad_norm 0.4788 (0.4724)	mem 39782MB
[2023-07-07 15:08:02 RepVGG-A0] (main.py 282): INFO Train: [204/300][40/78]	eta 0:01:18 lr 1.470869	time 2.7540 (2.0550)	loss 2.6937 (2.6857)	grad_norm 0.4729 (0.4648)	mem 39782MB
[2023-07-07 15:08:17 RepVGG-A0] (main.py 282): INFO Train: [204/300][50/78]	eta 0:00:54 lr 1.467256	time 1.1730 (1.9404)	loss 2.7035 (2.6911)	grad_norm 0.4387 (0.4709)	mem 39782MB
[2023-07-07 15:08:33 RepVGG-A0] (main.py 282): INFO Train: [204/300][60/78]	eta 0:00:33 lr 1.463646	time 1.3182 (1.8773)	loss 2.6587 (2.6901)	grad_norm 0.4452 (0.4674)	mem 39782MB
[2023-07-07 15:08:47 RepVGG-A0] (main.py 282): INFO Train: [204/300][70/78]	eta 0:00:14 lr 1.460039	time 1.1917 (1.8146)	loss 2.7079 (2.6912)	grad_norm 0.5104 (0.4689)	mem 39782MB
[2023-07-07 15:08:59 RepVGG-A0] (main.py 291): INFO EPOCH 204 training takes 0:02:20
[2023-07-07 15:09:18 RepVGG-A0] (main.py 282): INFO Train: [205/300][0/78]	eta 0:25:09 lr 1.457155	time 19.3583 (19.3583)	loss 2.5648 (2.5648)	grad_norm 0.4268 (0.4268)	mem 39782MB
[2023-07-07 15:09:35 RepVGG-A0] (main.py 282): INFO Train: [205/300][10/78]	eta 0:03:41 lr 1.453554	time 1.1730 (3.2643)	loss 2.6393 (2.6472)	grad_norm 0.5214 (0.4603)	mem 39782MB
[2023-07-07 15:09:51 RepVGG-A0] (main.py 282): INFO Train: [205/300][20/78]	eta 0:02:23 lr 1.449955	time 1.2048 (2.4798)	loss 2.6461 (2.6690)	grad_norm 0.4474 (0.4633)	mem 39782MB
[2023-07-07 15:10:06 RepVGG-A0] (main.py 282): INFO Train: [205/300][30/78]	eta 0:01:43 lr 1.446360	time 1.2696 (2.1611)	loss 2.6485 (2.6680)	grad_norm 0.4202 (0.4566)	mem 39782MB
[2023-07-07 15:10:23 RepVGG-A0] (main.py 282): INFO Train: [205/300][40/78]	eta 0:01:17 lr 1.442768	time 2.0452 (2.0501)	loss 2.6536 (2.6682)	grad_norm 0.4638 (0.4551)	mem 39782MB
[2023-07-07 15:10:38 RepVGG-A0] (main.py 282): INFO Train: [205/300][50/78]	eta 0:00:54 lr 1.439179	time 1.1714 (1.9364)	loss 2.6666 (2.6707)	grad_norm 0.4931 (0.4569)	mem 39782MB
[2023-07-07 15:10:53 RepVGG-A0] (main.py 282): INFO Train: [205/300][60/78]	eta 0:00:33 lr 1.435593	time 1.1904 (1.8642)	loss 2.6675 (2.6756)	grad_norm 0.4572 (0.4584)	mem 39782MB
[2023-07-07 15:11:10 RepVGG-A0] (main.py 282): INFO Train: [205/300][70/78]	eta 0:00:14 lr 1.432011	time 1.4704 (1.8389)	loss 2.7625 (2.6797)	grad_norm 0.4536 (0.4589)	mem 39782MB
[2023-07-07 15:11:21 RepVGG-A0] (main.py 291): INFO EPOCH 205 training takes 0:02:21
[2023-07-07 15:11:42 RepVGG-A0] (main.py 282): INFO Train: [206/300][0/78]	eta 0:28:23 lr 1.429147	time 21.8453 (21.8453)	loss 2.6968 (2.6968)	grad_norm 0.4490 (0.4490)	mem 39782MB
[2023-07-07 15:11:58 RepVGG-A0] (main.py 282): INFO Train: [206/300][10/78]	eta 0:03:50 lr 1.425570	time 1.2047 (3.3876)	loss 2.6308 (2.6694)	grad_norm 0.5078 (0.4835)	mem 39782MB
[2023-07-07 15:12:13 RepVGG-A0] (main.py 282): INFO Train: [206/300][20/78]	eta 0:02:24 lr 1.421997	time 1.2889 (2.4834)	loss 2.6881 (2.6606)	grad_norm 0.4207 (0.4753)	mem 39782MB
[2023-07-07 15:12:28 RepVGG-A0] (main.py 282): INFO Train: [206/300][30/78]	eta 0:01:44 lr 1.418426	time 1.2555 (2.1737)	loss 2.6709 (2.6586)	grad_norm 0.4883 (0.4718)	mem 39782MB
[2023-07-07 15:12:48 RepVGG-A0] (main.py 282): INFO Train: [206/300][40/78]	eta 0:01:20 lr 1.414859	time 2.8357 (2.1234)	loss 2.6626 (2.6608)	grad_norm 0.4709 (0.4731)	mem 39782MB
[2023-07-07 15:13:03 RepVGG-A0] (main.py 282): INFO Train: [206/300][50/78]	eta 0:00:56 lr 1.411295	time 1.1713 (2.0026)	loss 2.7870 (2.6637)	grad_norm 0.4930 (0.4689)	mem 39782MB
[2023-07-07 15:13:18 RepVGG-A0] (main.py 282): INFO Train: [206/300][60/78]	eta 0:00:34 lr 1.407734	time 1.2532 (1.9333)	loss 2.6846 (2.6676)	grad_norm 0.4478 (0.4682)	mem 39782MB
[2023-07-07 15:13:33 RepVGG-A0] (main.py 282): INFO Train: [206/300][70/78]	eta 0:00:14 lr 1.404177	time 1.1284 (1.8714)	loss 2.6773 (2.6710)	grad_norm 0.5127 (0.4701)	mem 39782MB
[2023-07-07 15:13:45 RepVGG-A0] (main.py 291): INFO EPOCH 206 training takes 0:02:24
[2023-07-07 15:14:07 RepVGG-A0] (main.py 282): INFO Train: [207/300][0/78]	eta 0:28:36 lr 1.401333	time 22.0081 (22.0081)	loss 2.6105 (2.6105)	grad_norm 0.4561 (0.4561)	mem 39782MB
[2023-07-07 15:14:22 RepVGG-A0] (main.py 282): INFO Train: [207/300][10/78]	eta 0:03:48 lr 1.397782	time 1.1960 (3.3554)	loss 2.6658 (2.6235)	grad_norm 0.4834 (0.4459)	mem 39782MB
[2023-07-07 15:14:36 RepVGG-A0] (main.py 282): INFO Train: [207/300][20/78]	eta 0:02:20 lr 1.394233	time 1.1750 (2.4301)	loss 2.6755 (2.6433)	grad_norm 0.4360 (0.4585)	mem 39782MB
[2023-07-07 15:14:51 RepVGG-A0] (main.py 282): INFO Train: [207/300][30/78]	eta 0:01:41 lr 1.390688	time 1.3345 (2.1240)	loss 2.6204 (2.6407)	grad_norm 0.4687 (0.4598)	mem 39782MB
[2023-07-07 15:15:10 RepVGG-A0] (main.py 282): INFO Train: [207/300][40/78]	eta 0:01:18 lr 1.387146	time 3.2593 (2.0604)	loss 2.6698 (2.6457)	grad_norm 0.4621 (0.4605)	mem 39782MB
[2023-07-07 15:15:25 RepVGG-A0] (main.py 282): INFO Train: [207/300][50/78]	eta 0:00:54 lr 1.383607	time 1.1716 (1.9548)	loss 2.6843 (2.6495)	grad_norm 0.4694 (0.4593)	mem 39782MB
[2023-07-07 15:15:39 RepVGG-A0] (main.py 282): INFO Train: [207/300][60/78]	eta 0:00:33 lr 1.380072	time 1.1780 (1.8727)	loss 2.6743 (2.6584)	grad_norm 0.4483 (0.4621)	mem 39782MB
[2023-07-07 15:15:55 RepVGG-A0] (main.py 282): INFO Train: [207/300][70/78]	eta 0:00:14 lr 1.376540	time 1.2156 (1.8255)	loss 2.7203 (2.6633)	grad_norm 0.5273 (0.4610)	mem 39782MB
[2023-07-07 15:16:06 RepVGG-A0] (main.py 291): INFO EPOCH 207 training takes 0:02:20
[2023-07-07 15:16:27 RepVGG-A0] (main.py 282): INFO Train: [208/300][0/78]	eta 0:27:27 lr 1.373717	time 21.1272 (21.1272)	loss 2.6811 (2.6811)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:16:42 RepVGG-A0] (main.py 282): INFO Train: [208/300][10/78]	eta 0:03:40 lr 1.370190	time 1.1740 (3.2399)	loss 2.6173 (2.6261)	grad_norm 0.4304 (0.4576)	mem 39782MB
[2023-07-07 15:16:56 RepVGG-A0] (main.py 282): INFO Train: [208/300][20/78]	eta 0:02:17 lr 1.366668	time 1.1725 (2.3766)	loss 2.7100 (2.6558)	grad_norm 0.5722 (0.4871)	mem 39782MB
[2023-07-07 15:17:10 RepVGG-A0] (main.py 282): INFO Train: [208/300][30/78]	eta 0:01:39 lr 1.363148	time 1.4510 (2.0776)	loss 2.6955 (2.6646)	grad_norm 0.4372 (0.4908)	mem 39782MB
[2023-07-07 15:17:30 RepVGG-A0] (main.py 282): INFO Train: [208/300][40/78]	eta 0:01:17 lr 1.359632	time 5.3023 (2.0444)	loss 2.6592 (2.6653)	grad_norm 0.4529 (0.4803)	mem 39782MB
[2023-07-07 15:17:45 RepVGG-A0] (main.py 282): INFO Train: [208/300][50/78]	eta 0:00:54 lr 1.356119	time 1.1724 (1.9391)	loss 2.6475 (2.6679)	grad_norm 0.4589 (0.4742)	mem 39782MB
[2023-07-07 15:18:00 RepVGG-A0] (main.py 282): INFO Train: [208/300][60/78]	eta 0:00:33 lr 1.352609	time 1.1762 (1.8709)	loss 2.6777 (2.6680)	grad_norm 0.5027 (0.4740)	mem 39782MB
[2023-07-07 15:18:15 RepVGG-A0] (main.py 282): INFO Train: [208/300][70/78]	eta 0:00:14 lr 1.349103	time 1.3047 (1.8155)	loss 2.6448 (2.6702)	grad_norm 0.4364 (0.4734)	mem 39782MB
[2023-07-07 15:18:27 RepVGG-A0] (main.py 291): INFO EPOCH 208 training takes 0:02:20
[2023-07-07 15:18:48 RepVGG-A0] (main.py 282): INFO Train: [209/300][0/78]	eta 0:27:41 lr 1.346300	time 21.2976 (21.2976)	loss 2.6293 (2.6293)	grad_norm 0.4722 (0.4722)	mem 39782MB
[2023-07-07 15:19:04 RepVGG-A0] (main.py 282): INFO Train: [209/300][10/78]	eta 0:03:50 lr 1.342800	time 1.1729 (3.3837)	loss 2.6038 (2.6288)	grad_norm 0.4505 (0.4658)	mem 39782MB
[2023-07-07 15:19:19 RepVGG-A0] (main.py 282): INFO Train: [209/300][20/78]	eta 0:02:24 lr 1.339303	time 1.4111 (2.4860)	loss 2.5905 (2.6300)	grad_norm 0.4839 (0.4602)	mem 39782MB
[2023-07-07 15:19:35 RepVGG-A0] (main.py 282): INFO Train: [209/300][30/78]	eta 0:01:45 lr 1.335809	time 1.9300 (2.1888)	loss 2.6832 (2.6360)	grad_norm 0.4522 (0.4636)	mem 39782MB
[2023-07-07 15:19:53 RepVGG-A0] (main.py 282): INFO Train: [209/300][40/78]	eta 0:01:19 lr 1.332319	time 4.2612 (2.0927)	loss 2.6851 (2.6427)	grad_norm 0.4650 (0.4680)	mem 39782MB
[2023-07-07 15:20:07 RepVGG-A0] (main.py 282): INFO Train: [209/300][50/78]	eta 0:00:55 lr 1.328832	time 1.1755 (1.9650)	loss 2.6930 (2.6446)	grad_norm 0.4505 (0.4659)	mem 39782MB
[2023-07-07 15:20:23 RepVGG-A0] (main.py 282): INFO Train: [209/300][60/78]	eta 0:00:34 lr 1.325349	time 1.2223 (1.8956)	loss 2.6700 (2.6493)	grad_norm 0.4856 (0.4687)	mem 39782MB
[2023-07-07 15:20:38 RepVGG-A0] (main.py 282): INFO Train: [209/300][70/78]	eta 0:00:14 lr 1.321869	time 1.1278 (1.8430)	loss 2.6428 (2.6529)	grad_norm 0.4369 (0.4675)	mem 39782MB
[2023-07-07 15:20:49 RepVGG-A0] (main.py 291): INFO EPOCH 209 training takes 0:02:22
[2023-07-07 15:21:10 RepVGG-A0] (main.py 282): INFO Train: [210/300][0/78]	eta 0:27:12 lr 1.319087	time 20.9303 (20.9303)	loss 2.5725 (2.5725)	grad_norm 0.4836 (0.4836)	mem 39782MB
[2023-07-07 15:21:24 RepVGG-A0] (main.py 282): INFO Train: [210/300][10/78]	eta 0:03:34 lr 1.315613	time 1.1736 (3.1587)	loss 2.6538 (2.6015)	grad_norm 0.4594 (0.4600)	mem 39782MB
[2023-07-07 15:21:38 RepVGG-A0] (main.py 282): INFO Train: [210/300][20/78]	eta 0:02:15 lr 1.312143	time 1.1727 (2.3383)	loss 2.6922 (2.6262)	grad_norm 0.4737 (0.4724)	mem 39782MB
[2023-07-07 15:21:54 RepVGG-A0] (main.py 282): INFO Train: [210/300][30/78]	eta 0:01:39 lr 1.308675	time 1.3676 (2.0756)	loss 2.6122 (2.6305)	grad_norm 0.4746 (0.4716)	mem 39782MB
[2023-07-07 15:22:11 RepVGG-A0] (main.py 282): INFO Train: [210/300][40/78]	eta 0:01:15 lr 1.305212	time 3.0048 (1.9887)	loss 2.5652 (2.6353)	grad_norm 0.4621 (0.4693)	mem 39782MB
[2023-07-07 15:22:27 RepVGG-A0] (main.py 282): INFO Train: [210/300][50/78]	eta 0:00:53 lr 1.301751	time 1.1280 (1.9085)	loss 2.7413 (2.6415)	grad_norm 0.4663 (0.4668)	mem 39782MB
[2023-07-07 15:22:42 RepVGG-A0] (main.py 282): INFO Train: [210/300][60/78]	eta 0:00:33 lr 1.298294	time 1.1762 (1.8505)	loss 2.7361 (2.6455)	grad_norm 0.4484 (0.4675)	mem 39782MB
[2023-07-07 15:22:57 RepVGG-A0] (main.py 282): INFO Train: [210/300][70/78]	eta 0:00:14 lr 1.294841	time 1.1761 (1.8017)	loss 2.6704 (2.6459)	grad_norm 0.5262 (0.4707)	mem 39782MB
[2023-07-07 15:23:10 RepVGG-A0] (main.py 291): INFO EPOCH 210 training takes 0:02:20
[2023-07-07 15:23:31 RepVGG-A0] (main.py 282): INFO Train: [211/300][0/78]	eta 0:27:41 lr 1.292080	time 21.3054 (21.3054)	loss 2.6925 (2.6925)	grad_norm 0.4356 (0.4356)	mem 39782MB
[2023-07-07 15:23:46 RepVGG-A0] (main.py 282): INFO Train: [211/300][10/78]	eta 0:03:41 lr 1.288633	time 1.1744 (3.2596)	loss 2.6599 (2.6117)	grad_norm 0.4630 (0.4541)	mem 39782MB
[2023-07-07 15:24:00 RepVGG-A0] (main.py 282): INFO Train: [211/300][20/78]	eta 0:02:18 lr 1.285189	time 1.1727 (2.3923)	loss 2.5803 (2.6201)	grad_norm 0.4485 (0.4595)	mem 39782MB
[2023-07-07 15:24:15 RepVGG-A0] (main.py 282): INFO Train: [211/300][30/78]	eta 0:01:41 lr 1.281749	time 1.4993 (2.1160)	loss 2.6525 (2.6264)	grad_norm 0.4985 (0.4621)	mem 39782MB
[2023-07-07 15:24:33 RepVGG-A0] (main.py 282): INFO Train: [211/300][40/78]	eta 0:01:17 lr 1.278312	time 4.1690 (2.0389)	loss 2.6651 (2.6317)	grad_norm 0.4584 (0.4635)	mem 39782MB
[2023-07-07 15:24:48 RepVGG-A0] (main.py 282): INFO Train: [211/300][50/78]	eta 0:00:53 lr 1.274878	time 1.1908 (1.9246)	loss 2.6082 (2.6340)	grad_norm 0.5000 (0.4648)	mem 39782MB
[2023-07-07 15:25:03 RepVGG-A0] (main.py 282): INFO Train: [211/300][60/78]	eta 0:00:33 lr 1.271448	time 1.1763 (1.8605)	loss 2.6538 (2.6385)	grad_norm 0.4516 (0.4671)	mem 39782MB
[2023-07-07 15:25:18 RepVGG-A0] (main.py 282): INFO Train: [211/300][70/78]	eta 0:00:14 lr 1.268022	time 1.1289 (1.8065)	loss 2.6208 (2.6448)	grad_norm 0.5160 (0.4688)	mem 39782MB
[2023-07-07 15:25:30 RepVGG-A0] (main.py 291): INFO EPOCH 211 training takes 0:02:20
[2023-07-07 15:25:52 RepVGG-A0] (main.py 282): INFO Train: [212/300][0/78]	eta 0:28:18 lr 1.265283	time 21.7766 (21.7766)	loss 2.6000 (2.6000)	grad_norm 0.4468 (0.4468)	mem 39782MB
[2023-07-07 15:26:06 RepVGG-A0] (main.py 282): INFO Train: [212/300][10/78]	eta 0:03:41 lr 1.261863	time 1.1724 (3.2507)	loss 2.6706 (2.6139)	grad_norm 0.4791 (0.4590)	mem 39782MB
[2023-07-07 15:26:21 RepVGG-A0] (main.py 282): INFO Train: [212/300][20/78]	eta 0:02:20 lr 1.258446	time 1.2868 (2.4164)	loss 2.5461 (2.6132)	grad_norm 0.4377 (0.4671)	mem 39782MB
[2023-07-07 15:26:36 RepVGG-A0] (main.py 282): INFO Train: [212/300][30/78]	eta 0:01:41 lr 1.255032	time 1.3592 (2.1193)	loss 2.6261 (2.6183)	grad_norm 0.4815 (0.4687)	mem 39782MB
[2023-07-07 15:26:54 RepVGG-A0] (main.py 282): INFO Train: [212/300][40/78]	eta 0:01:17 lr 1.251623	time 4.0886 (2.0515)	loss 2.6555 (2.6205)	grad_norm 0.4764 (0.4668)	mem 39782MB
[2023-07-07 15:27:09 RepVGG-A0] (main.py 282): INFO Train: [212/300][50/78]	eta 0:00:54 lr 1.248216	time 1.1697 (1.9370)	loss 2.6908 (2.6256)	grad_norm 0.4431 (0.4696)	mem 39782MB
[2023-07-07 15:27:25 RepVGG-A0] (main.py 282): INFO Train: [212/300][60/78]	eta 0:00:33 lr 1.244814	time 1.3474 (1.8808)	loss 2.6548 (2.6319)	grad_norm 0.4883 (0.4686)	mem 39782MB
[2023-07-07 15:27:39 RepVGG-A0] (main.py 282): INFO Train: [212/300][70/78]	eta 0:00:14 lr 1.241414	time 1.1764 (1.8086)	loss 2.6182 (2.6366)	grad_norm 0.4819 (0.4687)	mem 39782MB
[2023-07-07 15:27:52 RepVGG-A0] (main.py 291): INFO EPOCH 212 training takes 0:02:21
[2023-07-07 15:28:12 RepVGG-A0] (main.py 282): INFO Train: [213/300][0/78]	eta 0:26:44 lr 1.238697	time 20.5692 (20.5692)	loss 2.5808 (2.5808)	grad_norm 0.4698 (0.4698)	mem 39782MB
[2023-07-07 15:28:27 RepVGG-A0] (main.py 282): INFO Train: [213/300][10/78]	eta 0:03:36 lr 1.235305	time 1.1685 (3.1841)	loss 2.6820 (2.6074)	grad_norm 0.4888 (0.4668)	mem 39782MB
[2023-07-07 15:28:42 RepVGG-A0] (main.py 282): INFO Train: [213/300][20/78]	eta 0:02:17 lr 1.231915	time 1.1744 (2.3780)	loss 2.5989 (2.6134)	grad_norm 0.4763 (0.4782)	mem 39782MB
[2023-07-07 15:28:57 RepVGG-A0] (main.py 282): INFO Train: [213/300][30/78]	eta 0:01:40 lr 1.228529	time 1.5780 (2.1030)	loss 2.6427 (2.6121)	grad_norm 0.4601 (0.4699)	mem 39782MB
[2023-07-07 15:29:15 RepVGG-A0] (main.py 282): INFO Train: [213/300][40/78]	eta 0:01:16 lr 1.225147	time 4.0879 (2.0249)	loss 2.6927 (2.6206)	grad_norm 0.5136 (0.4774)	mem 39782MB
[2023-07-07 15:29:30 RepVGG-A0] (main.py 282): INFO Train: [213/300][50/78]	eta 0:00:53 lr 1.221768	time 1.1920 (1.9252)	loss 2.6384 (2.6193)	grad_norm 0.4761 (0.4741)	mem 39782MB
[2023-07-07 15:29:45 RepVGG-A0] (main.py 282): INFO Train: [213/300][60/78]	eta 0:00:33 lr 1.218393	time 1.1821 (1.8634)	loss 2.6719 (2.6227)	grad_norm 0.5029 (0.4761)	mem 39782MB
[2023-07-07 15:30:01 RepVGG-A0] (main.py 282): INFO Train: [213/300][70/78]	eta 0:00:14 lr 1.215022	time 1.2922 (1.8251)	loss 2.6394 (2.6270)	grad_norm 0.4545 (0.4756)	mem 39782MB
[2023-07-07 15:30:13 RepVGG-A0] (main.py 291): INFO EPOCH 213 training takes 0:02:21
[2023-07-07 15:30:33 RepVGG-A0] (main.py 282): INFO Train: [214/300][0/78]	eta 0:25:23 lr 1.212327	time 19.5369 (19.5369)	loss 2.6280 (2.6280)	grad_norm 0.4605 (0.4605)	mem 39782MB
[2023-07-07 15:30:49 RepVGG-A0] (main.py 282): INFO Train: [214/300][10/78]	eta 0:03:40 lr 1.208962	time 1.1705 (3.2443)	loss 2.6344 (2.6027)	grad_norm 0.4649 (0.4605)	mem 39782MB
[2023-07-07 15:31:05 RepVGG-A0] (main.py 282): INFO Train: [214/300][20/78]	eta 0:02:23 lr 1.205600	time 1.2990 (2.4820)	loss 2.5909 (2.5944)	grad_norm 0.5483 (0.4681)	mem 39782MB
[2023-07-07 15:31:19 RepVGG-A0] (main.py 282): INFO Train: [214/300][30/78]	eta 0:01:42 lr 1.202243	time 1.3165 (2.1390)	loss 2.6662 (2.6076)	grad_norm 0.4734 (0.4799)	mem 39782MB
[2023-07-07 15:31:37 RepVGG-A0] (main.py 282): INFO Train: [214/300][40/78]	eta 0:01:17 lr 1.198888	time 3.0709 (2.0513)	loss 2.5945 (2.6132)	grad_norm 0.4667 (0.4781)	mem 39782MB
[2023-07-07 15:31:52 RepVGG-A0] (main.py 282): INFO Train: [214/300][50/78]	eta 0:00:54 lr 1.195538	time 1.1955 (1.9395)	loss 2.6578 (2.6154)	grad_norm 0.4861 (0.4744)	mem 39782MB
[2023-07-07 15:32:07 RepVGG-A0] (main.py 282): INFO Train: [214/300][60/78]	eta 0:00:33 lr 1.192190	time 1.1817 (1.8682)	loss 2.6185 (2.6196)	grad_norm 0.4660 (0.4822)	mem 39782MB
[2023-07-07 15:32:23 RepVGG-A0] (main.py 282): INFO Train: [214/300][70/78]	eta 0:00:14 lr 1.188847	time 1.2781 (1.8308)	loss 2.7223 (2.6208)	grad_norm 0.4832 (0.4792)	mem 39782MB
[2023-07-07 15:32:33 RepVGG-A0] (main.py 291): INFO EPOCH 214 training takes 0:02:20
[2023-07-07 15:32:55 RepVGG-A0] (main.py 282): INFO Train: [215/300][0/78]	eta 0:27:44 lr 1.186175	time 21.3406 (21.3406)	loss 2.6178 (2.6178)	grad_norm 0.4838 (0.4838)	mem 39782MB
[2023-07-07 15:33:09 RepVGG-A0] (main.py 282): INFO Train: [215/300][10/78]	eta 0:03:40 lr 1.182838	time 1.1743 (3.2471)	loss 2.6186 (2.5735)	grad_norm 0.4760 (0.4567)	mem 39782MB
[2023-07-07 15:33:25 RepVGG-A0] (main.py 282): INFO Train: [215/300][20/78]	eta 0:02:23 lr 1.179504	time 1.1746 (2.4678)	loss 2.6003 (2.5822)	grad_norm 0.5156 (0.4638)	mem 39782MB
[2023-07-07 15:33:42 RepVGG-A0] (main.py 282): INFO Train: [215/300][30/78]	eta 0:01:45 lr 1.176175	time 1.1286 (2.1960)	loss 2.6442 (2.5996)	grad_norm 0.4806 (0.4775)	mem 39782MB
[2023-07-07 15:33:59 RepVGG-A0] (main.py 282): INFO Train: [215/300][40/78]	eta 0:01:19 lr 1.172849	time 2.9790 (2.0834)	loss 2.7057 (2.5999)	grad_norm 0.4640 (0.4733)	mem 39782MB
[2023-07-07 15:34:14 RepVGG-A0] (main.py 282): INFO Train: [215/300][50/78]	eta 0:00:55 lr 1.169526	time 1.1729 (1.9791)	loss 2.6567 (2.6078)	grad_norm 0.5113 (0.4762)	mem 39782MB
[2023-07-07 15:34:29 RepVGG-A0] (main.py 282): INFO Train: [215/300][60/78]	eta 0:00:34 lr 1.166208	time 1.1764 (1.8923)	loss 2.7002 (2.6130)	grad_norm 0.4671 (0.4752)	mem 39782MB
[2023-07-07 15:34:44 RepVGG-A0] (main.py 282): INFO Train: [215/300][70/78]	eta 0:00:14 lr 1.162893	time 1.1543 (1.8391)	loss 2.5891 (2.6145)	grad_norm 0.4564 (0.4789)	mem 39782MB
[2023-07-07 15:34:55 RepVGG-A0] (main.py 291): INFO EPOCH 215 training takes 0:02:22
[2023-07-07 15:35:17 RepVGG-A0] (main.py 282): INFO Train: [216/300][0/78]	eta 0:27:27 lr 1.160243	time 21.1225 (21.1225)	loss 2.6173 (2.6173)	grad_norm 0.5179 (0.5179)	mem 39782MB
[2023-07-07 15:35:33 RepVGG-A0] (main.py 282): INFO Train: [216/300][10/78]	eta 0:03:51 lr 1.156935	time 1.1720 (3.4057)	loss 2.6016 (2.5959)	grad_norm 0.4784 (0.4752)	mem 39782MB
[2023-07-07 15:35:47 RepVGG-A0] (main.py 282): INFO Train: [216/300][20/78]	eta 0:02:22 lr 1.153630	time 1.1745 (2.4608)	loss 2.6082 (2.5986)	grad_norm 0.4568 (0.4693)	mem 39782MB
[2023-07-07 15:36:03 RepVGG-A0] (main.py 282): INFO Train: [216/300][30/78]	eta 0:01:44 lr 1.150329	time 1.5423 (2.1842)	loss 2.6795 (2.6002)	grad_norm 0.5016 (0.4759)	mem 39782MB
[2023-07-07 15:36:21 RepVGG-A0] (main.py 282): INFO Train: [216/300][40/78]	eta 0:01:18 lr 1.147032	time 4.3340 (2.0749)	loss 2.6861 (2.6061)	grad_norm 0.4737 (0.4743)	mem 39782MB
[2023-07-07 15:36:36 RepVGG-A0] (main.py 282): INFO Train: [216/300][50/78]	eta 0:00:55 lr 1.143738	time 1.2278 (1.9676)	loss 2.6679 (2.6119)	grad_norm 0.5457 (0.4820)	mem 39782MB
[2023-07-07 15:36:51 RepVGG-A0] (main.py 282): INFO Train: [216/300][60/78]	eta 0:00:34 lr 1.140448	time 1.1957 (1.8921)	loss 2.5974 (2.6174)	grad_norm 0.4538 (0.4853)	mem 39782MB
[2023-07-07 15:37:07 RepVGG-A0] (main.py 282): INFO Train: [216/300][70/78]	eta 0:00:14 lr 1.137162	time 1.6182 (1.8463)	loss 2.6063 (2.6203)	grad_norm 0.4704 (0.4836)	mem 39782MB
[2023-07-07 15:37:16 RepVGG-A0] (main.py 291): INFO EPOCH 216 training takes 0:02:20
[2023-07-07 15:37:38 RepVGG-A0] (main.py 282): INFO Train: [217/300][0/78]	eta 0:28:22 lr 1.134535	time 21.8300 (21.8300)	loss 2.6533 (2.6533)	grad_norm 0.4783 (0.4783)	mem 39782MB
[2023-07-07 15:37:52 RepVGG-A0] (main.py 282): INFO Train: [217/300][10/78]	eta 0:03:40 lr 1.131256	time 1.1703 (3.2446)	loss 2.5845 (2.5851)	grad_norm 0.4741 (0.4763)	mem 39782MB
[2023-07-07 15:38:07 RepVGG-A0] (main.py 282): INFO Train: [217/300][20/78]	eta 0:02:19 lr 1.127980	time 1.1748 (2.4083)	loss 2.5462 (2.5773)	grad_norm 0.4497 (0.4682)	mem 39782MB
[2023-07-07 15:38:22 RepVGG-A0] (main.py 282): INFO Train: [217/300][30/78]	eta 0:01:41 lr 1.124708	time 1.1643 (2.1133)	loss 2.5909 (2.5833)	grad_norm 0.4814 (0.4721)	mem 39782MB
[2023-07-07 15:38:40 RepVGG-A0] (main.py 282): INFO Train: [217/300][40/78]	eta 0:01:17 lr 1.121440	time 4.2437 (2.0413)	loss 2.6607 (2.5940)	grad_norm 0.4837 (0.4768)	mem 39782MB
[2023-07-07 15:38:55 RepVGG-A0] (main.py 282): INFO Train: [217/300][50/78]	eta 0:00:54 lr 1.118175	time 1.1743 (1.9336)	loss 2.5953 (2.5998)	grad_norm 0.4781 (0.4750)	mem 39782MB
[2023-07-07 15:39:10 RepVGG-A0] (main.py 282): INFO Train: [217/300][60/78]	eta 0:00:33 lr 1.114914	time 1.2009 (1.8572)	loss 2.6799 (2.6010)	grad_norm 0.5024 (0.4758)	mem 39782MB
[2023-07-07 15:39:26 RepVGG-A0] (main.py 282): INFO Train: [217/300][70/78]	eta 0:00:14 lr 1.111657	time 1.2912 (1.8189)	loss 2.5400 (2.6023)	grad_norm 0.4819 (0.4764)	mem 39782MB
[2023-07-07 15:39:37 RepVGG-A0] (main.py 291): INFO EPOCH 217 training takes 0:02:20
[2023-07-07 15:39:59 RepVGG-A0] (main.py 282): INFO Train: [218/300][0/78]	eta 0:28:34 lr 1.109054	time 21.9844 (21.9844)	loss 2.5325 (2.5325)	grad_norm 0.4891 (0.4891)	mem 39782MB
[2023-07-07 15:40:15 RepVGG-A0] (main.py 282): INFO Train: [218/300][10/78]	eta 0:03:53 lr 1.105804	time 1.1725 (3.4335)	loss 2.5776 (2.5714)	grad_norm 0.5280 (0.4843)	mem 39782MB
[2023-07-07 15:40:30 RepVGG-A0] (main.py 282): INFO Train: [218/300][20/78]	eta 0:02:25 lr 1.102557	time 1.1660 (2.5070)	loss 2.5724 (2.5842)	grad_norm 0.4757 (0.4871)	mem 39782MB
[2023-07-07 15:40:45 RepVGG-A0] (main.py 282): INFO Train: [218/300][30/78]	eta 0:01:44 lr 1.099314	time 1.3194 (2.1866)	loss 2.6683 (2.5879)	grad_norm 0.4633 (0.4888)	mem 39782MB
[2023-07-07 15:41:03 RepVGG-A0] (main.py 282): INFO Train: [218/300][40/78]	eta 0:01:19 lr 1.096075	time 3.4844 (2.0908)	loss 2.5702 (2.5905)	grad_norm 0.4775 (0.4850)	mem 39782MB
[2023-07-07 15:41:18 RepVGG-A0] (main.py 282): INFO Train: [218/300][50/78]	eta 0:00:55 lr 1.092840	time 1.1775 (1.9727)	loss 2.6521 (2.5960)	grad_norm 0.4559 (0.4835)	mem 39782MB
[2023-07-07 15:41:33 RepVGG-A0] (main.py 282): INFO Train: [218/300][60/78]	eta 0:00:34 lr 1.089609	time 1.2683 (1.9017)	loss 2.6735 (2.5987)	grad_norm 0.4809 (0.4809)	mem 39782MB
[2023-07-07 15:41:48 RepVGG-A0] (main.py 282): INFO Train: [218/300][70/78]	eta 0:00:14 lr 1.086381	time 1.2703 (1.8468)	loss 2.6124 (2.6013)	grad_norm 0.5080 (0.4838)	mem 39782MB
[2023-07-07 15:42:00 RepVGG-A0] (main.py 291): INFO EPOCH 218 training takes 0:02:22
[2023-07-07 15:42:22 RepVGG-A0] (main.py 282): INFO Train: [219/300][0/78]	eta 0:27:58 lr 1.083802	time 21.5147 (21.5147)	loss 2.5239 (2.5239)	grad_norm 0.4598 (0.4598)	mem 39782MB
[2023-07-07 15:42:36 RepVGG-A0] (main.py 282): INFO Train: [219/300][10/78]	eta 0:03:44 lr 1.080581	time 1.1739 (3.2954)	loss 2.6124 (2.5583)	grad_norm 0.5098 (0.4698)	mem 39782MB
[2023-07-07 15:42:51 RepVGG-A0] (main.py 282): INFO Train: [219/300][20/78]	eta 0:02:20 lr 1.077364	time 1.2658 (2.4188)	loss 2.6110 (2.5685)	grad_norm 0.5126 (0.4855)	mem 39782MB
[2023-07-07 15:43:07 RepVGG-A0] (main.py 282): INFO Train: [219/300][30/78]	eta 0:01:43 lr 1.074151	time 1.5611 (2.1577)	loss 2.5674 (2.5700)	grad_norm 0.4718 (0.4858)	mem 39782MB
[2023-07-07 15:43:24 RepVGG-A0] (main.py 282): INFO Train: [219/300][40/78]	eta 0:01:18 lr 1.070942	time 2.3593 (2.0561)	loss 2.6227 (2.5714)	grad_norm 0.4710 (0.4841)	mem 39782MB
[2023-07-07 15:43:39 RepVGG-A0] (main.py 282): INFO Train: [219/300][50/78]	eta 0:00:54 lr 1.067737	time 1.1933 (1.9476)	loss 2.6513 (2.5775)	grad_norm 0.5241 (0.4860)	mem 39782MB
[2023-07-07 15:43:53 RepVGG-A0] (main.py 282): INFO Train: [219/300][60/78]	eta 0:00:33 lr 1.064535	time 1.1772 (1.8564)	loss 2.6165 (2.5819)	grad_norm 0.4939 (0.4877)	mem 39782MB
[2023-07-07 15:44:09 RepVGG-A0] (main.py 282): INFO Train: [219/300][70/78]	eta 0:00:14 lr 1.061337	time 1.2640 (1.8099)	loss 2.6148 (2.5875)	grad_norm 0.4977 (0.4861)	mem 39782MB
[2023-07-07 15:44:20 RepVGG-A0] (main.py 291): INFO EPOCH 219 training takes 0:02:20
[2023-07-07 15:44:41 RepVGG-A0] (main.py 282): INFO Train: [220/300][0/78]	eta 0:27:30 lr 1.058782	time 21.1654 (21.1654)	loss 2.5088 (2.5088)	grad_norm 0.4640 (0.4640)	mem 39782MB
[2023-07-07 15:44:56 RepVGG-A0] (main.py 282): INFO Train: [220/300][10/78]	eta 0:03:39 lr 1.055591	time 1.1704 (3.2277)	loss 2.5894 (2.5562)	grad_norm 0.4841 (0.4878)	mem 39782MB
[2023-07-07 15:45:10 RepVGG-A0] (main.py 282): INFO Train: [220/300][20/78]	eta 0:02:18 lr 1.052404	time 1.1737 (2.3876)	loss 2.5923 (2.5705)	grad_norm 0.4704 (0.5001)	mem 39782MB
[2023-07-07 15:45:27 RepVGG-A0] (main.py 282): INFO Train: [220/300][30/78]	eta 0:01:42 lr 1.049221	time 1.7024 (2.1383)	loss 2.6344 (2.5764)	grad_norm 0.4838 (0.4927)	mem 39782MB
[2023-07-07 15:45:44 RepVGG-A0] (main.py 282): INFO Train: [220/300][40/78]	eta 0:01:17 lr 1.046042	time 4.1477 (2.0514)	loss 2.5957 (2.5777)	grad_norm 0.4764 (0.4889)	mem 39782MB
[2023-07-07 15:45:59 RepVGG-A0] (main.py 282): INFO Train: [220/300][50/78]	eta 0:00:54 lr 1.042867	time 1.1731 (1.9433)	loss 2.5726 (2.5786)	grad_norm 0.4897 (0.4882)	mem 39782MB
[2023-07-07 15:46:14 RepVGG-A0] (main.py 282): INFO Train: [220/300][60/78]	eta 0:00:33 lr 1.039696	time 1.2612 (1.8716)	loss 2.6249 (2.5808)	grad_norm 0.4994 (0.4913)	mem 39782MB
[2023-07-07 15:46:30 RepVGG-A0] (main.py 282): INFO Train: [220/300][70/78]	eta 0:00:14 lr 1.036528	time 1.2123 (1.8272)	loss 2.5546 (2.5819)	grad_norm 0.4628 (0.4894)	mem 39782MB
[2023-07-07 15:46:41 RepVGG-A0] (main.py 291): INFO EPOCH 220 training takes 0:02:20
[2023-07-07 15:46:58 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.017 (17.017)	Loss 1.8846 (1.8846)	Acc@1 60.229 (60.229)	Acc@5 82.672 (82.672)	Mem 39782MB
[2023-07-07 15:46:59 RepVGG-A0] (main.py 342): INFO  * Acc@1 60.430 Acc@5 82.872
[2023-07-07 15:46:59 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 220: 60.430%
[2023-07-07 15:46:59 RepVGG-A0] (main.py 172): INFO Max accuracy: 60.43%
[2023-07-07 15:47:20 RepVGG-A0] (main.py 282): INFO Train: [221/300][0/78]	eta 0:26:31 lr 1.033997	time 20.4021 (20.4021)	loss 2.5746 (2.5746)	grad_norm 0.4686 (0.4686)	mem 39782MB
[2023-07-07 15:47:35 RepVGG-A0] (main.py 282): INFO Train: [221/300][10/78]	eta 0:03:40 lr 1.030836	time 1.1925 (3.2446)	loss 2.5046 (2.5407)	grad_norm 0.5104 (0.5007)	mem 39782MB
[2023-07-07 15:47:51 RepVGG-A0] (main.py 282): INFO Train: [221/300][20/78]	eta 0:02:21 lr 1.027680	time 1.1751 (2.4420)	loss 2.5747 (2.5553)	grad_norm 0.4605 (0.4899)	mem 39782MB
[2023-07-07 15:48:07 RepVGG-A0] (main.py 282): INFO Train: [221/300][30/78]	eta 0:01:44 lr 1.024527	time 1.4180 (2.1801)	loss 2.5813 (2.5620)	grad_norm 0.5106 (0.4890)	mem 39782MB
[2023-07-07 15:48:24 RepVGG-A0] (main.py 282): INFO Train: [221/300][40/78]	eta 0:01:18 lr 1.021379	time 3.6717 (2.0666)	loss 2.6093 (2.5661)	grad_norm 0.4713 (0.4880)	mem 39782MB
[2023-07-07 15:48:39 RepVGG-A0] (main.py 282): INFO Train: [221/300][50/78]	eta 0:00:54 lr 1.018234	time 1.3349 (1.9602)	loss 2.6246 (2.5677)	grad_norm 0.5240 (0.4871)	mem 39782MB
[2023-07-07 15:48:54 RepVGG-A0] (main.py 282): INFO Train: [221/300][60/78]	eta 0:00:33 lr 1.015093	time 1.1794 (1.8855)	loss 2.5953 (2.5734)	grad_norm 0.4760 (0.4858)	mem 39782MB
[2023-07-07 15:49:11 RepVGG-A0] (main.py 282): INFO Train: [221/300][70/78]	eta 0:00:14 lr 1.011956	time 1.5155 (1.8484)	loss 2.5910 (2.5772)	grad_norm 0.5042 (0.4868)	mem 39782MB
[2023-07-07 15:49:23 RepVGG-A0] (main.py 291): INFO EPOCH 221 training takes 0:02:23
[2023-07-07 15:49:45 RepVGG-A0] (main.py 282): INFO Train: [222/300][0/78]	eta 0:29:38 lr 1.009449	time 22.7977 (22.7977)	loss 2.5395 (2.5395)	grad_norm 0.4914 (0.4914)	mem 39782MB
[2023-07-07 15:50:00 RepVGG-A0] (main.py 282): INFO Train: [222/300][10/78]	eta 0:03:52 lr 1.006319	time 1.1722 (3.4179)	loss 2.5464 (2.5359)	grad_norm 0.4525 (0.4776)	mem 39782MB
[2023-07-07 15:50:14 RepVGG-A0] (main.py 282): INFO Train: [222/300][20/78]	eta 0:02:21 lr 1.003194	time 1.1718 (2.4422)	loss 2.5883 (2.5445)	grad_norm 0.4798 (0.4826)	mem 39782MB
[2023-07-07 15:50:28 RepVGG-A0] (main.py 282): INFO Train: [222/300][30/78]	eta 0:01:41 lr 1.000072	time 1.1300 (2.1226)	loss 2.5048 (2.5513)	grad_norm 0.4730 (0.4815)	mem 39782MB
[2023-07-07 15:50:46 RepVGG-A0] (main.py 282): INFO Train: [222/300][40/78]	eta 0:01:17 lr 0.996954	time 2.7953 (2.0319)	loss 2.5867 (2.5539)	grad_norm 0.5011 (0.4845)	mem 39782MB
[2023-07-07 15:51:01 RepVGG-A0] (main.py 282): INFO Train: [222/300][50/78]	eta 0:00:54 lr 0.993840	time 1.2110 (1.9371)	loss 2.6287 (2.5590)	grad_norm 0.4818 (0.4836)	mem 39782MB
[2023-07-07 15:51:17 RepVGG-A0] (main.py 282): INFO Train: [222/300][60/78]	eta 0:00:33 lr 0.990730	time 1.1741 (1.8803)	loss 2.5899 (2.5650)	grad_norm 0.4855 (0.4862)	mem 39782MB
[2023-07-07 15:51:32 RepVGG-A0] (main.py 282): INFO Train: [222/300][70/78]	eta 0:00:14 lr 0.987624	time 1.5045 (1.8263)	loss 2.5564 (2.5706)	grad_norm 0.4788 (0.4853)	mem 39782MB
[2023-07-07 15:51:44 RepVGG-A0] (main.py 291): INFO EPOCH 222 training takes 0:02:21
[2023-07-07 15:52:07 RepVGG-A0] (main.py 282): INFO Train: [223/300][0/78]	eta 0:29:36 lr 0.985142	time 22.7749 (22.7749)	loss 2.5072 (2.5072)	grad_norm 0.4824 (0.4824)	mem 39782MB
[2023-07-07 15:52:22 RepVGG-A0] (main.py 282): INFO Train: [223/300][10/78]	eta 0:03:53 lr 0.982043	time 1.1944 (3.4342)	loss 2.5448 (2.5367)	grad_norm 0.5013 (0.4981)	mem 39782MB
[2023-07-07 15:52:35 RepVGG-A0] (main.py 282): INFO Train: [223/300][20/78]	eta 0:02:22 lr 0.978948	time 1.1726 (2.4515)	loss 2.5728 (2.5476)	grad_norm 0.4780 (0.5029)	mem 39782MB
[2023-07-07 15:52:52 RepVGG-A0] (main.py 282): INFO Train: [223/300][30/78]	eta 0:01:46 lr 0.975857	time 1.7489 (2.2141)	loss 2.5526 (2.5528)	grad_norm 0.4752 (0.4952)	mem 39782MB
[2023-07-07 15:53:09 RepVGG-A0] (main.py 282): INFO Train: [223/300][40/78]	eta 0:01:19 lr 0.972771	time 3.0925 (2.0862)	loss 2.5665 (2.5575)	grad_norm 0.4764 (0.4953)	mem 39782MB
[2023-07-07 15:53:24 RepVGG-A0] (main.py 282): INFO Train: [223/300][50/78]	eta 0:00:55 lr 0.969688	time 1.1738 (1.9644)	loss 2.6424 (2.5636)	grad_norm 0.4945 (0.4948)	mem 39782MB
[2023-07-07 15:53:39 RepVGG-A0] (main.py 282): INFO Train: [223/300][60/78]	eta 0:00:34 lr 0.966609	time 1.2878 (1.8901)	loss 2.5586 (2.5650)	grad_norm 0.4734 (0.4932)	mem 39782MB
[2023-07-07 15:53:55 RepVGG-A0] (main.py 282): INFO Train: [223/300][70/78]	eta 0:00:14 lr 0.963534	time 1.2537 (1.8417)	loss 2.6415 (2.5672)	grad_norm 0.4944 (0.4923)	mem 39782MB
[2023-07-07 15:54:06 RepVGG-A0] (main.py 291): INFO EPOCH 223 training takes 0:02:22
[2023-07-07 15:54:27 RepVGG-A0] (main.py 282): INFO Train: [224/300][0/78]	eta 0:27:28 lr 0.961077	time 21.1406 (21.1406)	loss 2.5602 (2.5602)	grad_norm 0.4953 (0.4953)	mem 39782MB
[2023-07-07 15:54:41 RepVGG-A0] (main.py 282): INFO Train: [224/300][10/78]	eta 0:03:37 lr 0.958010	time 1.1703 (3.1953)	loss 2.5615 (2.5434)	grad_norm 0.4578 (0.5028)	mem 39782MB
[2023-07-07 15:54:57 RepVGG-A0] (main.py 282): INFO Train: [224/300][20/78]	eta 0:02:20 lr 0.954946	time 1.1922 (2.4250)	loss 2.5846 (2.5497)	grad_norm 0.4992 (0.5000)	mem 39782MB
[2023-07-07 15:55:12 RepVGG-A0] (main.py 282): INFO Train: [224/300][30/78]	eta 0:01:42 lr 0.951887	time 1.7480 (2.1376)	loss 2.5479 (2.5608)	grad_norm 0.4729 (0.4954)	mem 39782MB
[2023-07-07 15:55:31 RepVGG-A0] (main.py 282): INFO Train: [224/300][40/78]	eta 0:01:18 lr 0.948832	time 3.5358 (2.0713)	loss 2.5493 (2.5620)	grad_norm 0.5102 (0.4970)	mem 39782MB
[2023-07-07 15:55:46 RepVGG-A0] (main.py 282): INFO Train: [224/300][50/78]	eta 0:00:54 lr 0.945780	time 1.2072 (1.9575)	loss 2.5434 (2.5647)	grad_norm 0.4963 (0.4969)	mem 39782MB
[2023-07-07 15:56:01 RepVGG-A0] (main.py 282): INFO Train: [224/300][60/78]	eta 0:00:33 lr 0.942733	time 1.4533 (1.8809)	loss 2.5125 (2.5633)	grad_norm 0.4766 (0.4956)	mem 39782MB
[2023-07-07 15:56:16 RepVGG-A0] (main.py 282): INFO Train: [224/300][70/78]	eta 0:00:14 lr 0.939690	time 1.3277 (1.8317)	loss 2.6223 (2.5674)	grad_norm 0.4975 (0.4972)	mem 39782MB
[2023-07-07 15:56:28 RepVGG-A0] (main.py 291): INFO EPOCH 224 training takes 0:02:21
[2023-07-07 15:56:50 RepVGG-A0] (main.py 282): INFO Train: [225/300][0/78]	eta 0:28:27 lr 0.937258	time 21.8898 (21.8898)	loss 2.5303 (2.5303)	grad_norm 0.5075 (0.5075)	mem 39782MB
[2023-07-07 15:57:04 RepVGG-A0] (main.py 282): INFO Train: [225/300][10/78]	eta 0:03:43 lr 0.934222	time 1.1712 (3.2862)	loss 2.4987 (2.5378)	grad_norm 0.4895 (0.4909)	mem 39782MB
[2023-07-07 15:57:18 RepVGG-A0] (main.py 282): INFO Train: [225/300][20/78]	eta 0:02:19 lr 0.931191	time 1.1707 (2.4024)	loss 2.4845 (2.5347)	grad_norm 0.4810 (0.4851)	mem 39782MB
[2023-07-07 15:57:34 RepVGG-A0] (main.py 282): INFO Train: [225/300][30/78]	eta 0:01:43 lr 0.928163	time 1.8439 (2.1490)	loss 2.6054 (2.5480)	grad_norm 0.4985 (0.4874)	mem 39782MB
[2023-07-07 15:57:51 RepVGG-A0] (main.py 282): INFO Train: [225/300][40/78]	eta 0:01:16 lr 0.925140	time 3.4187 (2.0215)	loss 2.5460 (2.5489)	grad_norm 0.5378 (0.4909)	mem 39782MB
[2023-07-07 15:58:07 RepVGG-A0] (main.py 282): INFO Train: [225/300][50/78]	eta 0:00:54 lr 0.922120	time 1.2150 (1.9393)	loss 2.6309 (2.5566)	grad_norm 0.4918 (0.4955)	mem 39782MB
[2023-07-07 15:58:23 RepVGG-A0] (main.py 282): INFO Train: [225/300][60/78]	eta 0:00:33 lr 0.919105	time 1.3430 (1.8817)	loss 2.5836 (2.5568)	grad_norm 0.4952 (0.4940)	mem 39782MB
[2023-07-07 15:58:38 RepVGG-A0] (main.py 282): INFO Train: [225/300][70/78]	eta 0:00:14 lr 0.916093	time 1.2381 (1.8289)	loss 2.5894 (2.5584)	grad_norm 0.5021 (0.4925)	mem 39782MB
[2023-07-07 15:58:50 RepVGG-A0] (main.py 291): INFO EPOCH 225 training takes 0:02:21
[2023-07-07 15:59:10 RepVGG-A0] (main.py 282): INFO Train: [226/300][0/78]	eta 0:26:54 lr 0.913687	time 20.7005 (20.7005)	loss 2.5314 (2.5314)	grad_norm 0.4776 (0.4776)	mem 39782MB
[2023-07-07 15:59:27 RepVGG-A0] (main.py 282): INFO Train: [226/300][10/78]	eta 0:03:49 lr 0.910684	time 1.1706 (3.3817)	loss 2.5662 (2.5127)	grad_norm 0.4954 (0.4838)	mem 39782MB
[2023-07-07 15:59:42 RepVGG-A0] (main.py 282): INFO Train: [226/300][20/78]	eta 0:02:24 lr 0.907684	time 1.1876 (2.4909)	loss 2.5833 (2.5287)	grad_norm 0.4981 (0.4960)	mem 39782MB
[2023-07-07 15:59:56 RepVGG-A0] (main.py 282): INFO Train: [226/300][30/78]	eta 0:01:43 lr 0.904688	time 1.4065 (2.1535)	loss 2.5511 (2.5303)	grad_norm 0.4910 (0.4935)	mem 39782MB
[2023-07-07 16:00:14 RepVGG-A0] (main.py 282): INFO Train: [226/300][40/78]	eta 0:01:18 lr 0.901697	time 2.3662 (2.0600)	loss 2.5027 (2.5331)	grad_norm 0.5053 (0.4947)	mem 39782MB
[2023-07-07 16:00:29 RepVGG-A0] (main.py 282): INFO Train: [226/300][50/78]	eta 0:00:54 lr 0.898710	time 1.1551 (1.9520)	loss 2.5601 (2.5421)	grad_norm 0.5148 (0.4937)	mem 39782MB
[2023-07-07 16:00:45 RepVGG-A0] (main.py 282): INFO Train: [226/300][60/78]	eta 0:00:33 lr 0.895726	time 1.1783 (1.8852)	loss 2.6274 (2.5449)	grad_norm 0.5291 (0.4971)	mem 39782MB
[2023-07-07 16:00:59 RepVGG-A0] (main.py 282): INFO Train: [226/300][70/78]	eta 0:00:14 lr 0.892747	time 1.4564 (1.8260)	loss 2.6336 (2.5478)	grad_norm 0.5015 (0.4992)	mem 39782MB
[2023-07-07 16:01:11 RepVGG-A0] (main.py 291): INFO EPOCH 226 training takes 0:02:21
[2023-07-07 16:01:33 RepVGG-A0] (main.py 282): INFO Train: [227/300][0/78]	eta 0:28:23 lr 0.890367	time 21.8445 (21.8445)	loss 2.4998 (2.4998)	grad_norm 0.4839 (0.4839)	mem 39782MB
[2023-07-07 16:01:47 RepVGG-A0] (main.py 282): INFO Train: [227/300][10/78]	eta 0:03:43 lr 0.887396	time 1.1734 (3.2829)	loss 2.4689 (2.4919)	grad_norm 0.5000 (0.4859)	mem 39782MB
[2023-07-07 16:02:02 RepVGG-A0] (main.py 282): INFO Train: [227/300][20/78]	eta 0:02:21 lr 0.884428	time 1.2437 (2.4344)	loss 2.5686 (2.5045)	grad_norm 0.5048 (0.4904)	mem 39782MB
[2023-07-07 16:02:18 RepVGG-A0] (main.py 282): INFO Train: [227/300][30/78]	eta 0:01:43 lr 0.881465	time 1.4984 (2.1583)	loss 2.5860 (2.5153)	grad_norm 0.5313 (0.4920)	mem 39782MB
[2023-07-07 16:02:35 RepVGG-A0] (main.py 282): INFO Train: [227/300][40/78]	eta 0:01:17 lr 0.878506	time 3.8718 (2.0399)	loss 2.4954 (2.5204)	grad_norm 0.4835 (0.4962)	mem 39782MB
[2023-07-07 16:02:51 RepVGG-A0] (main.py 282): INFO Train: [227/300][50/78]	eta 0:00:54 lr 0.875552	time 1.1749 (1.9582)	loss 2.5771 (2.5288)	grad_norm 0.5101 (0.4968)	mem 39782MB
[2023-07-07 16:03:06 RepVGG-A0] (main.py 282): INFO Train: [227/300][60/78]	eta 0:00:34 lr 0.872601	time 1.6668 (1.8906)	loss 2.5816 (2.5309)	grad_norm 0.5010 (0.4974)	mem 39782MB
[2023-07-07 16:03:21 RepVGG-A0] (main.py 282): INFO Train: [227/300][70/78]	eta 0:00:14 lr 0.869654	time 1.2871 (1.8330)	loss 2.5185 (2.5329)	grad_norm 0.4780 (0.4987)	mem 39782MB
[2023-07-07 16:03:31 RepVGG-A0] (main.py 291): INFO EPOCH 227 training takes 0:02:20
[2023-07-07 16:03:52 RepVGG-A0] (main.py 282): INFO Train: [228/300][0/78]	eta 0:26:25 lr 0.867300	time 20.3288 (20.3288)	loss 2.5239 (2.5239)	grad_norm 0.4888 (0.4888)	mem 39782MB
[2023-07-07 16:04:06 RepVGG-A0] (main.py 282): INFO Train: [228/300][10/78]	eta 0:03:36 lr 0.864362	time 1.1902 (3.1825)	loss 2.5245 (2.4844)	grad_norm 0.5211 (0.5037)	mem 39782MB
[2023-07-07 16:04:21 RepVGG-A0] (main.py 282): INFO Train: [228/300][20/78]	eta 0:02:18 lr 0.861427	time 1.1726 (2.3838)	loss 2.5695 (2.5000)	grad_norm 0.4989 (0.4966)	mem 39782MB
[2023-07-07 16:04:37 RepVGG-A0] (main.py 282): INFO Train: [228/300][30/78]	eta 0:01:42 lr 0.858496	time 1.3255 (2.1334)	loss 2.5284 (2.5052)	grad_norm 0.4733 (0.4940)	mem 39782MB
[2023-07-07 16:04:55 RepVGG-A0] (main.py 282): INFO Train: [228/300][40/78]	eta 0:01:17 lr 0.855570	time 2.9805 (2.0363)	loss 2.4994 (2.5083)	grad_norm 0.5176 (0.4957)	mem 39782MB
[2023-07-07 16:05:10 RepVGG-A0] (main.py 282): INFO Train: [228/300][50/78]	eta 0:00:53 lr 0.852648	time 1.1873 (1.9273)	loss 2.5602 (2.5185)	grad_norm 0.4996 (0.5002)	mem 39782MB
[2023-07-07 16:05:25 RepVGG-A0] (main.py 282): INFO Train: [228/300][60/78]	eta 0:00:33 lr 0.849731	time 1.3602 (1.8601)	loss 2.5699 (2.5218)	grad_norm 0.4959 (0.4983)	mem 39782MB
[2023-07-07 16:05:40 RepVGG-A0] (main.py 282): INFO Train: [228/300][70/78]	eta 0:00:14 lr 0.846817	time 1.1980 (1.8095)	loss 2.4889 (2.5253)	grad_norm 0.5037 (0.4973)	mem 39782MB
[2023-07-07 16:05:51 RepVGG-A0] (main.py 291): INFO EPOCH 228 training takes 0:02:19
[2023-07-07 16:06:13 RepVGG-A0] (main.py 282): INFO Train: [229/300][0/78]	eta 0:28:40 lr 0.844489	time 22.0533 (22.0533)	loss 2.4880 (2.4880)	grad_norm 0.4955 (0.4955)	mem 39782MB
[2023-07-07 16:06:28 RepVGG-A0] (main.py 282): INFO Train: [229/300][10/78]	eta 0:03:46 lr 0.841583	time 1.1729 (3.3238)	loss 2.5002 (2.5053)	grad_norm 0.4885 (0.4975)	mem 39782MB
[2023-07-07 16:06:42 RepVGG-A0] (main.py 282): INFO Train: [229/300][20/78]	eta 0:02:20 lr 0.838682	time 1.1918 (2.4289)	loss 2.5042 (2.5148)	grad_norm 0.5325 (0.5072)	mem 39782MB
[2023-07-07 16:06:58 RepVGG-A0] (main.py 282): INFO Train: [229/300][30/78]	eta 0:01:42 lr 0.835784	time 1.4438 (2.1410)	loss 2.5395 (2.5177)	grad_norm 0.4963 (0.5021)	mem 39782MB
[2023-07-07 16:07:16 RepVGG-A0] (main.py 282): INFO Train: [229/300][40/78]	eta 0:01:18 lr 0.832891	time 3.0522 (2.0665)	loss 2.5213 (2.5248)	grad_norm 0.5258 (0.5019)	mem 39782MB
[2023-07-07 16:07:31 RepVGG-A0] (main.py 282): INFO Train: [229/300][50/78]	eta 0:00:54 lr 0.830003	time 1.1759 (1.9576)	loss 2.5155 (2.5252)	grad_norm 0.5343 (0.5030)	mem 39782MB
[2023-07-07 16:07:46 RepVGG-A0] (main.py 282): INFO Train: [229/300][60/78]	eta 0:00:33 lr 0.827118	time 1.1767 (1.8829)	loss 2.5809 (2.5267)	grad_norm 0.4989 (0.5037)	mem 39782MB
[2023-07-07 16:08:02 RepVGG-A0] (main.py 282): INFO Train: [229/300][70/78]	eta 0:00:14 lr 0.824238	time 1.5276 (1.8354)	loss 2.5570 (2.5283)	grad_norm 0.5166 (0.5035)	mem 39782MB
[2023-07-07 16:08:13 RepVGG-A0] (main.py 291): INFO EPOCH 229 training takes 0:02:21
[2023-07-07 16:08:34 RepVGG-A0] (main.py 282): INFO Train: [230/300][0/78]	eta 0:28:08 lr 0.821937	time 21.6487 (21.6487)	loss 2.4704 (2.4704)	grad_norm 0.4908 (0.4908)	mem 39782MB
[2023-07-07 16:08:49 RepVGG-A0] (main.py 282): INFO Train: [230/300][10/78]	eta 0:03:46 lr 0.819064	time 1.1727 (3.3280)	loss 2.4468 (2.4767)	grad_norm 0.5070 (0.4987)	mem 39782MB
[2023-07-07 16:09:05 RepVGG-A0] (main.py 282): INFO Train: [230/300][20/78]	eta 0:02:25 lr 0.816196	time 1.4002 (2.5044)	loss 2.4595 (2.4905)	grad_norm 0.4918 (0.5001)	mem 39782MB
[2023-07-07 16:09:19 RepVGG-A0] (main.py 282): INFO Train: [230/300][30/78]	eta 0:01:42 lr 0.813332	time 1.3562 (2.1319)	loss 2.5352 (2.4978)	grad_norm 0.4943 (0.5026)	mem 39782MB
[2023-07-07 16:09:36 RepVGG-A0] (main.py 282): INFO Train: [230/300][40/78]	eta 0:01:17 lr 0.810472	time 3.3142 (2.0368)	loss 2.4472 (2.5009)	grad_norm 0.4874 (0.5005)	mem 39782MB
[2023-07-07 16:09:52 RepVGG-A0] (main.py 282): INFO Train: [230/300][50/78]	eta 0:00:54 lr 0.807617	time 1.1728 (1.9499)	loss 2.5165 (2.5057)	grad_norm 0.5224 (0.5003)	mem 39782MB
[2023-07-07 16:10:07 RepVGG-A0] (main.py 282): INFO Train: [230/300][60/78]	eta 0:00:33 lr 0.804766	time 1.3698 (1.8766)	loss 2.4936 (2.5094)	grad_norm 0.5131 (0.5037)	mem 39782MB
[2023-07-07 16:10:22 RepVGG-A0] (main.py 282): INFO Train: [230/300][70/78]	eta 0:00:14 lr 0.801919	time 1.3959 (1.8252)	loss 2.5481 (2.5123)	grad_norm 0.4890 (0.5033)	mem 39782MB
[2023-07-07 16:10:34 RepVGG-A0] (main.py 291): INFO EPOCH 230 training takes 0:02:20
[2023-07-07 16:10:55 RepVGG-A0] (main.py 282): INFO Train: [231/300][0/78]	eta 0:28:29 lr 0.799645	time 21.9130 (21.9130)	loss 2.4549 (2.4549)	grad_norm 0.4890 (0.4890)	mem 39782MB
[2023-07-07 16:11:09 RepVGG-A0] (main.py 282): INFO Train: [231/300][10/78]	eta 0:03:41 lr 0.796806	time 1.1727 (3.2614)	loss 2.4825 (2.4844)	grad_norm 0.5044 (0.4964)	mem 39782MB
[2023-07-07 16:11:25 RepVGG-A0] (main.py 282): INFO Train: [231/300][20/78]	eta 0:02:20 lr 0.793971	time 1.1757 (2.4281)	loss 2.5593 (2.5027)	grad_norm 0.5226 (0.5073)	mem 39782MB
[2023-07-07 16:11:40 RepVGG-A0] (main.py 282): INFO Train: [231/300][30/78]	eta 0:01:43 lr 0.791141	time 1.2439 (2.1516)	loss 2.4473 (2.4974)	grad_norm 0.4892 (0.5057)	mem 39782MB
[2023-07-07 16:11:58 RepVGG-A0] (main.py 282): INFO Train: [231/300][40/78]	eta 0:01:18 lr 0.788315	time 2.8014 (2.0704)	loss 2.4997 (2.4959)	grad_norm 0.4973 (0.5028)	mem 39782MB
[2023-07-07 16:12:13 RepVGG-A0] (main.py 282): INFO Train: [231/300][50/78]	eta 0:00:54 lr 0.785493	time 1.1791 (1.9584)	loss 2.5926 (2.5000)	grad_norm 0.5195 (0.5043)	mem 39782MB
[2023-07-07 16:12:28 RepVGG-A0] (main.py 282): INFO Train: [231/300][60/78]	eta 0:00:33 lr 0.782676	time 1.2677 (1.8777)	loss 2.5875 (2.5053)	grad_norm 0.5058 (0.5039)	mem 39782MB
[2023-07-07 16:12:44 RepVGG-A0] (main.py 282): INFO Train: [231/300][70/78]	eta 0:00:14 lr 0.779863	time 1.4120 (1.8343)	loss 2.5251 (2.5075)	grad_norm 0.4934 (0.5065)	mem 39782MB
[2023-07-07 16:12:55 RepVGG-A0] (main.py 291): INFO EPOCH 231 training takes 0:02:21
[2023-07-07 16:13:17 RepVGG-A0] (main.py 282): INFO Train: [232/300][0/78]	eta 0:28:06 lr 0.777616	time 21.6273 (21.6273)	loss 2.4381 (2.4381)	grad_norm 0.5016 (0.5016)	mem 39782MB
[2023-07-07 16:13:31 RepVGG-A0] (main.py 282): INFO Train: [232/300][10/78]	eta 0:03:45 lr 0.774811	time 1.1698 (3.3092)	loss 2.6069 (2.5053)	grad_norm 0.5215 (0.5087)	mem 39782MB
[2023-07-07 16:13:46 RepVGG-A0] (main.py 282): INFO Train: [232/300][20/78]	eta 0:02:21 lr 0.772010	time 1.2297 (2.4435)	loss 2.5164 (2.5047)	grad_norm 0.5125 (0.5089)	mem 39782MB
[2023-07-07 16:14:00 RepVGG-A0] (main.py 282): INFO Train: [232/300][30/78]	eta 0:01:40 lr 0.769214	time 1.1317 (2.0981)	loss 2.5385 (2.5020)	grad_norm 0.5037 (0.5062)	mem 39782MB
[2023-07-07 16:14:20 RepVGG-A0] (main.py 282): INFO Train: [232/300][40/78]	eta 0:01:18 lr 0.766422	time 4.2184 (2.0645)	loss 2.5433 (2.5089)	grad_norm 0.5148 (0.5051)	mem 39782MB
[2023-07-07 16:14:35 RepVGG-A0] (main.py 282): INFO Train: [232/300][50/78]	eta 0:00:54 lr 0.763634	time 1.2529 (1.9544)	loss 2.5181 (2.5103)	grad_norm 0.4926 (0.5051)	mem 39782MB
[2023-07-07 16:14:51 RepVGG-A0] (main.py 282): INFO Train: [232/300][60/78]	eta 0:00:34 lr 0.760851	time 1.4661 (1.8977)	loss 2.5505 (2.5113)	grad_norm 0.5255 (0.5054)	mem 39782MB
[2023-07-07 16:15:04 RepVGG-A0] (main.py 282): INFO Train: [232/300][70/78]	eta 0:00:14 lr 0.758073	time 1.4404 (1.8162)	loss 2.5917 (2.5143)	grad_norm 0.5199 (0.5059)	mem 39782MB
[2023-07-07 16:15:16 RepVGG-A0] (main.py 291): INFO EPOCH 232 training takes 0:02:21
[2023-07-07 16:15:38 RepVGG-A0] (main.py 282): INFO Train: [233/300][0/78]	eta 0:28:10 lr 0.755853	time 21.6731 (21.6731)	loss 2.4654 (2.4654)	grad_norm 0.4861 (0.4861)	mem 39782MB
[2023-07-07 16:15:52 RepVGG-A0] (main.py 282): INFO Train: [233/300][10/78]	eta 0:03:43 lr 0.753082	time 1.1729 (3.2810)	loss 2.4514 (2.4527)	grad_norm 0.5264 (0.5047)	mem 39782MB
[2023-07-07 16:16:07 RepVGG-A0] (main.py 282): INFO Train: [233/300][20/78]	eta 0:02:19 lr 0.750316	time 1.1763 (2.4086)	loss 2.4621 (2.4706)	grad_norm 0.5059 (0.5057)	mem 39782MB
[2023-07-07 16:16:23 RepVGG-A0] (main.py 282): INFO Train: [233/300][30/78]	eta 0:01:43 lr 0.747554	time 1.3955 (2.1522)	loss 2.4705 (2.4786)	grad_norm 0.5195 (0.5117)	mem 39782MB
[2023-07-07 16:16:40 RepVGG-A0] (main.py 282): INFO Train: [233/300][40/78]	eta 0:01:17 lr 0.744796	time 3.1471 (2.0304)	loss 2.4789 (2.4844)	grad_norm 0.4857 (0.5098)	mem 39782MB
[2023-07-07 16:16:55 RepVGG-A0] (main.py 282): INFO Train: [233/300][50/78]	eta 0:00:53 lr 0.742043	time 1.1758 (1.9264)	loss 2.5321 (2.4884)	grad_norm 0.5036 (0.5124)	mem 39782MB
[2023-07-07 16:17:10 RepVGG-A0] (main.py 282): INFO Train: [233/300][60/78]	eta 0:00:33 lr 0.739294	time 1.3922 (1.8626)	loss 2.4418 (2.4917)	grad_norm 0.4957 (0.5112)	mem 39782MB
[2023-07-07 16:17:25 RepVGG-A0] (main.py 282): INFO Train: [233/300][70/78]	eta 0:00:14 lr 0.736550	time 1.1312 (1.8101)	loss 2.5226 (2.4950)	grad_norm 0.5257 (0.5134)	mem 39782MB
[2023-07-07 16:17:37 RepVGG-A0] (main.py 291): INFO EPOCH 233 training takes 0:02:20
[2023-07-07 16:18:00 RepVGG-A0] (main.py 282): INFO Train: [234/300][0/78]	eta 0:29:09 lr 0.734358	time 22.4271 (22.4271)	loss 2.4653 (2.4653)	grad_norm 0.5111 (0.5111)	mem 39782MB
[2023-07-07 16:18:14 RepVGG-A0] (main.py 282): INFO Train: [234/300][10/78]	eta 0:03:48 lr 0.731621	time 1.1706 (3.3634)	loss 2.4543 (2.4496)	grad_norm 0.5129 (0.5066)	mem 39782MB
[2023-07-07 16:18:29 RepVGG-A0] (main.py 282): INFO Train: [234/300][20/78]	eta 0:02:23 lr 0.728890	time 1.3450 (2.4687)	loss 2.4367 (2.4627)	grad_norm 0.5179 (0.5055)	mem 39782MB
[2023-07-07 16:18:44 RepVGG-A0] (main.py 282): INFO Train: [234/300][30/78]	eta 0:01:42 lr 0.726162	time 1.1631 (2.1418)	loss 2.5113 (2.4688)	grad_norm 0.5414 (0.5103)	mem 39782MB
[2023-07-07 16:19:02 RepVGG-A0] (main.py 282): INFO Train: [234/300][40/78]	eta 0:01:18 lr 0.723439	time 3.9377 (2.0663)	loss 2.5495 (2.4736)	grad_norm 0.5134 (0.5097)	mem 39782MB
[2023-07-07 16:19:18 RepVGG-A0] (main.py 282): INFO Train: [234/300][50/78]	eta 0:00:55 lr 0.720721	time 1.1733 (1.9762)	loss 2.4250 (2.4761)	grad_norm 0.4892 (0.5068)	mem 39782MB
[2023-07-07 16:19:32 RepVGG-A0] (main.py 282): INFO Train: [234/300][60/78]	eta 0:00:33 lr 0.718007	time 1.4161 (1.8814)	loss 2.4582 (2.4823)	grad_norm 0.5074 (0.5100)	mem 39782MB
[2023-07-07 16:19:48 RepVGG-A0] (main.py 282): INFO Train: [234/300][70/78]	eta 0:00:14 lr 0.715297	time 1.1390 (1.8439)	loss 2.5252 (2.4839)	grad_norm 0.5236 (0.5097)	mem 39782MB
[2023-07-07 16:19:59 RepVGG-A0] (main.py 291): INFO EPOCH 234 training takes 0:02:22
[2023-07-07 16:20:21 RepVGG-A0] (main.py 282): INFO Train: [235/300][0/78]	eta 0:27:48 lr 0.713133	time 21.3872 (21.3872)	loss 2.4316 (2.4316)	grad_norm 0.5096 (0.5096)	mem 39782MB
[2023-07-07 16:20:35 RepVGG-A0] (main.py 282): INFO Train: [235/300][10/78]	eta 0:03:43 lr 0.710431	time 1.1707 (3.2917)	loss 2.5134 (2.4579)	grad_norm 0.5333 (0.5153)	mem 39782MB
[2023-07-07 16:20:51 RepVGG-A0] (main.py 282): INFO Train: [235/300][20/78]	eta 0:02:21 lr 0.707735	time 1.1785 (2.4463)	loss 2.4777 (2.4621)	grad_norm 0.5101 (0.5163)	mem 39782MB
[2023-07-07 16:21:06 RepVGG-A0] (main.py 282): INFO Train: [235/300][30/78]	eta 0:01:43 lr 0.705042	time 1.2183 (2.1652)	loss 2.4590 (2.4689)	grad_norm 0.4835 (0.5139)	mem 39782MB
[2023-07-07 16:21:24 RepVGG-A0] (main.py 282): INFO Train: [235/300][40/78]	eta 0:01:18 lr 0.702354	time 3.9985 (2.0753)	loss 2.5295 (2.4706)	grad_norm 0.5222 (0.5125)	mem 39782MB
[2023-07-07 16:21:39 RepVGG-A0] (main.py 282): INFO Train: [235/300][50/78]	eta 0:00:54 lr 0.699671	time 1.1736 (1.9615)	loss 2.5306 (2.4761)	grad_norm 0.5040 (0.5119)	mem 39782MB
[2023-07-07 16:21:54 RepVGG-A0] (main.py 282): INFO Train: [235/300][60/78]	eta 0:00:34 lr 0.696992	time 1.3547 (1.8889)	loss 2.5350 (2.4772)	grad_norm 0.5282 (0.5113)	mem 39782MB
[2023-07-07 16:22:10 RepVGG-A0] (main.py 282): INFO Train: [235/300][70/78]	eta 0:00:14 lr 0.694317	time 1.1758 (1.8389)	loss 2.5555 (2.4777)	grad_norm 0.5023 (0.5132)	mem 39782MB
[2023-07-07 16:22:21 RepVGG-A0] (main.py 291): INFO EPOCH 235 training takes 0:02:22
[2023-07-07 16:22:43 RepVGG-A0] (main.py 282): INFO Train: [236/300][0/78]	eta 0:28:12 lr 0.692181	time 21.6943 (21.6943)	loss 2.4863 (2.4863)	grad_norm 0.5067 (0.5067)	mem 39782MB
[2023-07-07 16:22:58 RepVGG-A0] (main.py 282): INFO Train: [236/300][10/78]	eta 0:03:45 lr 0.689515	time 1.1732 (3.3100)	loss 2.4625 (2.4687)	grad_norm 0.5149 (0.5207)	mem 39782MB
[2023-07-07 16:23:12 RepVGG-A0] (main.py 282): INFO Train: [236/300][20/78]	eta 0:02:19 lr 0.686853	time 1.1726 (2.4135)	loss 2.4643 (2.4685)	grad_norm 0.5042 (0.5174)	mem 39782MB
[2023-07-07 16:23:28 RepVGG-A0] (main.py 282): INFO Train: [236/300][30/78]	eta 0:01:42 lr 0.684196	time 1.4598 (2.1435)	loss 2.4800 (2.4672)	grad_norm 0.5256 (0.5191)	mem 39782MB
[2023-07-07 16:23:45 RepVGG-A0] (main.py 282): INFO Train: [236/300][40/78]	eta 0:01:17 lr 0.681543	time 3.3079 (2.0498)	loss 2.4962 (2.4705)	grad_norm 0.5654 (0.5184)	mem 39782MB
[2023-07-07 16:24:00 RepVGG-A0] (main.py 282): INFO Train: [236/300][50/78]	eta 0:00:54 lr 0.678895	time 1.1724 (1.9390)	loss 2.4742 (2.4725)	grad_norm 0.5100 (0.5184)	mem 39782MB
[2023-07-07 16:24:15 RepVGG-A0] (main.py 282): INFO Train: [236/300][60/78]	eta 0:00:33 lr 0.676251	time 1.1844 (1.8686)	loss 2.4450 (2.4742)	grad_norm 0.5365 (0.5205)	mem 39782MB
[2023-07-07 16:24:31 RepVGG-A0] (main.py 282): INFO Train: [236/300][70/78]	eta 0:00:14 lr 0.673612	time 1.4891 (1.8246)	loss 2.4317 (2.4769)	grad_norm 0.5180 (0.5196)	mem 39782MB
[2023-07-07 16:24:43 RepVGG-A0] (main.py 291): INFO EPOCH 236 training takes 0:02:21
[2023-07-07 16:25:05 RepVGG-A0] (main.py 282): INFO Train: [237/300][0/78]	eta 0:27:43 lr 0.671504	time 21.3236 (21.3236)	loss 2.4349 (2.4349)	grad_norm 0.5018 (0.5018)	mem 39782MB
[2023-07-07 16:25:21 RepVGG-A0] (main.py 282): INFO Train: [237/300][10/78]	eta 0:03:51 lr 0.668873	time 1.1702 (3.3992)	loss 2.4235 (2.4524)	grad_norm 0.5053 (0.5123)	mem 39782MB
[2023-07-07 16:25:35 RepVGG-A0] (main.py 282): INFO Train: [237/300][20/78]	eta 0:02:24 lr 0.666247	time 1.2064 (2.4836)	loss 2.4624 (2.4548)	grad_norm 0.4952 (0.5129)	mem 39782MB
[2023-07-07 16:25:51 RepVGG-A0] (main.py 282): INFO Train: [237/300][30/78]	eta 0:01:44 lr 0.663625	time 1.4232 (2.1741)	loss 2.4687 (2.4591)	grad_norm 0.5083 (0.5118)	mem 39782MB
[2023-07-07 16:26:09 RepVGG-A0] (main.py 282): INFO Train: [237/300][40/78]	eta 0:01:19 lr 0.661008	time 3.0886 (2.0897)	loss 2.4850 (2.4603)	grad_norm 0.5057 (0.5110)	mem 39782MB
[2023-07-07 16:26:24 RepVGG-A0] (main.py 282): INFO Train: [237/300][50/78]	eta 0:00:55 lr 0.658395	time 1.1760 (1.9745)	loss 2.4885 (2.4613)	grad_norm 0.5189 (0.5121)	mem 39782MB
[2023-07-07 16:26:39 RepVGG-A0] (main.py 282): INFO Train: [237/300][60/78]	eta 0:00:34 lr 0.655787	time 1.2921 (1.9040)	loss 2.4700 (2.4661)	grad_norm 0.5117 (0.5155)	mem 39782MB
[2023-07-07 16:26:54 RepVGG-A0] (main.py 282): INFO Train: [237/300][70/78]	eta 0:00:14 lr 0.653184	time 1.2008 (1.8419)	loss 2.4720 (2.4665)	grad_norm 0.4989 (0.5149)	mem 39782MB
[2023-07-07 16:27:06 RepVGG-A0] (main.py 291): INFO EPOCH 237 training takes 0:02:23
[2023-07-07 16:27:27 RepVGG-A0] (main.py 282): INFO Train: [238/300][0/78]	eta 0:26:57 lr 0.651104	time 20.7314 (20.7314)	loss 2.4717 (2.4717)	grad_norm 0.5201 (0.5201)	mem 39782MB
[2023-07-07 16:27:43 RepVGG-A0] (main.py 282): INFO Train: [238/300][10/78]	eta 0:03:48 lr 0.648509	time 1.1708 (3.3621)	loss 2.4591 (2.4629)	grad_norm 0.5409 (0.5316)	mem 39782MB
[2023-07-07 16:27:58 RepVGG-A0] (main.py 282): INFO Train: [238/300][20/78]	eta 0:02:21 lr 0.645919	time 1.2400 (2.4343)	loss 2.4615 (2.4496)	grad_norm 0.5059 (0.5210)	mem 39782MB
[2023-07-07 16:28:12 RepVGG-A0] (main.py 282): INFO Train: [238/300][30/78]	eta 0:01:41 lr 0.643333	time 1.1773 (2.1247)	loss 2.4231 (2.4494)	grad_norm 0.5094 (0.5194)	mem 39782MB
[2023-07-07 16:28:30 RepVGG-A0] (main.py 282): INFO Train: [238/300][40/78]	eta 0:01:17 lr 0.640751	time 2.4581 (2.0348)	loss 2.4410 (2.4512)	grad_norm 0.5411 (0.5217)	mem 39782MB
[2023-07-07 16:28:46 RepVGG-A0] (main.py 282): INFO Train: [238/300][50/78]	eta 0:00:54 lr 0.638174	time 1.1833 (1.9450)	loss 2.5438 (2.4557)	grad_norm 0.5207 (0.5190)	mem 39782MB
[2023-07-07 16:29:01 RepVGG-A0] (main.py 282): INFO Train: [238/300][60/78]	eta 0:00:33 lr 0.635602	time 1.1731 (1.8774)	loss 2.4398 (2.4600)	grad_norm 0.5533 (0.5213)	mem 39782MB
[2023-07-07 16:29:17 RepVGG-A0] (main.py 282): INFO Train: [238/300][70/78]	eta 0:00:14 lr 0.633035	time 1.4713 (1.8435)	loss 2.4798 (2.4639)	grad_norm 0.5158 (0.5216)	mem 39782MB
[2023-07-07 16:29:30 RepVGG-A0] (main.py 291): INFO EPOCH 238 training takes 0:02:23
[2023-07-07 16:29:50 RepVGG-A0] (main.py 282): INFO Train: [239/300][0/78]	eta 0:25:48 lr 0.630984	time 19.8563 (19.8563)	loss 2.4463 (2.4463)	grad_norm 0.5044 (0.5044)	mem 39782MB
[2023-07-07 16:30:08 RepVGG-A0] (main.py 282): INFO Train: [239/300][10/78]	eta 0:03:50 lr 0.628425	time 1.1710 (3.3883)	loss 2.4018 (2.4305)	grad_norm 0.5167 (0.5076)	mem 39782MB
[2023-07-07 16:30:22 RepVGG-A0] (main.py 282): INFO Train: [239/300][20/78]	eta 0:02:22 lr 0.625870	time 1.1725 (2.4596)	loss 2.4058 (2.4309)	grad_norm 0.5082 (0.5065)	mem 39782MB
[2023-07-07 16:30:37 RepVGG-A0] (main.py 282): INFO Train: [239/300][30/78]	eta 0:01:43 lr 0.623320	time 1.1306 (2.1461)	loss 2.4664 (2.4385)	grad_norm 0.5131 (0.5116)	mem 39782MB
[2023-07-07 16:30:53 RepVGG-A0] (main.py 282): INFO Train: [239/300][40/78]	eta 0:01:16 lr 0.620775	time 2.4787 (2.0048)	loss 2.4438 (2.4446)	grad_norm 0.5239 (0.5122)	mem 39782MB
[2023-07-07 16:31:09 RepVGG-A0] (main.py 282): INFO Train: [239/300][50/78]	eta 0:00:53 lr 0.618235	time 1.2017 (1.9281)	loss 2.4883 (2.4487)	grad_norm 0.5131 (0.5181)	mem 39782MB
[2023-07-07 16:31:24 RepVGG-A0] (main.py 282): INFO Train: [239/300][60/78]	eta 0:00:33 lr 0.615699	time 1.1738 (1.8628)	loss 2.4844 (2.4497)	grad_norm 0.5130 (0.5182)	mem 39782MB
[2023-07-07 16:31:39 RepVGG-A0] (main.py 282): INFO Train: [239/300][70/78]	eta 0:00:14 lr 0.613167	time 1.2007 (1.8140)	loss 2.5023 (2.4490)	grad_norm 0.5155 (0.5188)	mem 39782MB
[2023-07-07 16:31:52 RepVGG-A0] (main.py 291): INFO EPOCH 239 training takes 0:02:21
[2023-07-07 16:32:13 RepVGG-A0] (main.py 282): INFO Train: [240/300][0/78]	eta 0:27:43 lr 0.611146	time 21.3323 (21.3323)	loss 2.5212 (2.5212)	grad_norm 0.5347 (0.5347)	mem 39782MB
[2023-07-07 16:32:27 RepVGG-A0] (main.py 282): INFO Train: [240/300][10/78]	eta 0:03:39 lr 0.608623	time 1.1919 (3.2313)	loss 2.4332 (2.4545)	grad_norm 0.5065 (0.5107)	mem 39782MB
[2023-07-07 16:32:42 RepVGG-A0] (main.py 282): INFO Train: [240/300][20/78]	eta 0:02:17 lr 0.606104	time 1.1939 (2.3694)	loss 2.4002 (2.4416)	grad_norm 0.5195 (0.5150)	mem 39782MB
[2023-07-07 16:32:57 RepVGG-A0] (main.py 282): INFO Train: [240/300][30/78]	eta 0:01:40 lr 0.603591	time 1.1758 (2.0870)	loss 2.4217 (2.4476)	grad_norm 0.5357 (0.5225)	mem 39782MB
[2023-07-07 16:33:15 RepVGG-A0] (main.py 282): INFO Train: [240/300][40/78]	eta 0:01:16 lr 0.601082	time 3.9514 (2.0242)	loss 2.4054 (2.4473)	grad_norm 0.5102 (0.5195)	mem 39782MB
[2023-07-07 16:33:30 RepVGG-A0] (main.py 282): INFO Train: [240/300][50/78]	eta 0:00:53 lr 0.598578	time 1.1710 (1.9235)	loss 2.4622 (2.4434)	grad_norm 0.5417 (0.5226)	mem 39782MB
[2023-07-07 16:33:45 RepVGG-A0] (main.py 282): INFO Train: [240/300][60/78]	eta 0:00:33 lr 0.596078	time 1.2579 (1.8561)	loss 2.5274 (2.4445)	grad_norm 0.5251 (0.5232)	mem 39782MB
[2023-07-07 16:34:01 RepVGG-A0] (main.py 282): INFO Train: [240/300][70/78]	eta 0:00:14 lr 0.593584	time 1.1612 (1.8123)	loss 2.4380 (2.4473)	grad_norm 0.5203 (0.5220)	mem 39782MB
[2023-07-07 16:34:12 RepVGG-A0] (main.py 291): INFO EPOCH 240 training takes 0:02:20
[2023-07-07 16:34:29 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.498 (17.498)	Loss 1.6567 (1.6567)	Acc@1 63.867 (63.867)	Acc@5 85.229 (85.229)	Mem 39782MB
[2023-07-07 16:34:31 RepVGG-A0] (main.py 342): INFO  * Acc@1 63.708 Acc@5 85.256
[2023-07-07 16:34:31 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 240: 63.708%
[2023-07-07 16:34:31 RepVGG-A0] (main.py 172): INFO Max accuracy: 63.71%
[2023-07-07 16:34:53 RepVGG-A0] (main.py 282): INFO Train: [241/300][0/78]	eta 0:28:55 lr 0.591591	time 22.2553 (22.2553)	loss 2.4414 (2.4414)	grad_norm 0.5200 (0.5200)	mem 39782MB
[2023-07-07 16:35:09 RepVGG-A0] (main.py 282): INFO Train: [241/300][10/78]	eta 0:03:55 lr 0.589105	time 1.1945 (3.4565)	loss 2.4004 (2.4245)	grad_norm 0.5386 (0.5268)	mem 39782MB
[2023-07-07 16:35:23 RepVGG-A0] (main.py 282): INFO Train: [241/300][20/78]	eta 0:02:23 lr 0.586623	time 1.1307 (2.4811)	loss 2.4069 (2.4292)	grad_norm 0.5181 (0.5230)	mem 39782MB
[2023-07-07 16:35:38 RepVGG-A0] (main.py 282): INFO Train: [241/300][30/78]	eta 0:01:44 lr 0.584146	time 1.5999 (2.1745)	loss 2.4550 (2.4352)	grad_norm 0.5373 (0.5264)	mem 39782MB
[2023-07-07 16:35:56 RepVGG-A0] (main.py 282): INFO Train: [241/300][40/78]	eta 0:01:18 lr 0.581674	time 3.0715 (2.0754)	loss 2.5111 (2.4400)	grad_norm 0.5300 (0.5295)	mem 39782MB
[2023-07-07 16:36:11 RepVGG-A0] (main.py 282): INFO Train: [241/300][50/78]	eta 0:00:54 lr 0.579206	time 1.1813 (1.9621)	loss 2.4370 (2.4387)	grad_norm 0.5122 (0.5267)	mem 39782MB
[2023-07-07 16:36:26 RepVGG-A0] (main.py 282): INFO Train: [241/300][60/78]	eta 0:00:34 lr 0.576744	time 1.1388 (1.8915)	loss 2.4705 (2.4448)	grad_norm 0.5366 (0.5284)	mem 39782MB
[2023-07-07 16:36:41 RepVGG-A0] (main.py 282): INFO Train: [241/300][70/78]	eta 0:00:14 lr 0.574286	time 1.1300 (1.8376)	loss 2.4679 (2.4477)	grad_norm 0.5246 (0.5284)	mem 39782MB
[2023-07-07 16:36:53 RepVGG-A0] (main.py 291): INFO EPOCH 241 training takes 0:02:22
[2023-07-07 16:37:15 RepVGG-A0] (main.py 282): INFO Train: [242/300][0/78]	eta 0:29:02 lr 0.572323	time 22.3418 (22.3418)	loss 2.3691 (2.3691)	grad_norm 0.4983 (0.4983)	mem 39782MB
[2023-07-07 16:37:30 RepVGG-A0] (main.py 282): INFO Train: [242/300][10/78]	eta 0:03:48 lr 0.569873	time 1.1709 (3.3655)	loss 2.4315 (2.4172)	grad_norm 0.5256 (0.5114)	mem 39782MB
[2023-07-07 16:37:45 RepVGG-A0] (main.py 282): INFO Train: [242/300][20/78]	eta 0:02:24 lr 0.567428	time 1.1820 (2.4984)	loss 2.4072 (2.4220)	grad_norm 0.5348 (0.5161)	mem 39782MB
[2023-07-07 16:38:00 RepVGG-A0] (main.py 282): INFO Train: [242/300][30/78]	eta 0:01:43 lr 0.564988	time 1.1862 (2.1589)	loss 2.4300 (2.4276)	grad_norm 0.5473 (0.5234)	mem 39782MB
[2023-07-07 16:38:17 RepVGG-A0] (main.py 282): INFO Train: [242/300][40/78]	eta 0:01:18 lr 0.562553	time 2.9797 (2.0630)	loss 2.4973 (2.4331)	grad_norm 0.5147 (0.5238)	mem 39782MB
[2023-07-07 16:38:33 RepVGG-A0] (main.py 282): INFO Train: [242/300][50/78]	eta 0:00:54 lr 0.560122	time 1.2644 (1.9547)	loss 2.5485 (2.4385)	grad_norm 0.5428 (0.5256)	mem 39782MB
[2023-07-07 16:38:48 RepVGG-A0] (main.py 282): INFO Train: [242/300][60/78]	eta 0:00:33 lr 0.557697	time 1.3055 (1.8802)	loss 2.4054 (2.4400)	grad_norm 0.5336 (0.5258)	mem 39782MB
[2023-07-07 16:39:03 RepVGG-A0] (main.py 282): INFO Train: [242/300][70/78]	eta 0:00:14 lr 0.555276	time 1.2342 (1.8269)	loss 2.4745 (2.4425)	grad_norm 0.5259 (0.5274)	mem 39782MB
[2023-07-07 16:39:15 RepVGG-A0] (main.py 291): INFO EPOCH 242 training takes 0:02:21
[2023-07-07 16:39:37 RepVGG-A0] (main.py 282): INFO Train: [243/300][0/78]	eta 0:28:58 lr 0.553342	time 22.2907 (22.2907)	loss 2.3982 (2.3982)	grad_norm 0.5264 (0.5264)	mem 39782MB
[2023-07-07 16:39:51 RepVGG-A0] (main.py 282): INFO Train: [243/300][10/78]	eta 0:03:45 lr 0.550930	time 1.1720 (3.3231)	loss 2.4324 (2.4031)	grad_norm 0.5474 (0.5210)	mem 39782MB
[2023-07-07 16:40:06 RepVGG-A0] (main.py 282): INFO Train: [243/300][20/78]	eta 0:02:21 lr 0.548522	time 1.1732 (2.4455)	loss 2.4471 (2.4068)	grad_norm 0.5586 (0.5246)	mem 39782MB
[2023-07-07 16:40:21 RepVGG-A0] (main.py 282): INFO Train: [243/300][30/78]	eta 0:01:43 lr 0.546119	time 1.4719 (2.1557)	loss 2.4662 (2.4180)	grad_norm 0.5263 (0.5280)	mem 39782MB
[2023-07-07 16:40:39 RepVGG-A0] (main.py 282): INFO Train: [243/300][40/78]	eta 0:01:18 lr 0.543721	time 4.4370 (2.0697)	loss 2.4071 (2.4189)	grad_norm 0.5355 (0.5277)	mem 39782MB
[2023-07-07 16:40:54 RepVGG-A0] (main.py 282): INFO Train: [243/300][50/78]	eta 0:00:54 lr 0.541328	time 1.1924 (1.9487)	loss 2.4577 (2.4215)	grad_norm 0.5468 (0.5269)	mem 39782MB
[2023-07-07 16:41:09 RepVGG-A0] (main.py 282): INFO Train: [243/300][60/78]	eta 0:00:33 lr 0.538939	time 1.1914 (1.8799)	loss 2.4350 (2.4261)	grad_norm 0.5250 (0.5287)	mem 39782MB
[2023-07-07 16:41:25 RepVGG-A0] (main.py 282): INFO Train: [243/300][70/78]	eta 0:00:14 lr 0.536556	time 1.2532 (1.8331)	loss 2.4620 (2.4287)	grad_norm 0.5215 (0.5294)	mem 39782MB
[2023-07-07 16:41:36 RepVGG-A0] (main.py 291): INFO EPOCH 243 training takes 0:02:21
[2023-07-07 16:41:58 RepVGG-A0] (main.py 282): INFO Train: [244/300][0/78]	eta 0:28:06 lr 0.534652	time 21.6199 (21.6199)	loss 2.4381 (2.4381)	grad_norm 0.5363 (0.5363)	mem 39782MB
[2023-07-07 16:42:12 RepVGG-A0] (main.py 282): INFO Train: [244/300][10/78]	eta 0:03:41 lr 0.532277	time 1.1727 (3.2644)	loss 2.3691 (2.4029)	grad_norm 0.5216 (0.5318)	mem 39782MB
[2023-07-07 16:42:27 RepVGG-A0] (main.py 282): INFO Train: [244/300][20/78]	eta 0:02:20 lr 0.529907	time 1.3111 (2.4161)	loss 2.4441 (2.4077)	grad_norm 0.5616 (0.5337)	mem 39782MB
[2023-07-07 16:42:43 RepVGG-A0] (main.py 282): INFO Train: [244/300][30/78]	eta 0:01:42 lr 0.527541	time 1.2644 (2.1453)	loss 2.3775 (2.4069)	grad_norm 0.5230 (0.5312)	mem 39782MB
[2023-07-07 16:43:01 RepVGG-A0] (main.py 282): INFO Train: [244/300][40/78]	eta 0:01:18 lr 0.525181	time 3.7182 (2.0579)	loss 2.4017 (2.4121)	grad_norm 0.5274 (0.5338)	mem 39782MB
[2023-07-07 16:43:17 RepVGG-A0] (main.py 282): INFO Train: [244/300][50/78]	eta 0:00:55 lr 0.522825	time 1.3605 (1.9678)	loss 2.4870 (2.4188)	grad_norm 0.5291 (0.5338)	mem 39782MB
[2023-07-07 16:43:32 RepVGG-A0] (main.py 282): INFO Train: [244/300][60/78]	eta 0:00:34 lr 0.520474	time 1.4264 (1.9008)	loss 2.3859 (2.4214)	grad_norm 0.5210 (0.5318)	mem 39782MB
[2023-07-07 16:43:47 RepVGG-A0] (main.py 282): INFO Train: [244/300][70/78]	eta 0:00:14 lr 0.518128	time 1.2072 (1.8433)	loss 2.4083 (2.4224)	grad_norm 0.5280 (0.5313)	mem 39782MB
[2023-07-07 16:43:58 RepVGG-A0] (main.py 291): INFO EPOCH 244 training takes 0:02:22
[2023-07-07 16:44:20 RepVGG-A0] (main.py 282): INFO Train: [245/300][0/78]	eta 0:27:45 lr 0.516254	time 21.3574 (21.3574)	loss 2.4350 (2.4350)	grad_norm 0.5272 (0.5272)	mem 39782MB
[2023-07-07 16:44:35 RepVGG-A0] (main.py 282): INFO Train: [245/300][10/78]	eta 0:03:46 lr 0.513917	time 1.1722 (3.3330)	loss 2.4533 (2.3989)	grad_norm 0.5456 (0.5333)	mem 39782MB
[2023-07-07 16:44:49 RepVGG-A0] (main.py 282): INFO Train: [245/300][20/78]	eta 0:02:20 lr 0.511584	time 1.1751 (2.4219)	loss 2.3666 (2.4018)	grad_norm 0.5279 (0.5315)	mem 39782MB
[2023-07-07 16:45:05 RepVGG-A0] (main.py 282): INFO Train: [245/300][30/78]	eta 0:01:43 lr 0.509256	time 1.2482 (2.1462)	loss 2.4126 (2.4070)	grad_norm 0.5196 (0.5296)	mem 39782MB
[2023-07-07 16:45:24 RepVGG-A0] (main.py 282): INFO Train: [245/300][40/78]	eta 0:01:19 lr 0.506933	time 4.9936 (2.0867)	loss 2.4137 (2.4106)	grad_norm 0.5629 (0.5344)	mem 39782MB
[2023-07-07 16:45:38 RepVGG-A0] (main.py 282): INFO Train: [245/300][50/78]	eta 0:00:54 lr 0.504615	time 1.1864 (1.9561)	loss 2.4304 (2.4108)	grad_norm 0.5365 (0.5367)	mem 39782MB
[2023-07-07 16:45:54 RepVGG-A0] (main.py 282): INFO Train: [245/300][60/78]	eta 0:00:34 lr 0.502302	time 1.3716 (1.8898)	loss 2.4510 (2.4141)	grad_norm 0.5408 (0.5354)	mem 39782MB
[2023-07-07 16:46:09 RepVGG-A0] (main.py 282): INFO Train: [245/300][70/78]	eta 0:00:14 lr 0.499994	time 1.1293 (1.8429)	loss 2.3717 (2.4141)	grad_norm 0.5221 (0.5342)	mem 39782MB
[2023-07-07 16:46:19 RepVGG-A0] (main.py 291): INFO EPOCH 245 training takes 0:02:21
[2023-07-07 16:46:40 RepVGG-A0] (main.py 282): INFO Train: [246/300][0/78]	eta 0:27:13 lr 0.498151	time 20.9486 (20.9486)	loss 2.4476 (2.4476)	grad_norm 0.5154 (0.5154)	mem 39782MB
[2023-07-07 16:46:56 RepVGG-A0] (main.py 282): INFO Train: [246/300][10/78]	eta 0:03:43 lr 0.495851	time 1.1732 (3.2797)	loss 2.3887 (2.3959)	grad_norm 0.5220 (0.5350)	mem 39782MB
[2023-07-07 16:47:10 RepVGG-A0] (main.py 282): INFO Train: [246/300][20/78]	eta 0:02:19 lr 0.493556	time 1.1746 (2.4110)	loss 2.3753 (2.3977)	grad_norm 0.5343 (0.5351)	mem 39782MB
[2023-07-07 16:47:25 RepVGG-A0] (main.py 282): INFO Train: [246/300][30/78]	eta 0:01:41 lr 0.491267	time 1.5490 (2.1162)	loss 2.4445 (2.4032)	grad_norm 0.5511 (0.5362)	mem 39782MB
[2023-07-07 16:47:44 RepVGG-A0] (main.py 282): INFO Train: [246/300][40/78]	eta 0:01:18 lr 0.488982	time 4.1089 (2.0535)	loss 2.3599 (2.4010)	grad_norm 0.5395 (0.5391)	mem 39782MB
[2023-07-07 16:47:59 RepVGG-A0] (main.py 282): INFO Train: [246/300][50/78]	eta 0:00:54 lr 0.486702	time 1.2810 (1.9496)	loss 2.4676 (2.4062)	grad_norm 0.5357 (0.5385)	mem 39782MB
[2023-07-07 16:48:14 RepVGG-A0] (main.py 282): INFO Train: [246/300][60/78]	eta 0:00:33 lr 0.484426	time 1.2993 (1.8761)	loss 2.4713 (2.4106)	grad_norm 0.5322 (0.5378)	mem 39782MB
[2023-07-07 16:48:30 RepVGG-A0] (main.py 282): INFO Train: [246/300][70/78]	eta 0:00:14 lr 0.482156	time 1.2688 (1.8349)	loss 2.3829 (2.4106)	grad_norm 0.5437 (0.5383)	mem 39782MB
[2023-07-07 16:48:42 RepVGG-A0] (main.py 291): INFO EPOCH 246 training takes 0:02:22
[2023-07-07 16:49:04 RepVGG-A0] (main.py 282): INFO Train: [247/300][0/78]	eta 0:28:01 lr 0.480343	time 21.5515 (21.5515)	loss 2.3962 (2.3962)	grad_norm 0.5318 (0.5318)	mem 39782MB
[2023-07-07 16:49:19 RepVGG-A0] (main.py 282): INFO Train: [247/300][10/78]	eta 0:03:46 lr 0.478082	time 1.1736 (3.3236)	loss 2.4253 (2.3923)	grad_norm 0.5305 (0.5308)	mem 39782MB
[2023-07-07 16:49:33 RepVGG-A0] (main.py 282): INFO Train: [247/300][20/78]	eta 0:02:20 lr 0.475825	time 1.1891 (2.4279)	loss 2.4682 (2.4104)	grad_norm 0.5342 (0.5354)	mem 39782MB
[2023-07-07 16:49:49 RepVGG-A0] (main.py 282): INFO Train: [247/300][30/78]	eta 0:01:42 lr 0.473574	time 1.5043 (2.1449)	loss 2.3909 (2.4105)	grad_norm 0.5426 (0.5353)	mem 39782MB
[2023-07-07 16:50:06 RepVGG-A0] (main.py 282): INFO Train: [247/300][40/78]	eta 0:01:17 lr 0.471327	time 3.2111 (2.0432)	loss 2.4016 (2.4108)	grad_norm 0.5285 (0.5371)	mem 39782MB
[2023-07-07 16:50:21 RepVGG-A0] (main.py 282): INFO Train: [247/300][50/78]	eta 0:00:54 lr 0.469085	time 1.2959 (1.9356)	loss 2.3994 (2.4105)	grad_norm 0.5415 (0.5373)	mem 39782MB
[2023-07-07 16:50:36 RepVGG-A0] (main.py 282): INFO Train: [247/300][60/78]	eta 0:00:33 lr 0.466848	time 1.2426 (1.8737)	loss 2.4301 (2.4115)	grad_norm 0.5326 (0.5376)	mem 39782MB
[2023-07-07 16:50:52 RepVGG-A0] (main.py 282): INFO Train: [247/300][70/78]	eta 0:00:14 lr 0.464616	time 1.2643 (1.8228)	loss 2.3881 (2.4104)	grad_norm 0.5408 (0.5387)	mem 39782MB
[2023-07-07 16:51:03 RepVGG-A0] (main.py 291): INFO EPOCH 247 training takes 0:02:21
[2023-07-07 16:51:25 RepVGG-A0] (main.py 282): INFO Train: [248/300][0/78]	eta 0:28:18 lr 0.462834	time 21.7722 (21.7722)	loss 2.3824 (2.3824)	grad_norm 0.5286 (0.5286)	mem 39782MB
[2023-07-07 16:51:40 RepVGG-A0] (main.py 282): INFO Train: [248/300][10/78]	eta 0:03:48 lr 0.460611	time 1.1708 (3.3639)	loss 2.4856 (2.3811)	grad_norm 0.5408 (0.5415)	mem 39782MB
[2023-07-07 16:51:56 RepVGG-A0] (main.py 282): INFO Train: [248/300][20/78]	eta 0:02:23 lr 0.458393	time 1.4042 (2.4818)	loss 2.3701 (2.3827)	grad_norm 0.5374 (0.5391)	mem 39782MB
[2023-07-07 16:52:10 RepVGG-A0] (main.py 282): INFO Train: [248/300][30/78]	eta 0:01:43 lr 0.456180	time 1.3232 (2.1586)	loss 2.4469 (2.3865)	grad_norm 0.5345 (0.5420)	mem 39782MB
[2023-07-07 16:52:28 RepVGG-A0] (main.py 282): INFO Train: [248/300][40/78]	eta 0:01:18 lr 0.453972	time 3.8434 (2.0680)	loss 2.4026 (2.3907)	grad_norm 0.5308 (0.5417)	mem 39782MB
[2023-07-07 16:52:44 RepVGG-A0] (main.py 282): INFO Train: [248/300][50/78]	eta 0:00:54 lr 0.451768	time 1.1730 (1.9617)	loss 2.3722 (2.3968)	grad_norm 0.5242 (0.5407)	mem 39782MB
[2023-07-07 16:52:59 RepVGG-A0] (main.py 282): INFO Train: [248/300][60/78]	eta 0:00:34 lr 0.449570	time 1.4484 (1.8978)	loss 2.3836 (2.3958)	grad_norm 0.5247 (0.5394)	mem 39782MB
[2023-07-07 16:53:14 RepVGG-A0] (main.py 282): INFO Train: [248/300][70/78]	eta 0:00:14 lr 0.447377	time 1.2617 (1.8341)	loss 2.3998 (2.3989)	grad_norm 0.5516 (0.5400)	mem 39782MB
[2023-07-07 16:53:25 RepVGG-A0] (main.py 291): INFO EPOCH 248 training takes 0:02:21
[2023-07-07 16:53:47 RepVGG-A0] (main.py 282): INFO Train: [249/300][0/78]	eta 0:28:15 lr 0.445626	time 21.7362 (21.7362)	loss 2.3714 (2.3714)	grad_norm 0.5415 (0.5415)	mem 39782MB
[2023-07-07 16:54:03 RepVGG-A0] (main.py 282): INFO Train: [249/300][10/78]	eta 0:03:52 lr 0.443441	time 1.1709 (3.4247)	loss 2.3613 (2.3842)	grad_norm 0.5613 (0.5463)	mem 39782MB
[2023-07-07 16:54:19 RepVGG-A0] (main.py 282): INFO Train: [249/300][20/78]	eta 0:02:26 lr 0.441262	time 1.4366 (2.5343)	loss 2.4128 (2.3846)	grad_norm 0.5299 (0.5436)	mem 39782MB
[2023-07-07 16:54:33 RepVGG-A0] (main.py 282): INFO Train: [249/300][30/78]	eta 0:01:44 lr 0.439087	time 1.3759 (2.1768)	loss 2.3759 (2.3950)	grad_norm 0.5466 (0.5423)	mem 39782MB
[2023-07-07 16:54:52 RepVGG-A0] (main.py 282): INFO Train: [249/300][40/78]	eta 0:01:20 lr 0.436918	time 3.5712 (2.1088)	loss 2.3679 (2.3925)	grad_norm 0.5560 (0.5440)	mem 39782MB
[2023-07-07 16:55:07 RepVGG-A0] (main.py 282): INFO Train: [249/300][50/78]	eta 0:00:55 lr 0.434753	time 1.1732 (1.9893)	loss 2.4100 (2.3924)	grad_norm 0.5436 (0.5435)	mem 39782MB
[2023-07-07 16:55:23 RepVGG-A0] (main.py 282): INFO Train: [249/300][60/78]	eta 0:00:34 lr 0.432593	time 1.2667 (1.9212)	loss 2.3859 (2.3944)	grad_norm 0.5453 (0.5442)	mem 39782MB
[2023-07-07 16:55:38 RepVGG-A0] (main.py 282): INFO Train: [249/300][70/78]	eta 0:00:14 lr 0.430439	time 1.7544 (1.8639)	loss 2.3823 (2.3952)	grad_norm 0.5415 (0.5455)	mem 39782MB
[2023-07-07 16:55:49 RepVGG-A0] (main.py 291): INFO EPOCH 249 training takes 0:02:23
[2023-07-07 16:56:12 RepVGG-A0] (main.py 282): INFO Train: [250/300][0/78]	eta 0:29:06 lr 0.428719	time 22.3869 (22.3869)	loss 2.3204 (2.3204)	grad_norm 0.5473 (0.5473)	mem 39782MB
[2023-07-07 16:56:25 RepVGG-A0] (main.py 282): INFO Train: [250/300][10/78]	eta 0:03:43 lr 0.426573	time 1.1716 (3.2838)	loss 2.3222 (2.3634)	grad_norm 0.5381 (0.5453)	mem 39782MB
[2023-07-07 16:56:41 RepVGG-A0] (main.py 282): INFO Train: [250/300][20/78]	eta 0:02:24 lr 0.424433	time 1.3282 (2.4889)	loss 2.3618 (2.3619)	grad_norm 0.5433 (0.5451)	mem 39782MB
[2023-07-07 16:56:56 RepVGG-A0] (main.py 282): INFO Train: [250/300][30/78]	eta 0:01:43 lr 0.422297	time 1.1290 (2.1464)	loss 2.3937 (2.3653)	grad_norm 0.5434 (0.5436)	mem 39782MB
[2023-07-07 16:57:13 RepVGG-A0] (main.py 282): INFO Train: [250/300][40/78]	eta 0:01:18 lr 0.420166	time 3.7376 (2.0531)	loss 2.3669 (2.3709)	grad_norm 0.5405 (0.5441)	mem 39782MB
[2023-07-07 16:57:28 RepVGG-A0] (main.py 282): INFO Train: [250/300][50/78]	eta 0:00:54 lr 0.418041	time 1.2910 (1.9436)	loss 2.3993 (2.3769)	grad_norm 0.5372 (0.5442)	mem 39782MB
[2023-07-07 16:57:44 RepVGG-A0] (main.py 282): INFO Train: [250/300][60/78]	eta 0:00:33 lr 0.415920	time 1.3171 (1.8771)	loss 2.4719 (2.3845)	grad_norm 0.5433 (0.5445)	mem 39782MB
[2023-07-07 16:57:58 RepVGG-A0] (main.py 282): INFO Train: [250/300][70/78]	eta 0:00:14 lr 0.413805	time 1.3105 (1.8209)	loss 2.3624 (2.3852)	grad_norm 0.5415 (0.5441)	mem 39782MB
[2023-07-07 16:58:10 RepVGG-A0] (main.py 291): INFO EPOCH 250 training takes 0:02:21
[2023-07-07 16:58:33 RepVGG-A0] (main.py 282): INFO Train: [251/300][0/78]	eta 0:29:22 lr 0.412116	time 22.5941 (22.5941)	loss 2.3060 (2.3060)	grad_norm 0.5354 (0.5354)	mem 39782MB
[2023-07-07 16:58:47 RepVGG-A0] (main.py 282): INFO Train: [251/300][10/78]	eta 0:03:47 lr 0.410009	time 1.1730 (3.3422)	loss 2.3497 (2.3509)	grad_norm 0.5519 (0.5437)	mem 39782MB
[2023-07-07 16:59:03 RepVGG-A0] (main.py 282): INFO Train: [251/300][20/78]	eta 0:02:25 lr 0.407908	time 1.2682 (2.5085)	loss 2.3830 (2.3573)	grad_norm 0.5602 (0.5462)	mem 39782MB
[2023-07-07 16:59:17 RepVGG-A0] (main.py 282): INFO Train: [251/300][30/78]	eta 0:01:44 lr 0.405811	time 1.3634 (2.1685)	loss 2.3883 (2.3669)	grad_norm 0.5405 (0.5464)	mem 39782MB
[2023-07-07 16:59:35 RepVGG-A0] (main.py 282): INFO Train: [251/300][40/78]	eta 0:01:18 lr 0.403720	time 3.7026 (2.0577)	loss 2.3704 (2.3711)	grad_norm 0.5541 (0.5469)	mem 39782MB
[2023-07-07 16:59:50 RepVGG-A0] (main.py 282): INFO Train: [251/300][50/78]	eta 0:00:54 lr 0.401634	time 1.2729 (1.9572)	loss 2.4239 (2.3742)	grad_norm 0.5494 (0.5473)	mem 39782MB
[2023-07-07 17:00:06 RepVGG-A0] (main.py 282): INFO Train: [251/300][60/78]	eta 0:00:34 lr 0.399552	time 1.1306 (1.8898)	loss 2.4088 (2.3766)	grad_norm 0.5450 (0.5477)	mem 39782MB
[2023-07-07 17:00:21 RepVGG-A0] (main.py 282): INFO Train: [251/300][70/78]	eta 0:00:14 lr 0.397476	time 1.6223 (1.8356)	loss 2.4076 (2.3768)	grad_norm 0.5406 (0.5481)	mem 39782MB
[2023-07-07 17:00:32 RepVGG-A0] (main.py 291): INFO EPOCH 251 training takes 0:02:21
[2023-07-07 17:00:54 RepVGG-A0] (main.py 282): INFO Train: [252/300][0/78]	eta 0:28:29 lr 0.395819	time 21.9180 (21.9180)	loss 2.3349 (2.3349)	grad_norm 0.5385 (0.5385)	mem 39782MB
[2023-07-07 17:01:10 RepVGG-A0] (main.py 282): INFO Train: [252/300][10/78]	eta 0:03:54 lr 0.393751	time 1.1744 (3.4548)	loss 2.3730 (2.3511)	grad_norm 0.5492 (0.5555)	mem 39782MB
[2023-07-07 17:01:25 RepVGG-A0] (main.py 282): INFO Train: [252/300][20/78]	eta 0:02:27 lr 0.391689	time 1.1812 (2.5387)	loss 2.3888 (2.3548)	grad_norm 0.5463 (0.5476)	mem 39782MB
[2023-07-07 17:01:41 RepVGG-A0] (main.py 282): INFO Train: [252/300][30/78]	eta 0:01:46 lr 0.389632	time 1.3781 (2.2207)	loss 2.3656 (2.3563)	grad_norm 0.5640 (0.5487)	mem 39782MB
[2023-07-07 17:01:58 RepVGG-A0] (main.py 282): INFO Train: [252/300][40/78]	eta 0:01:19 lr 0.387580	time 2.5768 (2.0997)	loss 2.3855 (2.3615)	grad_norm 0.5449 (0.5482)	mem 39782MB
[2023-07-07 17:02:14 RepVGG-A0] (main.py 282): INFO Train: [252/300][50/78]	eta 0:00:55 lr 0.385533	time 1.1924 (1.9900)	loss 2.3583 (2.3612)	grad_norm 0.5438 (0.5501)	mem 39782MB
[2023-07-07 17:02:29 RepVGG-A0] (main.py 282): INFO Train: [252/300][60/78]	eta 0:00:34 lr 0.383491	time 1.4779 (1.9158)	loss 2.3801 (2.3634)	grad_norm 0.5508 (0.5500)	mem 39782MB
[2023-07-07 17:02:44 RepVGG-A0] (main.py 282): INFO Train: [252/300][70/78]	eta 0:00:14 lr 0.381455	time 1.3740 (1.8603)	loss 2.3386 (2.3654)	grad_norm 0.5554 (0.5510)	mem 39782MB
[2023-07-07 17:02:56 RepVGG-A0] (main.py 291): INFO EPOCH 252 training takes 0:02:23
[2023-07-07 17:03:18 RepVGG-A0] (main.py 282): INFO Train: [253/300][0/78]	eta 0:28:52 lr 0.379829	time 22.2109 (22.2109)	loss 2.4208 (2.4208)	grad_norm 0.5560 (0.5560)	mem 39782MB
[2023-07-07 17:03:33 RepVGG-A0] (main.py 282): INFO Train: [253/300][10/78]	eta 0:03:51 lr 0.377801	time 1.1909 (3.4049)	loss 2.3934 (2.3730)	grad_norm 0.5352 (0.5418)	mem 39782MB
[2023-07-07 17:03:48 RepVGG-A0] (main.py 282): INFO Train: [253/300][20/78]	eta 0:02:23 lr 0.375779	time 1.1751 (2.4796)	loss 2.4017 (2.3718)	grad_norm 0.5387 (0.5432)	mem 39782MB
[2023-07-07 17:04:03 RepVGG-A0] (main.py 282): INFO Train: [253/300][30/78]	eta 0:01:44 lr 0.373761	time 1.3453 (2.1847)	loss 2.3507 (2.3708)	grad_norm 0.5472 (0.5463)	mem 39782MB
[2023-07-07 17:04:22 RepVGG-A0] (main.py 282): INFO Train: [253/300][40/78]	eta 0:01:20 lr 0.371749	time 3.0389 (2.1069)	loss 2.4353 (2.3716)	grad_norm 0.5497 (0.5491)	mem 39782MB
[2023-07-07 17:04:36 RepVGG-A0] (main.py 282): INFO Train: [253/300][50/78]	eta 0:00:55 lr 0.369742	time 1.1714 (1.9721)	loss 2.3798 (2.3737)	grad_norm 0.5633 (0.5515)	mem 39782MB
[2023-07-07 17:04:52 RepVGG-A0] (main.py 282): INFO Train: [253/300][60/78]	eta 0:00:34 lr 0.367740	time 1.3260 (1.9094)	loss 2.3789 (2.3719)	grad_norm 0.5622 (0.5516)	mem 39782MB
[2023-07-07 17:05:07 RepVGG-A0] (main.py 282): INFO Train: [253/300][70/78]	eta 0:00:14 lr 0.365743	time 1.1462 (1.8482)	loss 2.3520 (2.3730)	grad_norm 0.5523 (0.5535)	mem 39782MB
[2023-07-07 17:05:19 RepVGG-A0] (main.py 291): INFO EPOCH 253 training takes 0:02:23
[2023-07-07 17:05:40 RepVGG-A0] (main.py 282): INFO Train: [254/300][0/78]	eta 0:27:31 lr 0.364149	time 21.1709 (21.1709)	loss 2.3768 (2.3768)	grad_norm 0.5703 (0.5703)	mem 39782MB
[2023-07-07 17:05:55 RepVGG-A0] (main.py 282): INFO Train: [254/300][10/78]	eta 0:03:46 lr 0.362161	time 1.1729 (3.3305)	loss 2.2970 (2.3512)	grad_norm 0.5651 (0.5628)	mem 39782MB
[2023-07-07 17:06:11 RepVGG-A0] (main.py 282): INFO Train: [254/300][20/78]	eta 0:02:22 lr 0.360178	time 1.3010 (2.4631)	loss 2.4050 (2.3463)	grad_norm 0.5542 (0.5571)	mem 39782MB
[2023-07-07 17:06:26 RepVGG-A0] (main.py 282): INFO Train: [254/300][30/78]	eta 0:01:44 lr 0.358200	time 1.4449 (2.1714)	loss 2.3581 (2.3487)	grad_norm 0.5460 (0.5571)	mem 39782MB
[2023-07-07 17:06:44 RepVGG-A0] (main.py 282): INFO Train: [254/300][40/78]	eta 0:01:19 lr 0.356228	time 3.0904 (2.0793)	loss 2.3787 (2.3534)	grad_norm 0.5505 (0.5565)	mem 39782MB
[2023-07-07 17:06:58 RepVGG-A0] (main.py 282): INFO Train: [254/300][50/78]	eta 0:00:54 lr 0.354260	time 1.1997 (1.9497)	loss 2.3492 (2.3544)	grad_norm 0.5571 (0.5577)	mem 39782MB
[2023-07-07 17:07:13 RepVGG-A0] (main.py 282): INFO Train: [254/300][60/78]	eta 0:00:33 lr 0.352298	time 1.3060 (1.8756)	loss 2.3840 (2.3563)	grad_norm 0.5771 (0.5577)	mem 39782MB
[2023-07-07 17:07:28 RepVGG-A0] (main.py 282): INFO Train: [254/300][70/78]	eta 0:00:14 lr 0.350341	time 1.1759 (1.8207)	loss 2.3758 (2.3569)	grad_norm 0.5646 (0.5588)	mem 39782MB
[2023-07-07 17:07:40 RepVGG-A0] (main.py 291): INFO EPOCH 254 training takes 0:02:21
[2023-07-07 17:08:02 RepVGG-A0] (main.py 282): INFO Train: [255/300][0/78]	eta 0:28:08 lr 0.348779	time 21.6482 (21.6482)	loss 2.3455 (2.3455)	grad_norm 0.5669 (0.5669)	mem 39782MB
[2023-07-07 17:08:16 RepVGG-A0] (main.py 282): INFO Train: [255/300][10/78]	eta 0:03:39 lr 0.346831	time 1.1699 (3.2351)	loss 2.3415 (2.3368)	grad_norm 0.5479 (0.5538)	mem 39782MB
[2023-07-07 17:08:30 RepVGG-A0] (main.py 282): INFO Train: [255/300][20/78]	eta 0:02:18 lr 0.344889	time 1.1898 (2.3888)	loss 2.3221 (2.3430)	grad_norm 0.5469 (0.5539)	mem 39782MB
[2023-07-07 17:08:46 RepVGG-A0] (main.py 282): INFO Train: [255/300][30/78]	eta 0:01:42 lr 0.342951	time 1.2524 (2.1406)	loss 2.3153 (2.3400)	grad_norm 0.5710 (0.5572)	mem 39782MB
[2023-07-07 17:09:05 RepVGG-A0] (main.py 282): INFO Train: [255/300][40/78]	eta 0:01:19 lr 0.341019	time 3.3054 (2.0819)	loss 2.3659 (2.3379)	grad_norm 0.5662 (0.5588)	mem 39782MB
[2023-07-07 17:09:20 RepVGG-A0] (main.py 282): INFO Train: [255/300][50/78]	eta 0:00:55 lr 0.339091	time 1.3031 (1.9682)	loss 2.3992 (2.3406)	grad_norm 0.5755 (0.5597)	mem 39782MB
[2023-07-07 17:09:35 RepVGG-A0] (main.py 282): INFO Train: [255/300][60/78]	eta 0:00:34 lr 0.337169	time 1.2182 (1.8920)	loss 2.3741 (2.3449)	grad_norm 0.5575 (0.5600)	mem 39782MB
[2023-07-07 17:09:51 RepVGG-A0] (main.py 282): INFO Train: [255/300][70/78]	eta 0:00:14 lr 0.335252	time 1.2412 (1.8421)	loss 2.3519 (2.3483)	grad_norm 0.5533 (0.5602)	mem 39782MB
[2023-07-07 17:10:01 RepVGG-A0] (main.py 291): INFO EPOCH 255 training takes 0:02:21
[2023-07-07 17:10:23 RepVGG-A0] (main.py 282): INFO Train: [256/300][0/78]	eta 0:28:12 lr 0.333722	time 21.7015 (21.7015)	loss 2.3490 (2.3490)	grad_norm 0.5691 (0.5691)	mem 39782MB
[2023-07-07 17:10:38 RepVGG-A0] (main.py 282): INFO Train: [256/300][10/78]	eta 0:03:44 lr 0.331815	time 1.1724 (3.2992)	loss 2.3211 (2.3192)	grad_norm 0.5738 (0.5588)	mem 39782MB
[2023-07-07 17:10:53 RepVGG-A0] (main.py 282): INFO Train: [256/300][20/78]	eta 0:02:22 lr 0.329912	time 1.2184 (2.4576)	loss 2.3693 (2.3209)	grad_norm 0.5591 (0.5602)	mem 39782MB
[2023-07-07 17:11:08 RepVGG-A0] (main.py 282): INFO Train: [256/300][30/78]	eta 0:01:43 lr 0.328015	time 1.3048 (2.1545)	loss 2.3717 (2.3221)	grad_norm 0.5674 (0.5626)	mem 39782MB
[2023-07-07 17:11:26 RepVGG-A0] (main.py 282): INFO Train: [256/300][40/78]	eta 0:01:18 lr 0.326123	time 2.6901 (2.0588)	loss 2.3008 (2.3274)	grad_norm 0.5526 (0.5633)	mem 39782MB
[2023-07-07 17:11:41 RepVGG-A0] (main.py 282): INFO Train: [256/300][50/78]	eta 0:00:54 lr 0.324236	time 1.2133 (1.9475)	loss 2.3626 (2.3333)	grad_norm 0.5577 (0.5630)	mem 39782MB
[2023-07-07 17:11:56 RepVGG-A0] (main.py 282): INFO Train: [256/300][60/78]	eta 0:00:33 lr 0.322354	time 1.2429 (1.8812)	loss 2.3716 (2.3404)	grad_norm 0.5718 (0.5624)	mem 39782MB
[2023-07-07 17:12:12 RepVGG-A0] (main.py 282): INFO Train: [256/300][70/78]	eta 0:00:14 lr 0.320477	time 1.3083 (1.8340)	loss 2.3942 (2.3436)	grad_norm 0.5744 (0.5625)	mem 39782MB
[2023-07-07 17:12:23 RepVGG-A0] (main.py 291): INFO EPOCH 256 training takes 0:02:21
[2023-07-07 17:12:44 RepVGG-A0] (main.py 282): INFO Train: [257/300][0/78]	eta 0:27:48 lr 0.318980	time 21.3877 (21.3877)	loss 2.2870 (2.2870)	grad_norm 0.5496 (0.5496)	mem 39782MB
[2023-07-07 17:13:00 RepVGG-A0] (main.py 282): INFO Train: [257/300][10/78]	eta 0:03:52 lr 0.317113	time 1.1708 (3.4212)	loss 2.3183 (2.3194)	grad_norm 0.5543 (0.5601)	mem 39782MB
[2023-07-07 17:13:15 RepVGG-A0] (main.py 282): INFO Train: [257/300][20/78]	eta 0:02:25 lr 0.315251	time 1.3534 (2.5037)	loss 2.3129 (2.3232)	grad_norm 0.5422 (0.5634)	mem 39782MB
[2023-07-07 17:13:30 RepVGG-A0] (main.py 282): INFO Train: [257/300][30/78]	eta 0:01:44 lr 0.313394	time 1.3210 (2.1825)	loss 2.3528 (2.3261)	grad_norm 0.5773 (0.5651)	mem 39782MB
[2023-07-07 17:13:49 RepVGG-A0] (main.py 282): INFO Train: [257/300][40/78]	eta 0:01:19 lr 0.311542	time 2.6234 (2.0962)	loss 2.2990 (2.3287)	grad_norm 0.5564 (0.5640)	mem 39782MB
[2023-07-07 17:14:04 RepVGG-A0] (main.py 282): INFO Train: [257/300][50/78]	eta 0:00:55 lr 0.309696	time 1.1735 (1.9963)	loss 2.4116 (2.3351)	grad_norm 0.5823 (0.5645)	mem 39782MB
[2023-07-07 17:14:20 RepVGG-A0] (main.py 282): INFO Train: [257/300][60/78]	eta 0:00:34 lr 0.307854	time 1.4365 (1.9214)	loss 2.3550 (2.3360)	grad_norm 0.5753 (0.5650)	mem 39782MB
[2023-07-07 17:14:35 RepVGG-A0] (main.py 282): INFO Train: [257/300][70/78]	eta 0:00:14 lr 0.306018	time 1.5690 (1.8676)	loss 2.4048 (2.3389)	grad_norm 0.5710 (0.5652)	mem 39782MB
[2023-07-07 17:14:46 RepVGG-A0] (main.py 291): INFO EPOCH 257 training takes 0:02:22
[2023-07-07 17:15:07 RepVGG-A0] (main.py 282): INFO Train: [258/300][0/78]	eta 0:28:18 lr 0.304553	time 21.7816 (21.7816)	loss 2.3266 (2.3266)	grad_norm 0.5610 (0.5610)	mem 39782MB
[2023-07-07 17:15:23 RepVGG-A0] (main.py 282): INFO Train: [258/300][10/78]	eta 0:03:48 lr 0.302727	time 1.1703 (3.3552)	loss 2.3334 (2.3259)	grad_norm 0.5682 (0.5617)	mem 39782MB
[2023-07-07 17:15:38 RepVGG-A0] (main.py 282): INFO Train: [258/300][20/78]	eta 0:02:23 lr 0.300905	time 1.3118 (2.4801)	loss 2.3152 (2.3281)	grad_norm 0.5610 (0.5649)	mem 39782MB
[2023-07-07 17:15:53 RepVGG-A0] (main.py 282): INFO Train: [258/300][30/78]	eta 0:01:44 lr 0.299089	time 1.2365 (2.1752)	loss 2.3732 (2.3302)	grad_norm 0.5888 (0.5667)	mem 39782MB
[2023-07-07 17:16:11 RepVGG-A0] (main.py 282): INFO Train: [258/300][40/78]	eta 0:01:19 lr 0.297278	time 3.7233 (2.0867)	loss 2.3477 (2.3297)	grad_norm 0.5585 (0.5660)	mem 39782MB
[2023-07-07 17:16:26 RepVGG-A0] (main.py 282): INFO Train: [258/300][50/78]	eta 0:00:55 lr 0.295473	time 1.1729 (1.9664)	loss 2.3281 (2.3288)	grad_norm 0.5721 (0.5666)	mem 39782MB
[2023-07-07 17:16:41 RepVGG-A0] (main.py 282): INFO Train: [258/300][60/78]	eta 0:00:34 lr 0.293672	time 1.3481 (1.8913)	loss 2.3434 (2.3299)	grad_norm 0.5658 (0.5671)	mem 39782MB
[2023-07-07 17:16:56 RepVGG-A0] (main.py 282): INFO Train: [258/300][70/78]	eta 0:00:14 lr 0.291877	time 1.3324 (1.8380)	loss 2.3459 (2.3315)	grad_norm 0.5701 (0.5676)	mem 39782MB
[2023-07-07 17:17:08 RepVGG-A0] (main.py 291): INFO EPOCH 258 training takes 0:02:22
[2023-07-07 17:17:30 RepVGG-A0] (main.py 282): INFO Train: [259/300][0/78]	eta 0:28:37 lr 0.290444	time 22.0256 (22.0256)	loss 2.3348 (2.3348)	grad_norm 0.5662 (0.5662)	mem 39782MB
[2023-07-07 17:17:45 RepVGG-A0] (main.py 282): INFO Train: [259/300][10/78]	eta 0:03:47 lr 0.288659	time 1.1721 (3.3488)	loss 2.3051 (2.3078)	grad_norm 0.5638 (0.5631)	mem 39782MB
[2023-07-07 17:18:00 RepVGG-A0] (main.py 282): INFO Train: [259/300][20/78]	eta 0:02:24 lr 0.286878	time 1.2832 (2.4912)	loss 2.3105 (2.3144)	grad_norm 0.5729 (0.5700)	mem 39782MB
[2023-07-07 17:18:14 RepVGG-A0] (main.py 282): INFO Train: [259/300][30/78]	eta 0:01:42 lr 0.285103	time 1.2050 (2.1258)	loss 2.3087 (2.3145)	grad_norm 0.5809 (0.5702)	mem 39782MB
[2023-07-07 17:18:32 RepVGG-A0] (main.py 282): INFO Train: [259/300][40/78]	eta 0:01:18 lr 0.283333	time 3.3553 (2.0665)	loss 2.3578 (2.3160)	grad_norm 0.5714 (0.5703)	mem 39782MB
[2023-07-07 17:18:47 RepVGG-A0] (main.py 282): INFO Train: [259/300][50/78]	eta 0:00:54 lr 0.281568	time 1.1711 (1.9413)	loss 2.2849 (2.3153)	grad_norm 0.5831 (0.5699)	mem 39782MB
[2023-07-07 17:19:02 RepVGG-A0] (main.py 282): INFO Train: [259/300][60/78]	eta 0:00:33 lr 0.279808	time 1.4287 (1.8779)	loss 2.2861 (2.3187)	grad_norm 0.5977 (0.5710)	mem 39782MB
[2023-07-07 17:19:17 RepVGG-A0] (main.py 282): INFO Train: [259/300][70/78]	eta 0:00:14 lr 0.278054	time 1.1313 (1.8241)	loss 2.3664 (2.3231)	grad_norm 0.5771 (0.5717)	mem 39782MB
[2023-07-07 17:19:30 RepVGG-A0] (main.py 291): INFO EPOCH 259 training takes 0:02:21
[2023-07-07 17:19:50 RepVGG-A0] (main.py 282): INFO Train: [260/300][0/78]	eta 0:27:13 lr 0.276655	time 20.9458 (20.9458)	loss 2.3125 (2.3125)	grad_norm 0.5650 (0.5650)	mem 39782MB
[2023-07-07 17:20:06 RepVGG-A0] (main.py 282): INFO Train: [260/300][10/78]	eta 0:03:43 lr 0.274910	time 1.1705 (3.2851)	loss 2.3164 (2.3032)	grad_norm 0.5658 (0.5689)	mem 39782MB
[2023-07-07 17:20:20 RepVGG-A0] (main.py 282): INFO Train: [260/300][20/78]	eta 0:02:19 lr 0.273170	time 1.3352 (2.4080)	loss 2.2922 (2.3049)	grad_norm 0.5763 (0.5697)	mem 39782MB
[2023-07-07 17:20:35 RepVGG-A0] (main.py 282): INFO Train: [260/300][30/78]	eta 0:01:40 lr 0.271436	time 1.1907 (2.1018)	loss 2.2949 (2.3063)	grad_norm 0.5676 (0.5700)	mem 39782MB
[2023-07-07 17:20:53 RepVGG-A0] (main.py 282): INFO Train: [260/300][40/78]	eta 0:01:17 lr 0.269707	time 3.6021 (2.0324)	loss 2.2381 (2.3101)	grad_norm 0.5700 (0.5724)	mem 39782MB
[2023-07-07 17:21:08 RepVGG-A0] (main.py 282): INFO Train: [260/300][50/78]	eta 0:00:54 lr 0.267983	time 1.3093 (1.9365)	loss 2.3034 (2.3129)	grad_norm 0.5723 (0.5737)	mem 39782MB
[2023-07-07 17:21:23 RepVGG-A0] (main.py 282): INFO Train: [260/300][60/78]	eta 0:00:33 lr 0.266265	time 1.2102 (1.8627)	loss 2.3077 (2.3171)	grad_norm 0.5727 (0.5749)	mem 39782MB
[2023-07-07 17:21:38 RepVGG-A0] (main.py 282): INFO Train: [260/300][70/78]	eta 0:00:14 lr 0.264552	time 1.1519 (1.8139)	loss 2.3590 (2.3175)	grad_norm 0.5777 (0.5755)	mem 39782MB
[2023-07-07 17:21:50 RepVGG-A0] (main.py 291): INFO EPOCH 260 training takes 0:02:20
[2023-07-07 17:22:08 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.053 (17.053)	Loss 1.4969 (1.4969)	Acc@1 67.114 (67.114)	Acc@5 87.482 (87.482)	Mem 39782MB
[2023-07-07 17:22:09 RepVGG-A0] (main.py 342): INFO  * Acc@1 67.272 Acc@5 87.486
[2023-07-07 17:22:09 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 260: 67.272%
[2023-07-07 17:22:09 RepVGG-A0] (main.py 172): INFO Max accuracy: 67.27%
[2023-07-07 17:22:30 RepVGG-A0] (main.py 282): INFO Train: [261/300][0/78]	eta 0:27:45 lr 0.263185	time 21.3531 (21.3531)	loss 2.2426 (2.2426)	grad_norm 0.5742 (0.5742)	mem 39782MB
[2023-07-07 17:22:46 RepVGG-A0] (main.py 282): INFO Train: [261/300][10/78]	eta 0:03:47 lr 0.261482	time 1.1713 (3.3520)	loss 2.2616 (2.2868)	grad_norm 0.5759 (0.5737)	mem 39782MB
[2023-07-07 17:23:00 RepVGG-A0] (main.py 282): INFO Train: [261/300][20/78]	eta 0:02:21 lr 0.259783	time 1.1775 (2.4408)	loss 2.3361 (2.2902)	grad_norm 0.5811 (0.5762)	mem 39782MB
[2023-07-07 17:23:14 RepVGG-A0] (main.py 282): INFO Train: [261/300][30/78]	eta 0:01:41 lr 0.258090	time 1.2558 (2.1163)	loss 2.3545 (2.3053)	grad_norm 0.5711 (0.5770)	mem 39782MB
[2023-07-07 17:23:32 RepVGG-A0] (main.py 282): INFO Train: [261/300][40/78]	eta 0:01:17 lr 0.256403	time 1.9085 (2.0309)	loss 2.3259 (2.3103)	grad_norm 0.5813 (0.5768)	mem 39782MB
[2023-07-07 17:23:48 RepVGG-A0] (main.py 282): INFO Train: [261/300][50/78]	eta 0:00:54 lr 0.254720	time 1.1746 (1.9464)	loss 2.3182 (2.3113)	grad_norm 0.5722 (0.5772)	mem 39782MB
[2023-07-07 17:24:03 RepVGG-A0] (main.py 282): INFO Train: [261/300][60/78]	eta 0:00:33 lr 0.253043	time 1.1945 (1.8655)	loss 2.3180 (2.3134)	grad_norm 0.5751 (0.5766)	mem 39782MB
[2023-07-07 17:24:18 RepVGG-A0] (main.py 282): INFO Train: [261/300][70/78]	eta 0:00:14 lr 0.251371	time 1.3449 (1.8223)	loss 2.2821 (2.3147)	grad_norm 0.5704 (0.5782)	mem 39782MB
[2023-07-07 17:24:30 RepVGG-A0] (main.py 291): INFO EPOCH 261 training takes 0:02:21
[2023-07-07 17:24:52 RepVGG-A0] (main.py 282): INFO Train: [262/300][0/78]	eta 0:28:14 lr 0.250038	time 21.7221 (21.7221)	loss 2.2346 (2.2346)	grad_norm 0.5803 (0.5803)	mem 39782MB
[2023-07-07 17:25:07 RepVGG-A0] (main.py 282): INFO Train: [262/300][10/78]	eta 0:03:44 lr 0.248376	time 1.1901 (3.3017)	loss 2.2798 (2.3029)	grad_norm 0.5728 (0.5734)	mem 39782MB
[2023-07-07 17:25:22 RepVGG-A0] (main.py 282): INFO Train: [262/300][20/78]	eta 0:02:21 lr 0.246719	time 1.1744 (2.4419)	loss 2.3431 (2.3023)	grad_norm 0.5873 (0.5748)	mem 39782MB
[2023-07-07 17:25:38 RepVGG-A0] (main.py 282): INFO Train: [262/300][30/78]	eta 0:01:44 lr 0.245067	time 1.6140 (2.1815)	loss 2.3215 (2.3059)	grad_norm 0.5979 (0.5759)	mem 39782MB
[2023-07-07 17:25:56 RepVGG-A0] (main.py 282): INFO Train: [262/300][40/78]	eta 0:01:18 lr 0.243421	time 3.6390 (2.0771)	loss 2.3328 (2.3052)	grad_norm 0.5793 (0.5774)	mem 39782MB
[2023-07-07 17:26:10 RepVGG-A0] (main.py 282): INFO Train: [262/300][50/78]	eta 0:00:54 lr 0.241780	time 1.1717 (1.9608)	loss 2.3419 (2.3071)	grad_norm 0.5810 (0.5782)	mem 39782MB
[2023-07-07 17:26:26 RepVGG-A0] (main.py 282): INFO Train: [262/300][60/78]	eta 0:00:33 lr 0.240145	time 1.2075 (1.8863)	loss 2.2673 (2.3066)	grad_norm 0.5828 (0.5782)	mem 39782MB
[2023-07-07 17:26:41 RepVGG-A0] (main.py 282): INFO Train: [262/300][70/78]	eta 0:00:14 lr 0.238514	time 1.5163 (1.8344)	loss 2.2636 (2.3055)	grad_norm 0.5824 (0.5790)	mem 39782MB
[2023-07-07 17:26:52 RepVGG-A0] (main.py 291): INFO EPOCH 262 training takes 0:02:21
[2023-07-07 17:27:13 RepVGG-A0] (main.py 282): INFO Train: [263/300][0/78]	eta 0:27:15 lr 0.237214	time 20.9677 (20.9677)	loss 2.3061 (2.3061)	grad_norm 0.6101 (0.6101)	mem 39782MB
[2023-07-07 17:27:28 RepVGG-A0] (main.py 282): INFO Train: [263/300][10/78]	eta 0:03:39 lr 0.235594	time 1.1732 (3.2225)	loss 2.2771 (2.2662)	grad_norm 0.5813 (0.6169)	mem 39782MB
[2023-07-07 17:27:43 RepVGG-A0] (main.py 282): INFO Train: [263/300][20/78]	eta 0:02:20 lr 0.233978	time 1.2850 (2.4253)	loss 2.2951 (2.2784)	grad_norm 0.5791 (0.5982)	mem 39782MB
[2023-07-07 17:28:05 RepVGG-A0] (main.py 282): INFO Train: [263/300][30/78]	eta 0:01:51 lr 0.232368	time 1.1718 (2.3281)	loss 2.3029 (2.2811)	grad_norm 0.5789 (0.5924)	mem 39782MB
[2023-07-07 17:28:21 RepVGG-A0] (main.py 282): INFO Train: [263/300][40/78]	eta 0:01:21 lr 0.230764	time 1.1747 (2.1516)	loss 2.2835 (2.2855)	grad_norm 0.5843 (0.5906)	mem 39782MB
[2023-07-07 17:28:36 RepVGG-A0] (main.py 282): INFO Train: [263/300][50/78]	eta 0:00:57 lr 0.229165	time 1.1776 (2.0360)	loss 2.3137 (2.2917)	grad_norm 0.5638 (0.5889)	mem 39782MB
[2023-07-07 17:28:51 RepVGG-A0] (main.py 282): INFO Train: [263/300][60/78]	eta 0:00:35 lr 0.227571	time 1.2586 (1.9449)	loss 2.3233 (2.2948)	grad_norm 0.5914 (0.5885)	mem 39782MB
[2023-07-07 17:29:06 RepVGG-A0] (main.py 282): INFO Train: [263/300][70/78]	eta 0:00:15 lr 0.225982	time 1.2249 (1.8802)	loss 2.2785 (2.2957)	grad_norm 0.5738 (0.5882)	mem 39782MB
[2023-07-07 17:29:17 RepVGG-A0] (main.py 291): INFO EPOCH 263 training takes 0:02:24
[2023-07-07 17:29:37 RepVGG-A0] (main.py 282): INFO Train: [264/300][0/78]	eta 0:26:51 lr 0.224715	time 20.6543 (20.6543)	loss 2.2698 (2.2698)	grad_norm 0.5828 (0.5828)	mem 39782MB
[2023-07-07 17:29:53 RepVGG-A0] (main.py 282): INFO Train: [264/300][10/78]	eta 0:03:41 lr 0.223136	time 1.1720 (3.2574)	loss 2.2710 (2.2801)	grad_norm 0.5700 (0.5851)	mem 39782MB
[2023-07-07 17:30:07 RepVGG-A0] (main.py 282): INFO Train: [264/300][20/78]	eta 0:02:19 lr 0.221563	time 1.1734 (2.4042)	loss 2.2928 (2.2884)	grad_norm 0.5929 (0.5869)	mem 39782MB
[2023-07-07 17:30:23 RepVGG-A0] (main.py 282): INFO Train: [264/300][30/78]	eta 0:01:41 lr 0.219995	time 1.2664 (2.1201)	loss 2.2622 (2.2923)	grad_norm 0.6009 (0.5866)	mem 39782MB
[2023-07-07 17:30:40 RepVGG-A0] (main.py 282): INFO Train: [264/300][40/78]	eta 0:01:17 lr 0.218432	time 3.3310 (2.0335)	loss 2.2543 (2.2922)	grad_norm 0.5828 (0.5865)	mem 39782MB
[2023-07-07 17:30:55 RepVGG-A0] (main.py 282): INFO Train: [264/300][50/78]	eta 0:00:54 lr 0.216875	time 1.1737 (1.9336)	loss 2.2684 (2.2946)	grad_norm 0.5860 (0.5859)	mem 39782MB
[2023-07-07 17:31:11 RepVGG-A0] (main.py 282): INFO Train: [264/300][60/78]	eta 0:00:33 lr 0.215323	time 1.1414 (1.8746)	loss 2.3587 (2.2966)	grad_norm 0.5947 (0.5869)	mem 39782MB
[2023-07-07 17:31:26 RepVGG-A0] (main.py 282): INFO Train: [264/300][70/78]	eta 0:00:14 lr 0.213776	time 1.2217 (1.8137)	loss 2.2531 (2.2973)	grad_norm 0.5859 (0.5867)	mem 39782MB
[2023-07-07 17:31:38 RepVGG-A0] (main.py 291): INFO EPOCH 264 training takes 0:02:20
[2023-07-07 17:32:00 RepVGG-A0] (main.py 282): INFO Train: [265/300][0/78]	eta 0:28:34 lr 0.212543	time 21.9785 (21.9785)	loss 2.2515 (2.2515)	grad_norm 0.5911 (0.5911)	mem 39782MB
[2023-07-07 17:32:15 RepVGG-A0] (main.py 282): INFO Train: [265/300][10/78]	eta 0:03:49 lr 0.211006	time 1.1924 (3.3699)	loss 2.3076 (2.2679)	grad_norm 0.5899 (0.5860)	mem 39782MB
[2023-07-07 17:32:29 RepVGG-A0] (main.py 282): INFO Train: [265/300][20/78]	eta 0:02:23 lr 0.209474	time 1.1781 (2.4691)	loss 2.2550 (2.2722)	grad_norm 0.5889 (0.5902)	mem 39782MB
[2023-07-07 17:32:44 RepVGG-A0] (main.py 282): INFO Train: [265/300][30/78]	eta 0:01:43 lr 0.207948	time 1.2401 (2.1527)	loss 2.2871 (2.2747)	grad_norm 0.5842 (0.5901)	mem 39782MB
[2023-07-07 17:33:02 RepVGG-A0] (main.py 282): INFO Train: [265/300][40/78]	eta 0:01:18 lr 0.206427	time 3.6639 (2.0653)	loss 2.3247 (2.2781)	grad_norm 0.6056 (0.5899)	mem 39782MB
[2023-07-07 17:33:17 RepVGG-A0] (main.py 282): INFO Train: [265/300][50/78]	eta 0:00:54 lr 0.204912	time 1.1714 (1.9497)	loss 2.2575 (2.2789)	grad_norm 0.5949 (0.5911)	mem 39782MB
[2023-07-07 17:33:32 RepVGG-A0] (main.py 282): INFO Train: [265/300][60/78]	eta 0:00:33 lr 0.203402	time 1.1775 (1.8820)	loss 2.2819 (2.2821)	grad_norm 0.5862 (0.5911)	mem 39782MB
[2023-07-07 17:33:48 RepVGG-A0] (main.py 282): INFO Train: [265/300][70/78]	eta 0:00:14 lr 0.201897	time 1.3225 (1.8417)	loss 2.2629 (2.2828)	grad_norm 0.5918 (0.5905)	mem 39782MB
[2023-07-07 17:33:59 RepVGG-A0] (main.py 291): INFO EPOCH 265 training takes 0:02:21
[2023-07-07 17:34:21 RepVGG-A0] (main.py 282): INFO Train: [266/300][0/78]	eta 0:28:13 lr 0.200698	time 21.7142 (21.7142)	loss 2.2069 (2.2069)	grad_norm 0.5767 (0.5767)	mem 39782MB
[2023-07-07 17:34:36 RepVGG-A0] (main.py 282): INFO Train: [266/300][10/78]	eta 0:03:47 lr 0.199203	time 1.1716 (3.3423)	loss 2.2187 (2.2670)	grad_norm 0.5801 (0.5881)	mem 39782MB
[2023-07-07 17:34:51 RepVGG-A0] (main.py 282): INFO Train: [266/300][20/78]	eta 0:02:23 lr 0.197713	time 1.4493 (2.4710)	loss 2.3142 (2.2721)	grad_norm 0.5976 (0.5885)	mem 39782MB
[2023-07-07 17:35:07 RepVGG-A0] (main.py 282): INFO Train: [266/300][30/78]	eta 0:01:44 lr 0.196229	time 1.6026 (2.1731)	loss 2.2878 (2.2712)	grad_norm 0.5975 (0.5891)	mem 39782MB
[2023-07-07 17:35:23 RepVGG-A0] (main.py 282): INFO Train: [266/300][40/78]	eta 0:01:17 lr 0.194751	time 2.5900 (2.0435)	loss 2.3102 (2.2759)	grad_norm 0.5995 (0.5908)	mem 39782MB
[2023-07-07 17:35:39 RepVGG-A0] (main.py 282): INFO Train: [266/300][50/78]	eta 0:00:54 lr 0.193278	time 1.1724 (1.9507)	loss 2.3109 (2.2771)	grad_norm 0.5956 (0.5913)	mem 39782MB
[2023-07-07 17:35:54 RepVGG-A0] (main.py 282): INFO Train: [266/300][60/78]	eta 0:00:33 lr 0.191810	time 1.2012 (1.8723)	loss 2.2961 (2.2784)	grad_norm 0.5952 (0.5922)	mem 39782MB
[2023-07-07 17:36:09 RepVGG-A0] (main.py 282): INFO Train: [266/300][70/78]	eta 0:00:14 lr 0.190348	time 1.4103 (1.8201)	loss 2.3381 (2.2813)	grad_norm 0.6125 (0.5929)	mem 39782MB
[2023-07-07 17:36:21 RepVGG-A0] (main.py 291): INFO EPOCH 266 training takes 0:02:21
[2023-07-07 17:36:41 RepVGG-A0] (main.py 282): INFO Train: [267/300][0/78]	eta 0:25:59 lr 0.189182	time 19.9988 (19.9988)	loss 2.3696 (2.3696)	grad_norm 0.5900 (0.5900)	mem 39782MB
[2023-07-07 17:36:56 RepVGG-A0] (main.py 282): INFO Train: [267/300][10/78]	eta 0:03:34 lr 0.187729	time 1.1873 (3.1534)	loss 2.2340 (2.2643)	grad_norm 0.5996 (0.5898)	mem 39782MB
[2023-07-07 17:37:12 RepVGG-A0] (main.py 282): INFO Train: [267/300][20/78]	eta 0:02:21 lr 0.186282	time 1.3241 (2.4336)	loss 2.3303 (2.2746)	grad_norm 0.6010 (0.5914)	mem 39782MB
[2023-07-07 17:37:27 RepVGG-A0] (main.py 282): INFO Train: [267/300][30/78]	eta 0:01:42 lr 0.184840	time 1.7687 (2.1366)	loss 2.2781 (2.2778)	grad_norm 0.5988 (0.5931)	mem 39782MB
[2023-07-07 17:37:43 RepVGG-A0] (main.py 282): INFO Train: [267/300][40/78]	eta 0:01:16 lr 0.183404	time 3.4428 (2.0013)	loss 2.2542 (2.2744)	grad_norm 0.5921 (0.5955)	mem 39782MB
[2023-07-07 17:37:58 RepVGG-A0] (main.py 282): INFO Train: [267/300][50/78]	eta 0:00:53 lr 0.181973	time 1.3427 (1.9042)	loss 2.2692 (2.2744)	grad_norm 0.6023 (0.5957)	mem 39782MB
[2023-07-07 17:38:13 RepVGG-A0] (main.py 282): INFO Train: [267/300][60/78]	eta 0:00:33 lr 0.180548	time 1.1718 (1.8371)	loss 2.2879 (2.2752)	grad_norm 0.6014 (0.5958)	mem 39782MB
[2023-07-07 17:38:28 RepVGG-A0] (main.py 282): INFO Train: [267/300][70/78]	eta 0:00:14 lr 0.179128	time 1.3674 (1.7901)	loss 2.2896 (2.2747)	grad_norm 0.6048 (0.5967)	mem 39782MB
[2023-07-07 17:38:40 RepVGG-A0] (main.py 291): INFO EPOCH 267 training takes 0:02:18
[2023-07-07 17:39:01 RepVGG-A0] (main.py 282): INFO Train: [268/300][0/78]	eta 0:27:09 lr 0.177996	time 20.8916 (20.8916)	loss 2.3114 (2.3114)	grad_norm 0.5898 (0.5898)	mem 39782MB
[2023-07-07 17:39:16 RepVGG-A0] (main.py 282): INFO Train: [268/300][10/78]	eta 0:03:42 lr 0.176585	time 1.1715 (3.2649)	loss 2.2293 (2.2682)	grad_norm 0.5931 (0.5918)	mem 39782MB
[2023-07-07 17:39:31 RepVGG-A0] (main.py 282): INFO Train: [268/300][20/78]	eta 0:02:22 lr 0.175181	time 1.2128 (2.4486)	loss 2.2683 (2.2613)	grad_norm 0.5965 (0.5918)	mem 39782MB
[2023-07-07 17:39:46 RepVGG-A0] (main.py 282): INFO Train: [268/300][30/78]	eta 0:01:42 lr 0.173782	time 1.3609 (2.1338)	loss 2.2171 (2.2589)	grad_norm 0.5863 (0.5934)	mem 39782MB
[2023-07-07 17:40:03 RepVGG-A0] (main.py 282): INFO Train: [268/300][40/78]	eta 0:01:17 lr 0.172388	time 3.0072 (2.0411)	loss 2.2510 (2.2602)	grad_norm 0.5968 (0.5946)	mem 39782MB
[2023-07-07 17:40:19 RepVGG-A0] (main.py 282): INFO Train: [268/300][50/78]	eta 0:00:54 lr 0.170999	time 1.1723 (1.9439)	loss 2.2541 (2.2604)	grad_norm 0.5996 (0.5957)	mem 39782MB
[2023-07-07 17:40:34 RepVGG-A0] (main.py 282): INFO Train: [268/300][60/78]	eta 0:00:33 lr 0.169617	time 1.4377 (1.8739)	loss 2.2393 (2.2661)	grad_norm 0.5948 (0.5972)	mem 39782MB
[2023-07-07 17:40:49 RepVGG-A0] (main.py 282): INFO Train: [268/300][70/78]	eta 0:00:14 lr 0.168239	time 1.2836 (1.8169)	loss 2.2951 (2.2676)	grad_norm 0.6081 (0.5977)	mem 39782MB
[2023-07-07 17:41:00 RepVGG-A0] (main.py 291): INFO EPOCH 268 training takes 0:02:20
[2023-07-07 17:41:21 RepVGG-A0] (main.py 282): INFO Train: [269/300][0/78]	eta 0:27:25 lr 0.167141	time 21.0929 (21.0929)	loss 2.2151 (2.2151)	grad_norm 0.5896 (0.5896)	mem 39782MB
[2023-07-07 17:41:36 RepVGG-A0] (main.py 282): INFO Train: [269/300][10/78]	eta 0:03:43 lr 0.165774	time 1.1733 (3.2877)	loss 2.3108 (2.2462)	grad_norm 0.6026 (0.5946)	mem 39782MB
[2023-07-07 17:41:51 RepVGG-A0] (main.py 282): INFO Train: [269/300][20/78]	eta 0:02:21 lr 0.164411	time 1.2068 (2.4413)	loss 2.2045 (2.2449)	grad_norm 0.6027 (0.5969)	mem 39782MB
[2023-07-07 17:42:07 RepVGG-A0] (main.py 282): INFO Train: [269/300][30/78]	eta 0:01:42 lr 0.163055	time 1.2735 (2.1443)	loss 2.3157 (2.2519)	grad_norm 0.5956 (0.5978)	mem 39782MB
[2023-07-07 17:42:26 RepVGG-A0] (main.py 282): INFO Train: [269/300][40/78]	eta 0:01:19 lr 0.161704	time 3.8992 (2.0806)	loss 2.3000 (2.2547)	grad_norm 0.6046 (0.5996)	mem 39782MB
[2023-07-07 17:42:40 RepVGG-A0] (main.py 282): INFO Train: [269/300][50/78]	eta 0:00:54 lr 0.160358	time 1.1780 (1.9597)	loss 2.2556 (2.2585)	grad_norm 0.5963 (0.6004)	mem 39782MB
[2023-07-07 17:42:55 RepVGG-A0] (main.py 282): INFO Train: [269/300][60/78]	eta 0:00:33 lr 0.159018	time 1.1768 (1.8873)	loss 2.2871 (2.2597)	grad_norm 0.6096 (0.6003)	mem 39782MB
[2023-07-07 17:43:10 RepVGG-A0] (main.py 282): INFO Train: [269/300][70/78]	eta 0:00:14 lr 0.157683	time 1.3682 (1.8307)	loss 2.2130 (2.2597)	grad_norm 0.5994 (0.6009)	mem 39782MB
[2023-07-07 17:43:21 RepVGG-A0] (main.py 291): INFO EPOCH 269 training takes 0:02:21
[2023-07-07 17:43:43 RepVGG-A0] (main.py 282): INFO Train: [270/300][0/78]	eta 0:28:44 lr 0.156619	time 22.1104 (22.1104)	loss 2.2475 (2.2475)	grad_norm 0.6002 (0.6002)	mem 39782MB
[2023-07-07 17:43:58 RepVGG-A0] (main.py 282): INFO Train: [270/300][10/78]	eta 0:03:49 lr 0.155294	time 1.1737 (3.3782)	loss 2.2192 (2.2450)	grad_norm 0.5950 (0.6043)	mem 39782MB
[2023-07-07 17:44:14 RepVGG-A0] (main.py 282): INFO Train: [270/300][20/78]	eta 0:02:25 lr 0.153975	time 1.5299 (2.5027)	loss 2.2512 (2.2528)	grad_norm 0.5992 (0.6035)	mem 39782MB
[2023-07-07 17:44:28 RepVGG-A0] (main.py 282): INFO Train: [270/300][30/78]	eta 0:01:43 lr 0.152661	time 1.2929 (2.1660)	loss 2.3007 (2.2521)	grad_norm 0.6050 (0.6041)	mem 39782MB
[2023-07-07 17:44:46 RepVGG-A0] (main.py 282): INFO Train: [270/300][40/78]	eta 0:01:18 lr 0.151353	time 3.2304 (2.0636)	loss 2.2249 (2.2498)	grad_norm 0.6112 (0.6051)	mem 39782MB
[2023-07-07 17:45:01 RepVGG-A0] (main.py 282): INFO Train: [270/300][50/78]	eta 0:00:54 lr 0.150050	time 1.3935 (1.9567)	loss 2.2906 (2.2524)	grad_norm 0.6031 (0.6053)	mem 39782MB
[2023-07-07 17:45:16 RepVGG-A0] (main.py 282): INFO Train: [270/300][60/78]	eta 0:00:33 lr 0.148752	time 1.2195 (1.8780)	loss 2.2627 (2.2522)	grad_norm 0.6040 (0.6058)	mem 39782MB
[2023-07-07 17:45:31 RepVGG-A0] (main.py 282): INFO Train: [270/300][70/78]	eta 0:00:14 lr 0.147460	time 1.2458 (1.8261)	loss 2.2892 (2.2562)	grad_norm 0.6121 (0.6065)	mem 39782MB
[2023-07-07 17:45:43 RepVGG-A0] (main.py 291): INFO EPOCH 270 training takes 0:02:21
[2023-07-07 17:46:02 RepVGG-A0] (main.py 282): INFO Train: [271/300][0/78]	eta 0:25:38 lr 0.146431	time 19.7291 (19.7291)	loss 2.2451 (2.2451)	grad_norm 0.6115 (0.6115)	mem 39782MB
[2023-07-07 17:46:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][10/78]	eta 0:03:49 lr 0.145149	time 1.1713 (3.3767)	loss 2.2271 (2.2378)	grad_norm 0.5993 (0.6003)	mem 39782MB
[2023-07-07 17:46:33 RepVGG-A0] (main.py 282): INFO Train: [271/300][20/78]	eta 0:02:20 lr 0.143872	time 1.2185 (2.4189)	loss 2.2376 (2.2487)	grad_norm 0.5962 (0.6028)	mem 39782MB
[2023-07-07 17:46:48 RepVGG-A0] (main.py 282): INFO Train: [271/300][30/78]	eta 0:01:40 lr 0.142602	time 1.1914 (2.1038)	loss 2.2808 (2.2484)	grad_norm 0.6090 (0.6048)	mem 39782MB
[2023-07-07 17:47:05 RepVGG-A0] (main.py 282): INFO Train: [271/300][40/78]	eta 0:01:16 lr 0.141336	time 3.3187 (2.0121)	loss 2.2186 (2.2528)	grad_norm 0.6036 (0.6051)	mem 39782MB
[2023-07-07 17:47:20 RepVGG-A0] (main.py 282): INFO Train: [271/300][50/78]	eta 0:00:53 lr 0.140076	time 1.1808 (1.9118)	loss 2.2731 (2.2531)	grad_norm 0.6162 (0.6058)	mem 39782MB
[2023-07-07 17:47:36 RepVGG-A0] (main.py 282): INFO Train: [271/300][60/78]	eta 0:00:33 lr 0.138822	time 1.2508 (1.8526)	loss 2.3117 (2.2552)	grad_norm 0.6106 (0.6069)	mem 39782MB
[2023-07-07 17:47:50 RepVGG-A0] (main.py 282): INFO Train: [271/300][70/78]	eta 0:00:14 lr 0.137573	time 1.4821 (1.8008)	loss 2.2750 (2.2571)	grad_norm 0.6113 (0.6073)	mem 39782MB
[2023-07-07 17:48:02 RepVGG-A0] (main.py 291): INFO EPOCH 271 training takes 0:02:19
[2023-07-07 17:48:24 RepVGG-A0] (main.py 282): INFO Train: [272/300][0/78]	eta 0:28:41 lr 0.136578	time 22.0758 (22.0758)	loss 2.1948 (2.1948)	grad_norm 0.6081 (0.6081)	mem 39782MB
[2023-07-07 17:48:39 RepVGG-A0] (main.py 282): INFO Train: [272/300][10/78]	eta 0:03:46 lr 0.135339	time 1.1717 (3.3348)	loss 2.2126 (2.2351)	grad_norm 0.6057 (0.6103)	mem 39782MB
[2023-07-07 17:48:53 RepVGG-A0] (main.py 282): INFO Train: [272/300][20/78]	eta 0:02:21 lr 0.134105	time 1.2383 (2.4440)	loss 2.2412 (2.2304)	grad_norm 0.6070 (0.6112)	mem 39782MB
[2023-07-07 17:49:08 RepVGG-A0] (main.py 282): INFO Train: [272/300][30/78]	eta 0:01:41 lr 0.132877	time 1.2777 (2.1210)	loss 2.1952 (2.2324)	grad_norm 0.6172 (0.6116)	mem 39782MB
[2023-07-07 17:49:25 RepVGG-A0] (main.py 282): INFO Train: [272/300][40/78]	eta 0:01:17 lr 0.131655	time 3.9511 (2.0298)	loss 2.2492 (2.2379)	grad_norm 0.6209 (0.6121)	mem 39782MB
[2023-07-07 17:49:41 RepVGG-A0] (main.py 282): INFO Train: [272/300][50/78]	eta 0:00:54 lr 0.130438	time 1.1846 (1.9342)	loss 2.2168 (2.2405)	grad_norm 0.6034 (0.6133)	mem 39782MB
[2023-07-07 17:49:56 RepVGG-A0] (main.py 282): INFO Train: [272/300][60/78]	eta 0:00:33 lr 0.129227	time 1.2756 (1.8690)	loss 2.2764 (2.2414)	grad_norm 0.6289 (0.6136)	mem 39782MB
[2023-07-07 17:50:12 RepVGG-A0] (main.py 282): INFO Train: [272/300][70/78]	eta 0:00:14 lr 0.128021	time 1.2814 (1.8242)	loss 2.2995 (2.2442)	grad_norm 0.6133 (0.6140)	mem 39782MB
[2023-07-07 17:50:24 RepVGG-A0] (main.py 291): INFO EPOCH 272 training takes 0:02:21
[2023-07-07 17:50:45 RepVGG-A0] (main.py 282): INFO Train: [273/300][0/78]	eta 0:27:04 lr 0.127060	time 20.8219 (20.8219)	loss 2.2162 (2.2162)	grad_norm 0.6025 (0.6025)	mem 39782MB
[2023-07-07 17:51:01 RepVGG-A0] (main.py 282): INFO Train: [273/300][10/78]	eta 0:03:51 lr 0.125864	time 1.1731 (3.4018)	loss 2.2005 (2.2208)	grad_norm 0.6136 (0.6100)	mem 39782MB
[2023-07-07 17:51:17 RepVGG-A0] (main.py 282): INFO Train: [273/300][20/78]	eta 0:02:27 lr 0.124674	time 1.2904 (2.5389)	loss 2.2490 (2.2255)	grad_norm 0.6155 (0.6130)	mem 39782MB
[2023-07-07 17:51:32 RepVGG-A0] (main.py 282): INFO Train: [273/300][30/78]	eta 0:01:46 lr 0.123489	time 1.4664 (2.2136)	loss 2.2565 (2.2273)	grad_norm 0.6181 (0.6123)	mem 39782MB
[2023-07-07 17:51:50 RepVGG-A0] (main.py 282): INFO Train: [273/300][40/78]	eta 0:01:19 lr 0.122310	time 2.2953 (2.1026)	loss 2.2039 (2.2284)	grad_norm 0.6127 (0.6129)	mem 39782MB
[2023-07-07 17:52:05 RepVGG-A0] (main.py 282): INFO Train: [273/300][50/78]	eta 0:00:55 lr 0.121136	time 1.1920 (1.9923)	loss 2.2073 (2.2308)	grad_norm 0.6200 (0.6141)	mem 39782MB
[2023-07-07 17:52:20 RepVGG-A0] (main.py 282): INFO Train: [273/300][60/78]	eta 0:00:34 lr 0.119968	time 1.1743 (1.9059)	loss 2.2504 (2.2342)	grad_norm 0.6246 (0.6147)	mem 39782MB
[2023-07-07 17:52:35 RepVGG-A0] (main.py 282): INFO Train: [273/300][70/78]	eta 0:00:14 lr 0.118806	time 1.3119 (1.8490)	loss 2.2356 (2.2391)	grad_norm 0.6233 (0.6163)	mem 39782MB
[2023-07-07 17:52:46 RepVGG-A0] (main.py 291): INFO EPOCH 273 training takes 0:02:22
[2023-07-07 17:53:07 RepVGG-A0] (main.py 282): INFO Train: [274/300][0/78]	eta 0:26:31 lr 0.117880	time 20.4063 (20.4063)	loss 2.1965 (2.1965)	grad_norm 0.6061 (0.6061)	mem 39782MB
[2023-07-07 17:53:22 RepVGG-A0] (main.py 282): INFO Train: [274/300][10/78]	eta 0:03:39 lr 0.116727	time 1.1911 (3.2264)	loss 2.2116 (2.2284)	grad_norm 0.6169 (0.6088)	mem 39782MB
[2023-07-07 17:53:37 RepVGG-A0] (main.py 282): INFO Train: [274/300][20/78]	eta 0:02:20 lr 0.115580	time 1.1895 (2.4169)	loss 2.2748 (2.2311)	grad_norm 0.6198 (0.6120)	mem 39782MB
[2023-07-07 17:53:52 RepVGG-A0] (main.py 282): INFO Train: [274/300][30/78]	eta 0:01:41 lr 0.114439	time 1.2633 (2.1213)	loss 2.2126 (2.2212)	grad_norm 0.6142 (0.6141)	mem 39782MB
[2023-07-07 17:54:11 RepVGG-A0] (main.py 282): INFO Train: [274/300][40/78]	eta 0:01:18 lr 0.113303	time 3.8412 (2.0563)	loss 2.2297 (2.2195)	grad_norm 0.6123 (0.6146)	mem 39782MB
[2023-07-07 17:54:26 RepVGG-A0] (main.py 282): INFO Train: [274/300][50/78]	eta 0:00:54 lr 0.112173	time 1.2034 (1.9452)	loss 2.2042 (2.2200)	grad_norm 0.6258 (0.6161)	mem 39782MB
[2023-07-07 17:54:40 RepVGG-A0] (main.py 282): INFO Train: [274/300][60/78]	eta 0:00:33 lr 0.111048	time 1.2000 (1.8659)	loss 2.1838 (2.2234)	grad_norm 0.6216 (0.6162)	mem 39782MB
[2023-07-07 17:54:55 RepVGG-A0] (main.py 282): INFO Train: [274/300][70/78]	eta 0:00:14 lr 0.109929	time 1.1730 (1.8105)	loss 2.1538 (2.2225)	grad_norm 0.6171 (0.6171)	mem 39782MB
[2023-07-07 17:55:07 RepVGG-A0] (main.py 291): INFO EPOCH 274 training takes 0:02:20
[2023-07-07 17:55:28 RepVGG-A0] (main.py 282): INFO Train: [275/300][0/78]	eta 0:26:59 lr 0.109037	time 20.7566 (20.7566)	loss 2.1986 (2.1986)	grad_norm 0.6124 (0.6124)	mem 39782MB
[2023-07-07 17:55:43 RepVGG-A0] (main.py 282): INFO Train: [275/300][10/78]	eta 0:03:40 lr 0.107928	time 1.1712 (3.2447)	loss 2.2282 (2.2243)	grad_norm 0.6142 (0.6143)	mem 39782MB
[2023-07-07 17:55:57 RepVGG-A0] (main.py 282): INFO Train: [275/300][20/78]	eta 0:02:18 lr 0.106825	time 1.1723 (2.3939)	loss 2.2031 (2.2246)	grad_norm 0.6073 (0.6151)	mem 39782MB
[2023-07-07 17:56:13 RepVGG-A0] (main.py 282): INFO Train: [275/300][30/78]	eta 0:01:41 lr 0.105727	time 1.2462 (2.1191)	loss 2.2029 (2.2165)	grad_norm 0.6171 (0.6158)	mem 39782MB
[2023-07-07 17:56:30 RepVGG-A0] (main.py 282): INFO Train: [275/300][40/78]	eta 0:01:17 lr 0.104634	time 3.6743 (2.0280)	loss 2.2415 (2.2170)	grad_norm 0.6200 (0.6171)	mem 39782MB
[2023-07-07 17:56:45 RepVGG-A0] (main.py 282): INFO Train: [275/300][50/78]	eta 0:00:53 lr 0.103547	time 1.1720 (1.9179)	loss 2.2074 (2.2208)	grad_norm 0.6284 (0.6182)	mem 39782MB
[2023-07-07 17:57:00 RepVGG-A0] (main.py 282): INFO Train: [275/300][60/78]	eta 0:00:33 lr 0.102466	time 1.3301 (1.8545)	loss 2.2620 (2.2213)	grad_norm 0.6174 (0.6187)	mem 39782MB
[2023-07-07 17:57:15 RepVGG-A0] (main.py 282): INFO Train: [275/300][70/78]	eta 0:00:14 lr 0.101390	time 1.1696 (1.8038)	loss 2.2274 (2.2226)	grad_norm 0.6305 (0.6191)	mem 39782MB
[2023-07-07 17:57:26 RepVGG-A0] (main.py 291): INFO EPOCH 275 training takes 0:02:19
[2023-07-07 17:57:49 RepVGG-A0] (main.py 282): INFO Train: [276/300][0/78]	eta 0:29:15 lr 0.100534	time 22.5125 (22.5125)	loss 2.1612 (2.1612)	grad_norm 0.6158 (0.6158)	mem 39782MB
[2023-07-07 17:58:03 RepVGG-A0] (main.py 282): INFO Train: [276/300][10/78]	eta 0:03:42 lr 0.099468	time 1.1922 (3.2780)	loss 2.1792 (2.1971)	grad_norm 0.6254 (0.6183)	mem 39782MB
[2023-07-07 17:58:17 RepVGG-A0] (main.py 282): INFO Train: [276/300][20/78]	eta 0:02:18 lr 0.098408	time 1.1726 (2.3906)	loss 2.2469 (2.2184)	grad_norm 0.6192 (0.6210)	mem 39782MB
[2023-07-07 17:58:33 RepVGG-A0] (main.py 282): INFO Train: [276/300][30/78]	eta 0:01:43 lr 0.097354	time 1.2741 (2.1500)	loss 2.2550 (2.2221)	grad_norm 0.6238 (0.6215)	mem 39782MB
[2023-07-07 17:58:50 RepVGG-A0] (main.py 282): INFO Train: [276/300][40/78]	eta 0:01:17 lr 0.096305	time 3.4807 (2.0484)	loss 2.2579 (2.2201)	grad_norm 0.6140 (0.6213)	mem 39782MB
[2023-07-07 17:59:06 RepVGG-A0] (main.py 282): INFO Train: [276/300][50/78]	eta 0:00:54 lr 0.095262	time 1.1757 (1.9427)	loss 2.2174 (2.2171)	grad_norm 0.6189 (0.6214)	mem 39782MB
[2023-07-07 17:59:22 RepVGG-A0] (main.py 282): INFO Train: [276/300][60/78]	eta 0:00:34 lr 0.094224	time 1.3339 (1.8928)	loss 2.1613 (2.2179)	grad_norm 0.6191 (0.6219)	mem 39782MB
[2023-07-07 17:59:37 RepVGG-A0] (main.py 282): INFO Train: [276/300][70/78]	eta 0:00:14 lr 0.093192	time 1.2089 (1.8324)	loss 2.2428 (2.2202)	grad_norm 0.6211 (0.6219)	mem 39782MB
[2023-07-07 17:59:49 RepVGG-A0] (main.py 291): INFO EPOCH 276 training takes 0:02:22
[2023-07-07 18:00:11 RepVGG-A0] (main.py 282): INFO Train: [277/300][0/78]	eta 0:28:02 lr 0.092370	time 21.5708 (21.5708)	loss 2.1849 (2.1849)	grad_norm 0.6191 (0.6191)	mem 39782MB
[2023-07-07 18:00:25 RepVGG-A0] (main.py 282): INFO Train: [277/300][10/78]	eta 0:03:44 lr 0.091348	time 1.1734 (3.2981)	loss 2.2038 (2.2063)	grad_norm 0.6192 (0.6209)	mem 39782MB
[2023-07-07 18:00:41 RepVGG-A0] (main.py 282): INFO Train: [277/300][20/78]	eta 0:02:23 lr 0.090332	time 1.2147 (2.4717)	loss 2.2714 (2.2119)	grad_norm 0.6143 (0.6234)	mem 39782MB
[2023-07-07 18:00:56 RepVGG-A0] (main.py 282): INFO Train: [277/300][30/78]	eta 0:01:43 lr 0.089321	time 1.3787 (2.1528)	loss 2.1715 (2.2136)	grad_norm 0.6254 (0.6242)	mem 39782MB
[2023-07-07 18:01:13 RepVGG-A0] (main.py 282): INFO Train: [277/300][40/78]	eta 0:01:18 lr 0.088316	time 2.0358 (2.0541)	loss 2.2415 (2.2139)	grad_norm 0.6309 (0.6240)	mem 39782MB
[2023-07-07 18:01:29 RepVGG-A0] (main.py 282): INFO Train: [277/300][50/78]	eta 0:00:54 lr 0.087316	time 1.1714 (1.9601)	loss 2.2244 (2.2137)	grad_norm 0.6257 (0.6247)	mem 39782MB
[2023-07-07 18:01:44 RepVGG-A0] (main.py 282): INFO Train: [277/300][60/78]	eta 0:00:33 lr 0.086322	time 1.2035 (1.8872)	loss 2.2319 (2.2150)	grad_norm 0.6303 (0.6249)	mem 39782MB
[2023-07-07 18:01:59 RepVGG-A0] (main.py 282): INFO Train: [277/300][70/78]	eta 0:00:14 lr 0.085334	time 1.1739 (1.8298)	loss 2.2087 (2.2160)	grad_norm 0.6297 (0.6249)	mem 39782MB
[2023-07-07 18:02:11 RepVGG-A0] (main.py 291): INFO EPOCH 277 training takes 0:02:21
[2023-07-07 18:02:31 RepVGG-A0] (main.py 282): INFO Train: [278/300][0/78]	eta 0:25:59 lr 0.084548	time 19.9892 (19.9892)	loss 2.2280 (2.2280)	grad_norm 0.6245 (0.6245)	mem 39782MB
[2023-07-07 18:02:47 RepVGG-A0] (main.py 282): INFO Train: [278/300][10/78]	eta 0:03:41 lr 0.083569	time 1.1727 (3.2636)	loss 2.2559 (2.2092)	grad_norm 0.6288 (0.6279)	mem 39782MB
[2023-07-07 18:03:01 RepVGG-A0] (main.py 282): INFO Train: [278/300][20/78]	eta 0:02:18 lr 0.082597	time 1.2340 (2.3918)	loss 2.2552 (2.2037)	grad_norm 0.6294 (0.6258)	mem 39782MB
[2023-07-07 18:03:17 RepVGG-A0] (main.py 282): INFO Train: [278/300][30/78]	eta 0:01:42 lr 0.081630	time 1.1305 (2.1373)	loss 2.2213 (2.2092)	grad_norm 0.6267 (0.6270)	mem 39782MB
[2023-07-07 18:03:34 RepVGG-A0] (main.py 282): INFO Train: [278/300][40/78]	eta 0:01:16 lr 0.080668	time 3.3786 (2.0245)	loss 2.2096 (2.2101)	grad_norm 0.6280 (0.6274)	mem 39782MB
[2023-07-07 18:03:49 RepVGG-A0] (main.py 282): INFO Train: [278/300][50/78]	eta 0:00:53 lr 0.079713	time 1.1740 (1.9218)	loss 2.1845 (2.2111)	grad_norm 0.6328 (0.6273)	mem 39782MB
[2023-07-07 18:04:05 RepVGG-A0] (main.py 282): INFO Train: [278/300][60/78]	eta 0:00:33 lr 0.078762	time 1.2631 (1.8769)	loss 2.2777 (2.2113)	grad_norm 0.6323 (0.6273)	mem 39782MB
[2023-07-07 18:04:20 RepVGG-A0] (main.py 282): INFO Train: [278/300][70/78]	eta 0:00:14 lr 0.077818	time 1.2695 (1.8198)	loss 2.2700 (2.2126)	grad_norm 0.6310 (0.6271)	mem 39782MB
[2023-07-07 18:04:32 RepVGG-A0] (main.py 291): INFO EPOCH 278 training takes 0:02:21
[2023-07-07 18:04:54 RepVGG-A0] (main.py 282): INFO Train: [279/300][0/78]	eta 0:29:00 lr 0.077066	time 22.3169 (22.3169)	loss 2.2117 (2.2117)	grad_norm 0.6333 (0.6333)	mem 39782MB
[2023-07-07 18:05:08 RepVGG-A0] (main.py 282): INFO Train: [279/300][10/78]	eta 0:03:44 lr 0.076132	time 1.1812 (3.3042)	loss 2.1740 (2.2044)	grad_norm 0.6290 (0.6256)	mem 39782MB
[2023-07-07 18:05:22 RepVGG-A0] (main.py 282): INFO Train: [279/300][20/78]	eta 0:02:18 lr 0.075203	time 1.1710 (2.3926)	loss 2.2326 (2.2085)	grad_norm 0.6231 (0.6288)	mem 39782MB
[2023-07-07 18:05:38 RepVGG-A0] (main.py 282): INFO Train: [279/300][30/78]	eta 0:01:41 lr 0.074280	time 1.2650 (2.1208)	loss 2.2222 (2.2083)	grad_norm 0.6293 (0.6302)	mem 39782MB
[2023-07-07 18:05:56 RepVGG-A0] (main.py 282): INFO Train: [279/300][40/78]	eta 0:01:17 lr 0.073363	time 3.4916 (2.0411)	loss 2.1830 (2.2056)	grad_norm 0.6336 (0.6288)	mem 39782MB
[2023-07-07 18:06:11 RepVGG-A0] (main.py 282): INFO Train: [279/300][50/78]	eta 0:00:54 lr 0.072451	time 1.1741 (1.9327)	loss 2.2461 (2.2076)	grad_norm 0.6366 (0.6295)	mem 39782MB
[2023-07-07 18:06:26 RepVGG-A0] (main.py 282): INFO Train: [279/300][60/78]	eta 0:00:33 lr 0.071545	time 1.1802 (1.8612)	loss 2.2178 (2.2086)	grad_norm 0.6231 (0.6301)	mem 39782MB
[2023-07-07 18:06:40 RepVGG-A0] (main.py 282): INFO Train: [279/300][70/78]	eta 0:00:14 lr 0.070644	time 1.2225 (1.8098)	loss 2.2124 (2.2081)	grad_norm 0.6338 (0.6305)	mem 39782MB
[2023-07-07 18:06:52 RepVGG-A0] (main.py 291): INFO EPOCH 279 training takes 0:02:20
[2023-07-07 18:07:14 RepVGG-A0] (main.py 282): INFO Train: [280/300][0/78]	eta 0:28:29 lr 0.069928	time 21.9143 (21.9143)	loss 2.1965 (2.1965)	grad_norm 0.6307 (0.6307)	mem 39782MB
[2023-07-07 18:07:29 RepVGG-A0] (main.py 282): INFO Train: [280/300][10/78]	eta 0:03:46 lr 0.069037	time 1.1901 (3.3277)	loss 2.2120 (2.1942)	grad_norm 0.6386 (0.6312)	mem 39782MB
[2023-07-07 18:07:44 RepVGG-A0] (main.py 282): INFO Train: [280/300][20/78]	eta 0:02:22 lr 0.068153	time 1.3236 (2.4495)	loss 2.1592 (2.1895)	grad_norm 0.6311 (0.6313)	mem 39782MB
[2023-07-07 18:07:58 RepVGG-A0] (main.py 282): INFO Train: [280/300][30/78]	eta 0:01:41 lr 0.067273	time 1.1897 (2.1198)	loss 2.2213 (2.1886)	grad_norm 0.6304 (0.6313)	mem 39782MB
[2023-07-07 18:08:17 RepVGG-A0] (main.py 282): INFO Train: [280/300][40/78]	eta 0:01:19 lr 0.066400	time 4.6829 (2.0801)	loss 2.2052 (2.1908)	grad_norm 0.6321 (0.6312)	mem 39782MB
[2023-07-07 18:08:32 RepVGG-A0] (main.py 282): INFO Train: [280/300][50/78]	eta 0:00:54 lr 0.065532	time 1.1906 (1.9611)	loss 2.2006 (2.1942)	grad_norm 0.6427 (0.6314)	mem 39782MB
[2023-07-07 18:08:47 RepVGG-A0] (main.py 282): INFO Train: [280/300][60/78]	eta 0:00:33 lr 0.064670	time 1.1755 (1.8865)	loss 2.1400 (2.1939)	grad_norm 0.6401 (0.6316)	mem 39782MB
[2023-07-07 18:09:03 RepVGG-A0] (main.py 282): INFO Train: [280/300][70/78]	eta 0:00:14 lr 0.063813	time 1.1815 (1.8360)	loss 2.2015 (2.1957)	grad_norm 0.6405 (0.6322)	mem 39782MB
[2023-07-07 18:09:14 RepVGG-A0] (main.py 291): INFO EPOCH 280 training takes 0:02:22
[2023-07-07 18:09:32 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.601 (17.601)	Loss 1.3635 (1.3635)	Acc@1 69.037 (69.037)	Acc@5 88.812 (88.812)	Mem 39782MB
[2023-07-07 18:09:33 RepVGG-A0] (main.py 342): INFO  * Acc@1 69.638 Acc@5 88.854
[2023-07-07 18:09:33 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 280: 69.638%
[2023-07-07 18:09:33 RepVGG-A0] (main.py 172): INFO Max accuracy: 69.64%
[2023-07-07 18:09:52 RepVGG-A0] (main.py 282): INFO Train: [281/300][0/78]	eta 0:24:46 lr 0.063132	time 19.0598 (19.0598)	loss 2.1515 (2.1515)	grad_norm 0.6216 (0.6216)	mem 39782MB
[2023-07-07 18:10:08 RepVGG-A0] (main.py 282): INFO Train: [281/300][10/78]	eta 0:03:36 lr 0.062286	time 1.1698 (3.1902)	loss 2.1930 (2.1883)	grad_norm 0.6274 (0.6287)	mem 39782MB
[2023-07-07 18:10:24 RepVGG-A0] (main.py 282): INFO Train: [281/300][20/78]	eta 0:02:20 lr 0.061445	time 1.1929 (2.4237)	loss 2.1661 (2.1826)	grad_norm 0.6191 (0.6288)	mem 39782MB
[2023-07-07 18:10:39 RepVGG-A0] (main.py 282): INFO Train: [281/300][30/78]	eta 0:01:42 lr 0.060610	time 1.3019 (2.1314)	loss 2.2020 (2.1876)	grad_norm 0.6321 (0.6304)	mem 39782MB
[2023-07-07 18:10:58 RepVGG-A0] (main.py 282): INFO Train: [281/300][40/78]	eta 0:01:18 lr 0.059781	time 2.9416 (2.0581)	loss 2.1520 (2.1883)	grad_norm 0.6289 (0.6306)	mem 39782MB
[2023-07-07 18:11:12 RepVGG-A0] (main.py 282): INFO Train: [281/300][50/78]	eta 0:00:54 lr 0.058957	time 1.1719 (1.9383)	loss 2.2050 (2.1892)	grad_norm 0.6314 (0.6313)	mem 39782MB
[2023-07-07 18:11:28 RepVGG-A0] (main.py 282): INFO Train: [281/300][60/78]	eta 0:00:33 lr 0.058139	time 1.1791 (1.8744)	loss 2.1779 (2.1890)	grad_norm 0.6353 (0.6314)	mem 39782MB
[2023-07-07 18:11:43 RepVGG-A0] (main.py 282): INFO Train: [281/300][70/78]	eta 0:00:14 lr 0.057327	time 1.4260 (1.8332)	loss 2.1726 (2.1901)	grad_norm 0.6258 (0.6322)	mem 39782MB
[2023-07-07 18:11:54 RepVGG-A0] (main.py 291): INFO EPOCH 281 training takes 0:02:21
[2023-07-07 18:12:15 RepVGG-A0] (main.py 282): INFO Train: [282/300][0/78]	eta 0:27:30 lr 0.056681	time 21.1613 (21.1613)	loss 2.2349 (2.2349)	grad_norm 0.6240 (0.6240)	mem 39782MB
[2023-07-07 18:12:32 RepVGG-A0] (main.py 282): INFO Train: [282/300][10/78]	eta 0:03:51 lr 0.055879	time 1.1711 (3.4022)	loss 2.1768 (2.1767)	grad_norm 0.6307 (0.6304)	mem 39782MB
[2023-07-07 18:12:46 RepVGG-A0] (main.py 282): INFO Train: [282/300][20/78]	eta 0:02:24 lr 0.055082	time 1.3578 (2.4839)	loss 2.1475 (2.1747)	grad_norm 0.6330 (0.6300)	mem 39782MB
[2023-07-07 18:13:02 RepVGG-A0] (main.py 282): INFO Train: [282/300][30/78]	eta 0:01:44 lr 0.054291	time 1.4339 (2.1697)	loss 2.1935 (2.1758)	grad_norm 0.6427 (0.6300)	mem 39782MB
[2023-07-07 18:13:20 RepVGG-A0] (main.py 282): INFO Train: [282/300][40/78]	eta 0:01:19 lr 0.053506	time 4.4607 (2.0928)	loss 2.1755 (2.1800)	grad_norm 0.6304 (0.6312)	mem 39782MB
[2023-07-07 18:13:34 RepVGG-A0] (main.py 282): INFO Train: [282/300][50/78]	eta 0:00:54 lr 0.052727	time 1.1729 (1.9638)	loss 2.1554 (2.1792)	grad_norm 0.6291 (0.6317)	mem 39782MB
[2023-07-07 18:13:50 RepVGG-A0] (main.py 282): INFO Train: [282/300][60/78]	eta 0:00:34 lr 0.051953	time 1.1854 (1.8941)	loss 2.1466 (2.1794)	grad_norm 0.6489 (0.6326)	mem 39782MB
[2023-07-07 18:14:05 RepVGG-A0] (main.py 282): INFO Train: [282/300][70/78]	eta 0:00:14 lr 0.051185	time 1.3538 (1.8412)	loss 2.1659 (2.1810)	grad_norm 0.6391 (0.6338)	mem 39782MB
[2023-07-07 18:14:16 RepVGG-A0] (main.py 291): INFO EPOCH 282 training takes 0:02:21
[2023-07-07 18:14:35 RepVGG-A0] (main.py 282): INFO Train: [283/300][0/78]	eta 0:23:55 lr 0.050574	time 18.3982 (18.3982)	loss 2.1964 (2.1964)	grad_norm 0.6352 (0.6352)	mem 39782MB
[2023-07-07 18:14:52 RepVGG-A0] (main.py 282): INFO Train: [283/300][10/78]	eta 0:03:42 lr 0.049816	time 1.1697 (3.2756)	loss 2.1770 (2.1691)	grad_norm 0.6357 (0.6315)	mem 39782MB
[2023-07-07 18:15:07 RepVGG-A0] (main.py 282): INFO Train: [283/300][20/78]	eta 0:02:19 lr 0.049064	time 1.1758 (2.4132)	loss 2.2739 (2.1751)	grad_norm 0.6375 (0.6325)	mem 39782MB
[2023-07-07 18:15:21 RepVGG-A0] (main.py 282): INFO Train: [283/300][30/78]	eta 0:01:40 lr 0.048317	time 1.3620 (2.1018)	loss 2.2160 (2.1776)	grad_norm 0.6477 (0.6340)	mem 39782MB
[2023-07-07 18:15:40 RepVGG-A0] (main.py 282): INFO Train: [283/300][40/78]	eta 0:01:17 lr 0.047576	time 4.7295 (2.0432)	loss 2.1119 (2.1734)	grad_norm 0.6324 (0.6340)	mem 39782MB
[2023-07-07 18:15:54 RepVGG-A0] (main.py 282): INFO Train: [283/300][50/78]	eta 0:00:53 lr 0.046841	time 1.1715 (1.9231)	loss 2.1672 (2.1730)	grad_norm 0.6307 (0.6344)	mem 39782MB
[2023-07-07 18:16:09 RepVGG-A0] (main.py 282): INFO Train: [283/300][60/78]	eta 0:00:33 lr 0.046112	time 1.1725 (1.8534)	loss 2.2039 (2.1780)	grad_norm 0.6432 (0.6346)	mem 39782MB
[2023-07-07 18:16:25 RepVGG-A0] (main.py 282): INFO Train: [283/300][70/78]	eta 0:00:14 lr 0.045388	time 1.3354 (1.8150)	loss 2.1915 (2.1792)	grad_norm 0.6443 (0.6353)	mem 39782MB
[2023-07-07 18:16:37 RepVGG-A0] (main.py 291): INFO EPOCH 283 training takes 0:02:20
[2023-07-07 18:16:59 RepVGG-A0] (main.py 282): INFO Train: [284/300][0/78]	eta 0:28:38 lr 0.044813	time 22.0360 (22.0360)	loss 2.1627 (2.1627)	grad_norm 0.6296 (0.6296)	mem 39782MB
[2023-07-07 18:17:13 RepVGG-A0] (main.py 282): INFO Train: [284/300][10/78]	eta 0:03:43 lr 0.044099	time 1.1943 (3.2864)	loss 2.1769 (2.1678)	grad_norm 0.6321 (0.6322)	mem 39782MB
[2023-07-07 18:17:28 RepVGG-A0] (main.py 282): INFO Train: [284/300][20/78]	eta 0:02:20 lr 0.043391	time 1.1793 (2.4297)	loss 2.1735 (2.1715)	grad_norm 0.6344 (0.6327)	mem 39782MB
[2023-07-07 18:17:42 RepVGG-A0] (main.py 282): INFO Train: [284/300][30/78]	eta 0:01:41 lr 0.042689	time 1.2104 (2.1147)	loss 2.1951 (2.1747)	grad_norm 0.6331 (0.6334)	mem 39782MB
[2023-07-07 18:18:01 RepVGG-A0] (main.py 282): INFO Train: [284/300][40/78]	eta 0:01:18 lr 0.041992	time 4.5395 (2.0541)	loss 2.1480 (2.1749)	grad_norm 0.6395 (0.6343)	mem 39782MB
[2023-07-07 18:18:16 RepVGG-A0] (main.py 282): INFO Train: [284/300][50/78]	eta 0:00:54 lr 0.041301	time 1.1738 (1.9588)	loss 2.1936 (2.1739)	grad_norm 0.6439 (0.6352)	mem 39782MB
[2023-07-07 18:18:31 RepVGG-A0] (main.py 282): INFO Train: [284/300][60/78]	eta 0:00:33 lr 0.040616	time 1.1969 (1.8696)	loss 2.2148 (2.1734)	grad_norm 0.6367 (0.6358)	mem 39782MB
[2023-07-07 18:18:45 RepVGG-A0] (main.py 282): INFO Train: [284/300][70/78]	eta 0:00:14 lr 0.039937	time 1.2383 (1.8104)	loss 2.1814 (2.1755)	grad_norm 0.6448 (0.6363)	mem 39782MB
[2023-07-07 18:18:57 RepVGG-A0] (main.py 291): INFO EPOCH 284 training takes 0:02:20
[2023-07-07 18:19:19 RepVGG-A0] (main.py 282): INFO Train: [285/300][0/78]	eta 0:28:20 lr 0.039397	time 21.8000 (21.8000)	loss 2.1237 (2.1237)	grad_norm 0.6319 (0.6319)	mem 39782MB
[2023-07-07 18:19:33 RepVGG-A0] (main.py 282): INFO Train: [285/300][10/78]	eta 0:03:41 lr 0.038728	time 1.1721 (3.2561)	loss 2.1861 (2.1699)	grad_norm 0.6371 (0.6377)	mem 39782MB
[2023-07-07 18:19:48 RepVGG-A0] (main.py 282): INFO Train: [285/300][20/78]	eta 0:02:20 lr 0.038065	time 1.1738 (2.4215)	loss 2.1741 (2.1710)	grad_norm 0.6384 (0.6370)	mem 39782MB
[2023-07-07 18:20:03 RepVGG-A0] (main.py 282): INFO Train: [285/300][30/78]	eta 0:01:42 lr 0.037407	time 1.1832 (2.1301)	loss 2.1786 (2.1774)	grad_norm 0.6332 (0.6374)	mem 39782MB
[2023-07-07 18:20:22 RepVGG-A0] (main.py 282): INFO Train: [285/300][40/78]	eta 0:01:18 lr 0.036755	time 2.9925 (2.0588)	loss 2.2037 (2.1754)	grad_norm 0.6368 (0.6371)	mem 39782MB
[2023-07-07 18:20:37 RepVGG-A0] (main.py 282): INFO Train: [285/300][50/78]	eta 0:00:54 lr 0.036108	time 1.2449 (1.9619)	loss 2.2130 (2.1739)	grad_norm 0.6503 (0.6375)	mem 39782MB
[2023-07-07 18:20:52 RepVGG-A0] (main.py 282): INFO Train: [285/300][60/78]	eta 0:00:33 lr 0.035467	time 1.4890 (1.8842)	loss 2.2049 (2.1703)	grad_norm 0.6346 (0.6379)	mem 39782MB
[2023-07-07 18:21:07 RepVGG-A0] (main.py 282): INFO Train: [285/300][70/78]	eta 0:00:14 lr 0.034832	time 1.2038 (1.8330)	loss 2.1629 (2.1705)	grad_norm 0.6494 (0.6384)	mem 39782MB
[2023-07-07 18:21:19 RepVGG-A0] (main.py 291): INFO EPOCH 285 training takes 0:02:21
[2023-07-07 18:21:40 RepVGG-A0] (main.py 282): INFO Train: [286/300][0/78]	eta 0:28:07 lr 0.034329	time 21.6294 (21.6294)	loss 2.1542 (2.1542)	grad_norm 0.6346 (0.6346)	mem 39782MB
[2023-07-07 18:21:55 RepVGG-A0] (main.py 282): INFO Train: [286/300][10/78]	eta 0:03:45 lr 0.033704	time 1.1734 (3.3225)	loss 2.2069 (2.1588)	grad_norm 0.6388 (0.6375)	mem 39782MB
[2023-07-07 18:22:11 RepVGG-A0] (main.py 282): INFO Train: [286/300][20/78]	eta 0:02:23 lr 0.033085	time 1.2459 (2.4764)	loss 2.1240 (2.1587)	grad_norm 0.6456 (0.6377)	mem 39782MB
[2023-07-07 18:22:26 RepVGG-A0] (main.py 282): INFO Train: [286/300][30/78]	eta 0:01:44 lr 0.032471	time 1.1907 (2.1798)	loss 2.1693 (2.1619)	grad_norm 0.6315 (0.6382)	mem 39782MB
[2023-07-07 18:22:43 RepVGG-A0] (main.py 282): INFO Train: [286/300][40/78]	eta 0:01:18 lr 0.031864	time 3.2771 (2.0638)	loss 2.1452 (2.1658)	grad_norm 0.6351 (0.6383)	mem 39782MB
[2023-07-07 18:22:58 RepVGG-A0] (main.py 282): INFO Train: [286/300][50/78]	eta 0:00:54 lr 0.031262	time 1.1723 (1.9541)	loss 2.1948 (2.1648)	grad_norm 0.6456 (0.6389)	mem 39782MB
[2023-07-07 18:23:14 RepVGG-A0] (main.py 282): INFO Train: [286/300][60/78]	eta 0:00:33 lr 0.030666	time 1.1778 (1.8852)	loss 2.2003 (2.1653)	grad_norm 0.6461 (0.6393)	mem 39782MB
[2023-07-07 18:23:29 RepVGG-A0] (main.py 282): INFO Train: [286/300][70/78]	eta 0:00:14 lr 0.030075	time 1.3041 (1.8370)	loss 2.1864 (2.1658)	grad_norm 0.6385 (0.6391)	mem 39782MB
[2023-07-07 18:23:41 RepVGG-A0] (main.py 291): INFO EPOCH 286 training takes 0:02:22
[2023-07-07 18:24:02 RepVGG-A0] (main.py 282): INFO Train: [287/300][0/78]	eta 0:27:45 lr 0.029607	time 21.3504 (21.3504)	loss 2.1675 (2.1675)	grad_norm 0.6271 (0.6271)	mem 39782MB
[2023-07-07 18:24:16 RepVGG-A0] (main.py 282): INFO Train: [287/300][10/78]	eta 0:03:35 lr 0.029027	time 1.1715 (3.1707)	loss 2.1851 (2.1633)	grad_norm 0.6414 (0.6348)	mem 39782MB
[2023-07-07 18:24:30 RepVGG-A0] (main.py 282): INFO Train: [287/300][20/78]	eta 0:02:16 lr 0.028452	time 1.1735 (2.3549)	loss 2.1904 (2.1608)	grad_norm 0.6405 (0.6372)	mem 39782MB
[2023-07-07 18:24:47 RepVGG-A0] (main.py 282): INFO Train: [287/300][30/78]	eta 0:01:42 lr 0.027883	time 1.4376 (2.1374)	loss 2.1885 (2.1583)	grad_norm 0.6416 (0.6386)	mem 39782MB
[2023-07-07 18:25:04 RepVGG-A0] (main.py 282): INFO Train: [287/300][40/78]	eta 0:01:17 lr 0.027320	time 4.5392 (2.0331)	loss 2.1278 (2.1558)	grad_norm 0.6366 (0.6384)	mem 39782MB
[2023-07-07 18:25:19 RepVGG-A0] (main.py 282): INFO Train: [287/300][50/78]	eta 0:00:53 lr 0.026763	time 1.1719 (1.9245)	loss 2.2139 (2.1560)	grad_norm 0.6437 (0.6379)	mem 39782MB
[2023-07-07 18:25:34 RepVGG-A0] (main.py 282): INFO Train: [287/300][60/78]	eta 0:00:33 lr 0.026211	time 1.1798 (1.8552)	loss 2.1609 (2.1561)	grad_norm 0.6364 (0.6377)	mem 39782MB
[2023-07-07 18:25:49 RepVGG-A0] (main.py 282): INFO Train: [287/300][70/78]	eta 0:00:14 lr 0.025666	time 1.2318 (1.8101)	loss 2.2124 (2.1600)	grad_norm 0.6396 (0.6378)	mem 39782MB
[2023-07-07 18:26:02 RepVGG-A0] (main.py 291): INFO EPOCH 287 training takes 0:02:20
[2023-07-07 18:26:23 RepVGG-A0] (main.py 282): INFO Train: [288/300][0/78]	eta 0:28:07 lr 0.025233	time 21.6402 (21.6402)	loss 2.1786 (2.1786)	grad_norm 0.6299 (0.6299)	mem 39782MB
[2023-07-07 18:26:39 RepVGG-A0] (main.py 282): INFO Train: [288/300][10/78]	eta 0:03:49 lr 0.024697	time 1.1890 (3.3716)	loss 2.1770 (2.1559)	grad_norm 0.6283 (0.6344)	mem 39782MB
[2023-07-07 18:26:53 RepVGG-A0] (main.py 282): INFO Train: [288/300][20/78]	eta 0:02:22 lr 0.024167	time 1.1812 (2.4529)	loss 2.2322 (2.1598)	grad_norm 0.6313 (0.6354)	mem 39782MB
[2023-07-07 18:27:09 RepVGG-A0] (main.py 282): INFO Train: [288/300][30/78]	eta 0:01:43 lr 0.023643	time 1.5219 (2.1548)	loss 2.1523 (2.1583)	grad_norm 0.6364 (0.6366)	mem 39782MB
[2023-07-07 18:27:26 RepVGG-A0] (main.py 282): INFO Train: [288/300][40/78]	eta 0:01:18 lr 0.023125	time 3.6320 (2.0574)	loss 2.1560 (2.1586)	grad_norm 0.6396 (0.6369)	mem 39782MB
[2023-07-07 18:27:41 RepVGG-A0] (main.py 282): INFO Train: [288/300][50/78]	eta 0:00:54 lr 0.022612	time 1.1741 (1.9558)	loss 2.1674 (2.1636)	grad_norm 0.6432 (0.6380)	mem 39782MB
[2023-07-07 18:27:57 RepVGG-A0] (main.py 282): INFO Train: [288/300][60/78]	eta 0:00:33 lr 0.022105	time 1.2888 (1.8887)	loss 2.1063 (2.1618)	grad_norm 0.6505 (0.6383)	mem 39782MB
[2023-07-07 18:28:13 RepVGG-A0] (main.py 282): INFO Train: [288/300][70/78]	eta 0:00:14 lr 0.021604	time 1.6026 (1.8495)	loss 2.1535 (2.1616)	grad_norm 0.6443 (0.6382)	mem 39782MB
[2023-07-07 18:28:23 RepVGG-A0] (main.py 291): INFO EPOCH 288 training takes 0:02:21
[2023-07-07 18:28:45 RepVGG-A0] (main.py 282): INFO Train: [289/300][0/78]	eta 0:28:20 lr 0.021207	time 21.7957 (21.7957)	loss 2.1298 (2.1298)	grad_norm 0.6301 (0.6301)	mem 39782MB
[2023-07-07 18:28:59 RepVGG-A0] (main.py 282): INFO Train: [289/300][10/78]	eta 0:03:43 lr 0.020716	time 1.1750 (3.2797)	loss 2.1260 (2.1378)	grad_norm 0.6348 (0.6334)	mem 39782MB
[2023-07-07 18:29:14 RepVGG-A0] (main.py 282): INFO Train: [289/300][20/78]	eta 0:02:18 lr 0.020231	time 1.1716 (2.3922)	loss 2.1567 (2.1445)	grad_norm 0.6334 (0.6342)	mem 39782MB
[2023-07-07 18:29:29 RepVGG-A0] (main.py 282): INFO Train: [289/300][30/78]	eta 0:01:41 lr 0.019752	time 1.4564 (2.1180)	loss 2.1128 (2.1440)	grad_norm 0.6473 (0.6355)	mem 39782MB
[2023-07-07 18:29:47 RepVGG-A0] (main.py 282): INFO Train: [289/300][40/78]	eta 0:01:17 lr 0.019278	time 3.2528 (2.0307)	loss 2.1422 (2.1475)	grad_norm 0.6360 (0.6361)	mem 39782MB
[2023-07-07 18:30:02 RepVGG-A0] (main.py 282): INFO Train: [289/300][50/78]	eta 0:00:54 lr 0.018810	time 1.1738 (1.9325)	loss 2.1283 (2.1483)	grad_norm 0.6379 (0.6367)	mem 39782MB
[2023-07-07 18:30:17 RepVGG-A0] (main.py 282): INFO Train: [289/300][60/78]	eta 0:00:33 lr 0.018348	time 1.2602 (1.8637)	loss 2.1711 (2.1485)	grad_norm 0.6434 (0.6373)	mem 39782MB
[2023-07-07 18:30:32 RepVGG-A0] (main.py 282): INFO Train: [289/300][70/78]	eta 0:00:14 lr 0.017891	time 1.2577 (1.8082)	loss 2.1927 (2.1513)	grad_norm 0.6380 (0.6376)	mem 39782MB
[2023-07-07 18:30:44 RepVGG-A0] (main.py 291): INFO EPOCH 289 training takes 0:02:20
[2023-07-07 18:31:05 RepVGG-A0] (main.py 282): INFO Train: [290/300][0/78]	eta 0:27:57 lr 0.017530	time 21.5069 (21.5069)	loss 2.1261 (2.1261)	grad_norm 0.6331 (0.6331)	mem 39782MB
[2023-07-07 18:31:20 RepVGG-A0] (main.py 282): INFO Train: [290/300][10/78]	eta 0:03:45 lr 0.017084	time 1.1748 (3.3233)	loss 2.1567 (2.1388)	grad_norm 0.6345 (0.6371)	mem 39782MB
[2023-07-07 18:31:36 RepVGG-A0] (main.py 282): INFO Train: [290/300][20/78]	eta 0:02:23 lr 0.016643	time 1.1741 (2.4764)	loss 2.1179 (2.1468)	grad_norm 0.6403 (0.6375)	mem 39782MB
[2023-07-07 18:31:51 RepVGG-A0] (main.py 282): INFO Train: [290/300][30/78]	eta 0:01:43 lr 0.016209	time 1.3465 (2.1597)	loss 2.1389 (2.1519)	grad_norm 0.6392 (0.6381)	mem 39782MB
[2023-07-07 18:32:09 RepVGG-A0] (main.py 282): INFO Train: [290/300][40/78]	eta 0:01:19 lr 0.015780	time 3.7550 (2.0828)	loss 2.1376 (2.1529)	grad_norm 0.6362 (0.6382)	mem 39782MB
[2023-07-07 18:32:24 RepVGG-A0] (main.py 282): INFO Train: [290/300][50/78]	eta 0:00:55 lr 0.015356	time 1.1798 (1.9674)	loss 2.2215 (2.1557)	grad_norm 0.6442 (0.6385)	mem 39782MB
[2023-07-07 18:32:39 RepVGG-A0] (main.py 282): INFO Train: [290/300][60/78]	eta 0:00:33 lr 0.014939	time 1.3565 (1.8879)	loss 2.0862 (2.1523)	grad_norm 0.6374 (0.6388)	mem 39782MB
[2023-07-07 18:32:54 RepVGG-A0] (main.py 282): INFO Train: [290/300][70/78]	eta 0:00:14 lr 0.014527	time 1.1934 (1.8366)	loss 2.1847 (2.1526)	grad_norm 0.6340 (0.6390)	mem 39782MB
[2023-07-07 18:33:06 RepVGG-A0] (main.py 291): INFO EPOCH 290 training takes 0:02:21
[2023-07-07 18:33:23 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.693 (17.693)	Loss 1.3477 (1.3477)	Acc@1 70.551 (70.551)	Acc@5 89.075 (89.075)	Mem 39782MB
[2023-07-07 18:33:24 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.714 Acc@5 89.520
[2023-07-07 18:33:24 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 290: 70.714%
[2023-07-07 18:33:24 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:33:46 RepVGG-A0] (main.py 282): INFO Train: [291/300][0/78]	eta 0:27:49 lr 0.014202	time 21.4009 (21.4009)	loss 2.1533 (2.1533)	grad_norm 0.6434 (0.6434)	mem 39782MB
[2023-07-07 18:34:01 RepVGG-A0] (main.py 282): INFO Train: [291/300][10/78]	eta 0:03:48 lr 0.013800	time 1.1920 (3.3616)	loss 2.1908 (2.1471)	grad_norm 0.6438 (0.6372)	mem 39782MB
[2023-07-07 18:34:15 RepVGG-A0] (main.py 282): INFO Train: [291/300][20/78]	eta 0:02:20 lr 0.013405	time 1.1732 (2.4182)	loss 2.1200 (2.1447)	grad_norm 0.6340 (0.6360)	mem 39782MB
[2023-07-07 18:34:30 RepVGG-A0] (main.py 282): INFO Train: [291/300][30/78]	eta 0:01:41 lr 0.013015	time 1.3645 (2.1069)	loss 2.1394 (2.1475)	grad_norm 0.6422 (0.6367)	mem 39782MB
[2023-07-07 18:34:48 RepVGG-A0] (main.py 282): INFO Train: [291/300][40/78]	eta 0:01:17 lr 0.012630	time 3.3685 (2.0318)	loss 2.1450 (2.1492)	grad_norm 0.6372 (0.6366)	mem 39782MB
[2023-07-07 18:35:03 RepVGG-A0] (main.py 282): INFO Train: [291/300][50/78]	eta 0:00:53 lr 0.012252	time 1.3530 (1.9227)	loss 2.1544 (2.1487)	grad_norm 0.6398 (0.6368)	mem 39782MB
[2023-07-07 18:35:17 RepVGG-A0] (main.py 282): INFO Train: [291/300][60/78]	eta 0:00:33 lr 0.011879	time 1.1752 (1.8416)	loss 2.1626 (2.1507)	grad_norm 0.6288 (0.6369)	mem 39782MB
[2023-07-07 18:35:32 RepVGG-A0] (main.py 282): INFO Train: [291/300][70/78]	eta 0:00:14 lr 0.011512	time 1.3313 (1.7902)	loss 2.1466 (2.1507)	grad_norm 0.6503 (0.6372)	mem 39782MB
[2023-07-07 18:35:44 RepVGG-A0] (main.py 291): INFO EPOCH 291 training takes 0:02:19
[2023-07-07 18:36:01 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.290 (17.290)	Loss 1.3313 (1.3313)	Acc@1 70.636 (70.636)	Acc@5 89.459 (89.459)	Mem 39782MB
[2023-07-07 18:36:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.680 Acc@5 89.592
[2023-07-07 18:36:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 291: 70.680%
[2023-07-07 18:36:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:36:25 RepVGG-A0] (main.py 282): INFO Train: [292/300][0/78]	eta 0:28:57 lr 0.011223	time 22.2803 (22.2803)	loss 2.1440 (2.1440)	grad_norm 0.6248 (0.6248)	mem 39782MB
[2023-07-07 18:36:39 RepVGG-A0] (main.py 282): INFO Train: [292/300][10/78]	eta 0:03:47 lr 0.010866	time 1.1987 (3.3421)	loss 2.1701 (2.1499)	grad_norm 0.6354 (0.6333)	mem 39782MB
[2023-07-07 18:36:52 RepVGG-A0] (main.py 282): INFO Train: [292/300][20/78]	eta 0:02:17 lr 0.010515	time 1.1727 (2.3662)	loss 2.1215 (2.1472)	grad_norm 0.6346 (0.6351)	mem 39782MB
[2023-07-07 18:37:09 RepVGG-A0] (main.py 282): INFO Train: [292/300][30/78]	eta 0:01:43 lr 0.010170	time 1.6847 (2.1502)	loss 2.0952 (2.1450)	grad_norm 0.6324 (0.6356)	mem 39782MB
[2023-07-07 18:37:24 RepVGG-A0] (main.py 282): INFO Train: [292/300][40/78]	eta 0:01:15 lr 0.009831	time 1.5491 (1.9977)	loss 2.0779 (2.1458)	grad_norm 0.6360 (0.6356)	mem 39782MB
[2023-07-07 18:37:42 RepVGG-A0] (main.py 282): INFO Train: [292/300][50/78]	eta 0:00:54 lr 0.009497	time 1.1753 (1.9501)	loss 2.1334 (2.1472)	grad_norm 0.6320 (0.6359)	mem 39782MB
[2023-07-07 18:37:57 RepVGG-A0] (main.py 282): INFO Train: [292/300][60/78]	eta 0:00:33 lr 0.009169	time 1.1290 (1.8785)	loss 2.1505 (2.1488)	grad_norm 0.6324 (0.6360)	mem 39782MB
[2023-07-07 18:38:12 RepVGG-A0] (main.py 282): INFO Train: [292/300][70/78]	eta 0:00:14 lr 0.008847	time 1.3467 (1.8273)	loss 2.1346 (2.1495)	grad_norm 0.6374 (0.6361)	mem 39782MB
[2023-07-07 18:38:24 RepVGG-A0] (main.py 291): INFO EPOCH 292 training takes 0:02:21
[2023-07-07 18:38:41 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.245 (17.245)	Loss 1.3228 (1.3228)	Acc@1 70.398 (70.398)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:38:42 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.696 Acc@5 89.542
[2023-07-07 18:38:42 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 292: 70.696%
[2023-07-07 18:38:42 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.71%
[2023-07-07 18:39:04 RepVGG-A0] (main.py 282): INFO Train: [293/300][0/78]	eta 0:28:23 lr 0.008594	time 21.8459 (21.8459)	loss 2.1887 (2.1887)	grad_norm 0.6353 (0.6353)	mem 39782MB
[2023-07-07 18:39:19 RepVGG-A0] (main.py 282): INFO Train: [293/300][10/78]	eta 0:03:46 lr 0.008282	time 1.1720 (3.3330)	loss 2.1447 (2.1496)	grad_norm 0.6343 (0.6344)	mem 39782MB
[2023-07-07 18:39:34 RepVGG-A0] (main.py 282): INFO Train: [293/300][20/78]	eta 0:02:22 lr 0.007976	time 1.2608 (2.4580)	loss 2.1501 (2.1493)	grad_norm 0.6426 (0.6347)	mem 39782MB
[2023-07-07 18:39:48 RepVGG-A0] (main.py 282): INFO Train: [293/300][30/78]	eta 0:01:42 lr 0.007676	time 1.4421 (2.1310)	loss 2.0894 (2.1455)	grad_norm 0.6335 (0.6353)	mem 39782MB
[2023-07-07 18:40:06 RepVGG-A0] (main.py 282): INFO Train: [293/300][40/78]	eta 0:01:17 lr 0.007381	time 3.1009 (2.0442)	loss 2.1388 (2.1415)	grad_norm 0.6293 (0.6353)	mem 39782MB
[2023-07-07 18:40:21 RepVGG-A0] (main.py 282): INFO Train: [293/300][50/78]	eta 0:00:54 lr 0.007092	time 1.1728 (1.9330)	loss 2.1343 (2.1424)	grad_norm 0.6350 (0.6354)	mem 39782MB
[2023-07-07 18:40:37 RepVGG-A0] (main.py 282): INFO Train: [293/300][60/78]	eta 0:00:33 lr 0.006809	time 1.3787 (1.8754)	loss 2.1478 (2.1437)	grad_norm 0.6328 (0.6346)	mem 39782MB
[2023-07-07 18:40:51 RepVGG-A0] (main.py 282): INFO Train: [293/300][70/78]	eta 0:00:14 lr 0.006532	time 1.4238 (1.8195)	loss 2.1020 (2.1413)	grad_norm 0.6330 (0.6345)	mem 39782MB
[2023-07-07 18:41:04 RepVGG-A0] (main.py 291): INFO EPOCH 293 training takes 0:02:21
[2023-07-07 18:41:21 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.199 (17.199)	Loss 1.3155 (1.3155)	Acc@1 70.862 (70.862)	Acc@5 89.648 (89.648)	Mem 39782MB
[2023-07-07 18:41:22 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.908 Acc@5 89.588
[2023-07-07 18:41:22 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 293: 70.908%
[2023-07-07 18:41:22 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:41:45 RepVGG-A0] (main.py 282): INFO Train: [294/300][0/78]	eta 0:29:26 lr 0.006314	time 22.6530 (22.6530)	loss 2.1165 (2.1165)	grad_norm 0.6317 (0.6317)	mem 39782MB
[2023-07-07 18:41:59 RepVGG-A0] (main.py 282): INFO Train: [294/300][10/78]	eta 0:03:49 lr 0.006048	time 1.1708 (3.3743)	loss 2.0872 (2.1203)	grad_norm 0.6324 (0.6331)	mem 39782MB
[2023-07-07 18:42:13 RepVGG-A0] (main.py 282): INFO Train: [294/300][20/78]	eta 0:02:21 lr 0.005786	time 1.1763 (2.4355)	loss 2.1422 (2.1347)	grad_norm 0.6389 (0.6340)	mem 39782MB
[2023-07-07 18:42:29 RepVGG-A0] (main.py 282): INFO Train: [294/300][30/78]	eta 0:01:42 lr 0.005531	time 1.1932 (2.1449)	loss 2.1898 (2.1384)	grad_norm 0.6441 (0.6348)	mem 39782MB
[2023-07-07 18:42:47 RepVGG-A0] (main.py 282): INFO Train: [294/300][40/78]	eta 0:01:18 lr 0.005281	time 3.6150 (2.0665)	loss 2.1144 (2.1419)	grad_norm 0.6303 (0.6342)	mem 39782MB
[2023-07-07 18:43:01 RepVGG-A0] (main.py 282): INFO Train: [294/300][50/78]	eta 0:00:54 lr 0.005038	time 1.1729 (1.9488)	loss 2.1564 (2.1432)	grad_norm 0.6358 (0.6345)	mem 39782MB
[2023-07-07 18:43:16 RepVGG-A0] (main.py 282): INFO Train: [294/300][60/78]	eta 0:00:33 lr 0.004800	time 1.3459 (1.8746)	loss 2.1684 (2.1436)	grad_norm 0.6295 (0.6341)	mem 39782MB
[2023-07-07 18:43:32 RepVGG-A0] (main.py 282): INFO Train: [294/300][70/78]	eta 0:00:14 lr 0.004567	time 1.3447 (1.8283)	loss 2.1536 (2.1424)	grad_norm 0.6185 (0.6338)	mem 39782MB
[2023-07-07 18:43:43 RepVGG-A0] (main.py 291): INFO EPOCH 294 training takes 0:02:20
[2023-07-07 18:44:00 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.465 (17.465)	Loss 1.3250 (1.3250)	Acc@1 70.532 (70.532)	Acc@5 89.752 (89.752)	Mem 39782MB
[2023-07-07 18:44:02 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.842 Acc@5 89.598
[2023-07-07 18:44:02 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 294: 70.842%
[2023-07-07 18:44:02 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:44:23 RepVGG-A0] (main.py 282): INFO Train: [295/300][0/78]	eta 0:27:19 lr 0.004385	time 21.0140 (21.0140)	loss 2.1333 (2.1333)	grad_norm 0.6282 (0.6282)	mem 39782MB
[2023-07-07 18:44:38 RepVGG-A0] (main.py 282): INFO Train: [295/300][10/78]	eta 0:03:42 lr 0.004164	time 1.1695 (3.2759)	loss 2.0898 (2.1360)	grad_norm 0.6271 (0.6331)	mem 39782MB
[2023-07-07 18:44:52 RepVGG-A0] (main.py 282): INFO Train: [295/300][20/78]	eta 0:02:18 lr 0.003947	time 1.1714 (2.3957)	loss 2.1360 (2.1417)	grad_norm 0.6318 (0.6325)	mem 39782MB
[2023-07-07 18:45:07 RepVGG-A0] (main.py 282): INFO Train: [295/300][30/78]	eta 0:01:41 lr 0.003737	time 1.3594 (2.1119)	loss 2.1212 (2.1386)	grad_norm 0.6297 (0.6330)	mem 39782MB
[2023-07-07 18:45:25 RepVGG-A0] (main.py 282): INFO Train: [295/300][40/78]	eta 0:01:17 lr 0.003532	time 3.1347 (2.0296)	loss 2.2051 (2.1397)	grad_norm 0.6445 (0.6335)	mem 39782MB
[2023-07-07 18:45:40 RepVGG-A0] (main.py 282): INFO Train: [295/300][50/78]	eta 0:00:54 lr 0.003333	time 1.1755 (1.9341)	loss 2.1870 (2.1404)	grad_norm 0.6327 (0.6334)	mem 39782MB
[2023-07-07 18:45:55 RepVGG-A0] (main.py 282): INFO Train: [295/300][60/78]	eta 0:00:33 lr 0.003140	time 1.3639 (1.8630)	loss 2.1372 (2.1400)	grad_norm 0.6386 (0.6334)	mem 39782MB
[2023-07-07 18:46:10 RepVGG-A0] (main.py 282): INFO Train: [295/300][70/78]	eta 0:00:14 lr 0.002953	time 1.1545 (1.8038)	loss 2.1218 (2.1404)	grad_norm 0.6326 (0.6333)	mem 39782MB
[2023-07-07 18:46:22 RepVGG-A0] (main.py 291): INFO EPOCH 295 training takes 0:02:20
[2023-07-07 18:46:39 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.251 (17.251)	Loss 1.3213 (1.3213)	Acc@1 70.807 (70.807)	Acc@5 89.526 (89.526)	Mem 39782MB
[2023-07-07 18:46:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.834 Acc@5 89.672
[2023-07-07 18:46:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 295: 70.834%
[2023-07-07 18:46:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:47:03 RepVGG-A0] (main.py 282): INFO Train: [296/300][0/78]	eta 0:29:08 lr 0.002807	time 22.4186 (22.4186)	loss 2.1439 (2.1439)	grad_norm 0.6409 (0.6409)	mem 39782MB
[2023-07-07 18:47:18 RepVGG-A0] (main.py 282): INFO Train: [296/300][10/78]	eta 0:03:48 lr 0.002630	time 1.1724 (3.3655)	loss 2.1511 (2.1400)	grad_norm 0.6360 (0.6313)	mem 39782MB
[2023-07-07 18:47:32 RepVGG-A0] (main.py 282): INFO Train: [296/300][20/78]	eta 0:02:21 lr 0.002459	time 1.1913 (2.4429)	loss 2.1945 (2.1427)	grad_norm 0.6263 (0.6316)	mem 39782MB
[2023-07-07 18:47:48 RepVGG-A0] (main.py 282): INFO Train: [296/300][30/78]	eta 0:01:44 lr 0.002293	time 1.1586 (2.1708)	loss 2.1505 (2.1457)	grad_norm 0.6213 (0.6309)	mem 39782MB
[2023-07-07 18:48:05 RepVGG-A0] (main.py 282): INFO Train: [296/300][40/78]	eta 0:01:17 lr 0.002133	time 3.9098 (2.0486)	loss 2.1213 (2.1431)	grad_norm 0.6220 (0.6305)	mem 39782MB
[2023-07-07 18:48:20 RepVGG-A0] (main.py 282): INFO Train: [296/300][50/78]	eta 0:00:54 lr 0.001979	time 1.1731 (1.9422)	loss 2.1143 (2.1399)	grad_norm 0.6307 (0.6305)	mem 39782MB
[2023-07-07 18:48:35 RepVGG-A0] (main.py 282): INFO Train: [296/300][60/78]	eta 0:00:33 lr 0.001831	time 1.1770 (1.8776)	loss 2.1079 (2.1386)	grad_norm 0.6358 (0.6309)	mem 39782MB
[2023-07-07 18:48:51 RepVGG-A0] (main.py 282): INFO Train: [296/300][70/78]	eta 0:00:14 lr 0.001689	time 1.6679 (1.8416)	loss 2.1973 (2.1391)	grad_norm 0.6276 (0.6312)	mem 39782MB
[2023-07-07 18:49:02 RepVGG-A0] (main.py 291): INFO EPOCH 296 training takes 0:02:21
[2023-07-07 18:49:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.521 (17.521)	Loss 1.3167 (1.3167)	Acc@1 70.837 (70.837)	Acc@5 89.807 (89.807)	Mem 39782MB
[2023-07-07 18:49:21 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.906 Acc@5 89.658
[2023-07-07 18:49:21 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 296: 70.906%
[2023-07-07 18:49:21 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:49:41 RepVGG-A0] (main.py 282): INFO Train: [297/300][0/78]	eta 0:27:09 lr 0.001579	time 20.8961 (20.8961)	loss 2.1534 (2.1534)	grad_norm 0.6238 (0.6238)	mem 39782MB
[2023-07-07 18:49:57 RepVGG-A0] (main.py 282): INFO Train: [297/300][10/78]	eta 0:03:42 lr 0.001447	time 1.1717 (3.2745)	loss 2.1372 (2.1318)	grad_norm 0.6274 (0.6294)	mem 39782MB
[2023-07-07 18:50:12 RepVGG-A0] (main.py 282): INFO Train: [297/300][20/78]	eta 0:02:20 lr 0.001321	time 1.1731 (2.4306)	loss 2.1724 (2.1363)	grad_norm 0.6337 (0.6296)	mem 39782MB
[2023-07-07 18:50:27 RepVGG-A0] (main.py 282): INFO Train: [297/300][30/78]	eta 0:01:42 lr 0.001200	time 1.3848 (2.1412)	loss 2.1238 (2.1387)	grad_norm 0.6343 (0.6302)	mem 39782MB
[2023-07-07 18:50:44 RepVGG-A0] (main.py 282): INFO Train: [297/300][40/78]	eta 0:01:17 lr 0.001085	time 3.6906 (2.0387)	loss 2.1446 (2.1376)	grad_norm 0.6336 (0.6305)	mem 39782MB
[2023-07-07 18:51:00 RepVGG-A0] (main.py 282): INFO Train: [297/300][50/78]	eta 0:00:54 lr 0.000976	time 1.1890 (1.9424)	loss 2.1672 (2.1369)	grad_norm 0.6287 (0.6300)	mem 39782MB
[2023-07-07 18:51:15 RepVGG-A0] (main.py 282): INFO Train: [297/300][60/78]	eta 0:00:33 lr 0.000873	time 1.3406 (1.8701)	loss 2.1833 (2.1374)	grad_norm 0.6384 (0.6298)	mem 39782MB
[2023-07-07 18:51:31 RepVGG-A0] (main.py 282): INFO Train: [297/300][70/78]	eta 0:00:14 lr 0.000776	time 1.2780 (1.8384)	loss 2.1823 (2.1381)	grad_norm 0.6278 (0.6301)	mem 39782MB
[2023-07-07 18:51:42 RepVGG-A0] (main.py 291): INFO EPOCH 297 training takes 0:02:21
[2023-07-07 18:51:59 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.038 (17.038)	Loss 1.3204 (1.3204)	Acc@1 70.703 (70.703)	Acc@5 89.709 (89.709)	Mem 39782MB
[2023-07-07 18:52:01 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.910 Acc@5 89.666
[2023-07-07 18:52:01 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 297: 70.910%
[2023-07-07 18:52:01 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.91%
[2023-07-07 18:52:24 RepVGG-A0] (main.py 282): INFO Train: [298/300][0/78]	eta 0:29:17 lr 0.000702	time 22.5303 (22.5303)	loss 2.1638 (2.1638)	grad_norm 0.6243 (0.6243)	mem 39782MB
[2023-07-07 18:52:37 RepVGG-A0] (main.py 282): INFO Train: [298/300][10/78]	eta 0:03:44 lr 0.000615	time 1.1763 (3.2961)	loss 2.1846 (2.1489)	grad_norm 0.6289 (0.6289)	mem 39782MB
[2023-07-07 18:52:52 RepVGG-A0] (main.py 282): INFO Train: [298/300][20/78]	eta 0:02:20 lr 0.000533	time 1.1726 (2.4157)	loss 2.1796 (2.1459)	grad_norm 0.6324 (0.6287)	mem 39782MB
[2023-07-07 18:53:07 RepVGG-A0] (main.py 282): INFO Train: [298/300][30/78]	eta 0:01:42 lr 0.000458	time 1.5416 (2.1411)	loss 2.1823 (2.1442)	grad_norm 0.6304 (0.6298)	mem 39782MB
[2023-07-07 18:53:26 RepVGG-A0] (main.py 282): INFO Train: [298/300][40/78]	eta 0:01:18 lr 0.000388	time 3.9216 (2.0756)	loss 2.1699 (2.1400)	grad_norm 0.6381 (0.6295)	mem 39782MB
[2023-07-07 18:53:41 RepVGG-A0] (main.py 282): INFO Train: [298/300][50/78]	eta 0:00:55 lr 0.000324	time 1.1806 (1.9649)	loss 2.1433 (2.1417)	grad_norm 0.6352 (0.6292)	mem 39782MB
[2023-07-07 18:53:56 RepVGG-A0] (main.py 282): INFO Train: [298/300][60/78]	eta 0:00:33 lr 0.000266	time 1.2015 (1.8833)	loss 2.1315 (2.1424)	grad_norm 0.6251 (0.6291)	mem 39782MB
[2023-07-07 18:54:11 RepVGG-A0] (main.py 282): INFO Train: [298/300][70/78]	eta 0:00:14 lr 0.000213	time 1.3958 (1.8315)	loss 2.1914 (2.1416)	grad_norm 0.6323 (0.6295)	mem 39782MB
[2023-07-07 18:54:23 RepVGG-A0] (main.py 291): INFO EPOCH 298 training takes 0:02:21
[2023-07-07 18:54:40 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.112 (17.112)	Loss 1.3234 (1.3234)	Acc@1 70.844 (70.844)	Acc@5 89.368 (89.368)	Mem 39782MB
[2023-07-07 18:54:41 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.926 Acc@5 89.596
[2023-07-07 18:54:41 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 298: 70.926%
[2023-07-07 18:54:41 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:55:02 RepVGG-A0] (main.py 282): INFO Train: [299/300][0/78]	eta 0:27:03 lr 0.000175	time 20.8161 (20.8161)	loss 2.1786 (2.1786)	grad_norm 0.6278 (0.6278)	mem 39782MB
[2023-07-07 18:55:18 RepVGG-A0] (main.py 282): INFO Train: [299/300][10/78]	eta 0:03:46 lr 0.000133	time 1.1722 (3.3242)	loss 2.1209 (2.1449)	grad_norm 0.6257 (0.6300)	mem 39782MB
[2023-07-07 18:55:33 RepVGG-A0] (main.py 282): INFO Train: [299/300][20/78]	eta 0:02:22 lr 0.000097	time 1.1924 (2.4495)	loss 2.0722 (2.1457)	grad_norm 0.6276 (0.6300)	mem 39782MB
[2023-07-07 18:55:48 RepVGG-A0] (main.py 282): INFO Train: [299/300][30/78]	eta 0:01:43 lr 0.000066	time 1.3308 (2.1553)	loss 2.1286 (2.1368)	grad_norm 0.6263 (0.6297)	mem 39782MB
[2023-07-07 18:56:06 RepVGG-A0] (main.py 282): INFO Train: [299/300][40/78]	eta 0:01:18 lr 0.000042	time 2.6801 (2.0589)	loss 2.1266 (2.1359)	grad_norm 0.6283 (0.6291)	mem 39782MB
[2023-07-07 18:56:21 RepVGG-A0] (main.py 282): INFO Train: [299/300][50/78]	eta 0:00:54 lr 0.000023	time 1.1728 (1.9436)	loss 2.0933 (2.1382)	grad_norm 0.6304 (0.6295)	mem 39782MB
[2023-07-07 18:56:35 RepVGG-A0] (main.py 282): INFO Train: [299/300][60/78]	eta 0:00:33 lr 0.000009	time 1.1726 (1.8621)	loss 2.1472 (2.1364)	grad_norm 0.6289 (0.6294)	mem 39782MB
[2023-07-07 18:56:50 RepVGG-A0] (main.py 282): INFO Train: [299/300][70/78]	eta 0:00:14 lr 0.000002	time 1.2507 (1.8180)	loss 2.1508 (2.1372)	grad_norm 0.6317 (0.6294)	mem 39782MB
[2023-07-07 18:57:02 RepVGG-A0] (main.py 291): INFO EPOCH 299 training takes 0:02:20
[2023-07-07 18:57:19 RepVGG-A0] (main.py 334): INFO Test: [0/4]	Time 17.035 (17.035)	Loss 1.3233 (1.3233)	Acc@1 70.471 (70.471)	Acc@5 89.478 (89.478)	Mem 39782MB
[2023-07-07 18:57:20 RepVGG-A0] (main.py 342): INFO  * Acc@1 70.892 Acc@5 89.628
[2023-07-07 18:57:20 RepVGG-A0] (main.py 170): INFO Accuracy of the network at epoch 299: 70.892%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 172): INFO Max accuracy: 70.93%
[2023-07-07 18:57:20 RepVGG-A0] (main.py 194): INFO Training time 11:54:08
